From thanot at infovista.com  Fri Dec  1 02:28:16 2006
From: thanot at infovista.com (Thierry Hanot)
Date: Fri, 1 Dec 2006 08:28:16 +0100
Subject: [concurrency-interest] Proposal WeightedLinkedBoundedQueue
Message-ID: <0329C0D74DD1D64F98E6C6B43B5C78108B5457@frlulms01.iv.local>

Thanks a lot of these remarks.
The starvation can be a problem in my case. To avoid it I was thinking about using the fairness parameter on the locks.
Concerning heavy object (with weight greater than the max, I wanted to handle that using the atomics and a [greater or equal] not the semaphore.

B.R

Thierry Hanot  

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Brian Goetz
Sent: vendredi 1 d?cembre 2006 03:27
To: dholmes at ieee.org
Cc: concurrency-interest
Subject: Re: [concurrency-interest] Proposal WeightedLinkedBoundedQueue

That's what I meant -- the implementation _should_ reject it out of 
hand.  If it doesn't, it is subject to deadlock.

David Holmes wrote:
> But if the bound of 100 is a hard-bound then the enqueue of 101 should be
> rejected out of hand.
> 
> David Holmes
> 
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
>> Goetz
>> Sent: Friday, 1 December 2006 10:07 AM
>> To: Dawid Kurzyniec; concurrency-interest
>> Subject: Re: [concurrency-interest] Proposal WeightedLinkedBoundedQueue
>>
>>
>> Although there's a really unfortunate deadlock interaction if you use a
>> fair semaphore: you have a queue with a bound of 100 and someone tries
>> to enqueue an object of weight 101.  With a fair semaphore, it's game
>> over -- no one will ever succeed in enqueuing again.
>>
>>> Just one more thing - I am not sure if this is going to be a problem in
>>> your case, but are you aware of potential starvation scenarios? E.g. if
>>> your queue is full most of the time, and if you have a requestor that
>>> wants to put a really large object in the queue, it might never get a
>>> chance to do so (losing competition with other requestors putting
>>> smaller objects, so that there is never enough space available for the
>>> big guy). In the semaphore-based approach, you could prevent this by
>>> using a fair semaphore. If you're doing it by hand, you might want to be
>>> careful about this.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at altair.cs.oswego.edu
>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From david at walend.net  Fri Dec  1 10:46:06 2006
From: david at walend.net (David Walend)
Date: Fri, 1 Dec 2006 10:46:06 -0500
Subject: [concurrency-interest] Any fix for bug 6460501:
	AbstractQueuedSynchronizer$Node memory leak in BlockingQueues
In-Reply-To: <mailman.439.1161148675.2135.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.439.1161148675.2135.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>

I need your help with a leak of  
java.util.concurrent.locks.AbstractQueuedSynchronizer$Node s I'm  
seeing in a big application using SomnifugiJMS. In a profiler run of  
about two hours, it's leaking about 250,000 instances in an idle  
system. (Netbeans profiler says that is about 8 MB. I'm pretty sure  
it's a big contributor to why we're running out of memory in 4-day  
runs, but haven't made a profile run that long.) The allocation stack  
trace says these are getting allocated when I call  
PriorityBlockingQueue's poll() method with a timeout of 100 ms. I  
think it only leaks when the call times out, but don't have good  
evidence for that.

I found bug 6460501 ( http://bugs.sun.com/bugdatabase/view_bug.do? 
bug_id=6460501 ) which seems to be a match.

We're committed to using Java5.

Any suggestions for a fix or a work-around? Is there one already in  
the concurrency backport?

Thanks,

Dave

David Walend
david at walend.net



From dawidk at mathcs.emory.edu  Fri Dec  1 13:01:20 2006
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Fri, 01 Dec 2006 13:01:20 -0500
Subject: [concurrency-interest] Any fix for bug
 6460501:	AbstractQueuedSynchronizer$Node memory leak in BlockingQueues
In-Reply-To: <F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>
References: <mailman.439.1161148675.2135.concurrency-interest@altair.cs.oswego.edu>
	<F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>
Message-ID: <45706DF0.9050305@mathcs.emory.edu>

David Walend wrote:
> I need your help with a leak of  
> java.util.concurrent.locks.AbstractQueuedSynchronizer$Node s I'm  
> seeing in a big application using SomnifugiJMS. In a profiler run of  
> about two hours, it's leaking about 250,000 instances in an idle  
> system. (Netbeans profiler says that is about 8 MB. I'm pretty sure  
> it's a big contributor to why we're running out of memory in 4-day  
> runs, but haven't made a profile run that long.) The allocation stack  
> trace says these are getting allocated when I call  
> PriorityBlockingQueue's poll() method with a timeout of 100 ms. I  
> think it only leaks when the call times out, but don't have good  
> evidence for that.
>
> I found bug 6460501 ( http://bugs.sun.com/bugdatabase/view_bug.do? 
> bug_id=6460501 ) which seems to be a match.
>
> We're committed to using Java5.
>
> Any suggestions for a fix or a work-around? Is there one already in  
> the concurrency backport?
>   

There is jsr166.jar, updated on September 5, in which there is some fix 
labeled "Avoid memory leak on timeouts". I don't know if it fully solves 
the problem, I guess this is a question to Doug Lea. If yes, then I 
believe that by putting this JAR on your bootclasspath, you can override 
the platform's java.util.concurrent.

I suppose you could try using the backport as well. But don't use the 
backport version for "5.0", since it is using the native AQS and will 
probably suffer from the same problem. You would have to use standard 
1.4 backport, which does not rely on AQS at all, but it may have a 
performance impact. (Depending on the application, it may be 
unnoticeable, but it may be substantial, too).

Also, I would consider looking at the application logic, to see if you 
can avoid short timeouts in the first place. Short timeouts indicate 
that you're waiting for something else while trying to enqueue. Maybe 
you can write a specialized queue, that wakes up your putter thread once 
that something else happens?...


Regards,
Dawid


From david at walend.net  Sat Dec  2 12:53:15 2006
From: david at walend.net (David Walend)
Date: Sat, 2 Dec 2006 12:53:15 -0500
Subject: [concurrency-interest] Any fix for bug
	6460501:	AbstractQueuedSynchronizer$Node memory leak in
	BlockingQueues
In-Reply-To: <45706DF0.9050305@mathcs.emory.edu>
References: <mailman.439.1161148675.2135.concurrency-interest@altair.cs.oswego.edu>
	<F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>
	<45706DF0.9050305@mathcs.emory.edu>
Message-ID: <CE63FB58-80A0-40B1-8B41-0404AAECEDEA@walend.net>

On Dec 1, 2006, at 1:01 PM, Dawid Kurzyniec wrote:

> David Walend wrote:
>> I need your help with a leak of   
>> java.util.concurrent.locks.AbstractQueuedSynchronizer$Node s I'm   
>> seeing in a big application using SomnifugiJMS. ...
>> Any suggestions for a fix or a work-around? Is there one already  
>> in  the concurrency backport?
>>
>
> There is jsr166.jar, updated on September 5, in which there is some  
> fix labeled "Avoid memory leak on timeouts". I don't know if it  
> fully solves the problem, I guess this is a question to Doug Lea.  
> If yes, then I believe that by putting this JAR on your  
> bootclasspath, you can override the platform's java.util.concurrent.
>
> I suppose you could try using the backport as well. But don't use  
> the backport version for "5.0", since it is using the native AQS  
> and will probably suffer from the same problem. You would have to  
> use standard 1.4 backport, which does not rely on AQS at all, but  
> it may have a performance impact. (Depending on the application, it  
> may be unnoticeable, but it may be substantial, too).
>
> Also, I would consider looking at the application logic, to see if  
> you can avoid short timeouts in the first place. Short timeouts  
> indicate that you're waiting for something else while trying to  
> enqueue. Maybe you can write a specialized queue, that wakes up  
> your putter thread once that something else happens?...

Thanks for the suggestions, Dawid. You're right about the application  
logic (built by a guy who has since left our group), but that will  
take some effort to fix. From a design perspective, there's no need  
to have a time out. No one picked it up because no one has let the  
system sit idle that long. I'll post next week if the backport .jar  
fixes it.

Thanks again,

Dave

David Walend
david at walend.net



From dl at cs.oswego.edu  Sun Dec  3 19:00:00 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 03 Dec 2006 19:00:00 -0500
Subject: [concurrency-interest] Any fix for bug
 6460501:	AbstractQueuedSynchronizer$Node memory leak in BlockingQueues
In-Reply-To: <F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>
References: <mailman.439.1161148675.2135.concurrency-interest@altair.cs.oswego.edu>
	<F8F68778-4C5A-4BC3-AC6D-304E5B1C4C35@walend.net>
Message-ID: <45736500.9020201@cs.oswego.edu>

David Walend wrote:
> I need your help with a leak of  
> java.util.concurrent.locks.AbstractQueuedSynchronizer$Node s I'm  
> seeing in a big application using SomnifugiJMS. In a profiler run of  
> about two hours, it's leaking about 250,000 instances in an idle  
> system. (Netbeans profiler says that is about 8 MB. I'm pretty sure  
> it's a big contributor to why we're running out of memory in 4-day  
> runs, but haven't made a profile run that long.) The allocation stack  
> trace says these are getting allocated when I call  
> PriorityBlockingQueue's poll() method with a timeout of 100 ms. I  
> think it only leaks when the call times out, but don't have good  
> evidence for that.

This was, in retrospect, a design flaw in AQS: Originally,
internal nodes used in timeouts were only GCable when
a lock/condition/whatever was ever triggered. This turns out
not to be good enough when people continually time out on
events that never occur. So we've added mechanics to
clean out nodes even in these cases. Unfortunately, due
to missing freeze deadlines (months ago now), the full set
of them aren't even going to be in FCS of Java 6, but
will make some update release. (I did finally check the
last of these into our CVS though.)  Sorry about that.

> Any suggestions for a fix or a work-around? 

One workaround is to somehow occasionally trigger whatever
you are waiting for. Better though is to not continually use
short-time timeouts for things that never happen. Even
changing to use an exponential backoff would limit damage.

-Doug

From belaban at yahoo.com  Tue Dec  5 11:26:19 2006
From: belaban at yahoo.com (Bela Ban)
Date: Tue, 05 Dec 2006 17:26:19 +0100
Subject: [concurrency-interest] Upgrading a RL to WL in
	ReentrantReadWriteLock
Message-ID: <45759DAB.8010106@yahoo.com>

Apologies if this has been asked before - I tried to google and search 
the concurrency-interest mailing list archives, to no avail (note that 
the archives at 
http://altair.cs.oswego.edu/mailman/private/concurrency-interest/ cannot 
be searched ! It would be good if you guys could change this...).

We're using our own reentrant lock classes in JBossCache 
(http://labs.jboss.com/portal/jbosscache/), but we'd like to replace 
them with the java.util.concurrent.* equivalent classes. However, for 
ReentrantReadWriteLock, we need upgrading capabilities from RLs tro WLs. 
>From the documentation of RRWL:

   * *Lock downgrading*

     Reentrancy also allows downgrading from the write lock to a read
     lock, by acquiring the write lock, then the read lock and then
     releasing the write lock. However, upgrading from a read lock to
     the write lock is *not* possible.


What was the rationale for this ?

We would prefer *not* to release the RL first, then acquire the WL, as 
other threads might then be able to acquire RLs or WLs after the 
original thread releases the RL but before it acquires the WL.

-- 
Bela Ban
Lead JGroups / JBoss Clustering team
JBoss - a division of Red Hat


From dcholmes at optusnet.com.au  Tue Dec  5 17:17:44 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 6 Dec 2006 08:17:44 +1000
Subject: [concurrency-interest] Upgrading a RL to WL
	inReentrantReadWriteLock
In-Reply-To: <45759DAB.8010106@yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEGGHEAA.dcholmes@optusnet.com.au>

Hi,

This same question was asked only the other week.

http://altair.cs.oswego.edu/mailman/private/concurrency-interest/2006-Novemb
er/003323.html

See my response there as to original motivation to not support upgrading to
a write lock.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Bela Ban
> Sent: Wednesday, 6 December 2006 2:26 AM
> To: concurrency interest
> Subject: [concurrency-interest] Upgrading a RL to WL
> inReentrantReadWriteLock
>
>
> Apologies if this has been asked before - I tried to google and search
> the concurrency-interest mailing list archives, to no avail (note that
> the archives at
> http://altair.cs.oswego.edu/mailman/private/concurrency-interest/ cannot
> be searched ! It would be good if you guys could change this...).
>
> We're using our own reentrant lock classes in JBossCache
> (http://labs.jboss.com/portal/jbosscache/), but we'd like to replace
> them with the java.util.concurrent.* equivalent classes. However, for
> ReentrantReadWriteLock, we need upgrading capabilities from RLs tro WLs.
> >From the documentation of RRWL:
>
>    * *Lock downgrading*
>
>      Reentrancy also allows downgrading from the write lock to a read
>      lock, by acquiring the write lock, then the read lock and then
>      releasing the write lock. However, upgrading from a read lock to
>      the write lock is *not* possible.
>
>
> What was the rationale for this ?
>
> We would prefer *not* to release the RL first, then acquire the WL, as
> other threads might then be able to acquire RLs or WLs after the
> original thread releases the RL but before it acquires the WL.
>
> --
> Bela Ban
> Lead JGroups / JBoss Clustering team
> JBoss - a division of Red Hat
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From belaban at yahoo.com  Wed Dec  6 05:33:30 2006
From: belaban at yahoo.com (Bela Ban)
Date: Wed, 06 Dec 2006 11:33:30 +0100
Subject: [concurrency-interest] Upgrading a RL to WL
	inReentrantReadWriteLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEGGHEAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCMEGGHEAA.dcholmes@optusnet.com.au>
Message-ID: <45769C7A.6080700@yahoo.com>

Hi David,





David Holmes wrote:
> Hi,
>
> This same question was asked only the other week.

Sorry for repeating the question ! To avoid repetitive FAQ questions, it 
would be *very* important to make the concurrency-interest archives 
*searchable*, which is not the case today !


That said, with changes that went in to Java 6 to track read-lock ownership,
it shouldn't be too hard for you to modify ReentrantReadWriteLock to allow
the final-reader to acquire the writeLock.

That's exactly what we do in JBossCache. However, this stuff should be 
part of j.u.c.l itself, and not reside in application code. In our case, 
the semantics are that any reader can upgrade a RL to a WL *if* there 
are no other readers or writers present. So a typical scenario for 
ReentrantReadWriteLock is:

    * TX1 acquires a RL
    * TX2 acquires a RL
    * TX2 attempts an upgrade from RL to WL and blocks for N ms
    * (before N elapses): TX1 releases its RL
    * TX2 is able to upgrade its RL to a WL

If TX2 released its RL and then tried to acquire a WL directly, we could 
run into deadlocks (with ensuing timeouts and TX rollbacks) because 
locks are not acquired in the same order by all TXs.

For now, I will look into AQS as suggested by Tim. Thanks,

P.S.: JCIP is one of the few books that are a must-read (besides Doug's 
and Joshua's books), congrats to all the authors who are lingering on 
this list !


-- 
Bela Ban
Lead JGroups / JBoss Clustering team
JBoss - a division of Red Hat

From topppills at yahoo.com  Fri Dec  8 07:37:39 2006
From: topppills at yahoo.com (dan ker)
Date: Fri, 8 Dec 2006 04:37:39 -0800 (PST)
Subject: [concurrency-interest] Buy Viagra Online - THE LOWEST VIAGRA PRICE
	GUARANTEED.
Message-ID: <358951.29960.qm@web58812.mail.re1.yahoo.com>

Order Viagra Online From http://www.websfirst.info/viagra/ - THE LOWEST VIAGRA PRICE GUARANTEED,  Brand And Generic Viagra,       
Fast And Discreet Shipping Worldwide, Free Consultations.
http://www.websfirst.info/viagra/
   
   
   
   
   
   
   
   
   
   
  ..........................................

 
---------------------------------
Any questions?  Get answers on any topic at Yahoo! Answers. Try it now.
 
---------------------------------
Access over 1 million songs - Yahoo! Music Unlimited.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061208/e606ef67/attachment.html 

From gregg at cytetech.com  Fri Dec  8 16:39:45 2006
From: gregg at cytetech.com (Gregg Wonderly)
Date: Fri, 08 Dec 2006 15:39:45 -0600
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
Message-ID: <4579DBA1.4040300@cytetech.com>

I recently made some changes to a single large synchronized() block to use 
Futures and ConcurrentHashmap to distribute the locking to a finer grain.

I've been seeing some oddities in the behavior of the code after these changes, 
and today, I took a deeper look.  There is quite a bit of context and complexity 
around this code, it involves classloader creation in an RMIClassLoaderSPI 
implementation.  But, the basics are that when I use

	LoaderKey key = ...
	Future fut = ...
	Future runfut = map.putIfAbsent( key, fut );
	logger.info(this+": loader key[cur="+runfut+"] for access is: \""+key+"\", 
know: "+map );

I see that method returning null for multiple calls with the same key (as shown 
in the logging below).  If I change that single call to be

	LoaderKey key = ...
	Future fut = ...
	Future runfut = null;
	synchronized( map ) {
		runfut = map.get( key );
		if( runfut == null )
			map.put( key, fut );
	}

I see the expected behavior.

map is a class level object.  There is only a single instance of this class 
active and thus only one map defined.

Any thoughts on what I might be overlooking?

Gregg Wonderly

-------------------------------------------------------------------------
12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#10] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null] for 
access is: "LoaderKey: (parentnull=false) 
[vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 15151aa}

12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#11] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null] for 
access is: "LoaderKey: (parentnull=false) 
[vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 15151aa}

12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#12] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader 
key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2,LoaderKey: 
(parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 15151aa}

12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#13] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null] for 
access is: "LoaderKey: (parentnull=false) 
[vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 56c3cf, 
LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 15151aa}

12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#14] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null] for 
access is: "LoaderKey: (parentnull=false) 
[vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263, 
LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#15] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null] for 
access is: "LoaderKey: (parentnull=false) 
[vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263, 
LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#16] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader 
key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263,LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#17] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader 
key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263,LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#18] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader 
key[cur=java.util.concurrent.FutureTask at 515263] for access is: "LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263,LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#19] INFO # 
net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader 
key[cur=java.util.concurrent.FutureTask at f81402] for access is: "LoaderKey: 
(parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey: 
(parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 515263,LoaderKey: 
(parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar, 
vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at 7fc8b2, 
LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar, 
vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=java.util.concurrent.FutureTask at f81402}

From tim at peierls.net  Fri Dec  8 16:50:13 2006
From: tim at peierls.net (Tim Peierls)
Date: Fri, 8 Dec 2006 16:50:13 -0500
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <4579DBA1.4040300@cytetech.com>
References: <4579DBA1.4040300@cytetech.com>
Message-ID: <63b4e4050612081350s502fb3d8t760cbfa10e05955d@mail.gmail.com>

map.putIfAbsent uses identity semantics and map.get uses equals/hashCode
semantics.

--tim

On 12/8/06, Gregg Wonderly <gregg at cytetech.com> wrote:
>
> I recently made some changes to a single large synchronized() block to use
> Futures and ConcurrentHashmap to distribute the locking to a finer grain.
>
> I've been seeing some oddities in the behavior of the code after these
> changes,
> and today, I took a deeper look.  There is quite a bit of context and
> complexity
> around this code, it involves classloader creation in an RMIClassLoaderSPI
> implementation.  But, the basics are that when I use
>
>         LoaderKey key = ...
>         Future fut = ...
>         Future runfut = map.putIfAbsent( key, fut );
>         logger.info(this+": loader key[cur="+runfut+"] for access is:
> \""+key+"\",
> know: "+map );
>
> I see that method returning null for multiple calls with the same key (as
> shown
> in the logging below).  If I change that single call to be
>
>         LoaderKey key = ...
>         Future fut = ...
>         Future runfut = null;
>         synchronized( map ) {
>                 runfut = map.get( key );
>                 if( runfut == null )
>                         map.put( key, fut );
>         }
>
> I see the expected behavior.
>
> map is a class level object.  There is only a single instance of this
> class
> active and thus only one map defined.
>
> Any thoughts on what I might be overlooking?
>
> Gregg Wonderly
>
> -------------------------------------------------------------------------
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#10] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#11] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#12] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,LoaderKey:
> (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#13] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 56c3cf,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#14] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#15] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#16] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#17] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#18] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 515263] for access is: "LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#19] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at f81402] for access is: "LoaderKey:
> (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061208/7f1c1d4f/attachment-0001.html 

From tim at peierls.net  Fri Dec  8 16:52:13 2006
From: tim at peierls.net (Tim Peierls)
Date: Fri, 8 Dec 2006 16:52:13 -0500
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <63b4e4050612081350s502fb3d8t760cbfa10e05955d@mail.gmail.com>
References: <4579DBA1.4040300@cytetech.com>
	<63b4e4050612081350s502fb3d8t760cbfa10e05955d@mail.gmail.com>
Message-ID: <63b4e4050612081352i1e42453dp60dcc2330192c622@mail.gmail.com>

No, it doesn't. Forget I said anything.

On 12/8/06, Tim Peierls <tim at peierls.net> wrote:
>
> map.putIfAbsent uses identity semantics and map.get uses equals/hashCode
> semantics.
>
> --tim
>
> On 12/8/06, Gregg Wonderly < gregg at cytetech.com> wrote:
> >
> > I recently made some changes to a single large synchronized() block to
> > use
> > Futures and ConcurrentHashmap to distribute the locking to a finer
> > grain.
> >
> > I've been seeing some oddities in the behavior of the code after these
> > changes,
> > and today, I took a deeper look.  There is quite a bit of context and
> > complexity
> > around this code, it involves classloader creation in an
> > RMIClassLoaderSPI
> > implementation.  But, the basics are that when I use
> >
> >         LoaderKey key = ...
> >         Future fut = ...
> >         Future runfut = map.putIfAbsent( key, fut );
> >         logger.info(this+": loader key[cur="+runfut+"] for access is:
> > \""+key+"\",
> > know: "+map );
> >
> > I see that method returning null for multiple calls with the same key
> > (as shown
> > in the logging below).  If I change that single call to be
> >
> >         LoaderKey key = ...
> >         Future fut = ...
> >         Future runfut = null;
> >         synchronized( map ) {
> >                 runfut = map.get ( key );
> >                 if( runfut == null )
> >                         map.put( key, fut );
> >         }
> >
> > I see the expected behavior.
> >
> > map is a class level object.  There is only a single instance of this
> > class
> > active and thus only one map defined.
> >
> > Any thoughts on what I might be overlooking?
> >
> > Gregg Wonderly
> >
> >
> > -------------------------------------------------------------------------
> > 12/08/2006 15:33:29 [ net.jini.loader.pref.PreferredClassProvider#10]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> > for
> > access is: "LoaderKey: (parentnull=false)
> > [vhttp://mdp4.cytetech.com:8090/reggie- dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2 ,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 15151aa}
> >
> > 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#11 ]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> > for
> > access is: "LoaderKey: (parentnull=false)
> > [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk- dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 15151aa}
> >
> > 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#12]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9 : loader
> > key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is:
> > "LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,LoaderKey:
> > (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie- dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 15151aa}
> >
> > 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#13]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9 : loader
> > key[cur=null] for
> > access is: "LoaderKey: (parentnull=false)
> > [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie- dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 56c3cf,
> > LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2 ,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 15151aa}
> >
> > 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#14 ]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> > for
> > access is: "LoaderKey: (parentnull=false)
> > [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk- dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 515263,
> > LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402 }
> >
> > 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#15]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> > for
> > access is: "LoaderKey: (parentnull=false)
> > [vhttp://mdp3.cytetech.com:8090/reggie- dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 515263 ,
> > LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402}
> >
> > 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#16]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9 : loader
> > key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is:
> > "LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 515263,LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie- dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402 }
> >
> > 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#17]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> > key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is:
> > "LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk- dl.jar]=
> > java.util.concurrent.FutureTask at 515263,LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402}
> >
> > 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#18]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9 : loader
> > key[cur=java.util.concurrent.FutureTask at 515263] for access is:
> > "LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 515263,LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie- dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402 }
> >
> > 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#19]
> > INFO #
> > net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> > key[cur=java.util.concurrent.FutureTask at f81402] for access is:
> > "LoaderKey:
> > (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> > (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> > vhttp://mdp3.cytetech.com:8090/jsk- dl.jar]=
> > java.util.concurrent.FutureTask at 515263,LoaderKey:
> > (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> > vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at 7fc8b2,
> > LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> > dl.jar,
> > vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> > java.util.concurrent.FutureTask at f81402}
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061208/2d0d18e2/attachment.html 

From peter.royal at pobox.com  Fri Dec  8 17:34:19 2006
From: peter.royal at pobox.com (peter royal)
Date: Fri, 8 Dec 2006 14:34:19 -0800
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <63b4e4050612081350s502fb3d8t760cbfa10e05955d@mail.gmail.com>
References: <4579DBA1.4040300@cytetech.com>
	<63b4e4050612081350s502fb3d8t760cbfa10e05955d@mail.gmail.com>
Message-ID: <405ACFEA-6367-4527-8F2E-A6735F444C1F@pobox.com>

On Dec 8, 2006, at 1:50 PM, Tim Peierls wrote:
> map.putIfAbsent uses identity semantics and map.get uses equals/ 
> hashCode semantics.

Where is this documented?

Looking at http://java.sun.com/j2se/1.5.0/docs/api/java/util/ 
concurrent/ConcurrentHashMap.html#get(java.lang.Object) and http:// 
java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/ 
ConcurrentHashMap.html#putIfAbsent(K,%20V)

The javadocs for putIfAbsent say that its equivalent to a ! 
containsKey, and containsKey says it uses equals() to determine  
existence.

the JCIP book also does not mention anything about ConcurrentHashMap  
using identity semantics.

-pete

-- 
(peter.royal|osi)@pobox.com - http://fotap.org/~osi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 2454 bytes
Desc: not available
Url : /pipermail/attachments/20061208/a4d6439c/attachment.bin 

From hanson.char at gmail.com  Sat Dec  9 18:48:11 2006
From: hanson.char at gmail.com (Hanson Char)
Date: Sat, 9 Dec 2006 15:48:11 -0800
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <4579DBA1.4040300@cytetech.com>
References: <4579DBA1.4040300@cytetech.com>
Message-ID: <ca53c8f80612091548n38ad445dm8cded4fb3ef58fcc@mail.gmail.com>

Can you provide the implementation of the equals() and hashCode() methods of
LoaderKey ?  The usual suspects.

Hanson

On 12/8/06, Gregg Wonderly <gregg at cytetech.com> wrote:
>
> I recently made some changes to a single large synchronized() block to use
> Futures and ConcurrentHashmap to distribute the locking to a finer grain.
>
> I've been seeing some oddities in the behavior of the code after these
> changes,
> and today, I took a deeper look.  There is quite a bit of context and
> complexity
> around this code, it involves classloader creation in an RMIClassLoaderSPI
> implementation.  But, the basics are that when I use
>
>         LoaderKey key = ...
>         Future fut = ...
>         Future runfut = map.putIfAbsent( key, fut );
>         logger.info(this+": loader key[cur="+runfut+"] for access is:
> \""+key+"\",
> know: "+map );
>
> I see that method returning null for multiple calls with the same key (as
> shown
> in the logging below).  If I change that single call to be
>
>         LoaderKey key = ...
>         Future fut = ...
>         Future runfut = null;
>         synchronized( map ) {
>                 runfut = map.get( key );
>                 if( runfut == null )
>                         map.put( key, fut );
>         }
>
> I see the expected behavior.
>
> map is a class level object.  There is only a single instance of this
> class
> active and thus only one map defined.
>
> Any thoughts on what I might be overlooking?
>
> Gregg Wonderly
>
> -------------------------------------------------------------------------
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#10] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#11] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#12] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,LoaderKey:
> (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#13] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 56c3cf,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 15151aa}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#14] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:29 [net.jini.loader.pref.PreferredClassProvider#15] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader key[cur=null]
> for
> access is: "LoaderKey: (parentnull=false)
> [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,
> LoaderKey: (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#16] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#17] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 7fc8b2] for access is: "LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#18] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at 515263] for access is: "LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
>
> 12/08/2006 15:33:30 [net.jini.loader.pref.PreferredClassProvider#19] INFO
> #
> net.jini.loader.pref.PreferredClassProvider at 2a5ab9: loader
> key[cur=java.util.concurrent.FutureTask at f81402] for access is: "LoaderKey:
> (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]", know: {LoaderKey:
> (parentnull=false) [vhttp://mdp3.cytetech.com:8090/reggie-dl.jar,
> vhttp://mdp3.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 515263,LoaderKey:
> (parentnull=false) [vhttp://eoi1.cytetech.com:8090/reggie-dl.jar,
> vhttp://eoi1.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at 7fc8b2,
> LoaderKey: (parentnull=false) [vhttp://mdp4.cytetech.com:8090/reggie-
> dl.jar,
> vhttp://mdp4.cytetech.com:8090/jsk-dl.jar]=
> java.util.concurrent.FutureTask at f81402}
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061209/ce7f70ab/attachment.html 

From tonai98 at yahoo.com  Sun Dec 10 08:07:40 2006
From: tonai98 at yahoo.com (Tony)
Date: Sun, 10 Dec 2006 05:07:40 -0800 (PST)
Subject: [concurrency-interest] Backport concurrency util in EJB
Message-ID: <20061210130740.59843.qmail@web55513.mail.re4.yahoo.com>

dear all,

i would like to ask how safe it is to use backport concurrency util in EJB if the codes only depends on the datasource provided by the container.

the codes mainly query/update the database. It is actually a batch job which can be broken down to chunks of logical processes. Some of the processes can be running in parallel, while certain processes are depending on the outcome of other processes.

using JMS to achieve parallel processing (to speed up the process) is a bit complicated, so i was thinking of using this backport util to spawn off few threads.

if the codes only depending on database access, how safe is it to use backport concurrent util? (as the EJB spec clearly disencourage spawning thread).

regards,
tony


 
____________________________________________________________________________________
Need a quick answer? Get one in minutes from people who know.
Ask your question on www.Answers.yahoo.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061210/fd57365e/attachment.html 

From forax at univ-mlv.fr  Sun Dec 10 10:04:13 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?Forax_R=E9mi?=)
Date: Sun, 10 Dec 2006 16:04:13 +0100
Subject: [concurrency-interest] Backport concurrency util in EJB
In-Reply-To: <20061210130740.59843.qmail@web55513.mail.re4.yahoo.com>
References: <20061210130740.59843.qmail@web55513.mail.re4.yahoo.com>
Message-ID: <457C21ED.9040505@univ-mlv.fr>

Tony a ?crit :
>
> dear all,
>
>  
>
> i would like to ask how safe it is to use backport concurrency util in 
> EJB if the codes only depends on the datasource provided by the container.
>
>  
>
> the codes mainly query/update the database. It is actually a batch job 
> which can be broken down to chunks of logical processes. Some of the 
> processes can be running in parallel, while certain processes are 
> depending on the outcome of other processes.
>
>  
>
> using JMS to achieve parallel processing (to speed up the process) is 
> a bit complicated, so i was thinking of using this backport util to 
> spawn off few threads.
>
>  
>
> if the codes only depending on database access, how safe is it to use 
> backport concurrent util? (as the EJB spec clearly disencourage 
> spawning thread).
>
The problem is that an EJB container maintains informations associated 
with threads
in order to manage transactions, security etc.

more here, http://blog.w1c.ca/?p=92
and google: batch processing J2EE
>
>  
>
> regards,
>
> tony
>
>  
>
R?mi


From dharrigan at gmail.com  Mon Dec 11 06:14:59 2006
From: dharrigan at gmail.com (David Harrigan)
Date: Mon, 11 Dec 2006 03:14:59 -0800 (PST)
Subject: [concurrency-interest] Multi-core testing, help with findings
Message-ID: <7792970.post@talk.nabble.com>


Hi All,

I've recently acquired a nice new shiny core 2 duo (2 x 2.0Ghz) laptop and I
thought I would try out a test of threading in it. So, I wrote a simple
class (see below). However, my findings are curious and I would like if
possible someone to explain why they are slower on my multi-core system than
my older system which was a Pentium-M @ 2.33Ghz. Both machines, apart from
the processor are near enough identical - same disk speed, same type of
memory (667Mhz DDR2 2GB) etc..

After 20 runs of my program on the core 2 duo, the average time was : 6975ms 
After 5 runs of my program on the Pentium-M, the average time was : 2735m

I suspect it's because with two processors they are both contending for main
memory. Notice that I have the counter as volatile which forces the variable
to flush out to memory each time - since this is what I'm interested in
testing - real world stuff where things are synch'ed (when it wasn't
volatile, the change was dramatic - because the core 2 duo has 4MB of cache
it was extremely fast, whereas the Pentium-M with only 1MB of cache was a
lot lot slower)...




import java.util.concurrent.BrokenBarrierException;
import java.util.concurrent.CyclicBarrier;

public class ThreadTest {

    private static final int howMany = 1000;
    private static volatile boolean finished;
    final CyclicBarrier barrier = new CyclicBarrier(howMany, new Runnable()
{
        public void run() {
            finished = true;
        }
    });

    public static void main(String[] args) {
        ThreadTest t = new ThreadTest();
        long total = 0;
        for(int i = 0 ; i < 20 ; i ++) {
            long elapsedTime = t.doIt();
            total += elapsedTime;
            System.out.println("Run #" + i + " : elapsed time = " +
elapsedTime + "ms");
        }
        System.out.println("Average time = " + (total / 20) + "ms");
    }

    private long doIt() {
        long startTime = System.currentTimeMillis();
        for(int i = 0; i < howMany; i++) {
            new Thread(new Worker()).start();
        }
        while(!finished);
        long endTime = System.currentTimeMillis();
        return (endTime - startTime);
        
    }
       
    class Worker implements Runnable {
        volatile int counter;
        public void run() {
            for(counter = 0 ; counter < 1000000 ; counter++);
            try {
                barrier.await();
            } catch(InterruptedException e) {
                return;
            } catch(BrokenBarrierException e) {
                return;
            }
        }
    }
}


-=david=-
-- 
View this message in context: http://www.nabble.com/Multi-core-testing%2C-help-with-findings-tf2793302.html#a7792970
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From dharrigan at gmail.com  Mon Dec 11 07:32:20 2006
From: dharrigan at gmail.com (David Harrigan)
Date: Mon, 11 Dec 2006 04:32:20 -0800 (PST)
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <7792970.post@talk.nabble.com>
References: <7792970.post@talk.nabble.com>
Message-ID: <7793847.post@talk.nabble.com>


Hi,

Oops, that should be after 20 runs on the Pentium-M...not 5!!

Also, I'm using JDK 6 final - the one that was released today.

-=david=-


David Harrigan wrote:
> 
> Hi All,
> 
> I've recently acquired a nice new shiny core 2 duo (2 x 2.0Ghz) laptop and
> I thought I would try out a test of threading in it. So, I wrote a simple
> class (see below). However, my findings are curious and I would like if
> possible someone to explain why they are slower on my multi-core system
> than my older system which was a Pentium-M @ 2.33Ghz. Both machines, apart
> from the processor are near enough identical - same disk speed, same type
> of memory (667Mhz DDR2 2GB) etc..
> 
> After 20 runs of my program on the core 2 duo, the average time was :
> 6975ms 
> After 5 runs of my program on the Pentium-M, the average time was : 2735m
> 
> I suspect it's because with two processors they are both contending for
> main memory. Notice that I have the counter as volatile which forces the
> variable to flush out to memory each time - since this is what I'm
> interested in testing - real world stuff where things are synch'ed (when
> it wasn't volatile, the change was dramatic - because the core 2 duo has
> 4MB of cache it was extremely fast, whereas the Pentium-M with only 1MB of
> cache was a lot lot slower)...
> 
> 
> 
> 
> import java.util.concurrent.BrokenBarrierException;
> import java.util.concurrent.CyclicBarrier;
> 
> public class ThreadTest {
> 
>     private static final int howMany = 1000;
>     private static volatile boolean finished;
>     final CyclicBarrier barrier = new CyclicBarrier(howMany, new
> Runnable() {
>         public void run() {
>             finished = true;
>         }
>     });
> 
>     public static void main(String[] args) {
>         ThreadTest t = new ThreadTest();
>         long total = 0;
>         for(int i = 0 ; i < 20 ; i ++) {
>             long elapsedTime = t.doIt();
>             total += elapsedTime;
>             System.out.println("Run #" + i + " : elapsed time = " +
> elapsedTime + "ms");
>         }
>         System.out.println("Average time = " + (total / 20) + "ms");
>     }
> 
>     private long doIt() {
>         long startTime = System.currentTimeMillis();
>         for(int i = 0; i < howMany; i++) {
>             new Thread(new Worker()).start();
>         }
>         while(!finished);
>         long endTime = System.currentTimeMillis();
>         return (endTime - startTime);
>         
>     }
>        
>     class Worker implements Runnable {
>         volatile int counter;
>         public void run() {
>             for(counter = 0 ; counter < 1000000 ; counter++);
>             try {
>                 barrier.await();
>             } catch(InterruptedException e) {
>                 return;
>             } catch(BrokenBarrierException e) {
>                 return;
>             }
>         }
>     }
> }
> 
> 
> -=david=-
> 

-- 
View this message in context: http://www.nabble.com/Multi-core-testing%2C-help-with-findings-tf2793302.html#a7793847
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From gergg at cox.net  Mon Dec 11 09:29:32 2006
From: gergg at cox.net (Gregg Wonderly)
Date: Mon, 11 Dec 2006 08:29:32 -0600
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <ca53c8f80612091548n38ad445dm8cded4fb3ef58fcc@mail.gmail.com>
References: <4579DBA1.4040300@cytetech.com>
	<ca53c8f80612091548n38ad445dm8cded4fb3ef58fcc@mail.gmail.com>
Message-ID: <457D6B4C.9030109@cox.net>

Hanson Char wrote:
> Can you provide the implementation of the equals() and hashCode() 
> methods of LoaderKey ?  The usual suspects.

     private class LoaderKey extends WeakReference {
		private final URL[] urls;
		private final boolean nullParent;
		private final int hashValue;

		public String toString() {
			String str = "LoaderKey: (parentnull="+nullParent+") "+Arrays.toString( urls );
			if( logger.isLoggable(Level.FINER) )
				str += ": loader="+get();
			return str;
		}

		public LoaderKey(URL[] urls, ClassLoader parent) {
			super(parent, refQueue);
			this.urls = urls;
			nullParent = (parent == null);

			int h = nullParent ? 0 : parent.hashCode();
			for (int i = 0; i < urls.length; i++) {
				h ^= urls[i].hashCode();
			}
			hashValue = h;
		}

		public int hashCode() {
			return hashValue;
		}

		public boolean equals(Object obj) {
			if (obj == this) {
				return true;
			} else if (!(obj instanceof LoaderKey)) {
				return false;
			}
			LoaderKey other = (LoaderKey) obj;
			ClassLoader parent = (ClassLoader) get();
			return (nullParent ? other.nullParent
				 : ( parent != null &&
						parent == other.get() ) )
						&& Arrays.equals(urls, other.urls);
		}
     }

From matthias.ernst at coremedia.com  Mon Dec 11 10:08:34 2006
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Mon, 11 Dec 2006 16:08:34 +0100
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
Message-ID: <AE2A8E488D9B26438919DF3C9C95528D27EDA1@hermes.coremedia.com>

> ... && Arrays.equals(urls, other.urls);

I don't know if this is related to your problem but
comparing URLs has unpleasant side effects:

...
     * Two hosts are considered equivalent if both host names can be
resolved
     * into the same IP addresses; else if either host name can't be
     * resolved, the host names must be equal without regard to case; or
both
     * host names equal to null.<p>
     *
     * Since hosts comparison requires name resolution, this operation
is a
     * blocking operation. <p>
...

The one time I ran into this, it was not what I wanted.

Matthias

-- 
Matthias Ernst
Software Engineer
 
tel +49.40.32 55 87.503
fax +49.40.32 55 87.999
matthias.ernst at coremedia.com


From hanson.char at gmail.com  Mon Dec 11 11:39:07 2006
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 11 Dec 2006 08:39:07 -0800
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <457D6B4C.9030109@cox.net>
References: <4579DBA1.4040300@cytetech.com>
	<ca53c8f80612091548n38ad445dm8cded4fb3ef58fcc@mail.gmail.com>
	<457D6B4C.9030109@cox.net>
Message-ID: <ca53c8f80612110839i311a15fbgec638a27b03e9933@mail.gmail.com>

Consider changing "this.urls = urls;" to "this.urls = urls.clone();".  The
reference to the array "urls" is immutable (via final), but the content of
the "urls" array is still mutable and not thread-safe, which will cause
undesirable effect in the context of being used as a key.

Another trick you may consider for finding out the root cause at least is to
do something like below.  The basic idea is to make the hashCode and equals
being predictable/consistent all the time..

Hanson

     private class LoaderKey extends WeakReference {
                private final URL[] urls;
                private final boolean nullParent;
                private final int hashValue;
                private final String urlsString;

                public String toString() {
                      return urlsString;
                }

                public LoaderKey(URL[] urls, ClassLoader parent) {
                        super(parent, refQueue);
                        this.urls = urls.clone();
                        nullParent = (parent == null);
                        String str = "LoaderKey: (parentnull="+nullParent+")
"+Arrays.toString( this.urls );

                        if( logger.isLoggable(Level.FINER) )
                                str += ": loader="+get();
                        urlsString = str;
                        hashValue = urlsString.hashCode();
                        // Log both urlsString and hashValue here for
debugging purposes.
                }

                public int hashCode() {
                        return hashValue;
                }

                public boolean equals(Object obj) {
                        if (obj == this) {
                                return true;
                        } else if (!(obj instanceof LoaderKey)) {
                                return false;
                        }
                        LoaderKey other = (LoaderKey) obj;
                        return this.urlsString.equals(other.urlsString);
                }
     }


On 12/11/06, Gregg Wonderly <gergg at cox.net> wrote:
>
> Hanson Char wrote:
> > Can you provide the implementation of the equals() and hashCode()
> > methods of LoaderKey ?  The usual suspects.
>
>      private class LoaderKey extends WeakReference {
>                 private final URL[] urls;
>                 private final boolean nullParent;
>                 private final int hashValue;
>
>                 public String toString() {
>                         String str = "LoaderKey:
> (parentnull="+nullParent+") "+Arrays.toString( urls );
>                         if( logger.isLoggable(Level.FINER) )
>                                 str += ": loader="+get();
>                         return str;
>                 }
>
>                 public LoaderKey(URL[] urls, ClassLoader parent) {
>                         super(parent, refQueue);
>                         this.urls = urls;
>                         nullParent = (parent == null);
>
>                         int h = nullParent ? 0 : parent.hashCode();
>                         for (int i = 0; i < urls.length; i++) {
>                                 h ^= urls[i].hashCode();
>                         }
>                         hashValue = h;
>                 }
>
>                 public int hashCode() {
>                         return hashValue;
>                 }
>
>                 public boolean equals(Object obj) {
>                         if (obj == this) {
>                                 return true;
>                         } else if (!(obj instanceof LoaderKey)) {
>                                 return false;
>                         }
>                         LoaderKey other = (LoaderKey) obj;
>                         ClassLoader parent = (ClassLoader) get();
>                         return (nullParent ? other.nullParent
>                                  : ( parent != null &&
>                                                 parent == other.get() ) )
>                                                 && Arrays.equals(urls,
> other.urls);
>                 }
>      }
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061211/cb156f0c/attachment-0001.html 

From robertlazarski at gmail.com  Mon Dec 11 14:34:46 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Mon, 11 Dec 2006 14:34:46 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
Message-ID: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>

Hi all,

I've been tasked with converting a DNS problem from a GPL thread pool
from around 2000 to j.u.c. The current code ignores exceptions, is not
very maintainable and I've decided that it would be best to start
over. One caveat: The program uses recursion and a new thread for
every iteration.

The goal however necessary is to get every 'A record' , determine if
the 'A record' is actually a 'DN record' , and if so, start over -
perhaps recursively. The result being a List of every host and ip from
a given DNS server.

I'm looking at the jcip TransformingSequential example, and thinking
how I could apply that to this problem. I've also been thinking about
perhaps dividing the 'A record' and 'DN record' into different
CompletionService's . Nothing seems right yet. Here's the old code, an
inner class - the only relevant thing in the parent class is that it
inits the 'DirContext ictx'. Any ideas?

    // fugly code
    private class SearchDomain implements Runnable {

        private boolean recursive;
        private Map<String, String> collection;
        private String domain;

        public SearchDomain(String domain, Map<String, String> collection,
                boolean recursive) {

            this.domain = domain;
            this.collection = collection;
            this.recursive = recursive;
        }

        public void run() {

            if (!domainsVisitados.contains(domain)) {

                domainsVisitados.add(domain);

                try {
                    NamingEnumeration hostEnumeration = ictx.list(domain);

                    // get the hosts with their names and ip's.
                    while (hostEnumeration.hasMore()) {

                        String host = null;
                        host = ((NameClassPair) hostEnumeration.next())
                                .getNameInNamespace();

                        // Get 'A Records'
                        Attributes a = ictx.getAttributes(host,
                                new String[] { "A" });

                        if (a.get("A") != null) {
                            String ip = a.get("A").get().toString();
                            collection.put(host, ip);
                        }
                        if (recursive) {
                            // find which ones are DNS e create new thread
                            Attributes aDNS = ictx.getAttributes(host,
                                    new String[] { "NS" });
                            NamingEnumeration allDNS = aDNS.getAll();

                            while (allDNS.hasMore()) {
                                Attribute attr = (Attribute) allDNS.next();
                                NamingEnumeration values = attr.getAll();

                                // put the host and ip into the 'collection'
                                while (values.hasMore()) {
                                    String dns = values.next().toString();
                                    pool.assign(new SearchDomain(dns,
                                            collection, recursive));
                                }
                            }
                        }
                    }
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }

From dcholmes at optusnet.com.au  Mon Dec 11 17:24:23 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 12 Dec 2006 08:24:23 +1000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <7793847.post@talk.nabble.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEHPHEAA.dcholmes@optusnet.com.au>

David,

You have a busy wait-loop which will try to consume 1-CPU/CORE and
continually bang on the "finished" variable, doing nothing but interfere
with the execution of the real work due to memory/cache traffic. On a single
processor system your busy thread will get switched out after each timeslice
and get far less CPU time to interfere.

So I think what you are seeing here is a scheduling artifact of the OS.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David
> Harrigan
> Sent: Monday, 11 December 2006 10:32 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Multi-core testing, help with
> findings
>
>
>
> Hi,
>
> Oops, that should be after 20 runs on the Pentium-M...not 5!!
>
> Also, I'm using JDK 6 final - the one that was released today.
>
> -=david=-
>
>
> David Harrigan wrote:
> >
> > Hi All,
> >
> > I've recently acquired a nice new shiny core 2 duo (2 x 2.0Ghz)
> laptop and
> > I thought I would try out a test of threading in it. So, I
> wrote a simple
> > class (see below). However, my findings are curious and I would like if
> > possible someone to explain why they are slower on my multi-core system
> > than my older system which was a Pentium-M @ 2.33Ghz. Both
> machines, apart
> > from the processor are near enough identical - same disk speed,
> same type
> > of memory (667Mhz DDR2 2GB) etc..
> >
> > After 20 runs of my program on the core 2 duo, the average time was :
> > 6975ms
> > After 5 runs of my program on the Pentium-M, the average time
> was : 2735m
> >
> > I suspect it's because with two processors they are both contending for
> > main memory. Notice that I have the counter as volatile which forces the
> > variable to flush out to memory each time - since this is what I'm
> > interested in testing - real world stuff where things are synch'ed (when
> > it wasn't volatile, the change was dramatic - because the core 2 duo has
> > 4MB of cache it was extremely fast, whereas the Pentium-M with
> only 1MB of
> > cache was a lot lot slower)...
> >
> >
> >
> >
> > import java.util.concurrent.BrokenBarrierException;
> > import java.util.concurrent.CyclicBarrier;
> >
> > public class ThreadTest {
> >
> >     private static final int howMany = 1000;
> >     private static volatile boolean finished;
> >     final CyclicBarrier barrier = new CyclicBarrier(howMany, new
> > Runnable() {
> >         public void run() {
> >             finished = true;
> >         }
> >     });
> >
> >     public static void main(String[] args) {
> >         ThreadTest t = new ThreadTest();
> >         long total = 0;
> >         for(int i = 0 ; i < 20 ; i ++) {
> >             long elapsedTime = t.doIt();
> >             total += elapsedTime;
> >             System.out.println("Run #" + i + " : elapsed time = " +
> > elapsedTime + "ms");
> >         }
> >         System.out.println("Average time = " + (total / 20) + "ms");
> >     }
> >
> >     private long doIt() {
> >         long startTime = System.currentTimeMillis();
> >         for(int i = 0; i < howMany; i++) {
> >             new Thread(new Worker()).start();
> >         }
> >         while(!finished);
> >         long endTime = System.currentTimeMillis();
> >         return (endTime - startTime);
> >
> >     }
> >
> >     class Worker implements Runnable {
> >         volatile int counter;
> >         public void run() {
> >             for(counter = 0 ; counter < 1000000 ; counter++);
> >             try {
> >                 barrier.await();
> >             } catch(InterruptedException e) {
> >                 return;
> >             } catch(BrokenBarrierException e) {
> >                 return;
> >             }
> >         }
> >     }
> > }
> >
> >
> > -=david=-
> >
>
> --
> View this message in context:
> http://www.nabble.com/Multi-core-testing%2C-help-with-findings-tf2
793302.html#a7793847
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dcholmes at optusnet.com.au  Mon Dec 11 19:31:18 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 12 Dec 2006 10:31:18 +1000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <BDA38860DCFD334EAEA905E44EE8E7EF4D68DE@G3W0067.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEICHEAA.dcholmes@optusnet.com.au>

I've assumed the platform is Windows, but if it is linux then that opens
other possibilities. The problem can be explained if the busy-wait thread
doesn't get descheduled (which is easy to test by changing it to not be a
busy-wait). The issue as to why it doesn't get descheduled is then the
interesting part. I suspect an OS scheduling quirk on multi-core, but need
more information.

Cheers,
David Holmes

> -----Original Message-----
> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> Sent: Tuesday, 12 December 2006 10:14 AM
> To: dholmes at ieee.org; David Harrigan; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] Multi-core testing, help with
> findings
>
>
> Somehow that doesn't look like the whole explanation to me.  If I read
> the code correctly, finished is only being touched once by another
> thread for each major iteration.  Thus it should only leave the L1 cache
> of the main thread once every 7 seconds.  It's unclear to me why the
> main thread should be touching the memory system significantly at all.
> It's also unclear to me why it should be scheduled all the time, instead
> of just being 1 of 1001 threads.
>
> Depending on the platform, might the thread creation cost just be a lot
> higher?  Or might you get several instances of the counter variable in
> the same cache line?  Neither of those sounds all that likely, either
> ...
>
> Hans
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf
> > Of David Holmes
> > Sent: Monday, December 11, 2006 2:24 PM
> > To: David Harrigan; concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Multi-core testing, help
> > with findings
> >
> > David,
> >
> > You have a busy wait-loop which will try to consume
> > 1-CPU/CORE and continually bang on the "finished" variable,
> > doing nothing but interfere with the execution of the real
> > work due to memory/cache traffic. On a single processor
> > system your busy thread will get switched out after each
> > timeslice and get far less CPU time to interfere.
> >
> > So I think what you are seeing here is a scheduling artifact
> > of the OS.
> >
> > Cheers,
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On
> > Behalf Of David
> > > Harrigan
> > > Sent: Monday, 11 December 2006 10:32 PM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Multi-core testing, help with
> > > findings
> > >
> > >
> > >
> > > Hi,
> > >
> > > Oops, that should be after 20 runs on the Pentium-M...not 5!!
> > >
> > > Also, I'm using JDK 6 final - the one that was released today.
> > >
> > > -=david=-
> > >
> > >
> > > David Harrigan wrote:
> > > >
> > > > Hi All,
> > > >
> > > > I've recently acquired a nice new shiny core 2 duo (2 x 2.0Ghz)
> > > laptop and
> > > > I thought I would try out a test of threading in it. So, I
> > > wrote a simple
> > > > class (see below). However, my findings are curious and I
> > would like
> > > > if possible someone to explain why they are slower on my
> > multi-core
> > > > system than my older system which was a Pentium-M @ 2.33Ghz. Both
> > > machines, apart
> > > > from the processor are near enough identical - same disk speed,
> > > same type
> > > > of memory (667Mhz DDR2 2GB) etc..
> > > >
> > > > After 20 runs of my program on the core 2 duo, the
> > average time was :
> > > > 6975ms
> > > > After 5 runs of my program on the Pentium-M, the average time
> > > was : 2735m
> > > >
> > > > I suspect it's because with two processors they are both
> > contending
> > > > for main memory. Notice that I have the counter as volatile which
> > > > forces the variable to flush out to memory each time -
> > since this is
> > > > what I'm interested in testing - real world stuff where
> > things are
> > > > synch'ed (when it wasn't volatile, the change was
> > dramatic - because
> > > > the core 2 duo has 4MB of cache it was extremely fast,
> > whereas the
> > > > Pentium-M with
> > > only 1MB of
> > > > cache was a lot lot slower)...
> > > >
> > > >
> > > >
> > > >
> > > > import java.util.concurrent.BrokenBarrierException;
> > > > import java.util.concurrent.CyclicBarrier;
> > > >
> > > > public class ThreadTest {
> > > >
> > > >     private static final int howMany = 1000;
> > > >     private static volatile boolean finished;
> > > >     final CyclicBarrier barrier = new CyclicBarrier(howMany, new
> > > > Runnable() {
> > > >         public void run() {
> > > >             finished = true;
> > > >         }
> > > >     });
> > > >
> > > >     public static void main(String[] args) {
> > > >         ThreadTest t = new ThreadTest();
> > > >         long total = 0;
> > > >         for(int i = 0 ; i < 20 ; i ++) {
> > > >             long elapsedTime = t.doIt();
> > > >             total += elapsedTime;
> > > >             System.out.println("Run #" + i + " : elapsed
> > time = " +
> > > > elapsedTime + "ms");
> > > >         }
> > > >         System.out.println("Average time = " + (total /
> > 20) + "ms");
> > > >     }
> > > >
> > > >     private long doIt() {
> > > >         long startTime = System.currentTimeMillis();
> > > >         for(int i = 0; i < howMany; i++) {
> > > >             new Thread(new Worker()).start();
> > > >         }
> > > >         while(!finished);
> > > >         long endTime = System.currentTimeMillis();
> > > >         return (endTime - startTime);
> > > >
> > > >     }
> > > >
> > > >     class Worker implements Runnable {
> > > >         volatile int counter;
> > > >         public void run() {
> > > >             for(counter = 0 ; counter < 1000000 ; counter++);
> > > >             try {
> > > >                 barrier.await();
> > > >             } catch(InterruptedException e) {
> > > >                 return;
> > > >             } catch(BrokenBarrierException e) {
> > > >                 return;
> > > >             }
> > > >         }
> > > >     }
> > > > }
> > > >
> > > >
> > > > -=david=-
> > > >
> > >
> > > --
> > > View this message in context:
> > > http://www.nabble.com/Multi-core-testing%2C-help-with-findings-tf2
> > 793302.html#a7793847
> > Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>


From hans.boehm at hp.com  Mon Dec 11 19:13:51 2006
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 11 Dec 2006 18:13:51 -0600
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEHPHEAA.dcholmes@optusnet.com.au>
Message-ID: <BDA38860DCFD334EAEA905E44EE8E7EF4D68DE@G3W0067.americas.hpqcorp.net>

Somehow that doesn't look like the whole explanation to me.  If I read
the code correctly, finished is only being touched once by another
thread for each major iteration.  Thus it should only leave the L1 cache
of the main thread once every 7 seconds.  It's unclear to me why the
main thread should be touching the memory system significantly at all.
It's also unclear to me why it should be scheduled all the time, instead
of just being 1 of 1001 threads.

Depending on the platform, might the thread creation cost just be a lot
higher?  Or might you get several instances of the counter variable in
the same cache line?  Neither of those sounds all that likely, either
...

Hans

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf 
> Of David Holmes
> Sent: Monday, December 11, 2006 2:24 PM
> To: David Harrigan; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Multi-core testing, help 
> with findings
> 
> David,
> 
> You have a busy wait-loop which will try to consume 
> 1-CPU/CORE and continually bang on the "finished" variable, 
> doing nothing but interfere with the execution of the real 
> work due to memory/cache traffic. On a single processor 
> system your busy thread will get switched out after each 
> timeslice and get far less CPU time to interfere.
> 
> So I think what you are seeing here is a scheduling artifact 
> of the OS.
> 
> Cheers,
> David Holmes
> 
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On 
> Behalf Of David 
> > Harrigan
> > Sent: Monday, 11 December 2006 10:32 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Multi-core testing, help with 
> > findings
> >
> >
> >
> > Hi,
> >
> > Oops, that should be after 20 runs on the Pentium-M...not 5!!
> >
> > Also, I'm using JDK 6 final - the one that was released today.
> >
> > -=david=-
> >
> >
> > David Harrigan wrote:
> > >
> > > Hi All,
> > >
> > > I've recently acquired a nice new shiny core 2 duo (2 x 2.0Ghz)
> > laptop and
> > > I thought I would try out a test of threading in it. So, I
> > wrote a simple
> > > class (see below). However, my findings are curious and I 
> would like 
> > > if possible someone to explain why they are slower on my 
> multi-core 
> > > system than my older system which was a Pentium-M @ 2.33Ghz. Both
> > machines, apart
> > > from the processor are near enough identical - same disk speed,
> > same type
> > > of memory (667Mhz DDR2 2GB) etc..
> > >
> > > After 20 runs of my program on the core 2 duo, the 
> average time was :
> > > 6975ms
> > > After 5 runs of my program on the Pentium-M, the average time
> > was : 2735m
> > >
> > > I suspect it's because with two processors they are both 
> contending 
> > > for main memory. Notice that I have the counter as volatile which 
> > > forces the variable to flush out to memory each time - 
> since this is 
> > > what I'm interested in testing - real world stuff where 
> things are 
> > > synch'ed (when it wasn't volatile, the change was 
> dramatic - because 
> > > the core 2 duo has 4MB of cache it was extremely fast, 
> whereas the 
> > > Pentium-M with
> > only 1MB of
> > > cache was a lot lot slower)...
> > >
> > >
> > >
> > >
> > > import java.util.concurrent.BrokenBarrierException;
> > > import java.util.concurrent.CyclicBarrier;
> > >
> > > public class ThreadTest {
> > >
> > >     private static final int howMany = 1000;
> > >     private static volatile boolean finished;
> > >     final CyclicBarrier barrier = new CyclicBarrier(howMany, new
> > > Runnable() {
> > >         public void run() {
> > >             finished = true;
> > >         }
> > >     });
> > >
> > >     public static void main(String[] args) {
> > >         ThreadTest t = new ThreadTest();
> > >         long total = 0;
> > >         for(int i = 0 ; i < 20 ; i ++) {
> > >             long elapsedTime = t.doIt();
> > >             total += elapsedTime;
> > >             System.out.println("Run #" + i + " : elapsed 
> time = " + 
> > > elapsedTime + "ms");
> > >         }
> > >         System.out.println("Average time = " + (total / 
> 20) + "ms");
> > >     }
> > >
> > >     private long doIt() {
> > >         long startTime = System.currentTimeMillis();
> > >         for(int i = 0; i < howMany; i++) {
> > >             new Thread(new Worker()).start();
> > >         }
> > >         while(!finished);
> > >         long endTime = System.currentTimeMillis();
> > >         return (endTime - startTime);
> > >
> > >     }
> > >
> > >     class Worker implements Runnable {
> > >         volatile int counter;
> > >         public void run() {
> > >             for(counter = 0 ; counter < 1000000 ; counter++);
> > >             try {
> > >                 barrier.await();
> > >             } catch(InterruptedException e) {
> > >                 return;
> > >             } catch(BrokenBarrierException e) {
> > >                 return;
> > >             }
> > >         }
> > >     }
> > > }
> > >
> > >
> > > -=david=-
> > >
> >
> > --
> > View this message in context:
> > http://www.nabble.com/Multi-core-testing%2C-help-with-findings-tf2
> 793302.html#a7793847
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From gregg at cytetech.com  Mon Dec 11 22:12:46 2006
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 11 Dec 2006 21:12:46 -0600
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEICHEAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCGEICHEAA.dcholmes@optusnet.com.au>
Message-ID: <457E1E2E.8040004@cytetech.com>



David Holmes wrote:
> I've assumed the platform is Windows, but if it is linux then that opens
> other possibilities. The problem can be explained if the busy-wait thread
> doesn't get descheduled (which is easy to test by changing it to not be a
> busy-wait). The issue as to why it doesn't get descheduled is then the
> interesting part. I suspect an OS scheduling quirk on multi-core, but need
> more information.

>>>>>    private long doIt() {
>>>>>        long startTime = System.currentTimeMillis();
>>>>>        for(int i = 0; i < howMany; i++) {
>>>>>            new Thread(new Worker()).start();
>>>>>        }
>>>>>        while(!finished);
>>>>>        long endTime = System.currentTimeMillis();
>>>>>        return (endTime - startTime);
>>>>>
>>>>>    }

Historically, I've found that busy waits like the above are problematic.  I'd go 
along with David's comment/thought and try

	while(!finished) Thread.yield();

or something else to cause it to get descheduled for a whole quanta for each 
check rather than busy waiting for a whole quanta which will keep at least one 
CPU busy doing nothing productive.

Gregg Wonderly

From dharrigan at gmail.com  Tue Dec 12 01:57:02 2006
From: dharrigan at gmail.com (David Harrigan)
Date: Tue, 12 Dec 2006 06:57:02 +0000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <457E1E2E.8040004@cytetech.com>
References: <NFBBKALFDCPFIDBNKAPCGEICHEAA.dcholmes@optusnet.com.au>
	<457E1E2E.8040004@cytetech.com>
Message-ID: <7153be990612112257v20ca930fk7d4b028077697113@mail.gmail.com>

Hi,

I completely forgot to mention that platform is Linux (Ubuntu 6.10).

Just scanning thru the mail, will read when I get to work...

-=david=-

On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
>
>
>
> David Holmes wrote:
> > I've assumed the platform is Windows, but if it is linux then that opens
> > other possibilities. The problem can be explained if the busy-wait
> thread
> > doesn't get descheduled (which is easy to test by changing it to not be
> a
> > busy-wait). The issue as to why it doesn't get descheduled is then the
> > interesting part. I suspect an OS scheduling quirk on multi-core, but
> need
> > more information.
>
> >>>>>    private long doIt() {
> >>>>>        long startTime = System.currentTimeMillis();
> >>>>>        for(int i = 0; i < howMany; i++) {
> >>>>>            new Thread(new Worker()).start();
> >>>>>        }
> >>>>>        while(!finished);
> >>>>>        long endTime = System.currentTimeMillis();
> >>>>>        return (endTime - startTime);
> >>>>>
> >>>>>    }
>
> Historically, I've found that busy waits like the above are
> problematic.  I'd go
> along with David's comment/thought and try
>
>         while(!finished) Thread.yield();
>
> or something else to cause it to get descheduled for a whole quanta for
> each
> check rather than busy waiting for a whole quanta which will keep at least
> one
> CPU busy doing nothing productive.
>
> Gregg Wonderly
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061212/21459caa/attachment.html 

From ban at bea.com  Tue Dec 12 03:33:14 2006
From: ban at bea.com (Bjorn Antonsson)
Date: Tue, 12 Dec 2006 08:33:14 -0000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <7153be990612112257v20ca930fk7d4b028077697113@mail.gmail.com>
Message-ID: <814F0D1CB026A84CB79AF4813480922EAFCE89@ukhwex10.emea.bea.com>

Hi,

I would say that a lot of the extra time it takes comes from the fact that the volatile stores/loads in the Worker class, actually 1000000 of them, do mean something on a multi CPU.

On a typical x86 SMP machine the load/store/load pattern on volatiles results in an mfence instruction, which is quite costly. This is a normal load/store/load without mfence on a single CPU machine, since we are guaranteed that the next thread will have the same view of the memory.

/Bj?rn 

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf 
> Of David Harrigan
> Sent: den 12 december 2006 07:57
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Multi-core testing, help 
> with findings
> 
> Hi,
> 
> I completely forgot to mention that platform is Linux (Ubuntu 6.10).
> 
> Just scanning thru the mail, will read when I get to work...
> 
> -=david=-
> 
> 
> On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
> 
> 
> 
> 	David Holmes wrote:
> 	> I've assumed the platform is Windows, but if it is 
> linux then that opens
> 	> other possibilities. The problem can be explained if 
> the busy-wait thread
> 	> doesn't get descheduled (which is easy to test by 
> changing it to not be a 
> 	> busy-wait). The issue as to why it doesn't get 
> descheduled is then the
> 	> interesting part. I suspect an OS scheduling quirk on 
> multi-core, but need
> 	> more information.
> 	
> 	>>>>>    private long doIt() { 
> 	>>>>>        long startTime = System.currentTimeMillis();
> 	>>>>>        for(int i = 0; i < howMany; i++) {
> 	>>>>>            new Thread(new Worker()).start();
> 	>>>>>        } 
> 	>>>>>        while(!finished);
> 	>>>>>        long endTime = System.currentTimeMillis();
> 	>>>>>        return (endTime - startTime);
> 	>>>>>
> 	>>>>>    } 
> 	
> 	Historically, I've found that busy waits like the above 
> are problematic.  I'd go
> 	along with David's comment/thought and try
> 	
> 	        while(!finished) Thread.yield();
> 	
> 	or something else to cause it to get descheduled for a 
> whole quanta for each 
> 	check rather than busy waiting for a whole quanta which 
> will keep at least one
> 	CPU busy doing nothing productive.
> 	
> 	Gregg Wonderly
> 	
> 
> 
> 
_______________________________________________________________________
Notice:  This email message, together with any attachments, may contain
information  of  BEA Systems,  Inc.,  its subsidiaries  and  affiliated
entities,  that may be confidential,  proprietary,  copyrighted  and/or
legally privileged, and is intended solely for the use of the individual
or entity named in this message. If you are not the intended recipient,
and have received this message in error, please immediately return this
by email and then delete it.


From dharrigan at gmail.com  Tue Dec 12 04:51:48 2006
From: dharrigan at gmail.com (David Harrigan)
Date: Tue, 12 Dec 2006 09:51:48 +0000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <814F0D1CB026A84CB79AF4813480922EAFCE89@ukhwex10.emea.bea.com>
References: <7153be990612112257v20ca930fk7d4b028077697113@mail.gmail.com>
	<814F0D1CB026A84CB79AF4813480922EAFCE89@ukhwex10.emea.bea.com>
Message-ID: <7153be990612120151q7a0fb113w998ac349d3db6270@mail.gmail.com>

Hi All,

I would love to explore this further. I could certainly try out the
thread.yield().....but I have
a small problemo now! My core 2 duo is going back to the factory since the
screen doesn't
appear to want to play ball :-( I'll have to wait until I can try the
suggestions out. However,
this of course does not mean no-one else can give it a whirl. All this is
very interesting, and
I think highlights an area that is going to become more and more prevalent -
as more
developers have multi-core machines to develop on, then these things are
going to come
up more often...

>From what I can read in this thread so far - it's either a scheduling issue
with the OS, or
I'm being too aggressive with use of the volatile (I chose this since I
wanted to see what
the processors would act like when forced to go to main memory, rather than
fetching
from their 4MB cache.).

Oh, and it's Linux kernel 2.6.17.

-=david=-

On 12/12/06, Bjorn Antonsson <ban at bea.com> wrote:
>
> Hi,
>
> I would say that a lot of the extra time it takes comes from the fact that
> the volatile stores/loads in the Worker class, actually 1000000 of them, do
> mean something on a multi CPU.
>
> On a typical x86 SMP machine the load/store/load pattern on volatiles
> results in an mfence instruction, which is quite costly. This is a normal
> load/store/load without mfence on a single CPU machine, since we are
> guaranteed that the next thread will have the same view of the memory.
>
> /Bj?rn
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf
> > Of David Harrigan
> > Sent: den 12 december 2006 07:57
> > To: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Multi-core testing, help
> > with findings
> >
> > Hi,
> >
> > I completely forgot to mention that platform is Linux (Ubuntu 6.10).
> >
> > Just scanning thru the mail, will read when I get to work...
> >
> > -=david=-
> >
> >
> > On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
> >
> >
> >
> >       David Holmes wrote:
> >       > I've assumed the platform is Windows, but if it is
> > linux then that opens
> >       > other possibilities. The problem can be explained if
> > the busy-wait thread
> >       > doesn't get descheduled (which is easy to test by
> > changing it to not be a
> >       > busy-wait). The issue as to why it doesn't get
> > descheduled is then the
> >       > interesting part. I suspect an OS scheduling quirk on
> > multi-core, but need
> >       > more information.
> >
> >       >>>>>    private long doIt() {
> >       >>>>>        long startTime = System.currentTimeMillis();
> >       >>>>>        for(int i = 0; i < howMany; i++) {
> >       >>>>>            new Thread(new Worker()).start();
> >       >>>>>        }
> >       >>>>>        while(!finished);
> >       >>>>>        long endTime = System.currentTimeMillis();
> >       >>>>>        return (endTime - startTime);
> >       >>>>>
> >       >>>>>    }
> >
> >       Historically, I've found that busy waits like the above
> > are problematic.  I'd go
> >       along with David's comment/thought and try
> >
> >               while(!finished) Thread.yield();
> >
> >       or something else to cause it to get descheduled for a
> > whole quanta for each
> >       check rather than busy waiting for a whole quanta which
> > will keep at least one
> >       CPU busy doing nothing productive.
> >
> >       Gregg Wonderly
> >
> >
> >
> >
> _______________________________________________________________________
> Notice:  This email message, together with any attachments, may contain
> information  of  BEA Systems,  Inc.,  its subsidiaries  and  affiliated
> entities,  that may be confidential,  proprietary,  copyrighted  and/or
> legally privileged, and is intended solely for the use of the individual
> or entity named in this message. If you are not the intended recipient,
> and have received this message in error, please immediately return this
> by email and then delete it.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061212/089aca37/attachment.html 

From gergg at cox.net  Tue Dec 12 09:26:23 2006
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 12 Dec 2006 08:26:23 -0600
Subject: [concurrency-interest] ConcurrentHashmap.putIfAbsent oddities
In-Reply-To: <AE2A8E488D9B26438919DF3C9C95528D27EDA1@hermes.coremedia.com>
References: <AE2A8E488D9B26438919DF3C9C95528D27EDA1@hermes.coremedia.com>
Message-ID: <457EBC0F.2070308@cox.net>

Ernst, Matthias wrote:
>>... && Arrays.equals(urls, other.urls);
> 
> I don't know if this is related to your problem but
> comparing URLs has unpleasant side effects:

This is existing logic that I did not replace/alter that I know of.  I believe 
that it works as needed based on the fact that it causes a new ClassLoader to be 
created if one of the pieces of the codebase is not reachable.  Thus you will 
get class incompatibility which is at least a partially better result than using 
an incomplete codebase.

Gregg Wonderly

From MOKEEFFE at amfam.com  Tue Dec 12 10:01:56 2006
From: MOKEEFFE at amfam.com (OKeeffe, Michael K)
Date: Tue, 12 Dec 2006 09:01:56 -0600
Subject: [concurrency-interest] Backport concurrency util in EJB
Message-ID: <2E8B2DCB7DE50B42808F8063C4E2858F09583938@NHQ1ACCOEX05VS1.corporate.amfam.com>



>-----Original Message-----
>>
>> if the codes only depending on database access, how safe is 
>it to use 
>> backport concurrent util? (as the EJB spec clearly disencourage 
>> spawning thread).
>>
>The problem is that an EJB container maintains informations associated 
>with threads
>in order to manage transactions, security etc.
>
>more here, http://blog.w1c.ca/?p=92
>and google: batch processing J2EE
>>
According to this blog, until the spec catches up (and it seems it hasn't), the only acceptable way to do this is with vendor APIs, for example:
http://www.devwebsphere.com/devwebsphere/2003/11/async_beans_int.html


From tim at peierls.net  Tue Dec 12 10:01:59 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 12 Dec 2006 10:01:59 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>
References: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>
Message-ID: <63b4e4050612120701p8f74f55lffa9bd6507e3ab4b@mail.gmail.com>

The minimal approach would be to change pool.assign(...) to pool.execute(...),
where pool is now an Executor, externally managed by the parent class, say.
The pool implementation could be a fixed size ThreadPoolExecutor with a size
proportional to the number of processors on the server (a small constant
factor). For example,

    private final ExecutorService pool = Executors.newFixedThreadPool(2 *
Runtime.getRuntime().availableProcessors());

You need to make the various collections thread-safe, using
ConcurrentHashMap, for example -- that includes "domainsVisitados" and
"collection" (if the former is a set, you can use ConcurrentHashMap<String,
Boolean>).

And you can and should make the three private fields of SearchDomain final,
since SearchDomain is basically immutable.

Is ictx thread-safe? If not, you'll have to synchronize access to it.

--tim


On 12/11/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> Hi all,
>
> I've been tasked with converting a DNS problem from a GPL thread pool
> from around 2000 to j.u.c. The current code ignores exceptions, is not
> very maintainable and I've decided that it would be best to start
> over. One caveat: The program uses recursion and a new thread for
> every iteration.
>
> The goal however necessary is to get every 'A record' , determine if
> the 'A record' is actually a 'DN record' , and if so, start over -
> perhaps recursively. The result being a List of every host and ip from
> a given DNS server.
>
> I'm looking at the jcip TransformingSequential example, and thinking
> how I could apply that to this problem. I've also been thinking about
> perhaps dividing the 'A record' and 'DN record' into different
> CompletionService's . Nothing seems right yet. Here's the old code, an
> inner class - the only relevant thing in the parent class is that it
> inits the 'DirContext ictx'. Any ideas?
>
>     // fugly code
>     private class SearchDomain implements Runnable {
>
>         private boolean recursive;
>         private Map<String, String> collection;
>         private String domain;
>
>         public SearchDomain(String domain, Map<String, String> collection,
>                 boolean recursive) {
>
>             this.domain = domain;
>             this.collection = collection;
>             this.recursive = recursive;
>         }
>
>         public void run() {
>
>             if (!domainsVisitados.contains(domain)) {
>
>                 domainsVisitados.add(domain);
>
>                 try {
>                     NamingEnumeration hostEnumeration = ictx.list(domain);
>
>                     // get the hosts with their names and ip's.
>                     while (hostEnumeration.hasMore()) {
>
>                         String host = null;
>                         host = ((NameClassPair) hostEnumeration.next())
>                                 .getNameInNamespace();
>
>                         // Get 'A Records'
>                         Attributes a = ictx.getAttributes(host,
>                                 new String[] { "A" });
>
>                         if (a.get("A") != null) {
>                             String ip = a.get("A").get().toString();
>                             collection.put(host, ip);
>                         }
>                         if (recursive) {
>                             // find which ones are DNS e create new thread
>                             Attributes aDNS = ictx.getAttributes(host,
>                                     new String[] { "NS" });
>                             NamingEnumeration allDNS = aDNS.getAll();
>
>                             while (allDNS.hasMore()) {
>                                 Attribute attr = (Attribute) allDNS.next
> ();
>                                 NamingEnumeration values = attr.getAll();
>
>                                 // put the host and ip into the
> 'collection'
>                                 while (values.hasMore()) {
>                                     String dns = values.next().toString();
>                                     pool.assign(new SearchDomain(dns,
>                                             collection, recursive));
>                                 }
>                             }
>                         }
>                     }
>                 } catch (Exception e) {
>                     e.printStackTrace();
>                 }
>             }
>         }
>     }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061212/742da154/attachment-0001.html 

From MOKEEFFE at amfam.com  Tue Dec 12 10:41:07 2006
From: MOKEEFFE at amfam.com (michaelok)
Date: Tue, 12 Dec 2006 07:41:07 -0800 (PST)
Subject: [concurrency-interest] concurrency-interest search (Was
 Upgrading a RL to WL in ReentrantReadWriteLock)
In-Reply-To: <45759DAB.8010106@yahoo.com>
References: <45759DAB.8010106@yahoo.com>
Message-ID: <7835478.post@talk.nabble.com>




Bela Ban wrote:
> 
> Apologies if this has been asked before - I tried to google and search 
> the concurrency-interest mailing list archives, to no avail (note that 
> the archives at 
> http://altair.cs.oswego.edu/mailman/private/concurrency-interest/ cannot 
> be searched ! It would be good if you guys could change this...).
> 
> 

Bela, this site provides search capability of concurrency-interest.  Free
registration.  

http://www.nabble.com/Upgrading-a-RL-to-WL-in-ReentrantReadWriteLock-tf2762910.html#a7703406

-- 
View this message in context: http://www.nabble.com/Upgrading-a-RL-to-WL-in-ReentrantReadWriteLock-tf2762910.html#a7835478
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From robertlazarski at gmail.com  Tue Dec 12 16:06:31 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Tue, 12 Dec 2006 16:06:31 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <63b4e4050612120701p8f74f55lffa9bd6507e3ab4b@mail.gmail.com>
References: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>
	<63b4e4050612120701p8f74f55lffa9bd6507e3ab4b@mail.gmail.com>
Message-ID: <f87675ee0612121306j30802a05i22c8d8847b1c0581@mail.gmail.com>

On 12/12/06, Tim Peierls <tim at peierls.net> wrote:
> The minimal approach

Thanks for the reply Tim. I've decided to start from scratch as the
original code is broke in several ways. The whole recursion part may
be a misunderstanding of the original coder. Anyways, while I'm trying
to figure it out I implemented it using j.u.c and I'm posting it here
in case someone could review it.

There is one question I have: awaitTermination doesn't do what I
expect - end after 100 seconds, ie, I get the List returned but the
main() keeps going. Perhaps something to do with daemon threads. Any
insight appreciated.

package org;

import static java.lang.System.out;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Hashtable;
import java.util.List;
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.Executor;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

import javax.naming.NameClassPair;
import javax.naming.NamingEnumeration;
import javax.naming.directory.Attributes;
import javax.naming.directory.DirContext;
import javax.naming.directory.InitialDirContext;
import javax.naming.directory.Attribute;
import javax.naming.directory.Attributes;

public class DNS
{

  public static void main(String[] args) throws Exception {
      helloDNS();
  }

  /*******************************************************************
  Use this method to test dns
  *******************************************************************/
  private static void helloDNS() throws Exception {
       calculateDNS("bee.uspnet.usp.br", "usp.br");
  }

  private static List<String> calculateDNS(String dnsIP, String domain)
          throws Exception {

      Hashtable<String, String> env = new Hashtable<String, String>();
      env.put("java.naming.factory.initial",
"com.sun.jndi.dns.DnsContextFactory");
      env.put("java.naming.provider.url",  "dns://" + dnsIP + "/");

      // obter contexto inicial
      DirContext ictx = null;
      NamingEnumeration hostEnumeration = null;
      try {
          out.println("getting conn: ");
          ictx = new InitialDirContext(env);
          out.println("getting conn, getting list ");
          hostEnumeration = ictx.list(domain);
          out.println("got list ");
      } catch (Exception ex) {
          ex.printStackTrace();
          throw new Exception(ex);
      }
      ExecutorService exec = Executors.newCachedThreadPool(
              new ONExceptionThreadFactory(new ONExceptionHandler()));
      // skip those already found
      Queue <String> domainsVisitedQueue = new ConcurrentLinkedQueue<String>();
      domainsVisitedQueue.add(domain);
      Queue <String> resultQueue = new ConcurrentLinkedQueue<String>();
      parallelRecursiveDNS(exec, ictx, hostEnumeration,
domainsVisitedQueue, resultQueue);
      exec.awaitTermination(100L, TimeUnit.SECONDS);

      return new ArrayList<String>(resultQueue);
  }	

  private static void parallelRecursiveDNS(final Executor exec, final
DirContext ictx,
          final NamingEnumeration hostEnumeration, final
Collection<String> domainsVisitedQueue,
          final Collection<String> results)
      throws Exception {

      while (hostEnumeration.hasMore()) {

          exec.execute(new Runnable() {
              public void run() {
                  try {
                      String host = null;
                      host = ((NameClassPair) hostEnumeration.next())
                              .getNameInNamespace();
                      results.add(host);
                      out.println("Found host: " + host);
                      // all 'A records'
                      Attributes a = ictx.getAttributes(host,
                              new String[] { "A" });
                      if (a.get("A") != null) {
                          String ip = a.get("A").get().toString();
                          results.add(ip);
                          out.println("Found ip: " + ip);
                      }
                      // enter task suitable for recursion?
                      Attributes aDNS = ictx.getAttributes(host,
                                  new String[] { "NS" });
                      NamingEnumeration allDNS = aDNS.getAll();
                      while (allDNS.hasMore()) {
                          out.println("Entering allDNS: ");
                          Attribute attr = (Attribute) allDNS.next();
                          NamingEnumeration values = attr.getAll();
                          String dns = values.next().toString();
                          if (domainsVisitedQueue.contains(dns)) {
                              continue;
                          }
                          NamingEnumeration newHost = ictx.list(dns);
                          out.println("doing recursion: ");
                          parallelRecursiveDNS(exec, ictx, newHost,
domainsVisitedQueue, results);
                      }
                  } catch (Exception ex) { ex.printStackTrace(); }

              }

          });
      }
  }
}

From tim at peierls.net  Tue Dec 12 16:22:12 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 12 Dec 2006 16:22:12 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <f87675ee0612121306j30802a05i22c8d8847b1c0581@mail.gmail.com>
References: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>
	<63b4e4050612120701p8f74f55lffa9bd6507e3ab4b@mail.gmail.com>
	<f87675ee0612121306j30802a05i22c8d8847b1c0581@mail.gmail.com>
Message-ID: <63b4e4050612121322t1098346du1ccd4a24e7d56a6d@mail.gmail.com>

You need to shutdown the ExecutorService before awaitTermination can ever
succeed. See Listings 7.16 and 7.22 in JCiP for examples of awaitTermination
with shutdown and shutdownNow.

In your case, you don't know when the recursion is finished, so you don't
know when to shut down the pool. See the discussion on p.187 of JCiP about
stopping ConcurrentPuzzleSolver for different ways to deal with this.

--tim

On 12/12/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> On 12/12/06, Tim Peierls <tim at peierls.net> wrote:
> > The minimal approach
>
> Thanks for the reply Tim. I've decided to start from scratch as the
> original code is broke in several ways. The whole recursion part may
> be a misunderstanding of the original coder. Anyways, while I'm trying
> to figure it out I implemented it using j.u.c and I'm posting it here
> in case someone could review it.
>
> There is one question I have: awaitTermination doesn't do what I
> expect - end after 100 seconds, ie, I get the List returned but the
> main() keeps going. Perhaps something to do with daemon threads. Any
> insight appreciated.
>
> package org;
>
> import static java.lang.System.out;
>
> import java.util.ArrayList;
> import java.util.Collection;
> import java.util.Hashtable;
> import java.util.List;
> import java.util.Queue;
> import java.util.concurrent.ConcurrentLinkedQueue;
> import java.util.concurrent.Executor;
> import java.util.concurrent.ExecutorService;
> import java.util.concurrent.Executors;
> import java.util.concurrent.TimeUnit;
>
> import javax.naming.NameClassPair;
> import javax.naming.NamingEnumeration;
> import javax.naming.directory.Attributes;
> import javax.naming.directory.DirContext;
> import javax.naming.directory.InitialDirContext;
> import javax.naming.directory.Attribute;
> import javax.naming.directory.Attributes;
>
> public class DNS
> {
>
>   public static void main(String[] args) throws Exception {
>       helloDNS();
>   }
>
>   /*******************************************************************
>   Use this method to test dns
>   *******************************************************************/
>   private static void helloDNS() throws Exception {
>        calculateDNS("bee.uspnet.usp.br", "usp.br");
>   }
>
>   private static List<String> calculateDNS(String dnsIP, String domain)
>           throws Exception {
>
>       Hashtable<String, String> env = new Hashtable<String, String>();
>       env.put("java.naming.factory.initial",
> "com.sun.jndi.dns.DnsContextFactory");
>       env.put("java.naming.provider.url",  "dns://" + dnsIP + "/");
>
>       // obter contexto inicial
>       DirContext ictx = null;
>       NamingEnumeration hostEnumeration = null;
>       try {
>           out.println("getting conn: ");
>           ictx = new InitialDirContext(env);
>           out.println("getting conn, getting list ");
>           hostEnumeration = ictx.list(domain);
>           out.println("got list ");
>       } catch (Exception ex) {
>           ex.printStackTrace();
>           throw new Exception(ex);
>       }
>       ExecutorService exec = Executors.newCachedThreadPool(
>               new ONExceptionThreadFactory(new ONExceptionHandler()));
>       // skip those already found
>       Queue <String> domainsVisitedQueue = new
> ConcurrentLinkedQueue<String>();
>       domainsVisitedQueue.add(domain);
>       Queue <String> resultQueue = new ConcurrentLinkedQueue<String>();
>       parallelRecursiveDNS(exec, ictx, hostEnumeration,
> domainsVisitedQueue, resultQueue);
>       exec.awaitTermination(100L, TimeUnit.SECONDS);
>
>       return new ArrayList<String>(resultQueue);
>   }
>
>   private static void parallelRecursiveDNS(final Executor exec, final
> DirContext ictx,
>           final NamingEnumeration hostEnumeration, final
> Collection<String> domainsVisitedQueue,
>           final Collection<String> results)
>       throws Exception {
>
>       while (hostEnumeration.hasMore()) {
>
>           exec.execute(new Runnable() {
>               public void run() {
>                   try {
>                       String host = null;
>                       host = ((NameClassPair) hostEnumeration.next())
>                               .getNameInNamespace();
>                       results.add(host);
>                       out.println("Found host: " + host);
>                       // all 'A records'
>                       Attributes a = ictx.getAttributes(host,
>                               new String[] { "A" });
>                       if (a.get("A") != null) {
>                           String ip = a.get("A").get().toString();
>                           results.add(ip);
>                           out.println("Found ip: " + ip);
>                       }
>                       // enter task suitable for recursion?
>                       Attributes aDNS = ictx.getAttributes(host,
>                                   new String[] { "NS" });
>                       NamingEnumeration allDNS = aDNS.getAll();
>                       while (allDNS.hasMore()) {
>                           out.println("Entering allDNS: ");
>                           Attribute attr = (Attribute) allDNS.next();
>                           NamingEnumeration values = attr.getAll();
>                           String dns = values.next().toString();
>                           if (domainsVisitedQueue.contains(dns)) {
>                               continue;
>                           }
>                           NamingEnumeration newHost = ictx.list(dns);
>                           out.println("doing recursion: ");
>                           parallelRecursiveDNS(exec, ictx, newHost,
> domainsVisitedQueue, results);
>                       }
>                   } catch (Exception ex) { ex.printStackTrace(); }
>
>               }
>
>           });
>       }
>   }
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061212/fff03734/attachment.html 

From dcholmes at optusnet.com.au  Tue Dec 12 17:51:37 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 13 Dec 2006 08:51:37 +1000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <7153be990612120151q7a0fb113w998ac349d3db6270@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEIKHEAA.dcholmes@optusnet.com.au>

David,

> From what I can read in this thread so far - it's either a
> scheduling issue with the OS, or
> I'm being too aggressive with use of the volatile

Both. The scheduling issue gives the busy-wait thread far too much CPU time.
The fact that it is doing violatile accesses means that it is hitting the
memory system in a way that interferes with the other threads too.

> (I chose this since I wanted to see what
> the processors would act like when forced to go to main memory,
> rather than fetching from their 4MB cache.).

Please don't think of volatile in this way - the old model of "main memory"
vs. "local memory" was conceptually simple but doesn't reflect how actual
implementations work. The value will still be read from the cache if it is
present, the cache coherency hardware takes care of everything. It is the
fences/memory-barriers that add the overhead.

> Oh, and it's Linux kernel 2.6.17.

I've learnt that Ubuntu has some interesting behaviour in other areas too -
ie you can use real-time scheduling (SCHED_FIFO) without needing root
access. I'm trying to find out whether this is Ubuntu specific modifications
or whether these are kernel features.

Cheers,
David Holmes


From dcholmes at optusnet.com.au  Tue Dec 12 19:38:24 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 13 Dec 2006 10:38:24 +1000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEIKHEAA.dcholmes@optusnet.com.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEILHEAA.dcholmes@optusnet.com.au>

Correction:

> Both. The scheduling issue gives the busy-wait thread far too
> much CPU time.
> The fact that it is doing violatile accesses means that it is hitting the
> memory system in a way that interferes with the other threads too.

The spin loop does volatile reads which don't require fences/barriers, so it
shouldn't be causing interference.

It would be interesting to see how this performs without the spin-loop. It
might be all the fences induced by the worker threads as Bjorn suggested.

David Holmes


From hans.boehm at hp.com  Tue Dec 12 14:38:07 2006
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 12 Dec 2006 13:38:07 -0600
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <7153be990612120151q7a0fb113w998ac349d3db6270@mail.gmail.com>
Message-ID: <BDA38860DCFD334EAEA905E44EE8E7EF52C8F9@G3W0067.americas.hpqcorp.net>

I believe that Bjorn is right, and it's the fence following volatile stores on a multiprocessor that's causing the problem.  That sounds far more plausible than anything else I've seen here, including my own explanations.
 
Note that volatile doesn't force anything out of the cache; it just forces the processor to execute an mfence instructions for each store to enforce ordering between a volatile store and a subsequent volatile load.  On a P4 that typically costs you > 100 cycles.  On a core 2 duo I believe it's much less, but still significant.  
 
(Since the volatiles are only accessed by a single thread, I also believe it's actually correct to effectively optimize out the volatile qualifier in this case, or to optimize away the whole loop for that matter.   I'd be mildly impressed if a compiler actually did that.  As a general rule, it's poor practice to put empty loops in microbenchmarks.  It makes the benchmark very dependent on aspects of compiler optimization that don't matter for real code.)
 
Hans


________________________________

	From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David Harrigan
	Sent: Tuesday, December 12, 2006 1:52 AM
	To: concurrency-interest at cs.oswego.edu
	Subject: Re: [concurrency-interest] Multi-core testing, help with findings
	
	
	Hi All,
	
	I would love to explore this further. I could certainly try out the thread.yield().....but I have
	a small problemo now! My core 2 duo is going back to the factory since the screen doesn't
	appear to want to play ball :-( I'll have to wait until I can try the suggestions out. However, 
	this of course does not mean no-one else can give it a whirl. All this is very interesting, and
	I think highlights an area that is going to become more and more prevalent - as more
	developers have multi-core machines to develop on, then these things are going to come 
	up more often...
	
	From what I can read in this thread so far - it's either a scheduling issue with the OS, or
	I'm being too aggressive with use of the volatile (I chose this since I wanted to see what
	the processors would act like when forced to go to main memory, rather than fetching 
	from their 4MB cache.).
	
	Oh, and it's Linux kernel 2.6.17.
	
	-=david=-
	
	
	On 12/12/06, Bjorn Antonsson <ban at bea.com > wrote: 

		Hi,
		
		I would say that a lot of the extra time it takes comes from the fact that the volatile stores/loads in the Worker class, actually 1000000 of them, do mean something on a multi CPU. 
		
		On a typical x86 SMP machine the load/store/load pattern on volatiles results in an mfence instruction, which is quite costly. This is a normal load/store/load without mfence on a single CPU machine, since we are guaranteed that the next thread will have the same view of the memory. 
		
		/Bj?rn
		
		> -----Original Message-----
		> From: concurrency-interest-bounces at cs.oswego.edu
		> [mailto: concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu> ] On Behalf
		> Of David Harrigan
		> Sent: den 12 december 2006 07:57
		> To: concurrency-interest at cs.oswego.edu 
		> Subject: Re: [concurrency-interest] Multi-core testing, help
		> with findings
		>
		> Hi,
		>
		> I completely forgot to mention that platform is Linux (Ubuntu 6.10).
		>
		> Just scanning thru the mail, will read when I get to work... 
		>
		> -=david=-
		>
		>
		> On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
		>
		>
		>
		>       David Holmes wrote:
		>       > I've assumed the platform is Windows, but if it is 
		> linux then that opens
		>       > other possibilities. The problem can be explained if
		> the busy-wait thread
		>       > doesn't get descheduled (which is easy to test by
		> changing it to not be a 
		>       > busy-wait). The issue as to why it doesn't get
		> descheduled is then the
		>       > interesting part. I suspect an OS scheduling quirk on
		> multi-core, but need
		>       > more information. 
		>
		>       >>>>>    private long doIt() {
		>       >>>>>        long startTime = System.currentTimeMillis();
		>       >>>>>        for(int i = 0; i < howMany; i++) { 
		>       >>>>>            new Thread(new Worker()).start();
		>       >>>>>        }
		>       >>>>>        while(!finished);
		>       >>>>>        long endTime = System.currentTimeMillis();
		>       >>>>>        return (endTime - startTime);
		>       >>>>>
		>       >>>>>    }
		>
		>       Historically, I've found that busy waits like the above 
		> are problematic.  I'd go
		>       along with David's comment/thought and try
		>
		>               while(!finished) Thread.yield();
		>
		>       or something else to cause it to get descheduled for a 
		> whole quanta for each
		>       check rather than busy waiting for a whole quanta which
		> will keep at least one
		>       CPU busy doing nothing productive.
		>
		>       Gregg Wonderly
		>
		>
		>
		>
		_______________________________________________________________________
		Notice:  This email message, together with any attachments, may contain
		information  of  BEA Systems,  Inc.,  its subsidiaries  and  affiliated 
		entities,  that may be confidential,  proprietary,  copyrighted  and/or
		legally privileged, and is intended solely for the use of the individual
		or entity named in this message. If you are not the intended recipient, 
		and have received this message in error, please immediately return this
		by email and then delete it.
		
		_______________________________________________
		Concurrency-interest mailing list
		Concurrency-interest at altair.cs.oswego.edu
		http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
		


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061212/2ff4ccdd/attachment.html 

From dcholmes at optusnet.com.au  Tue Dec 12 23:01:40 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 13 Dec 2006 14:01:40 +1000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <BDA38860DCFD334EAEA905E44EE8E7EF52C8F9@G3W0067.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEILHEAA.dcholmes@optusnet.com.au>

I really must learn to read what is written in sample code rather than what
I expect to see :) The volatile on the per-thread counter had escaped my
notice. I most definitely agree that that is the cause of the performance
loss - volatiles are free on UP systems but not on MP and this is
pathological usage.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Boehm, Hans
  Sent: Wednesday, 13 December 2006 5:38 AM
  To: David Harrigan
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Multi-core testing, help with findings


  I believe that Bjorn is right, and it's the fence following volatile
stores on a multiprocessor that's causing the problem.  That sounds far more
plausible than anything else I've seen here, including my own explanations.

  Note that volatile doesn't force anything out of the cache; it just forces
the processor to execute an mfence instructions for each store to enforce
ordering between a volatile store and a subsequent volatile load.  On a P4
that typically costs you > 100 cycles.  On a core 2 duo I believe it's much
less, but still significant.

  (Since the volatiles are only accessed by a single thread, I also believe
it's actually correct to effectively optimize out the volatile qualifier in
this case, or to optimize away the whole loop for that matter.   I'd be
mildly impressed if a compiler actually did that.  As a general rule, it's
poor practice to put empty loops in microbenchmarks.  It makes the benchmark
very dependent on aspects of compiler optimization that don't matter for
real code.)

  Hans



----------------------------------------------------------------------------
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David
Harrigan
    Sent: Tuesday, December 12, 2006 1:52 AM
    To: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] Multi-core testing, help with
findings


    Hi All,

    I would love to explore this further. I could certainly try out the
thread.yield().....but I have
    a small problemo now! My core 2 duo is going back to the factory since
the screen doesn't
    appear to want to play ball :-( I'll have to wait until I can try the
suggestions out. However,
    this of course does not mean no-one else can give it a whirl. All this
is very interesting, and
    I think highlights an area that is going to become more and more
prevalent - as more
    developers have multi-core machines to develop on, then these things are
going to come
    up more often...

    From what I can read in this thread so far - it's either a scheduling
issue with the OS, or
    I'm being too aggressive with use of the volatile (I chose this since I
wanted to see what
    the processors would act like when forced to go to main memory, rather
than fetching
    from their 4MB cache.).

    Oh, and it's Linux kernel 2.6.17.

    -=david=-


    On 12/12/06, Bjorn Antonsson <ban at bea.com > wrote:
      Hi,

      I would say that a lot of the extra time it takes comes from the fact
that the volatile stores/loads in the Worker class, actually 1000000 of
them, do mean something on a multi CPU.

      On a typical x86 SMP machine the load/store/load pattern on volatiles
results in an mfence instruction, which is quite costly. This is a normal
load/store/load without mfence on a single CPU machine, since we are
guaranteed that the next thread will have the same view of the memory.

      /Bj?rn

      > -----Original Message-----
      > From: concurrency-interest-bounces at cs.oswego.edu
      > [mailto: concurrency-interest-bounces at cs.oswego.edu] On Behalf
      > Of David Harrigan
      > Sent: den 12 december 2006 07:57
      > To: concurrency-interest at cs.oswego.edu
      > Subject: Re: [concurrency-interest] Multi-core testing, help
      > with findings
      >
      > Hi,
      >
      > I completely forgot to mention that platform is Linux (Ubuntu 6.10).
      >
      > Just scanning thru the mail, will read when I get to work...
      >
      > -=david=-
      >
      >
      > On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
      >
      >
      >
      >       David Holmes wrote:
      >       > I've assumed the platform is Windows, but if it is
      > linux then that opens
      >       > other possibilities. The problem can be explained if
      > the busy-wait thread
      >       > doesn't get descheduled (which is easy to test by
      > changing it to not be a
      >       > busy-wait). The issue as to why it doesn't get
      > descheduled is then the
      >       > interesting part. I suspect an OS scheduling quirk on
      > multi-core, but need
      >       > more information.
      >
      >       >>>>>    private long doIt() {
      >       >>>>>        long startTime = System.currentTimeMillis();
      >       >>>>>        for(int i = 0; i < howMany; i++) {
      >       >>>>>            new Thread(new Worker()).start();
      >       >>>>>        }
      >       >>>>>        while(!finished);
      >       >>>>>        long endTime = System.currentTimeMillis();
      >       >>>>>        return (endTime - startTime);
      >       >>>>>
      >       >>>>>    }
      >
      >       Historically, I've found that busy waits like the above
      > are problematic.  I'd go
      >       along with David's comment/thought and try
      >
      >               while(!finished) Thread.yield();
      >
      >       or something else to cause it to get descheduled for a
      > whole quanta for each
      >       check rather than busy waiting for a whole quanta which
      > will keep at least one
      >       CPU busy doing nothing productive.
      >
      >       Gregg Wonderly
      >
      >
      >
      >

_______________________________________________________________________
      Notice:  This email message, together with any attachments, may
contain
      information  of  BEA Systems,  Inc.,  its subsidiaries  and
affiliated
      entities,  that may be confidential,  proprietary,  copyrighted
and/or
      legally privileged, and is intended solely for the use of the
individual
      or entity named in this message. If you are not the intended
recipient,
      and have received this message in error, please immediately return
this
      by email and then delete it.

      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at altair.cs.oswego.edu
      http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/69206aba/attachment-0001.html 

From dharrigan at gmail.com  Wed Dec 13 01:52:54 2006
From: dharrigan at gmail.com (David Harrigan)
Date: Wed, 13 Dec 2006 06:52:54 +0000
Subject: [concurrency-interest] Multi-core testing, help with findings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEILHEAA.dcholmes@optusnet.com.au>
References: <BDA38860DCFD334EAEA905E44EE8E7EF52C8F9@G3W0067.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCOEILHEAA.dcholmes@optusnet.com.au>
Message-ID: <7153be990612122252q32c881a6s5fded43a4b8c47a9@mail.gmail.com>

Hi,

Thanks to everyone who have spent the time looking at my little sample. It
has
been very educational. Yes, I was wrong to use the volatile in the counter -
I
thought it was a good way to test real-world performance, but I've been
wrong
and it's clear why now. All very interesting stuff :-)

As way of a test, what could I try to see the difference two cores makes
against
one core? I want to prove to myself that I've spent money on a worthwhile
thing ;-)

-=david=-

On 12/13/06, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  I really must learn to read what is written in sample code rather than
> what I expect to see :) The volatile on the per-thread counter had escaped
> my notice. I most definitely agree that that is the cause of the performance
> loss - volatiles are free on UP systems but not on MP and this is
> pathological usage.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Boehm, Hans
> *Sent:* Wednesday, 13 December 2006 5:38 AM
> *To:* David Harrigan
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Multi-core testing, help with
> findings
>
> I believe that Bjorn is right, and it's the fence following volatile
> stores on a multiprocessor that's causing the problem.  That sounds far more
> plausible than anything else I've seen here, including my own explanations.
>
> Note that volatile doesn't force anything out of the cache; it just forces
> the processor to execute an mfence instructions for each store to enforce
> ordering between a volatile store and a subsequent volatile load.  On a P4
> that typically costs you > 100 cycles.  On a core 2 duo I believe it's much
> less, but still significant.
>
> (Since the volatiles are only accessed by a single thread, I also believe
> it's actually correct to effectively optimize out the volatile qualifier in
> this case, or to optimize away the whole loop for that matter.   I'd be
> mildly impressed if a compiler actually did that.  As a general rule, it's
> poor practice to put empty loops in microbenchmarks.  It makes the benchmark
> very dependent on aspects of compiler optimization that don't matter for
> real code.)
>
> Hans
>
>  ------------------------------
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *David Harrigan
> *Sent:* Tuesday, December 12, 2006 1:52 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Multi-core testing, help with
> findings
>
> Hi All,
>
> I would love to explore this further. I could certainly try out the
> thread.yield().....but I have
> a small problemo now! My core 2 duo is going back to the factory since the
> screen doesn't
> appear to want to play ball :-( I'll have to wait until I can try the
> suggestions out. However,
> this of course does not mean no-one else can give it a whirl. All this is
> very interesting, and
> I think highlights an area that is going to become more and more prevalent
> - as more
> developers have multi-core machines to develop on, then these things are
> going to come
> up more often...
>
> From what I can read in this thread so far - it's either a scheduling
> issue with the OS, or
> I'm being too aggressive with use of the volatile (I chose this since I
> wanted to see what
> the processors would act like when forced to go to main memory, rather
> than fetching
> from their 4MB cache.).
>
> Oh, and it's Linux kernel 2.6.17.
>
> -=david=-
>
> On 12/12/06, Bjorn Antonsson <ban at bea.com > wrote:
> >
> > Hi,
> >
> > I would say that a lot of the extra time it takes comes from the fact
> > that the volatile stores/loads in the Worker class, actually 1000000 of
> > them, do mean something on a multi CPU.
> >
> > On a typical x86 SMP machine the load/store/load pattern on volatiles
> > results in an mfence instruction, which is quite costly. This is a normal
> > load/store/load without mfence on a single CPU machine, since we are
> > guaranteed that the next thread will have the same view of the memory.
> >
> > /Bj?rn
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto: concurrency-interest-bounces at cs.oswego.edu] On Behalf
> > > Of David Harrigan
> > > Sent: den 12 december 2006 07:57
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] Multi-core testing, help
> > > with findings
> > >
> > > Hi,
> > >
> > > I completely forgot to mention that platform is Linux (Ubuntu 6.10).
> > >
> > > Just scanning thru the mail, will read when I get to work...
> > >
> > > -=david=-
> > >
> > >
> > > On 12/12/06, Gregg Wonderly <gregg at cytetech.com> wrote:
> > >
> > >
> > >
> > >       David Holmes wrote:
> > >       > I've assumed the platform is Windows, but if it is
> > > linux then that opens
> > >       > other possibilities. The problem can be explained if
> > > the busy-wait thread
> > >       > doesn't get descheduled (which is easy to test by
> > > changing it to not be a
> > >       > busy-wait). The issue as to why it doesn't get
> > > descheduled is then the
> > >       > interesting part. I suspect an OS scheduling quirk on
> > > multi-core, but need
> > >       > more information.
> > >
> > >       >>>>>    private long doIt() {
> > >       >>>>>        long startTime = System.currentTimeMillis();
> > >       >>>>>        for(int i = 0; i < howMany; i++) {
> > >       >>>>>            new Thread(new Worker()).start();
> > >       >>>>>        }
> > >       >>>>>        while(!finished);
> > >       >>>>>        long endTime = System.currentTimeMillis();
> > >       >>>>>        return (endTime - startTime);
> > >       >>>>>
> > >       >>>>>    }
> > >
> > >       Historically, I've found that busy waits like the above
> > > are problematic.  I'd go
> > >       along with David's comment/thought and try
> > >
> > >               while(!finished) Thread.yield();
> > >
> > >       or something else to cause it to get descheduled for a
> > > whole quanta for each
> > >       check rather than busy waiting for a whole quanta which
> > > will keep at least one
> > >       CPU busy doing nothing productive.
> > >
> > >       Gregg Wonderly
> > >
> > >
> > >
> > >
> > _______________________________________________________________________
> > Notice:  This email message, together with any attachments, may contain
> > information  of  BEA Systems,  Inc.,  its subsidiaries  and  affiliated
> > entities,  that may be confidential,  proprietary,  copyrighted  and/or
> > legally privileged, and is intended solely for the use of the individual
> > or entity named in this message. If you are not the intended recipient,
> > and have received this message in error, please immediately return this
> > by email and then delete it.
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/5dce9840/attachment.html 

From dhanji at gmail.com  Wed Dec 13 03:11:56 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 13 Dec 2006 18:11:56 +1000
Subject: [concurrency-interest] Backport concurrency util in EJB
In-Reply-To: <2E8B2DCB7DE50B42808F8063C4E2858F09583938@NHQ1ACCOEX05VS1.corporate.amfam.com>
References: <2E8B2DCB7DE50B42808F8063C4E2858F09583938@NHQ1ACCOEX05VS1.corporate.amfam.com>
Message-ID: <aa067ea10612130011x4d3256d0k3e10edba9dafe7b9@mail.gmail.com>

If you have access to a JEE 1.4+ container you can use the timer EJB to
schedule multiple concurrent jobs from the original request (set firstDate
to sysdate to start immediately). These will run asynchronously and safely
within the EJB container.

http://www.onjava.com/pub/a/onjava/2004/10/13/j2ee-timers.html?page=1

On 12/13/06, OKeeffe, Michael K <MOKEEFFE at amfam.com> wrote:
>
>
>
> >-----Original Message-----
> >>
> >> if the codes only depending on database access, how safe is
> >it to use
> >> backport concurrent util? (as the EJB spec clearly disencourage
> >> spawning thread).
> >>
> >The problem is that an EJB container maintains informations associated
> >with threads
> >in order to manage transactions, security etc.
> >
> >more here, http://blog.w1c.ca/?p=92
> >and google: batch processing J2EE
> >>
> According to this blog, until the spec catches up (and it seems it
> hasn't), the only acceptable way to do this is with vendor APIs, for
> example:
> http://www.devwebsphere.com/devwebsphere/2003/11/async_beans_int.html
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/fb6323a9/attachment.html 

From peter.kovacs at chemaxon.hu  Wed Dec 13 06:54:42 2006
From: peter.kovacs at chemaxon.hu (=?ISO-8859-1?Q?P=E9ter_Kov=E1cs?=)
Date: Wed, 13 Dec 2006 12:54:42 +0100
Subject: [concurrency-interest] Best CPUs for testing
Message-ID: <457FEA02.4020006@chemaxon.hu>

Hi,

A passage in "The Java Memory Model" section in "Concurrent Programming 
in Java" prompted me to ask the question: can the CPUs currently 
available on the market be ranked by their suitability for detecting 
concurrent programming problems. While I am certainly interested in the 
"theoretical" considerations of why a given CPU is better positioned for 
testing concurrent code than another, I would like to use such an 
ordered list to effectively pick an affordable CPU for my tests. (So 
there is a practical motivation to my question.)

A similar question may be asked about OSs -- but OSs are probably less 
relevant in this regard.

The following anecdote may be related to this question: I recently 
discovered a synchronization bug in our code using a single-core 
single-Opteron machine (i.e one core in total) with Solaris 10 which 
went undetected on various single-core or multi-core (including 
multi-processor) Intel architectures with Linux and Windows operating 
systems. The bug was not obvious, because for it to occur a highly 
unlikely scheduling of two concurrent threads was required (one of the 
thread was required to be suspended almost about half a second after it 
has been started -- with the other going ahead with its work and getting 
into a state as if it hadn't done any work yet and, as a result, getting 
into a deadlock with the other). In your experience, which one is more 
relevant: the peculiarities of the CPU or those of the operating system? 
Or may be the HotSpot compiler? Might there be platform specific 
optimizations by the HotSpot compiler at work here? (I am starting to 
see that it is not trivial to tell the effect of these factors apart, 
since for certain platforms [like Solaris] there may be not many JIT 
compiler implementations to test with -- apart from that of the OS 
vendor's.)

The passage in Doug Lea's book mentioned above is: "The use of common 
caches across threads sharing a CPU, the lack of aggressive 
compiler-based optimizations, and the presence of strong cache 
consistency hardware often cause values to act as if they propagate 
immediately among threads."

Does this mean that, for example, Intel Core Duo processors are likelier 
to bring a concurrency problem to surface than are Intel Core 2 Duo 
processors with cores of the former working from separate caches. (I may 
be confusing several things here. For example, I do not even now if the 
"shared cache" of the Core 2 Duo-s is the same kind of cache which is 
meant by the passage above. :-) )

Any comment appreciated.

Thanks
Peter

From robertlazarski at gmail.com  Wed Dec 13 09:23:45 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Wed, 13 Dec 2006 09:23:45 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <63b4e4050612121322t1098346du1ccd4a24e7d56a6d@mail.gmail.com>
References: <f87675ee0612111134w49b9641cl5bada9da20925365@mail.gmail.com>
	<63b4e4050612120701p8f74f55lffa9bd6507e3ab4b@mail.gmail.com>
	<f87675ee0612121306j30802a05i22c8d8847b1c0581@mail.gmail.com>
	<63b4e4050612121322t1098346du1ccd4a24e7d56a6d@mail.gmail.com>
Message-ID: <f87675ee0612130623p2c71f471g158ff13c8cb4d01@mail.gmail.com>

OK, I put exec.shutdown() right before exec.awaitTermination().

However, I'm unclear on why the program wouldn't know if the recursion
is finished - lets assume no timeout. It roughly follows the jcip
listing 8.11 and 8.12, which doesn't have a latch or atomic counter.
Do I need a latch and atomic counter like the puzzle program for my
program to work right, as shown? I ask because each Runnable in my
case has the potential to add to the Collection, unlike the puzzler
which is looking for one result.

My main concern beyond the correct results is time: The program as
shown takes 7 minutes to run, though the original broken program was
even slower.

Thanks,
Robert

On 12/12/06, Tim Peierls <tim at peierls.net> wrote:
> You need to shutdown the ExecutorService before awaitTermination can ever
> succeed. See Listings 7.16 and 7.22 in JCiP for examples of awaitTermination
> with shutdown and shutdownNow.
>
> In your case, you don't know when the recursion is finished, so you don't
> know when to shut down the pool. See the discussion on p.187 of JCiP about
> stopping ConcurrentPuzzleSolver for different ways to deal with this.
>
> --tim
>
>
> On 12/12/06, robert lazarski < robertlazarski at gmail.com> wrote:
> >
> > On 12/12/06, Tim Peierls < tim at peierls.net> wrote:
> > > The minimal approach
> >
> > Thanks for the reply Tim. I've decided to start from scratch as the
> > original code is broke in several ways. The whole recursion part may
> > be a misunderstanding of the original coder. Anyways, while I'm trying
> > to figure it out I implemented it using j.u.c and I'm posting it here
> > in case someone could review it.
> >
> > There is one question I have: awaitTermination doesn't do what I
> > expect - end after 100 seconds, ie, I get the List returned but the
> > main() keeps going. Perhaps something to do with daemon threads. Any
> > insight appreciated.
> >
> > package org;
> >
> > import static java.lang.System.out;
> >
> > import java.util.ArrayList;
> > import java.util.Collection ;
> > import java.util.Hashtable;
> > import java.util.List;
> > import java.util.Queue;
> > import java.util.concurrent.ConcurrentLinkedQueue;
> > import java.util.concurrent.Executor;
> > import java.util.concurrent.ExecutorService ;
> > import java.util.concurrent.Executors;
> > import java.util.concurrent.TimeUnit;
> >
> > import javax.naming.NameClassPair;
> > import javax.naming.NamingEnumeration;
> > import javax.naming.directory.Attributes;
> > import javax.naming.directory.DirContext;
> > import javax.naming.directory.InitialDirContext;
> > import javax.naming.directory.Attribute;
> > import javax.naming.directory.Attributes;
> >
> > public class DNS
> > {
> >
> >   public static void main(String[] args) throws Exception {
> >       helloDNS();
> >   }
> >
> >
> /*******************************************************************
> >   Use this method to test dns
> >
> *******************************************************************/
> >   private static void helloDNS() throws Exception {
> >        calculateDNS("bee.uspnet.usp.br", "usp.br");
> >   }
> >
> >   private static List<String> calculateDNS(String dnsIP, String domain)
> >           throws Exception {
> >
> >       Hashtable<String, String> env = new Hashtable<String, String>();
> >       env.put("java.naming.factory.initial",
> > "com.sun.jndi.dns.DnsContextFactory ");
> >       env.put("java.naming.provider.url",  "dns://" + dnsIP + "/");
> >
> >       // obter contexto inicial
> >       DirContext ictx = null;
> >       NamingEnumeration hostEnumeration = null;
> >       try {
> >           out.println("getting conn: ");
> >           ictx = new InitialDirContext(env);
> >           out.println("getting conn, getting list ");
> >           hostEnumeration = ictx.list (domain);
> >           out.println("got list ");
> >       } catch (Exception ex) {
> >           ex.printStackTrace();
> >           throw new Exception(ex);
> >       }
> >       ExecutorService exec = Executors.newCachedThreadPool (
> >               new ONExceptionThreadFactory(new ONExceptionHandler()));
> >       // skip those already found
> >       Queue <String> domainsVisitedQueue = new
> ConcurrentLinkedQueue<String>();
> >       domainsVisitedQueue.add (domain);
> >       Queue <String> resultQueue = new
> ConcurrentLinkedQueue<String>();
> >       parallelRecursiveDNS(exec, ictx, hostEnumeration,
> > domainsVisitedQueue, resultQueue);
> >       exec.awaitTermination (100L, TimeUnit.SECONDS);
> >
> >       return new ArrayList<String>(resultQueue);
> >   }
> >
> >   private static void parallelRecursiveDNS(final Executor exec, final
> > DirContext ictx,
> >           final NamingEnumeration hostEnumeration, final
> > Collection<String> domainsVisitedQueue,
> >           final Collection<String> results)
> >       throws Exception {
> >
> >       while (hostEnumeration.hasMore()) {
> >
> >           exec.execute(new Runnable() {
> >               public void run() {
> >                   try {
> >                       String host = null;
> >                       host = ((NameClassPair) hostEnumeration.next())
> >                               .getNameInNamespace();
> >                       results.add(host);
> >                       out.println("Found host: " + host);
> >                       // all 'A records'
> >                       Attributes a =
> ictx.getAttributes(host,
> >                               new String[] { "A" });
> >                       if (a.get("A") != null) {
> >                           String ip =
> a.get("A").get().toString();
> >                            results.add(ip);
> >                           out.println("Found ip: " + ip);
> >                       }
> >                       // enter task suitable for recursion?
> >                       Attributes aDNS =
> ictx.getAttributes(host,
> >                                   new String[] { "NS" });
> >                       NamingEnumeration allDNS =
> aDNS.getAll();
> >                       while (allDNS.hasMore()) {
> >                            out.println("Entering allDNS: ");
> >                           Attribute attr = (Attribute)
> allDNS.next();
> >                           NamingEnumeration values =
> attr.getAll();
> >                           String dns =
> values.next().toString();
> >                           if (domainsVisitedQueue.contains(dns)) {
> >                               continue;
> >                           }
> >                           NamingEnumeration newHost =
> ictx.list(dns);
> >                           out.println("doing recursion: ");
> >                           parallelRecursiveDNS(exec,
> ictx, newHost,
> > domainsVisitedQueue, results);
> >                       }
> >                   } catch (Exception ex) { ex.printStackTrace(); }
> >
> >               }
> >
> >           });
> >       }
> >   }
> > }
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> >
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>

From joe.bowbeer at gmail.com  Wed Dec 13 11:23:33 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 13 Dec 2006 08:23:33 -0800
Subject: [concurrency-interest] Best CPUs for testing
In-Reply-To: <457FEA02.4020006@chemaxon.hu>
References: <457FEA02.4020006@chemaxon.hu>
Message-ID: <31f2a7bd0612130823w20dbebacu4444bdc6a83c399a@mail.gmail.com>

At the machine level, the DEC Alpha used to be the platform that would
expose the most bugs because it imposed the least order -- and was even
purported to flaunt this at every opportunity in order to shake out bugs.
(The principle of "least astonishment" turned on its head to benefit
testing.)

You can see in the cookbook that the Alpha has little respect for data
dependencies and consequentially needs a lot of memory barriers:

http://gee.cs.oswego.edu/dl/jmm/cookbook.html

On the other hand, since Alpha's Java VM implementation is so tightly
fenced, perhaps the Java apps running on it are *less* likely to do anything
astonishing? :-)


On 12/13/06, P?ter Kov?cs <peter.kovacs at chemaxon.hu> wrote:
>
>
> A passage in "The Java Memory Model" section in "Concurrent Programming
> in Java" prompted me to ask the question: can the CPUs currently
> available on the market be ranked by their suitability for detecting
> concurrent programming problems.  [...]
>
> Any comment appreciated.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/55c41666/attachment.html 

From joe.bowbeer at gmail.com  Wed Dec 13 11:37:24 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 13 Dec 2006 08:37:24 -0800
Subject: [concurrency-interest] Best CPUs for testing
In-Reply-To: <31f2a7bd0612130823w20dbebacu4444bdc6a83c399a@mail.gmail.com>
References: <457FEA02.4020006@chemaxon.hu>
	<31f2a7bd0612130823w20dbebacu4444bdc6a83c399a@mail.gmail.com>
Message-ID: <31f2a7bd0612130837h55bf4620o1229d0998d7e185@mail.gmail.com>

Minor correction.

I wrote:

"... and consequentially needs a lot of memory barriers"

Should be consequently.

As long as I'm correcting a nit:

"... since Alpha's Java VM implementation is so tightly fenced, perhaps the
Java apps running [within] it are ..."


On 12/13/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>
> At the machine level, the DEC Alpha used to be the platform that would
> expose the most bugs because it imposed the least order -- and was even
> purported to flaunt this at every opportunity in order to shake out bugs.
> (The principle of "least astonishment" turned on its head to benefit
> testing.)
>
> You can see in the cookbook that the Alpha has little respect for data
> dependencies and consequentially needs a lot of memory barriers:
>
> http://gee.cs.oswego.edu/dl/jmm/cookbook.html
>
> On the other hand, since Alpha's Java VM implementation is so tightly
> fenced, perhaps the Java apps running on it are *less* likely to do anything
> astonishing? :-)
>
>
> On 12/13/06, P?ter Kov?cs <peter.kovacs at chemaxon.hu> wrote:
> >
> >
> > A passage in "The Java Memory Model" section in "Concurrent Programming
> > in Java" prompted me to ask the question: can the CPUs currently
> > available on the market be ranked by their suitability for detecting
> > concurrent programming problems.  [...]
> >
> > Any comment appreciated.
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/58adab5e/attachment.html 

From robertlazarski at gmail.com  Wed Dec 13 15:20:57 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Wed, 13 Dec 2006 15:20:57 -0500
Subject: [concurrency-interest] Callable inside a Runnable and
	RejectedExecutionException
Message-ID: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>

Hi all, getting closer on my DNS problem. One of the things I'm
noticing is that on some Context.list() calls are taking too much time
to timeout. Unfortunately putting in a new dep such as dnsjava in this
project is a hard sell. Anyways What I'd like to do is limit the time
this  list() call can take via a Future. Is it illegal to have a
Callable inside Runnable? The code below throws on
exec.submit(listTask). Thanks for any help.

  private static void parallelRecursiveDNS(final ExecutorService exec,
final DirContext ictx,
          final NamingEnumeration hostEnumeration, final
Collection<String> domainsVisitedQueue,
          final Collection<String> results)
      throws Exception {

      taskCount.incrementAndGet();

      while (hostEnumeration.hasMore()) {

          exec.execute(new Runnable() {
              public void run() {
                  long runStart = System.currentTimeMillis();
                  try {
                      String host = null;
                      host = ((NameClassPair) hostEnumeration.next())
                              .getNameInNamespace();
                      if (results.contains(host)) {
                          return;
                      }
                      results.add(host);
                      out.println("Found host: " + host);
                      Attributes aDNS = ictx.getAttributes(host,
                                  new String[] { "NS" });
                      NamingEnumeration allDNS = aDNS.getAll();
                      while (allDNS.hasMore()) {
                          out.println("Entering allDNS: ");
                          Attribute attr = (Attribute) allDNS.next();
                          NamingEnumeration values = attr.getAll();
                          final String dns = values.next().toString();
                          if (domainsVisitedQueue.contains(dns)) {
                              continue;
                          }
                          domainsVisitedQueue.add(dns);

                          NamingEnumeration newEnumeration;
                          boolean gotList = false;
                          try {
                              Callable <NamingEnumeration> listTask =
                                  new Callable<NamingEnumeration>() {
                                      public NamingEnumeration call() {
                                          try {
                                              return ictx.list(dns);
                                          } catch (Exception ex) {
                                              ex.printStackTrace();
                                          }
                                          return null;
                                      }
                                  };
                              Future <NamingEnumeration> future =
exec.submit(listTask);
                              newEnumeration = future.get(10L,
TimeUnit.SECONDS);
                              if (hostEnumeration != null) {
                                  gotList = true;
                              }
                          } catch (Exception ex) {
                              ex.printStackTrace();
                              throw new Exception(ex);
                          }
                          if (!gotList) {
                              continue;
                          }
                          parallelRecursiveDNS(exec, ictx,
newEnumeration, domainsVisitedQueue, results);
                      }
                  } catch (Exception ex) {
                      ex.printStackTrace();
                  } finally {
                      long runEnd = System.currentTimeMillis();
                      out.println("runnable execution time was "
                        + (runEnd - runStart) / 1000 + " seconds ");
                      if (taskCount.decrementAndGet() == 0) {
                      }
                  }

              }
          });
      }
  }

From tim at peierls.net  Wed Dec 13 15:45:51 2006
From: tim at peierls.net (Tim Peierls)
Date: Wed, 13 Dec 2006 15:45:51 -0500
Subject: [concurrency-interest] Callable inside a Runnable and
	RejectedExecutionException
In-Reply-To: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>
References: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>
Message-ID: <63b4e4050612131245g263231d2qbb6065530b161c84@mail.gmail.com>

What does it throw?

I haven't looked carefully at this code, but consider getting rid of "catch
(Exception e) {...}" clauses in favor of more specific exception handling.

--tim

On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> Hi all, getting closer on my DNS problem. One of the things I'm
> noticing is that on some Context.list() calls are taking too much time
> to timeout. Unfortunately putting in a new dep such as dnsjava in this
> project is a hard sell. Anyways What I'd like to do is limit the time
> this  list() call can take via a Future. Is it illegal to have a
> Callable inside Runnable? The code below throws on
> exec.submit(listTask). Thanks for any help.
>
>   private static void parallelRecursiveDNS(final ExecutorService exec,
> final DirContext ictx,
>           final NamingEnumeration hostEnumeration, final
> Collection<String> domainsVisitedQueue,
>           final Collection<String> results)
>       throws Exception {
>
>       taskCount.incrementAndGet();
>
>       while (hostEnumeration.hasMore()) {
>
>           exec.execute(new Runnable() {
>               public void run() {
>                   long runStart = System.currentTimeMillis();
>                   try {
>                       String host = null;
>                       host = ((NameClassPair) hostEnumeration.next())
>                               .getNameInNamespace();
>                       if (results.contains(host)) {
>                           return;
>                       }
>                       results.add(host);
>                       out.println("Found host: " + host);
>                       Attributes aDNS = ictx.getAttributes(host,
>                                   new String[] { "NS" });
>                       NamingEnumeration allDNS = aDNS.getAll();
>                       while (allDNS.hasMore()) {
>                           out.println("Entering allDNS: ");
>                           Attribute attr = (Attribute) allDNS.next();
>                           NamingEnumeration values = attr.getAll();
>                           final String dns = values.next().toString();
>                           if (domainsVisitedQueue.contains(dns)) {
>                               continue;
>                           }
>                           domainsVisitedQueue.add(dns);
>
>                           NamingEnumeration newEnumeration;
>                           boolean gotList = false;
>                           try {
>                               Callable <NamingEnumeration> listTask =
>                                   new Callable<NamingEnumeration>() {
>                                       public NamingEnumeration call() {
>                                           try {
>                                               return ictx.list(dns);
>                                           } catch (Exception ex) {
>                                               ex.printStackTrace();
>                                           }
>                                           return null;
>                                       }
>                                   };
>                               Future <NamingEnumeration> future =
> exec.submit(listTask);
>                               newEnumeration = future.get(10L,
> TimeUnit.SECONDS);
>                               if (hostEnumeration != null) {
>                                   gotList = true;
>                               }
>                           } catch (Exception ex) {
>                               ex.printStackTrace();
>                               throw new Exception(ex);
>                           }
>                           if (!gotList) {
>                               continue;
>                           }
>                           parallelRecursiveDNS(exec, ictx,
> newEnumeration, domainsVisitedQueue, results);
>                       }
>                   } catch (Exception ex) {
>                       ex.printStackTrace();
>                   } finally {
>                       long runEnd = System.currentTimeMillis();
>                       out.println("runnable execution time was "
>                         + (runEnd - runStart) / 1000 + " seconds ");
>                       if (taskCount.decrementAndGet() == 0) {
>                       }
>                   }
>
>               }
>           });
>       }
>   }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/365c1375/attachment.html 

From robertlazarski at gmail.com  Wed Dec 13 15:55:33 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Wed, 13 Dec 2006 15:55:33 -0500
Subject: [concurrency-interest] Callable inside a Runnable and
	RejectedExecutionException
In-Reply-To: <63b4e4050612131245g263231d2qbb6065530b161c84@mail.gmail.com>
References: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>
	<63b4e4050612131245g263231d2qbb6065530b161c84@mail.gmail.com>
Message-ID: <f87675ee0612131255n64828d2fg1c7d7d996cc8c276@mail.gmail.com>

This is just proof of concept code, but I'll take the suggestion.
Here's the stack trace:

[java] Caused by: java.util.concurrent.RejectedExecutionException
     [java]     at
java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:1477)
     [java]     at
java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:384)
     [java]     at
java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:856)
     [java]     at
java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:45)
     [java]     at org.DNS$2.run(DNS.java:147)

Where DNS.java:147 is exec.submit(listTask) . I thought it might be
something about having Callable in a Runnable, but maybe not?

Robert


On 12/13/06, Tim Peierls <tim at peierls.net> wrote:
> What does it throw?
>
> I haven't looked carefully at this code, but consider getting rid of "catch
> (Exception e) {...}" clauses in favor of more specific exception handling.
>
> --tim
>
>
>  On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
> >
> > Hi all, getting closer on my DNS problem. One of the things I'm
> > noticing is that on some Context.list() calls are taking too much time
> > to timeout. Unfortunately putting in a new dep such as dnsjava in this
> > project is a hard sell. Anyways What I'd like to do is limit the time
> > this  list() call can take via a Future. Is it illegal to have a
> > Callable inside Runnable? The code below throws on
> > exec.submit(listTask). Thanks for any help.
> >
> >   private static void parallelRecursiveDNS(final ExecutorService exec,
> > final DirContext ictx,
> >           final NamingEnumeration hostEnumeration, final
> > Collection<String> domainsVisitedQueue,
> >           final Collection<String> results)
> >       throws Exception {
> >
> >       taskCount.incrementAndGet();
> >
> >       while (hostEnumeration.hasMore()) {
> >
> >           exec.execute(new Runnable() {
> >               public void run() {
> >                   long runStart = System.currentTimeMillis ();
> >                   try {
> >                       String host = null;
> >                       host = ((NameClassPair) hostEnumeration.next())
> >                               .getNameInNamespace();
> >                       if ( results.contains(host)) {
> >                           return;
> >                       }
> >                       results.add(host);
> >                       out.println("Found host: " + host);
> >                       Attributes aDNS =
> ictx.getAttributes(host,
> >                                   new String[] { "NS" });
> >                       NamingEnumeration allDNS =
> aDNS.getAll();
> >                       while (allDNS.hasMore()) {
> >                            out.println("Entering allDNS: ");
> >                           Attribute attr = (Attribute)
> allDNS.next();
> >                           NamingEnumeration values =
> attr.getAll();
> >                           final String dns = values.next().toString();
> >                           if (domainsVisitedQueue.contains(dns)) {
> >                               continue;
> >                           }
> >                           domainsVisitedQueue.add (dns);
> >
> >                           NamingEnumeration
> newEnumeration;
> >                           boolean gotList = false;
> >                           try {
> >                               Callable
> <NamingEnumeration> listTask =
> >                                   new
> Callable<NamingEnumeration>() {
> >                                       public
> NamingEnumeration call() {
> >                                           try {
> >                                               return
> ictx.list(dns);
> >                                           } catch
> (Exception ex) {
> >
> ex.printStackTrace();
> >                                           }
> >                                           return null;
> >                                       }
> >                                   };
> >                               Future <NamingEnumeration>
> future =
> > exec.submit(listTask);
> >                               newEnumeration =
> future.get(10L,
> > TimeUnit.SECONDS);
> >                               if (hostEnumeration !=
> null) {
> >                                   gotList = true;
> >                               }
> >                           } catch (Exception ex) {
> >                               ex.printStackTrace();
> >                               throw new Exception(ex);
> >                           }
> >                           if (!gotList) {
> >                               continue;
> >                           }
> >                           parallelRecursiveDNS(exec,
> ictx,
> > newEnumeration, domainsVisitedQueue, results);
> >                       }
> >                   } catch (Exception ex) {
> >                        ex.printStackTrace();
> >                   } finally {
> >                       long runEnd = System.currentTimeMillis();
> >                       out.println("runnable execution time was "
> >                         + (runEnd - runStart) / 1000 + " seconds ");
> >                       if (taskCount.decrementAndGet() == 0) {
> >                       }
> >                   }
> >
> >               }
> >           });
> >       }
> >   }
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> >
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>

From dcholmes at optusnet.com.au  Wed Dec 13 16:45:00 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 14 Dec 2006 07:45:00 +1000
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <f87675ee0612130623p2c71f471g158ff13c8cb4d01@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEIPHEAA.dcholmes@optusnet.com.au>

Robert,

You are shutting down the pool while it is still in use. The Runnables you
submit in the first parallelRecursiveDNS still submit further Runnables in
their own recursion.

This is likely why you get the RejectedExecutionExceptions - you are
submitting to a shutdown pool.

You should shutdown the pool after you have completed the task.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of robert
> lazarski
> Sent: Thursday, 14 December 2006 12:24 AM
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Migrating DNS problem to j.u.c
>
>
> OK, I put exec.shutdown() right before exec.awaitTermination().
>
> However, I'm unclear on why the program wouldn't know if the recursion
> is finished - lets assume no timeout. It roughly follows the jcip
> listing 8.11 and 8.12, which doesn't have a latch or atomic counter.
> Do I need a latch and atomic counter like the puzzle program for my
> program to work right, as shown? I ask because each Runnable in my
> case has the potential to add to the Collection, unlike the puzzler
> which is looking for one result.
>
> My main concern beyond the correct results is time: The program as
> shown takes 7 minutes to run, though the original broken program was
> even slower.
>
> Thanks,
> Robert
>
> On 12/12/06, Tim Peierls <tim at peierls.net> wrote:
> > You need to shutdown the ExecutorService before
> awaitTermination can ever
> > succeed. See Listings 7.16 and 7.22 in JCiP for examples of
> awaitTermination
> > with shutdown and shutdownNow.
> >
> > In your case, you don't know when the recursion is finished, so
> you don't
> > know when to shut down the pool. See the discussion on p.187 of
> JCiP about
> > stopping ConcurrentPuzzleSolver for different ways to deal with this.
> >
> > --tim
> >
> >
> > On 12/12/06, robert lazarski < robertlazarski at gmail.com> wrote:
> > >
> > > On 12/12/06, Tim Peierls < tim at peierls.net> wrote:
> > > > The minimal approach
> > >
> > > Thanks for the reply Tim. I've decided to start from scratch as the
> > > original code is broke in several ways. The whole recursion part may
> > > be a misunderstanding of the original coder. Anyways, while I'm trying
> > > to figure it out I implemented it using j.u.c and I'm posting it here
> > > in case someone could review it.
> > >
> > > There is one question I have: awaitTermination doesn't do what I
> > > expect - end after 100 seconds, ie, I get the List returned but the
> > > main() keeps going. Perhaps something to do with daemon threads. Any
> > > insight appreciated.
> > >
> > > package org;
> > >
> > > import static java.lang.System.out;
> > >
> > > import java.util.ArrayList;
> > > import java.util.Collection ;
> > > import java.util.Hashtable;
> > > import java.util.List;
> > > import java.util.Queue;
> > > import java.util.concurrent.ConcurrentLinkedQueue;
> > > import java.util.concurrent.Executor;
> > > import java.util.concurrent.ExecutorService ;
> > > import java.util.concurrent.Executors;
> > > import java.util.concurrent.TimeUnit;
> > >
> > > import javax.naming.NameClassPair;
> > > import javax.naming.NamingEnumeration;
> > > import javax.naming.directory.Attributes;
> > > import javax.naming.directory.DirContext;
> > > import javax.naming.directory.InitialDirContext;
> > > import javax.naming.directory.Attribute;
> > > import javax.naming.directory.Attributes;
> > >
> > > public class DNS
> > > {
> > >
> > >   public static void main(String[] args) throws Exception {
> > >       helloDNS();
> > >   }
> > >
> > >
> > /*******************************************************************
> > >   Use this method to test dns
> > >
> > *******************************************************************/
> > >   private static void helloDNS() throws Exception {
> > >        calculateDNS("bee.uspnet.usp.br", "usp.br");
> > >   }
> > >
> > >   private static List<String> calculateDNS(String dnsIP,
> String domain)
> > >           throws Exception {
> > >
> > >       Hashtable<String, String> env = new Hashtable<String, String>();
> > >       env.put("java.naming.factory.initial",
> > > "com.sun.jndi.dns.DnsContextFactory ");
> > >       env.put("java.naming.provider.url",  "dns://" + dnsIP + "/");
> > >
> > >       // obter contexto inicial
> > >       DirContext ictx = null;
> > >       NamingEnumeration hostEnumeration = null;
> > >       try {
> > >           out.println("getting conn: ");
> > >           ictx = new InitialDirContext(env);
> > >           out.println("getting conn, getting list ");
> > >           hostEnumeration = ictx.list (domain);
> > >           out.println("got list ");
> > >       } catch (Exception ex) {
> > >           ex.printStackTrace();
> > >           throw new Exception(ex);
> > >       }
> > >       ExecutorService exec = Executors.newCachedThreadPool (
> > >               new ONExceptionThreadFactory(new ONExceptionHandler()));
> > >       // skip those already found
> > >       Queue <String> domainsVisitedQueue = new
> > ConcurrentLinkedQueue<String>();
> > >       domainsVisitedQueue.add (domain);
> > >       Queue <String> resultQueue = new
> > ConcurrentLinkedQueue<String>();
> > >       parallelRecursiveDNS(exec, ictx, hostEnumeration,
> > > domainsVisitedQueue, resultQueue);
> > >       exec.awaitTermination (100L, TimeUnit.SECONDS);
> > >
> > >       return new ArrayList<String>(resultQueue);
> > >   }
> > >
> > >   private static void parallelRecursiveDNS(final Executor exec, final
> > > DirContext ictx,
> > >           final NamingEnumeration hostEnumeration, final
> > > Collection<String> domainsVisitedQueue,
> > >           final Collection<String> results)
> > >       throws Exception {
> > >
> > >       while (hostEnumeration.hasMore()) {
> > >
> > >           exec.execute(new Runnable() {
> > >               public void run() {
> > >                   try {
> > >                       String host = null;
> > >                       host = ((NameClassPair) hostEnumeration.next())
> > >                               .getNameInNamespace();
> > >                       results.add(host);
> > >                       out.println("Found host: " + host);
> > >                       // all 'A records'
> > >                       Attributes a =
> > ictx.getAttributes(host,
> > >                               new String[] { "A" });
> > >                       if (a.get("A") != null) {
> > >                           String ip =
> > a.get("A").get().toString();
> > >                            results.add(ip);
> > >                           out.println("Found ip: " + ip);
> > >                       }
> > >                       // enter task suitable for recursion?
> > >                       Attributes aDNS =
> > ictx.getAttributes(host,
> > >                                   new String[] { "NS" });
> > >                       NamingEnumeration allDNS =
> > aDNS.getAll();
> > >                       while (allDNS.hasMore()) {
> > >                            out.println("Entering allDNS: ");
> > >                           Attribute attr = (Attribute)
> > allDNS.next();
> > >                           NamingEnumeration values =
> > attr.getAll();
> > >                           String dns =
> > values.next().toString();
> > >                           if (domainsVisitedQueue.contains(dns)) {
> > >                               continue;
> > >                           }
> > >                           NamingEnumeration newHost =
> > ictx.list(dns);
> > >                           out.println("doing recursion: ");
> > >                           parallelRecursiveDNS(exec,
> > ictx, newHost,
> > > domainsVisitedQueue, results);
> > >                       }
> > >                   } catch (Exception ex) { ex.printStackTrace(); }
> > >
> > >               }
> > >
> > >           });
> > >       }
> > >   }
> > > }
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > >
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From tim at peierls.net  Wed Dec 13 17:28:22 2006
From: tim at peierls.net (Tim Peierls)
Date: Wed, 13 Dec 2006 17:28:22 -0500
Subject: [concurrency-interest] Callable inside a Runnable and
	RejectedExecutionException
In-Reply-To: <f87675ee0612131255n64828d2fg1c7d7d996cc8c276@mail.gmail.com>
References: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>
	<63b4e4050612131245g263231d2qbb6065530b161c84@mail.gmail.com>
	<f87675ee0612131255n64828d2fg1c7d7d996cc8c276@mail.gmail.com>
Message-ID: <63b4e4050612131428q8126213x67dd3e9bb0ea3e47@mail.gmail.com>

By "having a Callable in a Runnable" you mean "submitting a Callable task to
an ExecutorService within a Runnable task being executed by that same
service", right? There's nothing wrong with that in principle.

You might have inter-task dependencies that are exacerbated by the timed
get. Could it be that your ExecutorService is filling up very quickly with
tasks waiting for other tasks that can't run? If you use a separate
ExecutorService for the listTasks, does that improve matters?

Sorry that I don't have time to look into this more carefully...

--tim


On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> This is just proof of concept code, but I'll take the suggestion.
> Here's the stack trace:
>
> [java] Caused by: java.util.concurrent.RejectedExecutionException
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(
> ThreadPoolExecutor.java:1477)
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java
> :384)
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java
> :856)
>      [java]     at
> java.util.concurrent.AbstractExecutorService.submit(
> AbstractExecutorService.java:45)
>      [java]     at org.DNS$2.run(DNS.java:147)
>
> Where DNS.java:147 is exec.submit(listTask) . I thought it might be
> something about having Callable in a Runnable, but maybe not?
>
> Robert
>
>
> On 12/13/06, Tim Peierls <tim at peierls.net> wrote:
> > What does it throw?
> >
> > I haven't looked carefully at this code, but consider getting rid of
> "catch
> > (Exception e) {...}" clauses in favor of more specific exception
> handling.
> >
> > --tim
> >
> >
> >  On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
> > >
> > > Hi all, getting closer on my DNS problem. One of the things I'm
> > > noticing is that on some Context.list() calls are taking too much time
> > > to timeout. Unfortunately putting in a new dep such as dnsjava in this
> > > project is a hard sell. Anyways What I'd like to do is limit the time
> > > this  list() call can take via a Future. Is it illegal to have a
> > > Callable inside Runnable? The code below throws on
> > > exec.submit(listTask). Thanks for any help.
> > >
> > >   private static void parallelRecursiveDNS(final ExecutorService exec,
> > > final DirContext ictx,
> > >           final NamingEnumeration hostEnumeration, final
> > > Collection<String> domainsVisitedQueue,
> > >           final Collection<String> results)
> > >       throws Exception {
> > >
> > >       taskCount.incrementAndGet();
> > >
> > >       while (hostEnumeration.hasMore()) {
> > >
> > >           exec.execute(new Runnable() {
> > >               public void run() {
> > >                   long runStart = System.currentTimeMillis ();
> > >                   try {
> > >                       String host = null;
> > >                       host = ((NameClassPair) hostEnumeration.next())
> > >                               .getNameInNamespace();
> > >                       if ( results.contains(host)) {
> > >                           return;
> > >                       }
> > >                       results.add(host);
> > >                       out.println("Found host: " + host);
> > >                       Attributes aDNS =
> > ictx.getAttributes(host,
> > >                                   new String[] { "NS" });
> > >                       NamingEnumeration allDNS =
> > aDNS.getAll();
> > >                       while (allDNS.hasMore()) {
> > >                            out.println("Entering allDNS: ");
> > >                           Attribute attr = (Attribute)
> > allDNS.next();
> > >                           NamingEnumeration values =
> > attr.getAll();
> > >                           final String dns = values.next().toString();
> > >                           if (domainsVisitedQueue.contains(dns)) {
> > >                               continue;
> > >                           }
> > >                           domainsVisitedQueue.add (dns);
> > >
> > >                           NamingEnumeration
> > newEnumeration;
> > >                           boolean gotList = false;
> > >                           try {
> > >                               Callable
> > <NamingEnumeration> listTask =
> > >                                   new
> > Callable<NamingEnumeration>() {
> > >                                       public
> > NamingEnumeration call() {
> > >                                           try {
> > >                                               return
> > ictx.list(dns);
> > >                                           } catch
> > (Exception ex) {
> > >
> > ex.printStackTrace();
> > >                                           }
> > >                                           return null;
> > >                                       }
> > >                                   };
> > >                               Future <NamingEnumeration>
> > future =
> > > exec.submit(listTask);
> > >                               newEnumeration =
> > future.get(10L,
> > > TimeUnit.SECONDS);
> > >                               if (hostEnumeration !=
> > null) {
> > >                                   gotList = true;
> > >                               }
> > >                           } catch (Exception ex) {
> > >                               ex.printStackTrace();
> > >                               throw new Exception(ex);
> > >                           }
> > >                           if (!gotList) {
> > >                               continue;
> > >                           }
> > >                           parallelRecursiveDNS(exec,
> > ictx,
> > > newEnumeration, domainsVisitedQueue, results);
> > >                       }
> > >                   } catch (Exception ex) {
> > >                        ex.printStackTrace();
> > >                   } finally {
> > >                       long runEnd = System.currentTimeMillis();
> > >                       out.println("runnable execution time was "
> > >                         + (runEnd - runStart) / 1000 + " seconds ");
> > >                       if (taskCount.decrementAndGet() == 0) {
> > >                       }
> > >                   }
> > >
> > >               }
> > >           });
> > >       }
> > >   }
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > >
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/5e359d6d/attachment-0001.html 

From joe.bowbeer at gmail.com  Wed Dec 13 20:19:10 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 13 Dec 2006 17:19:10 -0800
Subject: [concurrency-interest] Callable inside a Runnable and
	RejectedExecutionException
In-Reply-To: <f87675ee0612131255n64828d2fg1c7d7d996cc8c276@mail.gmail.com>
References: <f87675ee0612131220i5b83e0d6n9bdc139e2f297962@mail.gmail.com>
	<63b4e4050612131245g263231d2qbb6065530b161c84@mail.gmail.com>
	<f87675ee0612131255n64828d2fg1c7d7d996cc8c276@mail.gmail.com>
Message-ID: <31f2a7bd0612131719j16391bacs9dadcbee3e6cccdd@mail.gmail.com>

The trace indicates that the task was rejected.  This might happen if the
pool thread limit has been reached and the backing queue is full, or (I
think) if the executor has been shutdown.

Has nothing to do with the task itself.

On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> This is just proof of concept code, but I'll take the suggestion.
> Here's the stack trace:
>
> [java] Caused by: java.util.concurrent.RejectedExecutionException
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(
> ThreadPoolExecutor.java:1477)
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java
> :384)
>      [java]     at
> java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java
> :856)
>      [java]     at
> java.util.concurrent.AbstractExecutorService.submit(
> AbstractExecutorService.java:45)
>      [java]     at org.DNS$2.run(DNS.java:147)
>
> Where DNS.java:147 is exec.submit(listTask) . I thought it might be
> something about having Callable in a Runnable, but maybe not?
>
> Robert
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061213/aefc7315/attachment.html 

From dcholmes at optusnet.com.au  Wed Dec 13 20:37:10 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 14 Dec 2006 11:37:10 +1000
Subject: [concurrency-interest] Callable inside a Runnable
	andRejectedExecutionException
In-Reply-To: <31f2a7bd0612131719j16391bacs9dadcbee3e6cccdd@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEJDHEAA.dcholmes@optusnet.com.au>

Right. Based on Robert's other thread it appears he is shutting down the
pool while it is still in use.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe Bowbeer
  Sent: Thursday, 14 December 2006 11:19 AM
  To: Concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Callable inside a Runnable
andRejectedExecutionException


  The trace indicates that the task was rejected.  This might happen if the
pool thread limit has been reached and the backing queue is full, or (I
think) if the executor has been shutdown.

  Has nothing to do with the task itself.


  On 12/13/06, robert lazarski <robertlazarski at gmail.com> wrote:
    This is just proof of concept code, but I'll take the suggestion.
    Here's the stack trace:

    [java] Caused by: java.util.concurrent.RejectedExecutionException
         [java]     at
    java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution
(ThreadPoolExecutor.java:1477)
         [java]     at

java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:384)
         [java]     at
    java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java
:856)
         [java]     at

java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.
java:45)
         [java]     at org.DNS$2.run(DNS.java:147)

    Where DNS.java:147 is exec.submit(listTask) . I thought it might be
    something about having Callable in a Runnable, but maybe not?

    Robert


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061214/3d6f5817/attachment.html 

From spark at xdev.net  Thu Dec 14 05:32:37 2006
From: spark at xdev.net (Dave Cunningham)
Date: Thu, 14 Dec 2006 10:32:37 +0000
Subject: [concurrency-interest] Best CPUs for testing
In-Reply-To: <457FEA02.4020006@chemaxon.hu>
References: <457FEA02.4020006@chemaxon.hu>
Message-ID: <20061214103237.GA10973@meep>

Perhaps some dynamic checks could be performed in a package like
valgrind?  Has anyone done this before?


From robertlazarski at gmail.com  Thu Dec 14 10:08:12 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Thu, 14 Dec 2006 10:08:12 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEIPHEAA.dcholmes@optusnet.com.au>
References: <f87675ee0612130623p2c71f471g158ff13c8cb4d01@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEIPHEAA.dcholmes@optusnet.com.au>
Message-ID: <f87675ee0612140708j1a2367dqcf7a20b3380f39a3@mail.gmail.com>

Indeed, I was submitting tasks to a shutdown pool, thanks. I now have
a latch, which seems to now know when to shutdown the pool.

My current problem is that the future times out correctly, but
DirContext.list() isn't being cancelled of course, as it throws
"java.net.ConnectException: Connection timed out" long after
Future.cancel() . Page 148 of jcip states that closing the underlying
socket could help, but in this case I'm not sure how I could do that.
The program calls shutdown after about 90 seconds, but hangs for 5 and
a half more minutes. Any ideas?

Here's my latest code - not pretty but I'm learning alot ;-) .
Robert

package org;

import java.util.concurrent.*;

public class RecursionLatch {
    private final CountDownLatch done = new CountDownLatch(1);

    public boolean isSet() {
        return (done.getCount() == 0);
    }

    public synchronized void setCompleted() {
        if (!isSet()) {
            done.countDown();
        }
    }

    public void taskCompleted() throws InterruptedException {
        done.await();
    }
}

package org;

import static java.lang.System.out;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Hashtable;
import java.util.List;
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.Executor;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.atomic.AtomicInteger;

import javax.naming.NameClassPair;
import javax.naming.NamingEnumeration;
import javax.naming.directory.Attributes;
import javax.naming.directory.DirContext;
import javax.naming.directory.InitialDirContext;
import javax.naming.directory.Attribute;
import javax.naming.directory.Attributes;
import javax.naming.NamingException;

public class DNS
{
  private static final AtomicInteger taskCount = new AtomicInteger(0);
  private static final RecursionLatch solution = new RecursionLatch();

  public static void main(String[] args) throws Exception {
      helloDNS();
  }

  /*******************************************************************
  Use this method to test dns
  *******************************************************************/
  private static void helloDNS() throws Exception {
       // calculateDNS("mailsrv2.atlantico.com.br", "atlantico.com.br");
       calculateDNS("bee.uspnet.usp.br", "usp.br");
  }

  private static List<String> calculateDNS(final String ipDNS, final
String domain)
          throws Exception {

      final Hashtable<String, String> env = new Hashtable<String, String>();
      env.put("java.naming.factory.initial",
"com.sun.jndi.dns.DnsContextFactory");
      env.put("java.naming.provider.url", "dns://" + ipDNS + "/");

      final DirContext ictx;
      ictx = new InitialDirContext(env);
      ExecutorService exec = Executors.newCachedThreadPool(
              new ONExceptionThreadFactory(new ONExceptionHandler()));

      NamingEnumeration hostEnumeration = null;
      boolean gotList = false;
      Callable <NamingEnumeration> listTask =
          new Callable<NamingEnumeration>() {
              public NamingEnumeration call() {
                  try {
                      return ictx.list(domain);
                  } catch (Exception ex) {
                      ex.printStackTrace();
                  }
                  return null;
              }
          };
      Future <NamingEnumeration> future = exec.submit(listTask);
      try {
          hostEnumeration = future.get(10L, TimeUnit.SECONDS);
          if (hostEnumeration != null) {
              gotList = true;
          }
      } catch (Exception ex) {
          ex.printStackTrace();
      } finally {
          future.cancel(true);
      }

      try {
          if (!gotList) {
              throw new Exception("Can't connect to DNS server");
          }
          // skip those already found
          Queue <String> domainsVisitedQueue = new
ConcurrentLinkedQueue<String>();
          domainsVisitedQueue.add(domain);

          Queue <String> resultQueue = new ConcurrentLinkedQueue<String>();
          parallelRecursiveDNS(exec, ictx, hostEnumeration,
domainsVisitedQueue, resultQueue );
          // wait for latch
          solution.taskCompleted();
          out.println("latch returned, waiting for shutdown");

          for (String s : resultQueue) {
              out.println("WTF: " + s);
          }
          return new ArrayList<String>(resultQueue);
      } catch (Exception ex) {
          ex.printStackTrace();
          throw new Exception (ex);
      } finally {
          exec.shutdown();
          out.println("awaiting termination");
          exec.awaitTermination(100L, TimeUnit.SECONDS);
          out.println("termination complete");
          if (ictx != null) {
            try {
                ictx.close();
            } catch (NamingException ex) {
                ex.printStackTrace();
            }
        }
      }

  }	

  private static void parallelRecursiveDNS(final ExecutorService exec,
final DirContext ictx,
          final NamingEnumeration hostEnumeration, final
Collection<String> domainsVisitedQueue,
          final Collection<String> results)
      throws Exception {


      while (hostEnumeration.hasMore()) {

          taskCount.incrementAndGet();
          exec.execute(new Runnable() {
              public void run() {
                  long runStart = System.currentTimeMillis();
                  try {
                      String host = null;
                      host = ((NameClassPair) hostEnumeration.next())
                              .getNameInNamespace();
                      if (results.contains(host)) {
                          return;
                      }
                      results.add(host);
                      out.println("Found host: " + host);
                      Attributes aDNS = ictx.getAttributes(host,
                                  new String[] { "NS" });
                      NamingEnumeration allDNS = aDNS.getAll();
                      while (allDNS.hasMore()) {
                          out.println("Entering allDNS: ");
                          Attribute attr = (Attribute) allDNS.next();
                          NamingEnumeration values = attr.getAll();
                          final String dns = values.next().toString();
                          if (domainsVisitedQueue.contains(dns)) {
                              continue;
                          }
                          domainsVisitedQueue.add(dns);

                          NamingEnumeration newEnumeration = null;
                          boolean gotList = false;
                          Callable <NamingEnumeration> listTask =
                              new Callable<NamingEnumeration>() {
                                  public NamingEnumeration call() {
                                      try {
                                          out.println("doing future on
ictx.list()");
                                          return ictx.list(dns);
                                      } catch (Exception ex) {
                                          ex.printStackTrace();
                                      }
                                      return null;
                                  }
                              };
                          Future <NamingEnumeration> future =
exec.submit(listTask);
                          try {
                              newEnumeration = future.get(10L,
TimeUnit.SECONDS);
                              if (newEnumeration != null) {
                                  gotList = true;
                              }
                          } catch (Exception ex) {
                              ex.printStackTrace();
                          } finally {
                              future.cancel(true);
                          }
                          if (!gotList) {
                              continue;
                          }
                          parallelRecursiveDNS(exec, ictx,
newEnumeration, domainsVisitedQueue, results);
                      }
                  } catch (Exception ex) {
                      ex.printStackTrace();
                  } finally {
                      long runEnd = System.currentTimeMillis();
                      out.println("runnable execution time was "
                        + (runEnd - runStart) / 1000 + " seconds ");
                      if (taskCount.decrementAndGet() == 0) {
                          out.println("\n\nparallelRecursiveDNS finished\n\n");
                          solution.setCompleted();
                      }
                  }

              }
          });
      }
  }
}


On 12/13/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> Robert,
>
> You are shutting down the pool while it is still in use. The Runnables you
> submit in the first parallelRecursiveDNS still submit further Runnables in
> their own recursion.
>
> This is likely why you get the RejectedExecutionExceptions - you are
> submitting to a shutdown pool.
>
> You should shutdown the pool after you have completed the task.
>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of robert
> > lazarski
> > Sent: Thursday, 14 December 2006 12:24 AM
> > Cc: Concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Migrating DNS problem to j.u.c
> >
> >
> > OK, I put exec.shutdown() right before exec.awaitTermination().
> >
> > However, I'm unclear on why the program wouldn't know if the recursion
> > is finished - lets assume no timeout. It roughly follows the jcip
> > listing 8.11 and 8.12, which doesn't have a latch or atomic counter.
> > Do I need a latch and atomic counter like the puzzle program for my
> > program to work right, as shown? I ask because each Runnable in my
> > case has the potential to add to the Collection, unlike the puzzler
> > which is looking for one result.
> >
> > My main concern beyond the correct results is time: The program as
> > shown takes 7 minutes to run, though the original broken program was
> > even slower.
> >
> > Thanks,
> > Robert
> >
> > On 12/12/06, Tim Peierls <tim at peierls.net> wrote:
> > > You need to shutdown the ExecutorService before
> > awaitTermination can ever
> > > succeed. See Listings 7.16 and 7.22 in JCiP for examples of
> > awaitTermination
> > > with shutdown and shutdownNow.
> > >
> > > In your case, you don't know when the recursion is finished, so
> > you don't
> > > know when to shut down the pool. See the discussion on p.187 of
> > JCiP about
> > > stopping ConcurrentPuzzleSolver for different ways to deal with this.
> > >
> > > --tim
> > >
> > >
> > > On 12/12/06, robert lazarski < robertlazarski at gmail.com> wrote:
> > > >
> > > > On 12/12/06, Tim Peierls < tim at peierls.net> wrote:
> > > > > The minimal approach
> > > >
> > > > Thanks for the reply Tim. I've decided to start from scratch as the
> > > > original code is broke in several ways. The whole recursion part may
> > > > be a misunderstanding of the original coder. Anyways, while I'm trying
> > > > to figure it out I implemented it using j.u.c and I'm posting it here
> > > > in case someone could review it.
> > > >
> > > > There is one question I have: awaitTermination doesn't do what I
> > > > expect - end after 100 seconds, ie, I get the List returned but the
> > > > main() keeps going. Perhaps something to do with daemon threads. Any
> > > > insight appreciated.
> > > >
> > > > package org;
> > > >
> > > > import static java.lang.System.out;
> > > >
> > > > import java.util.ArrayList;
> > > > import java.util.Collection ;
> > > > import java.util.Hashtable;
> > > > import java.util.List;
> > > > import java.util.Queue;
> > > > import java.util.concurrent.ConcurrentLinkedQueue;
> > > > import java.util.concurrent.Executor;
> > > > import java.util.concurrent.ExecutorService ;
> > > > import java.util.concurrent.Executors;
> > > > import java.util.concurrent.TimeUnit;
> > > >
> > > > import javax.naming.NameClassPair;
> > > > import javax.naming.NamingEnumeration;
> > > > import javax.naming.directory.Attributes;
> > > > import javax.naming.directory.DirContext;
> > > > import javax.naming.directory.InitialDirContext;
> > > > import javax.naming.directory.Attribute;
> > > > import javax.naming.directory.Attributes;
> > > >
> > > > public class DNS
> > > > {
> > > >
> > > >   public static void main(String[] args) throws Exception {
> > > >       helloDNS();
> > > >   }
> > > >
> > > >
> > > /*******************************************************************
> > > >   Use this method to test dns
> > > >
> > > *******************************************************************/
> > > >   private static void helloDNS() throws Exception {
> > > >        calculateDNS("bee.uspnet.usp.br", "usp.br");
> > > >   }
> > > >
> > > >   private static List<String> calculateDNS(String dnsIP,
> > String domain)
> > > >           throws Exception {
> > > >
> > > >       Hashtable<String, String> env = new Hashtable<String, String>();
> > > >       env.put("java.naming.factory.initial",
> > > > "com.sun.jndi.dns.DnsContextFactory ");
> > > >       env.put("java.naming.provider.url",  "dns://" + dnsIP + "/");
> > > >
> > > >       // obter contexto inicial
> > > >       DirContext ictx = null;
> > > >       NamingEnumeration hostEnumeration = null;
> > > >       try {
> > > >           out.println("getting conn: ");
> > > >           ictx = new InitialDirContext(env);
> > > >           out.println("getting conn, getting list ");
> > > >           hostEnumeration = ictx.list (domain);
> > > >           out.println("got list ");
> > > >       } catch (Exception ex) {
> > > >           ex.printStackTrace();
> > > >           throw new Exception(ex);
> > > >       }
> > > >       ExecutorService exec = Executors.newCachedThreadPool (
> > > >               new ONExceptionThreadFactory(new ONExceptionHandler()));
> > > >       // skip those already found
> > > >       Queue <String> domainsVisitedQueue = new
> > > ConcurrentLinkedQueue<String>();
> > > >       domainsVisitedQueue.add (domain);
> > > >       Queue <String> resultQueue = new
> > > ConcurrentLinkedQueue<String>();
> > > >       parallelRecursiveDNS(exec, ictx, hostEnumeration,
> > > > domainsVisitedQueue, resultQueue);
> > > >       exec.awaitTermination (100L, TimeUnit.SECONDS);
> > > >
> > > >       return new ArrayList<String>(resultQueue);
> > > >   }
> > > >
> > > >   private static void parallelRecursiveDNS(final Executor exec, final
> > > > DirContext ictx,
> > > >           final NamingEnumeration hostEnumeration, final
> > > > Collection<String> domainsVisitedQueue,
> > > >           final Collection<String> results)
> > > >       throws Exception {
> > > >
> > > >       while (hostEnumeration.hasMore()) {
> > > >
> > > >           exec.execute(new Runnable() {
> > > >               public void run() {
> > > >                   try {
> > > >                       String host = null;
> > > >                       host = ((NameClassPair) hostEnumeration.next())
> > > >                               .getNameInNamespace();
> > > >                       results.add(host);
> > > >                       out.println("Found host: " + host);
> > > >                       // all 'A records'
> > > >                       Attributes a =
> > > ictx.getAttributes(host,
> > > >                               new String[] { "A" });
> > > >                       if (a.get("A") != null) {
> > > >                           String ip =
> > > a.get("A").get().toString();
> > > >                            results.add(ip);
> > > >                           out.println("Found ip: " + ip);
> > > >                       }
> > > >                       // enter task suitable for recursion?
> > > >                       Attributes aDNS =
> > > ictx.getAttributes(host,
> > > >                                   new String[] { "NS" });
> > > >                       NamingEnumeration allDNS =
> > > aDNS.getAll();
> > > >                       while (allDNS.hasMore()) {
> > > >                            out.println("Entering allDNS: ");
> > > >                           Attribute attr = (Attribute)
> > > allDNS.next();
> > > >                           NamingEnumeration values =
> > > attr.getAll();
> > > >                           String dns =
> > > values.next().toString();
> > > >                           if (domainsVisitedQueue.contains(dns)) {
> > > >                               continue;
> > > >                           }
> > > >                           NamingEnumeration newHost =
> > > ictx.list(dns);
> > > >                           out.println("doing recursion: ");
> > > >                           parallelRecursiveDNS(exec,
> > > ictx, newHost,
> > > > domainsVisitedQueue, results);
> > > >                       }
> > > >                   } catch (Exception ex) { ex.printStackTrace(); }
> > > >
> > > >               }
> > > >
> > > >           });
> > > >       }
> > > >   }
> > > > }
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at altair.cs.oswego.edu
> > > >
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >
> > >
> > >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From joe.bowbeer at gmail.com  Thu Dec 14 13:42:56 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 14 Dec 2006 10:42:56 -0800
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <f87675ee0612140708j1a2367dqcf7a20b3380f39a3@mail.gmail.com>
References: <f87675ee0612130623p2c71f471g158ff13c8cb4d01@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEIPHEAA.dcholmes@optusnet.com.au>
	<f87675ee0612140708j1a2367dqcf7a20b3380f39a3@mail.gmail.com>
Message-ID: <31f2a7bd0612141042n6a01e305jc1b0622bbd53c36e@mail.gmail.com>

Your cancellation is requesting an interrupt via cancel(true), so it seems
that ictx.list() isn't responding to the interrupt.

Can you enhance ictx.list() to quit when it is interrupted?

Btw, when in the timeline is ictx.close() called, and how long does it take
to complete?


On 12/14/06, robert lazarski <robertlazarski at gmail.com> wrote:
>
> Indeed, I was submitting tasks to a shutdown pool, thanks. I now have
> a latch, which seems to now know when to shutdown the pool.
>
> My current problem is that the future times out correctly, but
> DirContext.list() isn't being cancelled of course, as it throws
> "java.net.ConnectException: Connection timed out" long after
> Future.cancel() . Page 148 of jcip states that closing the underlying
> socket could help, but in this case I'm not sure how I could do that.
> The program calls shutdown after about 90 seconds, but hangs for 5 and
> a half more minutes. Any ideas?
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061214/104793c3/attachment.html 

From robertlazarski at gmail.com  Thu Dec 14 15:53:21 2006
From: robertlazarski at gmail.com (robert lazarski)
Date: Thu, 14 Dec 2006 15:53:21 -0500
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <31f2a7bd0612141042n6a01e305jc1b0622bbd53c36e@mail.gmail.com>
References: <f87675ee0612130623p2c71f471g158ff13c8cb4d01@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEIPHEAA.dcholmes@optusnet.com.au>
	<f87675ee0612140708j1a2367dqcf7a20b3380f39a3@mail.gmail.com>
	<31f2a7bd0612141042n6a01e305jc1b0622bbd53c36e@mail.gmail.com>
Message-ID: <f87675ee0612141253g7ccd36bap968b57f18112163f@mail.gmail.com>

On 12/14/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Your cancellation is requesting an interrupt via cancel(true), so it seems
> that ictx.list() isn't responding to the interrupt.
>
> Can you enhance ictx.list() to quit when it is interrupted?

What's happening AFAICT via 'netstat -ancp' is that the
DirContext.list() sockets that were cancelled by the future get stuck
in 'SYN_SENT' until whenever it decides to switch to 'ESTABLISHED' ,
where it then throws 'java.net.ConnectException: Connection timed out'
at the line of ictx.list() in the Callable inside the Runnable. Any
idea on what I can do about that?

>
> Btw, when in the timeline is ictx.close() called, and how long does it take
> to complete?
>

itcx.close() is called in the same finally block as exec.shutdown().
It returns almost immediately, less than one second. I tried putting
itcx.close() before shutdown(), to no effect.

Thanks everyone,
Robert

From chirag_r_shah at rediffmail.com  Fri Dec 15 18:03:12 2006
From: chirag_r_shah at rediffmail.com (Chirag Shah)
Date: 15 Dec 2006 23:03:12 -0000
Subject: [concurrency-interest] Need to kill a single working thread,
	rather than killing the application
Message-ID: <20061215230312.1229.qmail@webmail32.rediffmail.com>

Hi,

I am new to TPE. I have a question. 

I have a Multithreaded Java Application running on SunOS Sparc. 
Which open a socket connection, get the request and pass it to the worker.  The worker will read/write the file and send the data back to the client. Rightnow we have setting of min 300 Thread and max 1000 Thread. 

My basic requirement is, if a thread takes more than couple of sec eg 5 seconds, I want that thread to stop doing the task, ie terminate that request and start serving other requestm, which is in the queue. b'cos that single task may hung my whole application. I can kill a single request rather than killing the whole application. 

Would you please give me the best idea?

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061215/6f18a284/attachment.html 

From dcholmes at optusnet.com.au  Sun Dec 17 18:00:52 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 18 Dec 2006 09:00:52 +1000
Subject: [concurrency-interest] Migrating DNS problem to j.u.c
In-Reply-To: <f87675ee0612141253g7ccd36bap968b57f18112163f@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEJOHEAA.dcholmes@optusnet.com.au>

Robert,

It seems your issue is with the naming service. Unless it supports some kind
of cancellation or timeout then you seem to be stuck. Sorry but I'm not
familiar with it.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of robert
> lazarski
> Sent: Friday, 15 December 2006 6:53 AM
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Migrating DNS problem to j.u.c
>
>
> On 12/14/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > Your cancellation is requesting an interrupt via cancel(true),
> so it seems
> > that ictx.list() isn't responding to the interrupt.
> >
> > Can you enhance ictx.list() to quit when it is interrupted?
>
> What's happening AFAICT via 'netstat -ancp' is that the
> DirContext.list() sockets that were cancelled by the future get stuck
> in 'SYN_SENT' until whenever it decides to switch to 'ESTABLISHED' ,
> where it then throws 'java.net.ConnectException: Connection timed out'
> at the line of ictx.list() in the Callable inside the Runnable. Any
> idea on what I can do about that?
>
> >
> > Btw, when in the timeline is ictx.close() called, and how long
> does it take
> > to complete?
> >
>
> itcx.close() is called in the same finally block as exec.shutdown().
> It returns almost immediately, less than one second. I tried putting
> itcx.close() before shutdown(), to no effect.
>
> Thanks everyone,
> Robert
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From sberlin at gmail.com  Mon Dec 18 13:25:11 2006
From: sberlin at gmail.com (Sam Berlin)
Date: Mon, 18 Dec 2006 13:25:11 -0500
Subject: [concurrency-interest] ThreadPool with maximum idle thread size?
Message-ID: <19196d860612181025s221031e9q16d1a441d322dd36@mail.gmail.com>

Hi Folks,

I'm looking into converting some of our custom thread pools to use
Java 5's concurrent package.  This will eliminate some of the bugs
with our packages, and let the code be a bit more interoperable with
other libraries.  One thing I'm looking for in the concurrent pools is
the ability to limit the number of idle threads.  I see settings for
the 'core size' (the number that will always remain alive, once
started), the 'maximum size' (the number to allow at most), and the
length of time that threads over the core size will remain alive, but
I don't see anything that can limit the number of idle threads.  The
goal behind this is to allow the threads to be created during peak
times (and thus the maximum size can't be used), but to not allow them
to linger for so long.  An alternative to a maximum idle size could be
a variable linger time, depending on how many idle threads there are
(for instance, > 0 idle == 5 seconds linger, > 5 == 2 seconds linger,
> 15 == no linger).

I've looked into the source to see if it's possible to do this by
subclassing ThreadPool and inserting hooks, but there doesn't seem to
be any easy way.

Any suggestions, or reasons why this functionality may not be a good idea?

Thanks,
 Sam

From joe.bowbeer at gmail.com  Mon Dec 18 17:00:56 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 18 Dec 2006 14:00:56 -0800
Subject: [concurrency-interest] ThreadPool with maximum idle thread size?
In-Reply-To: <19196d860612181025s221031e9q16d1a441d322dd36@mail.gmail.com>
References: <19196d860612181025s221031e9q16d1a441d322dd36@mail.gmail.com>
Message-ID: <31f2a7bd0612181400n2e553790s71f08f2ee7621845@mail.gmail.com>

Executors.newCachedThreadPool does not maintain a core pool of threads
and sheds idle threads after 60 seconds.

Can you compare the desired behavior to that of a cached thread pool?

Can tuning the keepAlive time achieve the desired result?  (Or it the
case that you want to avoid futzing around and just want a drop-in
replacement?)

Also note that ThreadPoolExecutor.allowCoreThreadTimeOut was added in Java 6.


On 12/18/06, Sam Berlin <sberlin at gmail.com> wrote:
> Hi Folks,
>
> I'm looking into converting some of our custom thread pools to use
> Java 5's concurrent package.  This will eliminate some of the bugs
> with our packages, and let the code be a bit more interoperable with
> other libraries.  One thing I'm looking for in the concurrent pools is
> the ability to limit the number of idle threads.  I see settings for
> the 'core size' (the number that will always remain alive, once
> started), the 'maximum size' (the number to allow at most), and the
> length of time that threads over the core size will remain alive, but
> I don't see anything that can limit the number of idle threads.  The
> goal behind this is to allow the threads to be created during peak
> times (and thus the maximum size can't be used), but to not allow them
> to linger for so long.  An alternative to a maximum idle size could be
> a variable linger time, depending on how many idle threads there are
> (for instance, > 0 idle == 5 seconds linger, > 5 == 2 seconds linger,
> > 15 == no linger).
>
> I've looked into the source to see if it's possible to do this by
> subclassing ThreadPool and inserting hooks, but there doesn't seem to
> be any easy way.
>
> Any suggestions, or reasons why this functionality may not be a good idea?
>
> Thanks,
>  Sam
>

From dcholmes at optusnet.com.au  Mon Dec 18 18:03:59 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 19 Dec 2006 09:03:59 +1000
Subject: [concurrency-interest] Need to kill a single working thread,
	rather than killing the application
In-Reply-To: <20061215230312.1229.qmail@webmail32.rediffmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEKCHEAA.dcholmes@optusnet.com.au>

Hi,

If you are concerned about the socket operation blocking for too long then
you can setSOTimeout and if it times out just abandon the current task.

If more generally you want to cancel a task after N seconds then you need to
write the task in a way that is cancellable (which means the socket blocking
still needs taking care of) and you need to set up a "watchdog task" to
trigger the cancellation. The watchdog task can be a FutureTask submitted to
a ScheduledThreadPoolExecutor. But you also need to cancel the watchdog if
the main task completes normally.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Chirag Shah
  Sent: Saturday, 16 December 2006 9:03 AM
  To: Concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Need to kill a single working
thread,rather than killing the application


  Hi,

  I am new to TPE. I have a question.

  I have a Multithreaded Java Application running on SunOS Sparc.
  Which open a socket connection, get the request and pass it to the worker.
The worker will read/write the file and send the data back to the client.
Rightnow we have setting of min 300 Thread and max 1000 Thread.

  My basic requirement is, if a thread takes more than couple of sec eg 5
seconds, I want that thread to stop doing the task, ie terminate that
request and start serving other requestm, which is in the queue. b'cos that
single task may hung my whole application. I can kill a single request
rather than killing the whole application.

  Would you please give me the best idea?

  Thanks.




-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061219/f05a9746/attachment.html 

From dhanji at gmail.com  Mon Dec 18 19:30:23 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 19 Dec 2006 10:30:23 +1000
Subject: [concurrency-interest] Need to kill a single working thread,
	rather than killing the applica
In-Reply-To: <20061218181702.22507.qmail@webmail28.rediffmail.com>
References: <20061218181702.22507.qmail@webmail28.rediffmail.com>
Message-ID: <aa067ea10612181630w2847b758r89895796237eae3f@mail.gmail.com>

On 18 Dec 2006 18:17:02 -0000, Chirag Shah <chirag_r_shah at rediffmail.com>
wrote:
>
>
> Hi Dhanji,
>
> Thanks for your reply. I have this code on the client side. But the thread
> on the server side is already in the working status. So from the server
> side, if I do not kill the thread, which is taking long time, I will hit the
> max capacity of threads (ie 600 threads all are working) and the new request
> will be queued until a thread gets free.
>

When I said client I am referring to the client code, i.e. the server
sockets (presumably) which are being run on the TPE, not the actual network
client itself.

Setting a timeout on your server sockets will force them to abort the job
after n seconds in a predictable manner. You can catch
SocketTimeoutException and close the socket properly.
>
>
> Is it better idea to call Thread.stop method. will TPE create new thread,
> if I kill a thread(s). ie I have 600 min thread and if I kill 10 thread,
> will it create 10 thread to reach min capacity?
>

It is a very bad idea to call Thread.stop()--it has even been deprecated
from the API. The client code (i.e. the Runnable) should exit itself by for
example exiting a loop or some such way of returning from run().

Thread operations that mutate the state of the thread outside of the client
code are inherently unsafe. This is why synchronization (thru wait() and
notify() or the higher-level constructs in j.u.c) is preferable to calling
suspend() and resume() for instance.
See this part of the doc for better explanation:

http://java.sun.com/j2se/1.5.0/docs/guide/misc/threadPrimitiveDeprecation.html


Dhanji.

> Thanks
> Chirag
>
> On Mon, 18 Dec 2006 Dhanji R.Prasanna wrote :
> >Hi Chirag
> >
> >I would advise having your client abort its io operation rather than an
> >enforced kill timeout from the TPE. Architecturally it is unsound to
> >arbitrarily terminate a client thread (you dont know what state it is in,
> >for instance). The client operation should raise an exception if it is
> >taking too long by for instance setting the timeout on a socket:
> >
> >try {
> >  socket.setSOTimeout(TOO_LONG);
> >  //blocking read from socket stream
> >  //...
> >} finally {
> >  cleanup();
> >}
> >
> >Dhanji.
> >
> >
> >On 15 Dec 2006 23:03:12 -0000, Chirag Shah <chirag_r_shah at rediffmail.com>
> >wrote:
> >>
> >>  Hi,
> >>
> >>I am new to TPE. I have a question.
> >>
> >>I have a Multithreaded Java Application running on SunOS Sparc.
> >>Which open a socket connection, get the request and pass it to the
> >>worker.  The worker will read/write the file and send the data back to
> the
> >>client. Rightnow we have setting of min 300 Thread and max 1000 Thread.
> >>
> >>My basic requirement is, if a thread takes more than couple of sec eg 5
> >>seconds, I want that thread to stop doing the task, ie terminate that
> >>request and start serving other requestm, which is in the queue. b'cos
> that
> >>single task may hung my whole application. I can kill a single request
> >>rather than killing the whole application.
> >>
> >>Would you please give me the best idea?
> >>
> >>Thanks.
> >>
> >>
> >>
> >><
> http://adworks.rediff.com/cgi-bin/AdWorks/sigclick.cgi/www.rediff.com/signature-home.htm/1507191490 at Middle5?PARTNER=3
> >
> >>_______________________________________________
> >>Concurrency-interest mailing list
> >>Concurrency-interest at altair.cs.oswego.edu
> >>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >>
>
>
> <http://adworks.rediff.com/cgi-bin/AdWorks/sigclick.cgi/www.rediff.com/signature-home.htm/1507191490 at Middle5?PARTNER=3>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061219/703fa634/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Tue Dec 19 08:29:43 2006
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 19 Dec 2006 14:29:43 +0100
Subject: [concurrency-interest] Closing a socket from another thread
Message-ID: <b6e8f2e80612190529s78f0158ayc60aafd85a3c9d4d@mail.gmail.com>

Hi,

Anyone has an idea/experience how safe it is to close a socket from another
thread. Are there any utility classes which help me close a socket safely?

Thanks

Peter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061219/6aa86883/attachment.html 

From dcholmes at optusnet.com.au  Tue Dec 19 08:31:39 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 19 Dec 2006 23:31:39 +1000
Subject: [concurrency-interest] Need to kill a single working thread,
	rather than killing the application
In-Reply-To: <4587E801.6040004@chemaxon.hu>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEKEHEAA.dcholmes@optusnet.com.au>

Closing the socket/stream is the preferred method for unblocking a thread
that is stuck on the socket/stream. This approach is also used in NIO where
an interrupt of a thread blocked on a channel will close the channel and
unblock all waitings threads.

Of course "safely" might mean those other threads being prepared for the
IOException they will get.

If you have access to the socket then you can just close it. If you don't
then you are relying on the library/framework you are using exposing a
cancellation API.

Cheers,
David Holmes

> -----Original Message-----
> From: P?ter Kov?cs [mailto:peter.kovacs at chemaxon.hu]
> Sent: Tuesday, 19 December 2006 11:24 PM
> To: dholmes at ieee.org
> Cc: Chirag Shah; Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Need to kill a single working
> thread, rather than killing the application
>
>
> Hi,
>
> Anyone has an idea/experience how safe it is to close a socket from
> another thread. Are there any utility classes which help me close a
> socket safely?
>
> Thanks
>
> Peter
>
> David Holmes wrote:
> > Hi,
> >
> > If you are concerned about the socket operation blocking for too long
> > then you can setSOTimeout and if it times out just abandon the
> current task.
> >
> > If more generally you want to cancel a task after N seconds then you
> > need to write the task in a way that is cancellable (which means the
> > socket blocking still needs taking care of) and you need to set up a
> > "watchdog task" to trigger the cancellation. The watchdog task can be a
> > FutureTask submitted to a ScheduledThreadPoolExecutor. But you
> also need
> > to cancel the watchdog if the main task completes normally.
> >
> > Cheers,
> > David Holmes
> >
> >     -----Original Message-----
> >     *From:* concurrency-interest-bounces at cs.oswego.edu
> >     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
> >     *Chirag Shah
> >     *Sent:* Saturday, 16 December 2006 9:03 AM
> >     *To:* Concurrency-interest at cs.oswego.edu
> >     *Subject:* [concurrency-interest] Need to kill a single working
> >     thread,rather than killing the application
> >
> >     Hi,
> >
> >     I am new to TPE. I have a question.
> >
> >     I have a Multithreaded Java Application running on SunOS Sparc.
> >     Which open a socket connection, get the request and pass it to the
> >     worker.  The worker will read/write the file and send the data back
> >     to the client. Rightnow we have setting of min 300 Thread and max
> >     1000 Thread.
> >
> >     My basic requirement is, if a thread takes more than couple of sec
> >     eg 5 seconds, I want that thread to stop doing the task, ie
> >     terminate that request and start serving other requestm, which is in
> >     the queue. b'cos that single task may hung my whole application. I
> >     can kill a single request rather than killing the whole application.
> >
> >     Would you please give me the best idea?
> >
> >     Thanks.
> >
> >
> >
> >
> <http://adworks.rediff.com/cgi-bin/AdWorks/sigclick.cgi/www.rediff
.com/signature-home.htm/1507191490 at Middle5?PARTNER=3>
>
>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



From Darron_Shaffer at stercomm.com  Tue Dec 19 13:11:22 2006
From: Darron_Shaffer at stercomm.com (Shaffer, Darron)
Date: Tue, 19 Dec 2006 13:11:22 -0500
Subject: [concurrency-interest] Closing a socket from another thread
In-Reply-To: <b6e8f2e80612190529s78f0158ayc60aafd85a3c9d4d@mail.gmail.com>
Message-ID: <303629700276DF4D9ED7D011221B8FAA08681349@scidubmsg03.sci.local>

This is a pain before JDK 1.4, because every JVM has its own little
quirks.  In fact, for at least one 1.3 JVM closing a ServerSocket from a
different thread would trigger a bug causing some future accepted
sockets to be handed to the wrong ServerSocket!
 
However, in 1.4 with the arrival of NIO the SocketChannel versions of
sockets have much better specifications of thread behavior.  Its now
supposed to just work, causing any threads blocked on the closed sockets
to receive an exception.  However, I haven't tested this extensively
because with NIO I avoid all blocking operations and don't have to do
this sort of thing.

________________________________

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Peter
Kovacs
Sent: Tuesday, December 19, 2006 7:30 AM
To: Concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Closing a socket from another thread


Hi, 

Anyone has an idea/experience how safe it is to close a socket from
another thread. Are there any utility classes which help me close a
socket safely? 

Thanks 

Peter 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061219/36100cb7/attachment.html 

From chancer357 at hotmail.com  Tue Dec 19 21:16:22 2006
From: chancer357 at hotmail.com (First Last)
Date: Wed, 20 Dec 2006 02:16:22 +0000
Subject: [concurrency-interest] Volatile / Sychronized?
Message-ID: <BAY13-F23D190F26BB10D23A504158ECF0@phx.gbl>

Please clear up something about the proper use of volatile for me. I'm 
having difficulty understanding when volatile is sufficent. Its a tricky 
thing to explain, so let me just show my confusion with a few examples and 
citations.

Question #1:

I see many examples of code such as this, taken from the JMM FAQ on Bill's 
site:

class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }

  public void reader() {
    if (v == true) {
      //uses x - guaranteed to see 42.
    }
  }
}

This is very clear to me. Marking the boolean field volatile is enough to 
effect the memory barrier/establish the happens-before relationship needed 
to make the order. The description of volatile being half-synchonized is 
very good.

Following this example in the JMM FAQ is the statement:

"Important Note: Note that it is important for both threads to access the 
same volatile variable in order to properly set up the happens-before 
relationship. It is not the case that everything visible to thread A when it 
writes volatile field f becomes visible to thread B after it reads volatile 
field g. The release and acquire have to "match" (i.e., be performed on the 
same volatile field) to have the right semantics."

What does this mean? Should I take this to mean that the following example 
won't work?

class BadUseOfVolatileExample {
  volatile int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }

  public void reader() {
    if (v == true) {
      //uses x - guaranteed to see 42.
    }
  }
}

If it is true the example above won't work, why does it work when x
is not volaitle. If it is false that the example won't work, can you please
show me an example that demonstrates the pitfall the Important Note
warns us of? Along with an explaination of why it is so?

Question #2:

I have often seen a poor man's synchonized implemented as such
(though I am admitedly having trouble locating a concrete example of
this as present. I could have sworn this has appeared on this list before,
but there is no search function on mailman..)

class SynchronizedVolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    synchronized(this) {
      v = true;
    }
  }

  public void reader() {
    if (v == true) {
      //uses x - guaranteed to see 42.
    }
  }
}

What I am trying to illustrate here with this poorly chosen example
is a situation in which a voliatle field is used, but is only ever written
to from within a synchronized block, and is read w/o the synchronzation.

Is this neccessarry in this example? If not what sort of situation is it 
neccessary
in? I could rephrase this whole question as, "Is there ever a circumstance 
where
a volaitle variable must be written to from within a synchronized block?" 
(and if so
please demonstrate the pitfall for my understanding.

Question #3:

I have seen it suggested that one scenario which the synchronized is 
required
would be to ensure the completion of a constructor before the assignment. 
The
fear being that w/o the synchronized keyword, its possible to somehow have
assigned the buffer reference to a StringBuffer object whose constructor has
not completed, or whose internal fields that are not volatile themselves may
not be visible to other threads.

class VolatileStringBufferExample {
  volatile StringBuffer buffer = new StringBuffer();
  public void swapInNewBuffer() {
    synchronized(this) {
      buffer = new StringBuffer();
    }
  }
  public StringBuffer getStringBuffer() {
    return buffer;
  }
}

Is this a valid concern, or does a constructor give you a happens-before 
garuntee?

Question #4:

Is there any use for AtomicBoolean or AtomicReference if we don't care about 
CAS semantics?
In other words, if all I want is to not use the word synchronized is all I 
need to do add "volatile",
kick back and enjoy?

Question #5:

How much am I saving by dropping synchronized keywords anyways? I've heard 
things like JSE5
and JSE6 are just a lot better at optimizing locks. That sounds great, but I 
can't quantify this kind
of assement. Does this mean its half as slow as it used to be? Does this 
mean its 2 times worse than
using a synchronized keyword? Does it mean there could theoretically be no 
locking at all because through some magic the JVM has optimized away the 
lock?

If I give up the relative clarity of happens-before relationships I can 
establish with a synchronized
keyword, I want to know how much I am giving up. Some developers I work with 
shudder as soon
as they see the word synchronized and I really don't have a good way to 
gauge the reality of
their concerns. Certainly there are scenarios in which fine grained locks, 
or lock-free algorithms are a boon - but that doesn't mean ALL 
synchronization is evil.

On a similar note, what is the cost of volatile field access? Compared to 
regular field access? There
must be something going on to ensure the happens-before relationships hold - 
and it can't be free
but again its one of those things I'm more generally assured the JVM is 
"better" at doing than it
used to be.

(And here by better, I mean articles, blog entries, sun docs, etc. The only 
source I do not have
at hand currently is Brian's newer book)

---

I thank you for any light you may shed on these mysteries for me, and you 
have my apologies if I repeat myself. It could be worthwhile to create 
examples, good & bad, to better demonstrate these points if I'm not just 
totally missing something already documented. Maybe as an appendix to
the JMM FAQ, or an addtion to the java.util.concurrent.package.html.

_________________________________________________________________
Get FREE Web site and company branded e-mail from Microsoft Office Live 
http://clk.atdmt.com/MRT/go/mcrssaub0050001411mrt/direct/01/


From jmanson at cs.umd.edu  Tue Dec 19 22:15:31 2006
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Tue, 19 Dec 2006 19:15:31 -0800
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <BAY13-F23D190F26BB10D23A504158ECF0@phx.gbl>
References: <BAY13-F23D190F26BB10D23A504158ECF0@phx.gbl>
Message-ID: <4588AAD3.2010509@cs.umd.edu>

First Last wrote:
> Question #1:

[snip]

> What does this mean? Should I take this to mean that the following example 
> won't work?
> 
> class BadUseOfVolatileExample {
>   volatile int x = 0;
>   volatile boolean v = false;
>   public void writer() {
>     x = 42;
>     v = true;
>   }
> 
>   public void reader() {
>     if (v == true) {
>       //uses x - guaranteed to see 42.
>     }
>   }
> }
> 
> If it is true the example above won't work, why does it work when x
> is not volaitle. If it is false that the example won't work, can you please
> show me an example that demonstrates the pitfall the Important Note
> warns us of? Along with an explaination of why it is so?

No, this example works, as you perform a write to v, followed by a read 
of v.  Making x volatile has no real effect on this code in isolation. 
The paragraph you quoted is meant to prevent people from assuming that a 
write to a volatile will act as a memory barrier; writing to a volatile 
variable won't necessarily flush values to memory unless there is a 
subsequent read of that same volatile variable.

> 
> Question #2:
> 

[snip]

> Is this neccessarry in this example? If not what sort of situation is it 
> neccessary
> in? I could rephrase this whole question as, "Is there ever a circumstance 
> where
> a volaitle variable must be written to from within a synchronized block?" 
> (and if so
> please demonstrate the pitfall for my understanding.

The synchronization is unnecessary in this example.  You can fairly 
easily contrive examples where you would use locking together with 
volatiles, but you will generally be using them for two different 
purposes.  The canonical example is double-checked locking:

   class Foo {
         private volatile Helper helper = null;
         public Helper getHelper() {
             if (helper == null) {
                 synchronized(this) {
                     if (helper == null)
                         helper = new Helper();
                 }
             }
             return helper;
         }
     }

This allows the reader not to synchronize when the object has already 
been constructed.  The synchronization is necessary for mutual 
exclusion; it makes sure that the helper field is null when the object 
is constructed and the field is assigned its value.

> 
> Question #3:
> 
> I have seen it suggested that one scenario which the synchronized is 
> required
> would be to ensure the completion of a constructor before the assignment. 

[snip]

> Is this a valid concern, or does a constructor give you a happens-before 
> garuntee?

The end of the constructor happens-before the assignment to buffer in 
this example.  In fact, any statements that get executed in this thread 
before the assignment to buffer happen-before the assignment to buffer 
-- this includes calls not just the constructor, but calls to other 
methods and so on.

Just looking at this code in isolation, I can't think of a reason you 
would need the synchronized block.

> 
> Question #4:
> 
> Is there any use for AtomicBoolean or AtomicReference if we don't care about 
> CAS semantics?
> In other words, if all I want is to not use the word synchronized is all I 
> need to do add "volatile",
> kick back and enjoy?

It shouldn't be a problem for you to do this right now.

> Question #5:
> 
> How much am I saving by dropping synchronized keywords anyways? I've heard 
> things like JSE5
> and JSE6 are just a lot better at optimizing locks. That sounds great, but I 
> can't quantify this kind
> of assement. Does this mean its half as slow as it used to be? Does this 
> mean its 2 times worse than
> using a synchronized keyword? Does it mean there could theoretically be no 
> locking at all because through some magic the JVM has optimized away the 
> lock?

In general, it means that the JVM is very good at reducing the cost of 
uncontended locks (such as the cost of synchronizing on a Vector or 
Hashtable that is never shared).  There are a lot of locks that will 
never be contended in a lot of Java programs.  OTOH, if you have a lot 
of lock contention, reducing it usually will give you a performance boost.

Other performance tips:

1) Always, always make sure you understand what you are writing, and 
that it is correct.  Lock-free and non-blocking algorithms are great, 
but it takes a lot of time and energy and a complete understanding of 
synchronization mechanisms to get them right.

2) The best bet is probably start by using java.util.concurrent 
whereever possible.

3) There is a lot of unnecessary synchronization in Java code.  Don't 
use Vector or Hashtable, and use java.nio where possible.

4) Use immutable objects a lot.  If you aren't sharing mutable objects 
across threads, then you don't need to worry about locking.  Final 
fields are your friend.  Read the stuff on immutability in JCiP carefully.

5) Avoid excess lock contention by reducing lock scopes and lock durations.

> On a similar note, what is the cost of volatile field access? Compared to 
> regular field access? There
> must be something going on to ensure the happens-before relationships hold - 
> and it can't be free
> but again its one of those things I'm more generally assured the JVM is 
> "better" at doing than it
> used to be.

They are more expensive, but what that means depends on your 
architecture.  On x86, volatile reads are very cheap, but writes cost 
somewhat more.

Phew!  Hope that helps.

					Jeremy

From chancer357 at hotmail.com  Tue Dec 19 22:50:13 2006
From: chancer357 at hotmail.com (First Last)
Date: Wed, 20 Dec 2006 03:50:13 +0000
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <4588AAD3.2010509@cs.umd.edu>
Message-ID: <BAY13-F232414904D498FA061DABE8ECF0@phx.gbl>

Thanks very much for the answers.

>>Question #1:
>
>
>No, this example works, as you perform a write to v, followed by a read of 
>v.  Making x volatile has no real effect on this code in isolation. The 
>paragraph you quoted is meant to prevent people from assuming that a write 
>to a volatile will act as a memory barrier; writing to a volatile variable 
>won't necessarily flush values to memory unless there is a subsequent read 
>of that same volatile variable.

Ok, so the pitfall is to assume volatile alone is enough, rather
you must use volatile along with a write and a read to that volatile
field - in that order.

I can't really think of an example of what this would like, should someone
code the mistake, unless they just removed the check of the volatile flag
completely before reading x because they thought the write was enough,
which kind of seems silly.

>>Question #2:
>>
>The canonical example is double-checked locking:
>
>   class Foo {
>         private volatile Helper helper = null;
>         public Helper getHelper() {
>             if (helper == null) {
>                 synchronized(this) {
>                     if (helper == null)
>                         helper = new Helper();
>                 }
>             }
>             return helper;
>         }
>     }
>
>This allows the reader not to synchronize when the object has already been 
>constructed.  The synchronization is necessary for mutual exclusion; it 
>makes sure that the helper field is null when the object is constructed and 
>the field is assigned its value.

Ok, so this just makes sure there is only one object instantiation
of Helper, and makes sure there is only assignment. Nothing at
all to do with a partially completed constructor. I see.

Explicitly synchronizing a write to a volatile field seems to be silly,
to me now unless I am synchronizing some other action around
the write as in your DCL example.


>>Question #3:
>>
>>I have seen it suggested that one scenario which the synchronized is 
>>required would be to ensure the completion of a constructor before the 
>>assignment.
>
>The end of the constructor happens-before the assignment to buffer in this 
>example.  In fact, any statements that get executed in this thread before 
>the assignment to buffer happen-before the assignment to buffer -- this 
>includes calls not just the constructor, but calls to other methods and so 
>on.

Just to be clear, I can rely on the runtime and the compiler not to
reorder anything oddly. The object will be fully constructed before
the assignment to the volatile makes anything visible to other threads.

>>Question #4:
>>
>>Is there any use for AtomicBoolean or AtomicReference if we don't care 
>>about CAS semantics?
>>In other words, if all I want is to not use the word synchronized is all I 
>>need to do add "volatile",
>>kick back and enjoy?
>
>It shouldn't be a problem for you to do this right now.

Is it fair to say the only reason to use Atomic* classes is for CAS
semantics?

_________________________________________________________________
Get FREE Web site and company branded e-mail from Microsoft Office Live 
http://clk.atdmt.com/MRT/go/mcrssaub0050001411mrt/direct/01/


From jmanson at cs.umd.edu  Tue Dec 19 23:50:17 2006
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Tue, 19 Dec 2006 20:50:17 -0800
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <BAY13-F232414904D498FA061DABE8ECF0@phx.gbl>
References: <BAY13-F232414904D498FA061DABE8ECF0@phx.gbl>
Message-ID: <4588C109.7030005@cs.umd.edu>

First Last wrote:
> Thanks very much for the answers.
> 
>>> Question #1:
> Ok, so the pitfall is to assume volatile alone is enough, rather
> you must use volatile along with a write and a read to that volatile
> field - in that order.

Right.

> I can't really think of an example of what this would like, should someone
> code the mistake, unless they just removed the check of the volatile flag
> completely before reading x because they thought the write was enough,
> which kind of seems silly.

A lot of people (especially OS types) are used to having a memory 
barrier operation available to them.  The point is, more or less, that 
accesses to volatile fields do NOT behave as memory barriers.

>>> Question #2:

> Ok, so this just makes sure there is only one object instantiation
> of Helper, and makes sure there is only assignment. Nothing at
> all to do with a partially completed constructor. I see.

Yup.

> Explicitly synchronizing a write to a volatile field seems to be silly,
> to me now unless I am synchronizing some other action around
> the write as in your DCL example.

Exactly -- the reason to use synchronized and the reason to use volatile 
have nothing to do with each other.

>>> Question #3:
>>>
> Just to be clear, I can rely on the runtime and the compiler not to
> reorder anything oddly. The object will be fully constructed before
> the assignment to the volatile makes anything visible to other threads.


Being extra-special careful -- it will only be visible to other threads 
that read the volatile and see the value assigned to it.  You can't 
think about it as the runtime and compiler not reordering things oddly, 
because that can come back to get you:

(volatile v = false, normal b = false, normal x = 0)

Thread 1:
x = 1;
v = true;
b = true;

Thread 2:
if (v)
   r1 = x; // sees 1;

Thread 3:
if (b)
   r2 = x; // can see 1 or 0

If you thought about it in terms of "the compiler not reordering 
anything oddly", you might imagine that the read in Thread 3 was 
guaranteed to see 1.  But you would be wrong.

> 
>>> Question #4:
> Is it fair to say the only reason to use Atomic* classes is for CAS
> semantics?

The AtomicX, where <X extends Number>, classes have atomic increment and 
decrement operations.  One common mistake with volatiles is the idea that:

volatile int v;
// later...
v++;

is guaranteed to happen all at once, and that no other thread can update 
v while it is occurring.  This is wrong.

The AtomicXArray classes have atomically accessed elements.  volatile 
arrays do not have special memory semantics for reads and writes of 
their elements -- only the reference to the array is atomic.

There is probably a fair bit that I am forgetting.  The javadoc for 
java.util.concurrent.atomic goes into it in detail.

					Jeremy

From ckessel at c-cor.com  Wed Dec 20 12:35:17 2006
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 20 Dec 2006 09:35:17 -0800
Subject: [concurrency-interest] Basic thread safety question:
	final/volatile/synchronized fields
Message-ID: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>

Having read JCiP, I find I'm quite paranoid now about thread safety :).
This is a good thing, but it leads me to a question just to make sure I
understand something basic.

Is it correct to say that a thread safe class requires (though this is
not necessarily sufficient) that every instance field be final,
volatile, or accessed in synchronized blocks?

The default in a lot of code, and my default for years, has been to
declare object fields "private Foo _f;" in objects that end up being
used in multi-threaded contexts.  Based on my understanding now, that
can't be a thread-safe field (unless used in synchronized blocks).

Chris



From jmanson at cs.umd.edu  Wed Dec 20 13:05:26 2006
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Wed, 20 Dec 2006 10:05:26 -0800
Subject: [concurrency-interest] Basic thread safety
 question:	final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
Message-ID: <45897B66.3040807@cs.umd.edu>

Kessel, Chris wrote:

> The default in a lot of code, and my default for years, has been to
> declare object fields "private Foo _f;" in objects that end up being
> used in multi-threaded contexts.  Based on my understanding now, that
> can't be a thread-safe field (unless used in synchronized blocks).
> 

This is a misconception I have never heard, so I'm thinking there must 
be more to it.  A private qualifier has no effect on threading 
whatsoever.  All it means is that (coarsely) you can't access that field 
directly from outside the object.

"Thread-safe" being something of an imprecise term, what effect did you 
think it had on threading?

					Jeremy

From ckessel at c-cor.com  Wed Dec 20 13:08:50 2006
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 20 Dec 2006 10:08:50 -0800
Subject: [concurrency-interest] Basic thread safety
	question:	final/volatile/synchronized fields
Message-ID: <FB46E3318E86BD40862DDB4DE178A737336E82@beomail1.NTSCD.C-COR.com>

The "private" has nothing to do with it. It's just a common default
declaration for instance fields.  I didn't mean to imply it had anything
to do with threading.

The question was in the first part really.  Must a thread safe class
have every instance field protected by volatile, final, or synchronized
blocks?

-----Original Message-----
From: Jeremy Manson [mailto:jmanson at cs.umd.edu] 
Sent: Wednesday, December 20, 2006 10:05 AM
To: Kessel, Chris
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Basic thread safety question:
final/volatile/synchronized fields

Kessel, Chris wrote:

> The default in a lot of code, and my default for years, has been to
> declare object fields "private Foo _f;" in objects that end up being
> used in multi-threaded contexts.  Based on my understanding now, that
> can't be a thread-safe field (unless used in synchronized blocks).
> 

This is a misconception I have never heard, so I'm thinking there must 
be more to it.  A private qualifier has no effect on threading 
whatsoever.  All it means is that (coarsely) you can't access that field

directly from outside the object.

"Thread-safe" being something of an imprecise term, what effect did you 
think it had on threading?

					Jeremy



From jmanson at cs.umd.edu  Wed Dec 20 13:16:51 2006
From: jmanson at cs.umd.edu (Jeremy Manson)
Date: Wed, 20 Dec 2006 10:16:51 -0800
Subject: [concurrency-interest] Basic thread safety
 question:	final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E82@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E82@beomail1.NTSCD.C-COR.com>
Message-ID: <45897E13.60205@cs.umd.edu>

Kessel, Chris wrote:
> The "private" has nothing to do with it. It's just a common default
> declaration for instance fields.  I didn't mean to imply it had anything
> to do with threading.
> 
> The question was in the first part really.  Must a thread safe class
> have every instance field protected by volatile, final, or synchronized
> blocks?

Oh, I see.  Well, the answer is "more or less" (and assuming you mean to 
include j.u.c locks under the aegis of "synchronized blocks").  There 
are other corner cases where some protection is offered.  For example, 
if one thread creates an object, places a reference to that object in a 
global variable, and then spawns another thread, then that other thread 
can read the object without using final, volatile or synchronized() 
(assuming no other thread is involved, and nobody writes to the object 
after the thread is spawned).  Similarly with a join.

					Jeremy

From brian at quiotix.com  Wed Dec 20 16:19:12 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 20 Dec 2006 16:19:12 -0500
Subject: [concurrency-interest] Basic thread safety
 question:	final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
Message-ID: <4589A8D0.4070004@quiotix.com>

> Having read JCiP, I find I'm quite paranoid now about thread safety :).

Then you read it right!

> Is it correct to say that a thread safe class requires (though this is
> not necessarily sufficient) that every instance field be final,
> volatile, or accessed in synchronized blocks?

There are edge cases, but to first order, yes.  (To be clear, insert 
"exclusively" after "accessed" in the above sentence.

> The default in a lot of code, and my default for years, has been to
> declare object fields "private Foo _f;" in objects that end up being
> used in multi-threaded contexts.  Based on my understanding now, that
> can't be a thread-safe field (unless used in synchronized blocks).

It is possible that the locking is higher up on the call stack.  For 
example:

class Foo { public int x; }

...

class Moo {
   @GuardedBy("this") private Foo foo = new Foo();

   public void doSomething() {
       synchronized (this) {
           System.out.println(foo.x);
       }
   }
}

The field x is accessed in a thread-safe manner in Moo, but the class 
Foo is not thread-safe.  The thread-safety is provided by the locking in 
Moo.


From brian at quiotix.com  Wed Dec 20 16:21:04 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 20 Dec 2006 16:21:04 -0500
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <BAY13-F23D190F26BB10D23A504158ECF0@phx.gbl>
References: <BAY13-F23D190F26BB10D23A504158ECF0@phx.gbl>
Message-ID: <4589A940.10501@quiotix.com>

> Please clear up something about the proper use of volatile for me. I'm 
> having difficulty understanding when volatile is sufficent. 

I'd add to this discussion that if in doubt, steer away from volatile. 
Except for very simple cases (such as "public volatile boolean 
shutdownRequested"), it is tricky to get right.

From ckessel at c-cor.com  Wed Dec 20 16:27:45 2006
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 20 Dec 2006 13:27:45 -0800
Subject: [concurrency-interest] Basic thread safety
	question:	final/volatile/synchronized fields
Message-ID: <FB46E3318E86BD40862DDB4DE178A737336E84@beomail1.NTSCD.C-COR.com>

>The field x is accessed in a thread-safe manner in Moo, but the class 
>Foo is not thread-safe.  The thread-safety is provided by the locking
in 
>Moo.

Ah, good point.  An external class can provide the thread safety
(client-side locking I think was the JCiP term?).

But, good to know I understand correctly.  The reason I questioned
myself was that I've seen precious few thread safe classes. I've rarely,
if ever, seen much attention paid to making sure each instance field is
properly protected.  A few assessors might be synchronized, but the
thread-safety considerations are ad-hoc at best.

Chris



From ckessel at c-cor.com  Wed Dec 20 16:31:56 2006
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 20 Dec 2006 13:31:56 -0800
Subject: [concurrency-interest] Volatile / Sychronized?
Message-ID: <FB46E3318E86BD40862DDB4DE178A737336E85@beomail1.NTSCD.C-COR.com>

I have various POJO's that I've just used volatile on and skipped
synchronization, except in the few instances where 2+ fields are always
changed at the same time.

Wouldn't volatile be sufficient in that case? My only real concern is
avoiding stale reads.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Brian
Goetz
Sent: Wednesday, December 20, 2006 1:21 PM
To: First Last
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Volatile / Sychronized?

> Please clear up something about the proper use of volatile for me. I'm

> having difficulty understanding when volatile is sufficent. 

I'd add to this discussion that if in doubt, steer away from volatile. 
Except for very simple cases (such as "public volatile boolean 
shutdownRequested"), it is tricky to get right.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



From Richie.Jefts at APCC.com  Wed Dec 20 16:41:27 2006
From: Richie.Jefts at APCC.com (Richie.Jefts at APCC.com)
Date: Wed, 20 Dec 2006 15:41:27 -0600
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E85@beomail1.NTSCD.C-COR.com>
Message-ID: <OFD8517012.F7CD7701-ON8525724A.0076BA52-8625724A.0076D575@apcc.com>

It depends on whether the fields in question are exclusive to each other. 
But if one variable is not dependent on another, volatile should be 
sufficient.

class Foo {
        private volatile int x;
        private volatile int y;

        public int getX() {
                return x;
        }

        public int getY() {
                return y;
        }

        public synchronized void set(int x, int y) {
                this.x = x;
                this.y = y;
        }
}

In this example, the setting of (x,y) is an atomic operation, but the 
reading of these values is not. A thread calling getX() could read a new 
value of x before the "this.y = y" occurs and therefore break the contract 
of class Foo.

richie




"Kessel, Chris" <ckessel at c-cor.com> 
Sent by: concurrency-interest-bounces at cs.oswego.edu
12/20/2006 03:31 PM

To
"Brian Goetz" <brian at quiotix.com>, "First Last" <chancer357 at hotmail.com>
cc
concurrency-interest at cs.oswego.edu
Subject
Re: [concurrency-interest] Volatile / Sychronized?






I have various POJO's that I've just used volatile on and skipped
synchronization, except in the few instances where 2+ fields are always
changed at the same time.

Wouldn't volatile be sufficient in that case? My only real concern is
avoiding stale reads.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Brian
Goetz
Sent: Wednesday, December 20, 2006 1:21 PM
To: First Last
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Volatile / Sychronized?

> Please clear up something about the proper use of volatile for me. I'm

> having difficulty understanding when volatile is sufficent. 

I'd add to this discussion that if in doubt, steer away from volatile. 
Except for very simple cases (such as "public volatile boolean 
shutdownRequested"), it is tricky to get right.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061220/50f014d2/attachment-0001.html 

From brian at quiotix.com  Wed Dec 20 16:55:07 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 20 Dec 2006 16:55:07 -0500
Subject: [concurrency-interest] Volatile / Sychronized?
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E85@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E85@beomail1.NTSCD.C-COR.com>
Message-ID: <4589B13B.5050709@quiotix.com>

So long as the fields do not participate in invariants with any other 
variables, and they have no state transitions where their new value 
depends on their old value (counters would not pass this requirement), 
then yes.

Kessel, Chris wrote:
> I have various POJO's that I've just used volatile on and skipped
> synchronization, except in the few instances where 2+ fields are always
> changed at the same time.
> 
> Wouldn't volatile be sufficient in that case? My only real concern is
> avoiding stale reads.
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Brian
> Goetz
> Sent: Wednesday, December 20, 2006 1:21 PM
> To: First Last
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Volatile / Sychronized?
> 
>> Please clear up something about the proper use of volatile for me. I'm
> 
>> having difficulty understanding when volatile is sufficent. 
> 
> I'd add to this discussion that if in doubt, steer away from volatile. 
> Except for very simple cases (such as "public volatile boolean 
> shutdownRequested"), it is tricky to get right.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From sberlin at gmail.com  Wed Dec 20 17:17:04 2006
From: sberlin at gmail.com (Sam Berlin)
Date: Wed, 20 Dec 2006 17:17:04 -0500
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
Message-ID: <19196d860612201417u306de727o4d0706a39c4adec0@mail.gmail.com>

Hi Folks,

We're interested in creating a ThreadPoolExecutor that lives with zero
live threads but will create a single thread and run any offered or
queued tasks when there are tasks to be run.  The rationale behind
this is to run occasional long-lived tasks that aren't time-critical
(and some requiring they be processed sequentially).  This is
different than the executor offered by Executors.singleThreadExecutor
because we don't want the thread it creates to live forever.

It appears that this is impossible, because using a core pool size of
0 causes no threads to ever be created.  (This is because of code in
execute(Runnable) that returns if poolSize < corePoolSize &&
addIfUnderCorePoolSize(runnable) both return true.
addIfUnderCorePoolSize doesn't add the thread because the core pool
size is 0, which the current size is not below.)

We unfortunately cannot use Java 1.6's corePoolSize timeout (which I
suspect would allow things to work by setting the core size to 1 and
adding a timeout).

Is there a way of doing this in Java 1.5?  Subclassing and adding
hooks will work fine, if it's possible to do it that way.

Thanks,
 Sam

From joe.bowbeer at gmail.com  Wed Dec 20 17:32:45 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 20 Dec 2006 14:32:45 -0800
Subject: [concurrency-interest] Basic thread safety question:
	final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
Message-ID: <31f2a7bd0612201432j154b6d67l56b0d9ebdfd3014b@mail.gmail.com>

On 12/20/06, Kessel, Chris <ckessel at c-cor.com> wrote:
>
> Is it correct to say that a thread safe class requires (though this is
> not necessarily sufficient) that every instance field be final,
> volatile, or accessed in synchronized blocks?
>

For objects that are not changed after they are constructed, "safe
publication" is sufficient.

Objects that are not changed after they are constructed come in two
flavors: those that can't be changed (aka immutable) and those that
could be changed but aren't (aka "effectively immutable").

Safe publication means transmitting the object to another thread by
means of a shared lock or volatile (that is, a "happens before"
relationship).

Passing an object through a thread-safe queue is a common means of
safe publication.

--Joe

From Ryan.LeCompte at pango.com  Wed Dec 20 17:43:48 2006
From: Ryan.LeCompte at pango.com (Ryan LeCompte)
Date: Wed, 20 Dec 2006 17:43:48 -0500
Subject: [concurrency-interest] Exposing self-references in constructors
References: <5F9C31E563BD404DB284240CAE7ACD52053409@pangomail2k3.pangonetworks.com>
Message-ID: <5F9C31E563BD404DB284240CAE7ACD5205340B@pangomail2k3.pangonetworks.com>

Hello all,
 
Here is a scenario:
 
- In Thread A's constructor, a reference to "this" is passed along which ultimately ends up stored as a reference in Thread B.
- Thread A's constructor completes and is fully instantiated.
- Thread B then is later executed (let's say restrained at 30 seconds later) -- and then uses the reference to Thread A that it was given in Thread A's constructor.
 
Is it possible that Thread B's reference to Thread A could be "stale" ? I'm not seeing that this is the case. I know that it's bad practice to hand off references to yourself before you are fully constructed, but in this paticular case I'd like to know if I'm "safe" if I have external time constraints that force Thread B to not read its reference to Thread A until a later time when Thread A has finished fully instantiating.
 
Also, what if Thread B is already executing and just operates on a an object instance that contains the reference stored in Thread A's constructor? Consider a scheduling framework where a  pool of threads are already instantiated and running, and simply periodically execute "work instances" that contain the logic to be executed. 
 
Thoughts?
 
Thanks
Ryan
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061220/cfaefdcd/attachment.html 

From brian at quiotix.com  Wed Dec 20 17:48:34 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 20 Dec 2006 17:48:34 -0500
Subject: [concurrency-interest] Basic thread
 safety	question:	final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E84@beomail1.NTSCD.C-COR.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E84@beomail1.NTSCD.C-COR.com>
Message-ID: <4589BDC2.8070004@quiotix.com>

> Ah, good point.  An external class can provide the thread safety
> (client-side locking I think was the JCiP term?).

In this case it would be called confinement -- the Foo is confined in 
the Moo, and Moo provides the right synchronization.

> But, good to know I understand correctly.  The reason I questioned
> myself was that I've seen precious few thread safe classes. I've rarely,
> if ever, seen much attention paid to making sure each instance field is
> properly protected.  A few assessors might be synchronized, but the
> thread-safety considerations are ad-hoc at best.

Sadly, yes.

From ckessel at c-cor.com  Wed Dec 20 17:54:15 2006
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 20 Dec 2006 14:54:15 -0800
Subject: [concurrency-interest] Basic thread safety
	question:final/volatile/synchronized fields
Message-ID: <FB46E3318E86BD40862DDB4DE178A737336E86@beomail1.NTSCD.C-COR.com>

>Safe publication means transmitting the object to another thread by
>means of a shared lock or volatile (that is, a "happens before"
>relationship).

>Passing an object through a thread-safe queue is a common means of
>safe publication.

This is where I commonly get confused because of reachability concerns,
such as your typical parent-child relationships.  If object A is
effectively immutable I understand it's published safely through a
thread-safe queue. But what about the references held by A?  If A has a
reference to B, is B also then considered to be safely published?

Chris


From dcholmes at optusnet.com.au  Wed Dec 20 18:36:53 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 09:36:53 +1000
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <19196d860612201417u306de727o4d0706a39c4adec0@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEKLHEAA.dcholmes@optusnet.com.au>

Sam,

I agree that there is no simple way to do this in the Java 5 TPE. Only
threads above "coreSize" have the idle-timeout that you are looking for, and
they are only created after the queue is full and that doesn't fit your
needs.

What is the problem with having the one thread live forever? If there is no
work for it then it consumes no CPU. If you are worried about application
termination and don't have a good hook at which to shutdown the pool then
define a ThreadFactory that provides a daemon thread. One thread should not
cause any resource issues.

Otherwise, you can always take the public domain version of the Java 6 TPE
and use that instead.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> Berlin
> Sent: Thursday, 21 December 2006 8:17 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
>
>
> Hi Folks,
>
> We're interested in creating a ThreadPoolExecutor that lives with zero
> live threads but will create a single thread and run any offered or
> queued tasks when there are tasks to be run.  The rationale behind
> this is to run occasional long-lived tasks that aren't time-critical
> (and some requiring they be processed sequentially).  This is
> different than the executor offered by Executors.singleThreadExecutor
> because we don't want the thread it creates to live forever.
>
> It appears that this is impossible, because using a core pool size of
> 0 causes no threads to ever be created.  (This is because of code in
> execute(Runnable) that returns if poolSize < corePoolSize &&
> addIfUnderCorePoolSize(runnable) both return true.
> addIfUnderCorePoolSize doesn't add the thread because the core pool
> size is 0, which the current size is not below.)
>
> We unfortunately cannot use Java 1.6's corePoolSize timeout (which I
> suspect would allow things to work by setting the core size to 1 and
> adding a timeout).
>
> Is there a way of doing this in Java 1.5?  Subclassing and adding
> hooks will work fine, if it's possible to do it that way.
>
> Thanks,
>  Sam
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dcholmes at optusnet.com.au  Wed Dec 20 18:41:29 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 09:41:29 +1000
Subject: [concurrency-interest] Exposing self-references in constructors
In-Reply-To: <5F9C31E563BD404DB284240CAE7ACD5205340B@pangomail2k3.pangonetworks.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEKMHEAA.dcholmes@optusnet.com.au>

When you say thread B is "later executed" do you mean start() is called
later? and by the thread that constructed A? There is a happens-before
relationship between the start() of a thread and the first action of that
thread.

Otherwise it all depends on the exact call sequence and what threads are
involved.

There are a number of implicit synchronization actions that occur when
creating and starting threads that could impose the right happens-before
relationships - eg. synchronization when adding to the thread group.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan
LeCompte
  Sent: Thursday, 21 December 2006 8:44 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Exposing self-references in constructors


  Hello all,

  Here is a scenario:

  - In Thread A's constructor, a reference to "this" is passed along which
ultimately ends up stored as a reference in Thread B.
  - Thread A's constructor completes and is fully instantiated.
  - Thread B then is later executed (let's say restrained at 30 seconds
later) -- and then uses the reference to Thread A that it was given in
Thread A's constructor.

  Is it possible that Thread B's reference to Thread A could be "stale" ?
I'm not seeing that this is the case. I know that it's bad practice to hand
off references to yourself before you are fully constructed, but in this
paticular case I'd like to know if I'm "safe" if I have external time
constraints that force Thread B to not read its reference to Thread A until
a later time when Thread A has finished fully instantiating.

  Also, what if Thread B is already executing and just operates on a an
object instance that contains the reference stored in Thread A's
constructor? Consider a scheduling framework where a  pool of threads are
already instantiated and running, and simply periodically execute "work
instances" that contain the logic to be executed.

  Thoughts?

  Thanks
  Ryan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061221/c8e0e829/attachment-0001.html 

From dcholmes at optusnet.com.au  Wed Dec 20 18:45:48 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 09:45:48 +1000
Subject: [concurrency-interest] Basic thread
	safetyquestion:final/volatile/synchronized fields
In-Reply-To: <FB46E3318E86BD40862DDB4DE178A737336E86@beomail1.NTSCD.C-COR.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEKMHEAA.dcholmes@optusnet.com.au>

Chris,

> >Passing an object through a thread-safe queue is a common means of
> >safe publication.
>
> This is where I commonly get confused because of reachability concerns,
> such as your typical parent-child relationships.  If object A is
> effectively immutable I understand it's published safely through a
> thread-safe queue. But what about the references held by A?  If A has a
> reference to B, is B also then considered to be safely published?

Safe-publication is transitive (because happens-before is transitive) as
long as construction happens correctly. Eg:

 construct B
 construct A, storing reference to B
 safely-publish A
 get B

works fine as B was also safely published as the construction of B happend
before the construction of A which happened-before the use of B by virtue of
safe-publication.

Of course if you mutate B, or change the B reference in A, after the
publication then that actin must itself be synchronized.

Cheers,
David Holmes


From dcholmes at optusnet.com.au  Wed Dec 20 18:48:56 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 09:48:56 +1000
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEKLHEAA.dcholmes@optusnet.com.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKNHEAA.dcholmes@optusnet.com.au>

Correction: making the thread a daemon isn't necessarily the right thing if
you want it to clear the queue before the application terminates. In that
case you'd need explicit lifecycle management to shutdown the pool.

David

David Holmes wrote:
>
> Sam,
>
> I agree that there is no simple way to do this in the Java 5 TPE. Only
> threads above "coreSize" have the idle-timeout that you are
> looking for, and
> they are only created after the queue is full and that doesn't fit your
> needs.
>
> What is the problem with having the one thread live forever? If
> there is no
> work for it then it consumes no CPU. If you are worried about application
> termination and don't have a good hook at which to shutdown the pool then
> define a ThreadFactory that provides a daemon thread. One thread
> should not
> cause any resource issues.
>
> Otherwise, you can always take the public domain version of the Java 6 TPE
> and use that instead.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> > Berlin
> > Sent: Thursday, 21 December 2006 8:17 AM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
> >
> >
> > Hi Folks,
> >
> > We're interested in creating a ThreadPoolExecutor that lives with zero
> > live threads but will create a single thread and run any offered or
> > queued tasks when there are tasks to be run.  The rationale behind
> > this is to run occasional long-lived tasks that aren't time-critical
> > (and some requiring they be processed sequentially).  This is
> > different than the executor offered by Executors.singleThreadExecutor
> > because we don't want the thread it creates to live forever.
> >
> > It appears that this is impossible, because using a core pool size of
> > 0 causes no threads to ever be created.  (This is because of code in
> > execute(Runnable) that returns if poolSize < corePoolSize &&
> > addIfUnderCorePoolSize(runnable) both return true.
> > addIfUnderCorePoolSize doesn't add the thread because the core pool
> > size is 0, which the current size is not below.)
> >
> > We unfortunately cannot use Java 1.6's corePoolSize timeout (which I
> > suspect would allow things to work by setting the core size to 1 and
> > adding a timeout).
> >
> > Is there a way of doing this in Java 1.5?  Subclassing and adding
> > hooks will work fine, if it's possible to do it that way.
> >
> > Thanks,
> >  Sam
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dhanji at gmail.com  Wed Dec 20 19:13:30 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 21 Dec 2006 10:13:30 +1000
Subject: [concurrency-interest] Exposing self-references in constructors
In-Reply-To: <5F9C31E563BD404DB284240CAE7ACD5205340B@pangomail2k3.pangonetworks.com>
References: <5F9C31E563BD404DB284240CAE7ACD52053409@pangomail2k3.pangonetworks.com>
	<5F9C31E563BD404DB284240CAE7ACD5205340B@pangomail2k3.pangonetworks.com>
Message-ID: <aa067ea10612201613g7962e41fk6a18fc7393d4d2ec@mail.gmail.com>

30 seconds seems like enough time, but it is not a great way to ensure a
happens-before boundary. Why not start thread B but wait it on a gate until
thread a is done:

class B impls Runnable {

   public Semaphore isReady = new Semaphore(1, true);

   public B(A a) { .. } //ctor

   public void run() {
      isReady.acquire();  //blocks until A is ready
   }
}

class A impls Runnable {
    A() { //ctor
       B b = new B(this);

       b.isReady.acquire();  //takes first lock on B
       new Thread(b).start();  //start B but its now blocked coz we have its
semaphore down

       //finish my init work
       //..

       b.isReady.release();  //raise semaphore--ensures B starts sometime
AFTER now
    }

}


Now whatever B does with its reference to A will be on a completely
constructed/initialized A.
Im sure you could work a similar scenario with j.u.c.Lock.

Also, what if Thread B is already executing and just operates on a an object
instance that contains the reference stored in Thread A's constructor?


Not too sure what you mean exactly. Do you mean the work instances will
control thread A's state? Or just work on each other? If the latter, you can
use a similar mutex scenario to the one I described above to prevent
"incomplete" instances from being read/mutated by other threads.

Dhanji.


On 12/21/06, Ryan LeCompte <Ryan.LeCompte at pango.com> wrote:
>
>  Hello all,
>
> Here is a scenario:
>
> - In Thread A's constructor, a reference to "this" is passed along which
> ultimately ends up stored as a reference in Thread B.
> - Thread A's constructor completes and is fully instantiated.
> - Thread B then is later executed (let's say restrained at 30 seconds
> later) -- and then uses the reference to Thread A that it was given in
> Thread A's constructor.
>
> Is it possible that Thread B's reference to Thread A could be "stale" ?
> I'm not seeing that this is the case. I know that it's bad practice to hand
> off references to yourself before you are fully constructed, but in this
> paticular case I'd like to know if I'm "safe" if I have external time
> constraints that force Thread B to not read its reference to Thread A until
> a later time when Thread A has finished fully instantiating.
>
> Also, what if Thread B is already executing and just operates on a an
> object instance that contains the reference stored in Thread A's
> constructor? Consider a scheduling framework where a  pool of threads are
> already instantiated and running, and simply periodically execute "work
> instances" that contain the logic to be executed.
>
> Thoughts?
>
> Thanks
> Ryan
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061221/b8efc73c/attachment.html 

From sberlin at gmail.com  Wed Dec 20 19:17:42 2006
From: sberlin at gmail.com (Sam Berlin)
Date: Wed, 20 Dec 2006 19:17:42 -0500
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEKLHEAA.dcholmes@optusnet.com.au>
References: <19196d860612201417u306de727o4d0706a39c4adec0@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEKLHEAA.dcholmes@optusnet.com.au>
Message-ID: <19196d860612201617y16dd6ed7w822190afbd07d23@mail.gmail.com>

Hi David,

We're designing this to be a general purpose construct for any part of
the application that needs to do sequential asynchronous processing.
This could be for HTTP GET requests to servers, writing / reading to /
from disk, DNS lookups, or any other potentially long-lived task.
Each part of the program (LimeWire, in this case) needs its own
executor to be sure another part isn't holding the executor-thread
hostage.  We did this previously with a custom 'ProcessingQueue' (see:
<https://www.limewire.org/fisheye/browse/limecvs/core/com/limegroup/gnutella/util/ProcessingQueue.java?r=1.13>
), but have decided to make better use of the built-in concurrent
features (for better compatibility, etc..).

What this means is that there could potentially be many of these
executor objects, which makes the resource issue more of a problem.
It's also compounded by the fact that the application will run on
consumer-level machines, so the less resources used, the better.

Your suggestion of using the Java 6 TPE code is likely what we'll end
up doing.  Is the public domain version different from the one in the
Java 6 source?  Where would I go to find that version?

Thanks,
 Sam

On 12/20/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> Sam,
>
> I agree that there is no simple way to do this in the Java 5 TPE. Only
> threads above "coreSize" have the idle-timeout that you are looking for, and
> they are only created after the queue is full and that doesn't fit your
> needs.
>
> What is the problem with having the one thread live forever? If there is no
> work for it then it consumes no CPU. If you are worried about application
> termination and don't have a good hook at which to shutdown the pool then
> define a ThreadFactory that provides a daemon thread. One thread should not
> cause any resource issues.
>
> Otherwise, you can always take the public domain version of the Java 6 TPE
> and use that instead.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> > Berlin
> > Sent: Thursday, 21 December 2006 8:17 AM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
> >
> >
> > Hi Folks,
> >
> > We're interested in creating a ThreadPoolExecutor that lives with zero
> > live threads but will create a single thread and run any offered or
> > queued tasks when there are tasks to be run.  The rationale behind
> > this is to run occasional long-lived tasks that aren't time-critical
> > (and some requiring they be processed sequentially).  This is
> > different than the executor offered by Executors.singleThreadExecutor
> > because we don't want the thread it creates to live forever.
> >
> > It appears that this is impossible, because using a core pool size of
> > 0 causes no threads to ever be created.  (This is because of code in
> > execute(Runnable) that returns if poolSize < corePoolSize &&
> > addIfUnderCorePoolSize(runnable) both return true.
> > addIfUnderCorePoolSize doesn't add the thread because the core pool
> > size is 0, which the current size is not below.)
> >
> > We unfortunately cannot use Java 1.6's corePoolSize timeout (which I
> > suspect would allow things to work by setting the core size to 1 and
> > adding a timeout).
> >
> > Is there a way of doing this in Java 1.5?  Subclassing and adding
> > hooks will work fine, if it's possible to do it that way.
> >
> > Thanks,
> >  Sam
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From dcholmes at optusnet.com.au  Wed Dec 20 19:24:16 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 10:24:16 +1000
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <19196d860612201617y16dd6ed7w822190afbd07d23@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKOHEAA.dcholmes@optusnet.com.au>

Hi Sam,

> Your suggestion of using the Java 6 TPE code is likely what we'll end
> up doing.  Is the public domain version different from the one in the
> Java 6 source?  Where would I go to find that version?

The public domain version is here - see jsr166x:

http://gee.cs.oswego.edu/dl/concurrency-interest/index.html

It contains bug fixes that will eventually make their way into the Java 6
version.

Cheers,
David


From dhanji at gmail.com  Wed Dec 20 20:03:09 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 21 Dec 2006 11:03:09 +1000
Subject: [concurrency-interest] Basic thread safety question:
	final/volatile/synchronized fields
In-Reply-To: <4589BDC2.8070004@quiotix.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E84@beomail1.NTSCD.C-COR.com>
	<4589BDC2.8070004@quiotix.com>
Message-ID: <aa067ea10612201703v2b43f856if1514808060ed954@mail.gmail.com>

On 12/21/06, Brian Goetz <brian at quiotix.com> wrote:
>
> > Ah, good point.  An external class can provide the thread safety
> > (client-side locking I think was the JCiP term?).
>
> In this case it would be called confinement -- the Foo is confined in
> the Moo, and Moo provides the right synchronization.
>
> > But, good to know I understand correctly.  The reason I questioned
> > myself was that I've seen precious few thread safe classes. I've rarely,
> > if ever, seen much attention paid to making sure each instance field is
> > properly protected.  A few assessors might be synchronized, but the
> > thread-safety considerations are ad-hoc at best.
>
> Sadly, yes.


 Is it really? I would consider most code (to be very general about it) to
be service code (frameworks, sdks, Business APis, Daos, etc.), and it should
be upto clients to synchronize correctly.

For one specific instance: I'd much more readily use
java.util.ArrayListthan Vector even though the latter is threadsafe
and the former is not
(apart from the other benefits of the Java Collections Framework), and
synchronize in my client code.

And these days most code runs in some kind of container which provides
threading out of the box--whether it be EJB, a servlet container, Swing
workers or some abstraction of j.u.c TPEs.

I agree that sometimes client code is not synchronized properly (or at all),
but I find more often that service code is unnecessarily and improprietously
synchronized which can cause far greater headaches and portability issues.
Do you agree?

_______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061221/ccdb7079/attachment-0001.html 

From Ryan.LeCompte at pango.com  Wed Dec 20 20:05:01 2006
From: Ryan.LeCompte at pango.com (Ryan LeCompte)
Date: Wed, 20 Dec 2006 20:05:01 -0500
Subject: [concurrency-interest] Exposing self-references in constructors
References: <NFBBKALFDCPFIDBNKAPCEEKMHEAA.dcholmes@optusnet.com.au>
Message-ID: <5F9C31E563BD404DB284240CAE7ACD5205340C@pangomail2k3.pangonetworks.com>

David,
 
In this case thread B has already been created and executed (start()). So basically what happens is inside of the class's constructor (Executed by thread A), a reference to the instance (this) is passed to a new object that is constructed. This intermediate object (which contains a reference to the class instantiated by thead a) will later be "processed" by thread b (which has already been start()'ed). Sorry if I'm not doing a great job of explaining the situation. Here are the steps again:
 
1) Thread A (main thread) has been started.
2) Thread A (main thread) instantiates class Foo.
3) In Foo's constructor, it creates a new object (Bar) which contains a reference to Foo (Foo passes "this" to Bar in Foo's constructor).
    Also, not sure if it matters, but I have a single volatile variable that is assigned a value before Bar is instantiated.
4) At a later point (30 seconds, for example), Thread B (which has already been started before Foo is instantiated) operates on the Bar instance and uses the reference to Foo that it contains.
    To be specific in this step, it first synchronize()'s on the "Foo" instance that Bar has a reference to.
 
 
Hope this helps clarify the situation.
 
Ryan
 
 
--
Ryan LeCompte +1.508.626.8900 x227
      mobile +1.781.249.4009
         fax +1.508.626.8901

PanGo Networks, Inc.
www.pango.com

________________________________

From: David Holmes [mailto:dcholmes at optusnet.com.au]
Sent: Wed 12/20/2006 6:41 PM
To: Ryan LeCompte; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Exposing self-references in constructors


When you say thread B is "later executed" do you mean start() is called later? and by the thread that constructed A? There is a happens-before relationship between the start() of a thread and the first action of that thread.
 
Otherwise it all depends on the exact call sequence and what threads are involved. 
 
There are a number of implicit synchronization actions that occur when creating and starting threads that could impose the right happens-before relationships - eg. synchronization when adding to the thread group.
 
Cheers,
David Holmes

	-----Original Message-----
	From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan LeCompte
	Sent: Thursday, 21 December 2006 8:44 AM
	To: concurrency-interest at cs.oswego.edu
	Subject: [concurrency-interest] Exposing self-references in constructors
	
	
	Hello all,
	 
	Here is a scenario:
	 
	- In Thread A's constructor, a reference to "this" is passed along which ultimately ends up stored as a reference in Thread B.
	- Thread A's constructor completes and is fully instantiated.
	- Thread B then is later executed (let's say restrained at 30 seconds later) -- and then uses the reference to Thread A that it was given in Thread A's constructor.
	 
	Is it possible that Thread B's reference to Thread A could be "stale" ? I'm not seeing that this is the case. I know that it's bad practice to hand off references to yourself before you are fully constructed, but in this paticular case I'd like to know if I'm "safe" if I have external time constraints that force Thread B to not read its reference to Thread A until a later time when Thread A has finished fully instantiating.
	 
	Also, what if Thread B is already executing and just operates on a an object instance that contains the reference stored in Thread A's constructor? Consider a scheduling framework where a  pool of threads are already instantiated and running, and simply periodically execute "work instances" that contain the logic to be executed. 
	 
	Thoughts?
	 
	Thanks
	Ryan
	 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061220/69c77c0c/attachment.html 

From dcholmes at optusnet.com.au  Wed Dec 20 20:16:37 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 21 Dec 2006 11:16:37 +1000
Subject: [concurrency-interest] Exposing self-references in constructors
In-Reply-To: <5F9C31E563BD404DB284240CAE7ACD5205340C@pangomail2k3.pangonetworks.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKPHEAA.dcholmes@optusnet.com.au>

Ryan,

It isn't completely clear to me how the Foo and Bar are "published" such
that thread B gets to see them. A code skeleton would help.

In practical terms there is no chance that all memory accesses won't have
stabilized after thirty seconds. But that isn't the sort of thing one wants
to be relying on - if for nothing else than "time" isn't very visible when
code is being read by people or processed by tools. :)

Cheers,
David
  -----Original Message-----
  From: Ryan LeCompte [mailto:Ryan.LeCompte at pango.com]
  Sent: Thursday, 21 December 2006 11:05 AM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Exposing self-references in
constructors


  David,

  In this case thread B has already been created and executed (start()). So
basically what happens is inside of the class's constructor (Executed by
thread A), a reference to the instance (this) is passed to a new object that
is constructed. This intermediate object (which contains a reference to the
class instantiated by thead a) will later be "processed" by thread b (which
has already been start()'ed). Sorry if I'm not doing a great job of
explaining the situation. Here are the steps again:

  1) Thread A (main thread) has been started.
  2) Thread A (main thread) instantiates class Foo.
  3) In Foo's constructor, it creates a new object (Bar) which contains a
reference to Foo (Foo passes "this" to Bar in Foo's constructor).
      Also, not sure if it matters, but I have a single volatile variable
that is assigned a value before Bar is instantiated.
  4) At a later point (30 seconds, for example), Thread B (which has already
been started before Foo is instantiated) operates on the Bar instance and
uses the reference to Foo that it contains.
      To be specific in this step, it first synchronize()'s on the "Foo"
instance that Bar has a reference to.


  Hope this helps clarify the situation.

  Ryan


  --
  Ryan LeCompte +1.508.626.8900 x227
        mobile +1.781.249.4009
           fax +1.508.626.8901

  PanGo Networks, Inc.
  www.pango.com


----------------------------------------------------------------------------
--
  From: David Holmes [mailto:dcholmes at optusnet.com.au]
  Sent: Wed 12/20/2006 6:41 PM
  To: Ryan LeCompte; concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Exposing self-references in
constructors


  When you say thread B is "later executed" do you mean start() is called
later? and by the thread that constructed A? There is a happens-before
relationship between the start() of a thread and the first action of that
thread.

  Otherwise it all depends on the exact call sequence and what threads are
involved. 

  There are a number of implicit synchronization actions that occur when
creating and starting threads that could impose the right happens-before
relationships - eg. synchronization when adding to the thread group.

  Cheers,
  David Holmes
    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan
LeCompte
    Sent: Thursday, 21 December 2006 8:44 AM
    To: concurrency-interest at cs.oswego.edu
    Subject: [concurrency-interest] Exposing self-references in constructors


    Hello all,

    Here is a scenario:

    - In Thread A's constructor, a reference to "this" is passed along which
ultimately ends up stored as a reference in Thread B.
    - Thread A's constructor completes and is fully instantiated.
    - Thread B then is later executed (let's say restrained at 30 seconds
later) -- and then uses the reference to Thread A that it was given in
Thread A's constructor.

    Is it possible that Thread B's reference to Thread A could be "stale" ?
I'm not seeing that this is the case. I know that it's bad practice to hand
off references to yourself before you are fully constructed, but in this
paticular case I'd like to know if I'm "safe" if I have external time
constraints that force Thread B to not read its reference to Thread A until
a later time when Thread A has finished fully instantiating.

    Also, what if Thread B is already executing and just operates on a an
object instance that contains the reference stored in Thread A's
constructor? Consider a scheduling framework where a  pool of threads are
already instantiated and running, and simply periodically execute "work
instances" that contain the logic to be executed. 

    Thoughts?

    Thanks
    Ryan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061221/f765fb8f/attachment-0001.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 1176 bytes
Desc: not available
Url : /pipermail/attachments/20061221/f765fb8f/attachment-0001.bin 

From Ryan.LeCompte at pango.com  Wed Dec 20 20:23:23 2006
From: Ryan.LeCompte at pango.com (Ryan LeCompte)
Date: Wed, 20 Dec 2006 20:23:23 -0500
Subject: [concurrency-interest] Exposing self-references in constructors
References: <NFBBKALFDCPFIDBNKAPCCEKPHEAA.dcholmes@optusnet.com.au>
Message-ID: <5F9C31E563BD404DB284240CAE7ACD5205340D@pangomail2k3.pangonetworks.com>

David,
 
Unfortunately I think the example is a bit too convoluted to try and provide a code skeleton here. I think the main idea here is that a happens-before relationship needs to occur before the other thread actually begins execution/processing on "Bar". I'll look into this further.
 
Thanks,
Ryan

________________________________

From: David Holmes [mailto:dcholmes at optusnet.com.au]
Sent: Wed 12/20/2006 8:16 PM
To: Ryan LeCompte; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Exposing self-references in constructors


Ryan,
 
It isn't completely clear to me how the Foo and Bar are "published" such that thread B gets to see them. A code skeleton would help.
 
In practical terms there is no chance that all memory accesses won't have stabilized after thirty seconds. But that isn't the sort of thing one wants to be relying on - if for nothing else than "time" isn't very visible when code is being read by people or processed by tools. :)
 
Cheers,
David

	-----Original Message-----
	From: Ryan LeCompte [mailto:Ryan.LeCompte at pango.com]
	Sent: Thursday, 21 December 2006 11:05 AM
	To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
	Subject: RE: [concurrency-interest] Exposing self-references in constructors
	
	
	David,
	 
	In this case thread B has already been created and executed (start()). So basically what happens is inside of the class's constructor (Executed by thread A), a reference to the instance (this) is passed to a new object that is constructed. This intermediate object (which contains a reference to the class instantiated by thead a) will later be "processed" by thread b (which has already been start()'ed). Sorry if I'm not doing a great job of explaining the situation. Here are the steps again:
	 
	1) Thread A (main thread) has been started.
	2) Thread A (main thread) instantiates class Foo.
	3) In Foo's constructor, it creates a new object (Bar) which contains a reference to Foo (Foo passes "this" to Bar in Foo's constructor).
	    Also, not sure if it matters, but I have a single volatile variable that is assigned a value before Bar is instantiated.
	4) At a later point (30 seconds, for example), Thread B (which has already been started before Foo is instantiated) operates on the Bar instance and uses the reference to Foo that it contains.
	    To be specific in this step, it first synchronize()'s on the "Foo" instance that Bar has a reference to.
	 
	 
	Hope this helps clarify the situation.
	 
	Ryan
	 
	 
	--
	Ryan LeCompte +1.508.626.8900 x227
	      mobile +1.781.249.4009
	         fax +1.508.626.8901
	
	PanGo Networks, Inc.
	www.pango.com

________________________________

	From: David Holmes [mailto:dcholmes at optusnet.com.au]
	Sent: Wed 12/20/2006 6:41 PM
	To: Ryan LeCompte; concurrency-interest at cs.oswego.edu
	Subject: RE: [concurrency-interest] Exposing self-references in constructors
	
	
	When you say thread B is "later executed" do you mean start() is called later? and by the thread that constructed A? There is a happens-before relationship between the start() of a thread and the first action of that thread.
	 
	Otherwise it all depends on the exact call sequence and what threads are involved. 
	 
	There are a number of implicit synchronization actions that occur when creating and starting threads that could impose the right happens-before relationships - eg. synchronization when adding to the thread group.
	 
	Cheers,
	David Holmes

		-----Original Message-----
		From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan LeCompte
		Sent: Thursday, 21 December 2006 8:44 AM
		To: concurrency-interest at cs.oswego.edu
		Subject: [concurrency-interest] Exposing self-references in constructors
		
		
		Hello all,
		 
		Here is a scenario:
		 
		- In Thread A's constructor, a reference to "this" is passed along which ultimately ends up stored as a reference in Thread B.
		- Thread A's constructor completes and is fully instantiated.
		- Thread B then is later executed (let's say restrained at 30 seconds later) -- and then uses the reference to Thread A that it was given in Thread A's constructor.
		 
		Is it possible that Thread B's reference to Thread A could be "stale" ? I'm not seeing that this is the case. I know that it's bad practice to hand off references to yourself before you are fully constructed, but in this paticular case I'd like to know if I'm "safe" if I have external time constraints that force Thread B to not read its reference to Thread A until a later time when Thread A has finished fully instantiating.
		 
		Also, what if Thread B is already executing and just operates on a an object instance that contains the reference stored in Thread A's constructor? Consider a scheduling framework where a  pool of threads are already instantiated and running, and simply periodically execute "work instances" that contain the logic to be executed. 
		 
		Thoughts?
		 
		Thanks
		Ryan
		 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061220/033838c4/attachment.html 

From conivek at gmail.com  Thu Dec 21 09:11:00 2006
From: conivek at gmail.com (Kevin Condon)
Date: Thu, 21 Dec 2006 09:11:00 -0500
Subject: [concurrency-interest] Unreported RuntimeException if Future.get()
	is never invoked
Message-ID: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>

If you use ExecutorService.submit() to start a task, but you never
invoke the returned Future's get(), then you'll never see any evidence
of RuntimeExceptions thrown during task execution.  Undetected
exceptions are bad and it was pretty difficult to figure out what was
happening in my own code.  I'm currently correcting several places in
our codebase where this vulnerability exists and thought it might be a
public service to point out to others the pit I fell into.  :)

There are a variety of reasons that you want a Future but may never
invoke get().  One situation where this could happen is a concurrent
task with a cancel option, so you only need the Future for the cancel.
 Here is a skeleton example:

public class CancellableTask implements Runnable {
  private final ExecutorService exec;
  private volatile Future<?> future = null;

  public CancellableTask(ExecutorService exec) {
    this.exec = exec;
  }

  public void execute() {
    // example ignores race on future for concurrent task executions
    future = exec.submit(this);
  }

  public void cancel() {
    if (future != null) {
      future.cancel(true);
    }
  }

  public void run() {
    boolean error = false;
    // work to be done ...
    if (error) {
      // this will not be logged!!!!
      throw IllegalStateException("Secret exception");
    }
  }
}

A co-worker and I, JCiP in hand, discovered that the solution to this
is to extend FutureTask overriding the done() hook to check/log the
exception and then use exec.execute(futureTask) instead of
submit(this).  To do this, change the execute() method:

  public void execute() {
    FutureTask<?> futureTask = new FutureTask<?>(this, null) {
      protected void done() {
        try {
          get();
        } catch (ExecutionException ex) {
          ex.getCause().printStackTrace();  // logging or handling of
your choice
        } catch (CancellationException ex) {
          // ignore unless you want to log task cancellation here
        } catch (InterruptedException ex) {
          // ignore; we're done, so get() won't block or be interrupted
        }
      }
    };
    future = futureTask;
    exec.execute(futureTask);
  }

Hope this helps someone to avoid stumbling into this, because without
knowing this can happen the problem can go entirely unnoticed.

Regards,
Kevin

From tim at peierls.net  Thu Dec 21 12:00:52 2006
From: tim at peierls.net (Tim Peierls)
Date: Thu, 21 Dec 2006 12:00:52 -0500
Subject: [concurrency-interest] Unreported RuntimeException if
	Future.get() is never invoked
In-Reply-To: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>
References: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>
Message-ID: <63b4e4050612210900u57fabb4w4646a8e739d3ae67@mail.gmail.com>

It's a minor point, but I think it would be better to restore the interrupt
flag in the IE catch clause in your example, with

Thread.currentThread().interrupt();

Without this, if you run your FutureTask directly with ft.run(), an
interrupt of the current thread might be lost. I know that your intent is to
confine this FutureTask to the execute() call, but now you have an extra
constraint that maintainers of your code need to think about -- and what if
the ExecutorService implementation passed to the CancellableTask constructor
isn't as well-behaved as TPE? It's safer to abide by the interrupt handling
golden rule: propagate by throwing or restore the interrupt status.


Another way to handle unchecked exceptions and errors thrown by Runnables is
to wrap each submitted Runnable with a try-catch block. For example (off the
top of my head, uncompiled):

interface UncheckedHandler {
    caughtRuntimeException(Runnable r, RuntimeException e);
    caughtError(Runnable r, Error e);
}

class UncheckedHandlingTask implements Runnable {
    private final Runnable task;
    private final UncheckedHandler handler;

    public UncheckedHandlingTask(Runnable task, UncheckedHandler handler) {
        this.task = task;
        this.handler = handler;
    }

    public void run() {
        try {
            task.run ();
        } catch (RuntimeException e) {
            handler.caughtRuntimeException(task, e);
            throw e;
        } catch (Error e) {
            handler.caughtError(task, e);
            throw e;
        }
    }
}

In Java 6, you can override the newTaskFor method of TPE (from
AbstractExecutorService) to perform this wrapping automatically, which
effectively gives you the ability to bind unchecked exception and error
handling behavior to a TPE instance.

In Java 5, you can get the same effect by wrapping your ExecutorService in
an AbstractExecutorService that wraps submitted Runnables and delegates to
the TPE.

Still another approach is to override TPE's afterExecute method. This is
simpler than wrapping Runnables, but the approach in the preceding paragraph
can be applied to any ExecutorService, not just TPE.

--tim

On 12/21/06, Kevin Condon <conivek at gmail.com> wrote:
>
> A co-worker and I, JCiP in hand, discovered that the solution to this
> is to extend FutureTask overriding the done() hook to check/log the
> exception and then use exec.execute(futureTask) instead of
> submit(this).  To do this, change the execute() method:
>
>   public void execute() {
>     FutureTask<?> futureTask = new FutureTask<?>(this, null) {
>       protected void done() {
>         try {
>           get();
>         } catch (ExecutionException ex) {
>           ex.getCause().printStackTrace();  // logging or handling of your
> choice
>         } catch (CancellationException ex) {
>           // ignore unless you want to log task cancellation here
>         } catch (InterruptedException ex) {
>           // ignore; we're done, so get() won't block or be interrupted
>         }
>       }
>     };
>     future = futureTask;
>     exec.execute(futureTask);
>   }
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061221/3fb936eb/attachment.html 

From sberlin at gmail.com  Thu Dec 21 13:49:24 2006
From: sberlin at gmail.com (Sam Berlin)
Date: Thu, 21 Dec 2006 13:49:24 -0500
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKOHEAA.dcholmes@optusnet.com.au>
References: <19196d860612201617y16dd6ed7w822190afbd07d23@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEKOHEAA.dcholmes@optusnet.com.au>
Message-ID: <19196d860612211049p58951db6ycec5c3896393610a@mail.gmail.com>

Thanks for the pointer to the code.  One minor problem with copying
the code as-is is the signature of RejectedExecutionHandler's reject
method takes a Runnable and a ThreadPoolExecutor.  If possible, we
would like to allow pre-existing RejectedExecutionHandlers (that is,
ones written with java.util.concurrent.ThreadPoolExecutor in mind) to
continue being used.  Do you expect there'll be any problems with
altering the copy to extend from
java.util.concurrent.ThreadPoolExecutor instead of
AbstractExecutorService?  It has the side-effect of duplicating all
the state variables of the super's ThreadPoolExecutor, but that's not
as large a problem as, say, accidentally firing a method from the
super's class instead of the current one.

Thanks,
 Sam

On 12/20/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> Hi Sam,
>
> > Your suggestion of using the Java 6 TPE code is likely what we'll end
> > up doing.  Is the public domain version different from the one in the
> > Java 6 source?  Where would I go to find that version?
>
> The public domain version is here - see jsr166x:
>
> http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
>
> It contains bug fixes that will eventually make their way into the Java 6
> version.
>
> Cheers,
> David
>
>

From dcholmes at optusnet.com.au  Thu Dec 21 20:50:43 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 22 Dec 2006 11:50:43 +1000
Subject: [concurrency-interest] ThreadPoolExecutor with corePoolSize = 0
In-Reply-To: <19196d860612211049p58951db6ycec5c3896393610a@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMELEHEAA.dcholmes@optusnet.com.au>

Sam,

I think what you propose will work, but as I haven't tried it ...

The other option, if you control the deployment is to place the Java 6
version on the bootclasspath to override the Java 5 version.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> Berlin
> Sent: Friday, 22 December 2006 4:49 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ThreadPoolExecutor with corePoolSize
> = 0
>
>
> Thanks for the pointer to the code.  One minor problem with copying
> the code as-is is the signature of RejectedExecutionHandler's reject
> method takes a Runnable and a ThreadPoolExecutor.  If possible, we
> would like to allow pre-existing RejectedExecutionHandlers (that is,
> ones written with java.util.concurrent.ThreadPoolExecutor in mind) to
> continue being used.  Do you expect there'll be any problems with
> altering the copy to extend from
> java.util.concurrent.ThreadPoolExecutor instead of
> AbstractExecutorService?  It has the side-effect of duplicating all
> the state variables of the super's ThreadPoolExecutor, but that's not
> as large a problem as, say, accidentally firing a method from the
> super's class instead of the current one.
>
> Thanks,
>  Sam
>
> On 12/20/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> > Hi Sam,
> >
> > > Your suggestion of using the Java 6 TPE code is likely what we'll end
> > > up doing.  Is the public domain version different from the one in the
> > > Java 6 source?  Where would I go to find that version?
> >
> > The public domain version is here - see jsr166x:
> >
> > http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
> >
> > It contains bug fixes that will eventually make their way into
> the Java 6
> > version.
> >
> > Cheers,
> > David
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dcholmes at optusnet.com.au  Thu Dec 21 21:05:46 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 22 Dec 2006 12:05:46 +1000
Subject: [concurrency-interest] Unreported RuntimeException if
	Future.get()is never invoked
In-Reply-To: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGELFHEAA.dcholmes@optusnet.com.au>

A number of people get tripped up over FutureTask not allowing there to be
any uncaught exceptions. This is a problem when they are used certain ways.
The basic issue is that anytime you invoke an API that will execute a "task"
for you then you also would like to be able to specify what to do if the
task throws any exceptions.

The most flexible approach would allow you to specify a different handler
per task:

  public void execute(Runnable r, UncaughtExceptionHander ueh)

where the UEH would have a handleException method that takes the Runnable
and the Throwable, similar to the existing Thread based UEH mechanism.

I'm not aware of any framework that goes to this much trouble. It is a
little cumbersome and unfortunately it is probably too late to redefine UEH
to use Runnable rather than Thread.

So a second approach is to have the execution framework provide an "uncaught
exception handling" mechanism. This is less flexible as it tends to provide
a handler per Executor and that only works well when the executor is
executing homogenous work.

The third approach is to recognize that given the first approach is too
cumbersome, and the second is too inflexible, then there isn't a general
solution for the framework so you throw the onus back onto the definer of
the tasks themselves. After all these should be the people that know how
they would like uncaught exceptions handled. So you can do this yourself
with a custom Runnable. Or we did this with FutureTask.

The problem then is that once we have adopted this
task-based-uncaught-exception-handling policy, if you actually want a
per-Executor policy then you either need to ensure you only get tasks that
don't handle the exceptions themselves (ie don't use FutureTask - not an
option in Java 5), or you have to provide work-arounds in the executor to
extract the exception information from the tasks - as per your proposal.

Personally I think the best solution is the cumbersome one: have the ability
to define a per-task UEH, combined with a default per-executor UEH, similar
to how we do the Thread UEH. But that would still require an alternative
FutureTask implementation to not handle the exceptions itself. And of course
there is nothing you can do about the end tasks catching everything
themselves anyway.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Kevin
> Condon
> Sent: Friday, 22 December 2006 12:11 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Unreported RuntimeException if
> Future.get()is never invoked
>
>
> If you use ExecutorService.submit() to start a task, but you never
> invoke the returned Future's get(), then you'll never see any evidence
> of RuntimeExceptions thrown during task execution.  Undetected
> exceptions are bad and it was pretty difficult to figure out what was
> happening in my own code.  I'm currently correcting several places in
> our codebase where this vulnerability exists and thought it might be a
> public service to point out to others the pit I fell into.  :)
>
> There are a variety of reasons that you want a Future but may never
> invoke get().  One situation where this could happen is a concurrent
> task with a cancel option, so you only need the Future for the cancel.
>  Here is a skeleton example:
>
> public class CancellableTask implements Runnable {
>   private final ExecutorService exec;
>   private volatile Future<?> future = null;
>
>   public CancellableTask(ExecutorService exec) {
>     this.exec = exec;
>   }
>
>   public void execute() {
>     // example ignores race on future for concurrent task executions
>     future = exec.submit(this);
>   }
>
>   public void cancel() {
>     if (future != null) {
>       future.cancel(true);
>     }
>   }
>
>   public void run() {
>     boolean error = false;
>     // work to be done ...
>     if (error) {
>       // this will not be logged!!!!
>       throw IllegalStateException("Secret exception");
>     }
>   }
> }
>
> A co-worker and I, JCiP in hand, discovered that the solution to this
> is to extend FutureTask overriding the done() hook to check/log the
> exception and then use exec.execute(futureTask) instead of
> submit(this).  To do this, change the execute() method:
>
>   public void execute() {
>     FutureTask<?> futureTask = new FutureTask<?>(this, null) {
>       protected void done() {
>         try {
>           get();
>         } catch (ExecutionException ex) {
>           ex.getCause().printStackTrace();  // logging or handling of
> your choice
>         } catch (CancellationException ex) {
>           // ignore unless you want to log task cancellation here
>         } catch (InterruptedException ex) {
>           // ignore; we're done, so get() won't block or be interrupted
>         }
>       }
>     };
>     future = futureTask;
>     exec.execute(futureTask);
>   }
>
> Hope this helps someone to avoid stumbling into this, because without
> knowing this can happen the problem can go entirely unnoticed.
>
> Regards,
> Kevin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From joe.bowbeer at gmail.com  Fri Dec 22 03:20:16 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 22 Dec 2006 00:20:16 -0800
Subject: [concurrency-interest] Unreported RuntimeException if
	Future.get() is never invoked
In-Reply-To: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>
References: <2e780ac60612210611s3ac945ecrd17c9a24fe142945@mail.gmail.com>
Message-ID: <31f2a7bd0612220020t3b209f6cwf2f70a10838f62a6@mail.gmail.com>

Based on the snippet you provided, it may be simpler to extend
FutureTask at the outer level:

public class MyTask<V> extends FutureTask<V> {
  public void execute() {
    exec.execute(this);
  }
  protected void done() {
    // log failures here...
  }
}


On 12/21/06, Kevin Condon <conivek at gmail.com> wrote:
>
> There are a variety of reasons that you want a Future but may never
> invoke get().  One situation where this could happen is a concurrent
> task with a cancel option, so you only need the Future for the cancel.
>  Here is a skeleton example:
>
> public class CancellableTask implements Runnable {
>   private final ExecutorService exec;
>   private volatile Future<?> future = null;
>
>   public CancellableTask(ExecutorService exec) {
>     this.exec = exec;
>   }
>
>   public void execute() {
>     // example ignores race on future for concurrent task executions
>     future = exec.submit(this);
>   }
>
>   public void cancel() {
>     if (future != null) {
>       future.cancel(true);
>     }
>   }
>
>   public void run() {
>     boolean error = false;
>     // work to be done ...
>     if (error) {
>       // this will not be logged!!!!
>       throw IllegalStateException("Secret exception");
>     }
>   }
> }
>
> A co-worker and I, JCiP in hand, discovered that the solution to this
> is to extend FutureTask overriding the done() hook to check/log the
> exception and then use exec.execute(futureTask) instead of
> submit(this).  To do this, change the execute() method:
>
>   public void execute() {
>     FutureTask<?> futureTask = new FutureTask<?>(this, null) {
>       protected void done() {
>         try {
>           get();
>         } catch (ExecutionException ex) {
>           ex.getCause().printStackTrace();
>         } catch (CancellationException ex) {
>           // ignore unless you want to log task cancellation here
>         } catch (InterruptedException ex) {
>           // ignore; we're done, so get() won't block or be interrupted
>         }
>       }
>     };
>     future = futureTask;
>     exec.execute(futureTask);
>   }
>

From tnentwig at verisign.com  Fri Dec 22 07:44:48 2006
From: tnentwig at verisign.com (Timo Nentwig)
Date: Fri, 22 Dec 2006 13:44:48 +0100
Subject: [concurrency-interest] Basic thread safety
 question:	final/volatile/synchronized fields
In-Reply-To: <31f2a7bd0612201432j154b6d67l56b0d9ebdfd3014b@mail.gmail.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
	<31f2a7bd0612201432j154b6d67l56b0d9ebdfd3014b@mail.gmail.com>
Message-ID: <458BD340.8020204@verisign.com>

Joe Bowbeer wrote:
> Objects that are not changed after they are constructed come in two
> flavors: those that can't be changed (aka immutable) and those that
> could be changed but aren't (aka "effectively immutable").
> 
> Safe publication means transmitting the object to another thread by
> means of a shared lock or volatile (that is, a "happens before"
> relationship).
> 
> Passing an object through a thread-safe queue is a common means of
> safe publication.

Sorry, I'm not sure whether I understood this properly: The "effectively
mutable" case actually is thread-safe or is explicitly neccessary that a
field is declared final to be thread-safe (and if so why is it)?

From joe.bowbeer at gmail.com  Fri Dec 22 13:21:12 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 22 Dec 2006 10:21:12 -0800
Subject: [concurrency-interest] Basic thread safety question:
	final/volatile/synchronized fields
In-Reply-To: <458BD340.8020204@verisign.com>
References: <FB46E3318E86BD40862DDB4DE178A737336E81@beomail1.NTSCD.C-COR.com>
	<31f2a7bd0612201432j154b6d67l56b0d9ebdfd3014b@mail.gmail.com>
	<458BD340.8020204@verisign.com>
Message-ID: <31f2a7bd0612221021x29ac01e1i5453cc3dccb6f953@mail.gmail.com>

On 12/22/06, Timo Nentwig <tnentwig at verisign.com> wrote:
> Joe Bowbeer wrote:
> > Objects that are not changed after they are constructed come in two
> > flavors: those that can't be changed (aka immutable) and those that
> > could be changed but aren't (aka "effectively immutable").
> >
> > Safe publication means transmitting the object to another thread by
> > means of a shared lock or volatile (that is, a "happens before"
> > relationship).
> >
> > Passing an object through a thread-safe queue is a common means of
> > safe publication.
>
> Sorry, I'm not sure whether I understood this properly: The "effectively
> mutable" case actually is thread-safe or is explicitly necessary that a
> field is declared final to be thread-safe (and if so why is it)?
>

The effectively immutable case is effectively thread-safe, that is, in
practice :-)

Using "final" lifts the safe-publication requirement for immutable
objects.  The only requirement is correct construction, meaning that
the object's reference hasn't been leaked during construction:

http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#finalRight

In general, even thread-safe objects must be safely published.
Immutable objects with final fields are an exception. They go one step
further; they are thread-safe even without safe publication.

--
Joe Bowbeer

From dovlex at gmail.com  Sat Dec 23 10:45:44 2006
From: dovlex at gmail.com (vladimir)
Date: Sat, 23 Dec 2006 07:45:44 -0800 (PST)
Subject: [concurrency-interest] Naming threads in Executor
Message-ID: <8034578.post@talk.nabble.com>


Hi,

Executor framework provide a mechanism to name threads that are used within
the framework. Once created these thread names are constant for their
lifetime. How would you attach some additional information to a thread name
as it runs various Runnables in Executor framework? They only way of doing
this seems to be setting a thread name ( Thread.currentThread.setName())
within run method of the Runnable. For example:

             executor.execute(new Runnable() {
                public void run() {
                    Thread runner = Thread.currentThread();
                    String oldName = runner.getName();
                    try
                    {
                       runner.setName(oldName+......); 
                       //do some work here                      
                    }
                    finally
                    {
                       runner.setName(oldName);
                    }                    
                }               
            });

Do you anticipate any problems with this approach? Btw, it is strange that
the name variable of Thread class does not seem to be thread safe. Any
ideas?

Regards,
Vladimir

-- 
View this message in context: http://www.nabble.com/Naming-threads-in-Executor-tf2874658.html#a8034578
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From tim at peierls.net  Sat Dec 23 14:20:03 2006
From: tim at peierls.net (Tim Peierls)
Date: Sat, 23 Dec 2006 14:20:03 -0500
Subject: [concurrency-interest] Naming threads in Executor
In-Reply-To: <8034578.post@talk.nabble.com>
References: <8034578.post@talk.nabble.com>
Message-ID: <63b4e4050612231120qb111d1yb9335ac0f1a46ba3@mail.gmail.com>

You can also override TPE's beforeExecute/afterExecute methods to set the
thread name.

--tim

On 12/23/06, vladimir <dovlex at gmail.com> wrote:
>
>
> Hi,
>
> Executor framework provide a mechanism to name threads that are used
> within
> the framework. Once created these thread names are constant for their
> lifetime. How would you attach some additional information to a thread
> name
> as it runs various Runnables in Executor framework? They only way of doing
> this seems to be setting a thread name ( Thread.currentThread.setName())
> within run method of the Runnable. For example:
>
>              executor.execute(new Runnable() {
>                 public void run() {
>                     Thread runner = Thread.currentThread();
>                     String oldName = runner.getName();
>                     try
>                     {
>                        runner.setName(oldName+......);
>                        //do some work here
>                     }
>                     finally
>                     {
>                        runner.setName(oldName);
>                     }
>                 }
>             });
>
> Do you anticipate any problems with this approach? Btw, it is strange that
> the name variable of Thread class does not seem to be thread safe. Any
> ideas?
>
> Regards,
> Vladimir
>
> --
> View this message in context:
> http://www.nabble.com/Naming-threads-in-Executor-tf2874658.html#a8034578
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061223/ae7df278/attachment.html 

From joe.bowbeer at gmail.com  Sat Dec 23 14:39:33 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 23 Dec 2006 11:39:33 -0800
Subject: [concurrency-interest] Naming threads in Executor
In-Reply-To: <8034578.post@talk.nabble.com>
References: <8034578.post@talk.nabble.com>
Message-ID: <31f2a7bd0612231139u230eca2rf074b8fc3e953a74@mail.gmail.com>

FWIW, this topic has been discussed a few times already:

http://nabble.com/forum/Search.jtp?query=concurrency-interest+setName


On 12/23/06, vladimir <dovlex at gmail.com> wrote:
>
> Executor framework provide a mechanism to name threads that are used within
> the framework. Once created these thread names are constant for their
> lifetime. How would you attach some additional information to a thread name
> as it runs various Runnables in Executor framework? They only way of doing
> this seems to be setting a thread name ( Thread.currentThread.setName())
> within run method of the Runnable. For example:
>
>              executor.execute(new Runnable() {
>                 public void run() {
>                     Thread runner = Thread.currentThread();
>                     String oldName = runner.getName();
>                     try
>                     {
>                        runner.setName(oldName+......);
>                        //do some work here
>                     }
>                     finally
>                     {
>                        runner.setName(oldName);
>                     }
>                 }
>             });
>
> Do you anticipate any problems with this approach? Btw, it is strange that
> the name variable of Thread class does not seem to be thread safe. Any
> ideas?
>

From brian at quiotix.com  Wed Dec 27 14:43:40 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 27 Dec 2006 14:43:40 -0500
Subject: [concurrency-interest] Nice video interview with Tim Harris and
	Simon Peyton-Jones
Message-ID: <4592CCEC.9070802@quiotix.com>

http://channel9.msdn.com/Showpost.aspx?postid=231495

Lousy interviewer, but good interviewees, talking about transactional 
memory and the future of concurrency.

My favorite quote (paraphrased): "Building concurrent programs with 
locks is kind of like building a skyscraper out of bananas.  Smart 
people can come up with clever techniques for hooking bananas together, 
but the result is still fragile.  Rather than investing energy in 
mastering banana-coupling techniques, it would be better to invest it in 
better materials."

From dcholmes at optusnet.com.au  Wed Dec 27 17:38:22 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 28 Dec 2006 08:38:22 +1000
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <4592CCEC.9070802@quiotix.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>

STM is just the latest (incomplete!) attempt at providing a system that
takes care of concurrency for you. I am not a believer. There are too many
different kinds of interactions that undermine a "one size fits all"
approach. Time will tell ...


The problem with concurrency is not the "materials" but the general
architecture. First you need to understand your sharing and atomicity
requirements and then you have to enforce them. Where people fail is in the
first step - understanding the problem - but it manifests in the second and
so we blame the mechanism as being too hard to use.

The issue isn't "bananas" for building skyscrapers, it's thinking you can
build a skyscraper just because you built a tree-house (or in some cases
because you read the plans for a tree-house!).

Of course the counter-argument is that perhaps locks and threads are only
good for building "tree houses", even if you do know how to build a
"skyscraper".

Cheers,
David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
> Goetz
> Sent: Thursday, 28 December 2006 5:44 AM
> To: Concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Nice video interview with Tim Harris
> andSimon Peyton-Jones
>
>
> http://channel9.msdn.com/Showpost.aspx?postid=231495
>
> Lousy interviewer, but good interviewees, talking about transactional
> memory and the future of concurrency.
>
> My favorite quote (paraphrased): "Building concurrent programs with
> locks is kind of like building a skyscraper out of bananas.  Smart
> people can come up with clever techniques for hooking bananas together,
> but the result is still fragile.  Rather than investing energy in
> mastering banana-coupling techniques, it would be better to invest it in
> better materials."
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From Philippe.Monnaie at gmail.com  Thu Dec 28 00:23:45 2006
From: Philippe.Monnaie at gmail.com (Philippe Monnaie)
Date: Thu, 28 Dec 2006 06:23:45 +0100
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
Message-ID: <57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>

I indeed have my doubts as well on STM making concurrency that much
easier. But I have to say it does offer some advantages on the side.
The abort/retry semantics make your program immune to deadlock, and
STM should make abstraction easier by making synchronization
structures composable.

On the other hand, a program with heavy data sharing, would produce
lots of collisions, leading to starvation and performance slowing down
to a crawl. So I have to agree that it won't work in every case.

Concerning the latter part of your comment, would it be possible to
solve this with design techniques, much like object oriented
programming simplified writing larger programs?


- Philippe

On 12/27/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> STM is just the latest (incomplete!) attempt at providing a system that
> takes care of concurrency for you. I am not a believer. There are too many
> different kinds of interactions that undermine a "one size fits all"
> approach. Time will tell ...
>
>
> The problem with concurrency is not the "materials" but the general
> architecture. First you need to understand your sharing and atomicity
> requirements and then you have to enforce them. Where people fail is in the
> first step - understanding the problem - but it manifests in the second and
> so we blame the mechanism as being too hard to use.
>
> The issue isn't "bananas" for building skyscrapers, it's thinking you can
> build a skyscraper just because you built a tree-house (or in some cases
> because you read the plans for a tree-house!).
>
> Of course the counter-argument is that perhaps locks and threads are only
> good for building "tree houses", even if you do know how to build a
> "skyscraper".
>
> Cheers,
> David
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
> > Goetz
> > Sent: Thursday, 28 December 2006 5:44 AM
> > To: Concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Nice video interview with Tim Harris
> > andSimon Peyton-Jones
> >
> >
> > http://channel9.msdn.com/Showpost.aspx?postid=231495
> >
> > Lousy interviewer, but good interviewees, talking about transactional
> > memory and the future of concurrency.
> >
> > My favorite quote (paraphrased): "Building concurrent programs with
> > locks is kind of like building a skyscraper out of bananas.  Smart
> > people can come up with clever techniques for hooking bananas together,
> > but the result is still fragile.  Rather than investing energy in
> > mastering banana-coupling techniques, it would be better to invest it in
> > better materials."
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From josh at bloch.us  Thu Dec 28 02:18:14 2006
From: josh at bloch.us (Joshua Bloch)
Date: Wed, 27 Dec 2006 23:18:14 -0800
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
Message-ID: <b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>

I too have my doubts.  I programmed general purpose transaction systems of
an earlier era (Camelot and Encina, for the terminally curious), and they're
harder to program in practice than they appear in theory.  Of course the
analogy between these systems and STMs is imperfect, but not entirely bogus,
I think.

     Josh

On 12/27/06, Philippe Monnaie <Philippe.Monnaie at gmail.com> wrote:
>
> I indeed have my doubts as well on STM making concurrency that much
> easier. But I have to say it does offer some advantages on the side.
> The abort/retry semantics make your program immune to deadlock, and
> STM should make abstraction easier by making synchronization
> structures composable.
>
> On the other hand, a program with heavy data sharing, would produce
> lots of collisions, leading to starvation and performance slowing down
> to a crawl. So I have to agree that it won't work in every case.
>
> Concerning the latter part of your comment, would it be possible to
> solve this with design techniques, much like object oriented
> programming simplified writing larger programs?
>
>
> - Philippe
>
> On 12/27/06, David Holmes <dcholmes at optusnet.com.au> wrote:
> > STM is just the latest (incomplete!) attempt at providing a system that
> > takes care of concurrency for you. I am not a believer. There are too
> many
> > different kinds of interactions that undermine a "one size fits all"
> > approach. Time will tell ...
> >
> >
> > The problem with concurrency is not the "materials" but the general
> > architecture. First you need to understand your sharing and atomicity
> > requirements and then you have to enforce them. Where people fail is in
> the
> > first step - understanding the problem - but it manifests in the second
> and
> > so we blame the mechanism as being too hard to use.
> >
> > The issue isn't "bananas" for building skyscrapers, it's thinking you
> can
> > build a skyscraper just because you built a tree-house (or in some cases
> > because you read the plans for a tree-house!).
> >
> > Of course the counter-argument is that perhaps locks and threads are
> only
> > good for building "tree houses", even if you do know how to build a
> > "skyscraper".
> >
> > Cheers,
> > David
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
> > > Goetz
> > > Sent: Thursday, 28 December 2006 5:44 AM
> > > To: Concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] Nice video interview with Tim Harris
> > > andSimon Peyton-Jones
> > >
> > >
> > > http://channel9.msdn.com/Showpost.aspx?postid=231495
> > >
> > > Lousy interviewer, but good interviewees, talking about transactional
> > > memory and the future of concurrency.
> > >
> > > My favorite quote (paraphrased): "Building concurrent programs with
> > > locks is kind of like building a skyscraper out of bananas.  Smart
> > > people can come up with clever techniques for hooking bananas
> together,
> > > but the result is still fragile.  Rather than investing energy in
> > > mastering banana-coupling techniques, it would be better to invest it
> in
> > > better materials."
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061227/4af64078/attachment.html 

From kimo at webnetic.net  Thu Dec 28 03:14:57 2006
From: kimo at webnetic.net (Kimo Crossman)
Date: Thu, 28 Dec 2006 00:14:57 -0800
Subject: [concurrency-interest] Nice video interview with Tim
	HarrisandSimon Peyton-Jones
In-Reply-To: <b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
Message-ID: <015b01c72a58$442df660$28681948@DesktopSystem>

The guys at comp.programming.threads pretty much hate the idea ...
 
See lively attack of the video here:
http://tinyurl.com/yj5u58
 
including this later comment:

"I'm not going to worry about STM.  The more I look at it the more it looks like locks without deadlocking.  They're not really going after scalability at all just as long as it doesn't suck too much.  Nothing to see here.  Move along."
-- 
Joe Seigh 
 
And more here about TM:
http://tinyurl.com/y7fax3

Hard issues:
Large transations
System and I/O calls
Objects shared between two processes.


________________________________

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joshua Bloch
Sent: 2006 December 27 23:18
To: Philippe Monnaie
Cc: Concurrency-interest at cs.oswego.edu; dholmes at ieee.org
Subject: Re: [concurrency-interest] Nice video interview with Tim HarrisandSimon Peyton-Jones


I too have my doubts.  I programmed general purpose transaction systems of an earlier era (Camelot and Encina, for the terminally curious), and they're harder to program in practice than they appear in theory.  Of course the analogy between these systems and STMs is imperfect, but not entirely bogus, I think. 

     Josh


On 12/27/06, Philippe Monnaie <Philippe.Monnaie at gmail.com> wrote: 

	I indeed have my doubts as well on STM making concurrency that much
	easier. But I have to say it does offer some advantages on the side.
	The abort/retry semantics make your program immune to deadlock, and
	STM should make abstraction easier by making synchronization 
	structures composable.
	
	On the other hand, a program with heavy data sharing, would produce
	lots of collisions, leading to starvation and performance slowing down
	to a crawl. So I have to agree that it won't work in every case. 
	
	Concerning the latter part of your comment, would it be possible to
	solve this with design techniques, much like object oriented
	programming simplified writing larger programs?
	
	
	- Philippe
	
	On 12/27/06, David Holmes < dcholmes at optusnet.com.au> wrote:
	> STM is just the latest (incomplete!) attempt at providing a system that
	> takes care of concurrency for you. I am not a believer. There are too many 
	> different kinds of interactions that undermine a "one size fits all"
	> approach. Time will tell ...
	>
	>
	> The problem with concurrency is not the "materials" but the general 
	> architecture. First you need to understand your sharing and atomicity
	> requirements and then you have to enforce them. Where people fail is in the
	> first step - understanding the problem - but it manifests in the second and 
	> so we blame the mechanism as being too hard to use.
	>
	> The issue isn't "bananas" for building skyscrapers, it's thinking you can
	> build a skyscraper just because you built a tree-house (or in some cases 
	> because you read the plans for a tree-house!).
	>
	> Of course the counter-argument is that perhaps locks and threads are only
	> good for building "tree houses", even if you do know how to build a 
	> "skyscraper".
	>
	> Cheers,
	> David
	>
	> > -----Original Message-----
	> > From: concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu> 
	> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
	> > Goetz
	> > Sent: Thursday, 28 December 2006 5:44 AM 
	> > To: Concurrency-interest at cs.oswego.edu
	> > Subject: [concurrency-interest] Nice video interview with Tim Harris
	> > andSimon Peyton-Jones 
	> >
	> >
	> > http://channel9.msdn.com/Showpost.aspx?postid=231495
	> >
	> > Lousy interviewer, but good interviewees, talking about transactional 
	> > memory and the future of concurrency.
	> >
	> > My favorite quote (paraphrased): "Building concurrent programs with
	> > locks is kind of like building a skyscraper out of bananas.  Smart 
	> > people can come up with clever techniques for hooking bananas together,
	> > but the result is still fragile.  Rather than investing energy in
	> > mastering banana-coupling techniques, it would be better to invest it in 
	> > better materials."
	> > _______________________________________________
	> > Concurrency-interest mailing list
	> > Concurrency-interest at altair.cs.oswego.edu <mailto:Concurrency-interest at altair.cs.oswego.edu> 
	> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
	>
	> _______________________________________________ 
	> Concurrency-interest mailing list
	> Concurrency-interest at altair.cs.oswego.edu
	> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
	>
	_______________________________________________
	Concurrency-interest mailing list
	Concurrency-interest at altair.cs.oswego.edu
	http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
	





From dcholmes at optusnet.com.au  Thu Dec 28 05:59:55 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 28 Dec 2006 20:59:55 +1000
Subject: [concurrency-interest] Nice video interview with
	TimHarrisandSimon Peyton-Jones
In-Reply-To: <015b01c72a58$442df660$28681948@DesktopSystem>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEMEHEAA.dcholmes@optusnet.com.au>

Yes those guys are stalwarts :-) And Joe Seigh has a lot of experience in
this area too.

I've had some involvement with people working on STM over the past few years
and someone who recently wrote a thesis around it told me that they now
agreed with my position that there are too many non-transactional actions
involved in synchronization/coordination to make STM a general solution. But
I'm all for them trying.

Cheers,
David Holmes

Kimo Crossman wrote:
>
> The guys at comp.programming.threads pretty much hate the idea ...
>
> See lively attack of the video here:
> http://tinyurl.com/yj5u58
>
> including this later comment:
>
> "I'm not going to worry about STM.  The more I look at it the
> more it looks like locks without deadlocking.  They're not really
> going after scalability at all just as long as it doesn't suck
> too much.  Nothing to see here.  Move along."
> --
> Joe Seigh
>
> And more here about TM:
> http://tinyurl.com/y7fax3
>
> Hard issues:
> Large transations
> System and I/O calls
> Objects shared between two processes.
>
>
> ________________________________
>
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of
> Joshua Bloch
> Sent: 2006 December 27 23:18
> To: Philippe Monnaie
> Cc: Concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> Subject: Re: [concurrency-interest] Nice video interview with Tim
> HarrisandSimon Peyton-Jones
>
>
> I too have my doubts.  I programmed general purpose transaction
> systems of an earlier era (Camelot and Encina, for the terminally
> curious), and they're harder to program in practice than they
> appear in theory.  Of course the analogy between these systems
> and STMs is imperfect, but not entirely bogus, I think.
>
>      Josh
>
>
> On 12/27/06, Philippe Monnaie <Philippe.Monnaie at gmail.com> wrote:
>
> 	I indeed have my doubts as well on STM making concurrency that much
> 	easier. But I have to say it does offer some advantages on the side.
> 	The abort/retry semantics make your program immune to deadlock, and
> 	STM should make abstraction easier by making synchronization
> 	structures composable.
>
> 	On the other hand, a program with heavy data sharing, would produce
> 	lots of collisions, leading to starvation and performance
> slowing down
> 	to a crawl. So I have to agree that it won't work in every case.
>
> 	Concerning the latter part of your comment, would it be possible to
> 	solve this with design techniques, much like object oriented
> 	programming simplified writing larger programs?
>
>
> 	- Philippe
>
> 	On 12/27/06, David Holmes < dcholmes at optusnet.com.au> wrote:
> 	> STM is just the latest (incomplete!) attempt at providing
> a system that
> 	> takes care of concurrency for you. I am not a believer.
> There are too many
> 	> different kinds of interactions that undermine a "one
> size fits all"
> 	> approach. Time will tell ...
> 	>
> 	>
> 	> The problem with concurrency is not the "materials" but
> the general
> 	> architecture. First you need to understand your sharing
> and atomicity
> 	> requirements and then you have to enforce them. Where
> people fail is in the
> 	> first step - understanding the problem - but it manifests
> in the second and
> 	> so we blame the mechanism as being too hard to use.
> 	>
> 	> The issue isn't "bananas" for building skyscrapers, it's
> thinking you can
> 	> build a skyscraper just because you built a tree-house
> (or in some cases
> 	> because you read the plans for a tree-house!).
> 	>
> 	> Of course the counter-argument is that perhaps locks and
> threads are only
> 	> good for building "tree houses", even if you do know how
> to build a
> 	> "skyscraper".
> 	>
> 	> Cheers,
> 	> David
> 	>
> 	> > -----Original Message-----
> 	> > From: concurrency-interest-bounces at cs.oswego.edu
<mailto:concurrency-interest-bounces at cs.oswego.edu>
	> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Brian
	> > Goetz
	> > Sent: Thursday, 28 December 2006 5:44 AM
	> > To: Concurrency-interest at cs.oswego.edu
	> > Subject: [concurrency-interest] Nice video interview with Tim Harris
	> > andSimon Peyton-Jones
	> >
	> >
	> > http://channel9.msdn.com/Showpost.aspx?postid=231495
	> >
	> > Lousy interviewer, but good interviewees, talking about transactional
	> > memory and the future of concurrency.
	> >
	> > My favorite quote (paraphrased): "Building concurrent programs with
	> > locks is kind of like building a skyscraper out of bananas.  Smart
	> > people can come up with clever techniques for hooking bananas together,
	> > but the result is still fragile.  Rather than investing energy in
	> > mastering banana-coupling techniques, it would be better to invest it
in
	> > better materials."
	> > _______________________________________________
	> > Concurrency-interest mailing list
	> > Concurrency-interest at altair.cs.oswego.edu
<mailto:Concurrency-interest at altair.cs.oswego.edu>
	> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
	>
	> _______________________________________________
	> Concurrency-interest mailing list
	> Concurrency-interest at altair.cs.oswego.edu
	> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
	>
	_______________________________________________
	Concurrency-interest mailing list
	Concurrency-interest at altair.cs.oswego.edu
	http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest





_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dcholmes at optusnet.com.au  Thu Dec 28 06:05:17 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 28 Dec 2006 21:05:17 +1000
Subject: [concurrency-interest] Nice video interview with Tim
	HarrisandSimon Peyton-Jones
In-Reply-To: <57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEMEHEAA.dcholmes@optusnet.com.au>

Philippe Monnaie wrote:
> Concerning the latter part of your comment, would it be possible to
> solve this with design techniques, much like object oriented
> programming simplified writing larger programs?

Well that is how we do try to solve it - with varying degrees of success.
Well structured systems, with clear division of responsibility and clear
communication paths, are easier to correctly synchronize and be performant.
There are lots of design patterns in this field.

Cheers,
David


From brian at quiotix.com  Thu Dec 28 12:00:21 2006
From: brian at quiotix.com (Brian Goetz)
Date: Thu, 28 Dec 2006 12:00:21 -0500
Subject: [concurrency-interest] Nice video interview with Tim
 Harris	andSimon Peyton-Jones
In-Reply-To: <b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
References: <4592CCEC.9070802@quiotix.com>	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
Message-ID: <4593F825.4050607@quiotix.com>

On the other hand, people said the same thing about garbage collection.

> I too have my doubts.  I programmed general purpose transaction systems 
> of an earlier era (Camelot and Encina, for the terminally curious), and 
> they're harder to program in practice than they appear in theory.  Of 
> course the analogy between these systems and STMs is imperfect, but not 
> entirely bogus, I think.

Unrelated unfortunate observation: There's snow on my driveway :(

From josh at bloch.us  Thu Dec 28 13:02:47 2006
From: josh at bloch.us (Joshua Bloch)
Date: Thu, 28 Dec 2006 10:02:47 -0800
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <4593F825.4050607@quiotix.com>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
	<4593F825.4050607@quiotix.com>
Message-ID: <b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>

Brian,

Hmmm.  I remember people bitching about GC performance, but not usability.
I'm saying that the transaction model is not as easy to program to as it
appears, and it does not free you from thinking about locks (in my
experience with Encina and Camelot).  Did people bitch about the usability
of GC?

        Josh

On 12/28/06, Brian Goetz <brian at quiotix.com> wrote:
>
> On the other hand, people said the same thing about garbage collection.
>
> > I too have my doubts.  I programmed general purpose transaction systems
> > of an earlier era (Camelot and Encina, for the terminally curious), and
> > they're harder to program in practice than they appear in theory.  Of
> > course the analogy between these systems and STMs is imperfect, but not
> > entirely bogus, I think.
>
> Unrelated unfortunate observation: There's snow on my driveway :(
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/06cbe418/attachment.html 

From brian at quiotix.com  Thu Dec 28 13:13:15 2006
From: brian at quiotix.com (Brian Goetz)
Date: Thu, 28 Dec 2006 13:13:15 -0500
Subject: [concurrency-interest] Nice video interview with Tim Harris
 andSimon Peyton-Jones
In-Reply-To: <b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
References: <4592CCEC.9070802@quiotix.com>	
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>	
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>	
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>	
	<4593F825.4050607@quiotix.com>
	<b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
Message-ID: <4594093B.3010303@quiotix.com>

> Hmmm.  I remember people bitching about GC performance, but not 
> usability.  

I remember people bitching about unreliability, too, though those were 
mostly out of ignorance.  FUD items like pointers hidden from the 
collector (newP = p XOR 0xCAFEBABE; p=0) and cyclical data structures 
that can't be reclaimed by reference counting.

> I'm saying that the transaction model is not as easy to 
> program to as it appears, and it does not free you from thinking about 
> locks (in my experience with Encina and Camelot).  Did people bitch 
> about the usability of GC?

A sufficiently large quantitative difference becomes a qualitative 
difference.  If the performance is so poor, you'll do all sorts of 
things to avoid using it, and then its as if you don't have it, and you 
bitch about that.

People understand "one big fat lock".  People don't use OBFL because 
they are convinced the performance would suck.  If we could make the 
performance of OBFL better, I think many of the usability issues go away 
_relative to the current audience_.

But, of course, once you make things easier, the audience grows, and the 
new expanded audience might not see the subtleties of "don't do I/O in 
atomic blocks" and things like that.

I don't want to come off as having drank the kool-aid -- I think there's 
a long way to go before STM is real (though the Azul implementation is a 
nice proof for the concept) -- I just think that many of the arguments 
raised against it are the same as those that have been raised against 
many other fledgling technologies that we've since come to love.  I am 
anxiously hoping the research boys come up with something good here, 
because what we've got now is a bunch of bananas.



From kimo at webnetic.net  Thu Dec 28 14:00:43 2006
From: kimo at webnetic.net (Kimo Crossman)
Date: Thu, 28 Dec 2006 11:00:43 -0800
Subject: [concurrency-interest] Nice video interview with Tim
	HarrisandSimon Peyton-Jones
In-Reply-To: <b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
Message-ID: <022b01c72ab2$7ad652c0$28681948@DesktopSystem>

I agree if you are in the middle of a memory transaction which performs I/O, there seems to be no way to rollback
 
on the lock question below - they have argued that the solution is composible so that may possibly help some lock situations.
 


  _____  

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joshua Bloch
Sent: 2006 December 28 10:03
To: Brian Goetz
Cc: Concurrency-interest at cs.oswego.edu; dholmes at ieee.org
Subject: Re: [concurrency-interest] Nice video interview with Tim HarrisandSimon Peyton-Jones


Brian,

Hmmm.  I remember people bitching about GC performance, but not usability.  I'm saying that the transaction model is not as easy to program to as it appears, and it does not free you from thinking about locks (in my experience with Encina and Camelot).  Did people bitch about the usability of GC? 

        Josh


On 12/28/06, Brian Goetz <brian at quiotix.com> wrote: 

On the other hand, people said the same thing about garbage collection.

> I too have my doubts.  I programmed general purpose transaction systems
> of an earlier era (Camelot and Encina, for the terminally curious), and 
> they're harder to program in practice than they appear in theory.  Of
> course the analogy between these systems and STMs is imperfect, but not
> entirely bogus, I think.

Unrelated unfortunate observation: There's snow on my driveway :( 



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/089d03e5/attachment.html 

From josh at bloch.us  Thu Dec 28 14:14:12 2006
From: josh at bloch.us (Joshua Bloch)
Date: Thu, 28 Dec 2006 11:14:12 -0800
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <4594093B.3010303@quiotix.com>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
	<4593F825.4050607@quiotix.com>
	<b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
	<4594093B.3010303@quiotix.com>
Message-ID: <b097ac510612281114o32035d6fy592efc03c11b7bde@mail.gmail.com>

Brian,

Yes, I think we're in agreement.  I a big fan of STM as a research topic.  I
just don't think it's ready for prime time yet.  In particular, I don't
think we really have a handle on how it will feel to programmers.

           Josh


On 12/28/06, Brian Goetz <brian at quiotix.com> wrote:
>
> > Hmmm.  I remember people bitching about GC performance, but not
> > usability.
>
> I remember people bitching about unreliability, too, though those were
> mostly out of ignorance.  FUD items like pointers hidden from the
> collector (newP = p XOR 0xCAFEBABE; p=0) and cyclical data structures
> that can't be reclaimed by reference counting.
>
> > I'm saying that the transaction model is not as easy to
> > program to as it appears, and it does not free you from thinking about
> > locks (in my experience with Encina and Camelot).  Did people bitch
> > about the usability of GC?
>
> A sufficiently large quantitative difference becomes a qualitative
> difference.  If the performance is so poor, you'll do all sorts of
> things to avoid using it, and then its as if you don't have it, and you
> bitch about that.
>
> People understand "one big fat lock".  People don't use OBFL because
> they are convinced the performance would suck.  If we could make the
> performance of OBFL better, I think many of the usability issues go away
> _relative to the current audience_.
>
> But, of course, once you make things easier, the audience grows, and the
> new expanded audience might not see the subtleties of "don't do I/O in
> atomic blocks" and things like that.
>
> I don't want to come off as having drank the kool-aid -- I think there's
> a long way to go before STM is real (though the Azul implementation is a
> nice proof for the concept) -- I just think that many of the arguments
> raised against it are the same as those that have been raised against
> many other fledgling technologies that we've since come to love.  I am
> anxiously hoping the research boys come up with something good here,
> because what we've got now is a bunch of bananas.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/59d8b3a8/attachment.html 

From kg103 at doc.ic.ac.uk  Thu Dec 28 14:53:42 2006
From: kg103 at doc.ic.ac.uk (kg103 at doc.ic.ac.uk)
Date: Thu, 28 Dec 2006 19:53:42 +0000
Subject: [concurrency-interest] Nice video interview with Tim
	Harris	andSimon Peyton-Jones
In-Reply-To: <b097ac510612281114o32035d6fy592efc03c11b7bde@mail.gmail.com>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
	<4593F825.4050607@quiotix.com>
	<b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
	<4594093B.3010303@quiotix.com>
	<b097ac510612281114o32035d6fy592efc03c11b7bde@mail.gmail.com>
Message-ID: <20061228195342.m1jn4wwhy8kg4swc@tern.doc.ic.ac.uk>

Hi,
I agree. STMs also have a number of other subtle problems like not  
being able to support strong atomicity due to the ABA problem with CAS  
instructions. Plus current solutions for IO are not general enough. Do  
you think hardware support is a possible reality or just a dream? the  
Hybrid Transactional Memory proposal seems to be a lot more realistic  
than previous hardware-only suggestions, although I guess this is up  
to chip manufacturers.

Khilan

Quoting Joshua Bloch <josh at bloch.us>:

> Brian,
>
> Yes, I think we're in agreement.  I a big fan of STM as a research topic.  I
> just don't think it's ready for prime time yet.  In particular, I don't
> think we really have a handle on how it will feel to programmers.
>
>           Josh
>
>
> On 12/28/06, Brian Goetz <brian at quiotix.com> wrote:
>>
>>> Hmmm.  I remember people bitching about GC performance, but not
>>> usability.
>>
>> I remember people bitching about unreliability, too, though those were
>> mostly out of ignorance.  FUD items like pointers hidden from the
>> collector (newP = p XOR 0xCAFEBABE; p=0) and cyclical data structures
>> that can't be reclaimed by reference counting.
>>
>>> I'm saying that the transaction model is not as easy to
>>> program to as it appears, and it does not free you from thinking about
>>> locks (in my experience with Encina and Camelot).  Did people bitch
>>> about the usability of GC?
>>
>> A sufficiently large quantitative difference becomes a qualitative
>> difference.  If the performance is so poor, you'll do all sorts of
>> things to avoid using it, and then its as if you don't have it, and you
>> bitch about that.
>>
>> People understand "one big fat lock".  People don't use OBFL because
>> they are convinced the performance would suck.  If we could make the
>> performance of OBFL better, I think many of the usability issues go away
>> _relative to the current audience_.
>>
>> But, of course, once you make things easier, the audience grows, and the
>> new expanded audience might not see the subtleties of "don't do I/O in
>> atomic blocks" and things like that.
>>
>> I don't want to come off as having drank the kool-aid -- I think there's
>> a long way to go before STM is real (though the Azul implementation is a
>> nice proof for the concept) -- I just think that many of the arguments
>> raised against it are the same as those that have been raised against
>> many other fledgling technologies that we've since come to love.  I am
>> anxiously hoping the research boys come up with something good here,
>> because what we've got now is a bunch of bananas.
>>
>>
>>





From josh at bloch.us  Thu Dec 28 14:56:35 2006
From: josh at bloch.us (Joshua Bloch)
Date: Thu, 28 Dec 2006 11:56:35 -0800
Subject: [concurrency-interest] Nice video interview with Tim Harris
	andSimon Peyton-Jones
In-Reply-To: <2fe9b4320612281152g408d5f84ie8b2ab720939d934@mail.gmail.com>
References: <4592CCEC.9070802@quiotix.com>
	<NFBBKALFDCPFIDBNKAPCCEMBHEAA.dcholmes@optusnet.com.au>
	<57b5dfde0612272123g5488275cmbb8e22f184a39c8f@mail.gmail.com>
	<b097ac510612272318g7e66a469xbac7d04a5714919d@mail.gmail.com>
	<4593F825.4050607@quiotix.com>
	<b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
	<4594093B.3010303@quiotix.com>
	<b097ac510612281114o32035d6fy592efc03c11b7bde@mail.gmail.com>
	<2fe9b4320612281152g408d5f84ie8b2ab720939d934@mail.gmail.com>
Message-ID: <b097ac510612281156r755f17f8v6df5894dd5da1253@mail.gmail.com>

It's funny; Al Spector (my thesis advisor) and I discussed hardware support
for transactional memory when I was at CMU (~1988).  We decided it was way
premature.  These days, I would say "a bit premature."  The thing about
hardware is that the startup costs are very high, and you have to plan to
get one (or two) generations wrong.  So once again, I see it as a promising
research area, rather than a market imperative.  That said, I really haven't
kept up with the area, so what do I know?

           Josh


On 12/28/06, Khilan Gudka <kgudka at gmail.com> wrote:
>
> Hi,
> I agree. STMs also have a number of other subtle problems like not being
> able to support strong atomicity due to the ABA problem with CAS
> instructions. Plus current solutions for IO are not general enough. Do you
> think hardware support is a possible reality or just a dream? the Hybrid
> Transactional Memory proposal seems to be a lot more realistic than previous
> hardware-only suggestions, although I guess this is up to chip
> manufacturers.
>
> Khilan
>
> On 12/28/06, Joshua Bloch <josh at bloch.us> wrote:
> >
> >  Brian,
> >
> > Yes, I think we're in agreement.  I a big fan of STM as a research
> > topic.  I just don't think it's ready for prime time yet.  In particular, I
> > don't think we really have a handle on how it will feel to programmers.
> >
> >            Josh
> >
> >
> > On 12/28/06, Brian Goetz <brian at quiotix.com > wrote:
> > >
> > > > Hmmm.  I remember people bitching about GC performance, but not
> > > > usability.
> > >
> > > I remember people bitching about unreliability, too, though those were
> > >
> > > mostly out of ignorance.  FUD items like pointers hidden from the
> > > collector (newP = p XOR 0xCAFEBABE; p=0) and cyclical data structures
> > > that can't be reclaimed by reference counting.
> > >
> > > > I'm saying that the transaction model is not as easy to
> > > > program to as it appears, and it does not free you from thinking
> > > about
> > > > locks (in my experience with Encina and Camelot).  Did people bitch
> > > > about the usability of GC?
> > >
> > > A sufficiently large quantitative difference becomes a qualitative
> > > difference.  If the performance is so poor, you'll do all sorts of
> > > things to avoid using it, and then its as if you don't have it, and
> > > you
> > > bitch about that.
> > >
> > > People understand "one big fat lock".  People don't use OBFL because
> > > they are convinced the performance would suck.  If we could make the
> > > performance of OBFL better, I think many of the usability issues go
> > > away
> > > _relative to the current audience_.
> > >
> > > But, of course, once you make things easier, the audience grows, and
> > > the
> > > new expanded audience might not see the subtleties of "don't do I/O in
> > > atomic blocks" and things like that.
> > >
> > > I don't want to come off as having drank the kool-aid -- I think
> > > there's
> > > a long way to go before STM is real (though the Azul implementation is
> > > a
> > > nice proof for the concept) -- I just think that many of the arguments
> > > raised against it are the same as those that have been raised against
> > > many other fledgling technologies that we've since come to love.  I am
> > >
> > > anxiously hoping the research boys come up with something good here,
> > > because what we've got now is a bunch of bananas.
> > >
> > >
> > >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/b66642e7/attachment-0001.html 

From crazybob at crazybob.org  Thu Dec 28 17:52:34 2006
From: crazybob at crazybob.org (Bob Lee)
Date: Thu, 28 Dec 2006 14:52:34 -0800
Subject: [concurrency-interest] Nice video interview with Tim
	HarrisandSimon Peyton-Jones
In-Reply-To: <022b01c72ab2$7ad652c0$28681948@DesktopSystem>
References: <b097ac510612281002i321bf531reef6cbf53f6d5972@mail.gmail.com>
	<022b01c72ab2$7ad652c0$28681948@DesktopSystem>
Message-ID: <a74683f90612281452o17062666s418a735e726a51de@mail.gmail.com>

On 12/28/06, Kimo Crossman <kimo at webnetic.net> wrote:
>
>  I agree if you are in the middle of a memory transaction which performs
> I/O, there seems to be no way to rollback
>

2PC? ;)

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/05c734cc/attachment.html 

From kimo at webnetic.net  Thu Dec 28 20:51:12 2006
From: kimo at webnetic.net (Kimo Crossman)
Date: Thu, 28 Dec 2006 17:51:12 -0800
Subject: [concurrency-interest] Nice video interview with Tim HarrisandSimon
	Peyton-Jones
In-Reply-To: <b097ac510612281156r755f17f8v6df5894dd5da1253@mail.gmail.com>
Message-ID: <02d201c72aeb$d2dae330$28681948@DesktopSystem>

Here is by the way a current bibliography of Software and Hardware Transactional Memory
 
http://www.cs.wisc.edu/trans-memory/biblio/index.html
 

  _____  

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joshua Bloch
Sent: 2006 December 28 11:57
To: Khilan Gudka
Cc: Brian Goetz; Concurrency-interest at cs.oswego.edu; dholmes at ieee.org
Subject: Re: [concurrency-interest] Nice video interview with Tim HarrisandSimon Peyton-Jones


It's funny; Al Spector (my thesis advisor) and I discussed hardware support for transactional memory when I was at CMU (~1988).  We decided it was way premature.  These days, I would say "a bit premature."  The thing about hardware is that the startup costs are very high, and you have to plan to get one (or two) generations wrong.  So once again, I see it as a promising research area, rather than a market imperative.  That said, I really haven't kept up with the area, so what do I know? 
 
           Josh

 
On 12/28/06, Khilan Gudka <kgudka at gmail.com> wrote: 

Hi,
I agree. STMs also have a number of other subtle problems like not being able to support strong atomicity due to the ABA problem with CAS instructions. Plus current solutions for IO are not general enough. Do you think hardware support is a possible reality or just a dream? the Hybrid Transactional Memory proposal seems to be a lot more realistic than previous hardware-only suggestions, although I guess this is up to chip manufacturers. 

Khilan


On 12/28/06, Joshua Bloch <josh at bloch.us  <mailto:josh at bloch.us> > wrote: 


Brian,
 
Yes, I think we're in agreement.  I a big fan of STM as a research topic.  I just don't think it's ready for prime time yet.  In particular, I don't think we really have a handle on how it will feel to programmers. 
 
           Josh

 
On 12/28/06, Brian Goetz <brian at quiotix.com  <mailto:brian at quiotix.com> > wrote: 


> Hmmm.  I remember people bitching about GC performance, but not 
> usability.

I remember people bitching about unreliability, too, though those were 
mostly out of ignorance.  FUD items like pointers hidden from the
collector (newP = p XOR 0xCAFEBABE; p=0) and cyclical data structures
that can't be reclaimed by reference counting. 

> I'm saying that the transaction model is not as easy to 
> program to as it appears, and it does not free you from thinking about
> locks (in my experience with Encina and Camelot).  Did people bitch 
> about the usability of GC?

A sufficiently large quantitative difference becomes a qualitative 
difference.  If the performance is so poor, you'll do all sorts of
things to avoid using it, and then its as if you don't have it, and you 
bitch about that.

People understand "one big fat lock".  People don't use OBFL because 
they are convinced the performance would suck.  If we could make the
performance of OBFL better, I think many of the usability issues go away 
_relative to the current audience_.

But, of course, once you make things easier, the audience grows, and the 
new expanded audience might not see the subtleties of "don't do I/O in
atomic blocks" and things like that. 

I don't want to come off as having drank the kool-aid -- I think there's
a long way to go before STM is real (though the Azul implementation is a 
nice proof for the concept) -- I just think that many of the arguments 
raised against it are the same as those that have been raised against
many other fledgling technologies that we've since come to love.  I am 
anxiously hoping the research boys come up with something good here, 
because what we've got now is a bunch of bananas.






_______________________________________________
Concurrency-interest mailing list 
Concurrency-interest at altair.cs.oswego.edu  <mailto:Concurrency-interest at altair.cs.oswego.edu> 
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest 






-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20061228/76312ee2/attachment.html 

From MOKEEFFE at amfam.com  Tue Dec 12 10:41:08 2006
From: MOKEEFFE at amfam.com (michaelok)
Date: Tue, 12 Dec 2006 15:41:08 -0000
Subject: [concurrency-interest] concurrency-interest search (Was
 Upgrading a RL to WL in ReentrantReadWriteLock)
In-Reply-To: <45759DAB.8010106@yahoo.com>
References: <45759DAB.8010106@yahoo.com>
Message-ID: <7835478.post@talk.nabble.com>




Bela Ban wrote:
> 
> Apologies if this has been asked before - I tried to google and search 
> the concurrency-interest mailing list archives, to no avail (note that 
> the archives at 
> http://altair.cs.oswego.edu/mailman/private/concurrency-interest/ cannot 
> be searched ! It would be good if you guys could change this...).
> 
> 

Bela, this site provides search capability of concurrency-interest.  Free
registration.  

http://www.nabble.com/Upgrading-a-RL-to-WL-in-ReentrantReadWriteLock-tf2762910.html#a7703406

-- 
View this message in context: http://www.nabble.com/Upgrading-a-RL-to-WL-in-ReentrantReadWriteLock-tf2762910.html#a7835478
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


