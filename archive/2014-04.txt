From dms at sosnoski.com  Tue Apr  1 19:16:54 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Wed, 02 Apr 2014 12:16:54 +1300
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine() hangs
Message-ID: <533B48E6.6050700@sosnoski.com>

I've run into a situation with CompletableFuture.thenCombine() hanging 
(i.e., the returned future never completing even though the original 
future and the combined one have completed) with the Oracle Java 8 
release for 64-bit Linux. I wanted to run this by the group before 
creating a bug report to make sure I'm not misunderstanding how this is 
supposed to work. Here's the code:

public class CompletableFutureFail {

     private Supplier<Integer> newLambda(int i) {
         return () -> Integer.valueOf(i);
     }

     private Integer run(int n) {
         CompletableFuture<Integer> last = 
CompletableFuture.supplyAsync(newLambda(0));
         for (int i = 1; i < n; i++) {
             last = CompletableFuture.supplyAsync(newLambda(i)) 
.thenCombine(last, Math::max);
         }
         return last.join();
     }

     public static void main(String[] args) {
         CompletableFutureFail fail = new CompletableFutureFail();
         for (int i = 0; i < 100; i++) {
             fail.run(10000);
             System.out.println("Did it " + i);
         }
     }
}

When I run it from the command line it mostly doesn't make it through 
the first call to run(). Sometimes it does, but it generally only makes 
a few passes before hanging. In other circumstances (such as running 
inside Eclipse) I've seen it make it all the way through to the end, 
though most often it also hangs there in the first few passes. I'm 
thinking it might be Hotspot related because of the halting pattern.

Any suggestions?

Thanks,

   - Dennis


From martinrb at google.com  Tue Apr  1 20:04:21 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 1 Apr 2014 17:04:21 -0700
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
	hangs
In-Reply-To: <533B48E6.6050700@sosnoski.com>
References: <533B48E6.6050700@sosnoski.com>
Message-ID: <CA+kOe0-cLgTSvAwQK90VShmDVUEMbKET+0x4zkXCcHQbCR03Qg@mail.gmail.com>

Thanks for finding this stress test for java.util.concurrent.
Looks like a bug to me - I can reproduce it.
Could be in hotspot, fork/join, or CompletableFuture.
Doug is by far the best person to investigate.

Here's the relevant stack portion:

"ForkJoinPool.commonPool-worker-1" #150 daemon prio=5 os_prio=0
tid=0x000000000253c000 nid=0x6237 waiting on condition [0x00007f8513390000]
   java.lang.Thread.State: TIMED_WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
- parking to wait for  <0x00000000ec50c120> (a
java.util.concurrent.ForkJoinPool)
at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1756)
at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1696)

"main" #1 prio=5 os_prio=0 tid=0x00000000021ed000 nid=0x613d waiting on
condition [0x00007f852a508000]
   java.lang.Thread.State: WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
- parking to wait for  <0x00000000ec50c518> (a
java.util.concurrent.CompletableFuture$WaitNode)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
at
java.util.concurrent.CompletableFuture$WaitNode.block(CompletableFuture.java:271)
at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3226)
at
java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:319)
at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:2292)



On Tue, Apr 1, 2014 at 4:16 PM, Dennis Sosnoski <dms at sosnoski.com> wrote:

> I've run into a situation with CompletableFuture.thenCombine() hanging
> (i.e., the returned future never completing even though the original future
> and the combined one have completed) with the Oracle Java 8 release for
> 64-bit Linux. I wanted to run this by the group before creating a bug
> report to make sure I'm not misunderstanding how this is supposed to work.
> Here's the code:
>
> public class CompletableFutureFail {
>
>     private Supplier<Integer> newLambda(int i) {
>         return () -> Integer.valueOf(i);
>     }
>
>     private Integer run(int n) {
>         CompletableFuture<Integer> last = CompletableFuture.supplyAsync(
> newLambda(0));
>         for (int i = 1; i < n; i++) {
>             last = CompletableFuture.supplyAsync(newLambda(i))
> .thenCombine(last, Math::max);
>         }
>         return last.join();
>     }
>
>     public static void main(String[] args) {
>         CompletableFutureFail fail = new CompletableFutureFail();
>         for (int i = 0; i < 100; i++) {
>             fail.run(10000);
>             System.out.println("Did it " + i);
>         }
>     }
> }
>
> When I run it from the command line it mostly doesn't make it through the
> first call to run(). Sometimes it does, but it generally only makes a few
> passes before hanging. In other circumstances (such as running inside
> Eclipse) I've seen it make it all the way through to the end, though most
> often it also hangs there in the first few passes. I'm thinking it might be
> Hotspot related because of the halting pattern.
>
> Any suggestions?
>
> Thanks,
>
>   - Dennis
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140401/69a48952/attachment.html>

From dms at sosnoski.com  Tue Apr  1 20:32:07 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Wed, 02 Apr 2014 13:32:07 +1300
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <CA+kOe0-cLgTSvAwQK90VShmDVUEMbKET+0x4zkXCcHQbCR03Qg@mail.gmail.com>
References: <533B48E6.6050700@sosnoski.com>
	<CA+kOe0-cLgTSvAwQK90VShmDVUEMbKET+0x4zkXCcHQbCR03Qg@mail.gmail.com>
Message-ID: <533B5A87.8070906@sosnoski.com>

Thanks for confirming it, Martin.

Should I create a bug report against Java 8, or will you just handle 
this directly, Doug?

   - Dennis

On 04/02/2014 01:04 PM, Martin Buchholz wrote:
> Thanks for finding this stress test for java.util.concurrent.
> Looks like a bug to me - I can reproduce it.
> Could be in hotspot, fork/join, or CompletableFuture.
> Doug is by far the best person to investigate.
>
> Here's the relevant stack portion:
>
> "ForkJoinPool.commonPool-worker-1" #150 daemon prio=5 os_prio=0 
> tid=0x000000000253c000 nid=0x6237 waiting on condition 
> [0x00007f8513390000]
>    java.lang.Thread.State: TIMED_WAITING (parking)
> at sun.misc.Unsafe.park(Native Method)
> - parking to wait for  <0x00000000ec50c120> (a 
> java.util.concurrent.ForkJoinPool)
> at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1756)
> at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1696)
>
> "main" #1 prio=5 os_prio=0 tid=0x00000000021ed000 nid=0x613d waiting 
> on condition [0x00007f852a508000]
>    java.lang.Thread.State: WAITING (parking)
> at sun.misc.Unsafe.park(Native Method)
> - parking to wait for  <0x00000000ec50c518> (a 
> java.util.concurrent.CompletableFuture$WaitNode)
> at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
> at 
> java.util.concurrent.CompletableFuture$WaitNode.block(CompletableFuture.java:271)
> at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3226)
> at 
> java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:319)
> at 
> java.util.concurrent.CompletableFuture.join(CompletableFuture.java:2292)
>
>
>
> On Tue, Apr 1, 2014 at 4:16 PM, Dennis Sosnoski <dms at sosnoski.com 
> <mailto:dms at sosnoski.com>> wrote:
>
>     I've run into a situation with CompletableFuture.thenCombine()
>     hanging (i.e., the returned future never completing even though
>     the original future and the combined one have completed) with the
>     Oracle Java 8 release for 64-bit Linux. I wanted to run this by
>     the group before creating a bug report to make sure I'm not
>     misunderstanding how this is supposed to work. Here's the code:
>
>     public class CompletableFutureFail {
>
>         private Supplier<Integer> newLambda(int i) {
>             return () -> Integer.valueOf(i);
>         }
>
>         private Integer run(int n) {
>             CompletableFuture<Integer> last =
>     CompletableFuture.supplyAsync(newLambda(0));
>             for (int i = 1; i < n; i++) {
>                 last = CompletableFuture.supplyAsync(newLambda(i))
>     .thenCombine(last, Math::max);
>             }
>             return last.join();
>         }
>
>         public static void main(String[] args) {
>             CompletableFutureFail fail = new CompletableFutureFail();
>             for (int i = 0; i < 100; i++) {
>                 fail.run(10000);
>                 System.out.println("Did it " + i);
>             }
>         }
>     }
>
>     When I run it from the command line it mostly doesn't make it
>     through the first call to run(). Sometimes it does, but it
>     generally only makes a few passes before hanging. In other
>     circumstances (such as running inside Eclipse) I've seen it make
>     it all the way through to the end, though most often it also hangs
>     there in the first few passes. I'm thinking it might be Hotspot
>     related because of the halting pattern.
>
>     Any suggestions?
>
>     Thanks,
>
>       - Dennis
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/3605d8c8/attachment.html>

From dl at cs.oswego.edu  Wed Apr  2 07:01:45 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 02 Apr 2014 07:01:45 -0400
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <533B5A87.8070906@sosnoski.com>
References: <533B48E6.6050700@sosnoski.com>	<CA+kOe0-cLgTSvAwQK90VShmDVUEMbKET+0x4zkXCcHQbCR03Qg@mail.gmail.com>
	<533B5A87.8070906@sosnoski.com>
Message-ID: <533BEE19.4070900@cs.oswego.edu>

On 04/01/2014 08:32 PM, Dennis Sosnoski wrote:
> Thanks for confirming it, Martin.
>
> Should I create a bug report against Java 8, or will you just handle this
> directly, Doug?

We'll track it down. Thanks for reporting this!

-Doug


>
>    - Dennis
>
> On 04/02/2014 01:04 PM, Martin Buchholz wrote:
>> Thanks for finding this stress test for java.util.concurrent.
>> Looks like a bug to me - I can reproduce it.
>> Could be in hotspot, fork/join, or CompletableFuture.
>> Doug is by far the best person to investigate.
>>
>> Here's the relevant stack portion:
>>
>> "ForkJoinPool.commonPool-worker-1" #150 daemon prio=5 os_prio=0
>> tid=0x000000000253c000 nid=0x6237 waiting on condition [0x00007f8513390000]
>>    java.lang.Thread.State: TIMED_WAITING (parking)
>> at sun.misc.Unsafe.park(Native Method)
>> - parking to wait for  <0x00000000ec50c120> (a java.util.concurrent.ForkJoinPool)
>> at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1756)
>> at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1696)
>>
>> "main" #1 prio=5 os_prio=0 tid=0x00000000021ed000 nid=0x613d waiting on
>> condition [0x00007f852a508000]
>>    java.lang.Thread.State: WAITING (parking)
>> at sun.misc.Unsafe.park(Native Method)
>> - parking to wait for  <0x00000000ec50c518> (a
>> java.util.concurrent.CompletableFuture$WaitNode)
>> at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
>> at
>> java.util.concurrent.CompletableFuture$WaitNode.block(CompletableFuture.java:271)
>> at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3226)
>> at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:319)
>> at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:2292)
>>
>>
>>
>> On Tue, Apr 1, 2014 at 4:16 PM, Dennis Sosnoski <dms at sosnoski.com
>> <mailto:dms at sosnoski.com>> wrote:
>>
>>     I've run into a situation with CompletableFuture.thenCombine() hanging
>>     (i.e., the returned future never completing even though the original
>>     future and the combined one have completed) with the Oracle Java 8 release
>>     for 64-bit Linux. I wanted to run this by the group before creating a bug
>>     report to make sure I'm not misunderstanding how this is supposed to work.
>>     Here's the code:
>>
>>     public class CompletableFutureFail {
>>
>>         private Supplier<Integer> newLambda(int i) {
>>             return () -> Integer.valueOf(i);
>>         }
>>
>>         private Integer run(int n) {
>>             CompletableFuture<Integer> last =
>>     CompletableFuture.supplyAsync(newLambda(0));
>>             for (int i = 1; i < n; i++) {
>>                 last = CompletableFuture.supplyAsync(newLambda(i))
>>     .thenCombine(last, Math::max);
>>             }
>>             return last.join();
>>         }
>>
>>         public static void main(String[] args) {
>>             CompletableFutureFail fail = new CompletableFutureFail();
>>             for (int i = 0; i < 100; i++) {
>>                 fail.run(10000);
>>                 System.out.println("Did it " + i);
>>             }
>>         }
>>     }
>>
>>     When I run it from the command line it mostly doesn't make it through the
>>     first call to run(). Sometimes it does, but it generally only makes a few
>>     passes before hanging. In other circumstances (such as running inside
>>     Eclipse) I've seen it make it all the way through to the end, though most
>>     often it also hangs there in the first few passes. I'm thinking it might
>>     be Hotspot related because of the halting pattern.
>>
>>     Any suggestions?
>>
>>     Thanks,
>>
>>       - Dennis
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From aph at redhat.com  Wed Apr  2 07:34:47 2014
From: aph at redhat.com (Andrew Haley)
Date: Wed, 02 Apr 2014 12:34:47 +0100
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <52FE2C47.1080904@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>
	<52FE2C47.1080904@cs.oswego.edu>
Message-ID: <533BF5D7.8060504@redhat.com>

It seems to me that Doug and Hans disagree.

So, I'm going to put this to a vote.

Should CAS on Aarch64 be

	<Access [A]>

	// atomic_op (B)
1:	ldxr	x0, [B]		// Exclusive load
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b
	dmb	ish		// Full barrier

	<Access [C]>

or

	<Access [A]>

	// atomic_op (B)
1:	ldxar	x0, [B]		// Exclusive load with acquire
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b

	<Access [C]>

or something else?

Please reply with your choice.

Thanks,
Andrew.

From paul.sandoz at oracle.com  Wed Apr  2 08:06:44 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Wed, 2 Apr 2014 14:06:44 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
	hangs
In-Reply-To: <533B48E6.6050700@sosnoski.com>
References: <533B48E6.6050700@sosnoski.com>
Message-ID: <3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>


On Apr 2, 2014, at 1:16 AM, Dennis Sosnoski <dms at sosnoski.com> wrote:

> I've run into a situation with CompletableFuture.thenCombine() hanging (i.e., the returned future never completing even though the original future and the combined one have completed) with the Oracle Java 8 release for 64-bit Linux. I wanted to run this by the group before creating a bug report to make sure I'm not misunderstanding how this is supposed to work. Here's the code:
> 
> public class CompletableFutureFail {
> 
>    private Supplier<Integer> newLambda(int i) {
>        return () -> Integer.valueOf(i);
>    }
> 
>    private Integer run(int n) {
>        CompletableFuture<Integer> last = CompletableFuture.supplyAsync(newLambda(0));
>        for (int i = 1; i < n; i++) {
>            last = CompletableFuture.supplyAsync(newLambda(i)) .thenCombine(last, Math::max);
>        }
>        return last.join();
>    }
> 
>    public static void main(String[] args) {
>        CompletableFutureFail fail = new CompletableFutureFail();
>        for (int i = 0; i < 100; i++) {
>            fail.run(10000);
>            System.out.println("Did it " + i);
>        }
>    }
> }
> 
> When I run it from the command line it mostly doesn't make it through the first call to run(). Sometimes it does, but it generally only makes a few passes before hanging. In other circumstances (such as running inside Eclipse) I've seen it make it all the way through to the end, though most often it also hangs there in the first few passes. I'm thinking it might be Hotspot related because of the halting pattern.
> 

My gut feeling is that it is more likely to be a race condition in the CompletableFuture.thenCombine and completion linked list management code.

I cannot reproduce:

1) if there is more work to do:

    private Supplier<Integer> newLambda(int i) {
        return () -> {
            BigInteger bi = BigInteger.probablePrime(64, ThreadLocalRandom.current());
            return Integer.valueOf(bi.hashCode());
        };
    }

2) changed to use "thenCombineAsync".

Some test code below shows that all suppliers are run (also easy to set a break point within the block of "if (cld.getCount() == 1) {", to analyze data structures).

Paul.

public class Test {

    static Map<Integer, Integer> m = new ConcurrentHashMap<>();
    static List<CompletableFuture<Integer>> tasks = new ArrayList<>();

    private Supplier<Integer> newLambda(int i) {
        return () -> {
            m.put(i, i);
            return i;
        };
    }

    private Integer run(int n) {
        CompletableFuture<Integer> last = CompletableFuture.supplyAsync(newLambda(0));
        last.join();
        tasks.add(last);
        for (int i = 1; i < n; i++) {
            last = CompletableFuture.supplyAsync(newLambda(i))
                    .thenCombine(last, Math::max);
            tasks.add(last);
        }
        System.out.println(last);
        return last.join();
    }


    public static void main(String[] args) {
        Test fail = new Test();
        for (int i = 0; i < 1000000; i++) {
            m.clear();
            tasks.clear();

            CountDownLatch cld = new CountDownLatch(1);
            Thread t = new Thread(() -> {
                try {
                    cld.await(2, TimeUnit.SECONDS);
                }
                catch (InterruptedException e) {
                }

                if (cld.getCount() == 1) {
                    List<CompletableFuture<Integer>> it = tasks.stream().filter(task -> !task.isDone()).collect(toList());
                    System.out.printf("%d tasks not completed\n", it.size());
                }
            });

            t.start();
            fail.run(5000);
            cld.countDown();
            System.out.println("Did it " + i);
        }
    }
}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/01718113/attachment.bin>

From vitalyd at gmail.com  Wed Apr  2 08:40:32 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 2 Apr 2014 08:40:32 -0400
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <533BF5D7.8060504@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
	<52FE162C.9080301@redhat.com> <52FE2C47.1080904@cs.oswego.edu>
	<533BF5D7.8060504@redhat.com>
Message-ID: <CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>

Seems like #1 is what most people would expect from CAS (and that would
match x86 semantics).

What do c++11 compilers emit for strong cas on AArch64?

Sent from my phone
On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:

> It seems to me that Doug and Hans disagree.
>
> So, I'm going to put this to a vote.
>
> Should CAS on Aarch64 be
>
>         <Access [A]>
>
>         // atomic_op (B)
> 1:      ldxr    x0, [B]         // Exclusive load
>         <op(B)>
>         stlxr   w1, x0, [B]     // Exclusive store with release
>         cbnz    w1, 1b
>         dmb     ish             // Full barrier
>
>         <Access [C]>
>
> or
>
>         <Access [A]>
>
>         // atomic_op (B)
> 1:      ldxar   x0, [B]         // Exclusive load with acquire
>         <op(B)>
>         stlxr   w1, x0, [B]     // Exclusive store with release
>         cbnz    w1, 1b
>
>         <Access [C]>
>
> or something else?
>
> Please reply with your choice.
>
> Thanks,
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/1da8992d/attachment.html>

From dl at cs.oswego.edu  Wed Apr  2 08:50:30 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 02 Apr 2014 08:50:30 -0400
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <533BF5D7.8060504@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>	<52FE2C47.1080904@cs.oswego.edu>
	<533BF5D7.8060504@redhat.com>
Message-ID: <533C0796.1020504@cs.oswego.edu>

On 04/02/2014 07:34 AM, Andrew Haley wrote:
> It seems to me that Doug and Hans disagree.
>
> So, I'm going to put this to a vote.

Backing up first. The current specs for CAS say only
(in java.util.concurrent.atomic package docs):

   compareAndSet ... have the memory effects of both reading and writing
   volatile variables.

Conservative mappings for volatiles on AArch64 are
volatile-read : load-acquire.
volatile-write : store-release followed by dmb.

The straightforward mapping for CAS using these is more conservative
than either of your options:

	<Access [A]>
	// atomic_op (B)
1:	ldxar	x0, [B]		// Exclusive load with acquire
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b
	dmb	ish		// Full barrier
	<Access [C]>

So if you want to do something uncontroversial
pending further analysis, you could stick with this
and avoid voting for now.

Your two options weaken this in different ways, and
the questions become whether either could detectably
impact any guarantees and whether either could conflict
with any internal openJDK/hotspot assumptions.
And also whether an improved spec for CAS in the style
of C11/C++-11 for revised JMM would matter.

-Doug

>
> Should CAS on Aarch64 be
>
> 	<Access [A]>
>
> 	// atomic_op (B)
> 1:	ldxr	x0, [B]		// Exclusive load
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
> 	dmb	ish		// Full barrier
>
> 	<Access [C]>
>
> or
>
> 	<Access [A]>
>
> 	// atomic_op (B)
> 1:	ldxar	x0, [B]		// Exclusive load with acquire
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
>
> 	<Access [C]>
>
> or something else?
>
> Please reply with your choice.
>
> Thanks,
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From aph at redhat.com  Wed Apr  2 10:11:51 2014
From: aph at redhat.com (Andrew Haley)
Date: Wed, 02 Apr 2014 15:11:51 +0100
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>	<52FE2C47.1080904@cs.oswego.edu>	<533BF5D7.8060504@redhat.com>
	<CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>
Message-ID: <533C1AA7.4080608@redhat.com>

On 04/02/2014 01:40 PM, Vitaly Davidovich wrote:
> Seems like #1 is what most people would expect from CAS (and that would
> match x86 semantics).
> 
> What do c++11 compilers emit for strong cas on AArch64?

bool cas (std::atomic<int> *obj, int expected, int desired) {
  return obj->compare_exchange_strong(expected, desired, std::memory_order_seq_cst);
}


cas(std::atomic<int>*, int, int):
	sub	sp, sp, #16
	str	w1, [sp]
.L2:
	ldaxr	w3, [x0]
	cmp	w3, w1
	bne	.L3
	stlxr	w4, w2, [x0]
	cbnz	w4, .L2
.L3:
	cset	w0, eq
	add	sp, sp, 16
	ret

> 
> Sent from my phone
> On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:
> 
>> It seems to me that Doug and Hans disagree.
>>
>> So, I'm going to put this to a vote.
>>
>> Should CAS on Aarch64 be
>>
>>         <Access [A]>
>>
>>         // atomic_op (B)
>> 1:      ldxr    x0, [B]         // Exclusive load
>>         <op(B)>
>>         stlxr   w1, x0, [B]     // Exclusive store with release
>>         cbnz    w1, 1b
>>         dmb     ish             // Full barrier
>>
>>         <Access [C]>
>>
>> or
>>
>>         <Access [A]>
>>
>>         // atomic_op (B)
>> 1:      ldxar   x0, [B]         // Exclusive load with acquire
>>         <op(B)>
>>         stlxr   w1, x0, [B]     // Exclusive store with release
>>         cbnz    w1, 1b
>>
>>         <Access [C]>
>>
>> or something else?
>>
>> Please reply with your choice.
>>
>> Thanks,
>> Andrew.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> 


From aph at redhat.com  Wed Apr  2 10:16:42 2014
From: aph at redhat.com (Andrew Haley)
Date: Wed, 02 Apr 2014 15:16:42 +0100
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <533C0796.1020504@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>	<52FE2C47.1080904@cs.oswego.edu>	<533BF5D7.8060504@redhat.com>
	<533C0796.1020504@cs.oswego.edu>
Message-ID: <533C1BCA.9050201@redhat.com>

On 04/02/2014 01:50 PM, Doug Lea wrote:
> Backing up first. The current specs for CAS say only
> (in java.util.concurrent.atomic package docs):
> 
>    compareAndSet ... have the memory effects of both reading and writing
>    volatile variables.
> 
> Conservative mappings for volatiles on AArch64 are
> volatile-read : load-acquire.
> volatile-write : store-release followed by dmb.

Well, yes... but I thought you wrote the specs, so I was rather hoping
that you'd know what you meant by this.  I know that the specs for CAS
don't really say what it means.

> So if you want to do something uncontroversial pending further
> analysis, you could stick with this and avoid voting for now.

That seems reasonable, I agree.

> Your two options weaken this in different ways, and the questions
> become whether either could detectably impact any guarantees and
> whether either could conflict with any internal openJDK/hotspot
> assumptions.  And also whether an improved spec for CAS in the style
> of C11/C++-11 for revised JMM would matter.

Andrew.

From vitalyd at gmail.com  Wed Apr  2 10:53:06 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 2 Apr 2014 10:53:06 -0400
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <533C1AA7.4080608@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
	<52FE162C.9080301@redhat.com> <52FE2C47.1080904@cs.oswego.edu>
	<533BF5D7.8060504@redhat.com>
	<CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>
	<533C1AA7.4080608@redhat.com>
Message-ID: <CAHjP37E8YDdHvo6a-+HgSXfx0ig+yfEBaVO6BxotyTXOTOjLiQ@mail.gmail.com>

So no dmb here? Is that expected for sequentially consistent mode?

Sent from my phone
On Apr 2, 2014 10:12 AM, "Andrew Haley" <aph at redhat.com> wrote:

> On 04/02/2014 01:40 PM, Vitaly Davidovich wrote:
> > Seems like #1 is what most people would expect from CAS (and that would
> > match x86 semantics).
> >
> > What do c++11 compilers emit for strong cas on AArch64?
>
> bool cas (std::atomic<int> *obj, int expected, int desired) {
>   return obj->compare_exchange_strong(expected, desired,
> std::memory_order_seq_cst);
> }
>
>
> cas(std::atomic<int>*, int, int):
>         sub     sp, sp, #16
>         str     w1, [sp]
> .L2:
>         ldaxr   w3, [x0]
>         cmp     w3, w1
>         bne     .L3
>         stlxr   w4, w2, [x0]
>         cbnz    w4, .L2
> .L3:
>         cset    w0, eq
>         add     sp, sp, 16
>         ret
>
> >
> > Sent from my phone
> > On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:
> >
> >> It seems to me that Doug and Hans disagree.
> >>
> >> So, I'm going to put this to a vote.
> >>
> >> Should CAS on Aarch64 be
> >>
> >>         <Access [A]>
> >>
> >>         // atomic_op (B)
> >> 1:      ldxr    x0, [B]         // Exclusive load
> >>         <op(B)>
> >>         stlxr   w1, x0, [B]     // Exclusive store with release
> >>         cbnz    w1, 1b
> >>         dmb     ish             // Full barrier
> >>
> >>         <Access [C]>
> >>
> >> or
> >>
> >>         <Access [A]>
> >>
> >>         // atomic_op (B)
> >> 1:      ldxar   x0, [B]         // Exclusive load with acquire
> >>         <op(B)>
> >>         stlxr   w1, x0, [B]     // Exclusive store with release
> >>         cbnz    w1, 1b
> >>
> >>         <Access [C]>
> >>
> >> or something else?
> >>
> >> Please reply with your choice.
> >>
> >> Thanks,
> >> Andrew.
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/1a78e335/attachment-0001.html>

From aph at redhat.com  Wed Apr  2 11:09:19 2014
From: aph at redhat.com (Andrew Haley)
Date: Wed, 02 Apr 2014 16:09:19 +0100
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAHjP37E8YDdHvo6a-+HgSXfx0ig+yfEBaVO6BxotyTXOTOjLiQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>	<52FE2C47.1080904@cs.oswego.edu>	<533BF5D7.8060504@redhat.com>	<CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>	<533C1AA7.4080608@redhat.com>
	<CAHjP37E8YDdHvo6a-+HgSXfx0ig+yfEBaVO6BxotyTXOTOjLiQ@mail.gmail.com>
Message-ID: <533C281F.2050003@redhat.com>

On 04/02/2014 03:53 PM, Vitaly Davidovich wrote:
> So no dmb here? Is that expected for sequentially consistent mode?

I don't understand what you are asking.  Do we need an extra DMB for
sequential consistency?  AFAIK, no: this code is correct.  But there
is so much fog surrounding this that it's hard to say.

> Sent from my phone
> On Apr 2, 2014 10:12 AM, "Andrew Haley" <aph at redhat.com> wrote:
> 
>> On 04/02/2014 01:40 PM, Vitaly Davidovich wrote:
>>> Seems like #1 is what most people would expect from CAS (and that would
>>> match x86 semantics).
>>>
>>> What do c++11 compilers emit for strong cas on AArch64?
>>
>> bool cas (std::atomic<int> *obj, int expected, int desired) {
>>   return obj->compare_exchange_strong(expected, desired,
>> std::memory_order_seq_cst);
>> }
>>
>>
>> cas(std::atomic<int>*, int, int):
>>         sub     sp, sp, #16
>>         str     w1, [sp]
>> .L2:
>>         ldaxr   w3, [x0]
>>         cmp     w3, w1
>>         bne     .L3
>>         stlxr   w4, w2, [x0]
>>         cbnz    w4, .L2
>> .L3:
>>         cset    w0, eq
>>         add     sp, sp, 16
>>         ret
>>
>>>
>>> Sent from my phone
>>> On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:
>>>
>>>> It seems to me that Doug and Hans disagree.
>>>>
>>>> So, I'm going to put this to a vote.
>>>>
>>>> Should CAS on Aarch64 be
>>>>
>>>>         <Access [A]>
>>>>
>>>>         // atomic_op (B)
>>>> 1:      ldxr    x0, [B]         // Exclusive load
>>>>         <op(B)>
>>>>         stlxr   w1, x0, [B]     // Exclusive store with release
>>>>         cbnz    w1, 1b
>>>>         dmb     ish             // Full barrier
>>>>
>>>>         <Access [C]>
>>>>
>>>> or
>>>>
>>>>         <Access [A]>
>>>>
>>>>         // atomic_op (B)
>>>> 1:      ldxar   x0, [B]         // Exclusive load with acquire
>>>>         <op(B)>
>>>>         stlxr   w1, x0, [B]     // Exclusive store with release
>>>>         cbnz    w1, 1b
>>>>
>>>>         <Access [C]>
>>>>
>>>> or something else?
>>>>
>>>> Please reply with your choice.
>>>>
>>>> Thanks,
>>>> Andrew.
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>
>>
> 


From vitalyd at gmail.com  Wed Apr  2 11:18:55 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 2 Apr 2014 11:18:55 -0400
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <533C281F.2050003@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
	<52FE162C.9080301@redhat.com> <52FE2C47.1080904@cs.oswego.edu>
	<533BF5D7.8060504@redhat.com>
	<CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>
	<533C1AA7.4080608@redhat.com>
	<CAHjP37E8YDdHvo6a-+HgSXfx0ig+yfEBaVO6BxotyTXOTOjLiQ@mail.gmail.com>
	<533C281F.2050003@redhat.com>
Message-ID: <CAHjP37HbaObhCviER622QJTV5OPn4nzi3cioRhfHz4fKyKYUdQ@mail.gmail.com>

Yes, that was my question :).  Indeed, it's a bit hard to figure out what
exactly is required.

Sent from my phone
On Apr 2, 2014 11:09 AM, "Andrew Haley" <aph at redhat.com> wrote:

> On 04/02/2014 03:53 PM, Vitaly Davidovich wrote:
> > So no dmb here? Is that expected for sequentially consistent mode?
>
> I don't understand what you are asking.  Do we need an extra DMB for
> sequential consistency?  AFAIK, no: this code is correct.  But there
> is so much fog surrounding this that it's hard to say.
>
> > Sent from my phone
> > On Apr 2, 2014 10:12 AM, "Andrew Haley" <aph at redhat.com> wrote:
> >
> >> On 04/02/2014 01:40 PM, Vitaly Davidovich wrote:
> >>> Seems like #1 is what most people would expect from CAS (and that would
> >>> match x86 semantics).
> >>>
> >>> What do c++11 compilers emit for strong cas on AArch64?
> >>
> >> bool cas (std::atomic<int> *obj, int expected, int desired) {
> >>   return obj->compare_exchange_strong(expected, desired,
> >> std::memory_order_seq_cst);
> >> }
> >>
> >>
> >> cas(std::atomic<int>*, int, int):
> >>         sub     sp, sp, #16
> >>         str     w1, [sp]
> >> .L2:
> >>         ldaxr   w3, [x0]
> >>         cmp     w3, w1
> >>         bne     .L3
> >>         stlxr   w4, w2, [x0]
> >>         cbnz    w4, .L2
> >> .L3:
> >>         cset    w0, eq
> >>         add     sp, sp, 16
> >>         ret
> >>
> >>>
> >>> Sent from my phone
> >>> On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:
> >>>
> >>>> It seems to me that Doug and Hans disagree.
> >>>>
> >>>> So, I'm going to put this to a vote.
> >>>>
> >>>> Should CAS on Aarch64 be
> >>>>
> >>>>         <Access [A]>
> >>>>
> >>>>         // atomic_op (B)
> >>>> 1:      ldxr    x0, [B]         // Exclusive load
> >>>>         <op(B)>
> >>>>         stlxr   w1, x0, [B]     // Exclusive store with release
> >>>>         cbnz    w1, 1b
> >>>>         dmb     ish             // Full barrier
> >>>>
> >>>>         <Access [C]>
> >>>>
> >>>> or
> >>>>
> >>>>         <Access [A]>
> >>>>
> >>>>         // atomic_op (B)
> >>>> 1:      ldxar   x0, [B]         // Exclusive load with acquire
> >>>>         <op(B)>
> >>>>         stlxr   w1, x0, [B]     // Exclusive store with release
> >>>>         cbnz    w1, 1b
> >>>>
> >>>>         <Access [C]>
> >>>>
> >>>> or something else?
> >>>>
> >>>> Please reply with your choice.
> >>>>
> >>>> Thanks,
> >>>> Andrew.
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at cs.oswego.edu
> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>
> >>>
> >>
> >>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/bdcab0a0/attachment.html>

From martinrb at google.com  Wed Apr  2 12:34:33 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 2 Apr 2014 09:34:33 -0700
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAHjP37HbaObhCviER622QJTV5OPn4nzi3cioRhfHz4fKyKYUdQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
	<52FE162C.9080301@redhat.com> <52FE2C47.1080904@cs.oswego.edu>
	<533BF5D7.8060504@redhat.com>
	<CAHjP37F2ULXB70D4Nxs46OXn7jhsufCenTKAG96Hpmi1_dKOQQ@mail.gmail.com>
	<533C1AA7.4080608@redhat.com>
	<CAHjP37E8YDdHvo6a-+HgSXfx0ig+yfEBaVO6BxotyTXOTOjLiQ@mail.gmail.com>
	<533C281F.2050003@redhat.com>
	<CAHjP37HbaObhCviER622QJTV5OPn4nzi3cioRhfHz4fKyKYUdQ@mail.gmail.com>
Message-ID: <CA+kOe0_4S19jnO9pP8JsJt-Y5m5M9A3DFU_taOCvNJKr_ng1kA@mail.gmail.com>

You want to watch Herb Sutter's talk
http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2
around 0:53
but the entire codegen section of his talk from 0:26 touches on different
architectures.
Frustratingly the "ARM v8 CAS" box of Herb's table is empty.
We could ask Herb what's up with that!
But Herb does have an entry for ARM v7 CAS, and that would conservatively
work for ARM v8 as well.  Perhaps that's the intent.  (Of course, this is
for C++, not Java)


On Wed, Apr 2, 2014 at 8:18 AM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Yes, that was my question :).  Indeed, it's a bit hard to figure out what
> exactly is required.
>
> Sent from my phone
> On Apr 2, 2014 11:09 AM, "Andrew Haley" <aph at redhat.com> wrote:
>
>> On 04/02/2014 03:53 PM, Vitaly Davidovich wrote:
>> > So no dmb here? Is that expected for sequentially consistent mode?
>>
>> I don't understand what you are asking.  Do we need an extra DMB for
>> sequential consistency?  AFAIK, no: this code is correct.  But there
>> is so much fog surrounding this that it's hard to say.
>>
>> > Sent from my phone
>> > On Apr 2, 2014 10:12 AM, "Andrew Haley" <aph at redhat.com> wrote:
>> >
>> >> On 04/02/2014 01:40 PM, Vitaly Davidovich wrote:
>> >>> Seems like #1 is what most people would expect from CAS (and that
>> would
>> >>> match x86 semantics).
>> >>>
>> >>> What do c++11 compilers emit for strong cas on AArch64?
>> >>
>> >> bool cas (std::atomic<int> *obj, int expected, int desired) {
>> >>   return obj->compare_exchange_strong(expected, desired,
>> >> std::memory_order_seq_cst);
>> >> }
>> >>
>> >>
>> >> cas(std::atomic<int>*, int, int):
>> >>         sub     sp, sp, #16
>> >>         str     w1, [sp]
>> >> .L2:
>> >>         ldaxr   w3, [x0]
>> >>         cmp     w3, w1
>> >>         bne     .L3
>> >>         stlxr   w4, w2, [x0]
>> >>         cbnz    w4, .L2
>> >> .L3:
>> >>         cset    w0, eq
>> >>         add     sp, sp, 16
>> >>         ret
>> >>
>> >>>
>> >>> Sent from my phone
>> >>> On Apr 2, 2014 7:39 AM, "Andrew Haley" <aph at redhat.com> wrote:
>> >>>
>> >>>> It seems to me that Doug and Hans disagree.
>> >>>>
>> >>>> So, I'm going to put this to a vote.
>> >>>>
>> >>>> Should CAS on Aarch64 be
>> >>>>
>> >>>>         <Access [A]>
>> >>>>
>> >>>>         // atomic_op (B)
>> >>>> 1:      ldxr    x0, [B]         // Exclusive load
>> >>>>         <op(B)>
>> >>>>         stlxr   w1, x0, [B]     // Exclusive store with release
>> >>>>         cbnz    w1, 1b
>> >>>>         dmb     ish             // Full barrier
>> >>>>
>> >>>>         <Access [C]>
>> >>>>
>> >>>> or
>> >>>>
>> >>>>         <Access [A]>
>> >>>>
>> >>>>         // atomic_op (B)
>> >>>> 1:      ldxar   x0, [B]         // Exclusive load with acquire
>> >>>>         <op(B)>
>> >>>>         stlxr   w1, x0, [B]     // Exclusive store with release
>> >>>>         cbnz    w1, 1b
>> >>>>
>> >>>>         <Access [C]>
>> >>>>
>> >>>> or something else?
>> >>>>
>> >>>> Please reply with your choice.
>> >>>>
>> >>>> Thanks,
>> >>>> Andrew.
>> >>>> _______________________________________________
>> >>>> Concurrency-interest mailing list
>> >>>> Concurrency-interest at cs.oswego.edu
>> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>>>
>> >>>
>> >>
>> >>
>> >
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140402/31e8169e/attachment.html>

From dms at sosnoski.com  Wed Apr  2 17:06:35 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Thu, 03 Apr 2014 10:06:35 +1300
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>
References: <533B48E6.6050700@sosnoski.com>
	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>
Message-ID: <533C7BDB.90403@sosnoski.com>

On 04/03/2014 01:06 AM, Paul Sandoz wrote:
> On Apr 2, 2014, at 1:16 AM, Dennis Sosnoski <dms at sosnoski.com> wrote:
>
>> ...
>>
>> When I run it from the command line it mostly doesn't make it through the first call to run(). Sometimes it does, but it generally only makes a few passes before hanging. In other circumstances (such as running inside Eclipse) I've seen it make it all the way through to the end, though most often it also hangs there in the first few passes. I'm thinking it might be Hotspot related because of the halting pattern.
>>
> My gut feeling is that it is more likely to be a race condition in the CompletableFuture.thenCombine and completion linked list management code.

What I meant to say in my original email was that it seemed like the 
failure either occurred in the first few loop executions or not at all, 
and I thought it might relate to optimizations in the JVM eliminating 
the window for this to occur. But even if that's the case, there still 
has to be a problem either in the classes or the VM implementation, and 
this would show up with "random" failures in other code.

I first saw the problem with a slightly more complex set of 
calculations, just reduced it down to what I provided to keep things simple.

   - Dennis


From paul.sandoz at oracle.com  Thu Apr  3 04:28:51 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 3 Apr 2014 10:28:51 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
	hangs
In-Reply-To: <533C7BDB.90403@sosnoski.com>
References: <533B48E6.6050700@sosnoski.com>
	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>
	<533C7BDB.90403@sosnoski.com>
Message-ID: <F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>


On Apr 2, 2014, at 11:06 PM, Dennis Sosnoski <dms at sosnoski.com> wrote:

> On 04/03/2014 01:06 AM, Paul Sandoz wrote:
>> On Apr 2, 2014, at 1:16 AM, Dennis Sosnoski <dms at sosnoski.com> wrote:
>> 
>>> ...
>>> 
>>> When I run it from the command line it mostly doesn't make it through the first call to run(). Sometimes it does, but it generally only makes a few passes before hanging. In other circumstances (such as running inside Eclipse) I've seen it make it all the way through to the end, though most often it also hangs there in the first few passes. I'm thinking it might be Hotspot related because of the halting pattern.
>>> 
>> My gut feeling is that it is more likely to be a race condition in the CompletableFuture.thenCombine and completion linked list management code.
> 
> What I meant to say in my original email was that it seemed like the failure either occurred in the first few loop executions or not at all, and I thought it might relate to optimizations in the JVM eliminating the window for this to occur. But even if that's the case, there still has to be a problem either in the classes or the VM implementation, and this would show up with "random" failures in other code.
> 
> I first saw the problem with a slightly more complex set of calculations, just reduced it down to what I provided to keep things simple.
> 

Thanks, very much appreciated.

I think i may have found the cause, my initial gut feeling was wrong about a race condition :-)

It appears to be caused by a StackOverflowException being thrown when an async task attempts to complete all its dependent tasks in the completion chain. That exception gets swallowed and does not propagate.

This behaviour is likely exacerbated because the default F/J pool (common pool) is LIFO-based, so precedence will be given for later tasks to execute before earlier tasks, thus setting up the scenario for a StackOverflowException to occur.

See example code below, where the first async task will not complete until subsequent async tasks have done so, which creates a very long completion chain.

Not quite sure how it fix it... might require the use of an explicit stack on the heap, plus it might point to a general weakness in CompletableFuture for handling exceptions thrown by the framework (e.g. OutOfMemoryError).

Paul.

public class Test2 {

    static List<CompletableFuture<Integer>> tasks = new ArrayList<>();

    private Integer run(int n) {
        CountDownLatch cdl = new CountDownLatch(n - 1);

        CompletableFuture<Integer> last = CompletableFuture.supplyAsync(() -> {
            try {
                cdl.await();
            }
            catch (InterruptedException e) { }
            return 0;
        });

        tasks.add(last);
        for (int i = 1; i < n; i++) {
            final int v = i;
            last = CompletableFuture.supplyAsync(() -> {
                cdl.countDown();
                return v;
            }).thenCombine(last, Integer::max);
            tasks.add(last);
        }
        return last.join();
    }

    public static void main(String[] args) {
        Test2 fail = new Test2();

        CountDownLatch cld = new CountDownLatch(1);
        Thread t = new Thread(() -> {
            try {
                cld.await(2, TimeUnit.SECONDS);
            }
            catch (InterruptedException e) {
            }

            if (cld.getCount() == 1) {
                List<CompletableFuture<Integer>> it = tasks.stream().filter(task -> !task.isDone()).collect(toList());
                System.out.printf("%d tasks not completed\n", it.size());
            }
        });

        t.start();
        fail.run(10000);
        cld.countDown();
    }
}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140403/ec2bd8d0/attachment.bin>

From dl at cs.oswego.edu  Thu Apr  3 07:08:20 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 03 Apr 2014 07:08:20 -0400
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
References: <533B48E6.6050700@sosnoski.com>	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>	<533C7BDB.90403@sosnoski.com>
	<F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
Message-ID: <533D4124.9020507@cs.oswego.edu>

On 04/03/2014 04:28 AM, Paul Sandoz wrote:

> It appears to be caused by a StackOverflowException being thrown when an
> async task attempts to complete all its dependent tasks in the completion
> chain. That exception gets swallowed and does not propagate.

Thanks! I'll look into ways of ensuring that StackOverflowException,
OutOfMemoryError, and the like at least get reported. These have
a history of being difficult to deal with, but we can surely do
better.

-Doug

From viktor.klang at gmail.com  Thu Apr  3 11:00:59 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 3 Apr 2014 17:00:59 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
	hangs
In-Reply-To: <533D4124.9020507@cs.oswego.edu>
References: <533B48E6.6050700@sosnoski.com>
	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>
	<533C7BDB.90403@sosnoski.com>
	<F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
	<533D4124.9020507@cs.oswego.edu>
Message-ID: <CANPzfU-DL+sHLjgUYOHZAO60TJrbzk=7uDv=s1hL7Ph4oXxxhw@mail.gmail.com>

In Scala, we solve these problems primarily by:

* Always executing callbacks *asynchronously[1]*?i.e. we get a
*trampolining* effect that avoids StackOverflowErrors.
* Always *compressing[2]* intermittent futures, so that *asynchronous tail
calls[3]* (potentially nested "infinite" thenCompose) don't lead to a long
chain of intermittent Futures that have no use (avoiding OutOfMemoryErrors).

[1]:
https://github.com/viktorklang/scala/blob/master/src/library/scala/concurrent/impl/Promise.scala#L35
[2]:
https://github.com/scala/scala/blob/master/src/library/scala/concurrent/impl/Promise.scala#L289
[3]: Example: https://gist.github.com/viktorklang/9414163



On Thu, Apr 3, 2014 at 1:08 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 04/03/2014 04:28 AM, Paul Sandoz wrote:
>
>  It appears to be caused by a StackOverflowException being thrown when an
>> async task attempts to complete all its dependent tasks in the completion
>> chain. That exception gets swallowed and does not propagate.
>>
>
> Thanks! I'll look into ways of ensuring that StackOverflowException,
> OutOfMemoryError, and the like at least get reported. These have
> a history of being difficult to deal with, but we can surely do
> better.
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140403/8e38e41c/attachment-0001.html>

From peter.levart at gmail.com  Thu Apr  3 11:06:43 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 03 Apr 2014 17:06:43 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <533D4124.9020507@cs.oswego.edu>
References: <533B48E6.6050700@sosnoski.com>	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>	<533C7BDB.90403@sosnoski.com>	<F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
	<533D4124.9020507@cs.oswego.edu>
Message-ID: <533D7903.3010407@gmail.com>

On 04/03/2014 01:08 PM, Doug Lea wrote:
> On 04/03/2014 04:28 AM, Paul Sandoz wrote:
>
>> It appears to be caused by a StackOverflowException being thrown when an
>> async task attempts to complete all its dependent tasks in the 
>> completion
>> chain. That exception gets swallowed and does not propagate.
>
> Thanks! I'll look into ways of ensuring that StackOverflowException,
> OutOfMemoryError, and the like at least get reported. These have
> a history of being difficult to deal with, but we can surely do
> better.
>
> -Doug

Hi Doug, Paul,

This explains why I saw a CompletableFuture with result != null (done), 
but it still had a non-empty stack of Completers left behind.

Paul's idea of having an off-stack "stack" is easily achievable. There 
already is such a stack - the CompletableFuture.completers stack.

Here's a dirty hack that (ab)uses it:

http://cr.openjdk.java.net/~plevart/jdk9-dev/CompletableFuture/webrev.01/

The re-linking of Completers from one CompletableFuture's stack to the 
other's does reverse  the order of execution of Completers that were 
initially added to the stack of the first CompletableFuture. Does the 
order of execution of Completers matter?

Anyway, the thenCombine() test passes with that change.


Regards, Peter

> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dms at sosnoski.com  Thu Apr  3 16:15:56 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Fri, 04 Apr 2014 09:15:56 +1300
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
References: <533B48E6.6050700@sosnoski.com>
	<3315E470-C217-4319-B900-7CB98C8AAEC9@oracle.com>
	<533C7BDB.90403@sosnoski.com>
	<F5D3C810-BDE2-433F-B939-A940442289CC@oracle.com>
Message-ID: <533DC17C.7040906@sosnoski.com>

On 04/03/2014 09:28 PM, Paul Sandoz wrote:
> I think i may have found the cause, my initial gut feeling was wrong about a race condition :-)
>
> It appears to be caused by a StackOverflowException being thrown when an async task attempts to complete all its dependent tasks in the completion chain. That exception gets swallowed and does not propagate.
>
> This behaviour is likely exacerbated because the default F/J pool (common pool) is LIFO-based, so precedence will be given for later tasks to execute before earlier tasks, thus setting up the scenario for a StackOverflowException to occur.
>
> See example code below, where the first async task will not complete until subsequent async tasks have done so, which creates a very long completion chain.
>
> Not quite sure how it fix it... might require the use of an explicit stack on the heap, plus it might point to a general weakness in CompletableFuture for handling exceptions thrown by the framework (e.g. OutOfMemoryError).

Better than a race condition, anyway!

Thanks,

   - Dennis


From blackdrag at gmx.org  Fri Apr  4 05:40:26 2014
From: blackdrag at gmx.org (Jochen Theodorou)
Date: Fri, 04 Apr 2014 11:40:26 +0200
Subject: [concurrency-interest] improving pcollections?
Message-ID: <533E7E0A.4080803@gmx.org>

Hi,

I hope this is not taken as advertisement - I am interested in improving 
the pcollections library, which I took over recently. For example adding 
a HAMT. But I wonder if I am the only one with interest in that library 
and if others are happy with Clojure and functional Java libraries. I am 
asking because now would be a good time for changes to the library.

As for why I did not use the alternatives... there seem to be too heavy 
weight or not fitting my needs.

bye Jochen

-- 
Jochen "blackdrag" Theodorou - Groovy Project Tech Lead
blog: http://blackdragsview.blogspot.com/
german groovy discussion newsgroup: de.comp.lang.misc
For Groovy programming sources visit http://groovy-lang.org


From philipa at mail.com  Sat Apr  5 10:08:19 2014
From: philipa at mail.com (Philip Aston)
Date: Sat, 05 Apr 2014 15:08:19 +0100
Subject: [concurrency-interest] JCIP annotations: @GuardedBy
Message-ID: <53400E53.6060808@mail.com>


Does anyone use the JCIP annotations? What's your take on the following?

We use the Java Concurrency In Practice annotations. This is mostly a
documentation discipline, but it also helps findbugs
<http://findbugs.sourceforge.net/manual/annotations.html> tell us not to
be stupid.

The class level @Immutable / @ThreadSafe / @NotThreadSafe are useful and
self explanatory.

Unfortunately, interpreted strictly according to JCIP Appendix A,
@GuardedBy is less so. It is not expressive enough to cover common
locking patterns. E.g. this might look right to the casual eye:

class Foo {
  @GuardedBy("bah")
  final Collection bah = new ArrayList();
}

but @GuardedBy refers to the field bah, which is final so doesn't need a
guard. There's no way to indicate access to the collection itself should
be guarded - e.g. that you must hold the lock on bah before iterating
over the collection.

The JCIP book ignores this distinction. E.g. Listing 11.6, page 236. I
find this a rare flaw in an otherwise very precise book. That "its
obvious what was intended" is a poor defence since the whole point of
the annotations is to specify intent.

Maybe Java 8 / JSR 308 is the answer and I should write something like:

    @Target({ ElementType.FIELD, ElementType.METHOD, ElementType.TYPE_USE })
    public @interface GuardedBy2 {
        String value();
    }

    final Collection bah = new @GuardedBy2("self") ArrayList();

but I'm on Java7, so

    final Collection bah = new /* GuardedBy("self") */ ArrayList();

for now.

Thoughts?

- Phil
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140405/cba63dfa/attachment.html>

From tim at peierls.net  Sat Apr  5 11:13:44 2014
From: tim at peierls.net (Tim Peierls)
Date: Sat, 5 Apr 2014 11:13:44 -0400
Subject: [concurrency-interest] JCIP annotations: @GuardedBy
In-Reply-To: <53400E53.6060808@mail.com>
References: <53400E53.6060808@mail.com>
Message-ID: <CA+F8eeTdRB7uDWEiDzLBz2RaVqOuhspSM6OwHx29HW5PBNFLiQ@mail.gmail.com>

It's a fair cop, but society is to blame -- or rather, our sense that the
society of Java developers, at the time that JCiP was written, was not
ready for a more elaborate system of annotations than what we settled on.
(It's not that we weren't aware of such systems; Doug Lea had many, many
draft proposals.)

We were concerned back then that forcing a set of complicated semantics on
users would guarantee that no one except experts would use them. We
thought, and I still think, that there is pedagogical value in this
simplified set beyond even the obvious practical benefits of FindBugs
support.

Remember, too, that although JSR 308 existed at the time, we couldn't rely
on its inclusion in the platform. (Good thing we didn't!)

The book's treatment of this subject is out of date, superseded by JSR 305.
It might be time to update the specs in javax.annotation.concurrent.
Purists would object, I'm sure, but just by expanding the syntactical
possibilities of the String value of @GuardedBy one could cover a lot of
ground with a minimum of fuss.

--tim


On Sat, Apr 5, 2014 at 10:08 AM, Philip Aston <philipa at mail.com> wrote:

>
> Does anyone use the JCIP annotations? What's your take on the following?
>
> We use the Java Concurrency In Practice annotations. This is mostly a
> documentation discipline, but it also helps findbugs<http://findbugs.sourceforge.net/manual/annotations.html>tell us not to be stupid.
>
> The class level @Immutable / @ThreadSafe / @NotThreadSafe are useful and
> self explanatory.
>
> Unfortunately, interpreted strictly according to JCIP Appendix A,
> @GuardedBy is less so. It is not expressive enough to cover common locking
> patterns. E.g. this might look right to the casual eye:
>
> class Foo {
>   @GuardedBy("bah")
>   final Collection bah = new ArrayList();
> }
>
> but @GuardedBy refers to the field bah, which is final so doesn't need a
> guard. There's no way to indicate access to the collection itself should be
> guarded - e.g. that you must hold the lock on bah before iterating over
> the collection.
>
> The JCIP book ignores this distinction. E.g. Listing 11.6, page 236. I
> find this a rare flaw in an otherwise very precise book. That "its obvious
> what was intended" is a poor defence since the whole point of the
> annotations is to specify intent.
>
> Maybe Java 8 / JSR 308 is the answer and I should write something like:
>
>     @Target({ ElementType.FIELD, ElementType.METHOD, ElementType.TYPE_USE
> })
>     public @interface GuardedBy2 {
>         String value();
>     }
>
>     final Collection bah = new @GuardedBy2("self") ArrayList();
>
> but I'm on Java7, so
>
>     final Collection bah = new /* GuardedBy("self") */ ArrayList();
>
> for now.
>
> Thoughts?
>
> - Phil
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140405/98753992/attachment.html>

From philipa at mail.com  Sun Apr  6 03:48:20 2014
From: philipa at mail.com (Philip Aston)
Date: Sun, 06 Apr 2014 08:48:20 +0100
Subject: [concurrency-interest] JCIP annotations: @GuardedBy
In-Reply-To: <CA+F8eeTdRB7uDWEiDzLBz2RaVqOuhspSM6OwHx29HW5PBNFLiQ@mail.gmail.com>
References: <53400E53.6060808@mail.com>
	<CA+F8eeTdRB7uDWEiDzLBz2RaVqOuhspSM6OwHx29HW5PBNFLiQ@mail.gmail.com>
Message-ID: <534106C4.6080308@mail.com>

Thanks Tim.

It's good to know I'm not missing something.

- Phil

On 05/04/14 16:13, Tim Peierls wrote:
> It's a fair cop, but society is to blame -- or rather, our sense that
> the society of Java developers, at the time that JCiP was written, was
> not ready for a more elaborate system of annotations than what we
> settled on. (It's not that we weren't aware of such systems; Doug Lea
> had many, many draft proposals.)
>
> We were concerned back then that forcing a set of complicated
> semantics on users would guarantee that no one except experts would
> use them. We thought, and I still think, that there is pedagogical
> value in this simplified set beyond even the obvious practical
> benefits of FindBugs support.
>
> Remember, too, that although JSR 308 existed at the time, we couldn't
> rely on its inclusion in the platform. (Good thing we didn't!)
>
> The book's treatment of this subject is out of date, superseded by JSR
> 305. It might be time to update the specs in
> javax.annotation.concurrent. Purists would object, I'm sure, but just
> by expanding the syntactical possibilities of the String value of
> @GuardedBy one could cover a lot of ground with a minimum of fuss.
>
> --tim
>
>
> On Sat, Apr 5, 2014 at 10:08 AM, Philip Aston <philipa at mail.com
> <mailto:philipa at mail.com>> wrote:
>
>
>     Does anyone use the JCIP annotations? What's your take on the
>     following?
>
>     We use the Java Concurrency In Practice annotations. This is
>     mostly a documentation discipline, but it also helps findbugs
>     <http://findbugs.sourceforge.net/manual/annotations.html> tell us
>     not to be stupid.
>
>     The class level @Immutable / @ThreadSafe / @NotThreadSafe are
>     useful and self explanatory.
>
>     Unfortunately, interpreted strictly according to JCIP Appendix A,
>     @GuardedBy is less so. It is not expressive enough to cover common
>     locking patterns. E.g. this might look right to the casual eye:
>
>     class Foo {
>       @GuardedBy("bah")
>       final Collection bah = new ArrayList();
>     }
>
>     but @GuardedBy refers to the field bah, which is final so doesn't
>     need a guard. There's no way to indicate access to the collection
>     itself should be guarded - e.g. that you must hold the lock on bah
>     before iterating over the collection.
>
>     The JCIP book ignores this distinction. E.g. Listing 11.6, page
>     236. I find this a rare flaw in an otherwise very precise book.
>     That "its obvious what was intended" is a poor defence since the
>     whole point of the annotations is to specify intent.
>
>     Maybe Java 8 / JSR 308 is the answer and I should write something
>     like:
>
>         @Target({ ElementType.FIELD, ElementType.METHOD,
>     ElementType.TYPE_USE })
>         public @interface GuardedBy2 {
>             String value();
>         }
>
>         final Collection bah = new @GuardedBy2("self") ArrayList();
>
>     but I'm on Java7, so
>
>         final Collection bah = new /* GuardedBy("self") */ ArrayList();
>
>     for now.
>
>     Thoughts?
>
>     - Phil
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140406/8dd11f6b/attachment.html>

From dl at cs.oswego.edu  Sun Apr  6 17:40:28 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 06 Apr 2014 17:40:28 -0400
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <533B48E6.6050700@sosnoski.com>
References: <533B48E6.6050700@sosnoski.com>
Message-ID: <5341C9CC.4080104@cs.oswego.edu>


On 04/01/2014 07:16 PM, Dennis Sosnoski wrote:
> I've run into a situation with CompletableFuture.thenCombine() hanging (i.e.,
> the returned future never completing even though the original future and the
> combined one have completed)
> ...

>          for (int i = 1; i < n; i++) {
>              last = CompletableFuture.supplyAsync(newLambda(i))
> .thenCombine(last, Math::max);
>          }
>          return last.join();
>      }
>

Which, as Paul Sandoz noted, was due to a StackOverflowError.
Even though this code looks like a loop, it was evaluated recursively
(across multiple threads) which can blow up default-sized runtime
stacks even when n is 10000 or so.

The StackOverflowError was correctly managed by one (or more)
of the intermediate CompletableFutures in the long chain
constructed. But the above code loses reference to intermediate
stages so never noticed. There is probably not very much we can
or should do about this from within CompletableFuture.

However, we can rework propagation in the case of linear
dependency chains, which are the only cases in which these
kinds of StackOverflowErrors occur. By re-packing actions
while processing dependent completions, we can isolate
tail-recursive cases and loopify them. This generally works out
better than moving them across lists, because doing so can
reduce opportunities for other threads to help process them.

I checked in a version that does this at
 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CompletableFuture.java?view=log
Also compiled into the jar at
   http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar
that you can run with -Xbootclasspath

Feel free to try it out. If no problems, I'll start the process
for submitting as a JDK8 update.

Again, the aim here is to avoid StackOverflowError in cases
where users would not expect it. We cannot remove all possible
causes of this or any other resource error.

Thanks to Paul, Martin, Viktor, and Peter for the helpful
suggestions which led to this one.

-Doug


From chris.hegarty at oracle.com  Mon Apr  7 09:03:48 2014
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Mon, 07 Apr 2014 14:03:48 +0100
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <5341C9CC.4080104@cs.oswego.edu>
References: <533B48E6.6050700@sosnoski.com> <5341C9CC.4080104@cs.oswego.edu>
Message-ID: <5342A234.4030608@oracle.com>


On 06/04/14 22:40, Doug Lea wrote:
> ....
> Feel free to try it out. If no problems, I'll start the process
> for submitting as a JDK8 update.

I filed a bug in the OpenJDK JIRA to track this:
   https://bugs.openjdk.java.net/browse/JDK-8039378

If/When you are happy we can pull this into JDK 9, and then request 
approval for an 8 Update.

-Chris.

From viktor.klang at gmail.com  Tue Apr  8 09:38:14 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 8 Apr 2014 15:38:14 +0200
Subject: [concurrency-interest] Queue quest
Message-ID: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>

Hey everyone,

I thought I'd throw this question out there before I go all out NIH.

Does anybody know of an open source (apache 2 compatible) "minimal
overhead", non-blocking, bounded, non-constant-space (i.e. no ringbuffer or
preallocated size array) multiple-producer
single-consumer/multiple-consumer queues in Java/bytecode?



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/e23fbfaa/attachment.html>

From comm at sergey-mashkov.net  Tue Apr  8 12:07:22 2014
From: comm at sergey-mashkov.net (Sergey Mashkov)
Date: Tue, 08 Apr 2014 09:07:22 -0700
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
Message-ID: <b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>

Hi Viktor

Well, if it will not make you anger, why don't you mention Java's 
LinkedBlockingQueue? In 99% cases it's sufficient so you generally don't 
need lock-free algos.

By the way I don't think it's possible to implement in practice actually 
efficient non-blocking queue with no preallocated buffer.

Kind regards
Sergey

?iktor ?lang ????? 2014-04-08 06:38:
> Hey everyone,
> 
> I thought I'd throw this question out there before I go all out NIH.
> 
> Does anybody know of an open source (apache 2 compatible) "minimal
> overhead", non-blocking, bounded, non-constant-space (i.e. no
> ringbuffer or preallocated size array) multiple-producer
> single-consumer/multiple-consumer queues in Java/bytecode?
> 
> --
> 
>  Cheers,
> ?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Tue Apr  8 12:17:25 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 8 Apr 2014 18:17:25 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
Message-ID: <CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>

Hi Sergey,

On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov <comm at sergey-mashkov.net>wrote:

> Hi Viktor
>
> Well, if it will not make you anger, why don't you mention Java's
> LinkedBlockingQueue? In 99% cases it's sufficient so you generally don't
> need lock-free algos.
>

Yep, that's a good fallback, but I figured I'd ask first :)


>
> By the way I don't think it's possible to implement in practice actually
> efficient non-blocking queue with no preallocated buffer.
>

Well, for some definition of efficient :-)
Given that most queues spend their lives either full or empty, a
preallocated buffer may not make sense in case there are many millions of
them and they spend their lives mostly empty.


>
> Kind regards
> Sergey
>
> ?iktor ?lang ????? 2014-04-08 06:38:
>
>> Hey everyone,
>>
>> I thought I'd throw this question out there before I go all out NIH.
>>
>> Does anybody know of an open source (apache 2 compatible) "minimal
>> overhead", non-blocking, bounded, non-constant-space (i.e. no
>> ringbuffer or preallocated size array) multiple-producer
>> single-consumer/multiple-consumer queues in Java/bytecode?
>>
>> --
>>
>>  Cheers,
>> ?
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/dad7a35b/attachment.html>

From comm at sergey-mashkov.net  Tue Apr  8 13:01:51 2014
From: comm at sergey-mashkov.net (Sergey Mashkov)
Date: Tue, 08 Apr 2014 10:01:51 -0700
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
Message-ID: <99fc0ce9fc2675603229968c44421837@sergey-mashkov.net>

?iktor ?lang ????? 2014-04-08 09:17:
> Hi Sergey,
> 
> On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov
> <comm at sergey-mashkov.net> wrote:
> 
>> Hi Viktor
>> 
>> Well, if it will not make you anger, why don't you mention Java's
>> LinkedBlockingQueue? In 99% cases it's sufficient so you generally
>> don't need lock-free algos.
> 
> Yep, that's a good fallback, but I figured I'd ask first :)
> ?
> 
>> By the way I don't think it's possible to implement in practice
>> actually efficient non-blocking queue with no preallocated buffer.
> 
> Well, for some definition of efficient :-)

Of course efficiency is very depends on usecase and criteria. In some 
cases lock-free algorithms could be even more expensive than old-school 
onces. So lock-free is not gold bullet that could rule all of us ;)

> Given that most queues spend their lives either full or empty, a
> preallocated buffer may not make sense in case there are many millions
> of them and they spend their lives mostly empty.
> ?

Agree, my point was that if you don't have preallocated array then you 
have two options: linked list of elements or linked list of small 
buffers. If you have linked list then you have to pay for GC overhead in 
case of high throughput. If you have list of chunks then enlarge logic 
will be difficult to make lock-free so it will have lock somewhere 
anyway or very dangerous loops/ifs that will eat time during spins. Also 
if you want to have it bounded then it will increase complexity even 
more. You actually have third option: use something like copy on write 
array list but it will lead to big overhead on copying everything so it 
will die very quickly so this options is just a joke :) This is why I 
don't think it could be implemented to conform all requirements you 
mentioned.

> 
>> Kind regards
>> Sergey
>> 
>> ?iktor ?lang ????? 2014-04-08 06:38:
>> 
>>> Hey everyone,
>>> 
>>> I thought I'd throw this question out there before I go all out
>>> NIH.
>>> 
>>> Does anybody know of an open source (apache 2 compatible)
>>> "minimal
>>> overhead", non-blocking, bounded, non-constant-space (i.e. no
>>> ringbuffer or preallocated size array) multiple-producer
>>> single-consumer/multiple-consumer queues in Java/bytecode?
>>> 
>>> --
>>> 
>>> ?Cheers,
>>> ?
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
> 
> --
> 
>  Cheers,
> ?
> 
> Links:
> ------
> [1] http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From comm at sergey-mashkov.net  Tue Apr  8 13:05:20 2014
From: comm at sergey-mashkov.net (Sergey Mashkov)
Date: Tue, 08 Apr 2014 10:05:20 -0700
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
Message-ID: <e680da98a7114b567b63301c1e7586e0@sergey-mashkov.net>

Just found interesting try: https://gist.github.com/alphazero/1680422  
and https://gist.github.com/alphazero/1680371

But it's better to rerun his tests on new hardware with new JVMs since 
it's two years old. And for your usecase. May be it will not be so good 
as alphazero talking ;)

?iktor ?lang ????? 2014-04-08 06:38:
> Hey everyone,
> 
> I thought I'd throw this question out there before I go all out NIH.
> 
> Does anybody know of an open source (apache 2 compatible) "minimal
> overhead", non-blocking, bounded, non-constant-space (i.e. no
> ringbuffer or preallocated size array) multiple-producer
> single-consumer/multiple-consumer queues in Java/bytecode?
> 
> --
> 
>  Cheers,
> ?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From nitsanw at yahoo.com  Tue Apr  8 13:13:52 2014
From: nitsanw at yahoo.com (Nitsan Wakart)
Date: Tue, 8 Apr 2014 10:13:52 -0700 (PDT)
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
Message-ID: <1396977232.30598.YahooMailNeo@web120702.mail.ne1.yahoo.com>

I'm busy building a lock free queue library:?https://github.com/nitsanw/JAQ-InABox
It's early stages, an I admit to not having what you are after at this point. The MPSC bounded queue is allot faster than the JDK variety but it is an array backed one to the bounded size. I think I can see a way to match your requirement but perhaps we can take it off list so I can have more detail.
On Tuesday, April 8, 2014 6:25 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
 
Hi Sergey,


On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov <comm at sergey-mashkov.net> wrote:

Hi Viktor
>
>Well, if it will not make you anger, why don't you mention Java's LinkedBlockingQueue? In 99% cases it's sufficient so you generally don't need lock-free algos.
>

Yep, that's a good fallback, but I figured I'd ask first :)
?

>By the way I don't think it's possible to implement in practice actually efficient non-blocking queue with no preallocated buffer.
>

Well, for some definition of efficient :-)
Given that most queues spend their lives either full or empty, a preallocated buffer may not make sense in case there are many millions of them and they spend their lives mostly empty.
?

>Kind regards
>Sergey
>
>?iktor ?lang ????? 2014-04-08 06:38:
>
>Hey everyone,
>>
>>I thought I'd throw this question out there before I go all out NIH.
>>
>>Does anybody know of an open source (apache 2 compatible) "minimal
>>overhead", non-blocking, bounded, non-constant-space (i.e. no
>>ringbuffer or preallocated size array) multiple-producer
>>single-consumer/multiple-consumer queues in Java/bytecode?
>>
>>--
>>
>>?Cheers,
>>?
>>
_______________________________________________
>>Concurrency-interest mailing list
>>Concurrency-interest at cs.oswego.edu
>>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>



-- 

Cheers,
?

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/e0845b2b/attachment-0001.html>

From ariel at weisberg.ws  Tue Apr  8 13:18:20 2014
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Tue, 08 Apr 2014 13:18:20 -0400
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
Message-ID: <1396977500.26506.104175781.7DE1335E@webmail.messagingengine.com>

Hi,



I am interested in a unbounded blocking multiple producer single
consumer queue. I was thinking of
taking [1]https://github.com/netty/netty/blob/master/common/src/main/ja
va/io/netty/util/internal/MpscLinkedQueue.java and adding a field for
the consumer to populate with it's Thread when parking.



If a producer calling unpark also nulls out the field you can avoid
redundant unparks. You can avoid lost unparks by checking the queue
after populating the field, but before parking. For hot threads there
is no locking to facilitate blocking, and roughly the minimum amount of
locking when unpark needs to be called.



You can convert any MPSC queue this way since the operation of the
queue is independent of the mechanism used for blocking. If the
principal behind blocking and unblocking is sound it will be as good as
the underlying queue.



I know MpscLinkedQueue is originally from Akka. Have you compared it's
non-blocking performance to ConcurrentLinkedQueue or
LinkedTransferQueue?



MPMC I have no ideas. That is obviously a harder problem, but it also
doesn't happen to be my problem. For me MPMC scenarios occur when task
sizes are large. When task sizes are small I don't need work stealing
(or I need it but don't provide it).



Regards,

Ariel

On Tue, Apr 8, 2014, at 12:17 PM, ?iktor ?lang wrote:

Hi Sergey,

On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov
<[2]comm at sergey-mashkov.net> wrote:

Hi Viktor



Well, if it will not make you anger, why don't you mention Java's
LinkedBlockingQueue? In 99% cases it's sufficient so you generally
don't need lock-free algos.


Yep, that's a good fallback, but I figured I'd ask first :)



By the way I don't think it's possible to implement in practice
actually efficient non-blocking queue with no preallocated buffer.


Well, for some definition of efficient :-)
Given that most queues spend their lives either full or empty, a
preallocated buffer may not make sense in case there are many millions
of them and they spend their lives mostly empty.



Kind regards

Sergey



?iktor ?lang ????? 2014-04-08 06:38:



Hey everyone,

I thought I'd throw this question out there before I go all out NIH.

Does anybody know of an open source (apache 2 compatible) "minimal
overhead", non-blocking, bounded, non-constant-space (i.e. no
ringbuffer or preallocated size array) multiple-producer
single-consumer/multiple-consumer queues in Java/bytecode?

--

 Cheers,
?

_______________________________________________

Concurrency-interest mailing list

[3]Concurrency-interest at cs.oswego.edu

[4]http://cs.oswego.edu/mailman/listinfo/concurrency-interest





_______________________________________________

Concurrency-interest mailing list

[5]Concurrency-interest at cs.oswego.edu

[6]http://cs.oswego.edu/mailman/listinfo/concurrency-interest






--
Cheers,
?

_______________________________________________

Concurrency-interest mailing list

[7]Concurrency-interest at cs.oswego.edu

[8]http://cs.oswego.edu/mailman/listinfo/concurrency-interest

References

1. https://github.com/netty/netty/blob/master/common/src/main/java/io/netty/util/internal/MpscLinkedQueue.java
2. mailto:comm at sergey-mashkov.net
3. mailto:Concurrency-interest at cs.oswego.edu
4. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
5. mailto:Concurrency-interest at cs.oswego.edu
6. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
7. mailto:Concurrency-interest at cs.oswego.edu
8. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/f2a75dfc/attachment.html>

From ariel at weisberg.ws  Tue Apr  8 13:28:42 2014
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Tue, 08 Apr 2014 13:28:42 -0400
Subject: [concurrency-interest] Queue quest
In-Reply-To: <1396977500.26506.104175781.7DE1335E@webmail.messagingengine.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
	<1396977500.26506.104175781.7DE1335E@webmail.messagingengine.com>
Message-ID: <1396978122.28968.104199877.50B2B487@webmail.messagingengine.com>

Hi,



I apologize for stomping on your thread. I misread and thought you said
unbounded.



Regards,

Ariel





On Tue, Apr 8, 2014, at 01:18 PM, Ariel Weisberg wrote:

Hi,


I am interested in a unbounded blocking multiple producer single
consumer queue. I was thinking of
taking [1]https://github.com/netty/netty/blob/master/common/src/main/ja
va/io/netty/util/internal/MpscLinkedQueue.java and adding a field for
the consumer to populate with it's Thread when parking.


If a producer calling unpark also nulls out the field you can avoid
redundant unparks. You can avoid lost unparks by checking the queue
after populating the field, but before parking. For hot threads there
is no locking to facilitate blocking, and roughly the minimum amount of
locking when unpark needs to be called.


You can convert any MPSC queue this way since the operation of the
queue is independent of the mechanism used for blocking. If the
principal behind blocking and unblocking is sound it will be as good as
the underlying queue.


I know MpscLinkedQueue is originally from Akka. Have you compared it's
non-blocking performance to ConcurrentLinkedQueue or
LinkedTransferQueue?


MPMC I have no ideas. That is obviously a harder problem, but it also
doesn't happen to be my problem. For me MPMC scenarios occur when task
sizes are large. When task sizes are small I don't need work stealing
(or I need it but don't provide it).


Regards,

Ariel

On Tue, Apr 8, 2014, at 12:17 PM, ?iktor ?lang wrote:

Hi Sergey,

On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov
<[2]comm at sergey-mashkov.net> wrote:

Hi Viktor


Well, if it will not make you anger, why don't you mention Java's
LinkedBlockingQueue? In 99% cases it's sufficient so you generally
don't need lock-free algos.


Yep, that's a good fallback, but I figured I'd ask first :)


By the way I don't think it's possible to implement in practice
actually efficient non-blocking queue with no preallocated buffer.


Well, for some definition of efficient :-)
Given that most queues spend their lives either full or empty, a
preallocated buffer may not make sense in case there are many millions
of them and they spend their lives mostly empty.


Kind regards

Sergey


?iktor ?lang ????? 2014-04-08 06:38:


Hey everyone,

I thought I'd throw this question out there before I go all out NIH.

Does anybody know of an open source (apache 2 compatible) "minimal
overhead", non-blocking, bounded, non-constant-space (i.e. no
ringbuffer or preallocated size array) multiple-producer
single-consumer/multiple-consumer queues in Java/bytecode?

--

 Cheers,
?

_______________________________________________

Concurrency-interest mailing list

[3]Concurrency-interest at cs.oswego.edu

[4]http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________

Concurrency-interest mailing list

[5]Concurrency-interest at cs.oswego.edu

[6]http://cs.oswego.edu/mailman/listinfo/concurrency-interest





--
Cheers,
?

_______________________________________________

Concurrency-interest mailing list

[7]Concurrency-interest at cs.oswego.edu

[8]http://cs.oswego.edu/mailman/listinfo/concurrency-interest

References

1. https://github.com/netty/netty/blob/master/common/src/main/java/io/netty/util/internal/MpscLinkedQueue.java
2. mailto:comm at sergey-mashkov.net
3. mailto:Concurrency-interest at cs.oswego.edu
4. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
5. mailto:Concurrency-interest at cs.oswego.edu
6. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
7. mailto:Concurrency-interest at cs.oswego.edu
8. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/3400336c/attachment.html>

From viktor.klang at gmail.com  Tue Apr  8 17:42:08 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 8 Apr 2014 23:42:08 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <99fc0ce9fc2675603229968c44421837@sergey-mashkov.net>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
	<99fc0ce9fc2675603229968c44421837@sergey-mashkov.net>
Message-ID: <CANPzfU_LVNpTJQ1ihvF9YkSuodiXQ22XwJYgEi0bu=3O=3PZdg@mail.gmail.com>

On Tue, Apr 8, 2014 at 7:01 PM, Sergey Mashkov <comm at sergey-mashkov.net>wrote:

> ?iktor ?lang ????? 2014-04-08 09:17:
>
>  Hi Sergey,
>>
>> On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov
>> <comm at sergey-mashkov.net> wrote:
>>
>>  Hi Viktor
>>>
>>> Well, if it will not make you anger, why don't you mention Java's
>>> LinkedBlockingQueue? In 99% cases it's sufficient so you generally
>>> don't need lock-free algos.
>>>
>>
>> Yep, that's a good fallback, but I figured I'd ask first :)
>>
>>
>>  By the way I don't think it's possible to implement in practice
>>> actually efficient non-blocking queue with no preallocated buffer.
>>>
>>
>> Well, for some definition of efficient :-)
>>
>
> Of course efficiency is very depends on usecase and criteria. In some
> cases lock-free algorithms could be even more expensive than old-school
> onces. So lock-free is not gold bullet that could rule all of us ;)


Absolutely, the bigger question is behavior under contention.


>
>
>  Given that most queues spend their lives either full or empty, a
>> preallocated buffer may not make sense in case there are many millions
>> of them and they spend their lives mostly empty.
>>
>>
>
> Agree, my point was that if you don't have preallocated array then you
> have two options: linked list of elements or linked list of small buffers.
> If you have linked list then you have to pay for GC overhead in case of
> high throughput.


However, in the case of high throughput the chance of objects dying young
is higher.


> If you have list of chunks then enlarge logic will be difficult to make
> lock-free so it will have lock somewhere anyway or very dangerous loops/ifs
> that will eat time during spins. Also if you want to have it bounded then
> it will increase complexity even more. You actually have third option: use
> something like copy on write array list but it will lead to big overhead on
> copying everything so it will die very quickly so this options is just a
> joke :) This is why I don't think it could be implemented to conform all
> requirements you mentioned.
>

The downside with a fixed quantity in the queue is the consensus amongst
writers it requires.
The question is if it is possible to "cheat".


>
>
>>  Kind regards
>>> Sergey
>>>
>>> ?iktor ?lang ????? 2014-04-08 06:38:
>>>
>>>  Hey everyone,
>>>>
>>>> I thought I'd throw this question out there before I go all out
>>>> NIH.
>>>>
>>>> Does anybody know of an open source (apache 2 compatible)
>>>> "minimal
>>>> overhead", non-blocking, bounded, non-constant-space (i.e. no
>>>> ringbuffer or preallocated size array) multiple-producer
>>>> single-consumer/multiple-consumer queues in Java/bytecode?
>>>>
>>>> --
>>>>
>>>>  Cheers,
>>>> ?
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
>>>
>>
>> --
>>
>>  Cheers,
>> ?
>>
>> Links:
>> ------
>> [1] http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/847a7376/attachment-0001.html>

From viktor.klang at gmail.com  Tue Apr  8 17:43:18 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 8 Apr 2014 23:43:18 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <1396977232.30598.YahooMailNeo@web120702.mail.ne1.yahoo.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
	<1396977232.30598.YahooMailNeo@web120702.mail.ne1.yahoo.com>
Message-ID: <CANPzfU-U6eNOgHbHHU74XN2Wp=dBq-0vwGxvKnZ7L+LeY6QLzQ@mail.gmail.com>

Please do share ideas if possible! :)


On Tue, Apr 8, 2014 at 7:13 PM, Nitsan Wakart <nitsanw at yahoo.com> wrote:

> I'm busy building a lock free queue library:
> https://github.com/nitsanw/JAQ-InABox
> It's early stages, an I admit to not having what you are after at this
> point. The MPSC bounded queue is allot faster than the JDK variety but it
> is an array backed one to the bounded size. I think I can see a way to
> match your requirement but perhaps we can take it off list so I can have
> more detail.
>   On Tuesday, April 8, 2014 6:25 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
>  Hi Sergey,
>
> On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov <comm at sergey-mashkov.net>wrote:
>
> Hi Viktor
>
> Well, if it will not make you anger, why don't you mention Java's
> LinkedBlockingQueue? In 99% cases it's sufficient so you generally don't
> need lock-free algos.
>
>
> Yep, that's a good fallback, but I figured I'd ask first :)
>
>
>
> By the way I don't think it's possible to implement in practice actually
> efficient non-blocking queue with no preallocated buffer.
>
>
> Well, for some definition of efficient :-)
> Given that most queues spend their lives either full or empty, a
> preallocated buffer may not make sense in case there are many millions of
> them and they spend their lives mostly empty.
>
>
>
> Kind regards
> Sergey
>
> ?iktor ?lang ????? 2014-04-08 06:38:
>
> Hey everyone,
>
> I thought I'd throw this question out there before I go all out NIH.
>
> Does anybody know of an open source (apache 2 compatible) "minimal
> overhead", non-blocking, bounded, non-constant-space (i.e. no
> ringbuffer or preallocated size array) multiple-producer
> single-consumer/multiple-consumer queues in Java/bytecode?
>
> --
>
>  Cheers,
> ?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/e9f7167b/attachment.html>

From viktor.klang at gmail.com  Tue Apr  8 17:44:11 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 8 Apr 2014 23:44:11 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <1396978122.28968.104199877.50B2B487@webmail.messagingengine.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
	<1396977500.26506.104175781.7DE1335E@webmail.messagingengine.com>
	<1396978122.28968.104199877.50B2B487@webmail.messagingengine.com>
Message-ID: <CANPzfU-raj2Sgr0b6=_m8uFp3OGv3drdfRfPvV4=xOWwjeG-QA@mail.gmail.com>

No probs!


On Tue, Apr 8, 2014 at 7:28 PM, Ariel Weisberg <ariel at weisberg.ws> wrote:

>  Hi,
>
> I apologize for stomping on your thread. I misread and thought you said
> unbounded.
>
> Regards,
> Ariel
>
>
> On Tue, Apr 8, 2014, at 01:18 PM, Ariel Weisberg wrote:
>
> Hi,
>
> I am interested in a unbounded blocking multiple producer single consumer
> queue. I was thinking of taking
> https://github.com/netty/netty/blob/master/common/src/main/java/io/netty/util/internal/MpscLinkedQueue.java and
> adding a field for the consumer to populate with it's Thread when parking.
>
> If a producer calling unpark also nulls out the field you can avoid
> redundant unparks. You can avoid lost unparks by checking the queue after
> populating the field, but before parking. For hot threads there is no
> locking to facilitate blocking, and roughly the minimum amount of locking
> when unpark needs to be called.
>
> You can convert any MPSC queue this way since the operation of the queue
> is independent of the mechanism used for blocking. If the principal behind
> blocking and unblocking is sound it will be as good as the underlying queue.
>
> I know MpscLinkedQueue is originally from Akka. Have you compared it's
> non-blocking performance to ConcurrentLinkedQueue or LinkedTransferQueue?
>
> MPMC I have no ideas. That is obviously a harder problem, but it also
> doesn't happen to be my problem. For me MPMC scenarios occur when task
> sizes are large. When task sizes are small I don't need work stealing (or I
> need it but don't provide it).
>
> Regards,
> Ariel
> On Tue, Apr 8, 2014, at 12:17 PM, ?iktor ?lang wrote:
>
> Hi Sergey,
>
> On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov <comm at sergey-mashkov.net>wrote:
>
>
> Hi Viktor
>
>  Well, if it will not make you anger, why don't you mention Java's
> LinkedBlockingQueue? In 99% cases it's sufficient so you generally don't
> need lock-free algos.
>
>
> Yep, that's a good fallback, but I figured I'd ask first :)
>
>
>
>  By the way I don't think it's possible to implement in practice actually
> efficient non-blocking queue with no preallocated buffer.
>
>
> Well, for some definition of efficient :-)
> Given that most queues spend their lives either full or empty, a
> preallocated buffer may not make sense in case there are many millions of
> them and they spend their lives mostly empty.
>
>
>
>  Kind regards
>  Sergey
>
>  ?iktor ?lang ????? 2014-04-08 06:38:
>
>
> Hey everyone,
>
>  I thought I'd throw this question out there before I go all out NIH.
>
>  Does anybody know of an open source (apache 2 compatible) "minimal
>  overhead", non-blocking, bounded, non-constant-space (i.e. no
>  ringbuffer or preallocated size array) multiple-producer
>  single-consumer/multiple-consumer queues in Java/bytecode?
>
>  --
>
>   Cheers,
>  ?
>  _______________________________________________
>  Concurrency-interest mailing list
>  Concurrency-interest at cs.oswego.edu
>  http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>  _______________________________________________
>  Concurrency-interest mailing list
>  Concurrency-interest at cs.oswego.edu
>  http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> --
>  Cheers,
> ?
>
>   *_______________________________________________*
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140408/50fafd73/attachment.html>

From vikas.vksingh at gmail.com  Wed Apr  9 02:20:54 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Tue, 8 Apr 2014 23:20:54 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
Message-ID: <1397024454362-10862.post@n7.nabble.com>

Hi just wanted a little clarification. 

I know the below code is broken and making _instance volatile would help 
fixing this this.  The reason for broken code is unsafe publication of
Singleton. Other threads can see non-null 
reference even before the object is fully constructed.

But if the Singleton is immutable i.e all instance fields are final, even
then would it be broken?.
AFAIK final fields give guarantees of safe publication of objects.
So my question is if i,j,k below are final do i need *_instance* to be
volatile. 

final class  Singleton {

          private static  Singleton _instance;

          public static Singleton getInstance() {
                            if(_instance == null) {
                                       synchronized(Singleton.class) {
                                                 if(_instance == null) {
                                                       _instance = new
Singleton();
                                                 }
                                       }
                             }
                            return _instance;
           }      
          
          private Singleton() {
                      i=9;
                      j=99;
                      k=999;
          }
          private int i,j,k;               
}



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From mthornton at optrak.com  Wed Apr  9 03:54:53 2014
From: mthornton at optrak.com (Mark Thornton)
Date: Wed, 9 Apr 2014 08:54:53 +0100
Subject: [concurrency-interest] Queue quest
In-Reply-To: <99fc0ce9fc2675603229968c44421837@sergey-mashkov.net>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<b04661274b6eccf9e1de3e5408e329a0@sergey-mashkov.net>
	<CANPzfU90aKG9X7wmj_EE60eUhyL28344THCtaVQy6corcTu6OA@mail.gmail.com>
	<99fc0ce9fc2675603229968c44421837@sergey-mashkov.net>
Message-ID: <CAC_SY70PXfpT+Y7yCwWB_5OQTiLYe=GAtj2FsMqs3SUYNJuKmQ@mail.gmail.com>

On Tuesday, 8 April 2014, Sergey Mashkov <comm at sergey-mashkov.net> wrote:

> ?iktor ?lang ????? 2014-04-08 09:17:
>
>> Hi Sergey,
>>
>> On Tue, Apr 8, 2014 at 6:07 PM, Sergey Mashkov
>> <comm at sergey-mashkov.net> wrote:
>>
>>  Hi Viktor
>>>
>>> Well, if it will not make you anger, why don't you mention Java's
>>> LinkedBlockingQueue? In 99% cases it's sufficient so you generally
>>> don't need lock-free algos.
>>>
>>
>> Yep, that's a good fallback, but I figured I'd ask first :)
>>
>>
>>  By the way I don't think it's possible to implement in practice
>>> actually efficient non-blocking queue with no preallocated buffer.
>>>
>>
>> Well, for some definition of efficient :-)
>>
>
> Of course efficiency is very depends on usecase and criteria. In some
> cases lock-free algorithms could be even more expensive than old-school
> onces. So lock-free is not gold bullet that could rule all of us ;)
>
>  Given that most queues spend their lives either full or empty, a
>> preallocated buffer may not make sense in case there are many millions
>> of them and they spend their lives mostly empty.
>>
>>
>
> Agree, my point was that if you don't have preallocated array then you
> have two options: linked list of elements or linked list of small buffers.
> If you have linked list then you have to pay for GC overhead in case of
> high throughput. If you have list of chunks then enlarge logic will be
> difficult to make lock-free so it will have lock somewhere anyway or very
> dangerous loops/ifs that will eat time during spins. Also if you want to
> have it bounded then it will increase complexity even more. You actually
> have third option: use something like copy on write array list but it will
> lead to big overhead on copying everything so it will die very quickly so
> this options is just a joke :) This is why I don't think it could be
> implemented to conform all requirements you mentioned.
>

There is one more case where you expect most queues to never contain more
than one (or perhaps two elements), in which case you keep that element in
the main object and never need to create an array at all.

Mark Thornton



>
>
>>  Kind regards
>>> Sergey
>>>
>>> ?iktor ?lang ????? 2014-04-08 06:38:
>>>
>>>  Hey everyone,
>>>>
>>>> I thought I'd throw this question out there before I go all out
>>>> NIH.
>>>>
>>>> Does anybody know of an open source (apache 2 compatible)
>>>> "minimal
>>>> overhead", non-blocking, bounded, non-constant-space (i.e. no
>>>> ringbuffer or preallocated size array) multiple-producer
>>>> single-consumer/multiple-consumer queues in Java/bytecode?
>>>>
>>>> --
>>>>
>>>>  Cheers,
>>>> ?
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest [1]
>>>
>>
>> --
>>
>>  Cheers,
>> ?
>>
>> Links:
>> ------
>> [1] http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/7a0c62ee/attachment-0001.html>

From concurrency at kuli.org  Wed Apr  9 04:46:35 2014
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Wed, 09 Apr 2014 10:46:35 +0200
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <1397024454362-10862.post@n7.nabble.com>
References: <1397024454362-10862.post@n7.nabble.com>
Message-ID: <534508EB.7050007@kuli.org>

Hi vikas,

you are absolutely right: _instance must be either volatile, or
Singleton must be immutable.

In this case it's easy since Singleton only has primitive types, so
marking all of them final makes Singleton immutable. It's getting more
problematic when Singleton contains values like HashMap or ArrayList; in
that case it's not enough to declare them as final because the values
themselves are not immutable. You'd had a safe publication of Singleton
itself then, but not of its contents.

The best choice would be to get rid of the lazy initialization
completely. I don't see a point here why Singleton shouldn't be
instantiated after the class has been loaded at all.

If you really need lazy initialization, it's better to put a static
final field into an inner class that does nothing else excepting keeping
this field. So the main class can be loaded without immediately
instantiating it, and Java's class loading mechanism can be used to
perform the lazy loading strategy.

-Kuli

Am 09.04.2014 08:20, schrieb vikas:
> Hi just wanted a little clarification. 
> 
> I know the below code is broken and making _instance volatile would help 
> fixing this this.  The reason for broken code is unsafe publication of
> Singleton. Other threads can see non-null 
> reference even before the object is fully constructed.
> 
> But if the Singleton is immutable i.e all instance fields are final, even
> then would it be broken?.
> AFAIK final fields give guarantees of safe publication of objects.
> So my question is if i,j,k below are final do i need *_instance* to be
> volatile. 
> 
> final class  Singleton {
> 
>           private static  Singleton _instance;
> 
>           public static Singleton getInstance() {
>                             if(_instance == null) {
>                                        synchronized(Singleton.class) {
>                                                  if(_instance == null) {
>                                                        _instance = new
> Singleton();
>                                                  }
>                                        }
>                              }
>                             return _instance;
>            }      
>           
>           private Singleton() {
>                       i=9;
>                       j=99;
>                       k=999;
>           }
>           private int i,j,k;               
> }
> 
> 
> 
> --
> View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From sitnikov.vladimir at gmail.com  Wed Apr  9 05:29:49 2014
From: sitnikov.vladimir at gmail.com (Vladimir Sitnikov)
Date: Wed, 9 Apr 2014 13:29:49 +0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <534508EB.7050007@kuli.org>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
Message-ID: <CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>

>It's getting more
>problematic when Singleton contains values like HashMap or ArrayList; in
>that case it's not enough to declare them as final because the values
>themselves are not immutable. You'd had a safe publication of Singleton
>itself then, but not of its contents.
This is false.
It works fine if you create HashMap and its contents in the same thread
that creates
Singleton _and_ you do _not_ leak the created objects before assigning the
value to _instance.

If the map in question was created in a different thread or you somehow
publish the reference
before Singleton constructor completes (i.e. Globals.staticField = this; in
constructor),
then crazy things can happen.

The order of initialization of the map and its contents does not matter.

For example, this is a safe publication of a map _and_ its contents.
However you'll have to synchronize mutations of the map if you need them.

final Map map;
Singleton() {
  map = new HashMap();
  map.put("answer", 42);
}

Vladimir
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/2ba306ad/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Apr  9 05:53:16 2014
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 9 Apr 2014 13:53:16 +0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
	(vikas)
Message-ID: <CAO-wXwKWCcHj+RdXRA_Z9b37FErw7N-qxrTAumzXTt3zcdUwdA@mail.gmail.com>

Yes, if i, j, k would be final your Singletor would be technically correct.
But I suppose invocations of getInstance() method MAY see _instance == null
more often than if field _instance would be volatile, and therefore
synchronized(...) block MAY be executed more often. Also I see no sense in
making your Singleton lazy, so you can just write
private static Singleton _instance = new Singleton();

code from the original question:

> final class  Singleton {
>           private static  Singleton _instance;
>           public static Singleton getInstance() {
>                             if(_instance == null) {
>                                        synchronized(Singleton.class) {
>                                                  if(_instance == null) {
>                                                        _instance = new
> Singleton();
>                                                  }
>                                        }
>                              }
>                             return _instance;
>            }
>           private Singleton() {
>                       i=9;
>                       j=99;
>                       k=999;
>           }
>           private int i,j,k;
> }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/fec1a0d0/attachment.html>

From concurrency at kuli.org  Wed Apr  9 05:55:42 2014
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Wed, 09 Apr 2014 11:55:42 +0200
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
Message-ID: <5345191E.6020101@kuli.org>

Am 09.04.2014 11:29, schrieb Vladimir Sitnikov:
>>It's getting more
>>problematic when Singleton contains values like HashMap or ArrayList; in
>>that case it's not enough to declare them as final because the values
>>themselves are not immutable. You'd had a safe publication of Singleton
>>itself then, but not of its contents.
> This is false.
> It works fine if you create HashMap and its contents in the same thread
> that creates
> Singleton _and_ you do _not_ leak the created objects before assigning
> the value to _instance.

My bad! You are right: As long as all fields of Singleton are final, the
publication is safe, independent of the mutability of their contents.

So forget what I wrote about HashMaps and ArrayLists.

Just one minor clarification:

It's of no matter whether _instance was assigned or not as long as
_instance if not volatile. You just mustn't leak the created objects
before the constructor execution is finished.

> 
> If the map in question was created in a different thread or you somehow
> publish the reference
> before Singleton constructor completes (i.e. Globals.staticField = this;
> in constructor),
> then crazy things can happen.
> 
> The order of initialization of the map and its contents does not matter.
> 
> For example, this is a safe publication of a map _and_ its contents.
> However you'll have to synchronize mutations of the map if you need them.
> 
> final Map map;
> Singleton() {
>   map = new HashMap();
>   map.put("answer", 42);
> }
> Vladimir

Correct.

-Kuli

From vikas.vksingh at gmail.com  Wed Apr  9 09:49:03 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Wed, 9 Apr 2014 06:49:03 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <5345191E.6020101@kuli.org>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
Message-ID: <1397051343398-10868.post@n7.nabble.com>

Thanks guys very much for clarification.



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10868.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From boehm at acm.org  Wed Apr  9 13:44:49 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 9 Apr 2014 10:44:49 -0700
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <1397051343398-10868.post@n7.nabble.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
Message-ID: <CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>

This code is wrong as written, for a different reason, unless _instance is
volatile.  The two reads of _instance in getInstance() can be performed out
of order and getInstance() can return null if another thread initializes it
concurrently.  If you really need to do this, there should be exactly one
read of _instance outslde the critical section. If this code is not so
performance critical that you absolutely need to do this, don't, and use
the volatile declaration.  The next person changing your code may also miss
problems like this, and it may take years to track down the resulting
intermittent problem.

Hans


On Wed, Apr 9, 2014 at 6:49 AM, vikas <vikas.vksingh at gmail.com> wrote:

> Thanks guys very much for clarification.
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10868.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/38c266b2/attachment.html>

From aleksey.shipilev at oracle.com  Wed Apr  9 14:23:35 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 09 Apr 2014 22:23:35 +0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>	<534508EB.7050007@kuli.org>	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>	<5345191E.6020101@kuli.org>	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
Message-ID: <53459027.2000201@oracle.com>

+1.

See also:
 http://hg.openjdk.java.net/code-tools/jcstress/file/tip/tests-custom/src/main/java/org/openjdk/jcstress/tests/singletons

What Hans is saying is here:
 http://hg.openjdk.java.net/code-tools/jcstress/file/tip/tests-custom/src/main/java/org/openjdk/jcstress/tests/singletons/UnsafeLocalDCLSingletonTest.java

-Aleksey.

On 04/09/2014 09:44 PM, Hans Boehm wrote:
> This code is wrong as written, for a different reason, unless _instance
> is volatile.  The two reads of _instance in getInstance() can be
> performed out of order and getInstance() can return null if another
> thread initializes it concurrently.  If you really need to do this,
> there should be exactly one read of _instance outslde the critical
> section. If this code is not so performance critical that you absolutely
> need to do this, don't, and use the volatile declaration.  The next
> person changing your code may also miss problems like this, and it may
> take years to track down the resulting intermittent problem.
> 
> Hans
> 
> 
> On Wed, Apr 9, 2014 at 6:49 AM, vikas <vikas.vksingh at gmail.com
> <mailto:vikas.vksingh at gmail.com>> wrote:
> 
>     Thanks guys very much for clarification.
> 
> 
> 
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10868.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From vikas.vksingh at gmail.com  Wed Apr  9 15:08:26 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Wed, 9 Apr 2014 12:08:26 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
Message-ID: <1397070506598-10871.post@n7.nabble.com>

Thanks Hans for pointing it out. 
I completely agree. Same debate on Stackoverflow 
http://stackoverflow.com/questions/14624365/immutability-and-reordering

thanks
vikas



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10871.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From zhong.j.yu at gmail.com  Wed Apr  9 21:32:25 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 9 Apr 2014 20:32:25 -0500
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <1397070506598-10871.post@n7.nabble.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
Message-ID: <CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>

> http://stackoverflow.com/questions/14624365/immutability-and-reordering

I agree with the conclusions, however I think it is flawed to argue
that if a transformation is valid from a single-thread point of view,
it is allowed by JMM. By that argument, a perfectly good code
    if( (tmp=resource) != null )
        return tmp;
can be transformed to a very bad code
    if( resource != null )
        return resource;   // [r1]
since they are equivalent in single-thread.

JMM only talks about reads/writes in the program source. Here [r1] did
not exist in the program source, how could the compiler reason about
its effect? Can the compiler ever introduce such ghost reads with
confidence of correctness?

Back to the original problem, can this code
    if( resource != null )
        return resource;
be transformed to
    tmp = resource;  // [r2]
    if( resource != null )
        return tmp;
? The compiler now does two reads unconditionally; [r2] would be a
ghost read that did not exist in the source, unless the if() condition
is true, but how could the compiler reach that prediction?

Zhong Yu

From vitalyd at gmail.com  Wed Apr  9 22:47:33 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 9 Apr 2014 22:47:33 -0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
Message-ID: <CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>

Compiler can assume single threaded execution unless told otherwise; in
that case, introducing phantom reads will not change observable behavior of
single threaded execution.

Sent from my phone
On Apr 9, 2014 9:35 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> > http://stackoverflow.com/questions/14624365/immutability-and-reordering
>
> I agree with the conclusions, however I think it is flawed to argue
> that if a transformation is valid from a single-thread point of view,
> it is allowed by JMM. By that argument, a perfectly good code
>     if( (tmp=resource) != null )
>         return tmp;
> can be transformed to a very bad code
>     if( resource != null )
>         return resource;   // [r1]
> since they are equivalent in single-thread.
>
> JMM only talks about reads/writes in the program source. Here [r1] did
> not exist in the program source, how could the compiler reason about
> its effect? Can the compiler ever introduce such ghost reads with
> confidence of correctness?
>
> Back to the original problem, can this code
>     if( resource != null )
>         return resource;
> be transformed to
>     tmp = resource;  // [r2]
>     if( resource != null )
>         return tmp;
> ? The compiler now does two reads unconditionally; [r2] would be a
> ghost read that did not exist in the source, unless the if() condition
> is true, but how could the compiler reach that prediction?
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/b0103835/attachment.html>

From boehm at acm.org  Thu Apr 10 01:39:17 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 9 Apr 2014 22:39:17 -0700
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
Message-ID: <CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>

Not all transformations that are valid in a single-threaded environment are
valid in Java.  (Or even in C/C++ with threads, which generally allow more
transformations than Java.)  In a single-threaded program, a compiler can
always introduce an x = x; assignment to an accessible program variable.
 In some contexts, that even turns out to be profitable, normally to
correct for a misspeculation.  That is not valid in C, C++, or Java, since
it may introduce a data race and hide a concurrent assignment to x.  (Gcc
occasionally does it, through about gcc 4.6, however.)

The exact Java semantics here are a bit unclear, since everyone now agrees
that the semantics for racing accesses in the Java memory model are a bit
buggy.  (One of the reasons to avoid them where possible.)  But if you look
at the rules, it is reasonably clear that reads from the same location can
be performed out of order.  There are good reasons for that.  Otherwise the
compiler wouldn't be able to reorder two loads through references x and y
without proving that they don't alias.  (This was one of the motivations
for the 2005 memory model revision.) And some hardware allows ordinary
loads from the same location to be performed out of order (either
intentionally or due to hardware errata).

Introducing a second load where the original code loaded it once into a
temporary, and used the temporary twice, is illegal in Java (but legal in
C++, since only racy programs can tell the difference.)

In general, there is no problem with the compiler introducing additional
dead loads, i.e. loads whose result isn't used.  As Zhong Yu points out,
that would happen on one control path if the compiler reorders the loads.
 But (a) that's fine, and (b) it's not an issue at the hardware level.
 Hardware issues speculative loads all the time, discarding the results if
the speculation proves wrong.

Hans


On Wed, Apr 9, 2014 at 7:47 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Compiler can assume single threaded execution unless told otherwise; in
> that case, introducing phantom reads will not change observable behavior of
> single threaded execution.
>
> Sent from my phone
> On Apr 9, 2014 9:35 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>
>> > http://stackoverflow.com/questions/14624365/immutability-and-reordering
>>
>> I agree with the conclusions, however I think it is flawed to argue
>> that if a transformation is valid from a single-thread point of view,
>> it is allowed by JMM. By that argument, a perfectly good code
>>     if( (tmp=resource) != null )
>>         return tmp;
>> can be transformed to a very bad code
>>     if( resource != null )
>>         return resource;   // [r1]
>> since they are equivalent in single-thread.
>>
>> JMM only talks about reads/writes in the program source. Here [r1] did
>> not exist in the program source, how could the compiler reason about
>> its effect? Can the compiler ever introduce such ghost reads with
>> confidence of correctness?
>>
>> Back to the original problem, can this code
>>     if( resource != null )
>>         return resource;
>> be transformed to
>>     tmp = resource;  // [r2]
>>     if( resource != null )
>>         return tmp;
>> ? The compiler now does two reads unconditionally; [r2] would be a
>> ghost read that did not exist in the source, unless the if() condition
>> is true, but how could the compiler reach that prediction?
>>
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140409/5b39eae9/attachment-0001.html>

From zhong.j.yu at gmail.com  Thu Apr 10 04:23:10 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 10 Apr 2014 03:23:10 -0500
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
Message-ID: <CACuKZqF5CntA4sUvjsmoiZKrr+3OGArE5RBMzzTsaH1_90=kZA@mail.gmail.com>

On Thu, Apr 10, 2014 at 12:39 AM, Hans Boehm <boehm at acm.org> wrote:
> Not all transformations that are valid in a single-threaded environment are
> valid in Java.  (Or even in C/C++ with threads, which generally allow more
> transformations than Java.)  In a single-threaded program, a compiler can
> always introduce an x = x; assignment to an accessible program variable.  In
> some contexts, that even turns out to be profitable, normally to correct for
> a misspeculation.  That is not valid in C, C++, or Java, since it may
> introduce a data race and hide a concurrent assignment to x.  (Gcc
> occasionally does it, through about gcc 4.6, however.)
>
> The exact Java semantics here are a bit unclear, since everyone now agrees
> that the semantics for racing accesses in the Java memory model are a bit
> buggy.  (One of the reasons to avoid them where possible.)  But if you look
> at the rules, it is reasonably clear that reads from the same location can
> be performed out of order.  There are good reasons for that.  Otherwise the
> compiler wouldn't be able to reorder two loads through references x and y
> without proving that they don't alias.  (This was one of the motivations for
> the 2005 memory model revision.) And some hardware allows ordinary loads
> from the same location to be performed out of order (either intentionally or
> due to hardware errata).
>
> Introducing a second load where the original code loaded it once into a
> temporary, and used the temporary twice, is illegal in Java (but legal in
> C++, since only racy programs can tell the difference.)
>
> In general, there is no problem with the compiler introducing additional
> dead loads, i.e. loads whose result isn't used.  As Zhong Yu points out,
> that would happen on one control path if the compiler reorders the loads.
> But (a) that's fine, and (b) it's not an issue at the hardware level.
> Hardware issues speculative loads all the time, discarding the results if
> the speculation proves wrong.

That makes sense, so the transformation is valid after all? Phew.

>
> Hans
>
>
> On Wed, Apr 9, 2014 at 7:47 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
>>
>> Compiler can assume single threaded execution unless told otherwise; in
>> that case, introducing phantom reads will not change observable behavior of
>> single threaded execution.
>>
>> Sent from my phone
>>
>> On Apr 9, 2014 9:35 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>
>>> > http://stackoverflow.com/questions/14624365/immutability-and-reordering
>>>
>>> I agree with the conclusions, however I think it is flawed to argue
>>> that if a transformation is valid from a single-thread point of view,
>>> it is allowed by JMM. By that argument, a perfectly good code
>>>     if( (tmp=resource) != null )
>>>         return tmp;
>>> can be transformed to a very bad code
>>>     if( resource != null )
>>>         return resource;   // [r1]
>>> since they are equivalent in single-thread.
>>>
>>> JMM only talks about reads/writes in the program source. Here [r1] did
>>> not exist in the program source, how could the compiler reason about
>>> its effect? Can the compiler ever introduce such ghost reads with
>>> confidence of correctness?
>>>
>>> Back to the original problem, can this code
>>>     if( resource != null )
>>>         return resource;
>>> be transformed to
>>>     tmp = resource;  // [r2]
>>>     if( resource != null )
>>>         return tmp;
>>> ? The compiler now does two reads unconditionally; [r2] would be a
>>> ghost read that did not exist in the source, unless the if() condition
>>> is true, but how could the compiler reach that prediction?
>>>
>>> Zhong Yu
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

From vitalyd at gmail.com  Thu Apr 10 08:28:50 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 10 Apr 2014 08:28:50 -0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
References: <1397024454362-10862.post@n7.nabble.com>
	<534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
Message-ID: <CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>

Right, the key here is java forbids adding second load for temporaries; if
this weren't true, all those benign data race coding practices wouldn't
work.  In Zhong's r2 example, compiler is allowed to make that
transformation since original code didn't have a load into a temp.

Sent from my phone
On Apr 10, 2014 1:39 AM, "Hans Boehm" <boehm at acm.org> wrote:

> Not all transformations that are valid in a single-threaded environment
> are valid in Java.  (Or even in C/C++ with threads, which generally allow
> more transformations than Java.)  In a single-threaded program, a compiler
> can always introduce an x = x; assignment to an accessible program
> variable.  In some contexts, that even turns out to be profitable, normally
> to correct for a misspeculation.  That is not valid in C, C++, or Java,
> since it may introduce a data race and hide a concurrent assignment to x.
>  (Gcc occasionally does it, through about gcc 4.6, however.)
>
> The exact Java semantics here are a bit unclear, since everyone now agrees
> that the semantics for racing accesses in the Java memory model are a bit
> buggy.  (One of the reasons to avoid them where possible.)  But if you look
> at the rules, it is reasonably clear that reads from the same location can
> be performed out of order.  There are good reasons for that.  Otherwise the
> compiler wouldn't be able to reorder two loads through references x and y
> without proving that they don't alias.  (This was one of the motivations
> for the 2005 memory model revision.) And some hardware allows ordinary
> loads from the same location to be performed out of order (either
> intentionally or due to hardware errata).
>
> Introducing a second load where the original code loaded it once into a
> temporary, and used the temporary twice, is illegal in Java (but legal in
> C++, since only racy programs can tell the difference.)
>
> In general, there is no problem with the compiler introducing additional
> dead loads, i.e. loads whose result isn't used.  As Zhong Yu points out,
> that would happen on one control path if the compiler reorders the loads.
>  But (a) that's fine, and (b) it's not an issue at the hardware level.
>  Hardware issues speculative loads all the time, discarding the results if
> the speculation proves wrong.
>
> Hans
>
>
> On Wed, Apr 9, 2014 at 7:47 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Compiler can assume single threaded execution unless told otherwise; in
>> that case, introducing phantom reads will not change observable behavior of
>> single threaded execution.
>>
>> Sent from my phone
>> On Apr 9, 2014 9:35 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>>> >
>>> http://stackoverflow.com/questions/14624365/immutability-and-reordering
>>>
>>> I agree with the conclusions, however I think it is flawed to argue
>>> that if a transformation is valid from a single-thread point of view,
>>> it is allowed by JMM. By that argument, a perfectly good code
>>>     if( (tmp=resource) != null )
>>>         return tmp;
>>> can be transformed to a very bad code
>>>     if( resource != null )
>>>         return resource;   // [r1]
>>> since they are equivalent in single-thread.
>>>
>>> JMM only talks about reads/writes in the program source. Here [r1] did
>>> not exist in the program source, how could the compiler reason about
>>> its effect? Can the compiler ever introduce such ghost reads with
>>> confidence of correctness?
>>>
>>> Back to the original problem, can this code
>>>     if( resource != null )
>>>         return resource;
>>> be transformed to
>>>     tmp = resource;  // [r2]
>>>     if( resource != null )
>>>         return tmp;
>>> ? The compiler now does two reads unconditionally; [r2] would be a
>>> ghost read that did not exist in the source, unless the if() condition
>>> is true, but how could the compiler reach that prediction?
>>>
>>> Zhong Yu
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140410/23d776be/attachment.html>

From vikas.vksingh at gmail.com  Thu Apr 10 10:03:50 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Thu, 10 Apr 2014 07:03:50 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>
References: <534508EB.7050007@kuli.org>
	<CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
	<CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>
Message-ID: <1397138630082-10877.post@n7.nabble.com>

So it means the code below can be fixed by adding a Temporary variable.
So its now a classic case of benign data race. The below method will never
return null but may compute more than one Resource Objects

public class UnsafeLazyInitialization {
    private static Resource resource;

    public static Resource getInstance() {
        Resource temp = resource; // only one read of shared variable
        if (temp == null)
             resource = temp = new Resource();  // unsafe publication
        return temp; 
    }
}





--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10877.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From vikas.vksingh at gmail.com  Thu Apr 10 10:10:37 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Thu, 10 Apr 2014 07:10:37 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <1397138630082-10877.post@n7.nabble.com>
References: <CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
	<CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>
	<1397138630082-10877.post@n7.nabble.com>
Message-ID: <1397139037118-10878.post@n7.nabble.com>

But is the same benign data race thing can be applied to DCL.
i.e is the code below DCL with a temp variable and immutable Singleton, can
ever 
return null? Is there a possible reordering which will allow the below code
to return null. 

final class  Singleton { 

          private static  Singleton _instance;  // not a volatile variable 

          public static Singleton getInstance() { 
                            Singeltom temp = _instance;  
                            if(temp == null) { 
                                       synchronized(Singleton.class) { 
                                                 temp = _instance; 
                                                 if(temp == null) { 
                                                       _instance =temp = new
Singleton(); 
                                                 } 
                                       } 
                             } 
                            return temp; 
           }       
          
          private Singleton() { 
                      i=9; 
                      j=99; 
                      k=999; 
          } 
          *final* private int i,j,k;               
}



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10878.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From vitalyd at gmail.com  Thu Apr 10 10:47:32 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 10 Apr 2014 10:47:32 -0400
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <1397139037118-10878.post@n7.nabble.com>
References: <CAB=Je-GJ+hwJF_iS9+oO+4mAnJLuOp=-8eehCCWiU-v59WAuRw@mail.gmail.com>
	<5345191E.6020101@kuli.org>
	<1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
	<CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>
	<1397138630082-10877.post@n7.nabble.com>
	<1397139037118-10878.post@n7.nabble.com>
Message-ID: <CAHjP37G0w+_FuCPK6KSaYNTCPnjVGwvv2A4vocGmL3siHAxCfQ@mail.gmail.com>

No, it cannot return null.  What you have there is basically a benign data
race-like construct except you ensure only one instance is ever created and
that same instance is returned.

I do agree with Hans and Aleksey that you really should try to avoid
constructs like this in real code as it's quite brittle.

Sent from my phone
On Apr 10, 2014 10:17 AM, "vikas" <vikas.vksingh at gmail.com> wrote:

> But is the same benign data race thing can be applied to DCL.
> i.e is the code below DCL with a temp variable and immutable Singleton, can
> ever
> return null? Is there a possible reordering which will allow the below code
> to return null.
>
> final class  Singleton {
>
>           private static  Singleton _instance;  // not a volatile variable
>
>           public static Singleton getInstance() {
>                             Singeltom temp = _instance;
>                             if(temp == null) {
>                                        synchronized(Singleton.class) {
>                                                  temp = _instance;
>                                                  if(temp == null) {
>                                                        _instance =temp =
> new
> Singleton();
>                                                  }
>                                        }
>                              }
>                             return temp;
>            }
>
>           private Singleton() {
>                       i=9;
>                       j=99;
>                       k=999;
>           }
>           *final* private int i,j,k;
> }
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10878.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140410/07ee41f2/attachment-0001.html>

From vikas.vksingh at gmail.com  Thu Apr 10 11:18:43 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Thu, 10 Apr 2014 08:18:43 -0700 (PDT)
Subject: [concurrency-interest] DCL clarification Immutable singelton
In-Reply-To: <CAHjP37G0w+_FuCPK6KSaYNTCPnjVGwvv2A4vocGmL3siHAxCfQ@mail.gmail.com>
References: <1397051343398-10868.post@n7.nabble.com>
	<CAPUmR1ZYBWebYb6mx59fqsfbG4hAM_tw8jJmZmsDRU6XLSi_rg@mail.gmail.com>
	<1397070506598-10871.post@n7.nabble.com>
	<CACuKZqHOtTNznT9Y=YLeiSyrGk1sAieNo0Ao=A2Qrc8SJTqOLA@mail.gmail.com>
	<CAHjP37HJ9D-+yoXOXfkNYckA7P_fWpF8V4ZwdLTV16iUqmeR2Q@mail.gmail.com>
	<CAPUmR1bFKbPfHTV6dyO60FChpfe4+3yasx7xZJL11V+793jkUw@mail.gmail.com>
	<CAHjP37HB0ygFOOUd5aUpa=cLfyf0rHG-1To-NsZwvr_QkpLt+w@mail.gmail.com>
	<1397138630082-10877.post@n7.nabble.com>
	<1397139037118-10878.post@n7.nabble.com>
	<CAHjP37G0w+_FuCPK6KSaYNTCPnjVGwvv2A4vocGmL3siHAxCfQ@mail.gmail.com>
Message-ID: <1397143123874-10880.post@n7.nabble.com>

*"I do agree with Hans and Aleksey that you really should try to avoid
constructs like this in real code as it's quite brittle."*

Yes i completely agree. It was more of understanding the how safely we can
publish objects
and why to avoid such bad design (no matter if they are correct) 



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/DCL-clarification-Immutable-singelton-tp10862p10880.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From stanimir at riflexo.com  Sun Apr 13 07:21:16 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Sun, 13 Apr 2014 14:21:16 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
Message-ID: <CAEJX8or5mux-GC+FZm=NJr+Ji9sNmZtHLmU8D2mkj_-tGkh-CQ@mail.gmail.com>

Hi

A classic concurrent Michael & Scott queue where nodes do contain an extra
field 'long counter' should be able to suffice - bounded,
non-constant-space and lock-free (still need to spin to insert on failed
CAS).
The field is initialized with the value of the tail.counter+1 and the queue
tail cannot drift unlike CLQ implementation. So the queuing routine first
CAS the tail then links the 'next'.

The size of the queue is obviously tail.counter-head.counter.
Due to having only a single consumer the notification mechanism requires
only one padded AtomicReference<Thread> + park/unpark. The only harder part
is making consumers effectively wait on full queue and they may need to
rely on spin + Thread.yield.

I can post a short implementation under CC0 if interested.

Stanimir


On Tue, Apr 8, 2014 at 4:38 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:

> Hey everyone,
>
> I thought I'd throw this question out there before I go all out NIH.
>
> Does anybody know of an open source (apache 2 compatible) "minimal
> overhead", non-blocking, bounded, non-constant-space (i.e. no ringbuffer or
> preallocated size array) multiple-producer
> single-consumer/multiple-consumer queues in Java/bytecode?
>
>
>
> --
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140413/d35e21a2/attachment.html>

From dl at cs.oswego.edu  Sun Apr 13 18:50:12 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 13 Apr 2014 18:50:12 -0400
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <5341C9CC.4080104@cs.oswego.edu>
References: <533B48E6.6050700@sosnoski.com> <5341C9CC.4080104@cs.oswego.edu>
Message-ID: <534B14A4.1080209@cs.oswego.edu>

Back to...

On 04/06/2014 05:40 PM, Doug Lea wrote:
> On 04/01/2014 07:16 PM, Dennis Sosnoski wrote:
>> I've run into a situation with CompletableFuture.thenCombine() hanging
>> ...
>
>>          for (int i = 1; i < n; i++) {
>>              last = CompletableFuture.supplyAsync(newLambda(i))
>> .thenCombine(last, Math::max);
>>          }
>>          return last.join();
>>      }
>
> Even though this code looks like a loop, it was evaluated recursively
> (across multiple threads) which can blow up default-sized runtime
> stacks even when n is 10000 or so.
>
> The StackOverflowError was correctly managed by one (or more)
> of the intermediate CompletableFutures in the long chain
> constructed.

Well, not necessarily. A StackOverflowError can occur at
any call, including, for CompletableFuture, internal
bookkeeping calls by unknown Executors. Considering
that CompletableFuture goes to great lengths to manage
other Errors and Exceptions, we ought to do the same here,
even for non-tail-recursive cases.


> By re-packing actions
> while processing dependent completions, we can isolate
> tail-recursive cases and loopify them. This generally works out
> better than moving them across lists, because doing so can
> reduce opportunities for other threads to help process them.

By further repacking actions, we can move completion lists
around even in non-tail recursive cases without practical
loss in potential parallelism, and, as it turns out, with
a small gain in average throughput. (For those interested,
the main change is for racing CFs to directly try to
complete rather than helping their sources do so, which
would not work if moved. This is a small change conceptually,
but leads to lots of diffs because the same idea is used
in different ways across functional forms.)

Updated sources at
 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CompletableFuture.java?view=log 


Also compiled into the jar at
    http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar
that you can run with -Xbootclasspath

Please try it out.

Thanks to Peter Levart for some further prodding on this.
Peter: Maybe you could post one of your examples as
a sample test program.

-Doug



From peter.levart at gmail.com  Mon Apr 14 02:51:11 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Mon, 14 Apr 2014 08:51:11 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <534B14A4.1080209@cs.oswego.edu>
References: <533B48E6.6050700@sosnoski.com> <5341C9CC.4080104@cs.oswego.edu>
	<534B14A4.1080209@cs.oswego.edu>
Message-ID: <534B855F.7040200@gmail.com>

On 04/14/2014 12:50 AM, Doug Lea wrote:
> Peter: Maybe you could post one of your examples as
> a sample test program.
>
> -Doug

Sure, here's an artificial example that provokes StackOverflowError in 
previous version (CVS:1.99):


import java.math.BigInteger;
import java.util.Set;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentSkipListSet;
import java.util.concurrent.Future;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Consumer;

public class FibonacciPrimes {

     static Future<Set<BigInteger>> fibonacciPrimes(
         CompletableFuture<BigInteger> f0,
         CompletableFuture<BigInteger> f1,
         int n) {
         if (n < 0) throw new IllegalArgumentException("n should be >= 0");

         Set<BigInteger> result = new ConcurrentSkipListSet<>();
         AtomicInteger c = new AtomicInteger(n + 1);
         CompletableFuture<Set<BigInteger>> future = new 
CompletableFuture<>();

         Consumer<BigInteger> addIfPrime = i -> {
             if (i.isProbablePrime(100)) result.add(i);
             if (c.decrementAndGet() == 0) future.complete(result);
         };

         f0.thenAcceptAsync(addIfPrime);
         if (n > 0) {
             f1.thenAcceptAsync(addIfPrime);
             for (int i = 2; i <= n; i++) {
                 f1 = f0.thenCombine(f0 = f1, BigInteger::add);
                 f1.thenAcceptAsync(addIfPrime);
             }
         }

         return future;
     }

     public static void main(String[] args) throws Exception {
         CompletableFuture<BigInteger> f0 = new CompletableFuture<>();
         CompletableFuture<BigInteger> f1 = new CompletableFuture<>();

         long t0 = System.currentTimeMillis();
         int n = 10000;
         Future<Set<BigInteger>> primes = fibonacciPrimes(f0, f1, n);

         f0.complete(BigInteger.ZERO);
         f1.complete(BigInteger.ONE);

         System.out.println("Primes among 1st " + (n + 1) + " Fibonacci 
numbers:");
         for (BigInteger prime : primes.get()) {
             System.out.println(prime);
         }
         System.out.println((System.currentTimeMillis() - t0) + " 
millis.");
     }
}


Regards, Peter


From oleksandr.otenko at oracle.com  Mon Apr 14 08:13:58 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 14 Apr 2014 13:13:58 +0100
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
Message-ID: <534BD106.4060502@oracle.com>

What do you mean, when you combine in one sentence "non-blocking" and 
"bounded"?

Alex

On 08/04/2014 14:38, ?iktor ?lang wrote:
> Hey everyone,
>
> I thought I'd throw this question out there before I go all out NIH.
>
> Does anybody know of an open source (apache 2 compatible) "minimal 
> overhead", non-blocking, bounded, non-constant-space (i.e. no 
> ringbuffer or preallocated size array) multiple-producer 
> single-consumer/multiple-consumer queues in Java/bytecode?
>
>
>
> -- 
> Cheers,
> ?
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/a7629b47/attachment.html>

From viktor.klang at gmail.com  Mon Apr 14 08:31:23 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 14 Apr 2014 14:31:23 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <534BD106.4060502@oracle.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
Message-ID: <CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>

boolean offer(T t) - i.e. non-blockingly either adds t or not, depending on
available capacity.
On Apr 14, 2014 2:14 PM, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
wrote:

>  What do you mean, when you combine in one sentence "non-blocking" and
> "bounded"?
>
> Alex
>
> On 08/04/2014 14:38, ?iktor ?lang wrote:
>
> Hey everyone,
>
>  I thought I'd throw this question out there before I go all out NIH.
>
>  Does anybody know of an open source (apache 2 compatible) "minimal
> overhead", non-blocking, bounded, non-constant-space (i.e. no ringbuffer or
> preallocated size array) multiple-producer
> single-consumer/multiple-consumer queues in Java/bytecode?
>
>
>
>  --
>  Cheers,
> ?
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/91ccdbd2/attachment.html>

From oleksandr.otenko at oracle.com  Mon Apr 14 10:00:38 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 14 Apr 2014 15:00:38 +0100
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
Message-ID: <534BEA06.3070305@oracle.com>

Yes, but capacity availability is tricky to define.

For example, knowing N threads are dequeuing, but haven't completed yet, 
does this count as capacity available or not?


Alex


On 14/04/2014 13:31, ?iktor ?lang wrote:
>
> boolean offer(T t) - i.e. non-blockingly either adds t or not, 
> depending on available capacity.
>
> On Apr 14, 2014 2:14 PM, "Oleksandr Otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     What do you mean, when you combine in one sentence "non-blocking"
>     and "bounded"?
>
>     Alex
>
>     On 08/04/2014 14:38, ?iktor ?lang wrote:
>>     Hey everyone,
>>
>>     I thought I'd throw this question out there before I go all out NIH.
>>
>>     Does anybody know of an open source (apache 2 compatible)
>>     "minimal overhead", non-blocking, bounded, non-constant-space
>>     (i.e. no ringbuffer or preallocated size array) multiple-producer
>>     single-consumer/multiple-consumer queues in Java/bytecode?
>>
>>
>>
>>     -- 
>>     Cheers,
>>     ?
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/4193d9a6/attachment.html>

From viktor.klang at gmail.com  Mon Apr 14 10:03:16 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 14 Apr 2014 16:03:16 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <534BEA06.3070305@oracle.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
Message-ID: <CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>

On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  Yes, but capacity availability is tricky to define.
>

Absolutely, I am open to suggestions!


>
> For example, knowing N threads are dequeuing, but haven't completed yet,
> does this count as capacity available or not?
>

It's fine with a MPSC queue.


>
>
> Alex
>
>
>
> On 14/04/2014 13:31, ?iktor ?lang wrote:
>
> boolean offer(T t) - i.e. non-blockingly either adds t or not, depending
> on available capacity.
> On Apr 14, 2014 2:14 PM, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
> wrote:
>
>>  What do you mean, when you combine in one sentence "non-blocking" and
>> "bounded"?
>>
>> Alex
>>
>> On 08/04/2014 14:38, ?iktor ?lang wrote:
>>
>> Hey everyone,
>>
>>  I thought I'd throw this question out there before I go all out NIH.
>>
>>  Does anybody know of an open source (apache 2 compatible) "minimal
>> overhead", non-blocking, bounded, non-constant-space (i.e. no ringbuffer or
>> preallocated size array) multiple-producer
>> single-consumer/multiple-consumer queues in Java/bytecode?
>>
>>
>>
>>  --
>>  Cheers,
>> ?
>>
>>
>>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/45db9fc9/attachment-0001.html>

From paul.sandoz at oracle.com  Mon Apr 14 11:41:56 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Mon, 14 Apr 2014 17:41:56 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
	hangs
In-Reply-To: <534B855F.7040200@gmail.com>
References: <533B48E6.6050700@sosnoski.com> <5341C9CC.4080104@cs.oswego.edu>
	<534B14A4.1080209@cs.oswego.edu> <534B855F.7040200@gmail.com>
Message-ID: <A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>


On Apr 14, 2014, at 8:51 AM, Peter Levart <peter.levart at gmail.com> wrote:

> On 04/14/2014 12:50 AM, Doug Lea wrote:
>> Peter: Maybe you could post one of your examples as
>> a sample test program.
>> 
>> -Doug
> 
> Sure, here's an artificial example that provokes StackOverflowError in previous version (CVS:1.99):
> 
> 

Very nice! that melts my laptop :-) below is a version that reproduces the same problem producing less heat.

I originally thought that the tail recursion fix would cover most cases, but as you have shown it is quite easy to create a linked list of completions > 1 node.

Relevant jtreg unit tests pass with the latest fix.
 
Paul.


import java.math.BigInteger;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;
import java.util.function.*;

public class FibonacciStackOverflow {

   static Future<BigInteger> fib(
       CompletableFuture<BigInteger> f0,
       CompletableFuture<BigInteger> f1,
       int n) {
       if (n < 0) throw new IllegalArgumentException("n should be >= 0");

       f0.thenAccept(i -> {});
       if (n > 0) {
           f1.thenAccept(v -> {});
           for (int i = 2; i <= n; i++) {
               f1 = f0.thenCombine(f0 = f1, BigInteger::add);
               f1.thenAccept(v -> {});
           }
       }

       return f1;
   }

   public static void main(String[] args) throws Exception {
       CompletableFuture<BigInteger> f0 = new CompletableFuture<>();
       CompletableFuture<BigInteger> f1 = new CompletableFuture<>();

       int n = Integer.valueOf(args[0]);
       Future<BigInteger> fn = fib(f0, f1, n);

       f0.complete(BigInteger.ZERO);

       f1.complete(BigInteger.ONE);  // Trigger SOE

       System.out.println(fn.get());
   }
}

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/48c9db12/attachment.bin>

From oleksandr.otenko at oracle.com  Mon Apr 14 16:18:34 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 14 Apr 2014 21:18:34 +0100
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>
References: <533B48E6.6050700@sosnoski.com>
	<5341C9CC.4080104@cs.oswego.edu>	<534B14A4.1080209@cs.oswego.edu>
	<534B855F.7040200@gmail.com>
	<A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>
Message-ID: <534C429A.3000502@oracle.com>

What's your expected behaviour with this Fibonacci example?

Do you mean it fails for some small values of args[0] with some build of 
Java 8?

Alex

On 14/04/2014 16:41, Paul Sandoz wrote:
> On Apr 14, 2014, at 8:51 AM, Peter Levart <peter.levart at gmail.com> wrote:
>
>> On 04/14/2014 12:50 AM, Doug Lea wrote:
>>> Peter: Maybe you could post one of your examples as
>>> a sample test program.
>>>
>>> -Doug
>> Sure, here's an artificial example that provokes StackOverflowError in previous version (CVS:1.99):
>>
>>
> Very nice! that melts my laptop :-) below is a version that reproduces the same problem producing less heat.
>
> I originally thought that the tail recursion fix would cover most cases, but as you have shown it is quite easy to create a linked list of completions > 1 node.
>
> Relevant jtreg unit tests pass with the latest fix.
>   
> Paul.
>
>
> import java.math.BigInteger;
> import java.util.*;
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
> import java.util.function.*;
>
> public class FibonacciStackOverflow {
>
>     static Future<BigInteger> fib(
>         CompletableFuture<BigInteger> f0,
>         CompletableFuture<BigInteger> f1,
>         int n) {
>         if (n < 0) throw new IllegalArgumentException("n should be >= 0");
>
>         f0.thenAccept(i -> {});
>         if (n > 0) {
>             f1.thenAccept(v -> {});
>             for (int i = 2; i <= n; i++) {
>                 f1 = f0.thenCombine(f0 = f1, BigInteger::add);
>                 f1.thenAccept(v -> {});
>             }
>         }
>
>         return f1;
>     }
>
>     public static void main(String[] args) throws Exception {
>         CompletableFuture<BigInteger> f0 = new CompletableFuture<>();
>         CompletableFuture<BigInteger> f1 = new CompletableFuture<>();
>
>         int n = Integer.valueOf(args[0]);
>         Future<BigInteger> fn = fib(f0, f1, n);
>
>         f0.complete(BigInteger.ZERO);
>
>         f1.complete(BigInteger.ONE);  // Trigger SOE
>
>         System.out.println(fn.get());
>     }
> }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/9f62071c/attachment.html>

From peter.levart at gmail.com  Mon Apr 14 17:15:21 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Mon, 14 Apr 2014 23:15:21 +0200
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <534C429A.3000502@oracle.com>
References: <533B48E6.6050700@sosnoski.com>	<5341C9CC.4080104@cs.oswego.edu>	<534B14A4.1080209@cs.oswego.edu>	<534B855F.7040200@gmail.com>	<A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>
	<534C429A.3000502@oracle.com>
Message-ID: <534C4FE9.6010905@gmail.com>


On 04/14/2014 10:18 PM, Oleksandr Otenko wrote:
> What's your expected behaviour with this Fibonacci example?
>
> Do you mean it fails for some small values of args[0] with some build 
> of Java 8?

I don't know exactly what is the tripping point on JDK 8 Release, but on 
my machine it's between 2000 (passes) and 3000 (fails). With Doug's 
intermediary fix it should be about 3x higher (only 1 stack frame in one 
recursion step vs. 3), but with latest fix it should work for any number.

Peter

>
> Alex
>
> On 14/04/2014 16:41, Paul Sandoz wrote:
>> On Apr 14, 2014, at 8:51 AM, Peter Levart<peter.levart at gmail.com>  wrote:
>>
>>> On 04/14/2014 12:50 AM, Doug Lea wrote:
>>>> Peter: Maybe you could post one of your examples as
>>>> a sample test program.
>>>>
>>>> -Doug
>>> Sure, here's an artificial example that provokes StackOverflowError in previous version (CVS:1.99):
>>>
>>>
>> Very nice! that melts my laptop :-) below is a version that reproduces the same problem producing less heat.
>>
>> I originally thought that the tail recursion fix would cover most cases, but as you have shown it is quite easy to create a linked list of completions > 1 node.
>>
>> Relevant jtreg unit tests pass with the latest fix.
>>   
>> Paul.
>>
>>
>> import java.math.BigInteger;
>> import java.util.*;
>> import java.util.concurrent.*;
>> import java.util.concurrent.atomic.*;
>> import java.util.function.*;
>>
>> public class FibonacciStackOverflow {
>>
>>     static Future<BigInteger> fib(
>>         CompletableFuture<BigInteger> f0,
>>         CompletableFuture<BigInteger> f1,
>>         int n) {
>>         if (n < 0) throw new IllegalArgumentException("n should be >= 0");
>>
>>         f0.thenAccept(i -> {});
>>         if (n > 0) {
>>             f1.thenAccept(v -> {});
>>             for (int i = 2; i <= n; i++) {
>>                 f1 = f0.thenCombine(f0 = f1, BigInteger::add);
>>                 f1.thenAccept(v -> {});
>>             }
>>         }
>>
>>         return f1;
>>     }
>>
>>     public static void main(String[] args) throws Exception {
>>         CompletableFuture<BigInteger> f0 = new CompletableFuture<>();
>>         CompletableFuture<BigInteger> f1 = new CompletableFuture<>();
>>
>>         int n = Integer.valueOf(args[0]);
>>         Future<BigInteger> fn = fib(f0, f1, n);
>>
>>         f0.complete(BigInteger.ZERO);
>>
>>         f1.complete(BigInteger.ONE);  // Trigger SOE
>>
>>         System.out.println(fn.get());
>>     }
>> }
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/266794ee/attachment.html>

From stanimir at riflexo.com  Mon Apr 14 17:59:12 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Tue, 15 Apr 2014 00:59:12 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
Message-ID: <CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>

> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  Yes, but capacity availability is tricky to define.
>>
>
> Absolutely, I am open to suggestions!
>
>
Here is an attempt with the described counter:  http://pastebin.com/fY1AudYY

Basically it is a linked queue w/o CAS on the head due to single consumer
only, each node has an extra field *long counter *and the current size is
1+tail.counter-head.counter.
poll(long nanos) may return spuriously as it doesn't bother with measuring
time. Usually that's ok for single consumer queues as they go back to
poll() if they don't have other tasks to do.



Stanimir
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/f743e8bb/attachment.html>

From viktor.klang at gmail.com  Mon Apr 14 18:05:10 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 15 Apr 2014 00:05:10 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
Message-ID: <CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>

Hi Stanimir,

It's really late here, but the presence of park/unpark tells me that this
isn't non-blocking.


On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff
<stanimir at riflexo.com>wrote:

>
>
>
>
>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  Yes, but capacity availability is tricky to define.
>>>
>>
>> Absolutely, I am open to suggestions!
>>
>>
> Here is an attempt with the described counter:
> http://pastebin.com/fY1AudYY
>
> Basically it is a linked queue w/o CAS on the head due to single consumer
> only, each node has an extra field *long counter *and the current size is
> 1+tail.counter-head.counter.
> poll(long nanos) may return spuriously as it doesn't bother with measuring
> time. Usually that's ok for single consumer queues as they go back to
> poll() if they don't have other tasks to do.
>
>
>
> Stanimir
>
>
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/82759f1c/attachment-0001.html>

From stanimir at riflexo.com  Mon Apr 14 18:07:32 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Tue, 15 Apr 2014 01:07:32 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
Message-ID: <CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>

Park/Unpark is only for the consumer size if you specify timeout to wait
for an element. The producer never waits besides the CAS loop.

Stanimir


On Tue, Apr 15, 2014 at 1:05 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Hi Stanimir,
>
> It's really late here, but the presence of park/unpark tells me that this
> isn't non-blocking.
>
>
> On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff <stanimir at riflexo.com
> > wrote:
>
>>
>>
>>
>>
>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>> oleksandr.otenko at oracle.com> wrote:
>>>
>>>>  Yes, but capacity availability is tricky to define.
>>>>
>>>
>>> Absolutely, I am open to suggestions!
>>>
>>>
>> Here is an attempt with the described counter:
>> http://pastebin.com/fY1AudYY
>>
>> Basically it is a linked queue w/o CAS on the head due to single consumer
>> only, each node has an extra field *long counter *and the current size
>> is 1+tail.counter-head.counter.
>> poll(long nanos) may return spuriously as it doesn't bother with
>> measuring time. Usually that's ok for single consumer queues as they go
>> back to poll() if they don't have other tasks to do.
>>
>>
>>
>> Stanimir
>>
>>
>>
>
>
>
> --
> Cheers,
> ?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/765a248a/attachment.html>

From dl at cs.oswego.edu  Mon Apr 14 19:53:34 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 14 Apr 2014 19:53:34 -0400
Subject: [concurrency-interest] Java 8 CompletableFuture.thenCombine()
 hangs
In-Reply-To: <A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>
References: <533B48E6.6050700@sosnoski.com>
	<5341C9CC.4080104@cs.oswego.edu>	<534B14A4.1080209@cs.oswego.edu>
	<534B855F.7040200@gmail.com>
	<A7E40DC0-E981-4DF0-B7A7-10D7360A402E@oracle.com>
Message-ID: <534C74FE.8000706@cs.oswego.edu>

On 04/14/2014 11:41 AM, Paul Sandoz wrote:
> I originally thought that the tail recursion fix would cover most cases, but
> as you have shown it is quite easy to create a linked list of completions > 1
> node.

Recapping: Because we cannot guarantee that a StackOverflowError
in another thread will always be noticed, we solve the harder-looking
problem of preventing them, by loopifying tail-recursion and/or heap-
allocating frames. So now people can write CompletableFuture based
recursive constructions that would blow up if coded using straight
recursion. Strange but true.

>
> Relevant jtreg unit tests pass with the latest fix.
>

I'll sit on this a few days in case anyone has any further
comments or experiences and then go for OpenJDK integration
via JDK-8039378.

-Doug


From martinrb at google.com  Mon Apr 14 22:41:56 2014
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 14 Apr 2014 19:41:56 -0700
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
Message-ID: <CA+kOe0-dsFmPmedC3VvKn3TxYwCCi1f6bm9g1GU8mWui6wGM9Q@mail.gmail.com>

CLQ can't get away with the counter because it supports internal removal.
 But it's reasonable for other implementations to do this.

If you read head before tail, you can never have head getting "ahead" of
tail, and then 1 + t.counter - h.counter should be mostly right.


   1.        static long sub(long tail, long head){
   2.                 if (head>tail || ((head^tail)&Long.MIN_VALUE)!=0){




On Mon, Apr 14, 2014 at 2:59 PM, Stanimir Simeonoff <stanimir at riflexo.com>wrote:

>
>
>
>
>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>>  Yes, but capacity availability is tricky to define.
>>>
>>
>> Absolutely, I am open to suggestions!
>>
>>
> Here is an attempt with the described counter:
> http://pastebin.com/fY1AudYY
>
> Basically it is a linked queue w/o CAS on the head due to single consumer
> only, each node has an extra field *long counter *and the current size is
> 1+tail.counter-head.counter.
> poll(long nanos) may return spuriously as it doesn't bother with measuring
> time. Usually that's ok for single consumer queues as they go back to
> poll() if they don't have other tasks to do.
>
>
>
> Stanimir
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140414/b5d9840a/attachment.html>

From stanimir at riflexo.com  Tue Apr 15 02:46:21 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Tue, 15 Apr 2014 09:46:21 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CA+kOe0-dsFmPmedC3VvKn3TxYwCCi1f6bm9g1GU8mWui6wGM9Q@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CA+kOe0-dsFmPmedC3VvKn3TxYwCCi1f6bm9g1GU8mWui6wGM9Q@mail.gmail.com>
Message-ID: <CAEJX8oqDDN4d4jd1R4zATkPCYJxbKFPdrPYroQumgokwmZFfXg@mail.gmail.com>

On Tue, Apr 15, 2014 at 5:41 AM, Martin Buchholz <martinrb at google.com>wrote:

> CLQ can't get away with the counter because it supports internal removal.
>  But it's reasonable for other implementations to do this.
>
> If you read head before tail, you can never have head getting "ahead" of
> tail, and then 1 + t.counter - h.counter should be mostly right.
>
>
>    1.        static long sub(long tail, long head){
>    2.                 if (head>tail || ((head^tail)&Long.MIN_VALUE)!=0){
>
>
>
> It's mostly meant as gimmick to support unsigned counter, i.e.
overflowing  long and having negative counter.

Stanimir


> On Mon, Apr 14, 2014 at 2:59 PM, Stanimir Simeonoff <stanimir at riflexo.com>wrote:
>
>>
>>
>>
>>
>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>> oleksandr.otenko at oracle.com> wrote:
>>>
>>>>  Yes, but capacity availability is tricky to define.
>>>>
>>>
>>> Absolutely, I am open to suggestions!
>>>
>>>
>> Here is an attempt with the described counter:
>> http://pastebin.com/fY1AudYY
>>
>> Basically it is a linked queue w/o CAS on the head due to single consumer
>> only, each node has an extra field *long counter *and the current size
>> is 1+tail.counter-head.counter.
>> poll(long nanos) may return spuriously as it doesn't bother with
>> measuring time. Usually that's ok for single consumer queues as they go
>> back to poll() if they don't have other tasks to do.
>>
>>
>>
>> Stanimir
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/17160fec/attachment-0001.html>

From viktor.klang at gmail.com  Tue Apr 15 07:04:26 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 15 Apr 2014 13:04:26 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
	<CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>
Message-ID: <CANPzfU8KGvFPDzY59kz_SOmV_XHjJ9oyMcyPxhsWiyAkFh0R0w@mail.gmail.com>

Alright, cool, I won't need that.


On Tue, Apr 15, 2014 at 12:07 AM, Stanimir Simeonoff
<stanimir at riflexo.com>wrote:

> Park/Unpark is only for the consumer size if you specify timeout to wait
> for an element. The producer never waits besides the CAS loop.
>
> Stanimir
>
>
> On Tue, Apr 15, 2014 at 1:05 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> Hi Stanimir,
>>
>> It's really late here, but the presence of park/unpark tells me that this
>> isn't non-blocking.
>>
>>
>> On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff <
>> stanimir at riflexo.com> wrote:
>>
>>>
>>>
>>>
>>>
>>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>>> oleksandr.otenko at oracle.com> wrote:
>>>>
>>>>>  Yes, but capacity availability is tricky to define.
>>>>>
>>>>
>>>> Absolutely, I am open to suggestions!
>>>>
>>>>
>>> Here is an attempt with the described counter:
>>> http://pastebin.com/fY1AudYY
>>>
>>> Basically it is a linked queue w/o CAS on the head due to single
>>> consumer only, each node has an extra field *long counter *and the
>>> current size is 1+tail.counter-head.counter.
>>> poll(long nanos) may return spuriously as it doesn't bother with
>>> measuring time. Usually that's ok for single consumer queues as they go
>>> back to poll() if they don't have other tasks to do.
>>>
>>>
>>>
>>> Stanimir
>>>
>>>
>>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/0b0e7905/attachment.html>

From stanimir at riflexo.com  Tue Apr 15 08:23:24 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Tue, 15 Apr 2014 15:23:24 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8KGvFPDzY59kz_SOmV_XHjJ9oyMcyPxhsWiyAkFh0R0w@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
	<CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>
	<CANPzfU8KGvFPDzY59kz_SOmV_XHjJ9oyMcyPxhsWiyAkFh0R0w@mail.gmail.com>
Message-ID: <CAEJX8orRFTJWtoRcsAhsEgxiSTfqNxvX8Zx17RVhDx=JB9qzPQ@mail.gmail.com>

If you can tolerate bulk drain(), i.e. "Collection<E> drain()" instead of
"E poll()" there is even a simpler implementation - using a stack and
reverse it on poll(). Although the stack would perform worse under
contention as the "head" is contended by both producers and the consumer,
yet the implementation is super simple.
http://pastebin.com/4FpvHPEy

I've been using bounded SC/MP queues/stacks with blocking on the consumer
for quite some time, hence the inclusion of park/unpark.

Stanimir




On Tue, Apr 15, 2014 at 2:04 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Alright, cool, I won't need that.
>
>
> On Tue, Apr 15, 2014 at 12:07 AM, Stanimir Simeonoff <stanimir at riflexo.com
> > wrote:
>
>> Park/Unpark is only for the consumer size if you specify timeout to wait
>> for an element. The producer never waits besides the CAS loop.
>>
>> Stanimir
>>
>>
>> On Tue, Apr 15, 2014 at 1:05 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>
>>> Hi Stanimir,
>>>
>>> It's really late here, but the presence of park/unpark tells me that
>>> this isn't non-blocking.
>>>
>>>
>>> On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff <
>>> stanimir at riflexo.com> wrote:
>>>
>>>>
>>>>
>>>>
>>>>
>>>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>>>> oleksandr.otenko at oracle.com> wrote:
>>>>>
>>>>>>  Yes, but capacity availability is tricky to define.
>>>>>>
>>>>>
>>>>> Absolutely, I am open to suggestions!
>>>>>
>>>>>
>>>> Here is an attempt with the described counter:
>>>> http://pastebin.com/fY1AudYY
>>>>
>>>> Basically it is a linked queue w/o CAS on the head due to single
>>>> consumer only, each node has an extra field *long counter *and the
>>>> current size is 1+tail.counter-head.counter.
>>>> poll(long nanos) may return spuriously as it doesn't bother with
>>>> measuring time. Usually that's ok for single consumer queues as they go
>>>> back to poll() if they don't have other tasks to do.
>>>>
>>>>
>>>>
>>>> Stanimir
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> Cheers,
>>> ?
>>>
>>
>>
>
>
> --
> Cheers,
> ?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/4b5c930f/attachment.html>

From stanimir at riflexo.com  Tue Apr 15 08:48:37 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Tue, 15 Apr 2014 15:48:37 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CANPzfU8fDd5Gr=QsM2b0B01b8z+_1kPL2JzPE0u-OMu=QZyfVg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
	<CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>
	<CANPzfU8KGvFPDzY59kz_SOmV_XHjJ9oyMcyPxhsWiyAkFh0R0w@mail.gmail.com>
	<CAEJX8orRFTJWtoRcsAhsEgxiSTfqNxvX8Zx17RVhDx=JB9qzPQ@mail.gmail.com>
	<CANPzfU8fDd5Gr=QsM2b0B01b8z+_1kPL2JzPE0u-OMu=QZyfVg@mail.gmail.com>
Message-ID: <CAEJX8orLeRGSa0=6Y4ZgGNse_C5rQTd1xL5xFj5v=L+NhXJ8jw@mail.gmail.com>

The 1st real queue should do fine then. Cut off the unnecessary
notification mechanism and it should be good enough, just pad the head and
tail to avoid the false sharing.
If you feel the queue doesn't perform good enough under contention, you can
try the with a slack tail and I don't think it can be done any better.
There was a small bug in the nightly post (it was 1am for me too) which has
been fixed (during offer the real head was read instead of the local
variable).

Technically, drain can work fine too. Since there is a single consumer, you
can store the result in the stack itself (ArrayDeque for instance) - if the
deque is empty then drains it all, stores is in the dequeue, return
dequeue.poll(). Need another volatile dequeueSize to be added to Node.size.
In the end it still takes a volatile write on the consumer size to update
dequeueSize, so there is no real benefit compared to the 1st queue approach.


Stanimir



On Tue, Apr 15, 2014 at 3:32 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Hi Stanimir,
>
> On Tue, Apr 15, 2014 at 2:23 PM, Stanimir Simeonoff <stanimir at riflexo.com>wrote:
>
>> If you can tolerate bulk drain(), i.e. "Collection<E> drain()" instead of
>> "E poll()" there is even a simpler implementation - using a stack and
>> reverse it on poll(). Although the stack would perform worse under
>> contention as the "head" is contended by both producers and the consumer,
>> yet the implementation is super simple.
>> http://pastebin.com/4FpvHPEy
>>
>> I've been using bounded SC/MP queues/stacks with blocking on the consumer
>> for quite some time, hence the inclusion of park/unpark.
>>
>
> We've already got one approach with bulk drains but it introduces a lot of
> extra complication for the consumer as you need to store away the batch in
> case something goes wrong when processing something in the batch, so I'd
> like to avoid it.
>
> I know when there's something in the queue (i get signalled when the
> "first" element is added, idempotently) so a poll should always return
> something on the first try, subsequent ones not required (given that the
> queue is empty).
>
>
>>
>>
>> Stanimir
>>
>>
>>
>>
>> On Tue, Apr 15, 2014 at 2:04 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>
>>> Alright, cool, I won't need that.
>>>
>>>
>>> On Tue, Apr 15, 2014 at 12:07 AM, Stanimir Simeonoff <
>>> stanimir at riflexo.com> wrote:
>>>
>>>> Park/Unpark is only for the consumer size if you specify timeout to
>>>> wait for an element. The producer never waits besides the CAS loop.
>>>>
>>>> Stanimir
>>>>
>>>>
>>>> On Tue, Apr 15, 2014 at 1:05 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>>>
>>>>> Hi Stanimir,
>>>>>
>>>>> It's really late here, but the presence of park/unpark tells me that
>>>>> this isn't non-blocking.
>>>>>
>>>>>
>>>>> On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff <
>>>>> stanimir at riflexo.com> wrote:
>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>>>>>> oleksandr.otenko at oracle.com> wrote:
>>>>>>>
>>>>>>>>  Yes, but capacity availability is tricky to define.
>>>>>>>>
>>>>>>>
>>>>>>> Absolutely, I am open to suggestions!
>>>>>>>
>>>>>>>
>>>>>> Here is an attempt with the described counter:
>>>>>> http://pastebin.com/fY1AudYY
>>>>>>
>>>>>> Basically it is a linked queue w/o CAS on the head due to single
>>>>>> consumer only, each node has an extra field *long counter *and the
>>>>>> current size is 1+tail.counter-head.counter.
>>>>>> poll(long nanos) may return spuriously as it doesn't bother with
>>>>>> measuring time. Usually that's ok for single consumer queues as they go
>>>>>> back to poll() if they don't have other tasks to do.
>>>>>>
>>>>>>
>>>>>>
>>>>>> Stanimir
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Cheers,
>>>>> ?
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> Cheers,
>>> ?
>>>
>>
>>
>
>
> --
> Cheers,
> ?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/f717c074/attachment-0001.html>

From viktor.klang at gmail.com  Tue Apr 15 09:02:20 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 15 Apr 2014 15:02:20 +0200
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CAEJX8orLeRGSa0=6Y4ZgGNse_C5rQTd1xL5xFj5v=L+NhXJ8jw@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CANPzfU8PeUAttZ58VFeD8j5gQjZZJpGfcVFWCWy8jpN5-1j_Ww@mail.gmail.com>
	<CAEJX8opy0goXBPnMW_VED+84p8+OL8negiRae1k5y1Rn=qyeVQ@mail.gmail.com>
	<CANPzfU8KGvFPDzY59kz_SOmV_XHjJ9oyMcyPxhsWiyAkFh0R0w@mail.gmail.com>
	<CAEJX8orRFTJWtoRcsAhsEgxiSTfqNxvX8Zx17RVhDx=JB9qzPQ@mail.gmail.com>
	<CANPzfU8fDd5Gr=QsM2b0B01b8z+_1kPL2JzPE0u-OMu=QZyfVg@mail.gmail.com>
	<CAEJX8orLeRGSa0=6Y4ZgGNse_C5rQTd1xL5xFj5v=L+NhXJ8jw@mail.gmail.com>
Message-ID: <CANPzfU86uSvUY=n19A0MtFwSYGGZfZB1ifpnO60H13VO5gaqxg@mail.gmail.com>

Fair enough!

I'll take it for a spin :)


On Tue, Apr 15, 2014 at 2:48 PM, Stanimir Simeonoff <stanimir at riflexo.com>wrote:

> The 1st real queue should do fine then. Cut off the unnecessary
> notification mechanism and it should be good enough, just pad the head and
> tail to avoid the false sharing.
> If you feel the queue doesn't perform good enough under contention, you
> can try the with a slack tail and I don't think it can be done any better.
> There was a small bug in the nightly post (it was 1am for me too) which
> has been fixed (during offer the real head was read instead of the local
> variable).
>
> Technically, drain can work fine too. Since there is a single consumer,
> you can store the result in the stack itself (ArrayDeque for instance) - if
> the deque is empty then drains it all, stores is in the dequeue, return
> dequeue.poll(). Need another volatile dequeueSize to be added to Node.size.
> In the end it still takes a volatile write on the consumer size to update
> dequeueSize, so there is no real benefit compared to the 1st queue approach.
>
>
> Stanimir
>
>
>
> On Tue, Apr 15, 2014 at 3:32 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> Hi Stanimir,
>>
>> On Tue, Apr 15, 2014 at 2:23 PM, Stanimir Simeonoff <stanimir at riflexo.com
>> > wrote:
>>
>>> If you can tolerate bulk drain(), i.e. "Collection<E> drain()" instead
>>> of "E poll()" there is even a simpler implementation - using a stack and
>>> reverse it on poll(). Although the stack would perform worse under
>>> contention as the "head" is contended by both producers and the consumer,
>>> yet the implementation is super simple.
>>> http://pastebin.com/4FpvHPEy
>>>
>>> I've been using bounded SC/MP queues/stacks with blocking on the
>>> consumer for quite some time, hence the inclusion of park/unpark.
>>>
>>
>> We've already got one approach with bulk drains but it introduces a lot
>> of extra complication for the consumer as you need to store away the batch
>> in case something goes wrong when processing something in the batch, so I'd
>> like to avoid it.
>>
>> I know when there's something in the queue (i get signalled when the
>> "first" element is added, idempotently) so a poll should always return
>> something on the first try, subsequent ones not required (given that the
>> queue is empty).
>>
>>
>>>
>>>
>>> Stanimir
>>>
>>>
>>>
>>>
>>> On Tue, Apr 15, 2014 at 2:04 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>>
>>>> Alright, cool, I won't need that.
>>>>
>>>>
>>>> On Tue, Apr 15, 2014 at 12:07 AM, Stanimir Simeonoff <
>>>> stanimir at riflexo.com> wrote:
>>>>
>>>>> Park/Unpark is only for the consumer size if you specify timeout to
>>>>> wait for an element. The producer never waits besides the CAS loop.
>>>>>
>>>>> Stanimir
>>>>>
>>>>>
>>>>> On Tue, Apr 15, 2014 at 1:05 AM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>>>>>
>>>>>> Hi Stanimir,
>>>>>>
>>>>>> It's really late here, but the presence of park/unpark tells me that
>>>>>> this isn't non-blocking.
>>>>>>
>>>>>>
>>>>>> On Mon, Apr 14, 2014 at 11:59 PM, Stanimir Simeonoff <
>>>>>> stanimir at riflexo.com> wrote:
>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> On Mon, Apr 14, 2014 at 4:00 PM, Oleksandr Otenko <
>>>>>>>> oleksandr.otenko at oracle.com> wrote:
>>>>>>>>
>>>>>>>>>  Yes, but capacity availability is tricky to define.
>>>>>>>>>
>>>>>>>>
>>>>>>>> Absolutely, I am open to suggestions!
>>>>>>>>
>>>>>>>>
>>>>>>> Here is an attempt with the described counter:
>>>>>>> http://pastebin.com/fY1AudYY
>>>>>>>
>>>>>>> Basically it is a linked queue w/o CAS on the head due to single
>>>>>>> consumer only, each node has an extra field *long counter *and the
>>>>>>> current size is 1+tail.counter-head.counter.
>>>>>>> poll(long nanos) may return spuriously as it doesn't bother with
>>>>>>> measuring time. Usually that's ok for single consumer queues as they go
>>>>>>> back to poll() if they don't have other tasks to do.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Stanimir
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Cheers,
>>>>>> ?
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> Cheers,
>>>> ?
>>>>
>>>
>>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/e7fde93a/attachment-0001.html>

From martinrb at google.com  Tue Apr 15 17:30:37 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 15 Apr 2014 14:30:37 -0700
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CAEJX8oqDDN4d4jd1R4zATkPCYJxbKFPdrPYroQumgokwmZFfXg@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CA+kOe0-dsFmPmedC3VvKn3TxYwCCi1f6bm9g1GU8mWui6wGM9Q@mail.gmail.com>
	<CAEJX8oqDDN4d4jd1R4zATkPCYJxbKFPdrPYroQumgokwmZFfXg@mail.gmail.com>
Message-ID: <CA+kOe09cu+U9DtZ8SBrVBtdrNAMSmpqSFqhhQKOF9RLJYW4S0w@mail.gmail.com>

On Mon, Apr 14, 2014 at 11:46 PM, Stanimir Simeonoff
<stanimir at riflexo.com>wrote:

>
>
>
> On Tue, Apr 15, 2014 at 5:41 AM, Martin Buchholz <martinrb at google.com>wrote:
>
>> CLQ can't get away with the counter because it supports internal removal.
>>  But it's reasonable for other implementations to do this.
>>
>> If you read head before tail, you can never have head getting "ahead" of
>> tail, and then 1 + t.counter - h.counter should be mostly right.
>>
>>
>>    1.        static long sub(long tail, long head){
>>    2.                 if (head>tail || ((head^tail)&Long.MIN_VALUE)!=0){
>>
>>
>>
>> It's mostly meant as gimmick to support unsigned counter, i.e.
> overflowing  long and having negative counter.
>

I believe my simple recipe supports even in the (unlikely) case that the
long counter overflows, as with the counter you get back from
System.nanoTime()
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140415/f21b9bfb/attachment.html>

From stanimir at riflexo.com  Tue Apr 15 18:52:33 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Wed, 16 Apr 2014 01:52:33 +0300
Subject: [concurrency-interest] Queue quest
In-Reply-To: <CA+kOe09cu+U9DtZ8SBrVBtdrNAMSmpqSFqhhQKOF9RLJYW4S0w@mail.gmail.com>
References: <CANPzfU8ruhWWjqqNzOk-B7nBzG0o+mVv6cfG1FvCQyaOnsn9Qg@mail.gmail.com>
	<534BD106.4060502@oracle.com>
	<CANPzfU-UKsW8uRT4rGBVWhN4Tr_=P8+BtPeUJFfqyCt4KGBqTQ@mail.gmail.com>
	<534BEA06.3070305@oracle.com>
	<CANPzfU_WTotm2TtcShXX64VnUFspDVVGOS3cL8+4bGhTa4KydA@mail.gmail.com>
	<CAEJX8opiBm_3KCcHzcSPYyZyEWDrUdJ2-RjJXpn4BjsMfnmGFQ@mail.gmail.com>
	<CA+kOe0-dsFmPmedC3VvKn3TxYwCCi1f6bm9g1GU8mWui6wGM9Q@mail.gmail.com>
	<CAEJX8oqDDN4d4jd1R4zATkPCYJxbKFPdrPYroQumgokwmZFfXg@mail.gmail.com>
	<CA+kOe09cu+U9DtZ8SBrVBtdrNAMSmpqSFqhhQKOF9RLJYW4S0w@mail.gmail.com>
Message-ID: <CAEJX8orTOo_-dHUoy9JhAoTbD_Rz_LjZeAWtnq+eLsGNjSj0RA@mail.gmail.com>

Thank you!
It makes sense.

Stanimir


On Wed, Apr 16, 2014 at 12:30 AM, Martin Buchholz <martinrb at google.com>wrote:

>
>
>
> On Mon, Apr 14, 2014 at 11:46 PM, Stanimir Simeonoff <stanimir at riflexo.com
> > wrote:
>
>>
>>
>>
>> On Tue, Apr 15, 2014 at 5:41 AM, Martin Buchholz <martinrb at google.com>wrote:
>>
>>> CLQ can't get away with the counter because it supports internal
>>> removal.  But it's reasonable for other implementations to do this.
>>>
>>> If you read head before tail, you can never have head getting "ahead" of
>>> tail, and then 1 + t.counter - h.counter should be mostly right.
>>>
>>>
>>>    1.        static long sub(long tail, long head){
>>>    2.                 if (head>tail || ((head^tail)&Long.MIN_VALUE)!=0){
>>>
>>>
>>>
>>> It's mostly meant as gimmick to support unsigned counter, i.e.
>> overflowing  long and having negative counter.
>>
>
> I believe my simple recipe supports even in the (unlikely) case that the
> long counter overflows, as with the counter you get back from
> System.nanoTime()
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140416/263b00a7/attachment.html>

From thobes at gmail.com  Wed Apr 16 07:25:15 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 16 Apr 2014 13:25:15 +0200
Subject: [concurrency-interest] Stricter read ordering
Message-ID: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>

[First some background, feel free to jump straight to the code below]

I believe I have a sufficient understanding of read and write barriers, and the barrier implications of volatile in java. With this knowledge I was eyeing a piece of code I wrote some time ago, that has been working fine all along, and thinking to myself that in theory there is a possibility of inconsistent reads in that code, I've just never seen it actually happening.

I've tried to read up on how I could change my code to make it guaranteed to be safe, but not found a good solution, in fact some sources seem to imply that my current implementation would be correct[1], but most confirm that my understanding of barriers is correct and that there is a potential inconsistency in my code.

I thus thought I'd ask in the hopes that someone has greater insight than me and can provide me with a tweak to make my code correct, or assure me in some way that the current code would work.

I'll present a simplified version of the code I have, and then describe the problem.

class VersionedData {
  // this is the overhead I use to manage consistency
  private final volatile long written;
  private final volatile long next;

  // this is the data I protect, in reality there is much more protected state
  private int x, y;
  
  public synchronized void update( int x, int y ) {
    // I guarantee single writers to this method,
    // illustrated with 'synchornized' in this simplification
    long next = this.next + 1;
    this.next = next;
    this.x = x;
    this.y = y;
    this.written = next;
  }

  public DataCarrier read() {
    // I allow multiple readers, so this method is not synchronized
    int x, y;
    long version;
    do {
      version = this.written;
      x = this.x;
      y = this.y;
    } while ( version != this.next );
    return new DataCarrier( x, y );
  }
}

The strategy above works quite well in practice, since reads are much more common than writes, so the occasional retry on read is fine an does not cost a lot.

According to my understanding of read barriers read instructions that are after the barrier in program order are guaranteed not to be moved to before the barrier, so the reading of the data cannot be moved to before the reading of this.written.
However, as far as I understand, there are no guarantees that read instructions that are before a barrier in program order are not moved to after the barrier, meaning that the reading of the data could be moved to after the reading of this.next, introducing an opportunity for a writer to introduce inconsistent data without the reader detecting this.

Is there any way I could introduce a fence that guarantees that the data reads will not be moved to after the read of this.next?

Thank you,
Tobias

[1] Doug Lea's Fences API claims that the orderReads() method "Ensures that a read of the given reference prior to the invocation of this method occurs before a subsequent use of the given reference with the effect of reading or writing a field": http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140416/680256e0/attachment-0001.html>

From d.sannella at contemplateltd.com  Wed Apr 16 10:09:47 2014
From: d.sannella at contemplateltd.com (Don Sannella)
Date: Wed, 16 Apr 2014 15:09:47 +0100
Subject: [concurrency-interest] ThreadSafe static analysis tool for Java
 concurrency: now with command-line invocation
In-Reply-To: <52CC2A60.4090307@contemplateltd.com>
References: <52B85014.60809@contemplateltd.com>
	<CAGu0ZE1cBcn+KH0Ax3k9qWbZ4v9AjgDKy_phPArCqkJKONd6RQ@mail.gmail.com>
	<52CC2A60.4090307@contemplateltd.com>
Message-ID: <534E8F2B.7070609@contemplateltd.com>

Contemplate has recently released a new version of ThreadSafe, an 
advanced static analysis tool that specifically targets Java concurrency 
defects and includes some dedicated treatment for java.util.concurrent. 
I have previously announced a ThreadSafe plugin for Eclipse on this list 
and invited feedback.

New in this release is a command-line version of ThreadSafe which 
produces an HTML report with clickable links, giving ways of browsing 
findings and relating them to the source code. This makes ThreadSafe 
available to people who use IDEs other than Eclipse, and opens the way 
to integration with build/CI tools.

We've also done some major surgery on ThreadSafe's analysis algorithms 
to improve the accuracy of its results, and made other improvements.

An recent InfoQ article about ThreadSafe, showing examples of 
concurrency errors it finds in open source applications including Apache 
JMeter and K9Mail, is here:
  www.infoq.com/articles/Java-Concurrency-Static-Analysis-with-ThreadSafe
As far as we've been able to determine, none of the bugs shown are 
caught by any other Java static analysis tool.

You can see an example of the output of the command-line interface at:
  download.contemplateltd.com/projects/jmeter-2.10/index.html
This is for the same version of Apache JMeter as was discussed in the 
InfoQ article.

You can get a free two-week trial of ThreadSafe Solo (Eclipse plugin and 
command-line version) by filling out a simple webform at:
  http://www.contemplateltd.com/try-buy/request-a-trial

A SonarQube plugin is also available for free trial. Please write to me 
if interested.

More information is on Contemplate's website:
  www.contemplateltd.com/threadsafe

As before, I'm interested in feedback and hope that you will help to 
spread the word!

Best regards,

Don Sannella

--
----------------------------------------------------------------------
Prof. Donald Sannella, Laboratory for Foundations of Computer Science,
School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK
http://homepages.inf.ed.ac.uk/dts  dts at inf.ed.ac.uk  +44 131 650 5184

and

---------------------------------------------------------
Don Sannella                d.sannella at contemplateltd.com
Contemplate Ltd                    www.contemplateltd.com
Appleton Tower, 11 Crichton Street, Edinburgh EH8 9LE, UK
tel +44 7939 132117  fax +44 131 6503474  skype dsannella

From thobes at gmail.com  Thu Apr 17 03:37:24 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Thu, 17 Apr 2014 09:37:24 +0200
Subject: [concurrency-interest] Stricter read ordering
Message-ID: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>

I'm sending this again, since it didn't end up anywhere the first time, I
apologise if anyone gets this email twice.

First some background, feel free to jump straight to the code below.

I believe I have a sufficient understanding of read and write barriers, and
the barrier implications of volatile in java. With this knowledge I was
eyeing a piece of code I wrote some time ago, that has been working fine
all along, and thinking to myself that in theory there is a possibility of
inconsistent reads in that code, I've just never seen it actually happening.

I've tried to read up on how I could change my code to make it guaranteed
to be safe, but not found a good solution, in fact some sources seem to
imply that my current implementation would be correct[1], but most confirm
that my understanding of barriers is correct and that there is a potential
inconsistency in my code.

I thus thought I'd ask in the hopes that someone has greater insight than
me and can provide me with a tweak to make my code correct, or assure me in
some way that the current code would work.

I'll present a simplified version of the code I have, and then describe the
problem.

class VersionedData {
  // this is the overhead I use to manage consistency
  private final volatile long written;
  private final volatile long next;

  // this is the data I protect, in reality there is much more protected
state
  private int x, y;

  public synchronized void update( int x, int y ) {
    // I guarantee single writers to this method,
    // illustrated with 'synchornized' in this simplification
    long next = this.next + 1;
    this.next = next;
    this.x = x;
    this.y = y;
    this.written = next;
  }

  public DataCarrier read() {
    // I allow multiple readers, so this method is not synchronized
    int x, y;
    long version;
    do {
      version = this.written;
      x = this.x;
      y = this.y;
    } while ( version != this.next );
    return new DataCarrier( x, y );
  }
}


The strategy above works quite well in practice, since reads are much more
common than writes, so the occasional retry on read is fine an does not
cost a lot.

According to my understanding of read barriers read instructions that are
after the barrier in program order are guaranteed not to be moved to before
the barrier, so the reading of the data cannot be moved to before the
reading of this.written.
However, as far as I understand, there are no guarantees that read
instructions that are before a barrier in program order are not moved to
after the barrier, meaning that the reading of the data could be moved to
after the reading of this.next, introducing an opportunity for a writer to
introduce inconsistent data without the reader detecting this.

Is there any way I could introduce a fence that guarantees that the data
reads will not be moved to after the read of this.next?

Thank you,
Tobias

[1] Doug Lea's Fences API claims that the orderReads() method "Ensures that
a read of the given reference prior to the invocation of this method occurs
before a subsequent use of the given reference with the effect of reading
or writing a field": http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util
/concurrent/atomic/Fences.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140417/618cda5a/attachment.html>

From aleksey.shipilev at oracle.com  Wed Apr 23 08:42:05 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 23 Apr 2014 16:42:05 +0400
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
Message-ID: <5357B51D.9000206@oracle.com>

On 04/16/2014 03:25 PM, Tobias Lindaaker wrote:
> Is there any way I could introduce a fence that guarantees that the data
> reads will not be moved to after the read of this.next?

I think you are reinventing sequence locks. Prime Java example is
StampedLock which deals with ordering reads with Unsafe.loadFence(), see
StampedLock.validate().

So, in your example, it amounts to:

       public DataCarrier read() {
         // I allow multiple readers, so this method is not ynchronized
         int x, y;
         long version;
         do {
           version = this.written;
           x = this.x;
           y = this.y;
           Unsafe.loadFence();
         } while ( version != this.next );
         return new DataCarrier( x, y );
       }
     }

-Aleksey.


From vitalyd at gmail.com  Wed Apr 23 09:05:03 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 23 Apr 2014 09:05:03 -0400
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357B51D.9000206@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
Message-ID: <CAHjP37E1bJcW11CoX7YbCuKVL9wL_4mJa+M3qc4QW5Sgt2n7zg@mail.gmail.com>

Right.  Otherwise, the loads of x and/or y can move after the load of next
and you may read "ahead" (I.e. read of next catches the old unchanged value
but x and y catch the newly written ones, leading to loop exiting but
having newer x and y that don't match next).

Sent from my phone
On Apr 23, 2014 8:47 AM, "Aleksey Shipilev" <aleksey.shipilev at oracle.com>
wrote:

> On 04/16/2014 03:25 PM, Tobias Lindaaker wrote:
> > Is there any way I could introduce a fence that guarantees that the data
> > reads will not be moved to after the read of this.next?
>
> I think you are reinventing sequence locks. Prime Java example is
> StampedLock which deals with ordering reads with Unsafe.loadFence(), see
> StampedLock.validate().
>
> So, in your example, it amounts to:
>
>        public DataCarrier read() {
>          // I allow multiple readers, so this method is not ynchronized
>          int x, y;
>          long version;
>          do {
>            version = this.written;
>            x = this.x;
>            y = this.y;
>            Unsafe.loadFence();
>          } while ( version != this.next );
>          return new DataCarrier( x, y );
>        }
>      }
>
> -Aleksey.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/e27e7a29/attachment.html>

From thobes at gmail.com  Wed Apr 23 09:05:10 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 15:05:10 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357B51D.9000206@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
Message-ID: <093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>

Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems to do exactly what I want, and if I was fortunate enough to be able to move to Java 8 I would use it. Unfortunately we are still stuck on Java 7. We even have customers who are still strongly requesting Java 6 compatibility.

-tobias

On 23 Apr 2014, at 14:42 , Aleksey Shipilev <aleksey.shipilev at oracle.com> wrote:

> On 04/16/2014 03:25 PM, Tobias Lindaaker wrote:
>> Is there any way I could introduce a fence that guarantees that the data
>> reads will not be moved to after the read of this.next?
> 
> I think you are reinventing sequence locks. Prime Java example is
> StampedLock which deals with ordering reads with Unsafe.loadFence(), see
> StampedLock.validate().
> 
> So, in your example, it amounts to:
> 
>       public DataCarrier read() {
>         // I allow multiple readers, so this method is not ynchronized
>         int x, y;
>         long version;
>         do {
>           version = this.written;
>           x = this.x;
>           y = this.y;
>           Unsafe.loadFence();
>         } while ( version != this.next );
>         return new DataCarrier( x, y );
>       }
>     }
> 
> -Aleksey.
> 



From thobes at gmail.com  Wed Apr 23 09:11:08 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 15:11:08 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <CAHjP37E1bJcW11CoX7YbCuKVL9wL_4mJa+M3qc4QW5Sgt2n7zg@mail.gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<CAHjP37E1bJcW11CoX7YbCuKVL9wL_4mJa+M3qc4QW5Sgt2n7zg@mail.gmail.com>
Message-ID: <3E76EF17-0DEC-49EE-9FE5-694B46426075@gmail.com>

On 23 Apr 2014, at 15:05 , Vitaly Davidovich <vitalyd at gmail.com> wrote:
> Right.  Otherwise, the loads of x and/or y can move after the load of next and you may read "ahead" (I.e. read of next catches the old unchanged value but x and y catch the newly written ones, leading to loop exiting but having newer x and y that don't match next).
> 

Yes, that is exactly the problem I want to solve. Unsafe.loadFence() solves it, as Aleksey elegantly points out.
So I guess my question amounts to: how do I do the same thing as Unsafe.loadFence(), which is introduced in Java 8, in Java 7.

-tobias

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/cd7cb0bd/attachment.html>

From oleksandr.otenko at oracle.com  Wed Apr 23 09:16:12 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 23 Apr 2014 14:16:12 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
Message-ID: <5357BD1C.3030201@oracle.com>

Your code does lead to inconsistencies.

A permitted reordering is:

this.x=x; can go ahead of this.next=next;, which will lead to the 
reading thread observe written==next, yet x being updated, and not y.

Alex

On 16/04/2014 12:25, Tobias Lindaaker wrote:
> [First some background, feel free to jump straight to the code below]
>
> I believe I have a sufficient understanding of read and write 
> barriers, and the barrier implications of volatile in java. With this 
> knowledge I was eyeing a piece of code I wrote some time ago, that has 
> been working fine all along, and thinking to myself that in theory 
> there is a possibility of inconsistent reads in that code, I've just 
> never seen it actually happening.
>
> I've tried to read up on how I could change my code to make it 
> guaranteed to be safe, but not found a good solution, in fact some 
> sources seem to imply that my current implementation would be 
> correct[1], but most confirm that my understanding of barriers is 
> correct and that there is a potential inconsistency in my code.
>
> I thus thought I'd ask in the hopes that someone has greater insight 
> than me and can provide me with a tweak to make my code correct, or 
> assure me in some way that the current code would work.
>
> I'll present a simplified version of the code I have, and then 
> describe the problem.
>
>     class VersionedData {
>       // this is the overhead I use to manage consistency
>       private final volatile long written;
>       private final volatile long next;
>
>       // this is the data I protect, in reality there is much more
>     protected state
>       private int x, y;
>       public synchronized void update( int x, int y ) {
>         // I guarantee single writers to this method,
>         // illustrated with 'synchornized' in this simplification
>         long next = this.next + 1;
>         this.next = next;
>         this.x = x;
>         this.y = y;
>         this.written = next;
>       }
>
>       public DataCarrier read() {
>         // I allow multiple readers, so this method is not synchronized
>         int x, y;
>         long version;
>         do {
>           version = this.written;
>           x = this.x;
>           y = this.y;
>         } while ( version != this.next );
>         return new DataCarrier( x, y );
>       }
>     }
>
>
> The strategy above works quite well in practice, since reads are much 
> more common than writes, so the occasional retry on read is fine an 
> does not cost a lot.
>
> According to my understanding of read barriers read instructions that 
> are after the barrier in program order are guaranteed not to be moved 
> to before the barrier, so the reading of the data cannot be moved to 
> before the reading of this.written.
> However, as far as I understand, there are no guarantees that read 
> instructions that are before a barrier in program order are not moved 
> to after the barrier, meaning that the reading of the data could be 
> moved to after the reading of this.next, introducing an opportunity 
> for a writer to introduce inconsistent data without the reader 
> detecting this.
>
> Is there any way I could introduce a fence that guarantees that the 
> data reads will not be moved to after the read of this.next?
>
> Thank you,
> Tobias
>
> [1] Doug Lea's Fences API claims that the orderReads() method "Ensures 
> that a read of the given reference prior to the invocation of this 
> method occurs before a subsequent use of the given reference with the 
> effect of reading or writing a field": 
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/cc388ee4/attachment-0001.html>

From aleksey.shipilev at oracle.com  Wed Apr 23 09:36:14 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 23 Apr 2014 17:36:14 +0400
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
Message-ID: <5357C1CE.30003@oracle.com>

On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
> to do exactly what I want, and if I was fortunate enough to be able
> to move to Java 8 I would use it. Unfortunately we are still stuck on
> Java 7. We even have customers who are still strongly requesting Java
> 6 compatibility.

These constraints make the problem unresolvable.

You might want to look for pre-JDK8 prototype for StampedLock [1]:

     * As noted in Boehm's paper (above), sequence validation (mainly
     * method validate()) requires stricter ordering rules than apply
     * to normal volatile reads (of "state").  In the absence of (but
     * continual hope for) explicit JVM support of intrinsics with
     * double-sided reordering prohibition, or corresponding fence
     * intrinsics, we for now uncomfortably rely on the fact that the
     * Unsafe.getXVolatile intrinsic must have this property
     * (syntactic volatile reads do not) for internal purposes anyway,
     * even though it is not documented.

    public boolean validate(long stamp) {
        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
    }

But if Unsafe.loadFence() is risky since it is not specified (yet)
JMM-wise, and so interactions with other volatile ops and fences is just
undocumented... then using Unsafe.getXVolatile is double-risky because
the behavioral effect of read ordering is *REALLY*
implementation-specific, and you if are using it for read ordering, you
are five miles past the gateway to Hell already.

Thanks,
-Aleksey.

[1]
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1

From Peter.Kaiser at compuware.com  Wed Apr 23 10:11:20 2014
From: Peter.Kaiser at compuware.com (Kaiser, Peter)
Date: Wed, 23 Apr 2014 14:11:20 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>
References: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>
Message-ID: <1951e808e46748f18ec1c2e512beecf0@DM2PR05MB349.namprd05.prod.outlook.com>

Hi!

Why not trying something like the following:

class VersionedData {
  private volatile DataCarrier dataCarrier;

 public void update( int x, int y ) {
    dataCarrier = new DataCarrier(x, y);
  }

  public DataCarrier read() {
    return new dataCarrier;
  }
}

Also making the read-method synchronized would be an easier solution. Or would this affect performance too much?

Best Regards, Peter


From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tobias Lindaaker
Sent: Donnerstag, 17. April 2014 09:37
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Stricter read ordering

I'm sending this again, since it didn't end up anywhere the first time, I apologise if anyone gets this email twice.

First some background, feel free to jump straight to the code below.

I believe I have a sufficient understanding of read and write barriers, and the barrier implications of volatile in java. With this knowledge I was eyeing a piece of code I wrote some time ago, that has been working fine all along, and thinking to myself that in theory there is a possibility of inconsistent reads in that code, I've just never seen it actually happening.

I've tried to read up on how I could change my code to make it guaranteed to be safe, but not found a good solution, in fact some sources seem to imply that my current implementation would be correct[1], but most confirm that my understanding of barriers is correct and that there is a potential inconsistency in my code.

I thus thought I'd ask in the hopes that someone has greater insight than me and can provide me with a tweak to make my code correct, or assure me in some way that the current code would work.

I'll present a simplified version of the code I have, and then describe the problem.

class VersionedData {
  // this is the overhead I use to manage consistency
  private final volatile long written;
  private final volatile long next;

  // this is the data I protect, in reality there is much more protected state
  private int x, y;

  public synchronized void update( int x, int y ) {
    // I guarantee single writers to this method,
    // illustrated with 'synchornized' in this simplification
    long next = this.next + 1;
    this.next = next;
    this.x = x;
    this.y = y;
    this.written = next;
  }

  public DataCarrier read() {
    // I allow multiple readers, so this method is not synchronized
    int x, y;
    long version;
    do {
      version = this.written;
      x = this.x;
      y = this.y;
    } while ( version != this.next );
    return new DataCarrier( x, y );
  }
}

The strategy above works quite well in practice, since reads are much more common than writes, so the occasional retry on read is fine an does not cost a lot.

According to my understanding of read barriers read instructions that are after the barrier in program order are guaranteed not to be moved to before the barrier, so the reading of the data cannot be moved to before the reading of this.written.
However, as far as I understand, there are no guarantees that read instructions that are before a barrier in program order are not moved to after the barrier, meaning that the reading of the data could be moved to after the reading of this.next, introducing an opportunity for a writer to introduce inconsistent data without the reader detecting this.

Is there any way I could introduce a fence that guarantees that the data reads will not be moved to after the read of this.next?

Thank you,
Tobias

[1] Doug Lea's Fences API claims that the orderReads() method "Ensures that a read of the given reference prior to the invocation of this method occurs before a subsequent use of the given reference with the effect of reading or writing a field": http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html

The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/d951af18/attachment-0001.html>

From thobes at gmail.com  Wed Apr 23 10:12:57 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 16:12:57 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357C1CE.30003@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
Message-ID: <6B806B2E-A44C-4459-9D36-40669073DB13@gmail.com>

See comments below.

On 23 Apr 2014, at 15:36 , Aleksey Shipilev <aleksey.shipilev at oracle.com> wrote:

> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>> to do exactly what I want, and if I was fortunate enough to be able
>> to move to Java 8 I would use it. Unfortunately we are still stuck on
>> Java 7. We even have customers who are still strongly requesting Java
>> 6 compatibility.
> 
> These constraints make the problem unresolvable.
> 
> You might want to look for pre-JDK8 prototype for StampedLock [1]:
> 
>     * As noted in Boehm's paper (above), sequence validation (mainly
>     * method validate()) requires stricter ordering rules than apply
>     * to normal volatile reads (of "state").  In the absence of (but
>     * continual hope for) explicit JVM support of intrinsics with
>     * double-sided reordering prohibition, or corresponding fence
>     * intrinsics, we for now uncomfortably rely on the fact that the
>     * Unsafe.getXVolatile intrinsic must have this property
>     * (syntactic volatile reads do not) for internal purposes anyway,
>     * even though it is not documented.
> 
>    public boolean validate(long stamp) {
>        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>    }
> 
> But if Unsafe.loadFence() is risky since it is not specified (yet)
> JMM-wise, and so interactions with other volatile ops and fences is just
> undocumented... then using Unsafe.getXVolatile is double-risky because
> the behavioral effect of read ordering is *REALLY*
> implementation-specific, and you if are using it for read ordering, you
> are five miles past the gateway to Hell already.
> 
> Thanks,
> -Aleksey.
> 
> [1]
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1

Thank you Aleksey,

Those incidental implementation implications of Unsafe.get*Volatile(...) is exactly what we were looking for.
I agree that it is scary and sad to have to rely on these things (and that even in Java 8, many things you need is hidden behind the discouraging name of "sun.misc.Unsafe"), but it's the reality of working on the JVM. Given how far we've already ventured beyond those gates, five more miles will make virtually no difference...

As a side note, if we could move to Java 8, it is possible that StampedLock could completely fulfil this use case, and that we could use that to simplify our code here. Although we would have to measure the implications of the indirection that would add.


On 23 Apr 2014, at 15:16 , Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:
> Your code does lead to inconsistencies.
> 
> A permitted reordering is:
> 
> this.x=x; can go ahead of this.next=next;, which will lead to the reading thread observe written==next, yet x being updated, and not y.
> 
> Alex
> 

You are right Alex, there is of course that reordering problem as well, and I would need similar fencing there too.

I would think this would suffice in Java 8:

  public synchronized void update( int x, int y ) {
    long next = this.next + 1;
    this.next = next;
    Unsafe.storeFence(); // <- this being the added line
    this.x = x;
    this.y = y;
    this.written = next;
  }

... and is there some primitive with similar incidental implications to what Aleksey pointed out for the load fence (but for store fencing in this case) that could be used in earlier JDKs?

Thank you both,
Tobias
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/c34cfce0/attachment.html>

From elizarov at devexperts.com  Wed Apr 23 10:16:31 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Wed, 23 Apr 2014 14:16:31 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357C1CE.30003@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
Message-ID: <a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>

The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list. 

Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.

So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path. 

class VersionedData {
    // bit that we'll use to indicate that the state is being written to
    private static final int WRITE = 1 << 31;
    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
    private final AtomicInteger version = new AtomicInteger();

    // this is the data I protect, in reality there is much more protected state
    private int x, y;

    public synchronized void update(int x, int y) {
        // I guarantee single writers to this method,
        // illustrated with 'synchronized' in this simplification
        // first use CAS to mark version as being written to
        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
        // then write protected data (non-volatile writes)
        this.x = x;
        this.y = y;
        // then increment version and reset write bit
        version.set((v0 + 1) & ~WRITE);
    }

    public DataCarrier read() {
        // I allow multiple readers, so this method is not synchronized
        int x, y;
        int v0;
        do {
            // first read version
            v0 = version.get();
            if ((v0 & WRITE) != 0)
                continue; // immediately abort, because write in progress was detected
            // then read protected data
            x = this.x;
            y = this.y;
            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
        } while (!version.compareAndSet(v0, v0));
        return new DataCarrier(x, y);
    }
}

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
Sent: Wednesday, April 23, 2014 5:36 PM
To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems 
> to do exactly what I want, and if I was fortunate enough to be able to 
> move to Java 8 I would use it. Unfortunately we are still stuck on 
> Java 7. We even have customers who are still strongly requesting Java
> 6 compatibility.

These constraints make the problem unresolvable.

You might want to look for pre-JDK8 prototype for StampedLock [1]:

     * As noted in Boehm's paper (above), sequence validation (mainly
     * method validate()) requires stricter ordering rules than apply
     * to normal volatile reads (of "state").  In the absence of (but
     * continual hope for) explicit JVM support of intrinsics with
     * double-sided reordering prohibition, or corresponding fence
     * intrinsics, we for now uncomfortably rely on the fact that the
     * Unsafe.getXVolatile intrinsic must have this property
     * (syntactic volatile reads do not) for internal purposes anyway,
     * even though it is not documented.

    public boolean validate(long stamp) {
        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
    }

But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.

Thanks,
-Aleksey.

[1]
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From thobes at gmail.com  Wed Apr 23 10:21:37 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 16:21:37 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <1951e808e46748f18ec1c2e512beecf0@DM2PR05MB349.namprd05.prod.outlook.com>
References: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>
	<1951e808e46748f18ec1c2e512beecf0@DM2PR05MB349.namprd05.prod.outlook.com>
Message-ID: <73647052-A385-4F70-B733-A26F436761CE@gmail.com>

If the actual code was as simple as the simplified example that would be a good idea.
But the actual state is in a ByteBuffer, making this approach impossible (or at least extremely inconvenient and impractical).

synchronizing the read method would have too much of a performance impact since it would make readers block one another.

-tobias

On 23 Apr 2014, at 16:11 , Kaiser, Peter <Peter.Kaiser at compuware.com> wrote:

> Hi!
>  
> Why not trying something like the following:
>  
> class VersionedData {
>   private volatile DataCarrier dataCarrier;
>  
>  public void update( int x, int y ) {
>     dataCarrier = new DataCarrier(x, y);
>   }
>  
>   public DataCarrier read() {
>     return new dataCarrier;
>   }
> }
>  
> Also making the read-method synchronized would be an easier solution. Or would this affect performance too much?
>  
> Best Regards, Peter
>  
>  
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tobias Lindaaker
> Sent: Donnerstag, 17. April 2014 09:37
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Stricter read ordering
>  
> I'm sending this again, since it didn't end up anywhere the first time, I apologise if anyone gets this email twice.
>  
> First some background, feel free to jump straight to the code below.
>  
> I believe I have a sufficient understanding of read and write barriers, and the barrier implications of volatile in java. With this knowledge I was eyeing a piece of code I wrote some time ago, that has been working fine all along, and thinking to myself that in theory there is a possibility of inconsistent reads in that code, I've just never seen it actually happening.
>  
> I've tried to read up on how I could change my code to make it guaranteed to be safe, but not found a good solution, in fact some sources seem to imply that my current implementation would be correct[1], but most confirm that my understanding of barriers is correct and that there is a potential inconsistency in my code.
>  
> I thus thought I'd ask in the hopes that someone has greater insight than me and can provide me with a tweak to make my code correct, or assure me in some way that the current code would work.
>  
> I'll present a simplified version of the code I have, and then describe the problem.
>  
> class VersionedData {
>   // this is the overhead I use to manage consistency
>   private final volatile long written;
>   private final volatile long next;
>  
>   // this is the data I protect, in reality there is much more protected state
>   private int x, y;
>   
>   public synchronized void update( int x, int y ) {
>     // I guarantee single writers to this method,
>     // illustrated with 'synchornized' in this simplification
>     long next = this.next + 1;
>     this.next = next;
>     this.x = x;
>     this.y = y;
>     this.written = next;
>   }
>  
>   public DataCarrier read() {
>     // I allow multiple readers, so this method is not synchronized
>     int x, y;
>     long version;
>     do {
>       version = this.written;
>       x = this.x;
>       y = this.y;
>     } while ( version != this.next );
>     return new DataCarrier( x, y );
>   }
> }
>  
> The strategy above works quite well in practice, since reads are much more common than writes, so the occasional retry on read is fine an does not cost a lot.
>  
> According to my understanding of read barriers read instructions that are after the barrier in program order are guaranteed not to be moved to before the barrier, so the reading of the data cannot be moved to before the reading of this.written.
> However, as far as I understand, there are no guarantees that read instructions that are before a barrier in program order are not moved to after the barrier, meaning that the reading of the data could be moved to after the reading of this.next, introducing an opportunity for a writer to introduce inconsistent data without the reader detecting this.
>  
> Is there any way I could introduce a fence that guarantees that the data reads will not be moved to after the read of this.next?
>  
> Thank you,
> Tobias
>  
> [1] Doug Lea's Fences API claims that the orderReads() method "Ensures that a read of the given reference prior to the invocation of this method occurs before a subsequent use of the given reference with the effect of reading or writing a field": http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>  
> The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/3dbd4805/attachment-0001.html>

From thobes at gmail.com  Wed Apr 23 10:29:11 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 16:29:11 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
Message-ID: <7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>

That is one of the approaches we have in our benchmark suite for this, and we also concluded that the CAS in read() would have a too substantial impact on the scalability of the algorithm.

-tobias

On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> wrote:

> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list. 
> 
> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
> 
> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path. 
> 
> class VersionedData {
>    // bit that we'll use to indicate that the state is being written to
>    private static final int WRITE = 1 << 31;
>    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>    private final AtomicInteger version = new AtomicInteger();
> 
>    // this is the data I protect, in reality there is much more protected state
>    private int x, y;
> 
>    public synchronized void update(int x, int y) {
>        // I guarantee single writers to this method,
>        // illustrated with 'synchronized' in this simplification
>        // first use CAS to mark version as being written to
>        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>        // then write protected data (non-volatile writes)
>        this.x = x;
>        this.y = y;
>        // then increment version and reset write bit
>        version.set((v0 + 1) & ~WRITE);
>    }
> 
>    public DataCarrier read() {
>        // I allow multiple readers, so this method is not synchronized
>        int x, y;
>        int v0;
>        do {
>            // first read version
>            v0 = version.get();
>            if ((v0 & WRITE) != 0)
>                continue; // immediately abort, because write in progress was detected
>            // then read protected data
>            x = this.x;
>            y = this.y;
>            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>        } while (!version.compareAndSet(v0, v0));
>        return new DataCarrier(x, y);
>    }
> }
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> Sent: Wednesday, April 23, 2014 5:36 PM
> To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Stricter read ordering
> 
> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems 
>> to do exactly what I want, and if I was fortunate enough to be able to 
>> move to Java 8 I would use it. Unfortunately we are still stuck on 
>> Java 7. We even have customers who are still strongly requesting Java
>> 6 compatibility.
> 
> These constraints make the problem unresolvable.
> 
> You might want to look for pre-JDK8 prototype for StampedLock [1]:
> 
>     * As noted in Boehm's paper (above), sequence validation (mainly
>     * method validate()) requires stricter ordering rules than apply
>     * to normal volatile reads (of "state").  In the absence of (but
>     * continual hope for) explicit JVM support of intrinsics with
>     * double-sided reordering prohibition, or corresponding fence
>     * intrinsics, we for now uncomfortably rely on the fact that the
>     * Unsafe.getXVolatile intrinsic must have this property
>     * (syntactic volatile reads do not) for internal purposes anyway,
>     * even though it is not documented.
> 
>    public boolean validate(long stamp) {
>        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>    }
> 
> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
> 
> Thanks,
> -Aleksey.
> 
> [1]
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From elizarov at devexperts.com  Wed Apr 23 10:40:16 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Wed, 23 Apr 2014 14:40:16 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
Message-ID: <9658a43ead3245c08a1bd50846769741@exchmb01.office.devexperts.com>

What was the reason, then, to use two control variables (written and next)? I don't see how it makes the algorithm "more correct", versus the one that uses just one "version" variable (write it before and after write and read before and after read). Without CAS or additional barriers (that are available in Java 8 only) both approaches are equally incorrect in theory, but both will should equally correct on x86 due to TSO, unless HotSpot does some crazy reordering. 

As a side note, I can prove that under JMM the read path of this algorithm must have at least one write (volatile write). You cannot make read path read-only under JMM (if you don't have explicit access to barriers). This prove yields a CAS-less construction of this algorithm, but I have not rigorously looked at it, since it is less intuitive and does not look to be not be giving a performance improvement over the CAS version. 

-----Original Message-----
From: Tobias Lindaaker [mailto:thobes at gmail.com] 
Sent: Wednesday, April 23, 2014 6:29 PM
To: Roman Elizarov
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

That is one of the approaches we have in our benchmark suite for this, and we also concluded that the CAS in read() would have a too substantial impact on the scalability of the algorithm.

-tobias

On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> wrote:

> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list. 
> 
> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
> 
> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path. 
> 
> class VersionedData {
>    // bit that we'll use to indicate that the state is being written to
>    private static final int WRITE = 1 << 31;
>    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>    private final AtomicInteger version = new AtomicInteger();
> 
>    // this is the data I protect, in reality there is much more protected state
>    private int x, y;
> 
>    public synchronized void update(int x, int y) {
>        // I guarantee single writers to this method,
>        // illustrated with 'synchronized' in this simplification
>        // first use CAS to mark version as being written to
>        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>        // then write protected data (non-volatile writes)
>        this.x = x;
>        this.y = y;
>        // then increment version and reset write bit
>        version.set((v0 + 1) & ~WRITE);
>    }
> 
>    public DataCarrier read() {
>        // I allow multiple readers, so this method is not synchronized
>        int x, y;
>        int v0;
>        do {
>            // first read version
>            v0 = version.get();
>            if ((v0 & WRITE) != 0)
>                continue; // immediately abort, because write in progress was detected
>            // then read protected data
>            x = this.x;
>            y = this.y;
>            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>        } while (!version.compareAndSet(v0, v0));
>        return new DataCarrier(x, y);
>    }
> }
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of 
> Aleksey Shipilev
> Sent: Wednesday, April 23, 2014 5:36 PM
> To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Stricter read ordering
> 
> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems 
>> to do exactly what I want, and if I was fortunate enough to be able 
>> to move to Java 8 I would use it. Unfortunately we are still stuck on 
>> Java 7. We even have customers who are still strongly requesting Java
>> 6 compatibility.
> 
> These constraints make the problem unresolvable.
> 
> You might want to look for pre-JDK8 prototype for StampedLock [1]:
> 
>     * As noted in Boehm's paper (above), sequence validation (mainly
>     * method validate()) requires stricter ordering rules than apply
>     * to normal volatile reads (of "state").  In the absence of (but
>     * continual hope for) explicit JVM support of intrinsics with
>     * double-sided reordering prohibition, or corresponding fence
>     * intrinsics, we for now uncomfortably rely on the fact that the
>     * Unsafe.getXVolatile intrinsic must have this property
>     * (syntactic volatile reads do not) for internal purposes anyway,
>     * even though it is not documented.
> 
>    public boolean validate(long stamp) {
>        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>    }
> 
> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
> 
> Thanks,
> -Aleksey.
> 
> [1]
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/Stampe
> dLock.java?revision=1.1 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From aleksey.shipilev at oracle.com  Wed Apr 23 10:58:54 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 23 Apr 2014 18:58:54 +0400
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
Message-ID: <5357D52E.6010300@oracle.com>

+1. Dragging us back to StampedLock example, the rationale for doing
ordered reads is to avoid writes on the read path.

Barring the locks (scalability hit), volatile writes / releasing stores
(still a potential scalability hit), or putting (x, y) into a wrapper
instance (cache misses, yay!), the only thing you are left with is
ordering the reads with fences.

If reads greatly out-weight writes, plus the data is encapsulateable
into the single instance, plus one possible cache miss is not an issue,
I would prefer to have the actual wrapper instance, though. I think
that's Peter Kaiser's point, although OP's example is greatly
simplified, and OP's non-simplified case may invalidate any of these
prerequisites.

-Aleksey.

On 04/23/2014 06:29 PM, Tobias Lindaaker wrote:
> That is one of the approaches we have in our benchmark suite for 
> this, and we also concluded that the CAS in read() would have a too 
> substantial impact on the scalability of the algorithm.
> 
> -tobias
> 
> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> 
> wrote:
>> It will not scale, though, if there are many concurrent readers, 
>> because of the CAS in read path.
>> 
>> -Roman

From Peter.Kaiser at compuware.com  Wed Apr 23 11:00:02 2014
From: Peter.Kaiser at compuware.com (Kaiser, Peter)
Date: Wed, 23 Apr 2014 15:00:02 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <73647052-A385-4F70-B733-A26F436761CE@gmail.com>
References: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>
	<1951e808e46748f18ec1c2e512beecf0@DM2PR05MB349.namprd05.prod.outlook.com>
	<73647052-A385-4F70-B733-A26F436761CE@gmail.com>
Message-ID: <e4d0c30386e345169f61812ec3c3c2c2@DM2PR05MB349.namprd05.prod.outlook.com>

Ok, I see. Do the reader threads apply any modifications to the state, so that they each need an individual copy of the state?
As the state has to be copied anyway to keep the program correctly synchronized there would have to be some very good arguments to use advanced synchronization mechanisms for a problem like this.
If the state could be provided as an immutable snapshot to the readers moving all the logic to the update method would seem to be a good solution to me. Also that way reads wouldn't be able to cause any memory problems by creating too much instances of the state object. If it's not possible to store the state in an immutable object, then would simply cloning it in the read method be a possibility for you? Of course you would have one more instance of the state object, but would that be a problem?

Best Regards, Peter

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tobias Lindaaker
Sent: Mittwoch, 23. April 2014 16:22
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

If the actual code was as simple as the simplified example that would be a good idea.
But the actual state is in a ByteBuffer, making this approach impossible (or at least extremely inconvenient and impractical).

synchronizing the read method would have too much of a performance impact since it would make readers block one another.

-tobias

On 23 Apr 2014, at 16:11 , Kaiser, Peter <Peter.Kaiser at compuware.com<mailto:Peter.Kaiser at compuware.com>> wrote:


Hi!

Why not trying something like the following:

class VersionedData {
  private volatile DataCarrier dataCarrier;

 public void update( int x, int y ) {
    dataCarrier = new DataCarrier(x, y);
  }

  public DataCarrier read() {
    return new dataCarrier;
  }
}

Also making the read-method synchronized would be an easier solution. Or would this affect performance too much?

Best Regards, Peter


From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tobias Lindaaker
Sent: Donnerstag, 17. April 2014 09:37
To: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: [concurrency-interest] Stricter read ordering

I'm sending this again, since it didn't end up anywhere the first time, I apologise if anyone gets this email twice.

First some background, feel free to jump straight to the code below.

I believe I have a sufficient understanding of read and write barriers, and the barrier implications of volatile in java. With this knowledge I was eyeing a piece of code I wrote some time ago, that has been working fine all along, and thinking to myself that in theory there is a possibility of inconsistent reads in that code, I've just never seen it actually happening.

I've tried to read up on how I could change my code to make it guaranteed to be safe, but not found a good solution, in fact some sources seem to imply that my current implementation would be correct[1], but most confirm that my understanding of barriers is correct and that there is a potential inconsistency in my code.

I thus thought I'd ask in the hopes that someone has greater insight than me and can provide me with a tweak to make my code correct, or assure me in some way that the current code would work.

I'll present a simplified version of the code I have, and then describe the problem.

class VersionedData {
  // this is the overhead I use to manage consistency
  private final volatile long written;
  private final volatile long next;

  // this is the data I protect, in reality there is much more protected state
  private int x, y;

  public synchronized void update( int x, int y ) {
    // I guarantee single writers to this method,
    // illustrated with 'synchornized' in this simplification
    long next = this.next + 1;
    this.next = next;
    this.x = x;
    this.y = y;
    this.written = next;
  }

  public DataCarrier read() {
    // I allow multiple readers, so this method is not synchronized
    int x, y;
    long version;
    do {
      version = this.written;
      x = this.x;
      y = this.y;
    } while ( version != this.next );
    return new DataCarrier( x, y );
  }
}

The strategy above works quite well in practice, since reads are much more common than writes, so the occasional retry on read is fine an does not cost a lot.

According to my understanding of read barriers read instructions that are after the barrier in program order are guaranteed not to be moved to before the barrier, so the reading of the data cannot be moved to before the reading of this.written.
However, as far as I understand, there are no guarantees that read instructions that are before a barrier in program order are not moved to after the barrier, meaning that the reading of the data could be moved to after the reading of this.next, introducing an opportunity for a writer to introduce inconsistent data without the reader detecting this.

Is there any way I could introduce a fence that guarantees that the data reads will not be moved to after the read of this.next?

Thank you,
Tobias

[1] Doug Lea's Fences API claims that the orderReads() method "Ensures that a read of the given reference prior to the invocation of this method occurs before a subsequent use of the given reference with the effect of reading or writing a field": http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html

The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.

The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/fbf87c62/attachment-0001.html>

From thobes at gmail.com  Wed Apr 23 11:00:58 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 17:00:58 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <9658a43ead3245c08a1bd50846769741@exchmb01.office.devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<9658a43ead3245c08a1bd50846769741@exchmb01.office.devexperts.com>
Message-ID: <B97E6E2B-0516-41D7-98DE-B0A2EEEF8170@gmail.com>

If you use the single "version" field in the way you outlined, to serve two purposes, both a special "someone is writing" mark and as a version, then one field would suffice.
The two fields were just a different way of achieving the same guarantees without having a special marker value.

We have contemplated a volatile write to an object that's local to the thread, in order to get the volatile write barrier semantics without writing to a contended location. Would that give sufficient barrier semantics? As Oleksandr Otenko pointed out earlier, there might even be a problem with reordering of writes.

-tobias

On 23 Apr 2014, at 16:40 , Roman Elizarov <elizarov at devexperts.com> wrote:

> What was the reason, then, to use two control variables (written and next)? I don't see how it makes the algorithm "more correct", versus the one that uses just one "version" variable (write it before and after write and read before and after read). Without CAS or additional barriers (that are available in Java 8 only) both approaches are equally incorrect in theory, but both will should equally correct on x86 due to TSO, unless HotSpot does some crazy reordering. 
> 
> As a side note, I can prove that under JMM the read path of this algorithm must have at least one write (volatile write). You cannot make read path read-only under JMM (if you don't have explicit access to barriers). This prove yields a CAS-less construction of this algorithm, but I have not rigorously looked at it, since it is less intuitive and does not look to be not be giving a performance improvement over the CAS version. 
> 
> -----Original Message-----
> From: Tobias Lindaaker [mailto:thobes at gmail.com] 
> Sent: Wednesday, April 23, 2014 6:29 PM
> To: Roman Elizarov
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Stricter read ordering
> 
> That is one of the approaches we have in our benchmark suite for this, and we also concluded that the CAS in read() would have a too substantial impact on the scalability of the algorithm.
> 
> -tobias
> 
> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> wrote:
> 
>> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list. 
>> 
>> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>> 
>> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path. 
>> 
>> class VersionedData {
>>   // bit that we'll use to indicate that the state is being written to
>>   private static final int WRITE = 1 << 31;
>>   // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>>   private final AtomicInteger version = new AtomicInteger();
>> 
>>   // this is the data I protect, in reality there is much more protected state
>>   private int x, y;
>> 
>>   public synchronized void update(int x, int y) {
>>       // I guarantee single writers to this method,
>>       // illustrated with 'synchronized' in this simplification
>>       // first use CAS to mark version as being written to
>>       int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>>       version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>       // then write protected data (non-volatile writes)
>>       this.x = x;
>>       this.y = y;
>>       // then increment version and reset write bit
>>       version.set((v0 + 1) & ~WRITE);
>>   }
>> 
>>   public DataCarrier read() {
>>       // I allow multiple readers, so this method is not synchronized
>>       int x, y;
>>       int v0;
>>       do {
>>           // first read version
>>           v0 = version.get();
>>           if ((v0 & WRITE) != 0)
>>               continue; // immediately abort, because write in progress was detected
>>           // then read protected data
>>           x = this.x;
>>           y = this.y;
>>           // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>>       } while (!version.compareAndSet(v0, v0));
>>       return new DataCarrier(x, y);
>>   }
>> }
>> 
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu 
>> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of 
>> Aleksey Shipilev
>> Sent: Wednesday, April 23, 2014 5:36 PM
>> To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Stricter read ordering
>> 
>> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems 
>>> to do exactly what I want, and if I was fortunate enough to be able 
>>> to move to Java 8 I would use it. Unfortunately we are still stuck on 
>>> Java 7. We even have customers who are still strongly requesting Java
>>> 6 compatibility.
>> 
>> These constraints make the problem unresolvable.
>> 
>> You might want to look for pre-JDK8 prototype for StampedLock [1]:
>> 
>>    * As noted in Boehm's paper (above), sequence validation (mainly
>>    * method validate()) requires stricter ordering rules than apply
>>    * to normal volatile reads (of "state").  In the absence of (but
>>    * continual hope for) explicit JVM support of intrinsics with
>>    * double-sided reordering prohibition, or corresponding fence
>>    * intrinsics, we for now uncomfortably rely on the fact that the
>>    * Unsafe.getXVolatile intrinsic must have this property
>>    * (syntactic volatile reads do not) for internal purposes anyway,
>>    * even though it is not documented.
>> 
>>   public boolean validate(long stamp) {
>>       return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>>   }
>> 
>> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>> 
>> Thanks,
>> -Aleksey.
>> 
>> [1]
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/Stampe
>> dLock.java?revision=1.1 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 



From thobes at gmail.com  Wed Apr 23 11:28:36 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Wed, 23 Apr 2014 17:28:36 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357D52E.6010300@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
Message-ID: <A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>

Yes, exactly, writes tend to get more expensive, so avoiding them for the read case is desired.

As I wrote in my reply to Peter Kaiser, the actual state that is guarded is a ByteBuffer.
This ByteBuffer contains multiple records, and readers read one record and need that to be consistent, while writers typically update multiple records at once.

And to answer Peters most recent question:

On 23 Apr 2014, at 17:00 , Kaiser, Peter <Peter.Kaiser at compuware.com> wrote:
> Ok, I see. Do the reader threads apply any modifications to the state, so that they each need an individual copy of the state?

> As the state has to be copied anyway to keep the program correctly synchronized there would have to be some very good arguments to use advanced synchronization mechanisms for a problem like this.

> If the state could be provided as an immutable snapshot to the readers moving all the logic to the update method would seem to be a good solution to me. Also that way reads wouldn?t be able to cause any memory problems by creating too much instances of the state object. If it?s not possible to store the state in an immutable object, then would simply cloning it in the read method be a possibility for you? Of course you would have one more instance of the state object, but would that be a problem?


The reader threads do not apply any modifications to the state, they do computation based on the state, which might later result in writes back.

Perhaps I shouldn't have simplified the code so much, but rather kept it closer to what it actually is, here is another version, where the state is closer to what it is in our actual application, but the data stored in it is still simplified:

class VersionedData {
  // this is the overhead I use to manage consistency
  private final volatile long written;
  private final volatile long next;

  // the protected data, this typically a memory mapped file
  private final ByteBuffer buffer;
  VersionedData( ByteBuffer buffer ) { this.buffer = buffer; }
  
  public synchronized void update( Iterable<DataCarrier> data ) {
    long next = this.next + 1;
    this.next = next;
    for (DataCarrier cursor : data) {
      int offset = data.offset * 8;
      buffer.putInt( offset    , data.x );
      buffer.putInt( offset + 4, data.y );
    }
    this.written = next;
  }

  public void read(DataCarrier cursor) {
    // I allow multiple readers, so this method is not synchronized
    int x, y, offset = cursor.offset * 8;
    long version;
    do {
      version = this.written;
      x = buffer.getInt(offset);
      y = buffer.getInt(offset + 4);
    } while ( version != this.next );
    cursor.x = x;
    cursor.y = y;
  }
}

Reading snapshots from different versions does not matter, but x and y have to be consistent with one another.

Readers typically instantiate one DataCarrier and do multiple reads using the same instance, changing the offset of it in between, this to avoid creating too many objects since neither escape analysis nor garbage collection is as good as anyone would want it to be. Again this being the sad truth about coding for the JVM, the happy truth of course being that many many other things are absolutely amazing.

-tobias

On 23 Apr 2014, at 16:58 , Aleksey Shipilev <aleksey.shipilev at oracle.com> wrote:

> +1. Dragging us back to StampedLock example, the rationale for doing
> ordered reads is to avoid writes on the read path.
> 
> Barring the locks (scalability hit), volatile writes / releasing stores
> (still a potential scalability hit), or putting (x, y) into a wrapper
> instance (cache misses, yay!), the only thing you are left with is
> ordering the reads with fences.
> 
> If reads greatly out-weight writes, plus the data is encapsulateable
> into the single instance, plus one possible cache miss is not an issue,
> I would prefer to have the actual wrapper instance, though. I think
> that's Peter Kaiser's point, although OP's example is greatly
> simplified, and OP's non-simplified case may invalidate any of these
> prerequisites.
> 
> -Aleksey.
> 
> On 04/23/2014 06:29 PM, Tobias Lindaaker wrote:
>> That is one of the approaches we have in our benchmark suite for 
>> this, and we also concluded that the CAS in read() would have a too 
>> substantial impact on the scalability of the algorithm.
>> 
>> -tobias
>> 
>> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> 
>> wrote:
>>> It will not scale, though, if there are many concurrent readers, 
>>> because of the CAS in read path.
>>> 
>>> -Roman

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/035989ec/attachment.html>

From stanimir at riflexo.com  Wed Apr 23 11:57:51 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Wed, 23 Apr 2014 18:57:51 +0300
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
Message-ID: <CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>

Just in case to make sure:
You have more than just 2 ints, right?
On 64bit and aligned direct buffers you'd get all you want via put/getLong
esp on LongBuffer as it always aligned.

Stanimir


On Wed, Apr 23, 2014 at 6:28 PM, Tobias Lindaaker <thobes at gmail.com> wrote:

> Yes, exactly, writes tend to get more expensive, so avoiding them for the
> read case is desired.
>
> As I wrote in my reply to Peter Kaiser, the actual state that is guarded
> is a ByteBuffer.
> This ByteBuffer contains multiple records, and readers read one record and
> need that to be consistent, while writers typically update multiple records
> at once.
>
> And to answer Peters most recent question:
>
>
> On 23 Apr 2014, at 17:00 , Kaiser, Peter <Peter.Kaiser at compuware.com>
> wrote:
>
> Ok, I see. Do the reader threads apply any modifications to the state, so
> that they each need an individual copy of the state?
>
> As the state has to be copied anyway to keep the program correctly
> synchronized there would have to be some very good arguments to use
> advanced synchronization mechanisms for a problem like this.
>
> If the state could be provided as an immutable snapshot to the readers
> moving all the logic to the update method would seem to be a good solution
> to me. Also that way reads wouldn't be able to cause any memory problems by
> creating too much instances of the state object. If it's not possible to
> store the state in an immutable object, then would simply cloning it in the
> read method be a possibility for you? Of course you would have one more
> instance of the state object, but would that be a problem?
>
>
> The reader threads do not apply any modifications to the state, they do
> computation based on the state, which might later result in writes back.
>
> Perhaps I shouldn't have simplified the code so much, but rather kept it
> closer to what it actually is, here is another version, where the state is
> closer to what it is in our actual application, but the data stored in it
> is still simplified:
>
> class VersionedData {
>   // this is the overhead I use to manage consistency
>   private final volatile long written;
>   private final volatile long next;
>
>   // the protected data, this typically a memory mapped file
>   private final ByteBuffer buffer;
>   VersionedData( ByteBuffer buffer ) { this.buffer = buffer; }
>
>   public synchronized void update( Iterable<DataCarrier> data ) {
>     long next = this.next + 1;
>     this.next = next;
>     for (DataCarrier cursor : data) {
>       int offset = data.offset * 8;
>       buffer.putInt( offset    , data.x );
>       buffer.putInt( offset + 4, data.y );
>     }
>     this.written = next;
>   }
>
>   public void read(DataCarrier cursor) {
>     // I allow multiple readers, so this method is not synchronized
>     int x, y, offset = cursor.offset * 8;
>     long version;
>     do {
>       version = this.written;
>       x = buffer.getInt(offset);
>       y = buffer.getInt(offset + 4);
>     } while ( version != this.next );
>     cursor.x = x;
>     cursor.y = y;
>   }
> }
>
>
> Reading snapshots from different versions does not matter, but x and y
> have to be consistent with one another.
>
> Readers typically instantiate one DataCarrier and do multiple reads using
> the same instance, changing the offset of it in between, this to avoid
> creating too many objects since neither escape analysis nor garbage
> collection is as good as anyone would want it to be. Again this being the
> sad truth about coding for the JVM, the happy truth of course being that
> many many other things are absolutely amazing.
>
> -tobias
>
> On 23 Apr 2014, at 16:58 , Aleksey Shipilev <aleksey.shipilev at oracle.com>
> wrote:
>
> +1. Dragging us back to StampedLock example, the rationale for doing
> ordered reads is to avoid writes on the read path.
>
> Barring the locks (scalability hit), volatile writes / releasing stores
> (still a potential scalability hit), or putting (x, y) into a wrapper
> instance (cache misses, yay!), the only thing you are left with is
> ordering the reads with fences.
>
> If reads greatly out-weight writes, plus the data is encapsulateable
> into the single instance, plus one possible cache miss is not an issue,
> I would prefer to have the actual wrapper instance, though. I think
> that's Peter Kaiser's point, although OP's example is greatly
> simplified, and OP's non-simplified case may invalidate any of these
> prerequisites.
>
> -Aleksey.
>
> On 04/23/2014 06:29 PM, Tobias Lindaaker wrote:
>
> That is one of the approaches we have in our benchmark suite for
> this, and we also concluded that the CAS in read() would have a too
> substantial impact on the scalability of the algorithm.
>
> -tobias
>
> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com>
> wrote:
>
> It will not scale, though, if there are many concurrent readers,
> because of the CAS in read path.
>
> -Roman
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/683d9e3b/attachment-0001.html>

From elizarov at devexperts.com  Wed Apr 23 12:04:36 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Wed, 23 Apr 2014 16:04:36 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <B97E6E2B-0516-41D7-98DE-B0A2EEEF8170@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<9658a43ead3245c08a1bd50846769741@exchmb01.office.devexperts.com>
	<B97E6E2B-0516-41D7-98DE-B0A2EEEF8170@gmail.com>
Message-ID: <68deadb22fb54e7db8e43effb756d3c0@exchmb01.office.devexperts.com>

There is a bunch of potential reorderings that have to be prevented. Consider writer and reader that ensure atomic multi-word snapshot by using a single "version" variable, that is written only by writer and is read only by reader:

Writer does (in PO): version.write();  x.write(); y.write(); version.write();
Reader does (in PO): version.read(); x.read(); y.read(); version.read();

What reorderings we must prevent in order to ensure that if both version.read() operations produce the same value, then snapshot is guaranteed to be consistent. It can be shown that the following set of (Store|Load)(Store|Load) barriers is minimal and sufficient:

Writer does (in PO): version.write();  StoreStore; x.write(); y.write(); StoreStore; version.write();
Reader does (in PO): version.read(); LoadLoad; x.read(); y.read(); LoadLoad; version.read();

Now, JSR-133 cookbook gives you an nice table, that tells exactly what barriers must be emitted by JVM to be conformant with JMM: http://gee.cs.oswego.edu/dl/jmm/cookbook.html

As you can see, there no way to emit LoadLoad barrier between non-volatile y.read()  and version.read(), even if the latter is volatile. So we *must* insert volatile write into the read path, and it has to be before version.read() which must also be made into the volatile read. Making the first version.read() volatile also emits a necessary LoadLoad barrier, giving the following operations for reader:

Reader does (in PO): version.volatileRead(); {LoadLoad emited}; x.read(); y.read(); {LoadStore emited}; something.volatileWrite(); {StoreLoad emited} version.volatileRead();

This ensures an effective LoadLoad barrier (LoadStore + StoreLoad == LoadLoad) that is necessary between y.read() and version.read(). I will not go into details of writer side here. You can do it yourself as an exercise, using the above logic. You'll find that you must add some volatile read at the beginning of the writer path. 

Now, getting back to your original question: 

"We have contemplated a volatile write to an object that's local to the thread, in order to get the volatile write barrier semantics without writing to a contended location. Would that give sufficient barrier semantics?"

The answer is: it depends on how you look at it. Per JSR-133 cookbook yes, it will force the corresponding barriers to be emitted by JVM. However, it is not going to make your program correct per the Java Memory Model, because synchronizes-with relation  (and, in turn, happens-before relation) is induced per JMM only when there is a volatile read and volatile write on the same variable (see JLS 17.4.4). JVM does not have to use JSR-133 cookbook to ensure conformance with JMM as specified by JLS, but, as of now, HotSpot does indeed use JSR-133 cookbook and emits the corresponding barriers. If you base your code on JSR-133 cookbook, you make it implementation-dependent. Is it Ok or not Ok for you, is a separate question.

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tobias Lindaaker
Sent: Wednesday, April 23, 2014 7:01 PM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

If you use the single "version" field in the way you outlined, to serve two purposes, both a special "someone is writing" mark and as a version, then one field would suffice.
The two fields were just a different way of achieving the same guarantees without having a special marker value.

We have contemplated a volatile write to an object that's local to the thread, in order to get the volatile write barrier semantics without writing to a contended location. Would that give sufficient barrier semantics? As Oleksandr Otenko pointed out earlier, there might even be a problem with reordering of writes.

-tobias

On 23 Apr 2014, at 16:40 , Roman Elizarov <elizarov at devexperts.com> wrote:

> What was the reason, then, to use two control variables (written and next)? I don't see how it makes the algorithm "more correct", versus the one that uses just one "version" variable (write it before and after write and read before and after read). Without CAS or additional barriers (that are available in Java 8 only) both approaches are equally incorrect in theory, but both will should equally correct on x86 due to TSO, unless HotSpot does some crazy reordering. 
> 
> As a side note, I can prove that under JMM the read path of this algorithm must have at least one write (volatile write). You cannot make read path read-only under JMM (if you don't have explicit access to barriers). This prove yields a CAS-less construction of this algorithm, but I have not rigorously looked at it, since it is less intuitive and does not look to be not be giving a performance improvement over the CAS version. 
> 
> -----Original Message-----
> From: Tobias Lindaaker [mailto:thobes at gmail.com]
> Sent: Wednesday, April 23, 2014 6:29 PM
> To: Roman Elizarov
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Stricter read ordering
> 
> That is one of the approaches we have in our benchmark suite for this, and we also concluded that the CAS in read() would have a too substantial impact on the scalability of the algorithm.
> 
> -tobias
> 
> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com> wrote:
> 
>> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list. 
>> 
>> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>> 
>> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path. 
>> 
>> class VersionedData {
>>   // bit that we'll use to indicate that the state is being written to
>>   private static final int WRITE = 1 << 31;
>>   // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>>   private final AtomicInteger version = new AtomicInteger();
>> 
>>   // this is the data I protect, in reality there is much more protected state
>>   private int x, y;
>> 
>>   public synchronized void update(int x, int y) {
>>       // I guarantee single writers to this method,
>>       // illustrated with 'synchronized' in this simplification
>>       // first use CAS to mark version as being written to
>>       int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>>       version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>       // then write protected data (non-volatile writes)
>>       this.x = x;
>>       this.y = y;
>>       // then increment version and reset write bit
>>       version.set((v0 + 1) & ~WRITE);
>>   }
>> 
>>   public DataCarrier read() {
>>       // I allow multiple readers, so this method is not synchronized
>>       int x, y;
>>       int v0;
>>       do {
>>           // first read version
>>           v0 = version.get();
>>           if ((v0 & WRITE) != 0)
>>               continue; // immediately abort, because write in progress was detected
>>           // then read protected data
>>           x = this.x;
>>           y = this.y;
>>           // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>>       } while (!version.compareAndSet(v0, v0));
>>       return new DataCarrier(x, y);
>>   }
>> }
>> 
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of 
>> Aleksey Shipilev
>> Sent: Wednesday, April 23, 2014 5:36 PM
>> To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Stricter read ordering
>> 
>> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it 
>>> seems to do exactly what I want, and if I was fortunate enough to be 
>>> able to move to Java 8 I would use it. Unfortunately we are still 
>>> stuck on Java 7. We even have customers who are still strongly 
>>> requesting Java
>>> 6 compatibility.
>> 
>> These constraints make the problem unresolvable.
>> 
>> You might want to look for pre-JDK8 prototype for StampedLock [1]:
>> 
>>    * As noted in Boehm's paper (above), sequence validation (mainly
>>    * method validate()) requires stricter ordering rules than apply
>>    * to normal volatile reads (of "state").  In the absence of (but
>>    * continual hope for) explicit JVM support of intrinsics with
>>    * double-sided reordering prohibition, or corresponding fence
>>    * intrinsics, we for now uncomfortably rely on the fact that the
>>    * Unsafe.getXVolatile intrinsic must have this property
>>    * (syntactic volatile reads do not) for internal purposes anyway,
>>    * even though it is not documented.
>> 
>>   public boolean validate(long stamp) {
>>       return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>>   }
>> 
>> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>> 
>> Thanks,
>> -Aleksey.
>> 
>> [1]
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/Stamp
>> e
>> dLock.java?revision=1.1
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Wed Apr 23 12:08:38 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 23 Apr 2014 17:08:38 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <6B806B2E-A44C-4459-9D36-40669073DB13@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<6B806B2E-A44C-4459-9D36-40669073DB13@gmail.com>
Message-ID: <5357E586.2060701@oracle.com>

storeFence here can be replaced with a volatile load.

eg

this.next=next;
next=this.next;

will do. (plus the question of ordering normal loads in the middle of 
volatile loads)

Alex


On 23/04/2014 15:12, Tobias Lindaaker wrote:
> See comments below.
>
> On 23 Apr 2014, at 15:36 , Aleksey Shipilev 
> <aleksey.shipilev at oracle.com <mailto:aleksey.shipilev at oracle.com>> wrote:
>
>> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>>> to do exactly what I want, and if I was fortunate enough to be able
>>> to move to Java 8 I would use it. Unfortunately we are still stuck on
>>> Java 7. We even have customers who are still strongly requesting Java
>>> 6 compatibility.
>>
>> These constraints make the problem unresolvable.
>>
>> You might want to look for pre-JDK8 prototype for StampedLock [1]:
>>
>>     * As noted in Boehm's paper (above), sequence validation (mainly
>>     * method validate()) requires stricter ordering rules than apply
>>     * to normal volatile reads (of "state").  In the absence of (but
>>     * continual hope for) explicit JVM support of intrinsics with
>>     * double-sided reordering prohibition, or corresponding fence
>>     * intrinsics, we for now uncomfortably rely on the fact that the
>>     * Unsafe.getXVolatile intrinsic must have this property
>>     * (syntactic volatile reads do not) for internal purposes anyway,
>>     * even though it is not documented.
>>
>>    public boolean validate(long stamp) {
>>        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & 
>> SBITS);
>>    }
>>
>> But if Unsafe.loadFence() is risky since it is not specified (yet)
>> JMM-wise, and so interactions with other volatile ops and fences is just
>> undocumented... then using Unsafe.getXVolatile is double-risky because
>> the behavioral effect of read ordering is *REALLY*
>> implementation-specific, and you if are using it for read ordering, you
>> are five miles past the gateway to Hell already.
>>
>> Thanks,
>> -Aleksey.
>>
>> [1]
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>
> Thank you Aleksey,
>
> Those incidental implementation implications of 
> Unsafe.get*Volatile(...) is exactly what we were looking for.
> I agree that it is scary and sad to have to rely on these things (and 
> that even in Java 8, many things you need is hidden behind the 
> discouraging name of "sun.misc.Unsafe"), but it's the reality of 
> working on the JVM. Given how far we've already ventured beyond those 
> gates, five more miles will make virtually no difference...
>
> As a side note, if we could move to Java 8, it is possible that 
> StampedLock could completely fulfil this use case, and that we could 
> use that to simplify our code here. Although we would have to measure 
> the implications of the indirection that would add.
>
>
> On 23 Apr 2014, at 15:16 , Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>> Your code does lead to inconsistencies.
>>
>> A permitted reordering is:
>>
>> this.x=x; can go ahead of this.next=next;, which will lead to the 
>> reading thread observe written==next, yet x being updated, and not y.
>>
>> Alex
>>
>
> You are right Alex, there is of course that reordering problem as 
> well, and I would need similar fencing there too.
>
> I would think this would suffice in Java 8:
>
>       public synchronized void update( int x, int y ) {
>         long next = this.next + 1;
>         this.next = next;
>         Unsafe.storeFence(); // <- this being the added line
>         this.x = x;
>         this.y = y;
>         this.written = next;
>       }
>
>
> ... and is there some primitive with similar incidental implications 
> to what Aleksey pointed out for the load fence (but for store fencing 
> in this case) that could be used in earlier JDKs?
>
> Thank you both,
> Tobias
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/7ccbcf6d/attachment.html>

From boehm at acm.org  Wed Apr 23 13:26:28 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 23 Apr 2014 10:26:28 -0700
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <e4d0c30386e345169f61812ec3c3c2c2@DM2PR05MB349.namprd05.prod.outlook.com>
References: <CALD=eTMNyd5AQ7ReodWO5Gxs5c5NTTwJrsGz-6=fc5kkQuYsAg@mail.gmail.com>
	<1951e808e46748f18ec1c2e512beecf0@DM2PR05MB349.namprd05.prod.outlook.com>
	<73647052-A385-4F70-B733-A26F436761CE@gmail.com>
	<e4d0c30386e345169f61812ec3c3c2c2@DM2PR05MB349.namprd05.prod.outlook.com>
Message-ID: <CAPUmR1ZE0O+=iYOEhejy6i2F6H0C9vevzV-6+Lyq=QaVwmZBdA@mail.gmail.com>

The original code is essentially a reimplementation of Linux seqlocks.  The
memory ordering issues are discussed in my MSPC 2012 paper, which you can
find at http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .

(The C++ writer code in that paper, which should be uninteresting, and is
beside the point, has a bug.  Don't copy!)

Hans


On Wed, Apr 23, 2014 at 8:00 AM, Kaiser, Peter
<Peter.Kaiser at compuware.com>wrote:

>  Ok, I see. Do the reader threads apply any modifications to the state,
> so that they each need an individual copy of the state?
>
> As the state has to be copied anyway to keep the program correctly
> synchronized there would have to be some very good arguments to use
> advanced synchronization mechanisms for a problem like this.
>
> If the state could be provided as an immutable snapshot to the readers
> moving all the logic to the update method would seem to be a good solution
> to me. Also that way reads wouldn?t be able to cause any memory problems by
> creating too much instances of the state object. If it?s not possible to
> store the state in an immutable object, then would simply cloning it in the
> read method be a possibility for you? Of course you would have one more
> instance of the state object, but would that be a problem?
>
>
>
> Best Regards, Peter
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Tobias
> Lindaaker
> *Sent:* Mittwoch, 23. April 2014 16:22
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Stricter read ordering
>
>
>
> If the actual code was as simple as the simplified example that would be a
> good idea.
>
> But the actual state is in a ByteBuffer, making this approach impossible
> (or at least extremely inconvenient and impractical).
>
>
>
> synchronizing the read method would have too much of a performance impact
> since it would make readers block one another.
>
>
>
> -tobias
>
>
>
> On 23 Apr 2014, at 16:11 , Kaiser, Peter <Peter.Kaiser at compuware.com>
> wrote:
>
>
>
>   Hi!
>
>
>
> Why not trying something like the following:
>
>
>
> class VersionedData {
>
>   private volatile DataCarrier dataCarrier;
>
>
>
>  public void update( int x, int y ) {
>
>     dataCarrier = new DataCarrier(x, y);
>
>   }
>
>
>
>   public DataCarrier read() {
>
>     return new dataCarrier;
>
>   }
>
> }
>
>
>
> Also making the read-method synchronized would be an easier solution. Or
> would this affect performance too much?
>
>
>
> Best Regards, Peter
>
>
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
> ] *On Behalf Of *Tobias Lindaaker
> *Sent:* Donnerstag, 17. April 2014 09:37
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Stricter read ordering
>
>
>
> I'm sending this again, since it didn't end up anywhere the first time, I
> apologise if anyone gets this email twice.
>
>
>
> First some background, feel free to jump straight to the code below.
>
>
>
> I believe I have a sufficient understanding of read and write barriers,
> and the barrier implications of volatile in java. With this knowledge I was
> eyeing a piece of code I wrote some time ago, that has been working fine
> all along, and thinking to myself that in theory there is a possibility of
> inconsistent reads in that code, I've just never seen it actually happening.
>
>
>
> I've tried to read up on how I could change my code to make it guaranteed
> to be safe, but not found a good solution, in fact some sources seem to
> imply that my current implementation would be correct[1], but most confirm
> that my understanding of barriers is correct and that there is a potential
> inconsistency in my code.
>
>
>
> I thus thought I'd ask in the hopes that someone has greater insight than
> me and can provide me with a tweak to make my code correct, or assure me in
> some way that the current code would work.
>
>
>
> I'll present a simplified version of the code I have, and then describe
> the problem.
>
>
>
>  class VersionedData {
>
>   // this is the overhead I use to manage consistency
>
>   private final volatile long written;
>
>   private final volatile long next;
>
>
>
>   // this is the data I protect, in reality there is much more protected
> state
>
>   private int x, y;
>
>
>
>   public synchronized void update( int x, int y ) {
>
>     // I guarantee single writers to this method,
>
>     // illustrated with 'synchornized' in this simplification
>
>     long next = this.next + 1;
>
>     this.next = next;
>
>     this.x = x;
>
>     this.y = y;
>
>     this.written = next;
>
>   }
>
>
>
>   public DataCarrier read() {
>
>     // I allow multiple readers, so this method is not synchronized
>
>     int x, y;
>
>     long version;
>
>     do {
>
>       version = this.written;
>
>       x = this.x;
>
>       y = this.y;
>
>     } while ( version != this.next );
>
>     return new DataCarrier( x, y );
>
>   }
>
> }
>
>
>
> The strategy above works quite well in practice, since reads are much more
> common than writes, so the occasional retry on read is fine an does not
> cost a lot.
>
>
>
> According to my understanding of read barriers read instructions that are
> after the barrier in program order are guaranteed not to be moved to before
> the barrier, so the reading of the data cannot be moved to before the
> reading of this.written.
>
> However, as far as I understand, there are no guarantees that read
> instructions that are before a barrier in program order are not moved to
> after the barrier, meaning that the reading of the data could be moved to
> after the reading of this.next, introducing an opportunity for a writer to
> introduce inconsistent data without the reader detecting this.
>
>
>
> Is there any way I could introduce a fence that guarantees that the data
> reads will not be moved to after the read of this.next?
>
>
>
> Thank you,
>
> Tobias
>
>
>
> [1] Doug Lea's Fences API claims that the orderReads() method "Ensures
> that a read of the given reference prior to the invocation of this method
> occurs before a subsequent use of the given reference with the effect of
> reading or writing a field":
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>
>
>
> The contents of this e-mail are intended for the named addressee only. It
> contains information that may be confidential. Unless you are the named
> addressee or an authorized designee, you may not copy or use it, or
> disclose it to anyone else. If you received it in error please notify us
> immediately and then destroy it. Compuware Austria GmbH (registration
> number FN 91482h) is a company registered in Vienna whose registered office
> is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
>
>
>  The contents of this e-mail are intended for the named addressee only. It
> contains information that may be confidential. Unless you are the named
> addressee or an authorized designee, you may not copy or use it, or
> disclose it to anyone else. If you received it in error please notify us
> immediately and then destroy it. Compuware Austria GmbH (registration
> number FN 91482h) is a company registered in Vienna whose registered office
> is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/85419fa7/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Apr 23 13:36:59 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 23 Apr 2014 18:36:59 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
Message-ID: <5357FA3B.8050100@oracle.com>

In light of the recent discussion of the semantics of CAS, this solution 
is not correct.

The outcome of that discussion is that the atomicity of CAS is only 
guaranteed with respect to the variable being CASed. This does not 
matter on x86, but on ARM, as I understand, the CAS will be implemented 
as two instructions that only preclude concurrent stores to the variable 
being CASed - which does not preclude reordering the normal stores 
following CAS with the "volatile store" part of CAS.

So, here:

         version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
         // then write protected data (non-volatile writes)
         this.x = x;
         this.y = y;

this.x=x; may be observed before compareAndSet completes.

The correct solution should produce:

writer:
vwrite(v,v+1)
*vread(s,_)**
*write(x,_)
write(y,_)
vwrite(v,v+1)

reader:
vread(v,_)
read(x,_)
read(y,_)
*vwrite(s,_)**
*vread(v,_)

For example:

writer:
// synchronized
long next = this.version;
this.version=next+1; // odd version means mutation underway
long tmp=static_volatile_dummy;
this.x=x;
this.y=y;
this.version=next+2; // even version means immutable

reader:
long v;
do{
   while((v=this.version) &1 != 0); // wait for version to become even
   x=this.x;
   y=this.y;
   static_volatile_dummy=v;
}while(this.version != v); // check the version didn't change


Proof:

It is not necessary to consider all possible reorderings individually. 
It is sufficient to consider relative ordering of volatile reads and writes.

All writers ensure exclusive access to this.x and this.y, so we only 
need to consider one writer performing modifications in a loop.

If volatile read of static_volatile_dummy appears after a volatile write 
of static_volatile_dummy in synchronization order, the former 
synchronizes-with the latter, and the normal reads of this.x and this.y 
by the reader happen-before the normal writes of those variables by the 
writer (transitive closure of program orders). So, the readers never see 
normal writes of those writers.

Now consider the writers whose read of static_volatile_dummy does not 
synchronize-with the writes. The reader may temporarily observe some 
values, but will only terminate the loop after observing the values of 
this.x and this.y whose write appear before the volatile write of a even 
version: the first loop ensures we only look at writes preceding a write 
of a even version, the condition of the outer loop ensures no other 
volatile writes to version appear in synchronization order. This means 
that the first loop synchronizes-with the last write of a even version, 
hence, through transitive closure of program orders the normal writes of 
this.x and this.y happen-before the normal reads. The outer condition 
ensures that since no other volatile writes of version appear in 
synchronization order, the volatile read of static_volatile_dummy after 
all such writes will synchronize-with the volatile write of 
static_volatile_dummy of the reader (and their normal writes won't be 
observed, as per the proof in the previous paragraph).


This concludes the proof that the reader always observes the consistent 
view of this.x and this.y.



Alex


On 23/04/2014 15:16, Roman Elizarov wrote:
> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>
> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>
> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>
> class VersionedData {
>      // bit that we'll use to indicate that the state is being written to
>      private static final int WRITE = 1 << 31;
>      // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>      private final AtomicInteger version = new AtomicInteger();
>
>      // this is the data I protect, in reality there is much more protected state
>      private int x, y;
>
>      public synchronized void update(int x, int y) {
>          // I guarantee single writers to this method,
>          // illustrated with 'synchronized' in this simplification
>          // first use CAS to mark version as being written to
>          int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>          // then write protected data (non-volatile writes)
>          this.x = x;
>          this.y = y;
>          // then increment version and reset write bit
>          version.set((v0 + 1) & ~WRITE);
>      }
>
>      public DataCarrier read() {
>          // I allow multiple readers, so this method is not synchronized
>          int x, y;
>          int v0;
>          do {
>              // first read version
>              v0 = version.get();
>              if ((v0 & WRITE) != 0)
>                  continue; // immediately abort, because write in progress was detected
>              // then read protected data
>              x = this.x;
>              y = this.y;
>              // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>          } while (!version.compareAndSet(v0, v0));
>          return new DataCarrier(x, y);
>      }
> }
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
> Sent: Wednesday, April 23, 2014 5:36 PM
> To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Stricter read ordering
>
> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>> to do exactly what I want, and if I was fortunate enough to be able to
>> move to Java 8 I would use it. Unfortunately we are still stuck on
>> Java 7. We even have customers who are still strongly requesting Java
>> 6 compatibility.
> These constraints make the problem unresolvable.
>
> You might want to look for pre-JDK8 prototype for StampedLock [1]:
>
>       * As noted in Boehm's paper (above), sequence validation (mainly
>       * method validate()) requires stricter ordering rules than apply
>       * to normal volatile reads (of "state").  In the absence of (but
>       * continual hope for) explicit JVM support of intrinsics with
>       * double-sided reordering prohibition, or corresponding fence
>       * intrinsics, we for now uncomfortably rely on the fact that the
>       * Unsafe.getXVolatile intrinsic must have this property
>       * (syntactic volatile reads do not) for internal purposes anyway,
>       * even though it is not documented.
>
>      public boolean validate(long stamp) {
>          return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>      }
>
> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>
> Thanks,
> -Aleksey.
>
> [1]
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/23e27b39/attachment.html>

From elizarov at devexperts.com  Wed Apr 23 14:34:39 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Wed, 23 Apr 2014 18:34:39 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357FA3B.8050100@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>
Message-ID: <81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>

There was no light in that discussion. CAS is currently spec'd as volatile load and volatile store.  Period. If someone implements CAS on ARM with weaker guarantees that violate this spec, then StampedLock in Java 8 solution also becomes broken for the same reason you've outlined below.

On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko" <oleksandr.otenko at oracle.com<mailto:oleksandr.otenko at oracle.com>> wrote:

In light of the recent discussion of the semantics of CAS, this solution is not correct.

The outcome of that discussion is that the atomicity of CAS is only guaranteed with respect to the variable being CASed. This does not matter on x86, but on ARM, as I understand, the CAS will be implemented as two instructions that only preclude concurrent stores to the variable being CASed - which does not preclude reordering the normal stores following CAS with the "volatile store" part of CAS.

So, here:


        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
        // then write protected data (non-volatile writes)
        this.x = x;
        this.y = y;

this.x=x; may be observed before compareAndSet completes.

The correct solution should produce:

writer:
vwrite(v,v+1)
vread(s,_)
write(x,_)
write(y,_)
vwrite(v,v+1)

reader:
vread(v,_)
read(x,_)
read(y,_)
vwrite(s,_)
vread(v,_)

For example:

writer:
// synchronized
long next = this.version;
this.version=next+1; // odd version means mutation underway
long tmp=static_volatile_dummy;
this.x=x;
this.y=y;
this.version=next+2; // even version means immutable

reader:
long v;
do{
  while((v=this.version) &1 != 0); // wait for version to become even
  x=this.x;
  y=this.y;
  static_volatile_dummy=v;
}while(this.version != v); // check the version didn't change


Proof:

It is not necessary to consider all possible reorderings individually. It is sufficient to consider relative ordering of volatile reads and writes.

All writers ensure exclusive access to this.x and this.y, so we only need to consider one writer performing modifications in a loop.

If volatile read of static_volatile_dummy appears after a volatile write of static_volatile_dummy in synchronization order, the former synchronizes-with the latter, and the normal reads of this.x and this.y by the reader happen-before the normal writes of those variables by the writer (transitive closure of program orders). So, the readers never see normal writes of those writers.

Now consider the writers whose read of static_volatile_dummy does not synchronize-with the writes. The reader may temporarily observe some values, but will only terminate the loop after observing the values of this.x and this.y whose write appear before the volatile write of a even version: the first loop ensures we only look at writes preceding a write of a even version, the condition of the outer loop ensures no other volatile writes to version appear in synchronization order. This means that the first loop synchronizes-with the last write of a even version, hence, through transitive closure of program orders the normal writes of this.x and this.y happen-before the normal reads. The outer condition ensures that since no other volatile writes of version appear in synchronization order, the volatile read of static_volatile_dummy after all such writes will synchronize-with the volatile write of static_volatile_dummy of the reader (and their normal writes won't be observed, as per the proof in the previous paragraph).


This concludes the proof that the reader always observes the consistent view of this.x and this.y.



Alex


On 23/04/2014 15:16, Roman Elizarov wrote:

The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.

Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.

So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.

class VersionedData {
    // bit that we'll use to indicate that the state is being written to
    private static final int WRITE = 1 << 31;
    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
    private final AtomicInteger version = new AtomicInteger();

    // this is the data I protect, in reality there is much more protected state
    private int x, y;

    public synchronized void update(int x, int y) {
        // I guarantee single writers to this method,
        // illustrated with 'synchronized' in this simplification
        // first use CAS to mark version as being written to
        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
        // then write protected data (non-volatile writes)
        this.x = x;
        this.y = y;
        // then increment version and reset write bit
        version.set((v0 + 1) & ~WRITE);
    }

    public DataCarrier read() {
        // I allow multiple readers, so this method is not synchronized
        int x, y;
        int v0;
        do {
            // first read version
            v0 = version.get();
            if ((v0 & WRITE) != 0)
                continue; // immediately abort, because write in progress was detected
            // then read protected data
            x = this.x;
            y = this.y;
            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
        } while (!version.compareAndSet(v0, v0));
        return new DataCarrier(x, y);
    }
}

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
Sent: Wednesday, April 23, 2014 5:36 PM
To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Stricter read ordering

On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:


Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
to do exactly what I want, and if I was fortunate enough to be able to
move to Java 8 I would use it. Unfortunately we are still stuck on
Java 7. We even have customers who are still strongly requesting Java
6 compatibility.


These constraints make the problem unresolvable.

You might want to look for pre-JDK8 prototype for StampedLock [1]:

     * As noted in Boehm's paper (above), sequence validation (mainly
     * method validate()) requires stricter ordering rules than apply
     * to normal volatile reads (of "state").  In the absence of (but
     * continual hope for) explicit JVM support of intrinsics with
     * double-sided reordering prohibition, or corresponding fence
     * intrinsics, we for now uncomfortably rely on the fact that the
     * Unsafe.getXVolatile intrinsic must have this property
     * (syntactic volatile reads do not) for internal purposes anyway,
     * even though it is not documented.

    public boolean validate(long stamp) {
        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
    }

But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.

Thanks,
-Aleksey.

[1]
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/4e1d7e9a/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Apr 23 15:12:00 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 23 Apr 2014 20:12:00 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>
	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
Message-ID: <53581080.3010008@oracle.com>

No. If CAS is implemented as a volatile load followed by a volatile 
store, the effect I describe is possible. There is no need for a weaker 
implementation for CAS.

Watch:

replace version.compareAndSet with get and set:

v0=version.get();
version.set(v0 | WRITE);
this.x=x; // normal write can go ahead of the volatile write, as per the 
cookbook

Or, in JMM terms, there is no edge enforcing this.x=x by the writer to 
appear strictly after x=this.x by the reader.

Alex

On 23/04/2014 19:34, Roman Elizarov wrote:
> There was no light in that discussion. CAS is currently spec'd as 
> volatile load and volatile store.  Period. If someone implements CAS 
> on ARM with weaker guarantees that violate this spec, then StampedLock 
> in Java 8 solution also becomes broken for the same reason you've 
> outlined below.
>
> On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>> In light of the recent discussion of the semantics of CAS, this 
>> solution is not correct.
>>
>> The outcome of that discussion is that the atomicity of CAS is only 
>> guaranteed with respect to the variable being CASed. This does not 
>> matter on x86, but on ARM, as I understand, the CAS will be 
>> implemented as two instructions that only preclude concurrent stores 
>> to the variable being CASed - which does not preclude reordering the 
>> normal stores following CAS with the "volatile store" part of CAS.
>>
>> So, here:
>>
>>          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>          // then write protected data (non-volatile writes)
>>          this.x = x;
>>          this.y = y;
>> this.x=x; may be observed before compareAndSet completes.
>>
>> The correct solution should produce:
>>
>> writer:
>> vwrite(v,v+1)
>> *vread(s,_)**
>> *write(x,_)
>> write(y,_)
>> vwrite(v,v+1)
>>
>> reader:
>> vread(v,_)
>> read(x,_)
>> read(y,_)
>> *vwrite(s,_)**
>> *vread(v,_)
>>
>> For example:
>>
>> writer:
>> // synchronized
>> long next = this.version;
>> this.version=next+1; // odd version means mutation underway
>> long tmp=static_volatile_dummy;
>> this.x=x;
>> this.y=y;
>> this.version=next+2; // even version means immutable
>>
>> reader:
>> long v;
>> do{
>>   while((v=this.version) &1 != 0); // wait for version to become even
>>   x=this.x;
>>   y=this.y;
>>   static_volatile_dummy=v;
>> }while(this.version != v); // check the version didn't change
>>
>>
>> Proof:
>>
>> It is not necessary to consider all possible reorderings 
>> individually. It is sufficient to consider relative ordering of 
>> volatile reads and writes.
>>
>> All writers ensure exclusive access to this.x and this.y, so we only 
>> need to consider one writer performing modifications in a loop.
>>
>> If volatile read of static_volatile_dummy appears after a volatile 
>> write of static_volatile_dummy in synchronization order, the former 
>> synchronizes-with the latter, and the normal reads of this.x and 
>> this.y by the reader happen-before the normal writes of those 
>> variables by the writer (transitive closure of program orders). So, 
>> the readers never see normal writes of those writers.
>>
>> Now consider the writers whose read of static_volatile_dummy does not 
>> synchronize-with the writes. The reader may temporarily observe some 
>> values, but will only terminate the loop after observing the values 
>> of this.x and this.y whose write appear before the volatile write of 
>> a even version: the first loop ensures we only look at writes 
>> preceding a write of a even version, the condition of the outer loop 
>> ensures no other volatile writes to version appear in synchronization 
>> order. This means that the first loop synchronizes-with the last 
>> write of a even version, hence, through transitive closure of program 
>> orders the normal writes of this.x and this.y happen-before the 
>> normal reads. The outer condition ensures that since no other 
>> volatile writes of version appear in synchronization order, the 
>> volatile read of static_volatile_dummy after all such writes will 
>> synchronize-with the volatile write of static_volatile_dummy of the 
>> reader (and their normal writes won't be observed, as per the proof 
>> in the previous paragraph).
>>
>>
>> This concludes the proof that the reader always observes the 
>> consistent view of this.x and this.y.
>>
>>
>>
>> Alex
>>
>>
>> On 23/04/2014 15:16, Roman Elizarov wrote:
>>> The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>>>
>>> Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>>>
>>> So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>>>
>>> class VersionedData {
>>>      // bit that we'll use to indicate that the state is being written to
>>>      private static final int WRITE = 1 << 31;
>>>      // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>>>      private final AtomicInteger version = new AtomicInteger();
>>>
>>>      // this is the data I protect, in reality there is much more protected state
>>>      private int x, y;
>>>
>>>      public synchronized void update(int x, int y) {
>>>          // I guarantee single writers to this method,
>>>          // illustrated with 'synchronized' in this simplification
>>>          // first use CAS to mark version as being written to
>>>          int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>>>          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>>          // then write protected data (non-volatile writes)
>>>          this.x = x;
>>>          this.y = y;
>>>          // then increment version and reset write bit
>>>          version.set((v0 + 1) & ~WRITE);
>>>      }
>>>
>>>      public DataCarrier read() {
>>>          // I allow multiple readers, so this method is not synchronized
>>>          int x, y;
>>>          int v0;
>>>          do {
>>>              // first read version
>>>              v0 = version.get();
>>>              if ((v0 & WRITE) != 0)
>>>                  continue; // immediately abort, because write in progress was detected
>>>              // then read protected data
>>>              x = this.x;
>>>              y = this.y;
>>>              // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>>>          } while (!version.compareAndSet(v0, v0));
>>>          return new DataCarrier(x, y);
>>>      }
>>> }
>>>
>>> -----Original Message-----
>>> From:concurrency-interest-bounces at cs.oswego.edu  [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>>> Sent: Wednesday, April 23, 2014 5:36 PM
>>> To: Tobias Lindaaker;concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] Stricter read ordering
>>>
>>> On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>>>> Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>>>> to do exactly what I want, and if I was fortunate enough to be able to
>>>> move to Java 8 I would use it. Unfortunately we are still stuck on
>>>> Java 7. We even have customers who are still strongly requesting Java
>>>> 6 compatibility.
>>> These constraints make the problem unresolvable.
>>>
>>> You might want to look for pre-JDK8 prototype for StampedLock [1]:
>>>
>>>       * As noted in Boehm's paper (above), sequence validation (mainly
>>>       * method validate()) requires stricter ordering rules than apply
>>>       * to normal volatile reads (of "state").  In the absence of (but
>>>       * continual hope for) explicit JVM support of intrinsics with
>>>       * double-sided reordering prohibition, or corresponding fence
>>>       * intrinsics, we for now uncomfortably rely on the fact that the
>>>       * Unsafe.getXVolatile intrinsic must have this property
>>>       * (syntactic volatile reads do not) for internal purposes anyway,
>>>       * even though it is not documented.
>>>
>>>      public boolean validate(long stamp) {
>>>          return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>>>      }
>>>
>>> But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>>>
>>> Thanks,
>>> -Aleksey.
>>>
>>> [1]
>>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/eb442e66/attachment.html>

From elizarov at devexperts.com  Wed Apr 23 15:57:33 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Wed, 23 Apr 2014 19:57:33 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <53581080.3010008@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>
	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
	<53581080.3010008@oracle.com>
Message-ID: <f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>

You are right. You cannot just split CAS into load and store this way. Actually, if you analyze required barriers for write path in the same way as I did for read path (remember, that writer has to have StoreStore barrier before version write and subsequent non-volatile writes), you see that you need to insert volatile read _after_ the version.write() in the write path, so it becomes:

Writer does (in PO): version.volatileWrite();  {StoreLoad emitted}; something.volatileRead(); {LoadStore emitted} x.write(); y.write(); {StoreStore emitted}; version.write();

This effectively gives you StoreStore barrier between version write and a first non-volatile write of protected data state. Ordering those two volatile operations at the beginning of write path the other way around, as in your example below, does not provide the necessary barrier to guarantee correctness of this idiom.

CAS has to do both volatile load and store in atomic and indivisible way, so that you cannot reorder subsequent normal write into the "middle of" CAS. This is not explicitly stated in the CAS spec as I can see (the wording about "atomic" behavior of CAS and about its load/store semantics are rather far apart, so it is debatable), but this is the property of CAS that Java 8's implementation of StampedLock relies upon, too.

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Wednesday, April 23, 2014 11:12 PM
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

No. If CAS is implemented as a volatile load followed by a volatile store, the effect I describe is possible. There is no need for a weaker implementation for CAS.

Watch:

replace version.compareAndSet with get and set:

v0=version.get();
version.set(v0 | WRITE);
this.x=x; // normal write can go ahead of the volatile write, as per the cookbook

Or, in JMM terms, there is no edge enforcing this.x=x by the writer to appear strictly after x=this.x by the reader.

Alex
On 23/04/2014 19:34, Roman Elizarov wrote:
There was no light in that discussion. CAS is currently spec'd as volatile load and volatile store.  Period. If someone implements CAS on ARM with weaker guarantees that violate this spec, then StampedLock in Java 8 solution also becomes broken for the same reason you've outlined below.

On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko" <oleksandr.otenko at oracle.com<mailto:oleksandr.otenko at oracle.com>> wrote:
In light of the recent discussion of the semantics of CAS, this solution is not correct.

The outcome of that discussion is that the atomicity of CAS is only guaranteed with respect to the variable being CASed. This does not matter on x86, but on ARM, as I understand, the CAS will be implemented as two instructions that only preclude concurrent stores to the variable being CASed - which does not preclude reordering the normal stores following CAS with the "volatile store" part of CAS.

So, here:



        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;
this.x=x; may be observed before compareAndSet completes.

The correct solution should produce:

writer:
vwrite(v,v+1)
vread(s,_)
write(x,_)
write(y,_)
vwrite(v,v+1)

reader:
vread(v,_)
read(x,_)
read(y,_)
vwrite(s,_)
vread(v,_)

For example:

writer:
// synchronized
long next = this.version;
this.version=next+1; // odd version means mutation underway
long tmp=static_volatile_dummy;
this.x=x;
this.y=y;
this.version=next+2; // even version means immutable

reader:
long v;
do{
  while((v=this.version) &1 != 0); // wait for version to become even
  x=this.x;
  y=this.y;
  static_volatile_dummy=v;
}while(this.version != v); // check the version didn't change


Proof:

It is not necessary to consider all possible reorderings individually. It is sufficient to consider relative ordering of volatile reads and writes.

All writers ensure exclusive access to this.x and this.y, so we only need to consider one writer performing modifications in a loop.

If volatile read of static_volatile_dummy appears after a volatile write of static_volatile_dummy in synchronization order, the former synchronizes-with the latter, and the normal reads of this.x and this.y by the reader happen-before the normal writes of those variables by the writer (transitive closure of program orders). So, the readers never see normal writes of those writers.

Now consider the writers whose read of static_volatile_dummy does not synchronize-with the writes. The reader may temporarily observe some values, but will only terminate the loop after observing the values of this.x and this.y whose write appear before the volatile write of a even version: the first loop ensures we only look at writes preceding a write of a even version, the condition of the outer loop ensures no other volatile writes to version appear in synchronization order. This means that the first loop synchronizes-with the last write of a even version, hence, through transitive closure of program orders the normal writes of this.x and this.y happen-before the normal reads. The outer condition ensures that since no other volatile writes of version appear in synchronization order, the volatile read of static_volatile_dummy after all such writes will synchronize-with the volatile write of static_volatile_dummy of the reader (and their normal writes won't be observed, as per the proof in the previous paragraph).


This concludes the proof that the reader always observes the consistent view of this.x and this.y.



Alex

On 23/04/2014 15:16, Roman Elizarov wrote:

The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.



Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.



So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.



class VersionedData {

    // bit that we'll use to indicate that the state is being written to

    private static final int WRITE = 1 << 31;

    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)

    private final AtomicInteger version = new AtomicInteger();



    // this is the data I protect, in reality there is much more protected state

    private int x, y;



    public synchronized void update(int x, int y) {

        // I guarantee single writers to this method,

        // illustrated with 'synchronized' in this simplification

        // first use CAS to mark version as being written to

        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry

        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;

        // then increment version and reset write bit

        version.set((v0 + 1) & ~WRITE);

    }



    public DataCarrier read() {

        // I allow multiple readers, so this method is not synchronized

        int x, y;

        int v0;

        do {

            // first read version

            v0 = version.get();

            if ((v0 & WRITE) != 0)

                continue; // immediately abort, because write in progress was detected

            // then read protected data

            x = this.x;

            y = this.y;

            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time

        } while (!version.compareAndSet(v0, v0));

        return new DataCarrier(x, y);

    }

}



-----Original Message-----

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev

Sent: Wednesday, April 23, 2014 5:36 PM

To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>

Subject: Re: [concurrency-interest] Stricter read ordering



On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:

Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems

to do exactly what I want, and if I was fortunate enough to be able to

move to Java 8 I would use it. Unfortunately we are still stuck on

Java 7. We even have customers who are still strongly requesting Java

6 compatibility.

These constraints make the problem unresolvable.



You might want to look for pre-JDK8 prototype for StampedLock [1]:



     * As noted in Boehm's paper (above), sequence validation (mainly

     * method validate()) requires stricter ordering rules than apply

     * to normal volatile reads (of "state").  In the absence of (but

     * continual hope for) explicit JVM support of intrinsics with

     * double-sided reordering prohibition, or corresponding fence

     * intrinsics, we for now uncomfortably rely on the fact that the

     * Unsafe.getXVolatile intrinsic must have this property

     * (syntactic volatile reads do not) for internal purposes anyway,

     * even though it is not documented.



    public boolean validate(long stamp) {

        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);

    }



But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.



Thanks,

-Aleksey.



[1]

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/3b087cbc/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Apr 23 17:19:51 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 23 Apr 2014 22:19:51 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
	<53581080.3010008@oracle.com>
	<f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
Message-ID: <53582E77.1060601@oracle.com>

Can you quote the exact spot? I see it is quite different from your 
suggestion, and where I look it doesn't seem atomicity of CAS matters.


Alex


On 23/04/2014 20:57, Roman Elizarov wrote:
>
> You are right. You cannot just split CAS into load and store this way. 
> Actually, if you analyze required barriers for write path in the same 
> way as I did for read path (remember, that writer has to have 
> StoreStore barrier before version write and subsequent non-volatile 
> writes), you see that you need to insert volatile read _/after/_ the 
> version.write() in the write path, so it becomes:
>
> Writer does (in PO): version.volatileWrite(); {StoreLoad emitted}; 
> something.volatileRead(); {LoadStore emitted} x.write(); y.write(); 
> {StoreStore emitted}; version.write();
>
> This effectively gives you StoreStore barrier between version write 
> and a first non-volatile write of protected data state. Ordering those 
> two volatile operations at the beginning of write path the other way 
> around, as in your example below, does not provide the necessary 
> barrier to guarantee correctness of this idiom.
>
> CAS has to do both volatile load and store in atomic and indivisible 
> way, so that you cannot reorder subsequent normal write into the 
> "middle of" CAS. This is not explicitly stated in the CAS spec as I 
> can see (the wording about "atomic" behavior of CAS and about its 
> load/store semantics are rather far apart, so it is debatable), but 
> this is the property of CAS that Java 8's implementation of 
> StampedLock relies upon, too.
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *Oleksandr Otenko
> *Sent:* Wednesday, April 23, 2014 11:12 PM
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Stricter read ordering
>
> No. If CAS is implemented as a volatile load followed by a volatile 
> store, the effect I describe is possible. There is no need for a 
> weaker implementation for CAS.
>
> Watch:
>
> replace version.compareAndSet with get and set:
>
> v0=version.get();
> version.set(v0 | WRITE);
> this.x=x; // normal write can go ahead of the volatile write, as per 
> the cookbook
>
> Or, in JMM terms, there is no edge enforcing this.x=x by the writer to 
> appear strictly after x=this.x by the reader.
>
> Alex
>
> On 23/04/2014 19:34, Roman Elizarov wrote:
>
>     There was no light in that discussion. CAS is currently spec'd as
>     volatile load and volatile store.  Period. If someone implements
>     CAS on ARM with weaker guarantees that violate this spec, then
>     StampedLock in Java 8 solution also becomes broken for the same
>     reason you've outlined below.
>
>
>     On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko"
>     <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>>
>     wrote:
>
>         In light of the recent discussion of the semantics of CAS,
>         this solution is not correct.
>
>         The outcome of that discussion is that the atomicity of CAS is
>         only guaranteed with respect to the variable being CASed. This
>         does not matter on x86, but on ARM, as I understand, the CAS
>         will be implemented as two instructions that only preclude
>         concurrent stores to the variable being CASed - which does not
>         preclude reordering the normal stores following CAS with the
>         "volatile store" part of CAS.
>
>         So, here:
>
>
>                  version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                  // then write protected data (non-volatile writes)
>
>                  this.x = x;
>
>                  this.y = y;
>
>         this.x=x; may be observed before compareAndSet completes.
>
>         The correct solution should produce:
>
>         writer:
>         vwrite(v,v+1)
>         *vread(s,_)
>         *write(x,_)
>         write(y,_)
>         vwrite(v,v+1)
>
>         reader:
>         vread(v,_)
>         read(x,_)
>         read(y,_)
>         *vwrite(s,_)
>         *vread(v,_)
>
>         For example:
>
>         writer:
>         // synchronized
>         long next = this.version;
>         this.version=next+1; // odd version means mutation underway
>         long tmp=static_volatile_dummy;
>         this.x=x;
>         this.y=y;
>         this.version=next+2; // even version means immutable
>
>         reader:
>         long v;
>         do{
>           while((v=this.version) &1 != 0); // wait for version to
>         become even
>           x=this.x;
>           y=this.y;
>           static_volatile_dummy=v;
>         }while(this.version != v); // check the version didn't change
>
>
>         Proof:
>
>         It is not necessary to consider all possible reorderings
>         individually. It is sufficient to consider relative ordering
>         of volatile reads and writes.
>
>         All writers ensure exclusive access to this.x and this.y, so
>         we only need to consider one writer performing modifications
>         in a loop.
>
>         If volatile read of static_volatile_dummy appears after a
>         volatile write of static_volatile_dummy in synchronization
>         order, the former synchronizes-with the latter, and the normal
>         reads of this.x and this.y by the reader happen-before the
>         normal writes of those variables by the writer (transitive
>         closure of program orders). So, the readers never see normal
>         writes of those writers.
>
>         Now consider the writers whose read of static_volatile_dummy
>         does not synchronize-with the writes. The reader may
>         temporarily observe some values, but will only terminate the
>         loop after observing the values of this.x and this.y whose
>         write appear before the volatile write of a even version: the
>         first loop ensures we only look at writes preceding a write of
>         a even version, the condition of the outer loop ensures no
>         other volatile writes to version appear in synchronization
>         order. This means that the first loop synchronizes-with the
>         last write of a even version, hence, through transitive
>         closure of program orders the normal writes of this.x and
>         this.y happen-before the normal reads. The outer condition
>         ensures that since no other volatile writes of version appear
>         in synchronization order, the volatile read of
>         static_volatile_dummy after all such writes will
>         synchronize-with the volatile write of static_volatile_dummy
>         of the reader (and their normal writes won't be observed, as
>         per the proof in the previous paragraph).
>
>
>         This concludes the proof that the reader always observes the
>         consistent view of this.x and this.y.
>
>
>
>         Alex
>
>         On 23/04/2014 15:16, Roman Elizarov wrote:
>
>             The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>
>               
>
>             Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>
>               
>
>             So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>
>               
>
>             class VersionedData {
>
>                  // bit that we'll use to indicate that the state is being written to
>
>                  private static final int WRITE = 1 << 31;
>
>                  // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>
>                  private final AtomicInteger version = new AtomicInteger();
>
>               
>
>                  // this is the data I protect, in reality there is much more protected state
>
>                  private int x, y;
>
>               
>
>                  public synchronized void update(int x, int y) {
>
>                      // I guarantee single writers to this method,
>
>                      // illustrated with 'synchronized' in this simplification
>
>                      // first use CAS to mark version as being written to
>
>                      int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>
>                      version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                      // then write protected data (non-volatile writes)
>
>                      this.x = x;
>
>                      this.y = y;
>
>                      // then increment version and reset write bit
>
>                      version.set((v0 + 1) & ~WRITE);
>
>                  }
>
>               
>
>                  public DataCarrier read() {
>
>                      // I allow multiple readers, so this method is not synchronized
>
>                      int x, y;
>
>                      int v0;
>
>                      do {
>
>                          // first read version
>
>                          v0 = version.get();
>
>                          if ((v0 & WRITE) != 0)
>
>                              continue; // immediately abort, because write in progress was detected
>
>                          // then read protected data
>
>                          x = this.x;
>
>                          y = this.y;
>
>                          // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>
>                      } while (!version.compareAndSet(v0, v0));
>
>                      return new DataCarrier(x, y);
>
>                  }
>
>             }
>
>               
>
>             -----Original Message-----
>
>             From:concurrency-interest-bounces at cs.oswego.edu  <mailto:concurrency-interest-bounces at cs.oswego.edu>  [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>
>             Sent: Wednesday, April 23, 2014 5:36 PM
>
>             To: Tobias Lindaaker;concurrency-interest at cs.oswego.edu  <mailto:concurrency-interest at cs.oswego.edu>
>
>             Subject: Re: [concurrency-interest] Stricter read ordering
>
>               
>
>             On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>
>                 Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>
>                 to do exactly what I want, and if I was fortunate enough to be able to
>
>                 move to Java 8 I would use it. Unfortunately we are still stuck on
>
>                 Java 7. We even have customers who are still strongly requesting Java
>
>                 6 compatibility.
>
>             These constraints make the problem unresolvable.
>
>               
>
>             You might want to look for pre-JDK8 prototype for StampedLock [1]:
>
>               
>
>                   * As noted in Boehm's paper (above), sequence validation (mainly
>
>                   * method validate()) requires stricter ordering rules than apply
>
>                   * to normal volatile reads (of "state").  In the absence of (but
>
>                   * continual hope for) explicit JVM support of intrinsics with
>
>                   * double-sided reordering prohibition, or corresponding fence
>
>                   * intrinsics, we for now uncomfortably rely on the fact that the
>
>                   * Unsafe.getXVolatile intrinsic must have this property
>
>                   * (syntactic volatile reads do not) for internal purposes anyway,
>
>                   * even though it is not documented.
>
>               
>
>                  public boolean validate(long stamp) {
>
>                      return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>
>                  }
>
>               
>
>             But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>
>               
>
>             Thanks,
>
>             -Aleksey.
>
>               
>
>             [1]
>
>             http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>
>             _______________________________________________
>
>             Concurrency-interest mailing list
>
>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>               
>
>             _______________________________________________
>
>             Concurrency-interest mailing list
>
>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/93d74a3e/attachment-0001.html>

From peter.levart at gmail.com  Wed Apr 23 17:25:42 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 23 Apr 2014 23:25:42 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
Message-ID: <53582FD6.3090504@gmail.com>

Hi Tobias,

I you don't mind keeping 2 mirrored variants of your state (two mirrored 
memory mapped files in your case, or one file with duplicate/striped 
records) and applying all modifications to both copies, then the 
following might interest you:

http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf


Regards, Peter

On 04/23/2014 05:28 PM, Tobias Lindaaker wrote:
> Yes, exactly, writes tend to get more expensive, so avoiding them for 
> the read case is desired.
>
> As I wrote in my reply to Peter Kaiser, the actual state that is 
> guarded is a ByteBuffer.
> This ByteBuffer contains multiple records, and readers read one record 
> and need that to be consistent, while writers typically update 
> multiple records at once.
>
> And to answer Peters most recent question:
>
>
>     On 23 Apr 2014, at 17:00 , Kaiser, Peter
>     <Peter.Kaiser at compuware.com <mailto:Peter.Kaiser at compuware.com>>
>     wrote:
>>     Ok, I see. Do the reader threads apply any modifications to the
>>     state, so that they each need an individual copy of the state?
>>     As the state has to be copied anyway to keep the program
>>     correctly synchronized there would have to be some very good
>>     arguments to use advanced synchronization mechanisms for a
>>     problem like this.
>>     If the state could be provided as an immutable snapshot to the
>>     readers moving all the logic to the update method would seem to
>>     be a good solution to me. Also that way reads wouldn't be able to
>>     cause any memory problems by creating too much instances of the
>>     state object. If it's not possible to store the state in an
>>     immutable object, then would simply cloning it in the read method
>>     be a possibility for you? Of course you would have one more
>>     instance of the state object, but would that be a problem?
>
>
> The reader threads do not apply any modifications to the state, they 
> do computation based on the state, which might later result in writes 
> back.
>
> Perhaps I shouldn't have simplified the code so much, but rather kept 
> it closer to what it actually is, here is another version, where the 
> state is closer to what it is in our actual application, but the data 
> stored in it is still simplified:
>
>     class VersionedData {
>       // this is the overhead I use to manage consistency
>       private final volatile long written;
>       private final volatile long next;
>
>       // the protected data, this typically a memory mapped file
>       private final ByteBuffer buffer;
>       VersionedData( ByteBuffer buffer ) { this.buffer = buffer; }
>       public synchronized void update( Iterable<DataCarrier> data ) {
>         long next = this.next + 1;
>         this.next = next;
>         for (DataCarrier cursor : data) {
>           int offset = data.offset * 8;
>           buffer.putInt( offset    , data.x );
>           buffer.putInt( offset + 4, data.y );
>         }
>         this.written = next;
>       }
>
>       public void read(DataCarrier cursor) {
>         // I allow multiple readers, so this method is not synchronized
>         int x, y, offset = cursor.offset * 8;
>         long version;
>         do {
>           version = this.written;
>           x = buffer.getInt(offset);
>           y = buffer.getInt(offset + 4);
>         } while ( version != this.next );
>         cursor.x = x;
>         cursor.y = y;
>       }
>     }
>
>
> Reading snapshots from different versions does not matter, but x and y 
> have to be consistent with one another.
>
> Readers typically instantiate one DataCarrier and do multiple reads 
> using the same instance, changing the offset of it in between, this to 
> avoid creating too many objects since neither escape analysis nor 
> garbage collection is as good as anyone would want it to be. Again 
> this being the sad truth about coding for the JVM, the happy truth of 
> course being that many many other things are absolutely amazing.
>
> -tobias
>
> On 23 Apr 2014, at 16:58 , Aleksey Shipilev 
> <aleksey.shipilev at oracle.com <mailto:aleksey.shipilev at oracle.com>> wrote:
>
>> +1. Dragging us back to StampedLock example, the rationale for doing
>> ordered reads is to avoid writes on the read path.
>>
>> Barring the locks (scalability hit), volatile writes / releasing stores
>> (still a potential scalability hit), or putting (x, y) into a wrapper
>> instance (cache misses, yay!), the only thing you are left with is
>> ordering the reads with fences.
>>
>> If reads greatly out-weight writes, plus the data is encapsulateable
>> into the single instance, plus one possible cache miss is not an issue,
>> I would prefer to have the actual wrapper instance, though. I think
>> that's Peter Kaiser's point, although OP's example is greatly
>> simplified, and OP's non-simplified case may invalidate any of these
>> prerequisites.
>>
>> -Aleksey.
>>
>> On 04/23/2014 06:29 PM, Tobias Lindaaker wrote:
>>> That is one of the approaches we have in our benchmark suite for
>>> this, and we also concluded that the CAS in read() would have a too
>>> substantial impact on the scalability of the algorithm.
>>>
>>> -tobias
>>>
>>> On 23 Apr 2014, at 16:16 , Roman Elizarov <elizarov at devexperts.com 
>>> <mailto:elizarov at devexperts.com>>
>>> wrote:
>>>> It will not scale, though, if there are many concurrent readers,
>>>> because of the CAS in read path.
>>>>
>>>> -Roman
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140423/fa596644/attachment.html>

From davidcholmes at aapt.net.au  Wed Apr 23 19:15:29 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 24 Apr 2014 09:15:29 +1000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEOHKFAA.davidcholmes@aapt.net.au>

The discussion of CAS being like a "volatile load plus volatile store" did
expose that that description is inadequate to fully convey the required
ordering constraints. The actual implementations in the Oracle JDK do not
allow external accesses to leak into the atomic region.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Roman
Elizarov
  Sent: Thursday, 24 April 2014 5:58 AM
  To: Oleksandr Otenko
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Stricter read ordering


  You are right. You cannot just split CAS into load and store this way.
Actually, if you analyze required barriers for write path in the same way as
I did for read path (remember, that writer has to have StoreStore barrier
before version write and subsequent non-volatile writes), you see that you
need to insert volatile read _after_ the version.write() in the write path,
so it becomes:



  Writer does (in PO): version.volatileWrite();  {StoreLoad emitted};
something.volatileRead(); {LoadStore emitted} x.write(); y.write();
{StoreStore emitted}; version.write();



  This effectively gives you StoreStore barrier between version write and a
first non-volatile write of protected data state. Ordering those two
volatile operations at the beginning of write path the other way around, as
in your example below, does not provide the necessary barrier to guarantee
correctness of this idiom.



  CAS has to do both volatile load and store in atomic and indivisible way,
so that you cannot reorder subsequent normal write into the "middle of" CAS.
This is not explicitly stated in the CAS spec as I can see (the wording
about "atomic" behavior of CAS and about its load/store semantics are rather
far apart, so it is debatable), but this is the property of CAS that Java 8'
s implementation of StampedLock relies upon, too.



  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr
Otenko
  Sent: Wednesday, April 23, 2014 11:12 PM
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Stricter read ordering



  No. If CAS is implemented as a volatile load followed by a volatile store,
the effect I describe is possible. There is no need for a weaker
implementation for CAS.

  Watch:

  replace version.compareAndSet with get and set:

  v0=version.get();
  version.set(v0 | WRITE);
  this.x=x; // normal write can go ahead of the volatile write, as per the
cookbook

  Or, in JMM terms, there is no edge enforcing this.x=x by the writer to
appear strictly after x=this.x by the reader.

  Alex

  On 23/04/2014 19:34, Roman Elizarov wrote:

    There was no light in that discussion. CAS is currently spec'd as
volatile load and volatile store.  Period. If someone implements CAS on ARM
with weaker guarantees that violate this spec, then StampedLock in Java 8
solution also becomes broken for the same reason you've outlined below.


    On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko"
<oleksandr.otenko at oracle.com> wrote:

      In light of the recent discussion of the semantics of CAS, this
solution is not correct.

      The outcome of that discussion is that the atomicity of CAS is only
guaranteed with respect to the variable being CASed. This does not matter on
x86, but on ARM, as I understand, the CAS will be implemented as two
instructions that only preclude concurrent stores to the variable being
CASed - which does not preclude reordering the normal stores following CAS
with the "volatile store" part of CAS.

      So, here:




        version.compareAndSet(v0, v0 | WRITE); // always succeeds in
single-writer case, ensures proper HB edges for JMM        // then write
protected data (non-volatile writes)        this.x = x;        this.y =
y;this.x=x; may be observed before compareAndSet completes.

      The correct solution should produce:

      writer:
      vwrite(v,v+1)
      vread(s,_)
      write(x,_)
      write(y,_)
      vwrite(v,v+1)

      reader:
      vread(v,_)
      read(x,_)
      read(y,_)
      vwrite(s,_)
      vread(v,_)

      For example:

      writer:
      // synchronized
      long next = this.version;
      this.version=next+1; // odd version means mutation underway
      long tmp=static_volatile_dummy;
      this.x=x;
      this.y=y;
      this.version=next+2; // even version means immutable

      reader:
      long v;
      do{
        while((v=this.version) &1 != 0); // wait for version to become even
        x=this.x;
        y=this.y;
        static_volatile_dummy=v;
      }while(this.version != v); // check the version didn't change


      Proof:

      It is not necessary to consider all possible reorderings individually.
It is sufficient to consider relative ordering of volatile reads and writes.

      All writers ensure exclusive access to this.x and this.y, so we only
need to consider one writer performing modifications in a loop.

      If volatile read of static_volatile_dummy appears after a volatile
write of static_volatile_dummy in synchronization order, the former
synchronizes-with the latter, and the normal reads of this.x and this.y by
the reader happen-before the normal writes of those variables by the writer
(transitive closure of program orders). So, the readers never see normal
writes of those writers.

      Now consider the writers whose read of static_volatile_dummy does not
synchronize-with the writes. The reader may temporarily observe some values,
but will only terminate the loop after observing the values of this.x and
this.y whose write appear before the volatile write of a even version: the
first loop ensures we only look at writes preceding a write of a even
version, the condition of the outer loop ensures no other volatile writes to
version appear in synchronization order. This means that the first loop
synchronizes-with the last write of a even version, hence, through
transitive closure of program orders the normal writes of this.x and this.y
happen-before the normal reads. The outer condition ensures that since no
other volatile writes of version appear in synchronization order, the
volatile read of static_volatile_dummy after all such writes will
synchronize-with the volatile write of static_volatile_dummy of the reader
(and their normal writes won't be observed, as per the proof in the previous
paragraph).


      This concludes the proof that the reader always observes the
consistent view of this.x and this.y.



      Alex



      On 23/04/2014 15:16, Roman Elizarov wrote:

The original problem itself is solvable, albeit with a different algorithm.
It's funny, that we've discussed the same problem today internally and then
I see this thread on concurrency-interest list.  Let me state the problem
first. There is a multi-word state that we have to read and write in
non-volatile way (if reads and writes of our state can be made volatile,
then solution is trivial and is not of a much interest). We need to
implement single-writer multi-reader atomic snapshot of this multi-word
state with the primitives described in and under the constraints of the Java
Memory Model (think Java 5+). The read does not have to be lock-free. It
just needs to detect that snapshot being read is not consistent. In original
question author was Ok for reader to spin in case of the read/write
conflict, but we actually have a different problem where it is Ok for reader
to abandon the read attempt altogether. The key is to detect this conflict
or to return an atomic snapshot of the protected state if there is no
read/write conflict. So, here is a solution. It can be proven to work on
current version of JMM (starting Java 5 and later) in the JMM's model, by
analyzing possible executions and their corresponding SO, SW, and HB
relations. It requires just one extra int of state (instead of two), but
this int needs to be CAS-ed both on read and on write to ensure proper
happens-before edges and to guarantee the consistent read of non-volatile
state. The proof of this algorithm's correctness is left as an exercise for
the reader. It will not scale, though, if there are many concurrent readers,
because of the CAS in read path.  class VersionedData {    // bit that we'll
use to indicate that the state is being written to    private static final
int WRITE = 1 << 31;    // we need to CAS version (in practise we'll do it
via Unsafe to avoid extra object)    private final AtomicInteger version =
new AtomicInteger();     // this is the data I protect, in reality there is
much more protected state    private int x, y;     public synchronized void
update(int x, int y) {        // I guarantee single writers to this method,
// illustrated with 'synchronized' in this simplification        // first
use CAS to mark version as being written to        int v0 = version.get();
// can be non-volatile read, but then the following CAS can fail and needs
to retry        version.compareAndSet(v0, v0 | WRITE); // always succeeds in
single-writer case, ensures proper HB edges for JMM        // then write
protected data (non-volatile writes)        this.x = x;        this.y = y;
// then increment version and reset write bit        version.set((v0 + 1) &
~WRITE);    }     public DataCarrier read() {        // I allow multiple
readers, so this method is not synchronized        int x, y;        int v0;
do {            // first read version            v0 = version.get();
if ((v0 & WRITE) != 0)                continue; // immediately abort,
because write in progress was detected            // then read protected
data            x = this.x;            y = this.y;            // use CAS to
check that version is still the same and to ensure proper HB edges for JMM
at the same time        } while (!version.compareAndSet(v0, v0));
return new DataCarrier(x, y);    }} -----Original Message-----From:
concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey
ShipilevSent: Wednesday, April 23, 2014 5:36 PMTo: Tobias Lindaaker;
concurrency-interest at cs.oswego.eduSubject: Re: [concurrency-interest]
Stricter read ordering On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:Yes, I
had a look at StampedLock and Unsafe.loadFence(), and it seems to do exactly
what I want, and if I was fortunate enough to be able to move to Java 8 I
would use it. Unfortunately we are still stuck on Java 7. We even have
customers who are still strongly requesting Java6 compatibility.These
constraints make the problem unresolvable. You might want to look for
pre-JDK8 prototype for StampedLock [1]:      * As noted in Boehm's paper
(above), sequence validation (mainly     * method validate()) requires
stricter ordering rules than apply     * to normal volatile reads (of
"state").  In the absence of (but     * continual hope for) explicit JVM
support of intrinsics with     * double-sided reordering prohibition, or
corresponding fence     * intrinsics, we for now uncomfortably rely on the
fact that the     * Unsafe.getXVolatile intrinsic must have this property
* (syntactic volatile reads do not) for internal purposes anyway,     * even
though it is not documented.     public boolean validate(long stamp)
{        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) &
TS);    } But if Unsafe.loadFence() is risky since it is not specified (yet)
JMM-wise, and so interactions with other volatile ops and fences is just
undocumented... then using Unsafe.getXVolatile is double-risky because the
behavioral effect of read ordering is *REALLY* implementation-specific, and
you if are using it for read ordering, you are five miles past the gateway
to Hell already. Thanks,-Aleksey.
[1]http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLo
ck.java?revision=1.1_______________________________________________Concurren
cy-interest mailing
listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/
concurrency-interest
_______________________________________________Concurrency-interest mailing
listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/
concurrency-interest

      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at cs.oswego.edu
      http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/98f89308/attachment-0001.html>

From elizarov at devexperts.com  Thu Apr 24 04:52:57 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 24 Apr 2014 08:52:57 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <53582E77.1060601@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>
	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
	<53581080.3010008@oracle.com>
	<f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
	<53582E77.1060601@oracle.com>
Message-ID: <aea9a435189f43ae94bde548414a79c7@exchmb01.office.devexperts.com>

Below is a solution to the original problem posted by Tobias using Java 8 StamedLock. I've expanded the actual implementation of StampedLock's operations in comments for the ease of reference in the further discussion:

class StampedData {
    // THE NEXT LINE ESSENTIALLY CONTAINS long state
    private final StampedLock lock = new StampedLock();

    // this is the data I protect, in reality there is much more protected state
    private int x, y;

    public synchronized void update(int x, int y) {
        // I guarantee single writers to this method,
        // illustrated with 'synchronized' in this simplification
        // first acquire write lock
        // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; state.CAS(stamp, stamp += WBIT);
        long stamp = lock.tryWriteLock(); // always succeeds in single-writer case
        // then write protected data (non-volatile writes)
        this.x = x;
        this.y = y;
        // then release write lock
        // THE NEXT LINE ESSENTIALLY EXPANDS TO: state = stamp + WBIT;
        lock.unlockWrite(stamp);
    }

    public DataCarrier read() {
        // I allow multiple readers, so this method is not synchronized
        int x, y;
        int v0;
        while (true) {
            // first try optimistic read
            // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; // if was not locked by writer
            long stamp = lock.tryOptimisticRead();
            if (stamp == 0)
                continue; // immediately abort, because write in progress was detected
            // then read protected data
            x = this.x;
            y = this.y;
            // validate to make sure that the read was consistent
            // THE NEXT LINE ESSENTIALLY EXPANDS TO: loadFence; if (state == stamp) break;
            if (lock.validate(stamp))
                break;
        }
        return new DataCarrier(x, y);
    }
}

As you can see, it is virtually the same code as I've presented in my original solution where "version" is replaced by StampedLock's "state". The primary difference can be found in the read path, when StampedLock uses loadFence to ensure LoadLoad barrier after the read of the protected data and before checking that state did not change. There is no Unsafe.loadFence before Java 8, so my solution had to resort to what Hans Boehm named "read-dont-modify-write" operation using CAS.

Now, let us take a closer look at the write path in update method. You can see that StampedLock's write path is the same as the write path that was used in my original solution (version is updated with CAS before writing protected data and updated again with volatile write after it). So, what happens if this CAS is not atomic from the standpoint of the memory model, but is modelled as two separate operations, the first being volatile read, the second one being volatile write?

As you've correctly observed, in this model non-volatile writes to the protected state can be reordered in between the volatile read and volatile write that constitute CAS. If this happens, reader can read an inconsistent snapshot of the protected state without detecting this fact (validate will return true), if all reader's actions take effect in between those volatile read and volatile write that constitute CAS. Q.E.D. From the memory model perspective (in JLS Chapter 17 terms) CAS has to be represented as one "inter-thread action" that has effect of both volatile read and volatile write. Otherwise, StampedLock idiom is broken.

From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
Sent: Thursday, April 24, 2014 1:20 AM
To: Roman Elizarov
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

Can you quote the exact spot? I see it is quite different from your suggestion, and where I look it doesn't seem atomicity of CAS matters.


Alex

On 23/04/2014 20:57, Roman Elizarov wrote:
You are right. You cannot just split CAS into load and store this way. Actually, if you analyze required barriers for write path in the same way as I did for read path (remember, that writer has to have StoreStore barrier before version write and subsequent non-volatile writes), you see that you need to insert volatile read _after_ the version.write() in the write path, so it becomes:

Writer does (in PO): version.volatileWrite();  {StoreLoad emitted}; something.volatileRead(); {LoadStore emitted} x.write(); y.write(); {StoreStore emitted}; version.write();

This effectively gives you StoreStore barrier between version write and a first non-volatile write of protected data state. Ordering those two volatile operations at the beginning of write path the other way around, as in your example below, does not provide the necessary barrier to guarantee correctness of this idiom.

CAS has to do both volatile load and store in atomic and indivisible way, so that you cannot reorder subsequent normal write into the "middle of" CAS. This is not explicitly stated in the CAS spec as I can see (the wording about "atomic" behavior of CAS and about its load/store semantics are rather far apart, so it is debatable), but this is the property of CAS that Java 8's implementation of StampedLock relies upon, too.

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Wednesday, April 23, 2014 11:12 PM
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Stricter read ordering

No. If CAS is implemented as a volatile load followed by a volatile store, the effect I describe is possible. There is no need for a weaker implementation for CAS.

Watch:

replace version.compareAndSet with get and set:

v0=version.get();
version.set(v0 | WRITE);
this.x=x; // normal write can go ahead of the volatile write, as per the cookbook

Or, in JMM terms, there is no edge enforcing this.x=x by the writer to appear strictly after x=this.x by the reader.

Alex
On 23/04/2014 19:34, Roman Elizarov wrote:
There was no light in that discussion. CAS is currently spec'd as volatile load and volatile store.  Period. If someone implements CAS on ARM with weaker guarantees that violate this spec, then StampedLock in Java 8 solution also becomes broken for the same reason you've outlined below.

On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko" <oleksandr.otenko at oracle.com<mailto:oleksandr.otenko at oracle.com>> wrote:
In light of the recent discussion of the semantics of CAS, this solution is not correct.

The outcome of that discussion is that the atomicity of CAS is only guaranteed with respect to the variable being CASed. This does not matter on x86, but on ARM, as I understand, the CAS will be implemented as two instructions that only preclude concurrent stores to the variable being CASed - which does not preclude reordering the normal stores following CAS with the "volatile store" part of CAS.

So, here:




        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;
this.x=x; may be observed before compareAndSet completes.

The correct solution should produce:

writer:
vwrite(v,v+1)
vread(s,_)
write(x,_)
write(y,_)
vwrite(v,v+1)

reader:
vread(v,_)
read(x,_)
read(y,_)
vwrite(s,_)
vread(v,_)

For example:

writer:
// synchronized
long next = this.version;
this.version=next+1; // odd version means mutation underway
long tmp=static_volatile_dummy;
this.x=x;
this.y=y;
this.version=next+2; // even version means immutable

reader:
long v;
do{
  while((v=this.version) &1 != 0); // wait for version to become even
  x=this.x;
  y=this.y;
  static_volatile_dummy=v;
}while(this.version != v); // check the version didn't change


Proof:

It is not necessary to consider all possible reorderings individually. It is sufficient to consider relative ordering of volatile reads and writes.

All writers ensure exclusive access to this.x and this.y, so we only need to consider one writer performing modifications in a loop.

If volatile read of static_volatile_dummy appears after a volatile write of static_volatile_dummy in synchronization order, the former synchronizes-with the latter, and the normal reads of this.x and this.y by the reader happen-before the normal writes of those variables by the writer (transitive closure of program orders). So, the readers never see normal writes of those writers.

Now consider the writers whose read of static_volatile_dummy does not synchronize-with the writes. The reader may temporarily observe some values, but will only terminate the loop after observing the values of this.x and this.y whose write appear before the volatile write of a even version: the first loop ensures we only look at writes preceding a write of a even version, the condition of the outer loop ensures no other volatile writes to version appear in synchronization order. This means that the first loop synchronizes-with the last write of a even version, hence, through transitive closure of program orders the normal writes of this.x and this.y happen-before the normal reads. The outer condition ensures that since no other volatile writes of version appear in synchronization order, the volatile read of static_volatile_dummy after all such writes will synchronize-with the volatile write of static_volatile_dummy of the reader (and their normal writes won't be observed, as per the proof in the previous paragraph).


This concludes the proof that the reader always observes the consistent view of this.x and this.y.



Alex


On 23/04/2014 15:16, Roman Elizarov wrote:

The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.



Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.



So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.



class VersionedData {

    // bit that we'll use to indicate that the state is being written to

    private static final int WRITE = 1 << 31;

    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)

    private final AtomicInteger version = new AtomicInteger();



    // this is the data I protect, in reality there is much more protected state

    private int x, y;



    public synchronized void update(int x, int y) {

        // I guarantee single writers to this method,

        // illustrated with 'synchronized' in this simplification

        // first use CAS to mark version as being written to

        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry

        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;

        // then increment version and reset write bit

        version.set((v0 + 1) & ~WRITE);

    }



    public DataCarrier read() {

        // I allow multiple readers, so this method is not synchronized

        int x, y;

        int v0;

        do {

            // first read version

            v0 = version.get();

            if ((v0 & WRITE) != 0)

                continue; // immediately abort, because write in progress was detected

            // then read protected data

            x = this.x;

            y = this.y;

            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time

        } while (!version.compareAndSet(v0, v0));

        return new DataCarrier(x, y);

    }

}



-----Original Message-----

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev

Sent: Wednesday, April 23, 2014 5:36 PM

To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>

Subject: Re: [concurrency-interest] Stricter read ordering



On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:

Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems

to do exactly what I want, and if I was fortunate enough to be able to

move to Java 8 I would use it. Unfortunately we are still stuck on

Java 7. We even have customers who are still strongly requesting Java

6 compatibility.

These constraints make the problem unresolvable.



You might want to look for pre-JDK8 prototype for StampedLock [1]:



     * As noted in Boehm's paper (above), sequence validation (mainly

     * method validate()) requires stricter ordering rules than apply

     * to normal volatile reads (of "state").  In the absence of (but

     * continual hope for) explicit JVM support of intrinsics with

     * double-sided reordering prohibition, or corresponding fence

     * intrinsics, we for now uncomfortably rely on the fact that the

     * Unsafe.getXVolatile intrinsic must have this property

     * (syntactic volatile reads do not) for internal purposes anyway,

     * even though it is not documented.



    public boolean validate(long stamp) {

        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);

    }



But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.



Thanks,

-Aleksey.



[1]

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/91fa400a/attachment-0001.html>

From thobes at gmail.com  Thu Apr 24 05:19:40 2014
From: thobes at gmail.com (Tobias Lindaaker)
Date: Thu, 24 Apr 2014 11:19:40 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
	<CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
Message-ID: <7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>

Stanimir,

Yes, the data in the buffers range from 9 to 130 bytes per data item.

On 23 Apr 2014, at 17:57 , Stanimir Simeonoff <stanimir at riflexo.com> wrote:

> Just in case to make sure:
> You have more than just 2 ints, right? 
> On 64bit and aligned direct buffers you'd get all you want via put/getLong esp on LongBuffer as it always aligned.
> 
> Stanimir

-----

Peter,

I have looked at LeftRight, and MVCC in general, previously. I like these approaches, and we have it included as one of the alternatives we are benchmarking against the one I outlined in this thread. The drawbacks of a solution using two (or more) versions of the data is that it requires more memory (meaning we can fit less data into memory) and that it is less similar to our current code, requiring larger changes to implement. It's still an interesting alternative, so thank you for adding it to the discussion. However our current focus is to make sure that the different alternatives we are benchmarking are correct, so that the comparison is fair.

On 23 Apr 2014, at 23:25 , Peter Levart <peter.levart at gmail.com> wrote:

> Hi Tobias,
> 
> I you don't mind keeping 2 mirrored variants of your state (two mirrored memory mapped files in your case, or one file with duplicate/striped records) and applying all modifications to both copies, then the following might interest you:
> 
> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
> 
> Regards, Peter

-----

Hans,

Thank you for the reference, a very nice read, those examples are very good at illustrating the problems and solutions.

On 23 Apr 2014, at 19:26 , Hans Boehm <boehm at acm.org> wrote:

> The original code is essentially a reimplementation of Linux seqlocks.  The memory ordering issues are discussed in my MSPC 2012 paper, which you can find at http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .
> 
> (The C++ writer code in that paper, which should be uninteresting, and is beside the point, has a bug.  Don't copy!)
> 
> Hans
> 


-----

Roman and Alex,

Thank you for all your great insight and suggestions, I greatly appreciate it.
I'm going to re-read the JSR-133 cookbook a few times.

Cheers,
Tobias
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/a8dddbfd/attachment.html>

From peter.levart at gmail.com  Thu Apr 24 05:56:24 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 24 Apr 2014 11:56:24 +0200
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>	<5357D52E.6010300@oracle.com>	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>	<CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
	<7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>
Message-ID: <5358DFC8.9090804@gmail.com>

On 04/24/2014 11:19 AM, Tobias Lindaaker wrote:
> Stanimir,
>
> Yes, the data in the buffers range from 9 to 130 bytes per data item.

If data items could be broken into 64 or 32 bit chunks so that each 
chunk contained a version counter (depending on the possible frequency 
of updates it could be just a few bits) and those chunks could be read 
and written atomically, then you could just read all the chunks of a 
data item and check that the versions of all chunks match. The writer 
would just have to increment the version counter of each chunk belonging 
to data items updated.

Regards, Peter

>
> On 23 Apr 2014, at 17:57 , Stanimir Simeonoff <stanimir at riflexo.com 
> <mailto:stanimir at riflexo.com>> wrote:
>
>> Just in case to make sure:
>> You have more than just 2 ints, right?
>> On 64bit and aligned direct buffers you'd get all you want via 
>> put/getLong esp on LongBuffer as it always aligned.
>>
>> Stanimir
>
> -----
>
> Peter,
>
> I have looked at LeftRight, and MVCC in general, previously. I like 
> these approaches, and we have it included as one of the alternatives 
> we are benchmarking against the one I outlined in this thread. The 
> drawbacks of a solution using two (or more) versions of the data is 
> that it requires more memory (meaning we can fit less data into 
> memory) and that it is less similar to our current code, requiring 
> larger changes to implement. It's still an interesting alternative, so 
> thank you for adding it to the discussion. However our current focus 
> is to make sure that the different alternatives we are benchmarking 
> are correct, so that the comparison is fair.
>
> On 23 Apr 2014, at 23:25 , Peter Levart <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>> wrote:
>
>> Hi Tobias,
>>
>> I you don't mind keeping 2 mirrored variants of your state (two 
>> mirrored memory mapped files in your case, or one file with 
>> duplicate/striped records) and applying all modifications to both 
>> copies, then the following might interest you:
>>
>> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>>
>> Regards, Peter
>
> -----
>
> Hans,
>
> Thank you for the reference, a very nice read, those examples are very 
> good at illustrating the problems and solutions.
>
> On 23 Apr 2014, at 19:26 , Hans Boehm <boehm at acm.org 
> <mailto:boehm at acm.org>> wrote:
>
>> The original code is essentially a reimplementation of Linux 
>> seqlocks.  The memory ordering issues are discussed in my MSPC 2012 
>> paper, which you can find at 
>> http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .
>>
>> (The C++ writer code in that paper, which should be uninteresting, 
>> and is beside the point, has a bug.  Don't copy!)
>>
>> Hans
>>
>
> -----
>
> Roman and Alex,
>
> Thank you for all your great insight and suggestions, I greatly 
> appreciate it.
> I'm going to re-read the JSR-133 cookbook a few times.
>
> Cheers,
> Tobias
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/84990fab/attachment.html>

From Peter.Kaiser at compuware.com  Thu Apr 24 06:10:27 2014
From: Peter.Kaiser at compuware.com (Kaiser, Peter)
Date: Thu, 24 Apr 2014 10:10:27 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5358DFC8.9090804@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
	<CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
	<7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>
	<5358DFC8.9090804@gmail.com>
Message-ID: <db85f24bcf31465c93990720a3ee2cf6@DM2PR05MB349.namprd05.prod.outlook.com>

Wouldn't it be possible to store each chunk in an individual byte array? Writes could simply exchange single arrays and safe publication to other threads would be much easier and more efficient. Reads would also be more efficient.

Best Regards, Peter

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Peter Levart
Sent: Donnerstag, 24. April 2014 11:56
To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

On 04/24/2014 11:19 AM, Tobias Lindaaker wrote:
Stanimir,

Yes, the data in the buffers range from 9 to 130 bytes per data item.

If data items could be broken into 64 or 32 bit chunks so that each chunk contained a version counter (depending on the possible frequency of updates it could be just a few bits) and those chunks could be read and written atomically, then you could just read all the chunks of a data item and check that the versions of all chunks match. The writer would just have to increment the version counter of each chunk belonging to data items updated.

Regards, Peter



On 23 Apr 2014, at 17:57 , Stanimir Simeonoff <stanimir at riflexo.com<mailto:stanimir at riflexo.com>> wrote:


Just in case to make sure:
You have more than just 2 ints, right?
On 64bit and aligned direct buffers you'd get all you want via put/getLong esp on LongBuffer as it always aligned.

Stanimir

-----

Peter,

I have looked at LeftRight, and MVCC in general, previously. I like these approaches, and we have it included as one of the alternatives we are benchmarking against the one I outlined in this thread. The drawbacks of a solution using two (or more) versions of the data is that it requires more memory (meaning we can fit less data into memory) and that it is less similar to our current code, requiring larger changes to implement. It's still an interesting alternative, so thank you for adding it to the discussion. However our current focus is to make sure that the different alternatives we are benchmarking are correct, so that the comparison is fair.

On 23 Apr 2014, at 23:25 , Peter Levart <peter.levart at gmail.com<mailto:peter.levart at gmail.com>> wrote:


Hi Tobias,

I you don't mind keeping 2 mirrored variants of your state (two mirrored memory mapped files in your case, or one file with duplicate/striped records) and applying all modifications to both copies, then the following might interest you:

http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf

Regards, Peter

-----

Hans,

Thank you for the reference, a very nice read, those examples are very good at illustrating the problems and solutions.

On 23 Apr 2014, at 19:26 , Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:


The original code is essentially a reimplementation of Linux seqlocks.  The memory ordering issues are discussed in my MSPC 2012 paper, which you can find at http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .

(The C++ writer code in that paper, which should be uninteresting, and is beside the point, has a bug.  Don't copy!)

Hans


-----

Roman and Alex,

Thank you for all your great insight and suggestions, I greatly appreciate it.
I'm going to re-read the JSR-133 cookbook a few times.

Cheers,
Tobias




_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/f85ff9e5/attachment-0001.html>

From Peter.Kaiser at compuware.com  Thu Apr 24 06:15:37 2014
From: Peter.Kaiser at compuware.com (Kaiser, Peter)
Date: Thu, 24 Apr 2014 10:15:37 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <db85f24bcf31465c93990720a3ee2cf6@DM2PR05MB349.namprd05.prod.outlook.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
	<CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
	<7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>
	<5358DFC8.9090804@gmail.com>
	<db85f24bcf31465c93990720a3ee2cf6@DM2PR05MB349.namprd05.prod.outlook.com>
Message-ID: <e1726355d7e8420089a96a3325dc7157@DM2PR05MB349.namprd05.prod.outlook.com>

Sorry, of course i meant to create an individual array per data item...

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Kaiser, Peter
Sent: Donnerstag, 24. April 2014 12:10
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

Wouldn't it be possible to store each chunk in an individual byte array? Writes could simply exchange single arrays and safe publication to other threads would be much easier and more efficient. Reads would also be more efficient.

Best Regards, Peter

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Peter Levart
Sent: Donnerstag, 24. April 2014 11:56
To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Stricter read ordering

On 04/24/2014 11:19 AM, Tobias Lindaaker wrote:
Stanimir,

Yes, the data in the buffers range from 9 to 130 bytes per data item.

If data items could be broken into 64 or 32 bit chunks so that each chunk contained a version counter (depending on the possible frequency of updates it could be just a few bits) and those chunks could be read and written atomically, then you could just read all the chunks of a data item and check that the versions of all chunks match. The writer would just have to increment the version counter of each chunk belonging to data items updated.

Regards, Peter


On 23 Apr 2014, at 17:57 , Stanimir Simeonoff <stanimir at riflexo.com<mailto:stanimir at riflexo.com>> wrote:

Just in case to make sure:
You have more than just 2 ints, right?
On 64bit and aligned direct buffers you'd get all you want via put/getLong esp on LongBuffer as it always aligned.

Stanimir

-----

Peter,

I have looked at LeftRight, and MVCC in general, previously. I like these approaches, and we have it included as one of the alternatives we are benchmarking against the one I outlined in this thread. The drawbacks of a solution using two (or more) versions of the data is that it requires more memory (meaning we can fit less data into memory) and that it is less similar to our current code, requiring larger changes to implement. It's still an interesting alternative, so thank you for adding it to the discussion. However our current focus is to make sure that the different alternatives we are benchmarking are correct, so that the comparison is fair.

On 23 Apr 2014, at 23:25 , Peter Levart <peter.levart at gmail.com<mailto:peter.levart at gmail.com>> wrote:

Hi Tobias,

I you don't mind keeping 2 mirrored variants of your state (two mirrored memory mapped files in your case, or one file with duplicate/striped records) and applying all modifications to both copies, then the following might interest you:

http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf

Regards, Peter

-----

Hans,

Thank you for the reference, a very nice read, those examples are very good at illustrating the problems and solutions.

On 23 Apr 2014, at 19:26 , Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

The original code is essentially a reimplementation of Linux seqlocks.  The memory ordering issues are discussed in my MSPC 2012 paper, which you can find at http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .

(The C++ writer code in that paper, which should be uninteresting, and is beside the point, has a bug.  Don't copy!)

Hans


-----

Roman and Alex,

Thank you for all your great insight and suggestions, I greatly appreciate it.
I'm going to re-read the JSR-133 cookbook a few times.

Cheers,
Tobias



_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
The contents of this e-mail are intended for the named addressee only. It contains information that may be confidential. Unless you are the named addressee or an authorized designee, you may not copy or use it, or disclose it to anyone else. If you received it in error please notify us immediately and then destroy it. Compuware Austria GmbH (registration number FN 91482h) is a company registered in Vienna whose registered office is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/dc699fad/attachment.html>

From stanimir at riflexo.com  Thu Apr 24 06:43:44 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 24 Apr 2014 13:43:44 +0300
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <db85f24bcf31465c93990720a3ee2cf6@DM2PR05MB349.namprd05.prod.outlook.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
	<CAEJX8opcjgvjoG2eFgPXfaPi2VFoeC-0pMT2sJF_igisFo9qXQ@mail.gmail.com>
	<7EA1A134-19CA-4992-83A4-FD001977973E@gmail.com>
	<5358DFC8.9090804@gmail.com>
	<db85f24bcf31465c93990720a3ee2cf6@DM2PR05MB349.namprd05.prod.outlook.com>
Message-ID: <CAEJX8opP9wWw-5FZf+C2NLcuqbFgJ76FJoa7r=mdQrBYyeymcg@mail.gmail.com>

If the ByteBuffers are direct (e.g. mapped ones, or just offheap memory)
that won't be usable. If they are plain heap buffers, there is no reason
not to use just normal java objects then.

Stanimir




On Thu, Apr 24, 2014 at 1:10 PM, Kaiser, Peter
<Peter.Kaiser at compuware.com>wrote:

>  Wouldn't it be possible to store each chunk in an individual byte array?
> Writes could simply exchange single arrays and safe publication to other
> threads would be much easier and more efficient. Reads would also be more
> efficient.
>
>
>
> Best Regards, Peter
>
>
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Peter Levart
> *Sent:* Donnerstag, 24. April 2014 11:56
>
> *To:* Tobias Lindaaker; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Stricter read ordering
>
>
>
> On 04/24/2014 11:19 AM, Tobias Lindaaker wrote:
>
>  Stanimir,
>
>
>
> Yes, the data in the buffers range from 9 to 130 bytes per data item.
>
>
> If data items could be broken into 64 or 32 bit chunks so that each chunk
> contained a version counter (depending on the possible frequency of updates
> it could be just a few bits) and those chunks could be read and written
> atomically, then you could just read all the chunks of a data item and
> check that the versions of all chunks match. The writer would just have to
> increment the version counter of each chunk belonging to data items updated.
>
> Regards, Peter
>
>
>
>
> On 23 Apr 2014, at 17:57 , Stanimir Simeonoff <stanimir at riflexo.com>
> wrote:
>
>
>
>    Just in case to make sure:
> You have more than just 2 ints, right?
> On 64bit and aligned direct buffers you'd get all you want via put/getLong
> esp on LongBuffer as it always aligned.
>
>
>
> Stanimir
>
>
>
> -----
>
>
>
> Peter,
>
>
>
> I have looked at LeftRight, and MVCC in general, previously. I like these
> approaches, and we have it included as one of the alternatives we are
> benchmarking against the one I outlined in this thread. The drawbacks of a
> solution using two (or more) versions of the data is that it requires more
> memory (meaning we can fit less data into memory) and that it is less
> similar to our current code, requiring larger changes to implement. It's
> still an interesting alternative, so thank you for adding it to the
> discussion. However our current focus is to make sure that the different
> alternatives we are benchmarking are correct, so that the comparison is
> fair.
>
>
>
> On 23 Apr 2014, at 23:25 , Peter Levart <peter.levart at gmail.com> wrote:
>
>
>
>   Hi Tobias,
>
> I you don't mind keeping 2 mirrored variants of your state (two mirrored
> memory mapped files in your case, or one file with duplicate/striped
> records) and applying all modifications to both copies, then the following
> might interest you:
>
> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>
>
> Regards, Peter
>
>
>
> -----
>
>
>
> Hans,
>
>
>
> Thank you for the reference, a very nice read, those examples are very
> good at illustrating the problems and solutions.
>
>
>
> On 23 Apr 2014, at 19:26 , Hans Boehm <boehm at acm.org> wrote:
>
>
>
>   The original code is essentially a reimplementation of Linux seqlocks.
>  The memory ordering issues are discussed in my MSPC 2012 paper, which you
> can find at http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .
>
>
>
> (The C++ writer code in that paper, which should be uninteresting, and is
> beside the point, has a bug.  Don't copy!)
>
>
>
> Hans
>
>
>
>
>
> -----
>
>
>
> Roman and Alex,
>
>
>
> Thank you for all your great insight and suggestions, I greatly appreciate
> it.
>
> I'm going to re-read the JSR-133 cookbook a few times.
>
>
>
> Cheers,
>
> Tobias
>
>
>
>
>  _______________________________________________
>
> Concurrency-interest mailing list
>
> Concurrency-interest at cs.oswego.edu
>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>  The contents of this e-mail are intended for the named addressee only. It
> contains information that may be confidential. Unless you are the named
> addressee or an authorized designee, you may not copy or use it, or
> disclose it to anyone else. If you received it in error please notify us
> immediately and then destroy it. Compuware Austria GmbH (registration
> number FN 91482h) is a company registered in Vienna whose registered office
> is at 1120 Wien, Austria, Am Euro Platz 2 / Geb?ude G.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/f5803bbc/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Apr 24 08:20:30 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 24 Apr 2014 13:20:30 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEOHKFAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEOHKFAA.davidcholmes@aapt.net.au>
Message-ID: <5359018E.6000705@oracle.com>

Thank you. I reviewed the thread, and now I see it did mention that. A 
pair of load/store with acquire/release semantics was only deemed 
adequate for C++11.

Alex

On 24/04/2014 00:15, David Holmes wrote:
> The discussion of CAS being like a "volatile load plus volatile store" 
> did expose that that description is inadequate to fully convey the 
> required ordering constraints. The actual implementations in the 
> Oracle JDK do not allow external accesses to leak into the atomic region.
> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Roman Elizarov
>     *Sent:* Thursday, 24 April 2014 5:58 AM
>     *To:* Oleksandr Otenko
>     *Cc:* concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Stricter read ordering
>
>     You are right. You cannot just split CAS into load and store this
>     way. Actually, if you analyze required barriers for write path in
>     the same way as I did for read path (remember, that writer has to
>     have StoreStore barrier before version write and subsequent
>     non-volatile writes), you see that you need to insert volatile
>     read _/after/_ the version.write() in the write path, so it becomes:
>
>     Writer does (in PO): version.volatileWrite();  {StoreLoad
>     emitted}; something.volatileRead(); {LoadStore emitted} x.write();
>     y.write(); {StoreStore emitted}; version.write();
>
>     This effectively gives you StoreStore barrier between version
>     write and a first non-volatile write of protected data state.
>     Ordering those two volatile operations at the beginning of write
>     path the other way around, as in your example below, does not
>     provide the necessary barrier to guarantee correctness of this idiom.
>
>     CAS has to do both volatile load and store in atomic and
>     indivisible way, so that you cannot reorder subsequent normal
>     write into the "middle of" CAS. This is not explicitly stated in
>     the CAS spec as I can see (the wording about "atomic" behavior of
>     CAS and about its load/store semantics are rather far apart, so it
>     is debatable), but this is the property of CAS that Java 8's
>     implementation of StampedLock relies upon, too.
>
>     *From:*concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of
>     *Oleksandr Otenko
>     *Sent:* Wednesday, April 23, 2014 11:12 PM
>     *Cc:* concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Stricter read ordering
>
>     No. If CAS is implemented as a volatile load followed by a
>     volatile store, the effect I describe is possible. There is no
>     need for a weaker implementation for CAS.
>
>     Watch:
>
>     replace version.compareAndSet with get and set:
>
>     v0=version.get();
>     version.set(v0 | WRITE);
>     this.x=x; // normal write can go ahead of the volatile write, as
>     per the cookbook
>
>     Or, in JMM terms, there is no edge enforcing this.x=x by the
>     writer to appear strictly after x=this.x by the reader.
>
>     Alex
>
>     On 23/04/2014 19:34, Roman Elizarov wrote:
>
>         There was no light in that discussion. CAS is currently spec'd
>         as volatile load and volatile store.  Period. If someone
>         implements CAS on ARM with weaker guarantees that violate this
>         spec, then StampedLock in Java 8 solution also becomes broken
>         for the same reason you've outlined below.
>
>
>         On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko"
>         <oleksandr.otenko at oracle.com
>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>             In light of the recent discussion of the semantics of CAS,
>             this solution is not correct.
>
>             The outcome of that discussion is that the atomicity of
>             CAS is only guaranteed with respect to the variable being
>             CASed. This does not matter on x86, but on ARM, as I
>             understand, the CAS will be implemented as two
>             instructions that only preclude concurrent stores to the
>             variable being CASed - which does not preclude reordering
>             the normal stores following CAS with the "volatile store"
>             part of CAS.
>
>             So, here:
>
>
>                      version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                      // then write protected data (non-volatile writes)
>
>                      this.x = x;
>
>                      this.y = y;
>
>             this.x=x; may be observed before compareAndSet completes.
>
>             The correct solution should produce:
>
>             writer:
>             vwrite(v,v+1)
>             *vread(s,_)
>             *write(x,_)
>             write(y,_)
>             vwrite(v,v+1)
>
>             reader:
>             vread(v,_)
>             read(x,_)
>             read(y,_)
>             *vwrite(s,_)
>             *vread(v,_)
>
>             For example:
>
>             writer:
>             // synchronized
>             long next = this.version;
>             this.version=next+1; // odd version means mutation underway
>             long tmp=static_volatile_dummy;
>             this.x=x;
>             this.y=y;
>             this.version=next+2; // even version means immutable
>
>             reader:
>             long v;
>             do{
>               while((v=this.version) &1 != 0); // wait for version to
>             become even
>               x=this.x;
>               y=this.y;
>               static_volatile_dummy=v;
>             }while(this.version != v); // check the version didn't change
>
>
>             Proof:
>
>             It is not necessary to consider all possible reorderings
>             individually. It is sufficient to consider relative
>             ordering of volatile reads and writes.
>
>             All writers ensure exclusive access to this.x and this.y,
>             so we only need to consider one writer performing
>             modifications in a loop.
>
>             If volatile read of static_volatile_dummy appears after a
>             volatile write of static_volatile_dummy in synchronization
>             order, the former synchronizes-with the latter, and the
>             normal reads of this.x and this.y by the reader
>             happen-before the normal writes of those variables by the
>             writer (transitive closure of program orders). So, the
>             readers never see normal writes of those writers.
>
>             Now consider the writers whose read of
>             static_volatile_dummy does not synchronize-with the
>             writes. The reader may temporarily observe some values,
>             but will only terminate the loop after observing the
>             values of this.x and this.y whose write appear before the
>             volatile write of a even version: the first loop ensures
>             we only look at writes preceding a write of a even
>             version, the condition of the outer loop ensures no other
>             volatile writes to version appear in synchronization
>             order. This means that the first loop synchronizes-with
>             the last write of a even version, hence, through
>             transitive closure of program orders the normal writes of
>             this.x and this.y happen-before the normal reads. The
>             outer condition ensures that since no other volatile
>             writes of version appear in synchronization order, the
>             volatile read of static_volatile_dummy after all such
>             writes will synchronize-with the volatile write of
>             static_volatile_dummy of the reader (and their normal
>             writes won't be observed, as per the proof in the previous
>             paragraph).
>
>
>             This concludes the proof that the reader always observes
>             the consistent view of this.x and this.y.
>
>
>
>             Alex
>
>             On 23/04/2014 15:16, Roman Elizarov wrote:
>
>                 The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>
>                   
>
>                 Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>
>                   
>
>                 So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>
>                   
>
>                 class VersionedData {
>
>                      // bit that we'll use to indicate that the state is being written to
>
>                      private static final int WRITE = 1 << 31;
>
>                      // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>
>                      private final AtomicInteger version = new AtomicInteger();
>
>                   
>
>                      // this is the data I protect, in reality there is much more protected state
>
>                      private int x, y;
>
>                   
>
>                      public synchronized void update(int x, int y) {
>
>                          // I guarantee single writers to this method,
>
>                          // illustrated with 'synchronized' in this simplification
>
>                          // first use CAS to mark version as being written to
>
>                          int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>
>                          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                          // then write protected data (non-volatile writes)
>
>                          this.x = x;
>
>                          this.y = y;
>
>                          // then increment version and reset write bit
>
>                          version.set((v0 + 1) & ~WRITE);
>
>                      }
>
>                   
>
>                      public DataCarrier read() {
>
>                          // I allow multiple readers, so this method is not synchronized
>
>                          int x, y;
>
>                          int v0;
>
>                          do {
>
>                              // first read version
>
>                              v0 = version.get();
>
>                              if ((v0 & WRITE) != 0)
>
>                                  continue; // immediately abort, because write in progress was detected
>
>                              // then read protected data
>
>                              x = this.x;
>
>                              y = this.y;
>
>                              // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>
>                          } while (!version.compareAndSet(v0, v0));
>
>                          return new DataCarrier(x, y);
>
>                      }
>
>                 }
>
>                   
>
>                 -----Original Message-----
>
>                 From:concurrency-interest-bounces at cs.oswego.edu  <mailto:concurrency-interest-bounces at cs.oswego.edu>  [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>
>                 Sent: Wednesday, April 23, 2014 5:36 PM
>
>                 To: Tobias Lindaaker;concurrency-interest at cs.oswego.edu  <mailto:concurrency-interest at cs.oswego.edu>
>
>                 Subject: Re: [concurrency-interest] Stricter read ordering
>
>                   
>
>                 On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>
>                     Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>
>                     to do exactly what I want, and if I was fortunate enough to be able to
>
>                     move to Java 8 I would use it. Unfortunately we are still stuck on
>
>                     Java 7. We even have customers who are still strongly requesting Java
>
>                     6 compatibility.
>
>                 These constraints make the problem unresolvable.
>
>                   
>
>                 You might want to look for pre-JDK8 prototype for StampedLock [1]:
>
>                   
>
>                       * As noted in Boehm's paper (above), sequence validation (mainly
>
>                       * method validate()) requires stricter ordering rules than apply
>
>                       * to normal volatile reads (of "state").  In the absence of (but
>
>                       * continual hope for) explicit JVM support of intrinsics with
>
>                       * double-sided reordering prohibition, or corresponding fence
>
>                       * intrinsics, we for now uncomfortably rely on the fact that the
>
>                       * Unsafe.getXVolatile intrinsic must have this property
>
>                       * (syntactic volatile reads do not) for internal purposes anyway,
>
>                       * even though it is not documented.
>
>                   
>
>                      public boolean validate(long stamp) {
>
>                          return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>
>                      }
>
>                   
>
>                 But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>
>                   
>
>                 Thanks,
>
>                 -Aleksey.
>
>                   
>
>                 [1]
>
>                 http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>
>                 _______________________________________________
>
>                 Concurrency-interest mailing list
>
>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>                   
>
>                 _______________________________________________
>
>                 Concurrency-interest mailing list
>
>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/a9e07129/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Apr 24 08:27:58 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 24 Apr 2014 13:27:58 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <aea9a435189f43ae94bde548414a79c7@exchmb01.office.devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
	<53581080.3010008@oracle.com>
	<f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
	<53582E77.1060601@oracle.com>
	<aea9a435189f43ae94bde548414a79c7@exchmb01.office.devexperts.com>
Message-ID: <5359034E.8090806@oracle.com>

Yes, I need to retract my statement about CAS. I checked the CAS thread 
again. It does say that "just" a pair of load/store is not adequate for 
Java. So, then the CAS-based version must be OK. I would still like to 
point out that my version doesn't rely on underspecified semantics of CAS.

Alex

On 24/04/2014 09:52, Roman Elizarov wrote:
>
> Below is a solution to the original problem posted by Tobias using 
> Java 8 StamedLock. I've expanded the actual implementation of 
> StampedLock's operations in comments for the ease of reference in the 
> further discussion:
>
> class StampedData {
>
>     // THE NEXT LINE ESSENTIALLY CONTAINS long state
>
>     private final StampedLock lock = new StampedLock();
>
>     // this is the data I protect, in reality there is much more 
> protected state
>
>     private int x, y;
>
>     public synchronized void update(int x, int y) {
>
>         // I guarantee single writers to this method,
>
>         // illustrated with 'synchronized' in this simplification
>
>         // first acquire write lock
>
>         // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; 
> state.CAS(stamp, stamp += WBIT);
>
>         long stamp = lock.tryWriteLock(); // always succeeds in 
> single-writer case
>
>         // then write protected data (non-volatile writes)
>
>         this.x = x;
>
>         this.y = y;
>
>         // then release write lock
>
>         // THE NEXT LINE ESSENTIALLY EXPANDS TO: state = stamp + WBIT;
>
>         lock.unlockWrite(stamp);
>
>     }
>
>     public DataCarrier read() {
>
>         // I allow multiple readers, so this method is not synchronized
>
>         int x, y;
>
>         int v0;
>
>         while (true) {
>
>             // first try optimistic read
>
>             // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; // 
> if was not locked by writer
>
>             long stamp = lock.tryOptimisticRead();
>
>             if (stamp == 0)
>
>                 continue; // immediately abort, because write in 
> progress was detected
>
>             // then read protected data
>
>             x = this.x;
>
>             y = this.y;
>
>             // validate to make sure that the read was consistent
>
>             // THE NEXT LINE ESSENTIALLY EXPANDS TO: loadFence; if 
> (state == stamp) break;
>
>             if (lock.validate(stamp))
>
>                 break;
>
>         }
>
>         return new DataCarrier(x, y);
>
>     }
>
> }
>
> As you can see, it is virtually the same code as I've presented in my 
> original solution where "version" is replaced by StampedLock's 
> "state". The primary difference can be found in the read path, when 
> StampedLock uses loadFence to ensure LoadLoad barrier after the read 
> of the protected data and before checking that state did not change. 
> There is no Unsafe.loadFence before Java 8, so my solution had to 
> resort to what Hans Boehm named "read-dont-modify-write" operation 
> using CAS.
>
> Now, let us take a closer look at the write path in update method. You 
> can see that StampedLock's write path is the same as the write path 
> that was used in my original solution (version is updated with CAS 
> before writing protected data and updated again with volatile write 
> after it). So, what happens if this CAS is not atomic from the 
> standpoint of the memory model, but is modelled as two separate 
> operations, the first being volatile read, the second one being 
> volatile write?
>
> As you've correctly observed, in this model non-volatile writes to the 
> protected state can be reordered in between the volatile read and 
> volatile write that constitute CAS. If this happens, reader can read 
> an inconsistent snapshot of the protected state without detecting this 
> fact (validate will return true), if all reader's actions take effect 
> in between those volatile read and volatile write that constitute CAS. 
> Q.E.D. From the memory model perspective (in JLS Chapter 17 terms) CAS 
> has to be represented as one "inter-thread action" that has effect of 
> both volatile read and volatile write. Otherwise, StampedLock idiom is 
> broken.
>
> *From:*Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
> *Sent:* Thursday, April 24, 2014 1:20 AM
> *To:* Roman Elizarov
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Stricter read ordering
>
> Can you quote the exact spot? I see it is quite different from your 
> suggestion, and where I look it doesn't seem atomicity of CAS matters.
>
>
> Alex
>
> On 23/04/2014 20:57, Roman Elizarov wrote:
>
>     You are right. You cannot just split CAS into load and store this
>     way. Actually, if you analyze required barriers for write path in
>     the same way as I did for read path (remember, that writer has to
>     have StoreStore barrier before version write and subsequent
>     non-volatile writes), you see that you need to insert volatile
>     read _/after/_ the version.write() in the write path, so it becomes:
>
>     Writer does (in PO): version.volatileWrite();  {StoreLoad
>     emitted}; something.volatileRead(); {LoadStore emitted} x.write();
>     y.write(); {StoreStore emitted}; version.write();
>
>     This effectively gives you StoreStore barrier between version
>     write and a first non-volatile write of protected data state.
>     Ordering those two volatile operations at the beginning of write
>     path the other way around, as in your example below, does not
>     provide the necessary barrier to guarantee correctness of this idiom.
>
>     CAS has to do both volatile load and store in atomic and
>     indivisible way, so that you cannot reorder subsequent normal
>     write into the "middle of" CAS. This is not explicitly stated in
>     the CAS spec as I can see (the wording about "atomic" behavior of
>     CAS and about its load/store semantics are rather far apart, so it
>     is debatable), but this is the property of CAS that Java 8's
>     implementation of StampedLock relies upon, too.
>
>     *From:*concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of
>     *Oleksandr Otenko
>     *Sent:* Wednesday, April 23, 2014 11:12 PM
>     *Cc:* concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     *Subject:* Re: [concurrency-interest] Stricter read ordering
>
>     No. If CAS is implemented as a volatile load followed by a
>     volatile store, the effect I describe is possible. There is no
>     need for a weaker implementation for CAS.
>
>     Watch:
>
>     replace version.compareAndSet with get and set:
>
>     v0=version.get();
>     version.set(v0 | WRITE);
>     this.x=x; // normal write can go ahead of the volatile write, as
>     per the cookbook
>
>     Or, in JMM terms, there is no edge enforcing this.x=x by the
>     writer to appear strictly after x=this.x by the reader.
>
>     Alex
>
>     On 23/04/2014 19:34, Roman Elizarov wrote:
>
>         There was no light in that discussion. CAS is currently spec'd
>         as volatile load and volatile store.  Period. If someone
>         implements CAS on ARM with weaker guarantees that violate this
>         spec, then StampedLock in Java 8 solution also becomes broken
>         for the same reason you've outlined below.
>
>
>         On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko"
>         <oleksandr.otenko at oracle.com
>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>             In light of the recent discussion of the semantics of CAS,
>             this solution is not correct.
>
>             The outcome of that discussion is that the atomicity of
>             CAS is only guaranteed with respect to the variable being
>             CASed. This does not matter on x86, but on ARM, as I
>             understand, the CAS will be implemented as two
>             instructions that only preclude concurrent stores to the
>             variable being CASed - which does not preclude reordering
>             the normal stores following CAS with the "volatile store"
>             part of CAS.
>
>             So, here:
>
>
>
>                      version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                      // then write protected data (non-volatile writes)
>
>                      this.x = x;
>
>                      this.y = y;
>
>             this.x=x; may be observed before compareAndSet completes.
>
>             The correct solution should produce:
>
>             writer:
>             vwrite(v,v+1)
>             *vread(s,_)
>             *write(x,_)
>             write(y,_)
>             vwrite(v,v+1)
>
>             reader:
>             vread(v,_)
>             read(x,_)
>             read(y,_)
>             *vwrite(s,_)
>             *vread(v,_)
>
>             For example:
>
>             writer:
>             // synchronized
>             long next = this.version;
>             this.version=next+1; // odd version means mutation underway
>             long tmp=static_volatile_dummy;
>             this.x=x;
>             this.y=y;
>             this.version=next+2; // even version means immutable
>
>             reader:
>             long v;
>             do{
>               while((v=this.version) &1 != 0); // wait for version to
>             become even
>               x=this.x;
>               y=this.y;
>               static_volatile_dummy=v;
>             }while(this.version != v); // check the version didn't change
>
>
>             Proof:
>
>             It is not necessary to consider all possible reorderings
>             individually. It is sufficient to consider relative
>             ordering of volatile reads and writes.
>
>             All writers ensure exclusive access to this.x and this.y,
>             so we only need to consider one writer performing
>             modifications in a loop.
>
>             If volatile read of static_volatile_dummy appears after a
>             volatile write of static_volatile_dummy in synchronization
>             order, the former synchronizes-with the latter, and the
>             normal reads of this.x and this.y by the reader
>             happen-before the normal writes of those variables by the
>             writer (transitive closure of program orders). So, the
>             readers never see normal writes of those writers.
>
>             Now consider the writers whose read of
>             static_volatile_dummy does not synchronize-with the
>             writes. The reader may temporarily observe some values,
>             but will only terminate the loop after observing the
>             values of this.x and this.y whose write appear before the
>             volatile write of a even version: the first loop ensures
>             we only look at writes preceding a write of a even
>             version, the condition of the outer loop ensures no other
>             volatile writes to version appear in synchronization
>             order. This means that the first loop synchronizes-with
>             the last write of a even version, hence, through
>             transitive closure of program orders the normal writes of
>             this.x and this.y happen-before the normal reads. The
>             outer condition ensures that since no other volatile
>             writes of version appear in synchronization order, the
>             volatile read of static_volatile_dummy after all such
>             writes will synchronize-with the volatile write of
>             static_volatile_dummy of the reader (and their normal
>             writes won't be observed, as per the proof in the previous
>             paragraph).
>
>
>             This concludes the proof that the reader always observes
>             the consistent view of this.x and this.y.
>
>
>
>             Alex
>
>
>             On 23/04/2014 15:16, Roman Elizarov wrote:
>
>                 The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>
>                   
>
>                 Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>
>                   
>
>                 So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>
>                   
>
>                 class VersionedData {
>
>                      // bit that we'll use to indicate that the state is being written to
>
>                      private static final int WRITE = 1 << 31;
>
>                      // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>
>                      private final AtomicInteger version = new AtomicInteger();
>
>                   
>
>                      // this is the data I protect, in reality there is much more protected state
>
>                      private int x, y;
>
>                   
>
>                      public synchronized void update(int x, int y) {
>
>                          // I guarantee single writers to this method,
>
>                          // illustrated with 'synchronized' in this simplification
>
>                          // first use CAS to mark version as being written to
>
>                          int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>
>                          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>
>                          // then write protected data (non-volatile writes)
>
>                          this.x = x;
>
>                          this.y = y;
>
>                          // then increment version and reset write bit
>
>                          version.set((v0 + 1) & ~WRITE);
>
>                      }
>
>                   
>
>                      public DataCarrier read() {
>
>                          // I allow multiple readers, so this method is not synchronized
>
>                          int x, y;
>
>                          int v0;
>
>                          do {
>
>                              // first read version
>
>                              v0 = version.get();
>
>                              if ((v0 & WRITE) != 0)
>
>                                  continue; // immediately abort, because write in progress was detected
>
>                              // then read protected data
>
>                              x = this.x;
>
>                              y = this.y;
>
>                              // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>
>                          } while (!version.compareAndSet(v0, v0));
>
>                          return new DataCarrier(x, y);
>
>                      }
>
>                 }
>
>                   
>
>                 -----Original Message-----
>
>                 From:concurrency-interest-bounces at cs.oswego.edu  <mailto:concurrency-interest-bounces at cs.oswego.edu>  [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>
>                 Sent: Wednesday, April 23, 2014 5:36 PM
>
>                 To: Tobias Lindaaker;concurrency-interest at cs.oswego.edu  <mailto:concurrency-interest at cs.oswego.edu>
>
>                 Subject: Re: [concurrency-interest] Stricter read ordering
>
>                   
>
>                 On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>
>                     Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>
>                     to do exactly what I want, and if I was fortunate enough to be able to
>
>                     move to Java 8 I would use it. Unfortunately we are still stuck on
>
>                     Java 7. We even have customers who are still strongly requesting Java
>
>                     6 compatibility.
>
>                 These constraints make the problem unresolvable.
>
>                   
>
>                 You might want to look for pre-JDK8 prototype for StampedLock [1]:
>
>                   
>
>                       * As noted in Boehm's paper (above), sequence validation (mainly
>
>                       * method validate()) requires stricter ordering rules than apply
>
>                       * to normal volatile reads (of "state").  In the absence of (but
>
>                       * continual hope for) explicit JVM support of intrinsics with
>
>                       * double-sided reordering prohibition, or corresponding fence
>
>                       * intrinsics, we for now uncomfortably rely on the fact that the
>
>                       * Unsafe.getXVolatile intrinsic must have this property
>
>                       * (syntactic volatile reads do not) for internal purposes anyway,
>
>                       * even though it is not documented.
>
>                   
>
>                      public boolean validate(long stamp) {
>
>                          return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>
>                      }
>
>                   
>
>                 But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>
>                   
>
>                 Thanks,
>
>                 -Aleksey.
>
>                   
>
>                 [1]
>
>                 http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>
>                 _______________________________________________
>
>                 Concurrency-interest mailing list
>
>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>                   
>
>                 _______________________________________________
>
>                 Concurrency-interest mailing list
>
>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>
>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>             _______________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/d7d2f0e9/attachment-0001.html>

From elizarov at devexperts.com  Thu Apr 24 12:00:29 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Thu, 24 Apr 2014 16:00:29 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5359034E.8090806@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>
	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>
	<53581080.3010008@oracle.com>
	<f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>
	<53582E77.1060601@oracle.com>
	<aea9a435189f43ae94bde548414a79c7@exchmb01.office.devexperts.com>,
	<5359034E.8090806@oracle.com>
Message-ID: <D0836E59-2AF4-4132-902F-19D6968E5E58@devexperts.com>

Also, it would be an interesting toy project to figure out which version (CAS or two volatile read/write ops in proper order) works faster in practise on different CPUs. Neither is satisfactory in practise anyway. Too bad we have direct access to fences only in Java 8 and still only via unsafe.

For my project, I would take the same approach that is used in StampedLock backport. I need CAS on write for lock anyway and I'll have to believe that Unsafe.getXXXVolatile provides the neccessary barrier in practise (I have not looked yet at its intinsic source to see why that should be true, though). I need a lock-free atomic snapshot (cannot spin forever while writer is suspended in the middle of write), so it has a writer-helping-reader path, too, but the core logic is still StampedLock-like.

On 24 ???. 2014 ?., at 16:32, "Oleksandr Otenko" <oleksandr.otenko at oracle.com<mailto:oleksandr.otenko at oracle.com>> wrote:

Yes, I need to retract my statement about CAS. I checked the CAS thread again. It does say that "just" a pair of load/store is not adequate for Java. So, then the CAS-based version must be OK. I would still like to point out that my version doesn't rely on underspecified semantics of CAS.

Alex

On 24/04/2014 09:52, Roman Elizarov wrote:
Below is a solution to the original problem posted by Tobias using Java 8 StamedLock. I?ve expanded the actual implementation of StampedLock?s operations in comments for the ease of reference in the further discussion:

class StampedData {
    // THE NEXT LINE ESSENTIALLY CONTAINS long state
    private final StampedLock lock = new StampedLock();

    // this is the data I protect, in reality there is much more protected state
    private int x, y;

    public synchronized void update(int x, int y) {
        // I guarantee single writers to this method,
        // illustrated with 'synchronized' in this simplification
        // first acquire write lock
        // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; state.CAS(stamp, stamp += WBIT);
        long stamp = lock.tryWriteLock(); // always succeeds in single-writer case
        // then write protected data (non-volatile writes)
        this.x = x;
        this.y = y;
        // then release write lock
        // THE NEXT LINE ESSENTIALLY EXPANDS TO: state = stamp + WBIT;
        lock.unlockWrite(stamp);
    }

    public DataCarrier read() {
        // I allow multiple readers, so this method is not synchronized
        int x, y;
        int v0;
        while (true) {
            // first try optimistic read
            // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; // if was not locked by writer
            long stamp = lock.tryOptimisticRead();
            if (stamp == 0)
                continue; // immediately abort, because write in progress was detected
            // then read protected data
            x = this.x;
            y = this.y;
            // validate to make sure that the read was consistent
            // THE NEXT LINE ESSENTIALLY EXPANDS TO: loadFence; if (state == stamp) break;
            if (lock.validate(stamp))
                break;
        }
        return new DataCarrier(x, y);
    }
}

As you can see, it is virtually the same code as I?ve presented in my original solution where ?version? is replaced by StampedLock?s ?state?. The primary difference can be found in the read path, when StampedLock uses loadFence to ensure LoadLoad barrier after the read of the protected data and before checking that state did not change. There is no Unsafe.loadFence before Java 8, so my solution had to resort to what Hans Boehm named ?read-dont-modify-write? operation using CAS.

Now, let us take a closer look at the write path in update method. You can see that StampedLock?s write path is the same as the write path that was used in my original solution (version is updated with CAS before writing protected data and updated again with volatile write after it). So, what happens if this CAS is not atomic from the standpoint of the memory model, but is modelled as two separate operations, the first being volatile read, the second one being volatile write?

As you?ve correctly observed, in this model non-volatile writes to the protected state can be reordered in between the volatile read and volatile write that constitute CAS. If this happens, reader can read an inconsistent snapshot of the protected state without detecting this fact (validate will return true), if all reader?s actions take effect in between those volatile read and volatile write that constitute CAS. Q.E.D. From the memory model perspective (in JLS Chapter 17 terms) CAS has to be represented as one ?inter-thread action? that has effect of both volatile read and volatile write. Otherwise, StampedLock idiom is broken.

From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
Sent: Thursday, April 24, 2014 1:20 AM
To: Roman Elizarov
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Stricter read ordering

Can you quote the exact spot? I see it is quite different from your suggestion, and where I look it doesn't seem atomicity of CAS matters.


Alex

On 23/04/2014 20:57, Roman Elizarov wrote:
You are right. You cannot just split CAS into load and store this way. Actually, if you analyze required barriers for write path in the same way as I did for read path (remember, that writer has to have StoreStore barrier before version write and subsequent non-volatile writes), you see that you need to insert volatile read _after_ the version.write() in the write path, so it becomes:

Writer does (in PO): version.volatileWrite();  {StoreLoad emitted}; something.volatileRead(); {LoadStore emitted} x.write(); y.write(); {StoreStore emitted}; version.write();

This effectively gives you StoreStore barrier between version write and a first non-volatile write of protected data state. Ordering those two volatile operations at the beginning of write path the other way around, as in your example below, does not provide the necessary barrier to guarantee correctness of this idiom.

CAS has to do both volatile load and store in atomic and indivisible way, so that you cannot reorder subsequent normal write into the ?middle of? CAS. This is not explicitly stated in the CAS spec as I can see (the wording about ?atomic? behavior of CAS and about its load/store semantics are rather far apart, so it is debatable), but this is the property of CAS that Java 8?s implementation of StampedLock relies upon, too.

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Oleksandr Otenko
Sent: Wednesday, April 23, 2014 11:12 PM
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Stricter read ordering

No. If CAS is implemented as a volatile load followed by a volatile store, the effect I describe is possible. There is no need for a weaker implementation for CAS.

Watch:

replace version.compareAndSet with get and set:

v0=version.get();
version.set(v0 | WRITE);
this.x=x; // normal write can go ahead of the volatile write, as per the cookbook

Or, in JMM terms, there is no edge enforcing this.x=x by the writer to appear strictly after x=this.x by the reader.

Alex
On 23/04/2014 19:34, Roman Elizarov wrote:
There was no light in that discussion. CAS is currently spec'd as volatile load and volatile store.  Period. If someone implements CAS on ARM with weaker guarantees that violate this spec, then StampedLock in Java 8 solution also becomes broken for the same reason you've outlined below.

On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko" <oleksandr.otenko at oracle.com<mailto:oleksandr.otenko at oracle.com>> wrote:
In light of the recent discussion of the semantics of CAS, this solution is not correct.

The outcome of that discussion is that the atomicity of CAS is only guaranteed with respect to the variable being CASed. This does not matter on x86, but on ARM, as I understand, the CAS will be implemented as two instructions that only preclude concurrent stores to the variable being CASed - which does not preclude reordering the normal stores following CAS with the "volatile store" part of CAS.

So, here:




        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;
this.x=x; may be observed before compareAndSet completes.

The correct solution should produce:

writer:
vwrite(v,v+1)
vread(s,_)
write(x,_)
write(y,_)
vwrite(v,v+1)

reader:
vread(v,_)
read(x,_)
read(y,_)
vwrite(s,_)
vread(v,_)

For example:

writer:
// synchronized
long next = this.version;
this.version=next+1; // odd version means mutation underway
long tmp=static_volatile_dummy;
this.x=x;
this.y=y;
this.version=next+2; // even version means immutable

reader:
long v;
do{
  while((v=this.version) &1 != 0); // wait for version to become even
  x=this.x;
  y=this.y;
  static_volatile_dummy=v;
}while(this.version != v); // check the version didn't change


Proof:

It is not necessary to consider all possible reorderings individually. It is sufficient to consider relative ordering of volatile reads and writes.

All writers ensure exclusive access to this.x and this.y, so we only need to consider one writer performing modifications in a loop.

If volatile read of static_volatile_dummy appears after a volatile write of static_volatile_dummy in synchronization order, the former synchronizes-with the latter, and the normal reads of this.x and this.y by the reader happen-before the normal writes of those variables by the writer (transitive closure of program orders). So, the readers never see normal writes of those writers.

Now consider the writers whose read of static_volatile_dummy does not synchronize-with the writes. The reader may temporarily observe some values, but will only terminate the loop after observing the values of this.x and this.y whose write appear before the volatile write of a even version: the first loop ensures we only look at writes preceding a write of a even version, the condition of the outer loop ensures no other volatile writes to version appear in synchronization order. This means that the first loop synchronizes-with the last write of a even version, hence, through transitive closure of program orders the normal writes of this.x and this.y happen-before the normal reads. The outer condition ensures that since no other volatile writes of version appear in synchronization order, the volatile read of static_volatile_dummy after all such writes will synchronize-with the volatile write of static_volatile_dummy of the reader (and their normal writes won't be observed, as per the proof in the previous paragraph).


This concludes the proof that the reader always observes the consistent view of this.x and this.y.



Alex


On 23/04/2014 15:16, Roman Elizarov wrote:

The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.



Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.



So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.



class VersionedData {

    // bit that we'll use to indicate that the state is being written to

    private static final int WRITE = 1 << 31;

    // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)

    private final AtomicInteger version = new AtomicInteger();



    // this is the data I protect, in reality there is much more protected state

    private int x, y;



    public synchronized void update(int x, int y) {

        // I guarantee single writers to this method,

        // illustrated with 'synchronized' in this simplification

        // first use CAS to mark version as being written to

        int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry

        version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM

        // then write protected data (non-volatile writes)

        this.x = x;

        this.y = y;

        // then increment version and reset write bit

        version.set((v0 + 1) & ~WRITE);

    }



    public DataCarrier read() {

        // I allow multiple readers, so this method is not synchronized

        int x, y;

        int v0;

        do {

            // first read version

            v0 = version.get();

            if ((v0 & WRITE) != 0)

                continue; // immediately abort, because write in progress was detected

            // then read protected data

            x = this.x;

            y = this.y;

            // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time

        } while (!version.compareAndSet(v0, v0));

        return new DataCarrier(x, y);

    }

}



-----Original Message-----

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev

Sent: Wednesday, April 23, 2014 5:36 PM

To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>

Subject: Re: [concurrency-interest] Stricter read ordering



On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:

Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems

to do exactly what I want, and if I was fortunate enough to be able to

move to Java 8 I would use it. Unfortunately we are still stuck on

Java 7. We even have customers who are still strongly requesting Java

6 compatibility.

These constraints make the problem unresolvable.



You might want to look for pre-JDK8 prototype for StampedLock [1]:



     * As noted in Boehm's paper (above), sequence validation (mainly

     * method validate()) requires stricter ordering rules than apply

     * to normal volatile reads (of "state").  In the absence of (but

     * continual hope for) explicit JVM support of intrinsics with

     * double-sided reordering prohibition, or corresponding fence

     * intrinsics, we for now uncomfortably rely on the fact that the

     * Unsafe.getXVolatile intrinsic must have this property

     * (syntactic volatile reads do not) for internal purposes anyway,

     * even though it is not documented.



    public boolean validate(long stamp) {

        return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);

    }



But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.



Thanks,

-Aleksey.



[1]

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/0603d3f9/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Apr 24 12:05:31 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 24 Apr 2014 17:05:31 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <D0836E59-2AF4-4132-902F-19D6968E5E58@devexperts.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>	<5357B51D.9000206@oracle.com>	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>	<5357C1CE.30003@oracle.com>	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>,
	<5357FA3B.8050100@oracle.com>	<81B4DC8B-13AD-40E1-8E22-3031E81172AC@devexperts.com>	<53581080.3010008@oracle.com>	<f043b906c466434e836c826a80870c8c@exchmb01.office.devexperts.com>	<53582E77.1060601@oracle.com>	<aea9a435189f43ae94bde548414a79c7@exchmb01.office.devexperts.com>,
	<5359034E.8090806@oracle.com>
	<D0836E59-2AF4-4132-902F-19D6968E5E58@devexperts.com>
Message-ID: <5359364B.8040303@oracle.com>

In theory, both read and write of static_volatile_dummy can be optimized 
out, leaving just the barriers - the writer doesn't use the value, so no 
instruction needs issuing, and, given no other code reading 
static_volatile_dummy exists, the reader doesn't need to commit the 
actual write. Having just barriers should be faster than CAS.

Alex

On 24/04/2014 17:00, Roman Elizarov wrote:
> Also, it would be an interesting toy project to figure out which 
> version (CAS or two volatile read/write ops in proper order) works 
> faster in practise on different CPUs. Neither is satisfactory in 
> practise anyway. Too bad we have direct access to fences only in Java 
> 8 and still only via unsafe.
>
> For my project, I would take the same approach that is used in 
> StampedLock backport. I need CAS on write for lock anyway and I'll 
> have to believe that Unsafe.getXXXVolatile provides the neccessary 
> barrier in practise (I have not looked yet at its intinsic source to 
> see why that should be true, though). I need a lock-free atomic 
> snapshot (cannot spin forever while writer is suspended in the middle 
> of write), so it has a writer-helping-reader path, too, but the core 
> logic is still StampedLock-like.
>
> On 24 ???. 2014 ?., at 16:32, "Oleksandr Otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>> Yes, I need to retract my statement about CAS. I checked the CAS 
>> thread again. It does say that "just" a pair of load/store is not 
>> adequate for Java. So, then the CAS-based version must be OK. I would 
>> still like to point out that my version doesn't rely on 
>> underspecified semantics of CAS.
>>
>> Alex
>>
>> On 24/04/2014 09:52, Roman Elizarov wrote:
>>>
>>> Below is a solution to the original problem posted by Tobias using 
>>> Java 8 StamedLock. I?ve expanded the actual implementation of 
>>> StampedLock?s operations in comments for the ease of reference in 
>>> the further discussion:
>>>
>>> class StampedData {
>>>
>>>     // THE NEXT LINE ESSENTIALLY CONTAINS long state
>>>
>>>     private final StampedLock lock = new StampedLock();
>>>
>>>     // this is the data I protect, in reality there is much more 
>>> protected state
>>>
>>>     private int x, y;
>>>
>>>     public synchronized void update(int x, int y) {
>>>
>>>         // I guarantee single writers to this method,
>>>
>>>         // illustrated with 'synchronized' in this simplification
>>>
>>>         // first acquire write lock
>>>
>>>         // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; 
>>> state.CAS(stamp, stamp += WBIT);
>>>
>>>         long stamp = lock.tryWriteLock(); // always succeeds in 
>>> single-writer case
>>>
>>>         // then write protected data (non-volatile writes)
>>>
>>>         this.x = x;
>>>
>>>         this.y = y;
>>>
>>>         // then release write lock
>>>
>>>         // THE NEXT LINE ESSENTIALLY EXPANDS TO: state = stamp + WBIT;
>>>
>>>         lock.unlockWrite(stamp);
>>>
>>>     }
>>>
>>>     public DataCarrier read() {
>>>
>>>         // I allow multiple readers, so this method is not synchronized
>>>
>>>         int x, y;
>>>
>>>         int v0;
>>>
>>>         while (true) {
>>>
>>>             // first try optimistic read
>>>
>>>             // THE NEXT LINE ESSENTIALLY EXPANDS TO: stamp = state; 
>>> // if was not locked by writer
>>>
>>>             long stamp = lock.tryOptimisticRead();
>>>
>>>             if (stamp == 0)
>>>
>>>                 continue; // immediately abort, because write in 
>>> progress was detected
>>>
>>>             // then read protected data
>>>
>>>             x = this.x;
>>>
>>>             y = this.y;
>>>
>>>             // validate to make sure that the read was consistent
>>>
>>>             // THE NEXT LINE ESSENTIALLY EXPANDS TO: loadFence; if 
>>> (state == stamp) break;
>>>
>>>             if (lock.validate(stamp))
>>>
>>>                 break;
>>>
>>>         }
>>>
>>>         return new DataCarrier(x, y);
>>>
>>>     }
>>>
>>> }
>>>
>>> As you can see, it is virtually the same code as I?ve presented in 
>>> my original solution where ?version? is replaced by StampedLock?s 
>>> ?state?. The primary difference can be found in the read path, when 
>>> StampedLock uses loadFence to ensure LoadLoad barrier after the read 
>>> of the protected data and before checking that state did not change. 
>>> There is no Unsafe.loadFence before Java 8, so my solution had to 
>>> resort to what Hans Boehm named ?read-dont-modify-write? operation 
>>> using CAS.
>>>
>>> Now, let us take a closer look at the write path in update method. 
>>> You can see that StampedLock?s write path is the same as the write 
>>> path that was used in my original solution (version is updated with 
>>> CAS before writing protected data and updated again with volatile 
>>> write after it). So, what happens if this CAS is not atomic from the 
>>> standpoint of the memory model, but is modelled as two separate 
>>> operations, the first being volatile read, the second one being 
>>> volatile write?
>>>
>>> As you?ve correctly observed, in this model non-volatile writes to 
>>> the protected state can be reordered in between the volatile read 
>>> and volatile write that constitute CAS. If this happens, reader can 
>>> read an inconsistent snapshot of the protected state without 
>>> detecting this fact (validate will return true), if all reader?s 
>>> actions take effect in between those volatile read and volatile 
>>> write that constitute CAS. Q.E.D. From the memory model perspective 
>>> (in JLS Chapter 17 terms) CAS has to be represented as one 
>>> ?inter-thread action? that has effect of both volatile read and 
>>> volatile write. Otherwise, StampedLock idiom is broken.
>>>
>>> *From:*Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
>>> *Sent:* Thursday, April 24, 2014 1:20 AM
>>> *To:* Roman Elizarov
>>> *Cc:* concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] Stricter read ordering
>>>
>>> Can you quote the exact spot? I see it is quite different from your 
>>> suggestion, and where I look it doesn't seem atomicity of CAS matters.
>>>
>>>
>>> Alex
>>>
>>> On 23/04/2014 20:57, Roman Elizarov wrote:
>>>
>>>     You are right. You cannot just split CAS into load and store
>>>     this way. Actually, if you analyze required barriers for write
>>>     path in the same way as I did for read path (remember, that
>>>     writer has to have StoreStore barrier before version write and
>>>     subsequent non-volatile writes), you see that you need to insert
>>>     volatile read _/after/_ the version.write() in the write path,
>>>     so it becomes:
>>>
>>>     Writer does (in PO): version.volatileWrite();  {StoreLoad
>>>     emitted}; something.volatileRead(); {LoadStore emitted}
>>>     x.write(); y.write(); {StoreStore emitted}; version.write();
>>>
>>>     This effectively gives you StoreStore barrier between version
>>>     write and a first non-volatile write of protected data state.
>>>     Ordering those two volatile operations at the beginning of write
>>>     path the other way around, as in your example below, does not
>>>     provide the necessary barrier to guarantee correctness of this
>>>     idiom.
>>>
>>>     CAS has to do both volatile load and store in atomic and
>>>     indivisible way, so that you cannot reorder subsequent normal
>>>     write into the ?middle of? CAS. This is not explicitly stated in
>>>     the CAS spec as I can see (the wording about ?atomic? behavior
>>>     of CAS and about its load/store semantics are rather far apart,
>>>     so it is debatable), but this is the property of CAS that Java
>>>     8?s implementation of StampedLock relies upon, too.
>>>
>>>     *From:*concurrency-interest-bounces at cs.oswego.edu
>>>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>     [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf
>>>     Of *Oleksandr Otenko
>>>     *Sent:* Wednesday, April 23, 2014 11:12 PM
>>>     *Cc:* concurrency-interest at cs.oswego.edu
>>>     <mailto:concurrency-interest at cs.oswego.edu>
>>>     *Subject:* Re: [concurrency-interest] Stricter read ordering
>>>
>>>     No. If CAS is implemented as a volatile load followed by a
>>>     volatile store, the effect I describe is possible. There is no
>>>     need for a weaker implementation for CAS.
>>>
>>>     Watch:
>>>
>>>     replace version.compareAndSet with get and set:
>>>
>>>     v0=version.get();
>>>     version.set(v0 | WRITE);
>>>     this.x=x; // normal write can go ahead of the volatile write, as
>>>     per the cookbook
>>>
>>>     Or, in JMM terms, there is no edge enforcing this.x=x by the
>>>     writer to appear strictly after x=this.x by the reader.
>>>
>>>     Alex
>>>
>>>     On 23/04/2014 19:34, Roman Elizarov wrote:
>>>
>>>         There was no light in that discussion. CAS is currently
>>>         spec'd as volatile load and volatile store.  Period. If
>>>         someone implements CAS on ARM with weaker guarantees that
>>>         violate this spec, then StampedLock in Java 8 solution also
>>>         becomes broken for the same reason you've outlined below.
>>>
>>>
>>>         On 23 ???. 2014 ?., at 21:42, "Oleksandr Otenko"
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             In light of the recent discussion of the semantics of
>>>             CAS, this solution is not correct.
>>>
>>>             The outcome of that discussion is that the atomicity of
>>>             CAS is only guaranteed with respect to the variable
>>>             being CASed. This does not matter on x86, but on ARM, as
>>>             I understand, the CAS will be implemented as two
>>>             instructions that only preclude concurrent stores to the
>>>             variable being CASed - which does not preclude
>>>             reordering the normal stores following CAS with the
>>>             "volatile store" part of CAS.
>>>
>>>             So, here:
>>>
>>>
>>>
>>>                      version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>>
>>>                      // then write protected data (non-volatile writes)
>>>
>>>                      this.x = x;
>>>
>>>                      this.y = y;
>>>
>>>             this.x=x; may be observed before compareAndSet completes.
>>>
>>>             The correct solution should produce:
>>>
>>>             writer:
>>>             vwrite(v,v+1)
>>>             *vread(s,_)
>>>             *write(x,_)
>>>             write(y,_)
>>>             vwrite(v,v+1)
>>>
>>>             reader:
>>>             vread(v,_)
>>>             read(x,_)
>>>             read(y,_)
>>>             *vwrite(s,_)
>>>             *vread(v,_)
>>>
>>>             For example:
>>>
>>>             writer:
>>>             // synchronized
>>>             long next = this.version;
>>>             this.version=next+1; // odd version means mutation underway
>>>             long tmp=static_volatile_dummy;
>>>             this.x=x;
>>>             this.y=y;
>>>             this.version=next+2; // even version means immutable
>>>
>>>             reader:
>>>             long v;
>>>             do{
>>>               while((v=this.version) &1 != 0); // wait for version
>>>             to become even
>>>               x=this.x;
>>>               y=this.y;
>>>               static_volatile_dummy=v;
>>>             }while(this.version != v); // check the version didn't
>>>             change
>>>
>>>
>>>             Proof:
>>>
>>>             It is not necessary to consider all possible reorderings
>>>             individually. It is sufficient to consider relative
>>>             ordering of volatile reads and writes.
>>>
>>>             All writers ensure exclusive access to this.x and
>>>             this.y, so we only need to consider one writer
>>>             performing modifications in a loop.
>>>
>>>             If volatile read of static_volatile_dummy appears after
>>>             a volatile write of static_volatile_dummy in
>>>             synchronization order, the former synchronizes-with the
>>>             latter, and the normal reads of this.x and this.y by the
>>>             reader happen-before the normal writes of those
>>>             variables by the writer (transitive closure of program
>>>             orders). So, the readers never see normal writes of
>>>             those writers.
>>>
>>>             Now consider the writers whose read of
>>>             static_volatile_dummy does not synchronize-with the
>>>             writes. The reader may temporarily observe some values,
>>>             but will only terminate the loop after observing the
>>>             values of this.x and this.y whose write appear before
>>>             the volatile write of a even version: the first loop
>>>             ensures we only look at writes preceding a write of a
>>>             even version, the condition of the outer loop ensures no
>>>             other volatile writes to version appear in
>>>             synchronization order. This means that the first loop
>>>             synchronizes-with the last write of a even version,
>>>             hence, through transitive closure of program orders the
>>>             normal writes of this.x and this.y happen-before the
>>>             normal reads. The outer condition ensures that since no
>>>             other volatile writes of version appear in
>>>             synchronization order, the volatile read of
>>>             static_volatile_dummy after all such writes will
>>>             synchronize-with the volatile write of
>>>             static_volatile_dummy of the reader (and their normal
>>>             writes won't be observed, as per the proof in the
>>>             previous paragraph).
>>>
>>>
>>>             This concludes the proof that the reader always observes
>>>             the consistent view of this.x and this.y.
>>>
>>>
>>>
>>>             Alex
>>>
>>>
>>>             On 23/04/2014 15:16, Roman Elizarov wrote:
>>>
>>>                 The original problem itself is solvable, albeit with a different algorithm. It's funny, that we've discussed the same problem today internally and then I see this thread on concurrency-interest list.
>>>
>>>                   
>>>
>>>                 Let me state the problem first. There is a multi-word state that we have to read and write in non-volatile way (if reads and writes of our state can be made volatile, then solution is trivial and is not of a much interest). We need to implement single-writer multi-reader atomic snapshot of this multi-word state with the primitives described in and under the constraints of the Java Memory Model (think Java 5+). The read does not have to be lock-free. It just needs to detect that snapshot being read is not consistent. In original question author was Ok for reader to spin in case of the read/write conflict, but we actually have a different problem where it is Ok for reader to abandon the read attempt altogether. The key is to detect this conflict or to return an atomic snapshot of the protected state if there is no read/write conflict.
>>>
>>>                   
>>>
>>>                 So, here is a solution. It can be proven to work on current version of JMM (starting Java 5 and later) in the JMM's model, by analyzing possible executions and their corresponding SO, SW, and HB relations. It requires just one extra int of state (instead of two), but this int needs to be CAS-ed both on read and on write to ensure proper happens-before edges and to guarantee the consistent read of non-volatile state. The proof of this algorithm's correctness is left as an exercise for the reader. It will not scale, though, if there are many concurrent readers, because of the CAS in read path.
>>>
>>>                   
>>>
>>>                 class VersionedData {
>>>
>>>                      // bit that we'll use to indicate that the state is being written to
>>>
>>>                      private static final int WRITE = 1 << 31;
>>>
>>>                      // we need to CAS version (in practise we'll do it via Unsafe to avoid extra object)
>>>
>>>                      private final AtomicInteger version = new AtomicInteger();
>>>
>>>                   
>>>
>>>                      // this is the data I protect, in reality there is much more protected state
>>>
>>>                      private int x, y;
>>>
>>>                   
>>>
>>>                      public synchronized void update(int x, int y) {
>>>
>>>                          // I guarantee single writers to this method,
>>>
>>>                          // illustrated with 'synchronized' in this simplification
>>>
>>>                          // first use CAS to mark version as being written to
>>>
>>>                          int v0 = version.get(); // can be non-volatile read, but then the following CAS can fail and needs to retry
>>>
>>>                          version.compareAndSet(v0, v0 | WRITE); // always succeeds in single-writer case, ensures proper HB edges for JMM
>>>
>>>                          // then write protected data (non-volatile writes)
>>>
>>>                          this.x = x;
>>>
>>>                          this.y = y;
>>>
>>>                          // then increment version and reset write bit
>>>
>>>                          version.set((v0 + 1) & ~WRITE);
>>>
>>>                      }
>>>
>>>                   
>>>
>>>                      public DataCarrier read() {
>>>
>>>                          // I allow multiple readers, so this method is not synchronized
>>>
>>>                          int x, y;
>>>
>>>                          int v0;
>>>
>>>                          do {
>>>
>>>                              // first read version
>>>
>>>                              v0 = version.get();
>>>
>>>                              if ((v0 & WRITE) != 0)
>>>
>>>                                  continue; // immediately abort, because write in progress was detected
>>>
>>>                              // then read protected data
>>>
>>>                              x = this.x;
>>>
>>>                              y = this.y;
>>>
>>>                              // use CAS to check that version is still the same and to ensure proper HB edges for JMM at the same time
>>>
>>>                          } while (!version.compareAndSet(v0, v0));
>>>
>>>                          return new DataCarrier(x, y);
>>>
>>>                      }
>>>
>>>                 }
>>>
>>>                   
>>>
>>>                 -----Original Message-----
>>>
>>>                 From:concurrency-interest-bounces at cs.oswego.edu  <mailto:concurrency-interest-bounces at cs.oswego.edu>  [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
>>>
>>>                 Sent: Wednesday, April 23, 2014 5:36 PM
>>>
>>>                 To: Tobias Lindaaker;concurrency-interest at cs.oswego.edu  <mailto:concurrency-interest at cs.oswego.edu>
>>>
>>>                 Subject: Re: [concurrency-interest] Stricter read ordering
>>>
>>>                   
>>>
>>>                 On 04/23/2014 05:05 PM, Tobias Lindaaker wrote:
>>>
>>>                     Yes, I had a look at StampedLock and Unsafe.loadFence(), and it seems
>>>
>>>                     to do exactly what I want, and if I was fortunate enough to be able to
>>>
>>>                     move to Java 8 I would use it. Unfortunately we are still stuck on
>>>
>>>                     Java 7. We even have customers who are still strongly requesting Java
>>>
>>>                     6 compatibility.
>>>
>>>                 These constraints make the problem unresolvable.
>>>
>>>                   
>>>
>>>                 You might want to look for pre-JDK8 prototype for StampedLock [1]:
>>>
>>>                   
>>>
>>>                       * As noted in Boehm's paper (above), sequence validation (mainly
>>>
>>>                       * method validate()) requires stricter ordering rules than apply
>>>
>>>                       * to normal volatile reads (of "state").  In the absence of (but
>>>
>>>                       * continual hope for) explicit JVM support of intrinsics with
>>>
>>>                       * double-sided reordering prohibition, or corresponding fence
>>>
>>>                       * intrinsics, we for now uncomfortably rely on the fact that the
>>>
>>>                       * Unsafe.getXVolatile intrinsic must have this property
>>>
>>>                       * (syntactic volatile reads do not) for internal purposes anyway,
>>>
>>>                       * even though it is not documented.
>>>
>>>                   
>>>
>>>                      public boolean validate(long stamp) {
>>>
>>>                          return (stamp & SBITS) == (U.getLongVolatile(this, STATE) & SBITS);
>>>
>>>                      }
>>>
>>>                   
>>>
>>>                 But if Unsafe.loadFence() is risky since it is not specified (yet) JMM-wise, and so interactions with other volatile ops and fences is just undocumented... then using Unsafe.getXVolatile is double-risky because the behavioral effect of read ordering is *REALLY* implementation-specific, and you if are using it for read ordering, you are five miles past the gateway to Hell already.
>>>
>>>                   
>>>
>>>                 Thanks,
>>>
>>>                 -Aleksey.
>>>
>>>                   
>>>
>>>                 [1]
>>>
>>>                 http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?revision=1.1
>>>
>>>                 _______________________________________________
>>>
>>>                 Concurrency-interest mailing list
>>>
>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>                   
>>>
>>>                 _______________________________________________
>>>
>>>                 Concurrency-interest mailing list
>>>
>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest at cs.oswego.edu
>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140424/77f71d72/attachment-0001.html>

From elizarov at devexperts.com  Fri Apr 25 03:02:42 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Fri, 25 Apr 2014 07:02:42 +0000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <5357B51D.9000206@oracle.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
Message-ID: <d2b0d53e839c465da809ac725db7c045@exchmb01.office.devexperts.com>

I cannot not stop thinking that Java 8 solution with Unsafe.loadFence() in StampedLock.validate() method is unsatisfactory. Not that because it is "Unsafe", but because it explicitly invokes a fence, which, in the ideal view of the world, should be just one possible implementation mechanism, not the primitive that the developer uses. To me it does "appear exceptionally unnatural" as Hans Boehm notes in his 2012 paper on seqlocks. 

Reading back and forth that paper I don't see a consolation in its conclusions. On a surface of it, all that is needed to make seqlock idiom implementable in the Java-like (happens-before) memory model are two new kinds of synchronization operations that would establish a synchronizes-with (sw) relation between a read and a subsequent write in synchronization order (so), as opposed to write-release/read-acquire pair that establishes sw-relation between a write and so-subsequent read. There's no need for "read-don't-modify-write". Even if its actual write is optimized away, its memory model effect still looks too strong for seqlock needs. As Hans points out in his paper, the compiler could have safely optimized "read-don't-modify-write" into "fence+read", but seqlock only needs "loadFence+read" in its validate  method.

In the validate method of seqlock we don't need any write (even if it does not modify). We don't need sw relation with so-previous write that "read-don't-modify-write" gives. We only need sw with so-subsequent write. In C++ terms, we just need to be able to memory_order_release on read in seqlock validate method (last read in the read path) and memory_order_acquire on a write in seqlock's first operation in a write path. For a multi-writer seqlock, the writer path uses read-modify-write operation anyway (to acquire lock), so it already has both acquire and release memory order. But what about read-release for validate? We don't have it now. Is there any existing research in that direction that might unify seqlocks with happens-before memory models in a satisfactory way? 
 
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
Sent: Wednesday, April 23, 2014 4:42 PM
To: Tobias Lindaaker; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Stricter read ordering

On 04/16/2014 03:25 PM, Tobias Lindaaker wrote:
> Is there any way I could introduce a fence that guarantees that the 
> data reads will not be moved to after the read of this.next?

I think you are reinventing sequence locks. Prime Java example is StampedLock which deals with ordering reads with Unsafe.loadFence(), see StampedLock.validate().

So, in your example, it amounts to:

       public DataCarrier read() {
         // I allow multiple readers, so this method is not ynchronized
         int x, y;
         long version;
         do {
           version = this.written;
           x = this.x;
           y = this.y;
           Unsafe.loadFence();
         } while ( version != this.next );
         return new DataCarrier( x, y );
       }
     }

-Aleksey.

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From howard.lovatt at gmail.com  Thu Apr 24 18:59:57 2014
From: howard.lovatt at gmail.com (Howard Lovatt)
Date: Fri, 25 Apr 2014 08:59:57 +1000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
Message-ID: <541910CB-FB16-448C-A825-4D468870B4EF@gmail.com>

Hi Tobias,

I find that if you can restructure your code to use immutable data and therefore avoid any locks, e.g. using streams, then this is the fastest. However you may not be able to or have the resources to do so, in which case I use a compromise of copy on write:

class DataCarrier {
  final int x, y, offset; // These are final to ensure copy on write
  DataCarrier(int x, int y, int offset) { this.x = x; this.y = y; this.offset = offset; }
}

class VersionedData {
  private static class DataCarrierCOW {
    private volatile DataCarrier data;
    DataCarrierCOW(DataCarrier data) { this.data = data; }
    synchronized void update(DataCarrier data) { this.data = data; }
    DataCarrier read() { return data; }
  }
  private final DataCarrierCOW[] datas; // I know data is also plural, but datas is clearer!
  VersionedData( ... ) { ... } // Copy the data into the array "datas"
  void update(Iterable<DataCarrier> cursors) { 
    for (DataCarrier cursor : cursors) {
      datas[cursor.offset].update(cursor);
    }
  }
  DataCarrier read(int offset) { return datas[offset].read(); }
}


Something like the above could be worth trying. It has worked well for me in the past. 

 -- Howard. 

Sent from my iPad

> On 24 Apr 2014, at 1:28 am, Tobias Lindaaker <thobes at gmail.com> wrote:
> 
> class VersionedData {
>   // this is the overhead I use to manage consistency
>   private final volatile long written;
>   private final volatile long next;
> 
>   // the protected data, this typically a memory mapped file
>   private final ByteBuffer buffer;
>   VersionedData( ByteBuffer buffer ) { this.buffer = buffer; }
>   
>   public synchronized void update( Iterable<DataCarrier> data ) {
>     long next = this.next + 1;
>     this.next = next;
>     for (DataCarrier cursor : data) {
>       int offset = data.offset * 8;
>       buffer.putInt( offset    , data.x );
>       buffer.putInt( offset + 4, data.y );
>     }
>     this.written = next;
>   }
> 
>   public void read(DataCarrier cursor) {
>     // I allow multiple readers, so this method is not synchronized
>     int x, y, offset = cursor.offset * 8;
>     long version;
>     do {
>       version = this.written;
>       x = buffer.getInt(offset);
>       y = buffer.getInt(offset + 4);
>     } while ( version != this.next );
>     cursor.x = x;
>     cursor.y = y;
>   }
> }
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140425/6de15146/attachment.html>

From howard.lovatt at gmail.com  Fri Apr 25 17:08:25 2014
From: howard.lovatt at gmail.com (Howard Lovatt)
Date: Sat, 26 Apr 2014 07:08:25 +1000
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
References: <E7E7AFC7-646D-4C34-9C55-7F5F5F1BCD0E@gmail.com>
	<5357B51D.9000206@oracle.com>
	<093396D4-2067-442E-91E5-B2FCA99AAE86@gmail.com>
	<5357C1CE.30003@oracle.com>
	<a9188f7b5cba4fa4a14cfc2460273557@exchmb01.office.devexperts.com>
	<7753C7F3-219E-4636-A97A-73AF4F576499@gmail.com>
	<5357D52E.6010300@oracle.com>
	<A7B8606D-B6C7-40BD-A505-805DD1552EFB@gmail.com>
Message-ID: <3DDCF912-739F-466A-B190-8C852DAB2EA6@gmail.com>

Hi Tobias,

I find that if you can restructure your code to use immutable data and therefore avoid any locks, e.g. using streams, then this is the fastest. However you may not be able to or have the resources to do so, in which case I use a compromise of copy on write:

class DataCarrier {
  final int x, y, offset; // These are final to ensure copy on write
  DataCarrier(int x, int y, int offset) { this.x = x; this.y = y; this.offset = offset; }
}

class VersionedData {
  private static class DataCarrierCOW {
    private volatile DataCarrier data;
    DataCarrierCOW(DataCarrier data) { this.data = data; }
    synchronized void update(DataCarrier data) { this.data = data; }
    DataCarrier read() { return data; }
  }
  private final DataCarrierCOW[] datas; // I know data is also plural, but datas is clearer!
  VersionedData( ... ) { ... } // Copy the data into the array "datas"
  void update(Iterable<DataCarrier> cursors) { 
    for (DataCarrier cursor : cursors) {
      datas[cursor.offset].update(cursor);
    }
  }
  DataCarrier read(int offset) { return datas[offset].read(); }
}


Something like the above could be worth trying. It has worked well for me in the past. 

 -- Howard. 

Sent from my iPad

> On 24 Apr 2014, at 1:28 am, Tobias Lindaaker <thobes at gmail.com> wrote:
> 
> class VersionedData {
>   // this is the overhead I use to manage consistency
>   private final volatile long written;
>   private final volatile long next;
> 
>   // the protected data, this typically a memory mapped file
>   private final ByteBuffer buffer;
>   VersionedData( ByteBuffer buffer ) { this.buffer = buffer; }
>   
>   public synchronized void update( Iterable<DataCarrier> data ) {
>     long next = this.next + 1;
>     this.next = next;
>     for (DataCarrier cursor : data) {
>       int offset = data.offset * 8;
>       buffer.putInt( offset    , data.x );
>       buffer.putInt( offset + 4, data.y );
>     }
>     this.written = next;
>   }
> 
>   public void read(DataCarrier cursor) {
>     // I allow multiple readers, so this method is not synchronized
>     int x, y, offset = cursor.offset * 8;
>     long version;
>     do {
>       version = this.written;
>       x = buffer.getInt(offset);
>       y = buffer.getInt(offset + 4);
>     } while ( version != this.next );
>     cursor.x = x;
>     cursor.y = y;
>   }
> }
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140426/03a3534e/attachment.html>

From aph at redhat.com  Tue Apr 29 06:22:28 2014
From: aph at redhat.com (Andrew Haley)
Date: Tue, 29 Apr 2014 11:22:28 +0100
Subject: [concurrency-interest] Stricter read ordering
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEOHKFAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEOHKFAA.davidcholmes@aapt.net.au>
Message-ID: <535F7D64.1060309@redhat.com>

On 04/24/2014 12:15 AM, David Holmes wrote:

> The discussion of CAS being like a "volatile load plus volatile
> store" did expose that that description is inadequate to fully
> convey the required ordering constraints.

Actually it didn't, unless I missed that message.  What are the
ordering constraints required by?  All I remember was "We don't
really know."  Only longer.  :-)

> The actual implementations in the Oracle JDK do not allow external
> accesses to leak into the atomic region.

OK.  If that is really what is required.

Andrew.


From martinrb at google.com  Tue Apr 29 13:44:58 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 29 Apr 2014 10:44:58 -0700
Subject: [concurrency-interest] Possible classloader leak caused by Striped64
Message-ID: <CA+kOe0_uKgJ8SW0LGS6fGUCeih7rMrJ9Y3Oea62R6eJ0fOHHWA@mail.gmail.com>

Guava bug
http://code.google.com/p/guava-libraries/issues/detail?id=1553
reports that Guava's private copy of Striped64 may cause classloader
retention because of the
class com.google.common.cache.Striped64$HashCode
held via a threadlocal.

Looking at jsr166 CVS, I see that the src/main version of Striped64 no
longer uses this class (and in any case this class is designed to be loaded
from the bootclass loader, making this problem moot), but the jsr166e
version of Striped64 appears to also have this problem.  If there is a
solution (and the guava bug report includes a patch) it is likely that both
guava and jsr166e would benefit from the same fix.

http://code.google.com/p/guava-libraries/source/browse/guava/src/com/google/common/cache/Striped64.java

Doug, could you take a look?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140429/a94409fd/attachment.html>

From haim at performize-it.com  Tue Apr 29 16:02:48 2014
From: haim at performize-it.com (Haim Yadid)
Date: Tue, 29 Apr 2014 23:02:48 +0300
Subject: [concurrency-interest] Another CompletableFuture Question
Message-ID: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>

Hi,
Is the a good way to convert a future to a CompletableFuture ?
The only way I have found is to wrap the Future which causes an overhead of
another busy thread.

    public static <V> CompletableFuture<V> convertFuture(Future<V> future) {
        CompletableFuture<V> brighterFuture = supplyAsync(() -> {
            try {
                return future.get();
            } catch (Exception e1) {
                throw new RuntimeException(e1);
            }
        });
        return brighterFuture;
    }

>
>
>

-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140429/cfe6b738/attachment.html>

From haim at performize-it.com  Tue Apr 29 16:03:37 2014
From: haim at performize-it.com (Haim Yadid)
Date: Tue, 29 Apr 2014 23:03:37 +0300
Subject: [concurrency-interest] A CompletableFuture Question
Message-ID: <CAJ-ba_PvtKAvVrYyAsVtJJF2xA9Rd24HPfEKoCK=q0dZs=O39g@mail.gmail.com>

Hi,
Take a look on the following code snippet.
Two CompletableFutures f1 returns 42 f2 throws exception.
If f2 ends before f1 an exception will be thrown on f3.get() .
As f1 is the only future which completes normally I would expect that it
will wait for f1 to complete and return its result. What am I missing?

        CompletableFuture<Integer> f1 = supplyAsync(
                () -> {sleep(2300);return 42;});
        CompletableFuture<Integer> f2 = supplyAsync(
                () -> {sleep(2200);if (true) throw new
RuntimeException();return 43;});

        CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r * r);

        System.out.println(f3.get());


PS - sleep is a Thread.sleep() wrapper when swallows check exceptions and
throws runtime exception instead.



-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140429/6721134b/attachment.html>

From dl at cs.oswego.edu  Tue Apr 29 16:17:49 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 29 Apr 2014 16:17:49 -0400
Subject: [concurrency-interest] Possible classloader leak caused by
	Striped64
In-Reply-To: <CA+kOe0_uKgJ8SW0LGS6fGUCeih7rMrJ9Y3Oea62R6eJ0fOHHWA@mail.gmail.com>
References: <CA+kOe0_uKgJ8SW0LGS6fGUCeih7rMrJ9Y3Oea62R6eJ0fOHHWA@mail.gmail.com>
Message-ID: <536008ED.9090007@cs.oswego.edu>


On 04/29/2014 01:44 PM, Martin Buchholz wrote:> Guava bug
> http://code.google.com/p/guava-libraries/issues/detail?id=1553 reports that
> Guava's private copy of Striped64 may cause classloader retention because of
> the class com.google.common.cache.Striped64$HashCode held via a threadlocal.

Using a one-element int[] (as suggested in patch) just to avoid
appEngine class-loader retention that can occur with a named class is
not going to win any beauty pageant awards, but we've done uglier
things for similar reasons. I'll double-check patch and put together
and commit jsr166e version sometime soon.

>
> Looking at jsr166 CVS, I see that the src/main version of Striped64 no
> longer uses this class

Right.

>
>
http://code.google.com/p/guava-libraries/source/browse/guava/src/com/google/common/cache/Striped64.java
>

From dl at cs.oswego.edu  Tue Apr 29 20:12:46 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 29 Apr 2014 20:12:46 -0400
Subject: [concurrency-interest] A CompletableFuture Question
In-Reply-To: <CAJ-ba_PvtKAvVrYyAsVtJJF2xA9Rd24HPfEKoCK=q0dZs=O39g@mail.gmail.com>
References: <CAJ-ba_PvtKAvVrYyAsVtJJF2xA9Rd24HPfEKoCK=q0dZs=O39g@mail.gmail.com>
Message-ID: <53603FFE.5060405@cs.oswego.edu>

On 04/29/2014 04:03 PM, Haim Yadid wrote:
>
> Hi,
> Take a look on the following code snippet.
> Two CompletableFutures f1 returns 42 f2 throws exception.
> If f2 ends before f1 an exception will be thrown on f3.get() .
> As f1 is the only future which completes normally I would expect that it will
> wait for f1 to complete and return its result. What am I missing?

A CompletableFuture is complete when its action either returns or throws
an exception. If exceptional, then the exception is propagated
to dependents. There are several CompletableFuture methods for handling
and transforming exceptional outcomes.
>
>          CompletableFuture<Integer> f1 = supplyAsync(
>                  () -> {sleep(2300);return 42;});
>          CompletableFuture<Integer> f2 = supplyAsync(
>                  () -> {sleep(2200);if (true) throw new
> RuntimeException();return 43;});
>
>          CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r * r);
>
>          System.out.println(f3.get());

This should print an exception.

-Doug

>
>
> PS - sleep is a Thread.sleep() wrapper when swallows check exceptions and throws
> runtime exception instead.
>
>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com <http://www.performize-it.com>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From haim at performize-it.com  Tue Apr 29 23:16:51 2014
From: haim at performize-it.com (Haim Yadid)
Date: Wed, 30 Apr 2014 06:16:51 +0300
Subject: [concurrency-interest] A CompletableFuture Question
Message-ID: <CAJ-ba_NpueUc_NEcoceP9vxPDraYmxtWsg-K=0s9N==XVcrqFQ@mail.gmail.com>

Thanks Doug,

I find the documentation a bit confusing:

applyToEither<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#applyToEither-java.util.concurrent.CompletionStage-java.util.function.Function->
(CompletionStage<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html><?
extends T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
> other, Function<http://docs.oracle.com/javase/8/docs/api/java/util/function/Function.html><?
super T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
,U> fn)
Returns a new CompletionStage that, when either this or the other given
stage complete normally, is executed with the corresponding result as
argument to the supplied function.

In other places of the documentation (such as thenApply)  "completes
normally" means successfully and not exceptionally.

In addition is there a way to do what I wanted to do in the first place ?
Query several services pick up the fastest non erroneous answer. If all are
exceptional pick one error.
I only need one successful



On Wed, Apr 30, 2014 at 3:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 04/29/2014 04:03 PM, Haim Yadid wrote:
>
>>
>> Hi,
>> Take a look on the following code snippet.
>> Two CompletableFutures f1 returns 42 f2 throws exception.
>> If f2 ends before f1 an exception will be thrown on f3.get() .
>> As f1 is the only future which completes normally I would expect that it
>> will
>> wait for f1 to complete and return its result. What am I missing?
>>
>
> A CompletableFuture is complete when its action either returns or throws
> an exception. If exceptional, then the exception is propagated
> to dependents. There are several CompletableFuture methods for handling
> and transforming exceptional outcomes.
>
>
>>          CompletableFuture<Integer> f1 = supplyAsync(
>>                  () -> {sleep(2300);return 42;});
>>          CompletableFuture<Integer> f2 = supplyAsync(
>>                  () -> {sleep(2200);if (true) throw new
>> RuntimeException();return 43;});
>>
>>          CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r *
>> r);
>>
>>          System.out.println(f3.get());
>>
>
> This should print an exception.
>
> -Doug
>
>
>>
>> PS - sleep is a Thread.sleep() wrapper when swallows check exceptions and
>> throws
>> runtime exception instead.
>>
>>
>>
>> --
>> Haim Yadid | Performization Expert
>> Performize-IT | t +972-54-7777132
>> www.performize-it.com <http://www.performize-it.com>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com



-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/1087bd61/attachment-0001.html>

From martinrb at google.com  Tue Apr 29 23:37:30 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 29 Apr 2014 20:37:30 -0700
Subject: [concurrency-interest] A CompletableFuture Question
In-Reply-To: <CAJ-ba_NpueUc_NEcoceP9vxPDraYmxtWsg-K=0s9N==XVcrqFQ@mail.gmail.com>
References: <CAJ-ba_NpueUc_NEcoceP9vxPDraYmxtWsg-K=0s9N==XVcrqFQ@mail.gmail.com>
Message-ID: <CA+kOe0_UZpJKexm5S-K4Su1Hhf24Kfwn7Ncd==Deb9NMw4eb4A@mail.gmail.com>

Haim,

The doc you cited also says,
See the CompletionStage documentation for rules covering exceptional
completion.
which leads to:

Two method forms support processing whether the triggering stage completed
normally or exceptionally: Method whenComplete allows injection of an
action regardless of outcome, otherwise preserving the outcome in its
completion. Method handle additionally allows the stage to compute a
replacement result that may enable further processing by other dependent
stages. In all other cases, if a stage's computation terminates abruptly
with an (unchecked) exception or error, then all dependent stages requiring
its completion complete exceptionally as well, with a CompletionException
holding the exception as its cause. If a stage is dependent on both of two
stages, and both complete exceptionally, then the CompletionException may
correspond to either one of these exceptions. If a stage is dependent on
either of two others, and only one of them completes exceptionally, no
guarantees are made about whether the dependent stage completes normally or
exceptionally. In the case of method whenComplete, when the supplied action
itself encounters an exception, then the stage exceptionally completes with
this exception if not already completed exceptionally.



On Tue, Apr 29, 2014 at 8:16 PM, Haim Yadid <haim at performize-it.com> wrote:

> Thanks Doug,
>
> I find the documentation a bit confusing:
>
> applyToEither<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#applyToEither-java.util.concurrent.CompletionStage-java.util.function.Function->
> (CompletionStage<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html><?
> extends T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
> > other, Function<http://docs.oracle.com/javase/8/docs/api/java/util/function/Function.html><?
> super T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
> ,U> fn)
> Returns a new CompletionStage that, when either this or the other given
> stage complete normally, is executed with the corresponding result as
> argument to the supplied function.
>
> In other places of the documentation (such as thenApply)  "completes
> normally" means successfully and not exceptionally.
>
> In addition is there a way to do what I wanted to do in the first place ?
> Query several services pick up the fastest non erroneous answer. If all are
> exceptional pick one error.
> I only need one successful
>
>
>
> On Wed, Apr 30, 2014 at 3:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
>> On 04/29/2014 04:03 PM, Haim Yadid wrote:
>>
>>>
>>> Hi,
>>> Take a look on the following code snippet.
>>> Two CompletableFutures f1 returns 42 f2 throws exception.
>>> If f2 ends before f1 an exception will be thrown on f3.get() .
>>> As f1 is the only future which completes normally I would expect that it
>>> will
>>> wait for f1 to complete and return its result. What am I missing?
>>>
>>
>> A CompletableFuture is complete when its action either returns or throws
>> an exception. If exceptional, then the exception is propagated
>> to dependents. There are several CompletableFuture methods for handling
>> and transforming exceptional outcomes.
>>
>>
>>>          CompletableFuture<Integer> f1 = supplyAsync(
>>>                  () -> {sleep(2300);return 42;});
>>>          CompletableFuture<Integer> f2 = supplyAsync(
>>>                  () -> {sleep(2200);if (true) throw new
>>> RuntimeException();return 43;});
>>>
>>>          CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r *
>>> r);
>>>
>>>          System.out.println(f3.get());
>>>
>>
>> This should print an exception.
>>
>> -Doug
>>
>>
>>>
>>> PS - sleep is a Thread.sleep() wrapper when swallows check exceptions
>>> and throws
>>> runtime exception instead.
>>>
>>>
>>>
>>> --
>>> Haim Yadid | Performization Expert
>>> Performize-IT | t +972-54-7777132
>>> www.performize-it.com <http://www.performize-it.com>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com
>
>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140429/7cd08224/attachment.html>

From haim at performize-it.com  Wed Apr 30 00:24:25 2014
From: haim at performize-it.com (Haim Yadid)
Date: Wed, 30 Apr 2014 07:24:25 +0300
Subject: [concurrency-interest] A CompletableFuture Question
In-Reply-To: <CA+kOe0_UZpJKexm5S-K4Su1Hhf24Kfwn7Ncd==Deb9NMw4eb4A@mail.gmail.com>
References: <CAJ-ba_NpueUc_NEcoceP9vxPDraYmxtWsg-K=0s9N==XVcrqFQ@mail.gmail.com>
	<CA+kOe0_UZpJKexm5S-K4Su1Hhf24Kfwn7Ncd==Deb9NMw4eb4A@mail.gmail.com>
Message-ID: <CAJ-ba_Mf45-73j0Yocgn010om-aDo3Gh92CyqrmYkDsRgH5RRw@mail.gmail.com>

Thanks Martin,
I now understand (documentation can be improved though - a one liner to
explain what the method do instead referencing another place).

Going back to the essence.   I am interested in the following functionality
: I do not care about "the other" future whether it is too late or
exceptional.
The only way I can think about making it work as I expect is by  slowing
down the exceptional flow and then cancelling it when all is done.


    static <T,U> CompletableFuture<U> myApplytoEither(CompletableFuture<T>
f1, CompletableFuture<T> f2,Function<? super T, U> fn)  {
        CompletableFuture<T> f1be = f1.exceptionally((t) ->
{sleep(100000);throw new RuntimeException(t);});
        CompletableFuture<T> f2be = f1.exceptionally((t) ->
{sleep(100000);throw new RuntimeException(t);});
        CompletableFuture t =
CompletableFuture.allOf(f1,f2).handle((res,trw)->
{f1be.cancel(true);f2be.cancel(true); return null;});
        return f1be.applyToEither(f2be,fn);
    }

I doubt that it really work probably there is some reason for it to be
flawed:)


On Wed, Apr 30, 2014 at 6:37 AM, Martin Buchholz <martinrb at google.com>wrote:

> Haim,
>
> The doc you cited also says,
> See the CompletionStage documentation for rules covering exceptional
> completion.
> which leads to:
>
> Two method forms support processing whether the triggering stage completed
> normally or exceptionally: Method whenComplete allows injection of an
> action regardless of outcome, otherwise preserving the outcome in its
> completion. Method handle additionally allows the stage to compute a
> replacement result that may enable further processing by other dependent
> stages. In all other cases, if a stage's computation terminates abruptly
> with an (unchecked) exception or error, then all dependent stages requiring
> its completion complete exceptionally as well, with a CompletionException
> holding the exception as its cause. If a stage is dependent on both of two
> stages, and both complete exceptionally, then the CompletionException may
> correspond to either one of these exceptions. If a stage is dependent on
> either of two others, and only one of them completes exceptionally, no
> guarantees are made about whether the dependent stage completes normally or
> exceptionally. In the case of method whenComplete, when the supplied action
> itself encounters an exception, then the stage exceptionally completes with
> this exception if not already completed exceptionally.
>
>
>
> On Tue, Apr 29, 2014 at 8:16 PM, Haim Yadid <haim at performize-it.com>wrote:
>
>> Thanks Doug,
>>
>> I find the documentation a bit confusing:
>>
>> applyToEither<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#applyToEither-java.util.concurrent.CompletionStage-java.util.function.Function->
>> (CompletionStage<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html><?
>> extends T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
>> > other, Function<http://docs.oracle.com/javase/8/docs/api/java/util/function/Function.html><?
>> super T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
>> ,U> fn)
>> Returns a new CompletionStage that, when either this or the other given
>> stage complete normally, is executed with the corresponding result as
>> argument to the supplied function.
>>
>> In other places of the documentation (such as thenApply)  "completes
>> normally" means successfully and not exceptionally.
>>
>> In addition is there a way to do what I wanted to do in the first place ?
>> Query several services pick up the fastest non erroneous answer. If all are
>> exceptional pick one error.
>> I only need one successful
>>
>>
>>
>> On Wed, Apr 30, 2014 at 3:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>
>>> On 04/29/2014 04:03 PM, Haim Yadid wrote:
>>>
>>>>
>>>> Hi,
>>>> Take a look on the following code snippet.
>>>> Two CompletableFutures f1 returns 42 f2 throws exception.
>>>> If f2 ends before f1 an exception will be thrown on f3.get() .
>>>> As f1 is the only future which completes normally I would expect that
>>>> it will
>>>> wait for f1 to complete and return its result. What am I missing?
>>>>
>>>
>>> A CompletableFuture is complete when its action either returns or throws
>>> an exception. If exceptional, then the exception is propagated
>>> to dependents. There are several CompletableFuture methods for handling
>>> and transforming exceptional outcomes.
>>>
>>>
>>>>          CompletableFuture<Integer> f1 = supplyAsync(
>>>>                  () -> {sleep(2300);return 42;});
>>>>          CompletableFuture<Integer> f2 = supplyAsync(
>>>>                  () -> {sleep(2200);if (true) throw new
>>>> RuntimeException();return 43;});
>>>>
>>>>          CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r *
>>>> r);
>>>>
>>>>          System.out.println(f3.get());
>>>>
>>>
>>> This should print an exception.
>>>
>>> -Doug
>>>
>>>
>>>>
>>>> PS - sleep is a Thread.sleep() wrapper when swallows check exceptions
>>>> and throws
>>>> runtime exception instead.
>>>>
>>>>
>>>>
>>>> --
>>>> Haim Yadid | Performization Expert
>>>> Performize-IT | t +972-54-7777132
>>>> www.performize-it.com <http://www.performize-it.com>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>> Haim Yadid | Performization Expert
>> Performize-IT | t +972-54-7777132
>> www.performize-it.com
>>
>>
>>
>> --
>> Haim Yadid | Performization Expert
>> Performize-IT | t +972-54-7777132
>> www.performize-it.com
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>


-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/817078fc/attachment-0001.html>

From haim at performize-it.com  Wed Apr 30 02:10:16 2014
From: haim at performize-it.com (Haim Yadid)
Date: Wed, 30 Apr 2014 09:10:16 +0300
Subject: [concurrency-interest] A CompletableFuture Question
In-Reply-To: <CAJ-ba_Mf45-73j0Yocgn010om-aDo3Gh92CyqrmYkDsRgH5RRw@mail.gmail.com>
References: <CAJ-ba_NpueUc_NEcoceP9vxPDraYmxtWsg-K=0s9N==XVcrqFQ@mail.gmail.com>
	<CA+kOe0_UZpJKexm5S-K4Su1Hhf24Kfwn7Ncd==Deb9NMw4eb4A@mail.gmail.com>
	<CAJ-ba_Mf45-73j0Yocgn010om-aDo3Gh92CyqrmYkDsRgH5RRw@mail.gmail.com>
Message-ID: <CAJ-ba_MB00=WNgZ8qM+rYpDj4ADPobFeZ2w_ZX-DvD+t-FRTWg@mail.gmail.com>

And ofcourse it doesn't work :)
Hope this one will be better:

    static<T> CompletableFuture<T>
holdDownExceptionally(CompletableFuture<T>f, CountDownLatch latch) {
        return f.exceptionally((t) -> {
                try {
                    latch.await();
                } catch (Exception e) {
                    throw new RuntimeException(t);
                }
                throw new RuntimeException(t);
             }).thenApply((r) -> {latch.countDown();return r;});
    }

    static <T,U> CompletableFuture<U> myApplytoEither(CompletableFuture<T>
f1, CompletableFuture<T> f2,Function<? super T, U> fn)  {
        CountDownLatch sync = new CountDownLatch(1);
        CompletableFuture<T> f1be = holdDownExceptionally(f1,sync);
        CompletableFuture<T> f2be = holdDownExceptionally(f2,sync);
        return f1be.applyToEither(f2be,fn);
    }


On Wed, Apr 30, 2014 at 7:24 AM, Haim Yadid <haim at performize-it.com> wrote:

> Thanks Martin,
> I now understand (documentation can be improved though - a one liner to
> explain what the method do instead referencing another place).
>
> Going back to the essence.   I am interested in the following
> functionality : I do not care about "the other" future whether it is too
> late or exceptional.
> The only way I can think about making it work as I expect is by  slowing
> down the exceptional flow and then cancelling it when all is done.
>
>
>     static <T,U> CompletableFuture<U> myApplytoEither(CompletableFuture<T>
> f1, CompletableFuture<T> f2,Function<? super T, U> fn)  {
>         CompletableFuture<T> f1be = f1.exceptionally((t) ->
> {sleep(100000);throw new RuntimeException(t);});
>         CompletableFuture<T> f2be = f1.exceptionally((t) ->
> {sleep(100000);throw new RuntimeException(t);});
>         CompletableFuture t =
> CompletableFuture.allOf(f1,f2).handle((res,trw)->
> {f1be.cancel(true);f2be.cancel(true); return null;});
>         return f1be.applyToEither(f2be,fn);
>     }
>
> I doubt that it really work probably there is some reason for it to be
> flawed:)
>
>
> On Wed, Apr 30, 2014 at 6:37 AM, Martin Buchholz <martinrb at google.com>wrote:
>
>> Haim,
>>
>> The doc you cited also says,
>> See the CompletionStage documentation for rules covering exceptional
>> completion.
>> which leads to:
>>
>> Two method forms support processing whether the triggering stage
>> completed normally or exceptionally: Method whenComplete allows injection
>> of an action regardless of outcome, otherwise preserving the outcome in its
>> completion. Method handle additionally allows the stage to compute a
>> replacement result that may enable further processing by other dependent
>> stages. In all other cases, if a stage's computation terminates abruptly
>> with an (unchecked) exception or error, then all dependent stages requiring
>> its completion complete exceptionally as well, with a CompletionException
>> holding the exception as its cause. If a stage is dependent on both of two
>> stages, and both complete exceptionally, then the CompletionException may
>> correspond to either one of these exceptions. If a stage is dependent on
>> either of two others, and only one of them completes exceptionally, no
>> guarantees are made about whether the dependent stage completes normally or
>> exceptionally. In the case of method whenComplete, when the supplied action
>> itself encounters an exception, then the stage exceptionally completes with
>> this exception if not already completed exceptionally.
>>
>>
>>
>> On Tue, Apr 29, 2014 at 8:16 PM, Haim Yadid <haim at performize-it.com>wrote:
>>
>>> Thanks Doug,
>>>
>>> I find the documentation a bit confusing:
>>>
>>> applyToEither<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#applyToEither-java.util.concurrent.CompletionStage-java.util.function.Function->
>>> (CompletionStage<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html><?
>>> extends T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
>>> > other, Function<http://docs.oracle.com/javase/8/docs/api/java/util/function/Function.html><?
>>> super T<http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html>
>>> ,U> fn)
>>> Returns a new CompletionStage that, when either this or the other given
>>> stage complete normally, is executed with the corresponding result as
>>> argument to the supplied function.
>>>
>>> In other places of the documentation (such as thenApply)  "completes
>>> normally" means successfully and not exceptionally.
>>>
>>> In addition is there a way to do what I wanted to do in the first place
>>> ? Query several services pick up the fastest non erroneous answer. If all
>>> are exceptional pick one error.
>>> I only need one successful
>>>
>>>
>>>
>>> On Wed, Apr 30, 2014 at 3:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>
>>>> On 04/29/2014 04:03 PM, Haim Yadid wrote:
>>>>
>>>>>
>>>>> Hi,
>>>>> Take a look on the following code snippet.
>>>>> Two CompletableFutures f1 returns 42 f2 throws exception.
>>>>> If f2 ends before f1 an exception will be thrown on f3.get() .
>>>>> As f1 is the only future which completes normally I would expect that
>>>>> it will
>>>>> wait for f1 to complete and return its result. What am I missing?
>>>>>
>>>>
>>>> A CompletableFuture is complete when its action either returns or throws
>>>> an exception. If exceptional, then the exception is propagated
>>>> to dependents. There are several CompletableFuture methods for handling
>>>> and transforming exceptional outcomes.
>>>>
>>>>
>>>>>          CompletableFuture<Integer> f1 = supplyAsync(
>>>>>                  () -> {sleep(2300);return 42;});
>>>>>          CompletableFuture<Integer> f2 = supplyAsync(
>>>>>                  () -> {sleep(2200);if (true) throw new
>>>>> RuntimeException();return 43;});
>>>>>
>>>>>          CompletableFuture<Integer> f3 = f1.applyToEither(f2,(r) -> r
>>>>> * r);
>>>>>
>>>>>          System.out.println(f3.get());
>>>>>
>>>>
>>>> This should print an exception.
>>>>
>>>> -Doug
>>>>
>>>>
>>>>>
>>>>> PS - sleep is a Thread.sleep() wrapper when swallows check exceptions
>>>>> and throws
>>>>> runtime exception instead.
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Haim Yadid | Performization Expert
>>>>> Performize-IT | t +972-54-7777132
>>>>> www.performize-it.com <http://www.performize-it.com>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>>
>>> --
>>> Haim Yadid | Performization Expert
>>> Performize-IT | t +972-54-7777132
>>> www.performize-it.com
>>>
>>>
>>>
>>> --
>>> Haim Yadid | Performization Expert
>>> Performize-IT | t +972-54-7777132
>>> www.performize-it.com
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com
>



-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/80bbfbaf/attachment.html>

From viktor.klang at gmail.com  Wed Apr 30 08:55:12 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 30 Apr 2014 14:55:12 +0200
Subject: [concurrency-interest] Another CompletableFuture Question
In-Reply-To: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>
References: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>
Message-ID: <CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>

Hi Haim,


Your (only) options are:

a) blocking (you already provided that solution)
b) polling (have some thread have a set of Futures that it intermittently
checks for isDone and then gets the value out)

CompletableFuture > Future


On Tue, Apr 29, 2014 at 10:02 PM, Haim Yadid <haim at performize-it.com> wrote:

>
> Hi,
> Is the a good way to convert a future to a CompletableFuture ?
> The only way I have found is to wrap the Future which causes an overhead
> of another busy thread.
>
>     public static <V> CompletableFuture<V> convertFuture(Future<V> future)
> {
>         CompletableFuture<V> brighterFuture = supplyAsync(() -> {
>             try {
>                 return future.get();
>             } catch (Exception e1) {
>                 throw new RuntimeException(e1);
>             }
>         });
>         return brighterFuture;
>     }
>
>>
>>
>>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/06a9b154/attachment-0001.html>

From haim at performize-it.com  Wed Apr 30 09:00:34 2014
From: haim at performize-it.com (Haim Yadid)
Date: Wed, 30 Apr 2014 16:00:34 +0300
Subject: [concurrency-interest] Another CompletableFuture Question
In-Reply-To: <CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>
References: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>
	<CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>
Message-ID: <CAJ-ba_NOOBEmNo0+Le+ecX=TaiOoyU+feD6b8q-2XLrXXCHSsg@mail.gmail.com>

Thanks Viktor
Do you ( or anyone else ) know why

   - AsynchronousFileChannel
   - AsynchronousServerSocketChannel
   - AsynchronousSocketChannel

where not converted to support CompletableFutures as well?


On Wed, Apr 30, 2014 at 3:55 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Hi Haim,
>
>
> Your (only) options are:
>
> a) blocking (you already provided that solution)
> b) polling (have some thread have a set of Futures that it intermittently
> checks for isDone and then gets the value out)
>
> CompletableFuture > Future
>
>
> On Tue, Apr 29, 2014 at 10:02 PM, Haim Yadid <haim at performize-it.com>wrote:
>
>>
>> Hi,
>> Is the a good way to convert a future to a CompletableFuture ?
>> The only way I have found is to wrap the Future which causes an overhead
>> of another busy thread.
>>
>>     public static <V> CompletableFuture<V> convertFuture(Future<V>
>> future) {
>>         CompletableFuture<V> brighterFuture = supplyAsync(() -> {
>>             try {
>>                 return future.get();
>>             } catch (Exception e1) {
>>                 throw new RuntimeException(e1);
>>             }
>>         });
>>         return brighterFuture;
>>     }
>>
>>>
>>>
>>>
>>
>> --
>> Haim Yadid | Performization Expert
>> Performize-IT | t +972-54-7777132
>> www.performize-it.com
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Cheers,
> ?
>



-- 
Haim Yadid | Performization Expert
Performize-IT | t +972-54-7777132
www.performize-it.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/93a61258/attachment.html>

From viktor.klang at gmail.com  Wed Apr 30 09:10:09 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 30 Apr 2014 15:10:09 +0200
Subject: [concurrency-interest] Another CompletableFuture Question
In-Reply-To: <CAJ-ba_NOOBEmNo0+Le+ecX=TaiOoyU+feD6b8q-2XLrXXCHSsg@mail.gmail.com>
References: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>
	<CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>
	<CAJ-ba_NOOBEmNo0+Le+ecX=TaiOoyU+feD6b8q-2XLrXXCHSsg@mail.gmail.com>
Message-ID: <CANPzfU8=RfWphurhJ-qqiFa_bKKNej3B03_-2TpjSFuncrEq2Q@mail.gmail.com>

Hi Haim,

from a quick glance I'd assume for compatibility reasons.
The classes you mention are abstract and as such there are implementations
out there that return Future, so you couldn't retrofit the methods to
return a more specific type (CompletableFuture).

And I also assume that there was neither time nor a desire to duplicate all
the API methods (since Java doesn't fare well with return type overloading).

A Future Java could/should in my opinion move away from the current
(n)io(1/2) libraries and offer IO APIs built to use non-blocking,
asynchronous streams with built in backpressure, as being worked on by the
Reactive Streams SIG?I'd even go so far as to say that it is java.io done
right.

The above is of course only my personal opinions as I have no insight into
the Java SDK roadmap etc.


On Wed, Apr 30, 2014 at 3:00 PM, Haim Yadid <haim at performize-it.com> wrote:

> Thanks Viktor
> Do you ( or anyone else ) know why
>
>    - AsynchronousFileChannel
>    - AsynchronousServerSocketChannel
>    - AsynchronousSocketChannel
>
> where not converted to support CompletableFutures as well?
>
>
> On Wed, Apr 30, 2014 at 3:55 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>> Hi Haim,
>>
>>
>> Your (only) options are:
>>
>> a) blocking (you already provided that solution)
>> b) polling (have some thread have a set of Futures that it intermittently
>> checks for isDone and then gets the value out)
>>
>> CompletableFuture > Future
>>
>>
>> On Tue, Apr 29, 2014 at 10:02 PM, Haim Yadid <haim at performize-it.com>wrote:
>>
>>>
>>> Hi,
>>> Is the a good way to convert a future to a CompletableFuture ?
>>> The only way I have found is to wrap the Future which causes an overhead
>>> of another busy thread.
>>>
>>>     public static <V> CompletableFuture<V> convertFuture(Future<V>
>>> future) {
>>>         CompletableFuture<V> brighterFuture = supplyAsync(() -> {
>>>             try {
>>>                 return future.get();
>>>             } catch (Exception e1) {
>>>                 throw new RuntimeException(e1);
>>>             }
>>>         });
>>>         return brighterFuture;
>>>     }
>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Haim Yadid | Performization Expert
>>> Performize-IT | t +972-54-7777132
>>> www.performize-it.com
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>
>
>
> --
> Haim Yadid | Performization Expert
> Performize-IT | t +972-54-7777132
> www.performize-it.com
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/e6243ba5/attachment.html>

From stanimir at riflexo.com  Wed Apr 30 10:28:01 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Wed, 30 Apr 2014 17:28:01 +0300
Subject: [concurrency-interest] Another CompletableFuture Question
In-Reply-To: <CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>
References: <CAJ-ba_MFoV6B5JjSzZhP1VWwfhvSYDx+xkkehy=xEoDJ55E0uQ@mail.gmail.com>
	<CANPzfU8X5gGQTXSwMuviPE6vOBH6T_LCZ7G8sKhNDGEwEY6pYg@mail.gmail.com>
Message-ID: <CAEJX8oo31DsjcPXvhkTg+ZsOPR25ZYGES36gzYYRznGbOzLpTw@mail.gmail.com>

Hi Haim,

It's possible if you have the option to create the future yourself (for
example overriding AbstractExecutorService.newTaskFor) and/or submitting
subclasses of j.u.c.FutureTask (for Runnable) with overridden done() method
However if you just receive a plain Future object you can't do much but
poll either get() or isDone().

On a flip note: java.nio is pretty much what *nix IO is about, so I don't
have qualms there. The harder part coming with any higher level and
effective API is actually not copying the direct buffers.

Stanimir



On Wed, Apr 30, 2014 at 3:55 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:

> Hi Haim,
>
>
> Your (only) options are:
>
> a) blocking (you already provided that solution)
> b) polling (have some thread have a set of Futures that it intermittently
> checks for isDone and then gets the value out)
>
> CompletableFuture > Future
>
>
> On Tue, Apr 29, 2014 at 10:02 PM, Haim Yadid <haim at performize-it.com>wrote:
>
>>
>> Hi,
>> Is the a good way to convert a future to a CompletableFuture ?
>> The only way I have found is to wrap the Future which causes an overhead
>> of another busy thread.
>>
>>     public static <V> CompletableFuture<V> convertFuture(Future<V>
>> future) {
>>         CompletableFuture<V> brighterFuture = supplyAsync(() -> {
>>             try {
>>                 return future.get();
>>             } catch (Exception e1) {
>>                 throw new RuntimeException(e1);
>>             }
>>         });
>>         return brighterFuture;
>>     }
>>
>>>
>>>
>>>
>>
>> --
>> Haim Yadid | Performization Expert
>> Performize-IT | t +972-54-7777132
>> www.performize-it.com
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140430/4a48ddfd/attachment-0001.html>

