From heinz at javaspecialists.eu  Sun Jun  1 01:07:30 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sun, 1 Jun 2014 08:07:30 +0300
Subject: [concurrency-interest] Potential threads getting stuck on
 WAITING(parking) in ReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEMDKGAA.davidcholmes@aapt.net.au>
References: <CALHzM99GODVdy=3dqOXwhEE1nKRyW6xvjTxrrs7YmhYcf+Y2Xw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEMDKGAA.davidcholmes@aapt.net.au>
Message-ID: <CACLL95qx-iu=CLK=pL_Jr1wzap9LFt4XqrdQ+5Z5JcL86Lo=cQ@mail.gmail.com>

Please send us a link to your code, both your ReentrantLock and the test code?

On 01/06/2014, David Holmes <davidcholmes at aapt.net.au> wrote:
> Hi Rafael,
>
> Does this reproduce with Oracle JDK or only the IcedTea distributions?
>
> The most likely issue is the StackOverflowError. Have excluded that
> possibility?
>
> David
>   -----Original Message-----
>   From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael
> Brand?o
>   Sent: Sunday, 1 June 2014 8:50 AM
>   To: concurrency-interest at cs.oswego.edu
>   Subject: [concurrency-interest] Potential threads getting stuck on
> WAITING(parking) in ReentrantLock
>
>
>   Hello,
>
>
>   I'm working on a few changes for ReentrantLock to make A/B tests between
> the original implementation and my modifications, so my first step was to
> copy the sources of ReentrantLock, AbstractQueuedSynchronizer (shortly AQS)
> and AbstractOwnableSynchronizer and put them in a different package. After
> resolving basic compilation issues, I've found the issue with Unsafe usage
> (insecurity exception) and I've solved it based on the article found in [1].
> So basically my ReentrantLock has nothing different from the original except
> for how I get the Unsafe in AQS.
>
>
>   After that, I've exhaustively conducted the following experiment: 200
> threads try to increment 1000 times each some integer counter protected by
> explicit locks. There are 10 counters, so each counter has 20 threads
> concurrently trying to increment it. The main thread spawns all those
> threads and then wait for them with join method. Once I've ran this
> experiment many times (about 30000), it consistently get stuck in a join for
> some thread when I use my almost unmodified ReentrantLock before 2000th
> attempt.
>
>
>   I've got the thread stacks in [2] and what I understood from it is that
> the remaining threads are all stuck waiting for the lock to be released.
> However I've managed to print the owner of that lock and I see it's unlocked
> and has no owner:
>
>
>     stuck thread state: WAITING
>     thread waiting lock: safe.ReentrantLock at 68a6a21a[Unlocked]
>     lock owner: null
>
>
>   I've been trying to reproduce it with the original ReentrantLock but I
> didn't get stuck so far. So I'm here to ask you if there's a known issue on
> ReentrantLock that could cause this situation (and also be extremely
> unlikely to happen) or if there's something obvious that I should know about
> the Unsafe usage given it's the only thing changed so far.
>
>
>   I suspect I have some disadvantage given that my nearly unmodified class
> is not already compiled in the JVM (I could try to build the JDK later), but
> this could only be a sign that the issue already exists in the code but can
> only become more likely to happen in a slower implementation. I've also
> searched for related bugs and the closest thing I've found was [3].
>
>
>   I'm using a Intel(R) Core(tm) i7-3632QM notebook running Ubuntu 12.04. Java
> version is "1.7.0_55" and I'm using OpenJDK Runtime Environment (IcedTea
> 2.4.7) (7u55-2.4.7-1ubuntu1~0.12.04.2) and OpenJDK 64-Bit Server VM (build
> 24.51-b03, mixed mode). I've experienced this issue after copying sources of
> jdk7u, jdk8u and jdk9.
>
>
>
>
>   Best regards,
>   Rafael
>
>
>
>
>   [1] http://howtodoinjava.com/2013/10/19/usage-of-class-sun-misc-unsafe/
>   [2] https://gist.github.com/rafaelbrandao/4ec5f2cd272c4b8b183a
>   [3] https://bugs.openjdk.java.net/browse/JDK-8028686
>
>
>   --
>   Rafael Brand?o @ CIn - Center of Informatics


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun/Oracle Java Champion 2005-2013
JavaOne Rockstar Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


From rblcin at gmail.com  Mon Jun  2 21:43:34 2014
From: rblcin at gmail.com (=?UTF-8?Q?Rafael_Brand=C3=A3o?=)
Date: Mon, 2 Jun 2014 22:43:34 -0300
Subject: [concurrency-interest] Potential threads getting stuck on
 WAITING(parking) in ReentrantLock
In-Reply-To: <CACLL95qx-iu=CLK=pL_Jr1wzap9LFt4XqrdQ+5Z5JcL86Lo=cQ@mail.gmail.com>
References: <CALHzM99GODVdy=3dqOXwhEE1nKRyW6xvjTxrrs7YmhYcf+Y2Xw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEMDKGAA.davidcholmes@aapt.net.au>
	<CACLL95qx-iu=CLK=pL_Jr1wzap9LFt4XqrdQ+5Z5JcL86Lo=cQ@mail.gmail.com>
Message-ID: <CALHzM99tfwDecAUBoSDC63HR0vDSTSctULY6KacJEwq9fngeoA@mail.gmail.com>

Hello,

David, I have now tested it with java version "1.8.0_05", Java(TM) SE
Runtime Environment (build 1.8.0_05-b13) and Java HotSpot(TM) 64-Bit Server
VM (build 25.5-b02, mixed mode). The problem with my nearly unmodified
ReentrantLock getting stuck is no longer happening when I run the
experiment. Would you also like me to test with any particular version?
Thanks for the tip! Now about StackOverflowError, I don't see how it could
be possible (I've posted a link to the code if you want to check), since
there's no infinite recursion for example and each test run is relatively
low in used resources.

Heinz, I have posted the code on https://github.com/rafaelbrandao/msc - the
latest commit message (it only has 3 commits) contains information on how
to reproduce this issue. It seems to be fixed when I use Oracle JDK 8
however.

What could be causing the stuck threads? Is it possible this is a problem
with the ReentrantLock algorithm/implementation?

Best regards,
Rafael

On Sun, Jun 1, 2014 at 2:07 AM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu
> wrote:

> Please send us a link to your code, both your ReentrantLock and the test
> code?
>
> On 01/06/2014, David Holmes <davidcholmes at aapt.net.au> wrote:
> > Hi Rafael,
> >
> > Does this reproduce with Oracle JDK or only the IcedTea distributions?
> >
> > The most likely issue is the StackOverflowError. Have excluded that
> > possibility?
> >
> > David
> >   -----Original Message-----
> >   From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael
> > Brand?o
> >   Sent: Sunday, 1 June 2014 8:50 AM
> >   To: concurrency-interest at cs.oswego.edu
> >   Subject: [concurrency-interest] Potential threads getting stuck on
> > WAITING(parking) in ReentrantLock
> >
> >
> >   Hello,
> >
> >
> >   I'm working on a few changes for ReentrantLock to make A/B tests
> between
> > the original implementation and my modifications, so my first step was to
> > copy the sources of ReentrantLock, AbstractQueuedSynchronizer (shortly
> AQS)
> > and AbstractOwnableSynchronizer and put them in a different package.
> After
> > resolving basic compilation issues, I've found the issue with Unsafe
> usage
> > (insecurity exception) and I've solved it based on the article found in
> [1].
> > So basically my ReentrantLock has nothing different from the original
> except
> > for how I get the Unsafe in AQS.
> >
> >
> >   After that, I've exhaustively conducted the following experiment: 200
> > threads try to increment 1000 times each some integer counter protected
> by
> > explicit locks. There are 10 counters, so each counter has 20 threads
> > concurrently trying to increment it. The main thread spawns all those
> > threads and then wait for them with join method. Once I've ran this
> > experiment many times (about 30000), it consistently get stuck in a join
> for
> > some thread when I use my almost unmodified ReentrantLock before 2000th
> > attempt.
> >
> >
> >   I've got the thread stacks in [2] and what I understood from it is that
> > the remaining threads are all stuck waiting for the lock to be released.
> > However I've managed to print the owner of that lock and I see it's
> unlocked
> > and has no owner:
> >
> >
> >     stuck thread state: WAITING
> >     thread waiting lock: safe.ReentrantLock at 68a6a21a[Unlocked]
> >     lock owner: null
> >
> >
> >   I've been trying to reproduce it with the original ReentrantLock but I
> > didn't get stuck so far. So I'm here to ask you if there's a known issue
> on
> > ReentrantLock that could cause this situation (and also be extremely
> > unlikely to happen) or if there's something obvious that I should know
> about
> > the Unsafe usage given it's the only thing changed so far.
> >
> >
> >   I suspect I have some disadvantage given that my nearly unmodified
> class
> > is not already compiled in the JVM (I could try to build the JDK later),
> but
> > this could only be a sign that the issue already exists in the code but
> can
> > only become more likely to happen in a slower implementation. I've also
> > searched for related bugs and the closest thing I've found was [3].
> >
> >
> >   I'm using a Intel(R) Core(tm) i7-3632QM notebook running Ubuntu 12.04.
> Java
> > version is "1.7.0_55" and I'm using OpenJDK Runtime Environment (IcedTea
> > 2.4.7) (7u55-2.4.7-1ubuntu1~0.12.04.2) and OpenJDK 64-Bit Server VM
> (build
> > 24.51-b03, mixed mode). I've experienced this issue after copying
> sources of
> > jdk7u, jdk8u and jdk9.
> >
> >
> >
> >
> >   Best regards,
> >   Rafael
> >
> >
> >
> >
> >   [1]
> http://howtodoinjava.com/2013/10/19/usage-of-class-sun-misc-unsafe/
> >   [2] https://gist.github.com/rafaelbrandao/4ec5f2cd272c4b8b183a
> >   [3] https://bugs.openjdk.java.net/browse/JDK-8028686
> >
> >
> >   --
> >   Rafael Brand?o @ CIn - Center of Informatics
>
>
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun/Oracle Java Champion 2005-2013
> JavaOne Rockstar Speaker 2012
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>



-- 
Rafael Brand?o @ CIn - Center of Informatics
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140602/69a5c018/attachment.html>

From davidcholmes at aapt.net.au  Mon Jun  2 22:35:42 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 3 Jun 2014 12:35:42 +1000
Subject: [concurrency-interest] Potential threads getting stuck on
	WAITING(parking) in ReentrantLock
In-Reply-To: <CALHzM99tfwDecAUBoSDC63HR0vDSTSctULY6KacJEwq9fngeoA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMENLKGAA.davidcholmes@aapt.net.au>

Hi Rafael,

Can you try Oracle JDK 7? This might be:

https://bugs.openjdk.java.net/browse/JDK-7011859

which was fixed in 8.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael Brand?o
  Sent: Tuesday, 3 June 2014 11:44 AM
  To: Dr Heinz M. Kabutz
  Cc: concurrency-interest at cs.oswego.edu; dholmes at ieee.org
  Subject: Re: [concurrency-interest] Potential threads getting stuck on WAITING(parking) in ReentrantLock


  Hello,


  David, I have now tested it with java version "1.8.0_05", Java(TM) SE Runtime Environment (build 1.8.0_05-b13) and Java HotSpot(TM) 64-Bit Server VM (build 25.5-b02, mixed mode). The problem with my nearly unmodified ReentrantLock getting stuck is no longer happening when I run the experiment. Would you also like me to test with any particular version? Thanks for the tip! Now about StackOverflowError, I don't see how it could be possible (I've posted a link to the code if you want to check), since there's no infinite recursion for example and each test run is relatively low in used resources.


  Heinz, I have posted the code on https://github.com/rafaelbrandao/msc - the latest commit message (it only has 3 commits) contains information on how to reproduce this issue. It seems to be fixed when I use Oracle JDK 8 however.


  What could be causing the stuck threads? Is it possible this is a problem with the ReentrantLock algorithm/implementation?


  Best regards,
  Rafael


  On Sun, Jun 1, 2014 at 2:07 AM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:

    Please send us a link to your code, both your ReentrantLock and the test code?


    On 01/06/2014, David Holmes <davidcholmes at aapt.net.au> wrote:
    > Hi Rafael,
    >
    > Does this reproduce with Oracle JDK or only the IcedTea distributions?
    >
    > The most likely issue is the StackOverflowError. Have excluded that
    > possibility?
    >
    > David
    >   -----Original Message-----
    >   From: concurrency-interest-bounces at cs.oswego.edu
    > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael
    > Brand?o
    >   Sent: Sunday, 1 June 2014 8:50 AM
    >   To: concurrency-interest at cs.oswego.edu
    >   Subject: [concurrency-interest] Potential threads getting stuck on
    > WAITING(parking) in ReentrantLock
    >
    >
    >   Hello,
    >
    >
    >   I'm working on a few changes for ReentrantLock to make A/B tests between
    > the original implementation and my modifications, so my first step was to
    > copy the sources of ReentrantLock, AbstractQueuedSynchronizer (shortly AQS)
    > and AbstractOwnableSynchronizer and put them in a different package. After
    > resolving basic compilation issues, I've found the issue with Unsafe usage
    > (insecurity exception) and I've solved it based on the article found in [1].
    > So basically my ReentrantLock has nothing different from the original except
    > for how I get the Unsafe in AQS.
    >
    >
    >   After that, I've exhaustively conducted the following experiment: 200
    > threads try to increment 1000 times each some integer counter protected by
    > explicit locks. There are 10 counters, so each counter has 20 threads
    > concurrently trying to increment it. The main thread spawns all those
    > threads and then wait for them with join method. Once I've ran this
    > experiment many times (about 30000), it consistently get stuck in a join for
    > some thread when I use my almost unmodified ReentrantLock before 2000th
    > attempt.
    >
    >
    >   I've got the thread stacks in [2] and what I understood from it is that
    > the remaining threads are all stuck waiting for the lock to be released.
    > However I've managed to print the owner of that lock and I see it's unlocked
    > and has no owner:
    >
    >
    >     stuck thread state: WAITING
    >     thread waiting lock: safe.ReentrantLock at 68a6a21a[Unlocked]
    >     lock owner: null
    >
    >
    >   I've been trying to reproduce it with the original ReentrantLock but I
    > didn't get stuck so far. So I'm here to ask you if there's a known issue on
    > ReentrantLock that could cause this situation (and also be extremely
    > unlikely to happen) or if there's something obvious that I should know about
    > the Unsafe usage given it's the only thing changed so far.
    >
    >
    >   I suspect I have some disadvantage given that my nearly unmodified class
    > is not already compiled in the JVM (I could try to build the JDK later), but
    > this could only be a sign that the issue already exists in the code but can
    > only become more likely to happen in a slower implementation. I've also
    > searched for related bugs and the closest thing I've found was [3].
    >
    >

    >   I'm using a Intel(R) Core(tm) i7-3632QM notebook running Ubuntu 12.04. Java

    > version is "1.7.0_55" and I'm using OpenJDK Runtime Environment (IcedTea
    > 2.4.7) (7u55-2.4.7-1ubuntu1~0.12.04.2) and OpenJDK 64-Bit Server VM (build
    > 24.51-b03, mixed mode). I've experienced this issue after copying sources of
    > jdk7u, jdk8u and jdk9.
    >
    >
    >
    >
    >   Best regards,
    >   Rafael
    >
    >
    >
    >
    >   [1] http://howtodoinjava.com/2013/10/19/usage-of-class-sun-misc-unsafe/
    >   [2] https://gist.github.com/rafaelbrandao/4ec5f2cd272c4b8b183a
    >   [3] https://bugs.openjdk.java.net/browse/JDK-8028686
    >
    >
    >   --
    >   Rafael Brand?o @ CIn - Center of Informatics



    --
    Dr Heinz M. Kabutz (PhD CompSci)
    Author of "The Java(tm) Specialists' Newsletter"
    Sun/Oracle Java Champion 2005-2013
    JavaOne Rockstar Speaker 2012
    http://www.javaspecialists.eu
    Tel: +30 69 75 595 262
    Skype: kabutz






  -- 
  Rafael Brand?o @ CIn - Center of Informatics 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140603/a60b32aa/attachment-0001.html>

From rblcin at gmail.com  Mon Jun  2 23:21:21 2014
From: rblcin at gmail.com (=?UTF-8?Q?Rafael_Brand=C3=A3o?=)
Date: Tue, 3 Jun 2014 00:21:21 -0300
Subject: [concurrency-interest] Potential threads getting stuck on
 WAITING(parking) in ReentrantLock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMENLKGAA.davidcholmes@aapt.net.au>
References: <CALHzM99tfwDecAUBoSDC63HR0vDSTSctULY6KacJEwq9fngeoA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMENLKGAA.davidcholmes@aapt.net.au>
Message-ID: <CALHzM98dWzaL46W2R29yZ0F+F0HmXtXtUZcOdXbftvUdLL9DkA@mail.gmail.com>

I can also reproduce this issue with java version "1.7.0_60": Java(TM) SE
Runtime Environment (build 1.7.0_60-b19) and Java HotSpot(TM) 64-Bit Server
VM (build 24.60-b09, mixed mode). It could be that bug then, thanks David.
:-)

I still find it weird how I can only reproduce this issue with my
ReentrantLock and not with the default ReentrantLock so far. If I
understood correctly this was a problem on AQS, so in theory I should get
stuck using the default ReentrantLock as well.

Thanks for your help!

Best regards,
Rafael


On Mon, Jun 2, 2014 at 11:35 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

>  Hi Rafael,
>
> Can you try Oracle JDK 7? This might be:
>
> https://bugs.openjdk.java.net/browse/JDK-7011859
>
> which was fixed in 8.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Rafael Brand?o
> *Sent:* Tuesday, 3 June 2014 11:44 AM
> *To:* Dr Heinz M. Kabutz
> *Cc:* concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> *Subject:* Re: [concurrency-interest] Potential threads getting stuck on
> WAITING(parking) in ReentrantLock
>
> Hello,
>
> David, I have now tested it with java version "1.8.0_05", Java(TM) SE
> Runtime Environment (build 1.8.0_05-b13) and Java HotSpot(TM) 64-Bit Server
> VM (build 25.5-b02, mixed mode). The problem with my nearly unmodified
> ReentrantLock getting stuck is no longer happening when I run the
> experiment. Would you also like me to test with any particular version?
> Thanks for the tip! Now about StackOverflowError, I don't see how it could
> be possible (I've posted a link to the code if you want to check), since
> there's no infinite recursion for example and each test run is relatively
> low in used resources.
>
> Heinz, I have posted the code on https://github.com/rafaelbrandao/msc -
> the latest commit message (it only has 3 commits) contains information on
> how to reproduce this issue. It seems to be fixed when I use Oracle JDK 8
> however.
>
> What could be causing the stuck threads? Is it possible this is a problem
> with the ReentrantLock algorithm/implementation?
>
> Best regards,
> Rafael
>
> On Sun, Jun 1, 2014 at 2:07 AM, Dr Heinz M. Kabutz <
> heinz at javaspecialists.eu> wrote:
>
>> Please send us a link to your code, both your ReentrantLock and the test
>> code?
>>
>> On 01/06/2014, David Holmes <davidcholmes at aapt.net.au> wrote:
>> > Hi Rafael,
>> >
>> > Does this reproduce with Oracle JDK or only the IcedTea distributions?
>> >
>> > The most likely issue is the StackOverflowError. Have excluded that
>> > possibility?
>> >
>> > David
>> >   -----Original Message-----
>> >   From: concurrency-interest-bounces at cs.oswego.edu
>> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael
>> > Brand?o
>> >   Sent: Sunday, 1 June 2014 8:50 AM
>> >   To: concurrency-interest at cs.oswego.edu
>> >   Subject: [concurrency-interest] Potential threads getting stuck on
>> > WAITING(parking) in ReentrantLock
>> >
>> >
>> >   Hello,
>> >
>> >
>> >   I'm working on a few changes for ReentrantLock to make A/B tests
>> between
>> > the original implementation and my modifications, so my first step was
>> to
>> > copy the sources of ReentrantLock, AbstractQueuedSynchronizer (shortly
>> AQS)
>> > and AbstractOwnableSynchronizer and put them in a different package.
>> After
>> > resolving basic compilation issues, I've found the issue with Unsafe
>> usage
>> > (insecurity exception) and I've solved it based on the article found in
>> [1].
>> > So basically my ReentrantLock has nothing different from the original
>> except
>> > for how I get the Unsafe in AQS.
>> >
>> >
>> >   After that, I've exhaustively conducted the following experiment: 200
>> > threads try to increment 1000 times each some integer counter protected
>> by
>> > explicit locks. There are 10 counters, so each counter has 20 threads
>> > concurrently trying to increment it. The main thread spawns all those
>> > threads and then wait for them with join method. Once I've ran this
>> > experiment many times (about 30000), it consistently get stuck in a
>> join for
>> > some thread when I use my almost unmodified ReentrantLock before 2000th
>> > attempt.
>> >
>> >
>> >   I've got the thread stacks in [2] and what I understood from it is
>> that
>> > the remaining threads are all stuck waiting for the lock to be released.
>> > However I've managed to print the owner of that lock and I see it's
>> unlocked
>> > and has no owner:
>> >
>> >
>> >     stuck thread state: WAITING
>> >     thread waiting lock: safe.ReentrantLock at 68a6a21a[Unlocked]
>> >     lock owner: null
>> >
>> >
>> >   I've been trying to reproduce it with the original ReentrantLock but I
>> > didn't get stuck so far. So I'm here to ask you if there's a known
>> issue on
>> > ReentrantLock that could cause this situation (and also be extremely
>> > unlikely to happen) or if there's something obvious that I should know
>> about
>> > the Unsafe usage given it's the only thing changed so far.
>> >
>> >
>> >   I suspect I have some disadvantage given that my nearly unmodified
>> class
>> > is not already compiled in the JVM (I could try to build the JDK
>> later), but
>> > this could only be a sign that the issue already exists in the code but
>> can
>> > only become more likely to happen in a slower implementation. I've also
>> > searched for related bugs and the closest thing I've found was [3].
>> >
>> >
>> >   I'm using a Intel(R) Core(tm) i7-3632QM notebook running Ubuntu
>> 12.04. Java
>>  > version is "1.7.0_55" and I'm using OpenJDK Runtime Environment
>> (IcedTea
>> > 2.4.7) (7u55-2.4.7-1ubuntu1~0.12.04.2) and OpenJDK 64-Bit Server VM
>> (build
>> > 24.51-b03, mixed mode). I've experienced this issue after copying
>> sources of
>> > jdk7u, jdk8u and jdk9.
>> >
>> >
>> >
>> >
>> >   Best regards,
>> >   Rafael
>> >
>> >
>> >
>> >
>> >   [1]
>> http://howtodoinjava.com/2013/10/19/usage-of-class-sun-misc-unsafe/
>> >   [2] https://gist.github.com/rafaelbrandao/4ec5f2cd272c4b8b183a
>> >   [3] https://bugs.openjdk.java.net/browse/JDK-8028686
>> >
>> >
>> >   --
>> >   Rafael Brand?o @ CIn - Center of Informatics
>>
>>
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun/Oracle Java Champion 2005-2013
>> JavaOne Rockstar Speaker 2012
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>>
>
>
>
> --
> Rafael Brand?o @ CIn - Center of Informatics
>
>


-- 
Rafael Brand?o @ CIn - Center of Informatics
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140603/08643cf6/attachment.html>

From davidcholmes at aapt.net.au  Mon Jun  2 23:25:32 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 3 Jun 2014 13:25:32 +1000
Subject: [concurrency-interest] Potential threads getting stuck on
	WAITING(parking) in ReentrantLock
In-Reply-To: <CALHzM98dWzaL46W2R29yZ0F+F0HmXtXtUZcOdXbftvUdLL9DkA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAENNKGAA.davidcholmes@aapt.net.au>

Maybe not so weird given that the bug was only ever observed using Semaphore and running a specific test case.

Race conditions are very fickle beasts :)

David
  -----Original Message-----
  From: Rafael Brand?o [mailto:rblcin at gmail.com]
  Sent: Tuesday, 3 June 2014 1:21 PM
  To: dholmes
  Cc: Dr Heinz M. Kabutz; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Potential threads getting stuck on WAITING(parking) in ReentrantLock


  I can also reproduce this issue with java version "1.7.0_60": Java(TM) SE Runtime Environment (build 1.7.0_60-b19) and Java HotSpot(TM) 64-Bit Server VM (build 24.60-b09, mixed mode). It could be that bug then, thanks David. :-)


  I still find it weird how I can only reproduce this issue with my ReentrantLock and not with the default ReentrantLock so far. If I understood correctly this was a problem on AQS, so in theory I should get stuck using the default ReentrantLock as well.


  Thanks for your help!


  Best regards,
  Rafael



  On Mon, Jun 2, 2014 at 11:35 PM, David Holmes <davidcholmes at aapt.net.au> wrote:

    Hi Rafael,

    Can you try Oracle JDK 7? This might be:

    https://bugs.openjdk.java.net/browse/JDK-7011859

    which was fixed in 8.

    David
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael Brand?o

      Sent: Tuesday, 3 June 2014 11:44 AM
      To: Dr Heinz M. Kabutz
      Cc: concurrency-interest at cs.oswego.edu; dholmes at ieee.org
      Subject: Re: [concurrency-interest] Potential threads getting stuck on WAITING(parking) in ReentrantLock


      Hello, 


      David, I have now tested it with java version "1.8.0_05", Java(TM) SE Runtime Environment (build 1.8.0_05-b13) and Java HotSpot(TM) 64-Bit Server VM (build 25.5-b02, mixed mode). The problem with my nearly unmodified ReentrantLock getting stuck is no longer happening when I run the experiment. Would you also like me to test with any particular version? Thanks for the tip! Now about StackOverflowError, I don't see how it could be possible (I've posted a link to the code if you want to check), since there's no infinite recursion for example and each test run is relatively low in used resources. 


      Heinz, I have posted the code on https://github.com/rafaelbrandao/msc - the latest commit message (it only has 3 commits) contains information on how to reproduce this issue. It seems to be fixed when I use Oracle JDK 8 however.


      What could be causing the stuck threads? Is it possible this is a problem with the ReentrantLock algorithm/implementation?


      Best regards,
      Rafael


      On Sun, Jun 1, 2014 at 2:07 AM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:

        Please send us a link to your code, both your ReentrantLock and the test code?


        On 01/06/2014, David Holmes <davidcholmes at aapt.net.au> wrote:
        > Hi Rafael,
        >
        > Does this reproduce with Oracle JDK or only the IcedTea distributions?
        >
        > The most likely issue is the StackOverflowError. Have excluded that
        > possibility?
        >
        > David
        >   -----Original Message-----
        >   From: concurrency-interest-bounces at cs.oswego.edu
        > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rafael
        > Brand?o
        >   Sent: Sunday, 1 June 2014 8:50 AM
        >   To: concurrency-interest at cs.oswego.edu
        >   Subject: [concurrency-interest] Potential threads getting stuck on
        > WAITING(parking) in ReentrantLock
        >
        >
        >   Hello,
        >
        >
        >   I'm working on a few changes for ReentrantLock to make A/B tests between
        > the original implementation and my modifications, so my first step was to
        > copy the sources of ReentrantLock, AbstractQueuedSynchronizer (shortly AQS)
        > and AbstractOwnableSynchronizer and put them in a different package. After
        > resolving basic compilation issues, I've found the issue with Unsafe usage
        > (insecurity exception) and I've solved it based on the article found in [1].
        > So basically my ReentrantLock has nothing different from the original except
        > for how I get the Unsafe in AQS.
        >
        >
        >   After that, I've exhaustively conducted the following experiment: 200
        > threads try to increment 1000 times each some integer counter protected by
        > explicit locks. There are 10 counters, so each counter has 20 threads
        > concurrently trying to increment it. The main thread spawns all those
        > threads and then wait for them with join method. Once I've ran this
        > experiment many times (about 30000), it consistently get stuck in a join for
        > some thread when I use my almost unmodified ReentrantLock before 2000th
        > attempt.
        >
        >
        >   I've got the thread stacks in [2] and what I understood from it is that
        > the remaining threads are all stuck waiting for the lock to be released.
        > However I've managed to print the owner of that lock and I see it's unlocked
        > and has no owner:
        >
        >
        >     stuck thread state: WAITING
        >     thread waiting lock: safe.ReentrantLock at 68a6a21a[Unlocked]
        >     lock owner: null
        >
        >
        >   I've been trying to reproduce it with the original ReentrantLock but I
        > didn't get stuck so far. So I'm here to ask you if there's a known issue on
        > ReentrantLock that could cause this situation (and also be extremely
        > unlikely to happen) or if there's something obvious that I should know about
        > the Unsafe usage given it's the only thing changed so far.
        >
        >
        >   I suspect I have some disadvantage given that my nearly unmodified class
        > is not already compiled in the JVM (I could try to build the JDK later), but
        > this could only be a sign that the issue already exists in the code but can
        > only become more likely to happen in a slower implementation. I've also
        > searched for related bugs and the closest thing I've found was [3].
        >
        >

        >   I'm using a Intel(R) Core(tm) i7-3632QM notebook running Ubuntu 12.04. Java

        > version is "1.7.0_55" and I'm using OpenJDK Runtime Environment (IcedTea
        > 2.4.7) (7u55-2.4.7-1ubuntu1~0.12.04.2) and OpenJDK 64-Bit Server VM (build
        > 24.51-b03, mixed mode). I've experienced this issue after copying sources of
        > jdk7u, jdk8u and jdk9.
        >
        >
        >
        >
        >   Best regards,
        >   Rafael
        >
        >
        >
        >
        >   [1] http://howtodoinjava.com/2013/10/19/usage-of-class-sun-misc-unsafe/
        >   [2] https://gist.github.com/rafaelbrandao/4ec5f2cd272c4b8b183a
        >   [3] https://bugs.openjdk.java.net/browse/JDK-8028686
        >
        >
        >   --
        >   Rafael Brand?o @ CIn - Center of Informatics



        --
        Dr Heinz M. Kabutz (PhD CompSci)
        Author of "The Java(tm) Specialists' Newsletter"
        Sun/Oracle Java Champion 2005-2013
        JavaOne Rockstar Speaker 2012
        http://www.javaspecialists.eu
        Tel: +30 69 75 595 262
        Skype: kabutz






      -- 
      Rafael Brand?o @ CIn - Center of Informatics 





  -- 
  Rafael Brand?o @ CIn - Center of Informatics 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140603/c13abc8b/attachment-0001.html>

From heinz at javaspecialists.eu  Tue Jun  3 08:06:13 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 03 Jun 2014 15:06:13 +0300
Subject: [concurrency-interest] Potential threads getting stuck on
 WAITING(parking) in ReentrantLock
In-Reply-To: <CALHzM98dWzaL46W2R29yZ0F+F0HmXtXtUZcOdXbftvUdLL9DkA@mail.gmail.com>
References: <CALHzM99tfwDecAUBoSDC63HR0vDSTSctULY6KacJEwq9fngeoA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMENLKGAA.davidcholmes@aapt.net.au>
	<CALHzM98dWzaL46W2R29yZ0F+F0HmXtXtUZcOdXbftvUdLL9DkA@mail.gmail.com>
Message-ID: <538DBA35.7060003@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140603/9948dbc9/attachment.html>

From vikas.vksingh at gmail.com  Wed Jun  4 14:54:42 2014
From: vikas.vksingh at gmail.com (vikas)
Date: Wed, 4 Jun 2014 11:54:42 -0700 (PDT)
Subject: [concurrency-interest] Single writer multiple readers no
	barriers -- safe ?
In-Reply-To: <1385707901.22231.YahooMailNeo@web120703.mail.ne1.yahoo.com>
References: <CAHbGfh1-5txgrnPn3V1Ee5yY261Mg8_iaaaWAVJkSVo9wKTL8Q@mail.gmail.com>
	<CAHjP37EtmdQCCoBXpbktUr2q-E6KuKGO38r+Gkd8WONuWQsW=w@mail.gmail.com>
	<1385707901.22231.YahooMailNeo@web120703.mail.ne1.yahoo.com>
Message-ID: <1401908082269-11048.post@n7.nabble.com>

>>On Fri, Nov 29, 2013 at 6:51 AM, Nitsan Wakart <[hidden email]> wrote:
>>From my experience, lazySet is indeed your best choice (but only a valid
choice for a single writer). You >>need a volatile read to match the HB
relationship otherwise the compiler is free to optimize the value you
>>read, so someone using your map in a loop may end up stuck if you don't do
it.

Hi Nitsan, 
   Why you said lazySet is a valid choice for single writer. Can you give
any reference or example on what can go wrong with multiple writers. 

>> You hopefully meant StoreStore | LoadStore .  Otherwise we have a very
>> subtle but serious problem.  >>(See
>> *http://www.hpl.hp.com/personal/Hans_Boehm/c++mm/no_write_fences.html
>> *for a C++ discussion >>from a few years ago.) 

Hi Hans,
  The link you provided is no more valid. Can you please provide the fresh
link 

thanks
vikas



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/Single-writer-multiple-readers-no-barriers-safe-tp10306p11048.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From vitalyd at gmail.com  Wed Jun  4 16:00:56 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 4 Jun 2014 16:00:56 -0400
Subject: [concurrency-interest] Single writer multiple readers no
 barriers -- safe ?
In-Reply-To: <1401908082269-11048.post@n7.nabble.com>
References: <CAHbGfh1-5txgrnPn3V1Ee5yY261Mg8_iaaaWAVJkSVo9wKTL8Q@mail.gmail.com>
	<CAHjP37EtmdQCCoBXpbktUr2q-E6KuKGO38r+Gkd8WONuWQsW=w@mail.gmail.com>
	<1385707901.22231.YahooMailNeo@web120703.mail.ne1.yahoo.com>
	<1401908082269-11048.post@n7.nabble.com>
Message-ID: <CAHjP37G3hEmM=Ab1CWZO401y-dydL0WW73Vwfnicwt2xXbCc2w@mail.gmail.com>

If you had multiple writers publishing a reference, lazySet won't work -
you'd need a CAS loop (or locking, depending on expected
contention/conflict rate).

Sent from my phone
On Jun 4, 2014 3:13 PM, "vikas" <vikas.vksingh at gmail.com> wrote:

> >>On Fri, Nov 29, 2013 at 6:51 AM, Nitsan Wakart <[hidden email]> wrote:
> >>From my experience, lazySet is indeed your best choice (but only a valid
> choice for a single writer). You >>need a volatile read to match the HB
> relationship otherwise the compiler is free to optimize the value you
> >>read, so someone using your map in a loop may end up stuck if you don't
> do
> it.
>
> Hi Nitsan,
>    Why you said lazySet is a valid choice for single writer. Can you give
> any reference or example on what can go wrong with multiple writers.
>
> >> You hopefully meant StoreStore | LoadStore .  Otherwise we have a very
> >> subtle but serious problem.  >>(See
> >> *http://www.hpl.hp.com/personal/Hans_Boehm/c++mm/no_write_fences.html
> >> *for a C++ discussion >>from a few years ago.)
>
> Hi Hans,
>   The link you provided is no more valid. Can you please provide the fresh
> link
>
> thanks
> vikas
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/Single-writer-multiple-readers-no-barriers-safe-tp10306p11048.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140604/82054594/attachment.html>

From rreja2000 at yahoo.com  Thu Jun  5 01:56:51 2014
From: rreja2000 at yahoo.com (Rohit Reja)
Date: Wed, 4 Jun 2014 22:56:51 -0700 (PDT)
Subject: [concurrency-interest] Executors.newCachedThreadPool()
In-Reply-To: <CAHjP37G3hEmM=Ab1CWZO401y-dydL0WW73Vwfnicwt2xXbCc2w@mail.gmail.com>
References: <CAHbGfh1-5txgrnPn3V1Ee5yY261Mg8_iaaaWAVJkSVo9wKTL8Q@mail.gmail.com>	<CAHjP37EtmdQCCoBXpbktUr2q-E6KuKGO38r+Gkd8WONuWQsW=w@mail.gmail.com>	<1385707901.22231.YahooMailNeo@web120703.mail.ne1.yahoo.com>	<1401908082269-11048.post@n7.nabble.com>
	<CAHjP37G3hEmM=Ab1CWZO401y-dydL0WW73Vwfnicwt2xXbCc2w@mail.gmail.com>
Message-ID: <1401947811.24303.YahooMailNeo@web120406.mail.ne1.yahoo.com>

Hi,

Why does the default implementation of?Executors.newCachedThreadPool() has Integer.MAX_VALUE as the upper limit for number of threads?
If I use this default implementation, don't I ?risk ?creating a lot of threads when a burst of tasks gets scheduled and JVM running out of stack memory?

What is recommended?

Thanks,
Rohit Reja




On Thursday, June 5, 2014 1:52 AM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
 


If you had multiple writers publishing a reference, lazySet won't work - you'd need a CAS loop (or locking, depending on expected contention/conflict rate).
Sent from my phone
On Jun 4, 2014 3:13 PM, "vikas" <vikas.vksingh at gmail.com> wrote:

>>On Fri, Nov 29, 2013 at 6:51 AM, Nitsan Wakart <[hidden email]> wrote:
>>>From my experience, lazySet is indeed your best choice (but only a valid
>choice for a single writer). You >>need a volatile read to match the HB
>relationship otherwise the compiler is free to optimize the value you
>>>read, so someone using your map in a loop may end up stuck if you don't do
>it.
>
>Hi Nitsan,
>? ?Why you said lazySet is a valid choice for single writer. Can you give
>any reference or example on what can go wrong with multiple writers.
>
>>> You hopefully meant StoreStore | LoadStore . ?Otherwise we have a very
>>> subtle but serious problem. ?>>(See
>>> *http://www.hpl.hp.com/personal/Hans_Boehm/c++mm/no_write_fences.html
>>> *for a C++ discussion >>from a few years ago.)
>
>Hi Hans,
>? The link you provided is no more valid. Can you please provide the fresh
>link
>
>thanks
>vikas
>
>
>
>--
>View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/Single-writer-multiple-readers-no-barriers-safe-tp10306p11048.html
>Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140604/f33642d7/attachment.html>

From nitsanw at yahoo.com  Thu Jun  5 08:14:41 2014
From: nitsanw at yahoo.com (Nitsan Wakart)
Date: Thu, 5 Jun 2014 05:14:41 -0700 (PDT)
Subject: [concurrency-interest] Single writer multiple readers no
	barriers -- safe ?
In-Reply-To: <CAHjP37G3hEmM=Ab1CWZO401y-dydL0WW73Vwfnicwt2xXbCc2w@mail.gmail.com>
References: <CAHbGfh1-5txgrnPn3V1Ee5yY261Mg8_iaaaWAVJkSVo9wKTL8Q@mail.gmail.com>	<CAHjP37EtmdQCCoBXpbktUr2q-E6KuKGO38r+Gkd8WONuWQsW=w@mail.gmail.com>	<1385707901.22231.YahooMailNeo@web120703.mail.ne1.yahoo.com>	<1401908082269-11048.post@n7.nabble.com>
	<CAHjP37G3hEmM=Ab1CWZO401y-dydL0WW73Vwfnicwt2xXbCc2w@mail.gmail.com>
Message-ID: <1401970481.66008.YahooMailNeo@web120702.mail.ne1.yahoo.com>



Q: Why you said lazySet is a valid choice for single writer. Can you give?any reference or example on what can go wrong with multiple writers.
A: ?If you had multiple writers publishing a reference, lazySet won't work* - you'd need a CAS loop (or locking, depending on expected contention/conflict rate).


* To clarify, lazySet would work in the sense that ordering will be preserved from the single writing thread POV. If you have multiple writers to an AtomicReference using lazySet you will see one of their writes (no fairness or order between writers is guaranteed). If this is all the guarantee you need that is fine. Usually some relationship is required between the writes, leading to a stronger ordering requirement than that offered by lazySet. How you would implement that is up to you, a CAS loop, getAndSet(XCHG), getAndAdd(LOCK XADD) or locking would typically end up being used.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140605/97b2e2f0/attachment-0001.html>

From radhakrishnan.mohan at gmail.com  Thu Jun  5 09:14:26 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 5 Jun 2014 18:44:26 +0530
Subject: [concurrency-interest] CompletableFuture - cancel incomplete
	requests
Message-ID: <CAOoXFP-iGrqLB58CepJf8bpAWuL=Usm9evG0E=agBb2b5ruQ+g@mail.gmail.com>

Hi,
       I would like to wait for a HTTP response or content by connecting to
multiple sites. Can I use 'anyOf' to cancel all incomplete
requests(response is not received or not fully streamed) if any one
completes ? I will decide when something completes by returning from
streamData.

Do I need a latch here to make the VM wait ?
Does NIO.2's async. support use these types of futures ?



Thanks,
Mohan


public class ReactiveCompletion {

    ExecutorService executor = Executors.newFixedThreadPool(4);

    private void fetch() throws IOException{

        CountDownLatch latch = new CountDownLatch(1);
        CompletableFuture future =
        CompletableFuture.anyOf(CompletableFuture.supplyAsync(() ->
streamData())
        .thenAccept(content -> {
            System.out.println("Completed");
            latch.countDown();
        })
        );
        try {
            latch.await();
        } catch (InterruptedException e) {
            System.out.println("Interrupted");
        }
    }

    private Content streamData(){
        Content content = null;
        try{
            CloseableHttpClient httpclient = HttpClients.createDefault();
            HttpGet httpget = new HttpGet("
http://data.gov.in/node/104089/datastore/export/json");
            CloseableHttpResponse response = httpclient.execute(httpget);
            try {
                HttpEntity entity = response.getEntity();
                if (entity != null) {
                    Scanner in = new Scanner(new BufferedReader(new
InputStreamReader(entity.getContent())));
                    while(in.hasNextLine() ){
                        System.out.println(in.nextLine());
                    }
                }
            } finally {
                response.close();
            }
        }catch (  IOException io){
            io.printStackTrace();
        }
        return content;
    }

    public static void main(String... argv) throws IOException {
        new ReactiveCompletion().fetch();
    }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140605/c45e0401/attachment.html>

From lukeisandberg at gmail.com  Fri Jun  6 12:17:36 2014
From: lukeisandberg at gmail.com (Luke Sandberg)
Date: Fri, 6 Jun 2014 09:17:36 -0700
Subject: [concurrency-interest] Proposal for a CallerRunsExecutor in
	j.u.c.Executors
In-Reply-To: <CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
References: <CAO9V1MKUEBD6Ea7yqHeqYW98JZX7cLv6zoyDgp7xu7051EHykg@mail.gmail.com>
	<5380DED8.9060103@cs.oswego.edu>
	<CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
Message-ID: <CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>

ping.  Is there anything i can do to help move this forward?

Thanks,
Luke


On Sat, May 24, 2014 at 3:15 PM, Luke Sandberg <lukeisandberg at gmail.com>
wrote:

> On Sat, May 24, 2014 at 11:03 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
>> On 05/23/2014 08:05 PM, Luke Sandberg wrote:
>>
>>> Guava has an Executor instance called MoreExecutors.sameThreadExecutor
>>> <http://docs.guava-libraries.googlecode.com/git/javadoc/
>>> com/google/common/util/concurrent/MoreExecutors.html#
>>> sameThreadExecutor()>
>>>
>>>
>>> For Guava users it is very popular for passing to APIs like
>>> ListenableFuture.addListener and other Executor accepting utilities for
>>> when the
>>> task will be quick enough that it isn't worth submitting to a thread
>>> pool.
>>>
>>> There was recently a performance bug reported against it:
>>> https://code.google.com/p/guava-libraries/issues/detail?id=1734
>>>
>>> This led to us reconsider the implementation in Guava and then thinking
>>> that
>>> maybe this should even be a j.u.c.Executors feature.
>>>
>>
>> The class has been sitting there under the name DirectExecutor
>> since JDK5 as a code example in the Executors javadoc.
>> (See http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/
>> concurrent/Executor.html)
>> We even discussed putting it (as well as the other code example,
>> ThreadPerTaskExecutor) in Executors but for some reason decided
>> they weren't important enough. But they are important in that
>> standardizing their names and usage will save people work.
>> So I can't think of a reason not to do this, even if a decade
>> too late for most purposes. Any objections to using these names?
>
>
> Yeah we noticed the DirectExecutor example too, but consensus appeared to
> be against using that name.  Also it was noted that in JCIP Brian Goetz
> calls the same thing 'WithinThreadExecutor'.  callerRunsExecutor was
> suggested due to the existence of ThreadPoolExecutor.CallerRunsPolicy. (And
> there were about 10 thousand other suggestions: immediateExecutor,
> currentThreadExecutor, synchronousExecutor,...).
>
> I have no objection to DirectExecutor though I do have a preference for
> CallerRunsExecutor.
>
> As for ThreadPerTaskExecutor, that name seems reasonable to me.
>
>
>
>>
>>
>>      MoreExecutors.newCallerRunsExecutorService():
>>>        which would be identical to the current sameThreadExecutor()
>>> (which
>>>     includes shutdown semantics)
>>>
>>
>>
>> I gather that this one uses a Lock just to support the
>> awaitTermination method? (Otherwise it would need only
>> a volatile boolean shutdown bit.) It does seem like a niche usage,
>> but maybe someone could make a case for including it.
>>
>
> That is correct.  I agree that this is less commonly useful (and it is
> often most useful in testing situations).  So just leaving this in Guava
> could make sense.  Martin Buchholz suggested just making the
> CallerRunsExecutor be a unshutdownable shared ExecutorService instance as a
> kind of compromise.
>
>
>>
>> -Doug
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140606/14f8cb07/attachment.html>

From radhakrishnan.mohan at gmail.com  Fri Jun 13 01:29:14 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Fri, 13 Jun 2014 10:59:14 +0530
Subject: [concurrency-interest] Passing argument to start method with
	Executor
Message-ID: <CAOoXFP8JFNOT7dKcreW8RNwBdRio6HRNmoSsXAVoZGTXL699xw@mail.gmail.com>

Hi,

    I am trying to work with sun.jvm.hotspot.tools.Tool which is a
Runnable. But it requires the start method to be called with arguments. It
looks like an older API.

    If I use ExecutorService executor = newFixedThreadPool(4); and execute
 sun.jvm.hotspot.tools.Tool then the contract is violated.

Is there a way to use an Executor and ensure the start method is called
with arguments ?

ThreadPoolExecutor calls 'start' deep in the code but  I am not sure how to
call a custom 'start' method which calls the thread's 'start' method in
turn.

Thanks,

Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140613/2ed3a75a/attachment.html>

From dms at sosnoski.com  Fri Jun 13 19:35:48 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 11:35:48 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
Message-ID: <539B8AD4.8090702@sosnoski.com>

I'm writing an article where I'm discussing both blocking waits and 
non-blocking callbacks for handling events. As I see it, there are two 
main reasons for preferring non-blocking:

1. Threads are expensive resources (limited to on the order of 10000 per 
JVM), and tying one up just waiting for an event completion is a waste 
of this resource
2. Thread switching adds substantial overhead to the application

Are there any other good reasons I'm missing?

On the thread switching issue, I tried a simple timing test where I 
create some number of threads and have them take turns incrementing a 
value, each one passing control off to the next after an increment. For 
a total of 4096*100 increments here's what I got on my 4-core AMD Linux 
desktop running Java 7:

Took 44 ms. with 1 threads
Took 3805 ms. with 2 threads
Took 6172 ms. with 4 threads
Took 6185 ms. with 8 threads
Took 6437 ms. with 16 threads
Took 6831 ms. with 32 threads
Took 6756 ms. with 64 threads
Took 6511 ms. with 128 threads
Took 6975 ms. with 256 threads
Took 7264 ms. with 512 threads
Took 7185 ms. with 1024 threads
Took 6826 ms. with 2048 threads
Took 7639 ms. with 4096 threads

So a big drop in performance going from one thread to two, and again 
from 2 to 4, but after than just a slowly increasing trend. That's about 
19 microseconds per switch with 4096 threads, about half that time for 
just 2 threads. Do these results make sense to others?

Thanks,

   - Dennis


From dl at cs.oswego.edu  Fri Jun 13 19:57:34 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 13 Jun 2014 19:57:34 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B8AD4.8090702@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>
Message-ID: <539B8FEE.8030107@cs.oswego.edu>

On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
> I'm writing an article where I'm discussing both blocking waits and non-blocking
> callbacks for handling events. As I see it, there are two main reasons for
> preferring non-blocking:
>
> 1. Threads are expensive resources (limited to on the order of 10000 per JVM),
> and tying one up just waiting for an event completion is a waste of this resource
> 2. Thread switching adds substantial overhead to the application
>
> Are there any other good reasons I'm missing?

Also memory locality (core X cache effects).

>
> On the thread switching issue, I tried a simple timing test where I create some
> number of threads and have them take turns incrementing a value, each one
> passing control off to the next after an increment. For a total of 4096*100
> increments here's what I got on my 4-core AMD Linux desktop running Java 7:
>
> Took 44 ms. with 1 threads
> Took 3805 ms. with 2 threads
> Took 6172 ms. with 4 threads
> Took 6185 ms. with 8 threads
> Took 6437 ms. with 16 threads
> Took 6831 ms. with 32 threads
> Took 6756 ms. with 64 threads
> Took 6511 ms. with 128 threads
> Took 6975 ms. with 256 threads
> Took 7264 ms. with 512 threads
> Took 7185 ms. with 1024 threads
> Took 6826 ms. with 2048 threads
> Took 7639 ms. with 4096 threads
>
> So a big drop in performance going from one thread to two, and again from 2 to
> 4, but after than just a slowly increasing trend. That's about 19 microseconds
> per switch with 4096 threads, about half that time for just 2 threads. Do these
> results make sense to others?

Your best case of approximately 20 thousand clock cycles is not an
unexpected result on a single-socket multicore with all cores turned
on (i.e., no power management, fusing, or clock-step effects)
and only a few bouncing cachelines.

We've seen cases of over 1 million cycles to unblock a thread
in some other cases. (Which can be challenging for us to deal
with in JDK8 Stream.parallel(). I'll post something on this sometime.)
Maybe Aleksey can someday arrange to collect believable
systematic measurements across a few platforms.

-Doug



From martinrb at google.com  Fri Jun 13 20:43:38 2014
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 13 Jun 2014 17:43:38 -0700
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B8AD4.8090702@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>
Message-ID: <CA+kOe0_=9vU6NtwshGxzUQWGznox2qETzJBmy_MoVwjHhqFuPA@mail.gmail.com>

http://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Herb-Sutter-Concurrency-and-Parallelism


On Fri, Jun 13, 2014 at 4:35 PM, Dennis Sosnoski <dms at sosnoski.com> wrote:

> I'm writing an article where I'm discussing both blocking waits and
> non-blocking callbacks for handling events. As I see it, there are two main
> reasons for preferring non-blocking:
>
> 1. Threads are expensive resources (limited to on the order of 10000 per
> JVM), and tying one up just waiting for an event completion is a waste of
> this resource
> 2. Thread switching adds substantial overhead to the application
>
> Are there any other good reasons I'm missing?
>
> On the thread switching issue, I tried a simple timing test where I create
> some number of threads and have them take turns incrementing a value, each
> one passing control off to the next after an increment. For a total of
> 4096*100 increments here's what I got on my 4-core AMD Linux desktop
> running Java 7:
>
> Took 44 ms. with 1 threads
> Took 3805 ms. with 2 threads
> Took 6172 ms. with 4 threads
> Took 6185 ms. with 8 threads
> Took 6437 ms. with 16 threads
> Took 6831 ms. with 32 threads
> Took 6756 ms. with 64 threads
> Took 6511 ms. with 128 threads
> Took 6975 ms. with 256 threads
> Took 7264 ms. with 512 threads
> Took 7185 ms. with 1024 threads
> Took 6826 ms. with 2048 threads
> Took 7639 ms. with 4096 threads
>
> So a big drop in performance going from one thread to two, and again from
> 2 to 4, but after than just a slowly increasing trend. That's about 19
> microseconds per switch with 4096 threads, about half that time for just 2
> threads. Do these results make sense to others?
>
> Thanks,
>
>   - Dennis
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140613/4d665a2b/attachment.html>

From dms at sosnoski.com  Fri Jun 13 20:51:58 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 12:51:58 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B8FEE.8030107@cs.oswego.edu>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
Message-ID: <539B9CAE.3010705@sosnoski.com>

On 06/14/2014 11:57 AM, Doug Lea wrote:
> On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>> I'm writing an article where I'm discussing both blocking waits and 
>> non-blocking
>> callbacks for handling events. As I see it, there are two main 
>> reasons for
>> preferring non-blocking:
>>
>> 1. Threads are expensive resources (limited to on the order of 10000 
>> per JVM),
>> and tying one up just waiting for an event completion is a waste of 
>> this resource
>> 2. Thread switching adds substantial overhead to the application
>>
>> Are there any other good reasons I'm missing?
>
> Also memory locality (core X cache effects).

I thought about that, though couldn't come up with any easy way of 
demonstrating the effect. I suppose something more memory-intensive 
would do this - perhaps having a fairly sizable array of values for each 
thread, and having the thread do some computation with those values each 
time it's run.

>
>>
>> ...
>> So a big drop in performance going from one thread to two, and again 
>> from 2 to
>> 4, but after than just a slowly increasing trend. That's about 19 
>> microseconds
>> per switch with 4096 threads, about half that time for just 2 
>> threads. Do these
>> results make sense to others?
>
> Your best case of approximately 20 thousand clock cycles is not an
> unexpected result on a single-socket multicore with all cores turned
> on (i.e., no power management, fusing, or clock-step effects)
> and only a few bouncing cachelines.
>
> We've seen cases of over 1 million cycles to unblock a thread
> in some other cases. (Which can be challenging for us to deal
> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
> Maybe Aleksey can someday arrange to collect believable
> systematic measurements across a few platforms.

The reason for the long delay being cache effects, right? I'll try some 
experiments with associated data per thread to see if I can demonstrate 
this on a small scale.

Thanks for the insights, Doug.

   - Dennis


From vitalyd at gmail.com  Fri Jun 13 21:31:28 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 13 Jun 2014 21:31:28 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B9CAE.3010705@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
	<539B9CAE.3010705@sosnoski.com>
Message-ID: <CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>

I'd think the 1M cycle delays to get a thread running again are probably
due to OS scheduling it on a cpu that is in a deep c-state; there can be
significant delays as the cpu powers back on.

Sent from my phone
On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com> wrote:

> On 06/14/2014 11:57 AM, Doug Lea wrote:
>
>> On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>
>>> I'm writing an article where I'm discussing both blocking waits and
>>> non-blocking
>>> callbacks for handling events. As I see it, there are two main reasons
>>> for
>>> preferring non-blocking:
>>>
>>> 1. Threads are expensive resources (limited to on the order of 10000 per
>>> JVM),
>>> and tying one up just waiting for an event completion is a waste of this
>>> resource
>>> 2. Thread switching adds substantial overhead to the application
>>>
>>> Are there any other good reasons I'm missing?
>>>
>>
>> Also memory locality (core X cache effects).
>>
>
> I thought about that, though couldn't come up with any easy way of
> demonstrating the effect. I suppose something more memory-intensive would
> do this - perhaps having a fairly sizable array of values for each thread,
> and having the thread do some computation with those values each time it's
> run.
>
>
>>
>>> ...
>>> So a big drop in performance going from one thread to two, and again
>>> from 2 to
>>> 4, but after than just a slowly increasing trend. That's about 19
>>> microseconds
>>> per switch with 4096 threads, about half that time for just 2 threads.
>>> Do these
>>> results make sense to others?
>>>
>>
>> Your best case of approximately 20 thousand clock cycles is not an
>> unexpected result on a single-socket multicore with all cores turned
>> on (i.e., no power management, fusing, or clock-step effects)
>> and only a few bouncing cachelines.
>>
>> We've seen cases of over 1 million cycles to unblock a thread
>> in some other cases. (Which can be challenging for us to deal
>> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
>> Maybe Aleksey can someday arrange to collect believable
>> systematic measurements across a few platforms.
>>
>
> The reason for the long delay being cache effects, right? I'll try some
> experiments with associated data per thread to see if I can demonstrate
> this on a small scale.
>
> Thanks for the insights, Doug.
>
>   - Dennis
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140613/fbbf7ab6/attachment.html>

From dms at sosnoski.com  Fri Jun 13 21:50:50 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 13:50:50 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>
	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
Message-ID: <539BAA7A.1020007@sosnoski.com>

On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>
> I'd think the 1M cycle delays to get a thread running again are 
> probably due to OS scheduling it on a cpu that is in a deep c-state; 
> there can be significant delays as the cpu powers back on.
>

That makes sense, but I'd think it would only be an issue for systems 
under light load.

   - Dennis

> Sent from my phone
>
> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com 
> <mailto:dms at sosnoski.com>> wrote:
>
>     On 06/14/2014 11:57 AM, Doug Lea wrote:
>
>         On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>
>             I'm writing an article where I'm discussing both blocking
>             waits and non-blocking
>             callbacks for handling events. As I see it, there are two
>             main reasons for
>             preferring non-blocking:
>
>             1. Threads are expensive resources (limited to on the
>             order of 10000 per JVM),
>             and tying one up just waiting for an event completion is a
>             waste of this resource
>             2. Thread switching adds substantial overhead to the
>             application
>
>             Are there any other good reasons I'm missing?
>
>
>         Also memory locality (core X cache effects).
>
>
>     I thought about that, though couldn't come up with any easy way of
>     demonstrating the effect. I suppose something more
>     memory-intensive would do this - perhaps having a fairly sizable
>     array of values for each thread, and having the thread do some
>     computation with those values each time it's run.
>
>
>
>             ...
>             So a big drop in performance going from one thread to two,
>             and again from 2 to
>             4, but after than just a slowly increasing trend. That's
>             about 19 microseconds
>             per switch with 4096 threads, about half that time for
>             just 2 threads. Do these
>             results make sense to others?
>
>
>         Your best case of approximately 20 thousand clock cycles is not an
>         unexpected result on a single-socket multicore with all cores
>         turned
>         on (i.e., no power management, fusing, or clock-step effects)
>         and only a few bouncing cachelines.
>
>         We've seen cases of over 1 million cycles to unblock a thread
>         in some other cases. (Which can be challenging for us to deal
>         with in JDK8 Stream.parallel(). I'll post something on this
>         sometime.)
>         Maybe Aleksey can someday arrange to collect believable
>         systematic measurements across a few platforms.
>
>
>     The reason for the long delay being cache effects, right? I'll try
>     some experiments with associated data per thread to see if I can
>     demonstrate this on a small scale.
>
>     Thanks for the insights, Doug.
>
>       - Dennis
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/2113d6e7/attachment-0001.html>

From vitalyd at gmail.com  Fri Jun 13 22:09:32 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 13 Jun 2014 22:09:32 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BAA7A.1020007@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
	<539B9CAE.3010705@sosnoski.com>
	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com>
Message-ID: <CAHjP37EduuXEB1fGEL-TCjBSwnCTxaqkmnhHT_hpPP84bpcCuA@mail.gmail.com>

I think this mostly equates to "unexplained" latency spikes.  It's true
that if you can peg all cores on a multi core machine then there won't be
enough idle cycles for the cpu to start powering down.

In practice, on machines with heterogeneous stuff running it's possible
that things align such that some core will power down and whenever
something gets scheduled to it, there will be a longer delay than normal.

I think for the purpose of your article this is maybe a nice little
footprint but is not a headline - my 2 cents.

Sent from my phone
On Jun 13, 2014 9:50 PM, "Dennis Sosnoski" <dms at sosnoski.com> wrote:

>  On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>
> I'd think the 1M cycle delays to get a thread running again are probably
> due to OS scheduling it on a cpu that is in a deep c-state; there can be
> significant delays as the cpu powers back on.
>
>
> That makes sense, but I'd think it would only be an issue for systems
> under light load.
>
>   - Dennis
>
>  Sent from my phone
> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com> wrote:
>
>> On 06/14/2014 11:57 AM, Doug Lea wrote:
>>
>>> On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>
>>>> I'm writing an article where I'm discussing both blocking waits and
>>>> non-blocking
>>>> callbacks for handling events. As I see it, there are two main reasons
>>>> for
>>>> preferring non-blocking:
>>>>
>>>> 1. Threads are expensive resources (limited to on the order of 10000
>>>> per JVM),
>>>> and tying one up just waiting for an event completion is a waste of
>>>> this resource
>>>> 2. Thread switching adds substantial overhead to the application
>>>>
>>>> Are there any other good reasons I'm missing?
>>>>
>>>
>>> Also memory locality (core X cache effects).
>>>
>>
>> I thought about that, though couldn't come up with any easy way of
>> demonstrating the effect. I suppose something more memory-intensive would
>> do this - perhaps having a fairly sizable array of values for each thread,
>> and having the thread do some computation with those values each time it's
>> run.
>>
>>
>>>
>>>> ...
>>>> So a big drop in performance going from one thread to two, and again
>>>> from 2 to
>>>> 4, but after than just a slowly increasing trend. That's about 19
>>>> microseconds
>>>> per switch with 4096 threads, about half that time for just 2 threads.
>>>> Do these
>>>> results make sense to others?
>>>>
>>>
>>> Your best case of approximately 20 thousand clock cycles is not an
>>> unexpected result on a single-socket multicore with all cores turned
>>> on (i.e., no power management, fusing, or clock-step effects)
>>> and only a few bouncing cachelines.
>>>
>>> We've seen cases of over 1 million cycles to unblock a thread
>>> in some other cases. (Which can be challenging for us to deal
>>> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
>>> Maybe Aleksey can someday arrange to collect believable
>>> systematic measurements across a few platforms.
>>>
>>
>> The reason for the long delay being cache effects, right? I'll try some
>> experiments with associated data per thread to see if I can demonstrate
>> this on a small scale.
>>
>> Thanks for the insights, Doug.
>>
>>   - Dennis
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140613/0a7a71cc/attachment.html>

From arcadiy at ivanov.biz  Fri Jun 13 22:32:57 2014
From: arcadiy at ivanov.biz (Arcadiy Ivanov)
Date: Fri, 13 Jun 2014 22:32:57 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BAA7A.1020007@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com>
Message-ID: <539BB459.2040600@ivanov.biz>

If memory serves me right, Mr Shipilev mentioned in one of his 
presentations in Oracle Spb DC re FJP optimization challenges (in 
Russian, sorry, https://www.youtube.com/watch?v=t0dGLFtRR9c#t=3096) that 
thread scheduling overhead of "sane OSes" (aka Linux) is approx 50 us on 
average, while 'certain not-quite-sane OS named starting with "W"' is 
much more than that.
Loaded Linux kernel can produce latencies in *tens of seconds* 
(http://www.versalogic.com/downloads/whitepapers/real-time_linux_benchmark.pdf, 
page 13) without RT patches, and tens of us with RT ones. YMMV 
dramatically depending on kernel, kernel version, scheduler, 
architecture and load.

That said, uncontended AbstractQueuedSynchronizer and everything based 
on it (ReentrantLock, Semaphore, CountDownLatch etc) is a single 
succeeding CAS (in best case scenario it could even be a cached volatile 
read such as in 0-count CountDownLatch), i.e. *relatively* inexpensive.

When talking about blocking vs non-blocking I would also take a close 
look at Quasar (https://github.com/puniverse/quasar) when discussing a 
scenario where one thread suspends after submitting a single task to 
pool and awaiting result of that task executing in the pool on, 
supposedly, other thread. Quasar implements continuations of sorts and 
resolves a problem of thread park/unpark in that quite narrow case while 
maintaining code Thread semantics (i.e. Fiber vs Thread) by executing 
the scheduled task on the same thread and avoiding park+wait/unpark.

On 2014-06-13 21:50, Dennis Sosnoski wrote:
> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>>
>> I'd think the 1M cycle delays to get a thread running again are 
>> probably due to OS scheduling it on a cpu that is in a deep c-state; 
>> there can be significant delays as the cpu powers back on.
>>
>
> That makes sense, but I'd think it would only be an issue for systems 
> under light load.
>
>   - Dennis
>
>> Sent from my phone
>>
>> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com 
>> <mailto:dms at sosnoski.com>> wrote:
>>
>>     On 06/14/2014 11:57 AM, Doug Lea wrote:
>>
>>         On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>
>>             I'm writing an article where I'm discussing both blocking
>>             waits and non-blocking
>>             callbacks for handling events. As I see it, there are two
>>             main reasons for
>>             preferring non-blocking:
>>
>>             1. Threads are expensive resources (limited to on the
>>             order of 10000 per JVM),
>>             and tying one up just waiting for an event completion is
>>             a waste of this resource
>>             2. Thread switching adds substantial overhead to the
>>             application
>>
>>             Are there any other good reasons I'm missing?
>>
>>
>>         Also memory locality (core X cache effects).
>>
>>
>>     I thought about that, though couldn't come up with any easy way
>>     of demonstrating the effect. I suppose something more
>>     memory-intensive would do this - perhaps having a fairly sizable
>>     array of values for each thread, and having the thread do some
>>     computation with those values each time it's run.
>>
>>
>>
>>             ...
>>             So a big drop in performance going from one thread to
>>             two, and again from 2 to
>>             4, but after than just a slowly increasing trend. That's
>>             about 19 microseconds
>>             per switch with 4096 threads, about half that time for
>>             just 2 threads. Do these
>>             results make sense to others?
>>
>>
>>         Your best case of approximately 20 thousand clock cycles is
>>         not an
>>         unexpected result on a single-socket multicore with all cores
>>         turned
>>         on (i.e., no power management, fusing, or clock-step effects)
>>         and only a few bouncing cachelines.
>>
>>         We've seen cases of over 1 million cycles to unblock a thread
>>         in some other cases. (Which can be challenging for us to deal
>>         with in JDK8 Stream.parallel(). I'll post something on this
>>         sometime.)
>>         Maybe Aleksey can someday arrange to collect believable
>>         systematic measurements across a few platforms.
>>
>>
>>     The reason for the long delay being cache effects, right? I'll
>>     try some experiments with associated data per thread to see if I
>>     can demonstrate this on a small scale.
>>
>>     Thanks for the insights, Doug.
>>
>>       - Dennis
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140613/cbf02492/attachment.html>

From dms at sosnoski.com  Sat Jun 14 00:31:21 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 16:31:21 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BB459.2040600@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
Message-ID: <539BD019.8090703@sosnoski.com>

On 06/14/2014 02:32 PM, Arcadiy Ivanov wrote:
> If memory serves me right, Mr Shipilev mentioned in one of his 
> presentations in Oracle Spb DC re FJP optimization challenges (in 
> Russian, sorry, https://www.youtube.com/watch?v=t0dGLFtRR9c#t=3096) 
> that thread scheduling overhead of "sane OSes" (aka Linux) is approx 
> 50 us on average, while 'certain not-quite-sane OS named starting with 
> "W"' is much more than that.
> Loaded Linux kernel can produce latencies in *tens of seconds* 
> (http://www.versalogic.com/downloads/whitepapers/real-time_linux_benchmark.pdf, 
> page 13) without RT patches, and tens of us with RT ones. YMMV 
> dramatically depending on kernel, kernel version, scheduler, 
> architecture and load.

Sounds scary, glad my kernel seems reasonable even without RT (stock 
OpenSUSE 12.3). I have a recentish W... OS installation on a laptop 
drive (I pulled it and replaced it with an SSD, but keep the original 
around for when I need to restore my keyboard backlight - you don't want 
to know). Maybe I'll give that a try to see how it compares to the Linux 
performance on the same system, just for fun.

>
> That said, uncontended AbstractQueuedSynchronizer and everything based 
> on it (ReentrantLock, Semaphore, CountDownLatch etc) is a single 
> succeeding CAS (in best case scenario it could even be a cached 
> volatile read such as in 0-count CountDownLatch), i.e. *relatively* 
> inexpensive.

I'm actually using direct wait()/notify() rather than a more 
sophisticated way of executing threads in turn, since I'm mostly 
interested in showing people why they should use callback-type event 
handling vs. blocking waits.

>
> When talking about blocking vs non-blocking I would also take a close 
> look at Quasar (https://github.com/puniverse/quasar) when discussing a 
> scenario where one thread suspends after submitting a single task to 
> pool and awaiting result of that task executing in the pool on, 
> supposedly, other thread. Quasar implements continuations of sorts and 
> resolves a problem of thread park/unpark in that quite narrow case 
> while maintaining code Thread semantics (i.e. Fiber vs Thread) by 
> executing the scheduled task on the same thread and avoiding 
> park+wait/unpark.

Yes, I'd noted Quasar from an earlier discussion on the list. It looks 
like it would make a good topic for a future article in the series. :-)

   - Dennis

>
> On 2014-06-13 21:50, Dennis Sosnoski wrote:
>> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>>>
>>> I'd think the 1M cycle delays to get a thread running again are 
>>> probably due to OS scheduling it on a cpu that is in a deep c-state; 
>>> there can be significant delays as the cpu powers back on.
>>>
>>
>> That makes sense, but I'd think it would only be an issue for systems 
>> under light load.
>>
>>   - Dennis
>>
>>> Sent from my phone
>>>
>>> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com 
>>> <mailto:dms at sosnoski.com>> wrote:
>>>
>>>     On 06/14/2014 11:57 AM, Doug Lea wrote:
>>>
>>>         On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>
>>>             I'm writing an article where I'm discussing both
>>>             blocking waits and non-blocking
>>>             callbacks for handling events. As I see it, there are
>>>             two main reasons for
>>>             preferring non-blocking:
>>>
>>>             1. Threads are expensive resources (limited to on the
>>>             order of 10000 per JVM),
>>>             and tying one up just waiting for an event completion is
>>>             a waste of this resource
>>>             2. Thread switching adds substantial overhead to the
>>>             application
>>>
>>>             Are there any other good reasons I'm missing?
>>>
>>>
>>>         Also memory locality (core X cache effects).
>>>
>>>
>>>     I thought about that, though couldn't come up with any easy way
>>>     of demonstrating the effect. I suppose something more
>>>     memory-intensive would do this - perhaps having a fairly sizable
>>>     array of values for each thread, and having the thread do some
>>>     computation with those values each time it's run.
>>>
>>>
>>>
>>>             ...
>>>             So a big drop in performance going from one thread to
>>>             two, and again from 2 to
>>>             4, but after than just a slowly increasing trend. That's
>>>             about 19 microseconds
>>>             per switch with 4096 threads, about half that time for
>>>             just 2 threads. Do these
>>>             results make sense to others?
>>>
>>>
>>>         Your best case of approximately 20 thousand clock cycles is
>>>         not an
>>>         unexpected result on a single-socket multicore with all
>>>         cores turned
>>>         on (i.e., no power management, fusing, or clock-step effects)
>>>         and only a few bouncing cachelines.
>>>
>>>         We've seen cases of over 1 million cycles to unblock a thread
>>>         in some other cases. (Which can be challenging for us to deal
>>>         with in JDK8 Stream.parallel(). I'll post something on this
>>>         sometime.)
>>>         Maybe Aleksey can someday arrange to collect believable
>>>         systematic measurements across a few platforms.
>>>
>>>
>>>     The reason for the long delay being cache effects, right? I'll
>>>     try some experiments with associated data per thread to see if I
>>>     can demonstrate this on a small scale.
>>>
>>>     Thanks for the insights, Doug.
>>>
>>>       - Dennis
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/6f807af2/attachment-0001.html>

From dms at sosnoski.com  Sat Jun 14 00:34:25 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 16:34:25 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <CA+kOe0_=9vU6NtwshGxzUQWGznox2qETzJBmy_MoVwjHhqFuPA@mail.gmail.com>
References: <539B8AD4.8090702@sosnoski.com>
	<CA+kOe0_=9vU6NtwshGxzUQWGznox2qETzJBmy_MoVwjHhqFuPA@mail.gmail.com>
Message-ID: <539BD0D1.9090307@sosnoski.com>

Wow, I don't even recognized C++ code anymore. This doesn't seem to 
really address the issue of why non-blocking, though, aside from the UI 
responsiveness issue (which most Java developers take for granted, since 
it's been part of the mindset since very early days).

   - Dennis

On 06/14/2014 12:43 PM, Martin Buchholz wrote:
> http://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Herb-Sutter-Concurrency-and-Parallelism
>
>
> On Fri, Jun 13, 2014 at 4:35 PM, Dennis Sosnoski <dms at sosnoski.com 
> <mailto:dms at sosnoski.com>> wrote:
>
>     I'm writing an article where I'm discussing both blocking waits
>     and non-blocking callbacks for handling events. As I see it, there
>     are two main reasons for preferring non-blocking:
>
>     1. Threads are expensive resources (limited to on the order of
>     10000 per JVM), and tying one up just waiting for an event
>     completion is a waste of this resource
>     2. Thread switching adds substantial overhead to the application
>
>     Are there any other good reasons I'm missing?
>
>     On the thread switching issue, I tried a simple timing test where
>     I create some number of threads and have them take turns
>     incrementing a value, each one passing control off to the next
>     after an increment. For a total of 4096*100 increments here's what
>     I got on my 4-core AMD Linux desktop running Java 7:
>
>     Took 44 ms. with 1 threads
>     Took 3805 ms. with 2 threads
>     Took 6172 ms. with 4 threads
>     Took 6185 ms. with 8 threads
>     Took 6437 ms. with 16 threads
>     Took 6831 ms. with 32 threads
>     Took 6756 ms. with 64 threads
>     Took 6511 ms. with 128 threads
>     Took 6975 ms. with 256 threads
>     Took 7264 ms. with 512 threads
>     Took 7185 ms. with 1024 threads
>     Took 6826 ms. with 2048 threads
>     Took 7639 ms. with 4096 threads
>
>     So a big drop in performance going from one thread to two, and
>     again from 2 to 4, but after than just a slowly increasing trend.
>     That's about 19 microseconds per switch with 4096 threads, about
>     half that time for just 2 threads. Do these results make sense to
>     others?
>
>     Thanks,
>
>       - Dennis
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/48189704/attachment.html>

From davidcholmes at aapt.net.au  Sat Jun 14 02:13:26 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 14 Jun 2014 16:13:26 +1000
Subject: [concurrency-interest] Passing argument to start method
	withExecutor
In-Reply-To: <CAOoXFP8JFNOT7dKcreW8RNwBdRio6HRNmoSsXAVoZGTXL699xw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEBMKHAA.davidcholmes@aapt.net.au>

Hi Mohan,

Tool implements Runnable but it is not intended to be used as a Runnable. It is a main application class that is intended to be subclassed. No connection to threads or executors and no connection between the fact that Thread has a start() method and so does Tool.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mohan Radhakrishnan
  Sent: Friday, 13 June 2014 3:29 PM
  To: Concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Passing argument to start method withExecutor


  Hi,

      I am trying to work with sun.jvm.hotspot.tools.Tool which is a Runnable. But it requires the start method to be called with arguments. It looks like an older API.   

      If I use ExecutorService executor = newFixedThreadPool(4); and execute  sun.jvm.hotspot.tools.Tool then the contract is violated. 

  Is there a way to use an Executor and ensure the start method is called with arguments ?

  ThreadPoolExecutor calls 'start' deep in the code but  I am not sure how to call a custom 'start' method which calls the thread's 'start' method in turn.

  Thanks,

  Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/166a01d4/attachment.html>

From arcadiy at ivanov.biz  Sat Jun 14 02:25:39 2014
From: arcadiy at ivanov.biz (Arcadiy Ivanov)
Date: Sat, 14 Jun 2014 02:25:39 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BD019.8090703@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<539BD019.8090703@sosnoski.com>
Message-ID: <539BEAE3.5030006@ivanov.biz>

On 2014-06-14 00:31, Dennis Sosnoski wrote:
>
> I'm actually using direct wait()/notify() rather than a more 
> sophisticated way of executing threads in turn, since I'm mostly 
> interested in showing people why they should use callback-type event 
> handling vs. blocking waits.
Interestingly enough, it actually depends on what you're doing. ;)

<imho>
Firstly, while everything you say about thousands of threads being a 
waste of resources is true, there are a few points to consider:

 1. Does your implementation satisfy user demand?
 2. Would it be cheaper to just get a bigger box/more boxes and stay
    with simple blocking code or would it be less expensive to
    (re-?)write the code to be non-blocking and then maintain it?

While I recognize my argument is somewhat tangential and narrower than 
the generic "wait/notify" vs "use callback" question, please consider this:

 1. Generally, only active threads are relevant. If you have a 100
    threads active at any given time it doesn't really matter
    context-switching-wise if you have 50k threads (that and more can be
    easily accomplished via trivial Linux kernel tuning) total. Yes you
    waste stack, PIDs and FDs but 24 CPU/128GB box already cost only
    ~$30k a year ago and pretty much any amount of development time is
    more expensive than adding another 128GB to the machine.
 2. If all you do is burn CPU, there is *no question* that the
    wait/notify is grossly inefficient vs a callback - Aleksey can
    elaborate at length what FJP optimizations were done to make sure
    that threads do not suspend waiting for tasks.
    If all you do is I/O and burn CPU based on that, the answer *could
    be* dramatically different: I/O latencies dominate any context
    switching overhead and on most OS'es when you perform most I/O there
    is an interrupt, a security context switch in kernel and possibly
    even a thread suspension and a thread context switch *anyway* in
    addition to that (you may get suspended with I/O syscall interrupt
    being handled by kernel thread pool)!
 3. Imagine you are processing a vast volume of SSH connections. At
    certain data volumes your load will be dominated by time of AES
    encryption/decryption of the SSH traffic, which will be a function
    of plain/ciphertext volume, not the number of threads. You're going
    to max out your compute at somewhere around 75MB/s/core of AES even
    with AES-NI, i.e. the number of clients you can reasonably support
    is, maybe, in low tens of thousands? If clients produce voluminous
    traffic then in low thousands. Even at 100% efficiency you're
    limited to those numbers. Does it make sense
    (time-/cost-/complexity-wise) to try to write a callback-based
    client that could handle hundreds of thousands or millions of
    clients *if not* for all that pesky encryption compute requirement
    you're going to be limited by anyway?
    Also, apparently, in heavy I/O scenarios, you may have a much better
    system throughput waiting for things to happen in I/O (blocking I/O)
    vs being notified of I/O events (Selector-based I/O):
    http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper is 6
    years old and kernel/Java realities might have changed, YMMV, but
    the difference is(was?) impressive. Also, Apache HTTP Client still
    swears by blocking I/O vs non-blocking one in terms of efficiency:
    http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore
 4. Callbacks, potentially, have to maintain and threads executing them
    have to switch application-defined contexts (e.g. current security
    principal, current transaction etc). How expensive it is depends on
    the application.
 5. *Callback hell* is not an urban myth and neither is architectural
    entropy. If you have a core of very competent developers that are
    going to work together on the product in perpetuity, callbacks are a
    reasonable and a very efficient solution. In enterprise environment
    with the number and the quality of the people that work on the code
    and with architectural preparation and control that time constraints
    allow and modularity demands, your callback hierarchy may
    disintegrate rapidly causing races, deadlocks etc forcing a complete
    rewrite in a just a few years or a complete project failure even
    before release. Blocking code is orders of magnitude easier to
    implement, validate and maintain, especially with people who cannot
    wrap their heads around the meaning of volatile after writing Java
    for a decade. Losing 20% (straw-man number) efficiency in thread
    context switching at high tens of thousands of threads is a small
    price to pay for the code that actually continues to work 10 years
    after it has been written. And you virtually always can add yet
    another box to increase your total throughput.
 6. Curiously, even a fully non-blocking algorithm that uses as many
    software threads as there are hardware ones with all data being
    thread-resident and no data sharing occurring can suffer severely
    from cache residency imbalance and demonstrate poor efficiency:
    https://blogs.oracle.com/dave/resource/spaa14-dice-UnfairnessResidency-CameraReady.pdf.
    This is to illustrate that there are monsters in virtually every
    approach and the end results may be quite surprising.

Again, not saying anything you said is wrong, but there are a few 
considerations other than eliminating context switches and reducing OS 
resource constraints when answering the question "should I block?" There 
are many tools, there are many scenarios, different tools are good for 
different scenarios => blanket recommendations are dangerous. :)
</imho>

- Arcadiy
> - Dennis
>
>>
>> On 2014-06-13 21:50, Dennis Sosnoski wrote:
>>> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>>>>
>>>> I'd think the 1M cycle delays to get a thread running again are 
>>>> probably due to OS scheduling it on a cpu that is in a deep 
>>>> c-state; there can be significant delays as the cpu powers back on.
>>>>
>>>
>>> That makes sense, but I'd think it would only be an issue for 
>>> systems under light load.
>>>
>>>   - Dennis
>>>
>>>> Sent from my phone
>>>>
>>>> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com 
>>>> <mailto:dms at sosnoski.com>> wrote:
>>>>
>>>>     On 06/14/2014 11:57 AM, Doug Lea wrote:
>>>>
>>>>         On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>>
>>>>             I'm writing an article where I'm discussing both
>>>>             blocking waits and non-blocking
>>>>             callbacks for handling events. As I see it, there are
>>>>             two main reasons for
>>>>             preferring non-blocking:
>>>>
>>>>             1. Threads are expensive resources (limited to on the
>>>>             order of 10000 per JVM),
>>>>             and tying one up just waiting for an event completion
>>>>             is a waste of this resource
>>>>             2. Thread switching adds substantial overhead to the
>>>>             application
>>>>
>>>>             Are there any other good reasons I'm missing?
>>>>
>>>>
>>>>         Also memory locality (core X cache effects).
>>>>
>>>>
>>>>     I thought about that, though couldn't come up with any easy way
>>>>     of demonstrating the effect. I suppose something more
>>>>     memory-intensive would do this - perhaps having a fairly
>>>>     sizable array of values for each thread, and having the thread
>>>>     do some computation with those values each time it's run.
>>>>
>>>>
>>>>
>>>>             ...
>>>>             So a big drop in performance going from one thread to
>>>>             two, and again from 2 to
>>>>             4, but after than just a slowly increasing trend.
>>>>             That's about 19 microseconds
>>>>             per switch with 4096 threads, about half that time for
>>>>             just 2 threads. Do these
>>>>             results make sense to others?
>>>>
>>>>
>>>>         Your best case of approximately 20 thousand clock cycles is
>>>>         not an
>>>>         unexpected result on a single-socket multicore with all
>>>>         cores turned
>>>>         on (i.e., no power management, fusing, or clock-step effects)
>>>>         and only a few bouncing cachelines.
>>>>
>>>>         We've seen cases of over 1 million cycles to unblock a thread
>>>>         in some other cases. (Which can be challenging for us to deal
>>>>         with in JDK8 Stream.parallel(). I'll post something on this
>>>>         sometime.)
>>>>         Maybe Aleksey can someday arrange to collect believable
>>>>         systematic measurements across a few platforms.
>>>>
>>>>
>>>>     The reason for the long delay being cache effects, right? I'll
>>>>     try some experiments with associated data per thread to see if
>>>>     I can demonstrate this on a small scale.
>>>>
>>>>     Thanks for the insights, Doug.
>>>>
>>>>       - Dennis
>>>>
>>>>     _______________________________________________
>>>>     Concurrency-interest mailing list
>>>>     Concurrency-interest at cs.oswego.edu
>>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/573adbd5/attachment-0001.html>

From dms at sosnoski.com  Sat Jun 14 02:43:43 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Sat, 14 Jun 2014 18:43:43 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BEAE3.5030006@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<539BD019.8090703@sosnoski.com> <539BEAE3.5030006@ivanov.biz>
Message-ID: <539BEF1F.6010106@sosnoski.com>

Interesting points, Arcadiy, and I agree on at least most of what you 
said. There certainly are times, especially in a single user 
application, when blocking operations are fine. IMHO the biggest coding 
problem with blocking code is the tendency to get into deadlocks (and 
the difficulty of avoiding at least the possibility of deadlocks when 
you starting using blocking waits throughout your system), but as long 
as your usage is simple this isn't likely to become a problem. And I 
have also experienced callback hell and know what that feels like (try 
understanding what's going on when debugging code that's using nested 
callbacks 10 levels deep). My preferred solution is actually to use an 
actor-type approach, whether formally with Akka or the like or 
informally by just using message passing as an alternative to either 
blocking or callbacks.

Hmmm. Now that I think about it, I've been telling people that there are 
just two fundamental ways of handling the completions of asynchronous 
events, with blocking waits or with callbacks. I suppose message passing 
could be considered a third way, even though it's kind of a variation of 
callbacks. Are there other ways that different significantly from these 
two (or three)?

   - Dennis

On 06/14/2014 06:25 PM, Arcadiy Ivanov wrote:
> On 2014-06-14 00:31, Dennis Sosnoski wrote:
>>
>> I'm actually using direct wait()/notify() rather than a more 
>> sophisticated way of executing threads in turn, since I'm mostly 
>> interested in showing people why they should use callback-type event 
>> handling vs. blocking waits.
> Interestingly enough, it actually depends on what you're doing. ;)
>
> <imho>
> Firstly, while everything you say about thousands of threads being a 
> waste of resources is true, there are a few points to consider:
>
>  1. Does your implementation satisfy user demand?
>  2. Would it be cheaper to just get a bigger box/more boxes and stay
>     with simple blocking code or would it be less expensive to
>     (re-?)write the code to be non-blocking and then maintain it?
>
> While I recognize my argument is somewhat tangential and narrower than 
> the generic "wait/notify" vs "use callback" question, please consider 
> this:
>
>  1. Generally, only active threads are relevant. If you have a 100
>     threads active at any given time it doesn't really matter
>     context-switching-wise if you have 50k threads (that and more can
>     be easily accomplished via trivial Linux kernel tuning) total. Yes
>     you waste stack, PIDs and FDs but 24 CPU/128GB box already cost
>     only ~$30k a year ago and pretty much any amount of development
>     time is more expensive than adding another 128GB to the machine.
>  2. If all you do is burn CPU, there is *no question* that the
>     wait/notify is grossly inefficient vs a callback - Aleksey can
>     elaborate at length what FJP optimizations were done to make sure
>     that threads do not suspend waiting for tasks.
>     If all you do is I/O and burn CPU based on that, the answer *could
>     be* dramatically different: I/O latencies dominate any context
>     switching overhead and on most OS'es when you perform most I/O
>     there is an interrupt, a security context switch in kernel and
>     possibly even a thread suspension and a thread context switch
>     *anyway* in addition to that (you may get suspended with I/O
>     syscall interrupt being handled by kernel thread pool)!
>  3. Imagine you are processing a vast volume of SSH connections. At
>     certain data volumes your load will be dominated by time of AES
>     encryption/decryption of the SSH traffic, which will be a function
>     of plain/ciphertext volume, not the number of threads. You're
>     going to max out your compute at somewhere around 75MB/s/core of
>     AES even with AES-NI, i.e. the number of clients you can
>     reasonably support is, maybe, in low tens of thousands? If clients
>     produce voluminous traffic then in low thousands. Even at 100%
>     efficiency you're limited to those numbers. Does it make sense
>     (time-/cost-/complexity-wise) to try to write a callback-based
>     client that could handle hundreds of thousands or millions of
>     clients *if not* for all that pesky encryption compute requirement
>     you're going to be limited by anyway?
>     Also, apparently, in heavy I/O scenarios, you may have a much
>     better system throughput waiting for things to happen in I/O
>     (blocking I/O) vs being notified of I/O events (Selector-based
>     I/O): http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper
>     is 6 years old and kernel/Java realities might have changed, YMMV,
>     but the difference is(was?) impressive. Also, Apache HTTP Client
>     still swears by blocking I/O vs non-blocking one in terms of
>     efficiency:
>     http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore
>  4. Callbacks, potentially, have to maintain and threads executing
>     them have to switch application-defined contexts (e.g. current
>     security principal, current transaction etc). How expensive it is
>     depends on the application.
>  5. *Callback hell* is not an urban myth and neither is architectural
>     entropy. If you have a core of very competent developers that are
>     going to work together on the product in perpetuity, callbacks are
>     a reasonable and a very efficient solution. In enterprise
>     environment with the number and the quality of the people that
>     work on the code and with architectural preparation and control
>     that time constraints allow and modularity demands, your callback
>     hierarchy may disintegrate rapidly causing races, deadlocks etc
>     forcing a complete rewrite in a just a few years or a complete
>     project failure even before release. Blocking code is orders of
>     magnitude easier to implement, validate and maintain, especially
>     with people who cannot wrap their heads around the meaning of
>     volatile after writing Java for a decade. Losing 20% (straw-man
>     number) efficiency in thread context switching at high tens of
>     thousands of threads is a small price to pay for the code that
>     actually continues to work 10 years after it has been written. And
>     you virtually always can add yet another box to increase your
>     total throughput.
>  6. Curiously, even a fully non-blocking algorithm that uses as many
>     software threads as there are hardware ones with all data being
>     thread-resident and no data sharing occurring can suffer severely
>     from cache residency imbalance and demonstrate poor efficiency:
>     https://blogs.oracle.com/dave/resource/spaa14-dice-UnfairnessResidency-CameraReady.pdf.
>     This is to illustrate that there are monsters in virtually every
>     approach and the end results may be quite surprising.
>
> Again, not saying anything you said is wrong, but there are a few 
> considerations other than eliminating context switches and reducing OS 
> resource constraints when answering the question "should I block?" 
> There are many tools, there are many scenarios, different tools are 
> good for different scenarios => blanket recommendations are dangerous. :)
> </imho>
>
> - Arcadiy
>>   - Dennis
>>
>>>
>>> On 2014-06-13 21:50, Dennis Sosnoski wrote:
>>>> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>>>>>
>>>>> I'd think the 1M cycle delays to get a thread running again are 
>>>>> probably due to OS scheduling it on a cpu that is in a deep 
>>>>> c-state; there can be significant delays as the cpu powers back on.
>>>>>
>>>>
>>>> That makes sense, but I'd think it would only be an issue for 
>>>> systems under light load.
>>>>
>>>>   - Dennis
>>>>
>>>>> Sent from my phone
>>>>>
>>>>> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com 
>>>>> <mailto:dms at sosnoski.com>> wrote:
>>>>>
>>>>>     On 06/14/2014 11:57 AM, Doug Lea wrote:
>>>>>
>>>>>         On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>>>
>>>>>             I'm writing an article where I'm discussing both
>>>>>             blocking waits and non-blocking
>>>>>             callbacks for handling events. As I see it, there are
>>>>>             two main reasons for
>>>>>             preferring non-blocking:
>>>>>
>>>>>             1. Threads are expensive resources (limited to on the
>>>>>             order of 10000 per JVM),
>>>>>             and tying one up just waiting for an event completion
>>>>>             is a waste of this resource
>>>>>             2. Thread switching adds substantial overhead to the
>>>>>             application
>>>>>
>>>>>             Are there any other good reasons I'm missing?
>>>>>
>>>>>
>>>>>         Also memory locality (core X cache effects).
>>>>>
>>>>>
>>>>>     I thought about that, though couldn't come up with any easy
>>>>>     way of demonstrating the effect. I suppose something more
>>>>>     memory-intensive would do this - perhaps having a fairly
>>>>>     sizable array of values for each thread, and having the thread
>>>>>     do some computation with those values each time it's run.
>>>>>
>>>>>
>>>>>
>>>>>             ...
>>>>>             So a big drop in performance going from one thread to
>>>>>             two, and again from 2 to
>>>>>             4, but after than just a slowly increasing trend.
>>>>>             That's about 19 microseconds
>>>>>             per switch with 4096 threads, about half that time for
>>>>>             just 2 threads. Do these
>>>>>             results make sense to others?
>>>>>
>>>>>
>>>>>         Your best case of approximately 20 thousand clock cycles
>>>>>         is not an
>>>>>         unexpected result on a single-socket multicore with all
>>>>>         cores turned
>>>>>         on (i.e., no power management, fusing, or clock-step effects)
>>>>>         and only a few bouncing cachelines.
>>>>>
>>>>>         We've seen cases of over 1 million cycles to unblock a thread
>>>>>         in some other cases. (Which can be challenging for us to deal
>>>>>         with in JDK8 Stream.parallel(). I'll post something on
>>>>>         this sometime.)
>>>>>         Maybe Aleksey can someday arrange to collect believable
>>>>>         systematic measurements across a few platforms.
>>>>>
>>>>>
>>>>>     The reason for the long delay being cache effects, right? I'll
>>>>>     try some experiments with associated data per thread to see if
>>>>>     I can demonstrate this on a small scale.
>>>>>
>>>>>     Thanks for the insights, Doug.
>>>>>
>>>>>       - Dennis
>>>>>
>>>>>     _______________________________________________
>>>>>     Concurrency-interest mailing list
>>>>>     Concurrency-interest at cs.oswego.edu
>>>>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/dd905b81/attachment.html>

From davidcholmes at aapt.net.au  Sat Jun 14 03:02:52 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 14 Jun 2014 17:02:52 +1000
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BEF1F.6010106@sosnoski.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBNKHAA.davidcholmes@aapt.net.au>

This is well trodden ground. See for example numerous papers, articles, etc
by Doug Schmidt on I/O frameworks and architectures.

http://www.dre.vanderbilt.edu/~schmidt/resume.html#books

In particular the POSA book(s).

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dennis
Sosnoski
  Sent: Saturday, 14 June 2014 4:44 PM
  To: Arcadiy Ivanov; Vitaly Davidovich
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Blocking vs. non-blocking


  Interesting points, Arcadiy, and I agree on at least most of what you
said. There certainly are times, especially in a single user application,
when blocking operations are fine. IMHO the biggest coding problem with
blocking code is the tendency to get into deadlocks (and the difficulty of
avoiding at least the possibility of deadlocks when you starting using
blocking waits throughout your system), but as long as your usage is simple
this isn't likely to become a problem. And I have also experienced callback
hell and know what that feels like (try understanding what's going on when
debugging code that's using nested callbacks 10 levels deep). My preferred
solution is actually to use an actor-type approach, whether formally with
Akka or the like or informally by just using message passing as an
alternative to either blocking or callbacks.

  Hmmm. Now that I think about it, I've been telling people that there are
just two fundamental ways of handling the completions of asynchronous
events, with blocking waits or with callbacks. I suppose message passing
could be considered a third way, even though it's kind of a variation of
callbacks. Are there other ways that different significantly from these two
(or three)?

    - Dennis

  On 06/14/2014 06:25 PM, Arcadiy Ivanov wrote:

    On 2014-06-14 00:31, Dennis Sosnoski wrote:


      I'm actually using direct wait()/notify() rather than a more
sophisticated way of executing threads in turn, since I'm mostly interested
in showing people why they should use callback-type event handling vs.
blocking waits.

    Interestingly enough, it actually depends on what you're doing. ;)

    <imho>
    Firstly, while everything you say about thousands of threads being a
waste of resources is true, there are a few points to consider:

      1.. Does your implementation satisfy user demand?

      2.. Would it be cheaper to just get a bigger box/more boxes and stay
with simple blocking code or would it be less expensive to (re-?)write the
code to be non-blocking and then maintain it?
    While I recognize my argument is somewhat tangential and narrower than
the generic "wait/notify" vs "use callback" question, please consider this:

      1.. Generally, only active threads are relevant. If you have a 100
threads active at any given time it doesn't really matter
context-switching-wise if you have 50k threads (that and more can be easily
accomplished via trivial Linux kernel tuning) total. Yes you waste stack,
PIDs and FDs but 24 CPU/128GB box already cost only ~$30k a year ago and
pretty much any amount of development time is more expensive than adding
another 128GB to the machine.

      2.. If all you do is burn CPU, there is *no question* that the
wait/notify is grossly inefficient vs a callback - Aleksey can elaborate at
length what FJP optimizations were done to make sure that threads do not
suspend waiting for tasks.
      If all you do is I/O and burn CPU based on that, the answer *could be*
dramatically different: I/O latencies dominate any context switching
overhead and on most OS'es when you perform most I/O there is an interrupt,
a security context switch in kernel and possibly even a thread suspension
and a thread context switch *anyway* in addition to that (you may get
suspended with I/O syscall interrupt being handled by kernel thread pool)!

      3.. Imagine you are processing a vast volume of SSH connections. At
certain data volumes your load will be dominated by time of AES
encryption/decryption of the SSH traffic, which will be a function of
plain/ciphertext volume, not the number of threads. You're going to max out
your compute at somewhere around 75MB/s/core of AES even with AES-NI, i.e.
the number of clients you can reasonably support is, maybe, in low tens of
thousands? If clients produce voluminous traffic then in low thousands. Even
at 100% efficiency you're limited to those numbers. Does it make sense
(time-/cost-/complexity-wise) to try to write a callback-based client that
could handle hundreds of thousands or millions of clients *if not* for all
that pesky encryption compute requirement you're going to be limited by
anyway?
      Also, apparently, in heavy I/O scenarios, you may have a much better
system throughput waiting for things to happen in I/O (blocking I/O) vs
being notified of I/O events (Selector-based I/O):
http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper is 6 years old
and kernel/Java realities might have changed, YMMV, but the difference
is(was?) impressive. Also, Apache HTTP Client still swears by blocking I/O
vs non-blocking one in terms of efficiency:
http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore
      4.. Callbacks, potentially, have to maintain and threads executing
them have to switch application-defined contexts (e.g. current security
principal, current transaction etc). How expensive it is depends on the
application.

      5.. *Callback hell* is not an urban myth and neither is architectural
entropy. If you have a core of very competent developers that are going to
work together on the product in perpetuity, callbacks are a reasonable and a
very efficient solution. In enterprise environment with the number and the
quality of the people that work on the code and with architectural
preparation and control that time constraints allow and modularity demands,
your callback hierarchy may disintegrate rapidly causing races, deadlocks
etc forcing a complete rewrite in a just a few years or a complete project
failure even before release. Blocking code is orders of magnitude easier to
implement, validate and maintain, especially with people who cannot wrap
their heads around the meaning of volatile after writing Java for a decade.
Losing 20% (straw-man number) efficiency in thread context switching at high
tens of thousands of threads is a small price to pay for the code that
actually continues to work 10 years after it has been written. And you
virtually always can add yet another box to increase your total throughput.
      6.. Curiously, even a fully non-blocking algorithm that uses as many
software threads as there are hardware ones with all data being
thread-resident and no data sharing occurring can suffer severely from cache
residency imbalance and demonstrate poor efficiency:
https://blogs.oracle.com/dave/resource/spaa14-dice-UnfairnessResidency-Camer
aReady.pdf. This is to illustrate that there are monsters in virtually every
approach and the end results may be quite surprising.

    Again, not saying anything you said is wrong, but there are a few
considerations other than eliminating context switches and reducing OS
resource constraints when answering the question "should I block?" There are
many tools, there are many scenarios, different tools are good for different
scenarios => blanket recommendations are dangerous. :)
    </imho>

    - Arcadiy

        - Dennis



        On 2014-06-13 21:50, Dennis Sosnoski wrote:

          On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:

            I'd think the 1M cycle delays to get a thread running again are
probably due to OS scheduling it on a cpu that is in a deep c-state; there
can be significant delays as the cpu powers back on.


          That makes sense, but I'd think it would only be an issue for
systems under light load.

            - Dennis


            Sent from my phone

            On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com>
wrote:

              On 06/14/2014 11:57 AM, Doug Lea wrote:

                On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:

                  I'm writing an article where I'm discussing both blocking
waits and non-blocking
                  callbacks for handling events. As I see it, there are two
main reasons for
                  preferring non-blocking:

                  1. Threads are expensive resources (limited to on the
order of 10000 per JVM),
                  and tying one up just waiting for an event completion is a
waste of this resource
                  2. Thread switching adds substantial overhead to the
application

                  Are there any other good reasons I'm missing?


                Also memory locality (core X cache effects).


              I thought about that, though couldn't come up with any easy
way of demonstrating the effect. I suppose something more memory-intensive
would do this - perhaps having a fairly sizable array of values for each
thread, and having the thread do some computation with those values each
time it's run.





                  ...
                  So a big drop in performance going from one thread to two,
and again from 2 to
                  4, but after than just a slowly increasing trend. That's
about 19 microseconds
                  per switch with 4096 threads, about half that time for
just 2 threads. Do these
                  results make sense to others?


                Your best case of approximately 20 thousand clock cycles is
not an
                unexpected result on a single-socket multicore with all
cores turned
                on (i.e., no power management, fusing, or clock-step
effects)
                and only a few bouncing cachelines.

                We've seen cases of over 1 million cycles to unblock a
thread
                in some other cases. (Which can be challenging for us to
deal
                with in JDK8 Stream.parallel(). I'll post something on this
sometime.)
                Maybe Aleksey can someday arrange to collect believable
                systematic measurements across a few platforms.


              The reason for the long delay being cache effects, right? I'll
try some experiments with associated data per thread to see if I can
demonstrate this on a small scale.

              Thanks for the insights, Doug.

                - Dennis

              _______________________________________________
              Concurrency-interest mailing list
              Concurrency-interest at cs.oswego.edu
              http://cs.oswego.edu/mailman/listinfo/concurrency-interest





_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/2808254f/attachment-0001.html>

From stanimir at riflexo.com  Sat Jun 14 05:54:56 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Sat, 14 Jun 2014 12:54:56 +0300
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BEAE3.5030006@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
	<539B9CAE.3010705@sosnoski.com>
	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<539BD019.8090703@sosnoski.com> <539BEAE3.5030006@ivanov.biz>
Message-ID: <CAEJX8optWz8kH5CdPU=hzXcBL=M3BUPJa2Ym42AMwRfq-=Ui8A@mail.gmail.com>

>
> Also, apparently, in heavy I/O scenarios, you may have a much better
> system throughput waiting for things to happen in I/O (blocking I/O) vs
> being notified of I/O events (Selector-based I/O):
> http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper is 6 years old
> and kernel/Java realities might have changed, YMMV, but the difference
> is(was?) impressive. Also, Apache HTTP Client still swears by blocking I/O
> vs non-blocking one in terms of efficiency:
> http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore


Blocking IO is basically a single threaded poll() + copying the buffer via
malloc/free (or stack alloc for smaller arrays); selector based NIO is
epoll() without the copy when direct buffers are used. Windows is worse as
WaitForMultipleObjects  is limited to 64 handle, hence it requires tiered
threads to implement a selector.

Waking up a selector, esp. when done via naked wakeup(), suffers from
unneeded contention. I am not sure if that has been filed as a bug/feature
request in JDK, yet the impl is like that
    public Selector wakeup() {
        synchronized (interruptLock) {
            if (!interruptTriggered) {
                pollWrapper.interrupt();
                interruptTriggered = true;
            }
        }
        return this;
    }
 pollWrapper.interrupt() call is the real wakeup via Pipe or a pair of
sockets. The call completes relatively slow and causes stall of all
concurrent calls to Selector.wakeup - which is mostly used for writing.
That requires a check+CAS around Selector.wakeup to ensure only a single
thread carries the call.
More also Java lacks a good,out of the box MP/SC queue (preferably bounded)
to implement the event queue (writes/registration) for the selector loop.
Recently I had a look at netty.io and the implementation seems to pick
almost all tricks in the book.

There is no way a good implementation of NIO to lose to a blocking one.
Yet, the biggest downside is measuring just the throughput which is rarely
what matters -- blocking IO doesn't offer any reasonable means to control
latency, which thread(respectively socket) is scheduled depends entirely on
the OS scheduler. The latter is especially true when delivering real-time
information like market quotes.


Stanimir


On Sat, Jun 14, 2014 at 9:25 AM, Arcadiy Ivanov <arcadiy at ivanov.biz> wrote:

>  On 2014-06-14 00:31, Dennis Sosnoski wrote:
>
>
> I'm actually using direct wait()/notify() rather than a more sophisticated
> way of executing threads in turn, since I'm mostly interested in showing
> people why they should use callback-type event handling vs. blocking waits.
>
> Interestingly enough, it actually depends on what you're doing. ;)
>
> <imho>
> Firstly, while everything you say about thousands of threads being a waste
> of resources is true, there are a few points to consider:
>
>    1. Does your implementation satisfy user demand?
>     2. Would it be cheaper to just get a bigger box/more boxes and stay
>    with simple blocking code or would it be less expensive to (re-?)write the
>    code to be non-blocking and then maintain it?
>
> While I recognize my argument is somewhat tangential and narrower than the
> generic "wait/notify" vs "use callback" question, please consider this:
>
>    1. Generally, only active threads are relevant. If you have a 100
>    threads active at any given time it doesn't really matter
>    context-switching-wise if you have 50k threads (that and more can be easily
>    accomplished via trivial Linux kernel tuning) total. Yes you waste stack,
>    PIDs and FDs but 24 CPU/128GB box already cost only ~$30k a year ago and
>    pretty much any amount of development time is more expensive than adding
>    another 128GB to the machine.
>     2. If all you do is burn CPU, there is *no question* that the
>    wait/notify is grossly inefficient vs a callback - Aleksey can elaborate at
>    length what FJP optimizations were done to make sure that threads do not
>    suspend waiting for tasks.
>    If all you do is I/O and burn CPU based on that, the answer *could be*
>    dramatically different: I/O latencies dominate any context switching
>    overhead and on most OS'es when you perform most I/O there is an interrupt,
>    a security context switch in kernel and possibly even a thread suspension
>    and a thread context switch *anyway* in addition to that (you may get
>    suspended with I/O syscall interrupt being handled by kernel thread pool)!
>     3. Imagine you are processing a vast volume of SSH connections. At
>    certain data volumes your load will be dominated by time of AES
>    encryption/decryption of the SSH traffic, which will be a function of
>    plain/ciphertext volume, not the number of threads. You're going to max out
>    your compute at somewhere around 75MB/s/core of AES even with AES-NI, i.e.
>    the number of clients you can reasonably support is, maybe, in low tens of
>    thousands? If clients produce voluminous traffic then in low thousands.
>    Even at 100% efficiency you're limited to those numbers. Does it make sense
>    (time-/cost-/complexity-wise) to try to write a callback-based client that
>    could handle hundreds of thousands or millions of clients *if not* for all
>    that pesky encryption compute requirement you're going to be limited by
>    anyway?
>    Also, apparently, in heavy I/O scenarios, you may have a much better
>    system throughput waiting for things to happen in I/O (blocking I/O) vs
>    being notified of I/O events (Selector-based I/O):
>    http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper is 6 years
>    old and kernel/Java realities might have changed, YMMV, but the difference
>    is(was?) impressive. Also, Apache HTTP Client still swears by blocking I/O
>    vs non-blocking one in terms of efficiency:
>    http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore
>    4. Callbacks, potentially, have to maintain and threads executing them
>    have to switch application-defined contexts (e.g. current security
>    principal, current transaction etc). How expensive it is depends on the
>    application.
>     5. *Callback hell* is not an urban myth and neither is architectural
>    entropy. If you have a core of very competent developers that are going to
>    work together on the product in perpetuity, callbacks are a reasonable and
>    a very efficient solution. In enterprise environment with the number and
>    the quality of the people that work on the code and with architectural
>    preparation and control that time constraints allow and modularity demands,
>    your callback hierarchy may disintegrate rapidly causing races, deadlocks
>    etc forcing a complete rewrite in a just a few years or a complete project
>    failure even before release. Blocking code is orders of magnitude easier to
>    implement, validate and maintain, especially with people who cannot wrap
>    their heads around the meaning of volatile after writing Java for a decade.
>    Losing 20% (straw-man number) efficiency in thread context switching at
>    high tens of thousands of threads is a small price to pay for the code that
>    actually continues to work 10 years after it has been written. And you
>    virtually always can add yet another box to increase your total throughput.
>    6. Curiously, even a fully non-blocking algorithm that uses as many
>    software threads as there are hardware ones with all data being
>    thread-resident and no data sharing occurring can suffer severely from
>    cache residency imbalance and demonstrate poor efficiency:
>    https://blogs.oracle.com/dave/resource/spaa14-dice-UnfairnessResidency-CameraReady.pdf.
>    This is to illustrate that there are monsters in virtually every approach
>    and the end results may be quite surprising.
>
> Again, not saying anything you said is wrong, but there are a few
> considerations other than eliminating context switches and reducing OS
> resource constraints when answering the question "should I block?" There
> are many tools, there are many scenarios, different tools are good for
> different scenarios => blanket recommendations are dangerous. :)
> </imho>
>
> - Arcadiy
>
>    - Dennis
>
>
> On 2014-06-13 21:50, Dennis Sosnoski wrote:
>
> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>
> I'd think the 1M cycle delays to get a thread running again are probably
> due to OS scheduling it on a cpu that is in a deep c-state; there can be
> significant delays as the cpu powers back on.
>
>
> That makes sense, but I'd think it would only be an issue for systems
> under light load.
>
>   - Dennis
>
>  Sent from my phone
> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com> wrote:
>
>> On 06/14/2014 11:57 AM, Doug Lea wrote:
>>
>>> On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>
>>>> I'm writing an article where I'm discussing both blocking waits and
>>>> non-blocking
>>>> callbacks for handling events. As I see it, there are two main reasons
>>>> for
>>>> preferring non-blocking:
>>>>
>>>> 1. Threads are expensive resources (limited to on the order of 10000
>>>> per JVM),
>>>> and tying one up just waiting for an event completion is a waste of
>>>> this resource
>>>> 2. Thread switching adds substantial overhead to the application
>>>>
>>>> Are there any other good reasons I'm missing?
>>>>
>>>
>>> Also memory locality (core X cache effects).
>>>
>>
>> I thought about that, though couldn't come up with any easy way of
>> demonstrating the effect. I suppose something more memory-intensive would
>> do this - perhaps having a fairly sizable array of values for each thread,
>> and having the thread do some computation with those values each time it's
>> run.
>>
>>
>>>
>>>> ...
>>>> So a big drop in performance going from one thread to two, and again
>>>> from 2 to
>>>> 4, but after than just a slowly increasing trend. That's about 19
>>>> microseconds
>>>> per switch with 4096 threads, about half that time for just 2 threads.
>>>> Do these
>>>> results make sense to others?
>>>>
>>>
>>> Your best case of approximately 20 thousand clock cycles is not an
>>> unexpected result on a single-socket multicore with all cores turned
>>> on (i.e., no power management, fusing, or clock-step effects)
>>> and only a few bouncing cachelines.
>>>
>>> We've seen cases of over 1 million cycles to unblock a thread
>>> in some other cases. (Which can be challenging for us to deal
>>> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
>>> Maybe Aleksey can someday arrange to collect believable
>>> systematic measurements across a few platforms.
>>>
>>
>> The reason for the long delay being cache effects, right? I'll try some
>> experiments with associated data per thread to see if I can demonstrate
>> this on a small scale.
>>
>> Thanks for the insights, Doug.
>>
>>   - Dennis
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/d229d57a/attachment-0001.html>

From kasperni at gmail.com  Sat Jun 14 06:01:49 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Sat, 14 Jun 2014 12:01:49 +0200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B8AD4.8090702@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>
Message-ID: <CAPs6153bDB2frUreN+t4OeuHGkk5AdB=2QJJVFr8gjWpUG2XNg@mail.gmail.com>

On Sat, Jun 14, 2014 at 1:35 AM, Dennis Sosnoski <dms at sosnoski.com> wrote:

> I'm writing an article where I'm discussing both blocking waits and
> non-blocking callbacks for handling events. As I see it, there are two main
> reasons for preferring non-blocking:
>
> 1. Threads are expensive resources (limited to on the order of 10000 per
> JVM), and tying one up just waiting for an event completion is a waste of
> this resource
> 2. Thread switching adds substantial overhead to the application
>
> Are there any other good reasons I'm missing?
>
If you include non-performance reasons. Blocking waits scores big on
simpler control flow, easier to debug and no manual stack management.

- Kasper
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140614/3bed64cf/attachment.html>

From aleksey.shipilev at oracle.com  Sat Jun 14 15:04:17 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Sat, 14 Jun 2014 21:04:17 +0200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539B8FEE.8030107@cs.oswego.edu>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
Message-ID: <C4FE4E15-12B8-4107-8AD3-415C43C0F400@oracle.com>


On 14.06.2014, at 1:57, Doug Lea <dl at cs.oswego.edu> wrote:

> Your best case of approximately 20 thousand clock cycles is not an
> unexpected result on a single-socket multicore with all cores turned
> on (i.e., no power management, fusing, or clock-step effects)
> and only a few bouncing cachelines

+1. The empirical rule of thumb we figured in early JDK 8 work was that you need around 50 us to wakeup the thread on Linux and Solaris (i.e. at least 50us passes since the wakeup request like LockSupport.unpark before thread starts executing after wakeup).

> We've seen cases of over 1 million cycles to unblock a thread
> in some other cases. (Which can be challenging for us to deal
> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
> Maybe Aleksey can someday arrange to collect believable
> systematic measurements across a few platforms.

Yeah, I should definitely do that some time this summer.

Crawling back to enjoy my vacation,
-Aleksey

From ron.pressler at gmail.com  Sun Jun 15 17:48:25 2014
From: ron.pressler at gmail.com (Ron Pressler)
Date: Mon, 16 Jun 2014 00:48:25 +0300
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BEAE3.5030006@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com> <539B8FEE.8030107@cs.oswego.edu>
	<539B9CAE.3010705@sosnoski.com>
	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<539BD019.8090703@sosnoski.com> <539BEAE3.5030006@ivanov.biz>
Message-ID: <CABg6-qi+S7i7gzoWgCR10t4aG=qpdWB1rYhc--w3NV62CWByAQ@mail.gmail.com>

Well, in the case of IO-heavy code (say, a web server), what often matters
most is the number of requests you can handle per second. This is
determined, according to Little's Law, by your latency and capacity (the
number of requests you can service concurrently). Now, in web servers you
often have little control over the latency -- it depends on your database
or on other microservices -- but the choice of blocking vs. nonblocking can
have a sever impact on capacity.

Recently we did a little experiment with common Java web servers, and found
<http://blog.paralleluniverse.co/2014/05/29/cascading-failures/> that
blocking code is severely susceptible to cascading failure as a result of a
temporary rise in latency (due to lack of headroom capacity). Switching to
nonblocking (well, actually the code stayed the same, but we told the
servers to use fibers instead of threads when serving HTTP requests), we
got an immediate 4x increase in server capacity.


On Sat, Jun 14, 2014 at 9:25 AM, Arcadiy Ivanov <arcadiy at ivanov.biz> wrote:

>  On 2014-06-14 00:31, Dennis Sosnoski wrote:
>
>
> I'm actually using direct wait()/notify() rather than a more sophisticated
> way of executing threads in turn, since I'm mostly interested in showing
> people why they should use callback-type event handling vs. blocking waits.
>
> Interestingly enough, it actually depends on what you're doing. ;)
>
> <imho>
> Firstly, while everything you say about thousands of threads being a waste
> of resources is true, there are a few points to consider:
>
>    1. Does your implementation satisfy user demand?
>     2. Would it be cheaper to just get a bigger box/more boxes and stay
>    with simple blocking code or would it be less expensive to (re-?)write the
>    code to be non-blocking and then maintain it?
>
> While I recognize my argument is somewhat tangential and narrower than the
> generic "wait/notify" vs "use callback" question, please consider this:
>
>    1. Generally, only active threads are relevant. If you have a 100
>    threads active at any given time it doesn't really matter
>    context-switching-wise if you have 50k threads (that and more can be easily
>    accomplished via trivial Linux kernel tuning) total. Yes you waste stack,
>    PIDs and FDs but 24 CPU/128GB box already cost only ~$30k a year ago and
>    pretty much any amount of development time is more expensive than adding
>    another 128GB to the machine.
>     2. If all you do is burn CPU, there is *no question* that the
>    wait/notify is grossly inefficient vs a callback - Aleksey can elaborate at
>    length what FJP optimizations were done to make sure that threads do not
>    suspend waiting for tasks.
>    If all you do is I/O and burn CPU based on that, the answer *could be*
>    dramatically different: I/O latencies dominate any context switching
>    overhead and on most OS'es when you perform most I/O there is an interrupt,
>    a security context switch in kernel and possibly even a thread suspension
>    and a thread context switch *anyway* in addition to that (you may get
>    suspended with I/O syscall interrupt being handled by kernel thread pool)!
>     3. Imagine you are processing a vast volume of SSH connections. At
>    certain data volumes your load will be dominated by time of AES
>    encryption/decryption of the SSH traffic, which will be a function of
>    plain/ciphertext volume, not the number of threads. You're going to max out
>    your compute at somewhere around 75MB/s/core of AES even with AES-NI, i.e.
>    the number of clients you can reasonably support is, maybe, in low tens of
>    thousands? If clients produce voluminous traffic then in low thousands.
>    Even at 100% efficiency you're limited to those numbers. Does it make sense
>    (time-/cost-/complexity-wise) to try to write a callback-based client that
>    could handle hundreds of thousands or millions of clients *if not* for all
>    that pesky encryption compute requirement you're going to be limited by
>    anyway?
>    Also, apparently, in heavy I/O scenarios, you may have a much better
>    system throughput waiting for things to happen in I/O (blocking I/O) vs
>    being notified of I/O events (Selector-based I/O):
>    http://www.mailinator.com/tymaPaulMultithreaded.pdf. Paper is 6 years
>    old and kernel/Java realities might have changed, YMMV, but the difference
>    is(was?) impressive. Also, Apache HTTP Client still swears by blocking I/O
>    vs non-blocking one in terms of efficiency:
>    http://wiki.apache.org/HttpComponents/HttpClient3vsHttpClient4vsHttpCore
>    4. Callbacks, potentially, have to maintain and threads executing them
>    have to switch application-defined contexts (e.g. current security
>    principal, current transaction etc). How expensive it is depends on the
>    application.
>     5. *Callback hell* is not an urban myth and neither is architectural
>    entropy. If you have a core of very competent developers that are going to
>    work together on the product in perpetuity, callbacks are a reasonable and
>    a very efficient solution. In enterprise environment with the number and
>    the quality of the people that work on the code and with architectural
>    preparation and control that time constraints allow and modularity demands,
>    your callback hierarchy may disintegrate rapidly causing races, deadlocks
>    etc forcing a complete rewrite in a just a few years or a complete project
>    failure even before release. Blocking code is orders of magnitude easier to
>    implement, validate and maintain, especially with people who cannot wrap
>    their heads around the meaning of volatile after writing Java for a decade.
>    Losing 20% (straw-man number) efficiency in thread context switching at
>    high tens of thousands of threads is a small price to pay for the code that
>    actually continues to work 10 years after it has been written. And you
>    virtually always can add yet another box to increase your total throughput.
>    6. Curiously, even a fully non-blocking algorithm that uses as many
>    software threads as there are hardware ones with all data being
>    thread-resident and no data sharing occurring can suffer severely from
>    cache residency imbalance and demonstrate poor efficiency:
>    https://blogs.oracle.com/dave/resource/spaa14-dice-UnfairnessResidency-CameraReady.pdf.
>    This is to illustrate that there are monsters in virtually every approach
>    and the end results may be quite surprising.
>
> Again, not saying anything you said is wrong, but there are a few
> considerations other than eliminating context switches and reducing OS
> resource constraints when answering the question "should I block?" There
> are many tools, there are many scenarios, different tools are good for
> different scenarios => blanket recommendations are dangerous. :)
> </imho>
>
> - Arcadiy
>
>    - Dennis
>
>
> On 2014-06-13 21:50, Dennis Sosnoski wrote:
>
> On 06/14/2014 01:31 PM, Vitaly Davidovich wrote:
>
> I'd think the 1M cycle delays to get a thread running again are probably
> due to OS scheduling it on a cpu that is in a deep c-state; there can be
> significant delays as the cpu powers back on.
>
>
> That makes sense, but I'd think it would only be an issue for systems
> under light load.
>
>   - Dennis
>
>  Sent from my phone
> On Jun 13, 2014 9:07 PM, "Dennis Sosnoski" <dms at sosnoski.com> wrote:
>
>> On 06/14/2014 11:57 AM, Doug Lea wrote:
>>
>>> On 06/13/2014 07:35 PM, Dennis Sosnoski wrote:
>>>
>>>> I'm writing an article where I'm discussing both blocking waits and
>>>> non-blocking
>>>> callbacks for handling events. As I see it, there are two main reasons
>>>> for
>>>> preferring non-blocking:
>>>>
>>>> 1. Threads are expensive resources (limited to on the order of 10000
>>>> per JVM),
>>>> and tying one up just waiting for an event completion is a waste of
>>>> this resource
>>>> 2. Thread switching adds substantial overhead to the application
>>>>
>>>> Are there any other good reasons I'm missing?
>>>>
>>>
>>> Also memory locality (core X cache effects).
>>>
>>
>> I thought about that, though couldn't come up with any easy way of
>> demonstrating the effect. I suppose something more memory-intensive would
>> do this - perhaps having a fairly sizable array of values for each thread,
>> and having the thread do some computation with those values each time it's
>> run.
>>
>>
>>>
>>>> ...
>>>> So a big drop in performance going from one thread to two, and again
>>>> from 2 to
>>>> 4, but after than just a slowly increasing trend. That's about 19
>>>> microseconds
>>>> per switch with 4096 threads, about half that time for just 2 threads.
>>>> Do these
>>>> results make sense to others?
>>>>
>>>
>>> Your best case of approximately 20 thousand clock cycles is not an
>>> unexpected result on a single-socket multicore with all cores turned
>>> on (i.e., no power management, fusing, or clock-step effects)
>>> and only a few bouncing cachelines.
>>>
>>> We've seen cases of over 1 million cycles to unblock a thread
>>> in some other cases. (Which can be challenging for us to deal
>>> with in JDK8 Stream.parallel(). I'll post something on this sometime.)
>>> Maybe Aleksey can someday arrange to collect believable
>>> systematic measurements across a few platforms.
>>>
>>
>> The reason for the long delay being cache effects, right? I'll try some
>> experiments with associated data per thread to see if I can demonstrate
>> this on a small scale.
>>
>> Thanks for the insights, Doug.
>>
>>   - Dennis
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140616/21598e84/attachment.html>

From alexei.kaigorodov at gmail.com  Mon Jun 16 23:44:39 2014
From: alexei.kaigorodov at gmail.com (Alexei Kaigorodova)
Date: Tue, 17 Jun 2014 03:44:39 +0000 (UTC)
Subject: [concurrency-interest] Blocking vs. non-blocking
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<539BD019.8090703@sosnoski.com> <539BEAE3.5030006@ivanov.biz>
	<539BEF1F.6010106@sosnoski.com>
Message-ID: <loom.20140617T053852-445@post.gmane.org>

Dennis Sosnoski <dms <at> sosnoski.com> writes:
>       Hmmm. Now that I think about it, I've been telling people that
>       there are just two fundamental ways of handling the completions of
>       asynchronous events, with blocking waits or with callbacks. I
>       suppose message passing could be considered a third way, even
>       though it's kind of a variation of callbacks. Are there other ways
>       that different significantly from these two (or three)?
>       ? - Dennis

The two fundamental ways are threads with blocking waits and dataflow actors
with multiple input ports. Ports accept tokens (messages or signals), and
actor fires when the firing rule is satisfied. The typical firing rule is
"all inputs ready". Akka actors is a restricted implementation of general
dataflow actors: each actor has just 2 ports: one message port and one
signal port to prevent parallel execution of the same actor instance.
Callbacks are even more restricted: actor has only one message port for
callback parameters, leaving managing of parallelism to the user. As a
result, callbacks are not parallel-friendly. The art of asynchronous
programming is to chose the right actor implementation for the given task:
for some tasks callbacks are optimal, and for some tasks Akka is not enough.



From dms at sosnoski.com  Tue Jun 17 22:39:27 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Wed, 18 Jun 2014 14:39:27 +1200
Subject: [concurrency-interest] CompletableFuture exception handling
Message-ID: <53A0FBDF.9050006@sosnoski.com>

I've been playing with an example of composing sequences of events 
represented by CompletableFutures. task1 starts directly, then when it 
completes successfully I want to start task2 and task3, when these both 
complete successfully I want to start task4, then when task4 completes I 
want to set the completion of the future that represents the entire set 
of tasks.

Here's code to do this with exceptions ignored:

     private static CompletableFuture<Integer> runNonblocking() {
         CompletableFuture<Integer> result = new 
CompletableFuture<Integer>();
         task1(1).thenAccept(i1 -> {
             CompletableFuture<Integer> future2 = task2(i1);
             CompletableFuture<Integer> future3 = task3(i1);
             future2.thenAcceptBoth(future3, (i2, i3) ->
                 task4(i2 + i3).thenAccept(i4 ->
                     result.complete(i4)));
         });
         return result;
     }

That seems reasonable and fairly easy to understand. But if I want to 
also propagate exception completions from the individual tasks into the 
composite task I get something like this:

     private static CompletableFuture<Integer> runNonblocking() {
         CompletableFuture<Integer> result = new 
CompletableFuture<Integer>();
         task1(1).whenComplete((i1, t1) -> {
             if (t1 != null) {
                 result.completeExceptionally(t1);
             } else {
                 CompletableFuture<Integer> future2 = task2(i1);
                 CompletableFuture<Integer> future3 = task3(i1);
                 future2.whenComplete((i2, t2) -> {
                     future3.whenComplete((i3, t3) -> {
                         if (t2 != null) {
                             result.completeExceptionally(t2);
                         } else if (t3 != null) {
                             result.completeExceptionally(t3);
                         } else {
                             task4(i2 + i3).whenComplete((i4, t4) -> {
                                 if (t4 != null) {
result.completeExceptionally(t4);
                                 } else {
                                     result.complete(i4);
                                 }
                             });
                         }
                     });
                 });
             }
         });
         return result;
     }

This seems, well, /exceptionally/ complex. Am I missing some simpler way 
of doing this kind of composition of futures, or am I just totally 
outside the use cases in wanting to do this in the first place?

It would be cleaner if whenComplete accepted two separate functions, one 
for success and the other for an exception, since that would get rid of 
the null checks.

Thanks for any feedback,

   - Dennis

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140618/a1e909fb/attachment.html>

From martinrb at google.com  Wed Jun 18 15:09:47 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 18 Jun 2014 12:09:47 -0700
Subject: [concurrency-interest] CompletableFuture exception handling
In-Reply-To: <53A0FBDF.9050006@sosnoski.com>
References: <53A0FBDF.9050006@sosnoski.com>
Message-ID: <CA+kOe0_coovb_Frwp8MBm0tHj6h4y9q9eWk3MzteH3k22sWjrA@mail.gmail.com>

Probably just like in regular java code, handling exceptional behavior
should be rare because exceptions propagate through your code, and when
chaining a bunch of CompletableFutures, you can also by default let
exceptions propagate.  In the hopefully rare case where you do want to
handle the exceptions explicitly, you can use
handle/whenComplete/exceptionally/.

It's weird to call complete(value) in the leaf future.  Why not just
return .... .thenAcceptBoth(...)

But I haven't written "real" code using CompletableFuture myself - perhaps
others have and can report their experience?


On Tue, Jun 17, 2014 at 7:39 PM, Dennis Sosnoski <dms at sosnoski.com> wrote:

>  I've been playing with an example of composing sequences of events
> represented by CompletableFutures. task1 starts directly, then when it
> completes successfully I want to start task2 and task3, when these both
> complete successfully I want to start task4, then when task4 completes I
> want to set the completion of the future that represents the entire set of
> tasks.
>
> Here's code to do this with exceptions ignored:
>
>     private static CompletableFuture<Integer> runNonblocking() {
>         CompletableFuture<Integer> result = new
> CompletableFuture<Integer>();
>         task1(1).thenAccept(i1 -> {
>             CompletableFuture<Integer> future2 = task2(i1);
>             CompletableFuture<Integer> future3 = task3(i1);
>             future2.thenAcceptBoth(future3, (i2, i3) ->
>                 task4(i2 + i3).thenAccept(i4 ->
>                     result.complete(i4)));
>         });
>         return result;
>     }
>
> That seems reasonable and fairly easy to understand. But if I want to also
> propagate exception completions from the individual tasks into the
> composite task I get something like this:
>
>     private static CompletableFuture<Integer> runNonblocking() {
>         CompletableFuture<Integer> result = new
> CompletableFuture<Integer>();
>         task1(1).whenComplete((i1, t1) -> {
>             if (t1 != null) {
>                 result.completeExceptionally(t1);
>             } else {
>                 CompletableFuture<Integer> future2 = task2(i1);
>                 CompletableFuture<Integer> future3 = task3(i1);
>                 future2.whenComplete((i2, t2) -> {
>                     future3.whenComplete((i3, t3) -> {
>                         if (t2 != null) {
>                             result.completeExceptionally(t2);
>                         } else if (t3 != null) {
>                             result.completeExceptionally(t3);
>                         } else {
>                             task4(i2 + i3).whenComplete((i4, t4) -> {
>                                 if (t4 != null) {
>                                     result.completeExceptionally(t4);
>                                 } else {
>                                     result.complete(i4);
>                                 }
>                             });
>                         }
>                     });
>                 });
>             }
>         });
>         return result;
>     }
>
> This seems, well, *exceptionally* complex. Am I missing some simpler way
> of doing this kind of composition of futures, or am I just totally outside
> the use cases in wanting to do this in the first place?
>
> It would be cleaner if whenComplete accepted two separate functions, one
> for success and the other for an exception, since that would get rid of the
> null checks.
>
> Thanks for any feedback,
>
>   - Dennis
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140618/acea12de/attachment.html>

From zhong.j.yu at gmail.com  Wed Jun 18 17:59:30 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 18 Jun 2014 16:59:30 -0500
Subject: [concurrency-interest] CompletableFuture exception handling
In-Reply-To: <CA+kOe0_coovb_Frwp8MBm0tHj6h4y9q9eWk3MzteH3k22sWjrA@mail.gmail.com>
References: <53A0FBDF.9050006@sosnoski.com>
	<CA+kOe0_coovb_Frwp8MBm0tHj6h4y9q9eWk3MzteH3k22sWjrA@mail.gmail.com>
Message-ID: <CACuKZqF3aPAWGbWy92FanTwGb881TizrSMyLURv0XvPfJeCyPw@mail.gmail.com>

On Wed, Jun 18, 2014 at 2:09 PM, Martin Buchholz <martinrb at google.com> wrote:
> It's weird to call complete(value) in the leaf future.  Why not just
> return .... .thenAcceptBoth(...)
>
> But I haven't written "real" code using CompletableFuture myself - perhaps
> others have and can report their experience?

Yes, this should work:

    CompletableFuture<Integer> runNonblocking()
    {
        return task1(1)
            .thenCompose( i1 -> task2(i1).thenCombine(task3(i1),
(i2,i3)->i2+i3) )
            .thenCompose( i4 -> task4(i4) );
    }

PS, shameless plug, I'm working on an Async API too, in which the
example can be coded as

        Async<Integer> runNonblocking()
        {
            return task1(1)
                .then( i1 -> Async.invoke(this::plus, task2(i1), task3(i1)) )
                .then( i4 -> task4(i4) );
        }

see  http://bayou.io/release/0.9/docs/async/Async_Programming.html

Zhong Yu
http://bayou.io

From dms at sosnoski.com  Wed Jun 18 21:03:35 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Thu, 19 Jun 2014 13:03:35 +1200
Subject: [concurrency-interest] CompletableFuture exception handling
In-Reply-To: <CACuKZqF3aPAWGbWy92FanTwGb881TizrSMyLURv0XvPfJeCyPw@mail.gmail.com>
References: <53A0FBDF.9050006@sosnoski.com>	<CA+kOe0_coovb_Frwp8MBm0tHj6h4y9q9eWk3MzteH3k22sWjrA@mail.gmail.com>
	<CACuKZqF3aPAWGbWy92FanTwGb881TizrSMyLURv0XvPfJeCyPw@mail.gmail.com>
Message-ID: <53A236E7.9030803@sosnoski.com>

On 06/19/2014 09:59 AM, Zhong Yu wrote:
> ...
> Yes, this should work:
>
>      CompletableFuture<Integer> runNonblocking()
>      {
>          return task1(1)
>              .thenCompose( i1 -> task2(i1).thenCombine(task3(i1),
> (i2,i3)->i2+i3) )
>              .thenCompose( i4 -> task4(i4) );
>      }

Wow, that's beautiful! I just needed to add a cast to 
CompletableFuture<Integer> on the thenCombine() to make the types work. 
I suppose I should have realized the key to composing and combining 
events would be in methods named "thenCompose" and "thenCombine". :-[

>
> PS, shameless plug, I'm working on an Async API too, in which the
> example can be coded as
>
>          Async<Integer> runNonblocking()
>          {
>              return task1(1)
>                  .then( i1 -> Async.invoke(this::plus, task2(i1), task3(i1)) )
>                  .then( i4 -> task4(i4) );
>          }
>
> see  http://bayou.io/release/0.9/docs/async/Async_Programming.html

Looks interesting. I'll check into it more.

Thanks Martin and Zhong.

   - Dennis

>
> Zhong Yu
> http://bayou.io
>


From martinrb at google.com  Thu Jun 19 00:25:30 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 18 Jun 2014 21:25:30 -0700
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
Message-ID: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>

ThreadLocalRandom's clinit method creates an intermediate broken state of
ThreadLocalRandom and then proceeds to run some networking code to get some
more machine-specific entropy in initialSeed().  This will fail if the
networking code ever recursively uses a (not yet functional)
ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
be run,

at
java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
at java.net.InetAddress$3.run(InetAddress.java:923)
at java.net.InetAddress$3.run(InetAddress.java:918)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.InetAddress.createNSProvider(InetAddress.java:917)
at java.net.InetAddress.<clinit>(InetAddress.java:962)

if the sun.net.spi.nameservice.provider system property is defined.

The current strategy of ThreadLocalRandom relying on other java code for
initialization seems risky.  Safer would be to have native code provide
some entropy at program startup for use by ThreadLocalRandom.  I don't have
a clean solution for this problem (other than to rip out initialSeed()).
 Strictly more reliable would be to mix in the entropy from the system at
the end of ThreadLocalRandom's clinit instead of the beginning, but the
basic problem remains.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140618/8e1947ad/attachment.html>

From stanimir at riflexo.com  Thu Jun 19 02:32:02 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 19 Jun 2014 09:32:02 +0300
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
Message-ID: <CAEJX8ooEQUvAPBbYeCjT5DDcAeB8jnWVi_UUm3hAqzDk+uaoMw@mail.gmail.com>

I wonder why just don't use the /dev/random if available on *nix -
implemented by sun.security.provider.NativePRNG or
sun.security.mscapi.PRNG() on Windows that calls CryptGenRandom.
Both support SecureRandomSpi.engineGenerateSeed(int) that provides an
arbitrary amount of entropy.
Although the approach would cause some more classes to load, no arbitrary
providers should be initialized.

Stanimir



On Thu, Jun 19, 2014 at 7:25 AM, Martin Buchholz <martinrb at google.com>
wrote:

> ThreadLocalRandom's clinit method creates an intermediate broken state of
> ThreadLocalRandom and then proceeds to run some networking code to get some
> more machine-specific entropy in initialSeed().  This will fail if the
> networking code ever recursively uses a (not yet functional)
> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
> be run,
>
> at
> java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
>  at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
> at java.net.InetAddress$3.run(InetAddress.java:923)
>  at java.net.InetAddress$3.run(InetAddress.java:918)
> at java.security.AccessController.doPrivileged(Native Method)
>  at java.net.InetAddress.createNSProvider(InetAddress.java:917)
> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>
> if the sun.net.spi.nameservice.provider system property is defined.
>
> The current strategy of ThreadLocalRandom relying on other java code for
> initialization seems risky.  Safer would be to have native code provide
> some entropy at program startup for use by ThreadLocalRandom.  I don't have
> a clean solution for this problem (other than to rip out initialSeed()).
>  Strictly more reliable would be to mix in the entropy from the system at
> the end of ThreadLocalRandom's clinit instead of the beginning, but the
> basic problem remains.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140619/7496958a/attachment-0001.html>

From peter.levart at gmail.com  Thu Jun 19 03:49:43 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 19 Jun 2014 09:49:43 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
Message-ID: <53A29617.4080606@gmail.com>

Hi Martin,

What version of TLR are you looking at? As far as I remmember, the 
InetAddress-related code to obtain initial seed has been replaced by 
NetworkInterface.getHardwareAddress(). Is this still triggering the 
initialization of InetAddress or is this the case of using 
"java.util.secureRandomSeed" set to "true" ? Can you show the whole 
stack trace?

On 06/19/2014 06:25 AM, Martin Buchholz wrote:
 > ThreadLocalRandom's clinit method creates an intermediate broken state of
 > ThreadLocalRandom and then proceeds to run some networking code to 
get some
 > more machine-specific entropy in initialSeed().
 >   This will fail if the
 > networking code ever recursively uses a (not yet functional)
 > ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary 
code to
 > be run,
 >
 > at
 > 
java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
 > at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
 > at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
 > at java.net.InetAddress$3.run(InetAddress.java:923)
 > at java.net.InetAddress$3.run(InetAddress.java:918)
 > at java.security.AccessController.doPrivileged(Native Method)
 > at java.net.InetAddress.createNSProvider(InetAddress.java:917)
 > at java.net.InetAddress.<clinit>(InetAddress.java:962)
 >
 > if the sun.net.spi.nameservice.provider system property is defined.
 >
 > The current strategy of ThreadLocalRandom relying on other java code for
 > initialization seems risky.  Safer would be to have native code provide
 > some entropy at program startup for use by ThreadLocalRandom. I don't 
have
 > a clean solution for this problem (other than to rip out initialSeed()).
 >   Strictly more reliable would be to mix in the entropy from the 
system at
 > the end of ThreadLocalRandom's clinit instead of the beginning, but the
 > basic problem remains.

Would it be acceptable for TLR to be functional even when invoked during 
it's clinit, but using a less randomized "seeder" (based only on current 
time) and after the "networking" or SecureRandom code is finished, 
complete the initialization of "seeder" state and clear the thread-local 
probe so that TLR's thread state is re-initialized afterwards. for example:

http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR.seeder/webrev.01/

Regards, Peter


From peter.levart at gmail.com  Thu Jun 19 04:02:44 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 19 Jun 2014 10:02:44 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CAEJX8ooEQUvAPBbYeCjT5DDcAeB8jnWVi_UUm3hAqzDk+uaoMw@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<CAEJX8ooEQUvAPBbYeCjT5DDcAeB8jnWVi_UUm3hAqzDk+uaoMw@mail.gmail.com>
Message-ID: <53A29924.4020804@gmail.com>

On 06/19/2014 08:32 AM, Stanimir Simeonoff wrote:
> I wonder why just don't use the /dev/random if available on *nix -
> implemented by sun.security.provider.NativePRNG or
> sun.security.mscapi.PRNG() on Windows that calls CryptGenRandom.
> Both support SecureRandomSpi.engineGenerateSeed(int) that provides an
> arbitrary amount of entropy.
> Although the approach would cause some more classes to load, no arbitrary
> providers should be initialized.

I think this is waht you get when you set "java.util.secureRandomSeed" 
system property to "true". TLR uses 
java.security.SecureRandom.getSeed(8) in this case.

Regards, Peter

>
> Stanimir
>
>
>
> On Thu, Jun 19, 2014 at 7:25 AM, Martin Buchholz <martinrb at google.com>
> wrote:
>
>> ThreadLocalRandom's clinit method creates an intermediate broken state of
>> ThreadLocalRandom and then proceeds to run some networking code to get some
>> more machine-specific entropy in initialSeed().  This will fail if the
>> networking code ever recursively uses a (not yet functional)
>> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
>> be run,
>>
>> at
>> java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
>> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
>>   at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
>> at java.net.InetAddress$3.run(InetAddress.java:923)
>>   at java.net.InetAddress$3.run(InetAddress.java:918)
>> at java.security.AccessController.doPrivileged(Native Method)
>>   at java.net.InetAddress.createNSProvider(InetAddress.java:917)
>> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>>
>> if the sun.net.spi.nameservice.provider system property is defined.
>>
>> The current strategy of ThreadLocalRandom relying on other java code for
>> initialization seems risky.  Safer would be to have native code provide
>> some entropy at program startup for use by ThreadLocalRandom.  I don't have
>> a clean solution for this problem (other than to rip out initialSeed()).
>>   Strictly more reliable would be to mix in the entropy from the system at
>> the end of ThreadLocalRandom's clinit instead of the beginning, but the
>> basic problem remains.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140619/cc485963/attachment.html>

From stanimir at riflexo.com  Thu Jun 19 04:14:30 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 19 Jun 2014 11:14:30 +0300
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A29924.4020804@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<CAEJX8ooEQUvAPBbYeCjT5DDcAeB8jnWVi_UUm3hAqzDk+uaoMw@mail.gmail.com>
	<53A29924.4020804@gmail.com>
Message-ID: <CAEJX8opG8=shAC8FvW-QjP85uNxM-ppQxEO2M+gS0wZ=wBq0Tw@mail.gmail.com>

 The problem is that java.security.SecureRandom may need custom security
providers that in effect are not prevented from touching TLR.
The code in clinit should not be able load unknown classes.

Stanimir


On Thu, Jun 19, 2014 at 11:02 AM, Peter Levart <peter.levart at gmail.com>
wrote:

>  On 06/19/2014 08:32 AM, Stanimir Simeonoff wrote:
>
> I wonder why just don't use the /dev/random if available on *nix -
> implemented by sun.security.provider.NativePRNG or
> sun.security.mscapi.PRNG() on Windows that calls CryptGenRandom.
> Both support SecureRandomSpi.engineGenerateSeed(int) that provides an
> arbitrary amount of entropy.
> Although the approach would cause some more classes to load, no arbitrary
> providers should be initialized.
>
>
> I think this is waht you get when you set "java.util.secureRandomSeed"
> system property to "true". TLR uses java.security.SecureRandom.getSeed(8)
> in this case.
>
> Regards, Peter
>
>
>
> Stanimir
>
>
>
> On Thu, Jun 19, 2014 at 7:25 AM, Martin Buchholz <martinrb at google.com> <martinrb at google.com>
> wrote:
>
>
>  ThreadLocalRandom's clinit method creates an intermediate broken state of
> ThreadLocalRandom and then proceeds to run some networking code to get some
> more machine-specific entropy in initialSeed().  This will fail if the
> networking code ever recursively uses a (not yet functional)
> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
> be run,
>
> at
> java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
>  at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
> at java.net.InetAddress$3.run(InetAddress.java:923)
>  at java.net.InetAddress$3.run(InetAddress.java:918)
> at java.security.AccessController.doPrivileged(Native Method)
>  at java.net.InetAddress.createNSProvider(InetAddress.java:917)
> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>
> if the sun.net.spi.nameservice.provider system property is defined.
>
> The current strategy of ThreadLocalRandom relying on other java code for
> initialization seems risky.  Safer would be to have native code provide
> some entropy at program startup for use by ThreadLocalRandom.  I don't have
> a clean solution for this problem (other than to rip out initialSeed()).
>  Strictly more reliable would be to mix in the entropy from the system at
> the end of ThreadLocalRandom's clinit instead of the beginning, but the
> basic problem remains.
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140619/f8e62113/attachment.html>

From Alan.Bateman at oracle.com  Thu Jun 19 04:22:29 2014
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Thu, 19 Jun 2014 09:22:29 +0100
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
Message-ID: <53A29DC5.1030605@oracle.com>

On 19/06/2014 05:25, Martin Buchholz wrote:
> ThreadLocalRandom's clinit method creates an intermediate broken state of
> ThreadLocalRandom and then proceeds to run some networking code to get some
> more machine-specific entropy in initialSeed().  This will fail if the
> networking code ever recursively uses a (not yet functional)
> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
> be run,
>
> at
> java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:354)
> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
> at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
> at java.net.InetAddress$3.run(InetAddress.java:923)
> at java.net.InetAddress$3.run(InetAddress.java:918)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.InetAddress.createNSProvider(InetAddress.java:917)
> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>
> if the sun.net.spi.nameservice.provider system property is defined.
>
> The current strategy of ThreadLocalRandom relying on other java code for
> initialization seems risky.
Using a name service provider other than the default is going to 
interact badly here. So is this configured to use the JNDI-DNS provider 
("dns,sun") or something else? This provider mechanism has been a source 
of many problems, recursive initialization and stack overflow mostly 
because any custom provider is likely going to use the network and 
resolve host names. It can interact very badly with security when the 
provider doesn't have AllPermision because attempts to establish 
connections involve security checks that often need to do lookups too.

So I'm curious if there is more to this stack trace to put more context 
on the issue. It may be another example to back a suggestion to just 
drop the JDK-internal name service provider mechanism. But in general, I 
think you are right, it's not good for TLR initialization to trigger 
arbitrary code to execute.

-Alan.

From peter.levart at gmail.com  Thu Jun 19 04:37:41 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 19 Jun 2014 10:37:41 +0200
Subject: [concurrency-interest] ThreadLocalRandom.nextSecondarySeed()
	re-initializes TLR's seed
Message-ID: <53A2A155.3040509@gmail.com>

Hi,

I noticed an inconsistency in calling TLR.localInit() method. Everywhere 
it's called conditionaly if thread-local "probe" is zero except in 
TLR.nextSecondarySeed() where it's called if "secondary" seed is zero. 
This re-initializes the "probe" and "seed" even though they might have 
already been initialized. It's not a big deal, because this happens at 
most once per thread, but it would be more consistent to call 
localInit() conditionaly, I think:


diff -r 5b45a5efe417 
src/share/classes/java/util/concurrent/ThreadLocalRandom.java
--- a/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Tue 
May 20 10:11:23 2014 +0400
+++ b/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Thu 
Jun 19 10:34:18 2014 +0200
@@ -1034,7 +1034,8 @@
              r ^= r << 5;
}
          else {
- localInit();
+            if (UNSAFE.getInt(t, PROBE) == 0)
+ localInit();
              if ((r = (int)UNSAFE.getLong(t, SEED)) == 0)
                  r = 1; // avoid zero
          }



Regards, Peter


From peter.levart at gmail.com  Thu Jun 19 04:48:24 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 19 Jun 2014 10:48:24 +0200
Subject: [concurrency-interest] ThreadLocalRandom.nextSecondarySeed()
	re-initializes TLR's seed
In-Reply-To: <53A2A155.3040509@gmail.com>
References: <53A2A155.3040509@gmail.com>
Message-ID: <53A2A3D8.8000602@gmail.com>

Or, even better, why not just using the next value from the "seeder" 
sequence for the initial value of "secondary" seed and avoid interaction 
with TLR's main seed/probe:


diff -r 5b45a5efe417 
src/share/classes/java/util/concurrent/ThreadLocalRandom.java
--- a/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Tue 
May 20 10:11:23 2014 +0400
+++ b/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Thu 
Jun 19 10:45:25 2014 +0200
@@ -1034,8 +1034,7 @@
              r ^= r << 5;
          }
          else {
-            localInit();
-            if ((r = (int)UNSAFE.getLong(t, SEED)) == 0)
+            if ((r = (int)mix64(seeder.getAndAdd(SEEDER_INCREMENT))) == 0)
                  r = 1; // avoid zero
          }
          UNSAFE.putInt(t, SECONDARY, r);


Regards, Peter

On 06/19/2014 10:37 AM, Peter Levart wrote:
> Hi,
>
> I noticed an inconsistency in calling TLR.localInit() method. 
> Everywhere it's called conditionaly if thread-local "probe" is zero 
> except in TLR.nextSecondarySeed() where it's called if "secondary" 
> seed is zero. This re-initializes the "probe" and "seed" even though 
> they might have already been initialized. It's not a big deal, because 
> this happens at most once per thread, but it would be more consistent 
> to call localInit() conditionaly, I think:
>
>
> diff -r 5b45a5efe417 
> src/share/classes/java/util/concurrent/ThreadLocalRandom.java
> --- a/src/share/classes/java/util/concurrent/ThreadLocalRandom.java 
> Tue May 20 10:11:23 2014 +0400
> +++ b/src/share/classes/java/util/concurrent/ThreadLocalRandom.java 
> Thu Jun 19 10:34:18 2014 +0200
> @@ -1034,7 +1034,8 @@
>              r ^= r << 5;
> }
>          else {
> - localInit();
> +            if (UNSAFE.getInt(t, PROBE) == 0)
> + localInit();
>              if ((r = (int)UNSAFE.getLong(t, SEED)) == 0)
>                  r = 1; // avoid zero
>          }
>
>
>
> Regards, Peter
>


From dl at cs.oswego.edu  Thu Jun 19 08:02:06 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 19 Jun 2014 08:02:06 -0400
Subject: [concurrency-interest] ThreadLocalRandom.nextSecondarySeed()
 re-initializes TLR's seed
In-Reply-To: <53A2A3D8.8000602@gmail.com>
References: <53A2A155.3040509@gmail.com> <53A2A3D8.8000602@gmail.com>
Message-ID: <53A2D13E.4020006@cs.oswego.edu>

On 06/19/2014 04:48 AM, Peter Levart wrote:
> Or, even better, why not just using the next value from the "seeder" sequence
> for the initial value of "secondary" seed and avoid interaction with TLR's main
> seed/probe:

Thanks! Or better, just use mix32:

>
> +            if ((r = (int)mix64(seeder.getAndAdd(SEEDER_INCREMENT))) == 0)
=>
      if ((r = mix32(seeder.getAndAdd(SEEDER_INCREMENT))) == 0)

I committed this to jsr166 cvs. As you noted, this only addresses
an uncommon performance glitch. I don't have any further ideas
since we discussed last year the tradeoffs between computing
decent quality initial seeds versus class-loading.
I still think we have the best practical compromise in place.

-Doug

>           }
>           UNSAFE.putInt(t, SECONDARY, r);
>
>
> Regards, Peter
>
> On 06/19/2014 10:37 AM, Peter Levart wrote:
>> Hi,
>>
>> I noticed an inconsistency in calling TLR.localInit() method. Everywhere it's
>> called conditionaly if thread-local "probe" is zero except in
>> TLR.nextSecondarySeed() where it's called if "secondary" seed is zero. This
>> re-initializes the "probe" and "seed" even though they might have already been
>> initialized. It's not a big deal, because this happens at most once per
>> thread, but it would be more consistent to call localInit() conditionaly, I
>> think:
>>
>>
>> diff -r 5b45a5efe417
>> src/share/classes/java/util/concurrent/ThreadLocalRandom.java
>> --- a/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Tue May 20
>> 10:11:23 2014 +0400
>> +++ b/src/share/classes/java/util/concurrent/ThreadLocalRandom.java Thu Jun 19
>> 10:34:18 2014 +0200
>> @@ -1034,7 +1034,8 @@
>>              r ^= r << 5;
>> }
>>          else {
>> - localInit();
>> +            if (UNSAFE.getInt(t, PROBE) == 0)
>> + localInit();
>>              if ((r = (int)UNSAFE.getLong(t, SEED)) == 0)
>>                  r = 1; // avoid zero
>>          }
>>
>>
>>
>> Regards, Peter
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From martinrb at google.com  Thu Jun 19 14:04:19 2014
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 19 Jun 2014 11:04:19 -0700
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A29DC5.1030605@oracle.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<53A29DC5.1030605@oracle.com>
Message-ID: <CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>

On Thu, Jun 19, 2014 at 1:22 AM, Alan Bateman <Alan.Bateman at oracle.com>
wrote:

> On 19/06/2014 05:25, Martin Buchholz wrote:
>
>> ThreadLocalRandom's clinit method creates an intermediate broken state of
>> ThreadLocalRandom and then proceeds to run some networking code to get
>> some
>> more machine-specific entropy in initialSeed().  This will fail if the
>> networking code ever recursively uses a (not yet functional)
>> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
>> be run,
>>
>> at
>> java.util.ServiceLoader$LazyIterator.hasNextService(
>> ServiceLoader.java:354)
>> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
>> at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
>> at java.net.InetAddress$3.run(InetAddress.java:923)
>> at java.net.InetAddress$3.run(InetAddress.java:918)
>> at java.security.AccessController.doPrivileged(Native Method)
>> at java.net.InetAddress.createNSProvider(InetAddress.java:917)
>> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>>
>> if the sun.net.spi.nameservice.provider system property is defined.
>>
>> The current strategy of ThreadLocalRandom relying on other java code for
>> initialization seems risky.
>>
> Using a name service provider other than the default is going to interact
> badly here. So is this configured to use the JNDI-DNS provider ("dns,sun")
> or something else? This provider mechanism has been a source of many
> problems, recursive initialization and stack overflow mostly because any
> custom provider is likely going to use the network and resolve host names.
> It can interact very badly with security when the provider doesn't have
> AllPermision because attempts to establish connections involve security
> checks that often need to do lookups too.
>
> So I'm curious if there is more to this stack trace to put more context on
> the issue.


The way we are actually seeing this is:
- there are jdk8 jtreg tests that set the sun.net.spi.nameservice.provider
property.  Grepping:

./java/net/Inet4Address/textToNumericFormat.java
./java/net/URLPermission/nstest/lookup.sh
./sun/net/InetAddress/nameservice/dns/cname.sh
./sun/net/InetAddress/nameservice/deadlock/Hang.java
./sun/net/InetAddress/nameservice/chaining/Providers.java
./sun/net/InetAddress/nameservice/simple/DefaultCaching.java
./sun/net/InetAddress/nameservice/simple/CacheTest.java
./sun/security/krb5/auto/KDC.java
./sun/security/krb5/canonicalize/Test.java

- we have local modifications to classloading that happen to use TLR
via ConcurrentSkipListMap - a "reasonable" thing to do.  Probably the
simplest way to provoke a failure is to try to use a TLR from e.g.
URLClassPath.

In general, any core library boot class should try hard to avoid
loading/invoking code from the user's classpath.


> It may be another example to back a suggestion to just drop the
> JDK-internal name service provider mechanism. But in general, I think you
> are right, it's not good for TLR initialization to trigger arbitrary code
> to execute.
>
> -Alan.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140619/4c49e256/attachment.html>

From peter.levart at gmail.com  Fri Jun 20 04:42:31 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 20 Jun 2014 10:42:31 +0200
Subject: [concurrency-interest] ThreadLocalRandom.nextSecondarySeed()
 re-initializes TLR's seed
In-Reply-To: <53A2D13E.4020006@cs.oswego.edu>
References: <53A2A155.3040509@gmail.com> <53A2A3D8.8000602@gmail.com>
	<53A2D13E.4020006@cs.oswego.edu>
Message-ID: <53A3F3F7.9010506@gmail.com>

Hi Doug,

On 06/19/2014 02:02 PM, Doug Lea wrote:
> On 06/19/2014 04:48 AM, Peter Levart wrote:
>> Or, even better, why not just using the next value from the "seeder" 
>> sequence
>> for the initial value of "secondary" seed and avoid interaction with 
>> TLR's main
>> seed/probe:
>
> Thanks! Or better, just use mix32:
>
>>
>> +            if ((r = (int)mix64(seeder.getAndAdd(SEEDER_INCREMENT))) 
>> == 0)
> =>
>      if ((r = mix32(seeder.getAndAdd(SEEDER_INCREMENT))) == 0)

That's right.

>
> I committed this to jsr166 cvs. As you noted, this only addresses
> an uncommon performance glitch. 

Not so performance as the "expected" behaviour. I'm assuming the aim of 
TLR.nextSecondarySeed() as a java.util.concurrent private thread-local 
source of random numbers is:
- enough quality for it's purpose
- fast
- does not "disturb" the sequence of the primary public TLR sequence.

I was concerned about the last point only.

> I don't have any further ideas
> since we discussed last year the tradeoffs between computing
> decent quality initial seeds versus class-loading.
> I still think we have the best practical compromise in place.

This pertains to the other thread (ThreadLocalRandom clinit troubles) 
started by Martin Buchholz, right? He's making a valid point. The 
"seeder" static field is still uninitialized during either 
NetworkInterface class initialization (as a result of 
NetworkInterface.getNetworkInterfaces() call) or during 
SecureRandom.getSeed() call. Either of which can execute user code in 
some configurations which might in turn use ThreadLocalRandom. If this 
happens, TLR.current() throws a NPE. I proposed a re-arrangement of 
class initialization that allows TLR to be fully functional even during 
it's initialization, albeit with a less randomized seed, and does not 
change the behaviour otherwise (since it triggers re-initialization at 
the end). See the proposed patch in the other thread.

Regards, Peter

>
> -Doug
>
>>           }
>>           UNSAFE.putInt(t, SECONDARY, r);
>>
>>
>> Regards, Peter
>>
>> On 06/19/2014 10:37 AM, Peter Levart wrote:
>>> Hi,
>>>
>>> I noticed an inconsistency in calling TLR.localInit() method. 
>>> Everywhere it's
>>> called conditionaly if thread-local "probe" is zero except in
>>> TLR.nextSecondarySeed() where it's called if "secondary" seed is 
>>> zero. This
>>> re-initializes the "probe" and "seed" even though they might have 
>>> already been
>>> initialized. It's not a big deal, because this happens at most once per
>>> thread, but it would be more consistent to call localInit() 
>>> conditionaly, I
>>> think:
>>>
>>>
>>> diff -r 5b45a5efe417
>>> src/share/classes/java/util/concurrent/ThreadLocalRandom.java
>>> --- a/src/share/classes/java/util/concurrent/ThreadLocalRandom.java 
>>> Tue May 20
>>> 10:11:23 2014 +0400
>>> +++ b/src/share/classes/java/util/concurrent/ThreadLocalRandom.java 
>>> Thu Jun 19
>>> 10:34:18 2014 +0200
>>> @@ -1034,7 +1034,8 @@
>>>              r ^= r << 5;
>>> }
>>>          else {
>>> - localInit();
>>> +            if (UNSAFE.getInt(t, PROBE) == 0)
>>> + localInit();
>>>              if ((r = (int)UNSAFE.getLong(t, SEED)) == 0)
>>>                  r = 1; // avoid zero
>>>          }
>>>
>>>
>>>
>>> Regards, Peter
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From peter.levart at gmail.com  Fri Jun 20 05:10:10 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 20 Jun 2014 11:10:10 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
Message-ID: <53A3FA72.3060706@gmail.com>

On 06/19/2014 08:04 PM, Martin Buchholz wrote:
> On Thu, Jun 19, 2014 at 1:22 AM, Alan Bateman <Alan.Bateman at oracle.com>
> wrote:
>
>> On 19/06/2014 05:25, Martin Buchholz wrote:
>>
>>> ThreadLocalRandom's clinit method creates an intermediate broken state of
>>> ThreadLocalRandom and then proceeds to run some networking code to get
>>> some
>>> more machine-specific entropy in initialSeed().  This will fail if the
>>> networking code ever recursively uses a (not yet functional)
>>> ThreadLocalRandom.  The clinit for InetAddress can cause arbitrary code to
>>> be run,
>>>
>>> at
>>> java.util.ServiceLoader$LazyIterator.hasNextService(
>>> ServiceLoader.java:354)
>>> at java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)
>>> at java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)
>>> at java.net.InetAddress$3.run(InetAddress.java:923)
>>> at java.net.InetAddress$3.run(InetAddress.java:918)
>>> at java.security.AccessController.doPrivileged(Native Method)
>>> at java.net.InetAddress.createNSProvider(InetAddress.java:917)
>>> at java.net.InetAddress.<clinit>(InetAddress.java:962)
>>>
>>> if the sun.net.spi.nameservice.provider system property is defined.
>>>
>>> The current strategy of ThreadLocalRandom relying on other java code for
>>> initialization seems risky.
>>>
>> Using a name service provider other than the default is going to interact
>> badly here. So is this configured to use the JNDI-DNS provider ("dns,sun")
>> or something else? This provider mechanism has been a source of many
>> problems, recursive initialization and stack overflow mostly because any
>> custom provider is likely going to use the network and resolve host names.
>> It can interact very badly with security when the provider doesn't have
>> AllPermision because attempts to establish connections involve security
>> checks that often need to do lookups too.
>>
>> So I'm curious if there is more to this stack trace to put more context on
>> the issue.
>
> The way we are actually seeing this is:
> - there are jdk8 jtreg tests that set the sun.net.spi.nameservice.provider
> property.  Grepping:
>
> ./java/net/Inet4Address/textToNumericFormat.java
> ./java/net/URLPermission/nstest/lookup.sh
> ./sun/net/InetAddress/nameservice/dns/cname.sh
> ./sun/net/InetAddress/nameservice/deadlock/Hang.java
> ./sun/net/InetAddress/nameservice/chaining/Providers.java
> ./sun/net/InetAddress/nameservice/simple/DefaultCaching.java
> ./sun/net/InetAddress/nameservice/simple/CacheTest.java
> ./sun/security/krb5/auto/KDC.java
> ./sun/security/krb5/canonicalize/Test.java
>
> - we have local modifications to classloading that happen to use TLR
> via ConcurrentSkipListMap - a "reasonable" thing to do.  Probably the
> simplest way to provoke a failure is to try to use a TLR from e.g.
> URLClassPath.
>
> In general, any core library boot class should try hard to avoid
> loading/invoking code from the user's classpath.

Hi Martin,

Does my proposed patch solve these issues or does the 
"sun.net.spi.nameservice.provider" triggered changed initialization 
order provoke other failures. I can imagine there might be other issues. 
Perhaps a more lazy initialization of NetworkInterface class that does 
not trigger initialization of NS providers could help. We just need to 
invoke two methods on NetworkInterface:

- static NetworkInterface.getNetworkInterfaces()
- instance NetworkInterface.getHardwareAddress()

both of which could provide the result without the need of NS providers, 
I think.

This would solve the most general case of using TLR. The case that 
doesn't involve SecureRandom's help which I think is rarely needed and 
not default.


Regards, Peter

>
>
>> It may be another example to back a suggestion to just drop the
>> JDK-internal name service provider mechanism. But in general, I think you
>> are right, it's not good for TLR initialization to trigger arbitrary code
>> to execute.
>>
>> -Alan.
>>


From peter.levart at gmail.com  Fri Jun 20 07:20:18 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 20 Jun 2014 13:20:18 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A3FA72.3060706@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com>
Message-ID: <53A418F2.3080201@gmail.com>

On 06/20/2014 11:10 AM, Peter Levart wrote:
> Perhaps a more lazy initialization of NetworkInterface class that does 
> not trigger initialization of NS providers could help. We just need to 
> invoke two methods on NetworkInterface:
>
> - static NetworkInterface.getNetworkInterfaces()
> - instance NetworkInterface.getHardwareAddress()
>
> both of which could provide the result without the need of NS 
> providers, I think.
>
> This would solve the most general case of using TLR. The case that 
> doesn't involve SecureRandom's help which I think is rarely needed and 
> not default.
>
>
> Regards, Peter 

Hi,

A patch that solves this is a patch to InetAddress. We can't suppress 
initialization of InetAddress as part of NetworkInterface 
initialization, but we can suppress initialization of NameService 
providers as part of InetAddress initialization by moving them into a 
nested class called NameServices:

http://cr.openjdk.java.net/~plevart/jdk9-dev/InetAddress.NameServices/webrev.01/

This should solve Martin's issue, but the patch to TLR initialization 
could be applied nevertheless, since it might help overcome possible 
issues when using SecureRandom for TLR's seed.

Regards, Peter


From stanimir at riflexo.com  Fri Jun 20 08:16:03 2014
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Fri, 20 Jun 2014 15:16:03 +0300
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A418F2.3080201@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
Message-ID: <CAEJX8op2dQG6_xpamupg87g0-q84iSquhArKpb3618-TXpZ5bQ@mail.gmail.com>

Hi Peter,
Irrc, ServiceLoader.load(NameServiceDescriptor.class) uses
Thread.contextClassLoader to load the services. Depending how late the
NameServices is getting initialized, perhaps it can be used to circumvent
the loader available at clinit of InetAddress.

I am not sure it could be a real security concern (as the caller has to be
authorized to create custom classloaders), yet the behavior is not exactly
the same. Storing Thread.currentThread().getContextClassLoader() during
clinit in a WeakRefernce (and clearing on use) should be closest to the
original code.

Cheers,
Stanimir



On Fri, Jun 20, 2014 at 2:20 PM, Peter Levart <peter.levart at gmail.com>
wrote:

> On 06/20/2014 11:10 AM, Peter Levart wrote:
>
>> Perhaps a more lazy initialization of NetworkInterface class that does
>> not trigger initialization of NS providers could help. We just need to
>> invoke two methods on NetworkInterface:
>>
>> - static NetworkInterface.getNetworkInterfaces()
>> - instance NetworkInterface.getHardwareAddress()
>>
>> both of which could provide the result without the need of NS providers,
>> I think.
>>
>> This would solve the most general case of using TLR. The case that
>> doesn't involve SecureRandom's help which I think is rarely needed and not
>> default.
>>
>>
>> Regards, Peter
>>
>
> Hi,
>
> A patch that solves this is a patch to InetAddress. We can't suppress
> initialization of InetAddress as part of NetworkInterface initialization,
> but we can suppress initialization of NameService providers as part of
> InetAddress initialization by moving them into a nested class called
> NameServices:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/InetAddress.
> NameServices/webrev.01/
>
> This should solve Martin's issue, but the patch to TLR initialization
> could be applied nevertheless, since it might help overcome possible issues
> when using SecureRandom for TLR's seed.
>
> Regards, Peter
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140620/71ed88f9/attachment-0001.html>

From chris.hegarty at oracle.com  Fri Jun 20 08:50:06 2014
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Fri, 20 Jun 2014 13:50:06 +0100
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CAEJX8op2dQG6_xpamupg87g0-q84iSquhArKpb3618-TXpZ5bQ@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>	<53A3FA72.3060706@gmail.com>
	<53A418F2.3080201@gmail.com>
	<CAEJX8op2dQG6_xpamupg87g0-q84iSquhArKpb3618-TXpZ5bQ@mail.gmail.com>
Message-ID: <53A42DFE.4080402@oracle.com>

I'm in favor of Peters approach ( I would need to do a more detailed 
review though ).

Looking up name service providers during initialization of InetAddress 
has been the cause of several issues in the past.

I agree with Stanimir's point about TCCL, but I don't think we should 
try to do anything about it. If some application depends on having a 
particular thread, with a "special" TCCL set, initialize InetAddress, 
then it is just broken.

I would prefer to keep this code as simple as possible, and stashing the 
TCCL for later use just adds complication.

-Chris.

On 20/06/14 13:16, Stanimir Simeonoff wrote:
> Hi Peter,
> Irrc, ServiceLoader.load(NameServiceDescriptor.class) uses
> Thread.contextClassLoader to load the services. Depending how late the
> NameServices is getting initialized, perhaps it can be used to
> circumvent the loader available at clinit of InetAddress.
>
> I am not sure it could be a real security concern (as the caller has to
> be authorized to create custom classloaders), yet the behavior is not
> exactly the same. Storing Thread.currentThread().getContextClassLoader()
> during clinit in a WeakRefernce (and clearing on use) should be closest
> to the original code.
>
> Cheers,
> Stanimir
>
>
>
> On Fri, Jun 20, 2014 at 2:20 PM, Peter Levart <peter.levart at gmail.com
> <mailto:peter.levart at gmail.com>> wrote:
>
>     On 06/20/2014 11:10 AM, Peter Levart wrote:
>
>         Perhaps a more lazy initialization of NetworkInterface class
>         that does not trigger initialization of NS providers could help.
>         We just need to invoke two methods on NetworkInterface:
>
>         - static NetworkInterface.__getNetworkInterfaces()
>         - instance NetworkInterface.__getHardwareAddress()
>
>         both of which could provide the result without the need of NS
>         providers, I think.
>
>         This would solve the most general case of using TLR. The case
>         that doesn't involve SecureRandom's help which I think is rarely
>         needed and not default.
>
>
>         Regards, Peter
>
>
>     Hi,
>
>     A patch that solves this is a patch to InetAddress. We can't
>     suppress initialization of InetAddress as part of NetworkInterface
>     initialization, but we can suppress initialization of NameService
>     providers as part of InetAddress initialization by moving them into
>     a nested class called NameServices:
>
>     http://cr.openjdk.java.net/~__plevart/jdk9-dev/InetAddress.__NameServices/webrev.01/
>     <http://cr.openjdk.java.net/~plevart/jdk9-dev/InetAddress.NameServices/webrev.01/>
>
>     This should solve Martin's issue, but the patch to TLR
>     initialization could be applied nevertheless, since it might help
>     overcome possible issues when using SecureRandom for TLR's seed.
>
>     Regards, Peter
>
>
>     _________________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.__oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From Alan.Bateman at oracle.com  Fri Jun 20 09:00:05 2014
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Fri, 20 Jun 2014 14:00:05 +0100
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A418F2.3080201@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
Message-ID: <53A43055.5070803@oracle.com>

On 20/06/2014 12:20, Peter Levart wrote:
>
> Hi,
>
> A patch that solves this is a patch to InetAddress. We can't suppress 
> initialization of InetAddress as part of NetworkInterface 
> initialization, but we can suppress initialization of NameService 
> providers as part of InetAddress initialization by moving them into a 
> nested class called NameServices:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/InetAddress.NameServices/webrev.01/ 
>
>
> This should solve Martin's issue, but the patch to TLR initialization 
> could be applied nevertheless, since it might help overcome possible 
> issues when using SecureRandom for TLR's seed.
That should work. An alternative is to just get rid of this mechanism. 
Way back then it was useful for running on systems that has NIS/YP 
configured as it wasn't always possible get to the fully qualified host 
name. It was also used as a workaround to long timeouts on Windows doing 
NetBIOS lookups. I don't think if either of these cases it interesting 
these days so it might be the simplest thing to just get rid of it. The 
other thing is that it was never meant to be a general service provider 
mechanism, it's not usable outside of the JDK without extending 
JDK-internal classes for example.

-Alan

From peter.levart at gmail.com  Fri Jun 20 10:02:27 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 20 Jun 2014 16:02:27 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A43055.5070803@oracle.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
	<53A43055.5070803@oracle.com>
Message-ID: <53A43EF3.8000206@gmail.com>

On 06/20/2014 03:00 PM, Alan Bateman wrote:
> On 20/06/2014 12:20, Peter Levart wrote:
>>
>> Hi,
>>
>> A patch that solves this is a patch to InetAddress. We can't suppress 
>> initialization of InetAddress as part of NetworkInterface 
>> initialization, but we can suppress initialization of NameService 
>> providers as part of InetAddress initialization by moving them into a 
>> nested class called NameServices:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/InetAddress.NameServices/webrev.01/ 
>>
>>
>> This should solve Martin's issue, but the patch to TLR initialization 
>> could be applied nevertheless, since it might help overcome possible 
>> issues when using SecureRandom for TLR's seed.
> That should work. An alternative is to just get rid of this mechanism. 
> Way back then it was useful for running on systems that has NIS/YP 
> configured as it wasn't always possible get to the fully qualified 
> host name. It was also used as a workaround to long timeouts on 
> Windows doing NetBIOS lookups. I don't think if either of these cases 
> it interesting these days so it might be the simplest thing to just 
> get rid of it. The other thing is that it was never meant to be a 
> general service provider mechanism, it's not usable outside of the JDK 
> without extending JDK-internal classes for example.
>
> -Alan

And, as Martin pointed out, it seems to be used for tests that exercise 
particular responses from NameService API to test the behaviour of JDK 
classes. It would be a shame for those tests to go away.

Regards, Peter


From Alan.Bateman at oracle.com  Fri Jun 20 10:59:06 2014
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Fri, 20 Jun 2014 15:59:06 +0100
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A43EF3.8000206@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
	<53A43055.5070803@oracle.com> <53A43EF3.8000206@gmail.com>
Message-ID: <53A44C3A.6000607@oracle.com>

On 20/06/2014 15:02, Peter Levart wrote:
>
> And, as Martin pointed out, it seems to be used for tests that 
> exercise particular responses from NameService API to test the 
> behaviour of JDK classes. It would be a shame for those tests to go away.
We've been talking about removing it for many years because it has been 
so troublesome. If we really need to having something for testing then I 
don't think it needs to be general purpose, we can get right of the 
lookup at least.

-Alan.

From martinrb at google.com  Sun Jun 22 00:05:23 2014
From: martinrb at google.com (Martin Buchholz)
Date: Sat, 21 Jun 2014 21:05:23 -0700
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A44C3A.6000607@oracle.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
	<53A43055.5070803@oracle.com> <53A43EF3.8000206@gmail.com>
	<53A44C3A.6000607@oracle.com>
Message-ID: <CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>

While looking at NativePRNG, I filed

https://bugs.openjdk.java.net/browse/JDK-8047769

SecureRandom should be more frugal with file descriptors

If I run this java program on Linux

public class SecureRandoms {
    public static void main(String[] args) throws Throwable {
        new java.security.SecureRandom();
    }
}

it creates 6 file descriptors for /dev/random and /dev/urandom, as shown
by:

strace -q -ff -e open java SecureRandoms |& grep /dev/
[pid 20769] open("/dev/random", O_RDONLY) = 5
[pid 20769] open("/dev/urandom", O_RDONLY) = 6
[pid 20769] open("/dev/random", O_RDONLY) = 7
[pid 20769] open("/dev/random", O_RDONLY) = 8
[pid 20769] open("/dev/urandom", O_RDONLY) = 9
[pid 20769] open("/dev/urandom", O_RDONLY) = 10

Looking at jdk/src/solaris/classes/sun/security/provider/NativePRNG.java
it looks like 2 file descriptors are created for every variant of
NativePRNG, whether or not they are ever used. Which is wasteful. In fact,
you only ever need at most two file descriptors, one for /dev/random and
one for /dev/urandom.

Further, it would be nice if the file descriptors were closed when idle and
lazily re-created. Especially /dev/random should typically be used at
startup and never thereafter.


On Fri, Jun 20, 2014 at 7:59 AM, Alan Bateman <Alan.Bateman at oracle.com>
wrote:

> On 20/06/2014 15:02, Peter Levart wrote:
>
>>
>> And, as Martin pointed out, it seems to be used for tests that exercise
>> particular responses from NameService API to test the behaviour of JDK
>> classes. It would be a shame for those tests to go away.
>>
> We've been talking about removing it for many years because it has been so
> troublesome. If we really need to having something for testing then I don't
> think it needs to be general purpose, we can get right of the lookup at
> least.
>
> -Alan.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140621/223c1506/attachment.html>

From anmiller at redhat.com  Sun Jun 22 11:39:38 2014
From: anmiller at redhat.com (Andrig Miller)
Date: Sun, 22 Jun 2014 11:39:38 -0400 (EDT)
Subject: [concurrency-interest] micro-benchmark for concurrent collections
In-Reply-To: <1350438252.1858561.1403451502639.JavaMail.zimbra@redhat.com>
Message-ID: <1938831105.1858614.1403451578986.JavaMail.zimbra@redhat.com>

I was wondering if anyone new of a good micro-benchmark for the concurrent collections? I specifically would like to benchmark ConcurrentHashMap, against an alternative implementation. A JMH based one would be preferable. 

Thanks. 

-- 
Andrig (Andy) Miller 
Global Platform Director for JBoss Middle-ware 
Red Hat, Inc. 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140622/07069e48/attachment.html>

From martinrb at google.com  Sun Jun 22 13:12:02 2014
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 22 Jun 2014 10:12:02 -0700
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
	<53A43055.5070803@oracle.com> <53A43EF3.8000206@gmail.com>
	<53A44C3A.6000607@oracle.com>
	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>
Message-ID: <CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>

We know that loading the networking machinery is problematic.  On Linux we
would be content to hard-code a read from /dev/urandom, which is safer and
strictly more random than the existing network hardware determination, but
y'all will reject that as too system-dependent (insufficient machinery!).
Hmmmm .... maybe not .... as long as we code up a good fallback ...

I learned that SecureRandom by default on Unix uses /dev/random for "seed
bytes" and /dev/urandom for nextBytes.

Here's my proposal, that in the default case on Unix doesn't load any
machinery, and as a fallback loads the SecureRandom machinery instead of
the network machinery, while maintaining the ultra-secure behavior of the
java.util.secureRandomSeed system property:


    private static long initialSeed() {
        byte[] seedBytes = initialSeedBytes();
        long s = (long)(seedBytes[0]) & 0xffL;
        for (int i = 1; i < seedBytes.length; ++i)
            s = (s << 8) | ((long)(seedBytes[i]) & 0xffL);
        return s ^ mix64(System.currentTimeMillis()) ^
mix64(System.nanoTime());
    }

    private static byte[] initialSeedBytes() {
        String pp = java.security.AccessController.doPrivileged(
                new sun.security.action.GetPropertyAction(
                        "java.util.secureRandomSeed"));
        boolean secureRandomSeed = (pp != null &&
pp.equalsIgnoreCase("true"));
        if (secureRandomSeed)
            return java.security.SecureRandom.getSeed(8);
        final byte[] seedBytes = new byte[8];
        File seedSource = new File("/dev/urandom");
        if (seedSource.exists()) {
            try (FileInputStream stream = new FileInputStream(seedSource)) {
                if (stream.read(seedBytes) == 8)
                    return seedBytes;
            } catch (IOException ignore) { }
        }
        new java.security.SecureRandom().nextBytes(seedBytes);
        return seedBytes;
    }




On Sat, Jun 21, 2014 at 9:05 PM, Martin Buchholz <martinrb at google.com>
wrote:

> While looking at NativePRNG, I filed
>
> https://bugs.openjdk.java.net/browse/JDK-8047769
>
> SecureRandom should be more frugal with file descriptors
>
> If I run this java program on Linux
>
> public class SecureRandoms {
>     public static void main(String[] args) throws Throwable {
>         new java.security.SecureRandom();
>     }
> }
>
> it creates 6 file descriptors for /dev/random and /dev/urandom, as shown
> by:
>
> strace -q -ff -e open java SecureRandoms |& grep /dev/
> [pid 20769] open("/dev/random", O_RDONLY) = 5
> [pid 20769] open("/dev/urandom", O_RDONLY) = 6
> [pid 20769] open("/dev/random", O_RDONLY) = 7
> [pid 20769] open("/dev/random", O_RDONLY) = 8
> [pid 20769] open("/dev/urandom", O_RDONLY) = 9
> [pid 20769] open("/dev/urandom", O_RDONLY) = 10
>
> Looking at jdk/src/solaris/classes/sun/security/provider/NativePRNG.java
> it looks like 2 file descriptors are created for every variant of
> NativePRNG, whether or not they are ever used. Which is wasteful. In fact,
> you only ever need at most two file descriptors, one for /dev/random and
> one for /dev/urandom.
>
> Further, it would be nice if the file descriptors were closed when idle
> and lazily re-created. Especially /dev/random should typically be used at
> startup and never thereafter.
>
>
> On Fri, Jun 20, 2014 at 7:59 AM, Alan Bateman <Alan.Bateman at oracle.com>
> wrote:
>
>> On 20/06/2014 15:02, Peter Levart wrote:
>>
>>>
>>> And, as Martin pointed out, it seems to be used for tests that exercise
>>> particular responses from NameService API to test the behaviour of JDK
>>> classes. It would be a shame for those tests to go away.
>>>
>> We've been talking about removing it for many years because it has been
>> so troublesome. If we really need to having something for testing then I
>> don't think it needs to be general purpose, we can get right of the lookup
>> at least.
>>
>> -Alan.
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140622/948fceeb/attachment.html>

From martinrb at google.com  Sun Jun 22 14:54:24 2014
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 22 Jun 2014 11:54:24 -0700
Subject: [concurrency-interest] ThreadLocalRandom.nextSecondarySeed()
 re-initializes TLR's seed
In-Reply-To: <53A3F3F7.9010506@gmail.com>
References: <53A2A155.3040509@gmail.com> <53A2A3D8.8000602@gmail.com>
	<53A2D13E.4020006@cs.oswego.edu> <53A3F3F7.9010506@gmail.com>
Message-ID: <CA+kOe0-Z2kCgADAPJ1dhqNYw+n6pM-josKDKcQTcwLkG=oJMEQ@mail.gmail.com>

On Fri, Jun 20, 2014 at 1:42 AM, Peter Levart <peter.levart at gmail.com>
wrote:

>
> This pertains to the other thread (ThreadLocalRandom clinit troubles)
> started by Martin Buchholz, right? He's making a valid point. The "seeder"
> static field is still uninitialized during either NetworkInterface class
> initialization (as a result of NetworkInterface.getNetworkInterfaces()
> call) or during SecureRandom.getSeed() call. Either of which can execute
> user code in some configurations which might in turn use ThreadLocalRandom.
> If this happens, TLR.current() throws a NPE. I proposed a re-arrangement of
> class initialization that allows TLR to be fully functional even during
> it's initialization, albeit with a less randomized seed, and does not
> change the behaviour otherwise (since it triggers re-initialization at the
> end). See the proposed patch in the other thread.
>

I tried this same approach, and found that:

yes, we see some previously failing tests that start passing when the TLR
is functional even while executing its own clinit method, BUT there are
other tests that still fail, and only start passing when the network init
code is removed ... for unknown reasons.  We could debug them, but the
fundamental danger remains - TLR may be invoked very early during JDK
startup, and it is simply too risky to load higher-level libraries so
early, possibly invoking foreign code that might do anything.  Which is why
I keep trying to minimize TLR's external dependencies.

Whatever we decide to do here, the same changes should be made to
SplittableRandom.  Maybe there's scope for some refactoring/sharing, both
of code and of file system access at runtime.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140622/fb66d0ed/attachment.html>

From martinrb at google.com  Mon Jun 23 18:39:47 2014
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 23 Jun 2014 15:39:47 -0700
Subject: [concurrency-interest] Proposal for a CallerRunsExecutor in
	j.u.c.Executors
In-Reply-To: <CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>
References: <CAO9V1MKUEBD6Ea7yqHeqYW98JZX7cLv6zoyDgp7xu7051EHykg@mail.gmail.com>
	<5380DED8.9060103@cs.oswego.edu>
	<CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
	<CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>
Message-ID: <CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>

So ... as usual, the best is the enemy of the good.

None of the current methods in Executors returns "just" an Executor - they
always return at least an ExecutorService.
While defining an Executor is easy, there are questions about defining an
ExecutorService, especially around life cycle management.  I think we
should define a static "system" caller-runs ExecutorService that is an
analogue of the common fork join pool - it cannot be shutdown and persists
to the end of the JVM's lifetime.  The uncomfortable questions are what to
do about calls to shutdown() and and awaitTermination() - we do not want to
keep track of currently active tasks to await quiescence.  We could have
awaitTermination hang until timeout elapses, or return immediately, or
throw UOE.

Since introducing a plain Executor is much better than doing nothing, let's
start with that.


On Fri, Jun 6, 2014 at 9:17 AM, Luke Sandberg <lukeisandberg at gmail.com>
wrote:

> ping.  Is there anything i can do to help move this forward?
>
> Thanks,
> Luke
>
>
> On Sat, May 24, 2014 at 3:15 PM, Luke Sandberg <lukeisandberg at gmail.com>
> wrote:
>
>> On Sat, May 24, 2014 at 11:03 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>
>>> On 05/23/2014 08:05 PM, Luke Sandberg wrote:
>>>
>>>> Guava has an Executor instance called MoreExecutors.sameThreadExecutor
>>>> <http://docs.guava-libraries.googlecode.com/git/javadoc/
>>>> com/google/common/util/concurrent/MoreExecutors.html#
>>>> sameThreadExecutor()>
>>>>
>>>>
>>>> For Guava users it is very popular for passing to APIs like
>>>> ListenableFuture.addListener and other Executor accepting utilities for
>>>> when the
>>>> task will be quick enough that it isn't worth submitting to a thread
>>>> pool.
>>>>
>>>> There was recently a performance bug reported against it:
>>>> https://code.google.com/p/guava-libraries/issues/detail?id=1734
>>>>
>>>> This led to us reconsider the implementation in Guava and then thinking
>>>> that
>>>> maybe this should even be a j.u.c.Executors feature.
>>>>
>>>
>>> The class has been sitting there under the name DirectExecutor
>>> since JDK5 as a code example in the Executors javadoc.
>>> (See http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/
>>> concurrent/Executor.html)
>>> We even discussed putting it (as well as the other code example,
>>> ThreadPerTaskExecutor) in Executors but for some reason decided
>>> they weren't important enough. But they are important in that
>>> standardizing their names and usage will save people work.
>>> So I can't think of a reason not to do this, even if a decade
>>> too late for most purposes. Any objections to using these names?
>>
>>
>> Yeah we noticed the DirectExecutor example too, but consensus appeared to
>> be against using that name.  Also it was noted that in JCIP Brian Goetz
>> calls the same thing 'WithinThreadExecutor'.  callerRunsExecutor was
>> suggested due to the existence of ThreadPoolExecutor.CallerRunsPolicy. (And
>> there were about 10 thousand other suggestions: immediateExecutor,
>> currentThreadExecutor, synchronousExecutor,...).
>>
>> I have no objection to DirectExecutor though I do have a preference for
>> CallerRunsExecutor.
>>
>> As for ThreadPerTaskExecutor, that name seems reasonable to me.
>>
>>
>>
>>>
>>>
>>>      MoreExecutors.newCallerRunsExecutorService():
>>>>        which would be identical to the current sameThreadExecutor()
>>>> (which
>>>>     includes shutdown semantics)
>>>>
>>>
>>>
>>> I gather that this one uses a Lock just to support the
>>> awaitTermination method? (Otherwise it would need only
>>> a volatile boolean shutdown bit.) It does seem like a niche usage,
>>> but maybe someone could make a case for including it.
>>>
>>
>> That is correct.  I agree that this is less commonly useful (and it is
>> often most useful in testing situations).  So just leaving this in Guava
>> could make sense.  Martin Buchholz suggested just making the
>> CallerRunsExecutor be a unshutdownable shared ExecutorService instance as a
>> kind of compromise.
>>
>>
>>>
>>> -Doug
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140623/71d26bdf/attachment.html>

From martinrb at google.com  Mon Jun 23 18:51:38 2014
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 23 Jun 2014 15:51:38 -0700
Subject: [concurrency-interest] Proposal for a CallerRunsExecutor in
	j.u.c.Executors
In-Reply-To: <CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>
References: <CAO9V1MKUEBD6Ea7yqHeqYW98JZX7cLv6zoyDgp7xu7051EHykg@mail.gmail.com>
	<5380DED8.9060103@cs.oswego.edu>
	<CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
	<CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>
	<CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>
Message-ID: <CA+kOe08wOyA_v5kM4saHuT7LE8F-_EvazGnoyFwO0qoY-ekuZA@mail.gmail.com>

--- src/main/java/util/concurrent/Executors.java 18 Jul 2013 17:13:42 -0000
1.88
+++ src/main/java/util/concurrent/Executors.java 23 Jun 2014 22:49:59 -0000
@@ -167,6 +167,21 @@
                                     threadFactory));
     }

+    private static class CallerRunsExecutor implements Executor {
+        static final CallerRunsExecutor INSTANCE = new
CallerRunsExecutor();
+        public void execute(Runnable r) { r.run(); }
+    }
+
+    /**
+     * Returns an Executor that runs tasks in the current thread.
+     * Tasks run entirely during calls to {@link Executor#execute}.
+     *
+     * @return a caller-runs Executor
+     */
+    public static Executor callerRunsExecutor() {
+        return CallerRunsExecutor.INSTANCE;
+    }
+
     /**
      * Creates a thread pool that creates new threads as needed, but
      * will reuse previously constructed threads when they are
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140623/c645a616/attachment.html>

From regank at google.com  Mon Jun 23 19:41:38 2014
From: regank at google.com (Kevin Regan)
Date: Mon, 23 Jun 2014 16:41:38 -0700
Subject: [concurrency-interest] Accessing original callable object from a
	Future?
Message-ID: <CAG=mn_stY1sCKtsBRtW0Ovosg=vM4+V6dteDyOkvHjZCuWJuYg@mail.gmail.com>

Sometimes, I find the need to be able to access the original Callable
object from a Future.  It seems like this requires the a keep a map from
Future to the original Callable value (and assuming that
ExecutionCompletionService returns the same Future in take() as in
submit()).

Has there been any thought into possibly making this task easier?  Possibly
some way of connecting some identifying information with the Future?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140623/62460858/attachment.html>

From martinrb at google.com  Mon Jun 23 21:45:35 2014
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 23 Jun 2014 18:45:35 -0700
Subject: [concurrency-interest] Accessing original callable object from
	a Future?
In-Reply-To: <CAG=mn_stY1sCKtsBRtW0Ovosg=vM4+V6dteDyOkvHjZCuWJuYg@mail.gmail.com>
References: <CAG=mn_stY1sCKtsBRtW0Ovosg=vM4+V6dteDyOkvHjZCuWJuYg@mail.gmail.com>
Message-ID: <CA+kOe09s4Y+vEzyTMYELBE454hc+LuijtQW3LBwH3e-uX_PkCw@mail.gmail.com>

Kevin,

There is nothing in java.util.concurrent to make this easier.  Future in
general is not associated with any task, so there is no API there to help
you.  FutureTask *is* associated with a task, but it tries hard to forget
about it once it reaches the "done" state, to make the memory reclaimable.


On Mon, Jun 23, 2014 at 4:41 PM, Kevin Regan <regank at google.com> wrote:

> Sometimes, I find the need to be able to access the original Callable
> object from a Future.  It seems like this requires the a keep a map from
> Future to the original Callable value (and assuming that
> ExecutionCompletionService returns the same Future in take() as in
> submit()).
>
> Has there been any thought into possibly making this task easier?
>  Possibly some way of connecting some identifying information with the
> Future?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140623/f6fe3051/attachment-0001.html>

From zhong.j.yu at gmail.com  Mon Jun 23 22:19:33 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Mon, 23 Jun 2014 21:19:33 -0500
Subject: [concurrency-interest] Proposal for a CallerRunsExecutor in
	j.u.c.Executors
In-Reply-To: <CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>
References: <CAO9V1MKUEBD6Ea7yqHeqYW98JZX7cLv6zoyDgp7xu7051EHykg@mail.gmail.com>
	<5380DED8.9060103@cs.oswego.edu>
	<CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
	<CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>
	<CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>
Message-ID: <CACuKZqFb5mkuujCOw8Brk7taJ_x-XsKhNdLkWwzQnsYe3tzEyQ@mail.gmail.com>

On Mon, Jun 23, 2014 at 5:39 PM, Martin Buchholz <martinrb at google.com> wrote:
> Since introducing a plain Executor is much better than doing nothing, let's
> start with that.

Is it necessary though? In java 8, programmers can simply use

    (Executor)Runnable::run

Pre java8, an anonymous class isn't too verbose either

    new Executor(){ public void execute(Runnable r) { r.run(); } }

It doesn't seem to warrant a convenience method in java.*.

Zhong Yu
bayou.io

From peter.firmstone at zeus.net.au  Tue Jun 24 06:24:59 2014
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Tue, 24 Jun 2014 20:24:59 +1000
Subject: [concurrency-interest] Deadlock
Message-ID: <53A951FB.8060506@zeus.net.au>

This appears to be a ClassLoader deadlock in Java 7.

The stack trace from the main thread is missing.

Any ideas?

Regards,

Peter.

Attaching to process ID 7124, please wait...
Debugger attached successfully.
Client compiler detected.
JVM version is 25.0-b70
Deadlock Detection:

Found one Java-level deadlock:
=============================

"main":
   waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a 
java/lang/Object),
   which is held by "Thread-1"
"Thread-1":
   waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
   which is held by "main"

Found a total of 1 deadlock.

Thread 8: (state = BLOCKED)
  - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object, 
au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229, 
line=60 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=37, line=128 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=4, line=44 (Interpreted frame)
  - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, 
boolean, boolean) @bci=7, line=248 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lang.Object, 
java.lang.Object) @bci=8, line=67 (Interpreted frame)
  - 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission, 
java.lang.Object) @bci=161, line=260 (Interpreted frame)
  - 
com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(java.lang.Class) 
@bci=59, line=1848 (Interpreted frame)
  - 
com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(java.lang.Object, 
javax.management.ObjectName) @bci=25, line=322 (Interpreted frame)
  - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17, line=1225 
(Interpreted frame)
  - 
java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction) 
@bci=0 (Interpreted frame)
  - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25, 
line=1223 (Interpreted frame)
  - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate, 
com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) @bci=133, 
line=255 (Interpreted frame)
  - 
com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate, 
boolean) @bci=13, line=1437 (Interpreted frame)
  - javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate) 
@bci=4, line=110 (Interpreted frame)
  - javax.management.MBeanServerFactory.newMBeanServer(java.lang.String) 
@bci=36, line=329 (Interpreted frame)
  - 
javax.management.MBeanServerFactory.createMBeanServer(java.lang.String) 
@bci=6, line=231 (Interpreted frame)
  - javax.management.MBeanServerFactory.createMBeanServer() @bci=1, 
line=192 (Interpreted frame)
  - java.lang.management.ManagementFactory.getPlatformMBeanServer() 
@bci=29, line=468 (Interpreted frame)
  - 
sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer() 
@bci=66, line=518 (Interpreted frame)
  - sun.management.Agent.startLocalManagementAgent() @bci=13, line=138 
(Interpreted frame)
  - sun.management.Agent.startAgent(java.util.Properties) @bci=76, 
line=260 (Interpreted frame)
  - sun.management.Agent.agentmain(java.lang.String) @bci=45, line=128 
(Interpreted frame)
  - 
sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method, 
java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
  - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object, 
java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
  - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, 
java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
  - java.lang.reflect.Method.invoke(java.lang.Object, 
java.lang.Object[]) @bci=56, line=483 (Interpreted frame)
  - 
sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lang.String, 
java.lang.String, java.lang.String) @bci=192, line=388 (Interpreted frame)
  - 
sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.lang.String, 
java.lang.String) @bci=5, line=411 (Interpreted frame)


Thread 7: (state = BLOCKED)


Thread 5: (state = BLOCKED)
  - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object, 
au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229, 
line=60 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=37, line=128 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=4, line=44 (Interpreted frame)
  - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, 
boolean, boolean) @bci=7, line=248 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lang.Object, 
java.lang.Object) @bci=8, line=67 (Interpreted frame)
  - 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission, 
java.lang.Object) @bci=161, line=260 (Interpreted frame)
  - 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission) 
@bci=27, line=202 (Interpreted frame)
  - java.net.NetworkInterface.getHardwareAddress() @bci=18, line=447 
(Interpreted frame)
  - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116, 
line=158 (Interpreted frame)
  - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14, line=137 
(Interpreted frame)
  - java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean) 
@bci=0, line=2526 (Interpreted frame)
  - java.util.concurrent.ConcurrentHashMap.addCount(long, int) @bci=104, 
line=2266 (Interpreted frame)
  - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object, 
java.lang.Object, boolean) @bci=357, line=1070 (Interpreted frame)
  - java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object, 
java.lang.Object) @bci=4, line=1535 (Interpreted frame)
  - java.lang.ClassLoader.getClassLoadingLock(java.lang.String) @bci=23, 
line=463 (Interpreted frame)
  - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=2, 
line=404 (Interpreted frame)
  - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=38, 
line=411 (Interpreted frame)
  - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, 
boolean) @bci=36, line=308 (Interpreted frame)
  - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357 
(Interpreted frame)
  - 
org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.cliffc.high_scale_lib.NonBlockingHashMap) 
@bci=10, line=1167 (Interpreted frame)
  - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() @bci=8, 
line=1200 (Interpreted frame)
  - au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() 
@bci=15, line=166 (Interpreted frame)
  - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, 
line=511 (Interpreted frame)
  - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308 
(Interpreted frame)
  - 
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask) 
@bci=1, line=180 (Interpreted frame)
  - 
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run() 
@bci=37, line=294 (Interpreted frame)
  - 
java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) 
@bci=95, line=1142 (Interpreted frame)
  - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, 
line=617 (Interpreted frame)
  - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)


Thread 4: (state = BLOCKED)
  - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
  - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142 
(Interpreted frame)
  - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158 (Interpreted 
frame)
  - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209 
(Interpreted frame)


Thread 3: (state = BLOCKED)
  - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
  - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
  - java.lang.ref.Reference$ReferenceHandler.run() @bci=36, line=157 
(Interpreted frame)


Thread 1: (state = BLOCKED)
  - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=8, 
line=406 (Interpreted frame)
  - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, 
boolean) @bci=36, line=308 (Interpreted frame)
  - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357 
(Interpreted frame)
  - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object, 
au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229, 
line=60 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=37, line=128 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) @bci=4, line=44 (Interpreted frame)
  - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, 
boolean, boolean) @bci=7, line=248 (Interpreted frame)
  - 
au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lang.Object, 
java.lang.Object) @bci=8, line=67 (Interpreted frame)
  - 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission, 
java.lang.Object) @bci=161, line=260 (Interpreted frame)
  - 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission) 
@bci=27, line=202 (Interpreted frame)
  - java.lang.System.checkIO() @bci=18, line=253 (Interpreted frame)
  - java.lang.System.setErr(java.io.PrintStream) @bci=0, line=199 
(Interpreted frame)
  - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[]) @bci=9, 
line=84 (Interpreted frame)

The long version:

Attaching to process ID 7124, please wait...
Debugger attached successfully.
Client compiler detected.
JVM version is 25.0-b70
Deadlock Detection:

Found one Java-level deadlock:
=============================

"main":
   waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a 
java/lang/Object),
   which is held by "Thread-1"
"Thread-1":
   waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
   which is held by "main"

Found a total of 1 deadlock.

----------------- 0 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x00e64d7b    java + 0x4d7b
0x00e631ca    java + 0x31ca
0x00e642ab    java + 0x42ab
0x00e63440    java + 0x3440
0x00130138        ????????
----------------- 1 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
0x5bea1b28    jvm + 0x71b28
0x01aa1cef    * java.lang.ClassLoader.loadClass(java.lang.String, 
boolean) bci:8 line:406 (Interpreted frame)
0x01a94054    * 
sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean) 
bci:36 line:308 (Interpreted frame)
0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3 
line:357 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
0x5be77d6f    jvm + 0x47d6f
0x5be7822a    jvm + 0x4822a
0x5be794c0    jvm + 0x494c0
0x5be7950a    jvm + 0x4950a
0x5bf20de5    jvm!_JVM_FindClassFromClass at 16 + 0x135
0x73b515cd    verify + 0x15cd
0x73b51d53    verify + 0x1d53
0x73b52c67    verify + 0x2c67
0x14d6f5e8        ????????
Locked ownable synchronizers:
     - None
----------------- 2 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
0x5bf99671    jvm!JVM_GetThreadStateNames + 0x6d221
0x5bf99a32    jvm!JVM_GetThreadStateNames + 0x6d5e2
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
----------------- 3 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
0x01a940f4    * java.lang.Object.wait() bci:2 line:502 (Interpreted frame)
0x01a940f4    * java.lang.ref.Reference$ReferenceHandler.run() bci:36 
line:157 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
0x5bf1de0f    jvm!jio_printf + 0x9f
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 4 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
0x01a940f4    * java.lang.ref.ReferenceQueue.remove(long) bci:44 
line:142 (Interpreted frame)
0x01a94054    * java.lang.ref.ReferenceQueue.remove() bci:2 line:158 
(Interpreted frame)
0x01a94054    * java.lang.ref.Finalizer$FinalizerThread.run() bci:36 
line:209 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
0x5bf1de0f    jvm!jio_printf + 0x9f
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 5 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
0x5bee0d10    jvm + 0xb0d10
0x5bee2854    jvm + 0xb2854
0x5bee3548    jvm + 0xb3548
0x5bea5641    jvm + 0x75641
0x01aa17be    * 
au.net.zeus.collection.ReferenceFactory.create(java.lang.Object, 
au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229 
line:60 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) bci:37 line:128 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) bci:4 line:44 (Interpreted frame)
0x01a94089    * 
au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean, 
boolean) bci:7 line:248 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lang.Object, 
java.lang.Object) bci:8 line:67 (Interpreted frame)
0x01a94089    * 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission, 
java.lang.Object) bci:161 line:260 (Interpreted frame)
0x01a940f4    * 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission) 
bci:27 line:202 (Interpreted frame)
0x01a940f4    * java.net.NetworkInterface.getHardwareAddress() bci:18 
line:447 (Interpreted frame)
0x01a94054    * java.util.concurrent.ThreadLocalRandom.initialSeed() 
bci:116 line:158 (Interpreted frame)
0x01a93e20    * java.util.concurrent.ThreadLocalRandom.<clinit>() bci:14 
line:137 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bee0f44    jvm + 0xb0f44
0x5bee2b21    jvm + 0xb2b21
0x5bee3548    jvm + 0xb3548
0x5bea9796    jvm + 0x79796
0x5beaa7b2    jvm + 0x7a7b2
0x5bea5dc7    jvm + 0x75dc7
0x01aa12ae    * 
java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean) bci:0 
line:2526 (Interpreted frame)
0x01a940f4    * java.util.concurrent.ConcurrentHashMap.addCount(long, 
int) bci:104 line:2266 (Interpreted frame)
0x01a940f4    * 
java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object, 
java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
0x01a94054    * 
java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object, 
java.lang.Object) bci:4 line:1535 (Interpreted frame)
0x01a94054    * 
java.lang.ClassLoader.getClassLoadingLock(java.lang.String) bci:23 
line:463 (Interpreted frame)
0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String, 
boolean) bci:2 line:404 (Interpreted frame)
0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String, 
boolean) bci:38 line:411 (Interpreted frame)
0x01a94054    * 
sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean) 
bci:36 line:308 (Interpreted frame)
0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3 
line:357 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
0x5be77d6f    jvm + 0x47d6f
0x5be7822a    jvm + 0x4822a
0x5be794c0    jvm + 0x494c0
0x5be7950a    jvm + 0x4950a
0x5be79f66    jvm + 0x49f66
0x5be715c7    jvm + 0x415c7
0x5be7a53c    jvm + 0x4a53c
0x5be817e2    jvm + 0x517e2
0x5be822d9    jvm + 0x522d9
0x5be82414    jvm + 0x52414
0x5bed85dd    jvm + 0xa85dd
0x5bee0d80    jvm + 0xb0d80
0x5bee2854    jvm + 0xb2854
0x5bee3548    jvm + 0xb3548
0x5bea5641    jvm + 0x75641
0x01aa17be    * 
org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.cliffc.high_scale_lib.NonBlockingHashMap) 
bci:10 line:1167 (Interpreted frame)
0x01a940f4    * 
org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8 
line:1200 (Interpreted frame)
0x01a94089    * 
au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() bci:15 
line:166 (Interpreted frame)
0x01a94129    * java.util.concurrent.Executors$RunnableAdapter.call() 
bci:4 line:511 (Interpreted frame)
0x01a94089    * java.util.concurrent.FutureTask.runAndReset() bci:47 
line:308 (Interpreted frame)
0x01a93ba0    * 
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask) 
bci:1 line:180 (Interpreted frame)
0x01a93ba0    * 
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run() 
bci:37 line:294 (Interpreted frame)
0x01a94129    * 
java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) 
bci:95 line:1142 (Interpreted frame)
0x01a940f4    * java.util.concurrent.ThreadPoolExecutor$Worker.run() 
bci:5 line:617 (Interpreted frame)
0x01a94129    * java.lang.Thread.run() bci:11 line:744 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
0x5bf1de0f    jvm!jio_printf + 0x9f
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - <0x03d58650>, (a java/util/concurrent/ThreadPoolExecutor$Worker)
----------------- 6 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
----------------- 7 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd9539    jvm!_JVM_FindSignal at 4 + 0x5269
0x5bfd9607    jvm!_JVM_FindSignal at 4 + 0x5337
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 8 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
0x5bf7856b    jvm!JVM_GetThreadStateNames + 0x4c11b
0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
0x5bee0d10    jvm + 0xb0d10
0x5bee2854    jvm + 0xb2854
0x5bee3548    jvm + 0xb3548
0x5bea5641    jvm + 0x75641
0x01aa17be    * 
au.net.zeus.collection.ReferenceFactory.create(java.lang.Object, 
au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229 
line:60 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) bci:37 line:128 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object, 
boolean, boolean) bci:4 line:44 (Interpreted frame)
0x01a94089    * 
au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean, 
boolean) bci:7 line:248 (Interpreted frame)
0x01a94054    * 
au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lang.Object, 
java.lang.Object) bci:8 line:67 (Interpreted frame)
0x01a94089    * 
org.apache.river.api.security.CombinerSecurityManager.checkPermission(java.security.Permission, 
java.lang.Object) bci:161 line:260 (Interpreted frame)
0x01a940f4    * 
com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(java.lang.Class) 
bci:59 line:1848 (Interpreted frame)
0x01a940f4    * 
com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(java.lang.Object, 
javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
0x01a94089    * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() bci:17 
line:1225 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf299ed    jvm!_JVM_DoPrivileged at 20 + 0x2bd
0x73b21047    
java_73b20000!_Java_java_security_AccessController_doPrivileged__Ljava_security_PrivilegedExceptionAction_2 at 12 
+ 0x15
0x01a94054    * com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() 
bci:25 line:1223 (Interpreted frame)
0x01a940f4    * 
com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate, 
com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) bci:133 
line:255 (Interpreted frame)
0x01a940f4    * 
com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate, 
boolean) bci:13 line:1437 (Interpreted frame)
0x01a94054    * 
javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String, 
javax.management.MBeanServer, javax.management.MBeanServerDelegate) 
bci:4 line:110 (Interpreted frame)
0x01a94054    * 
javax.management.MBeanServerFactory.newMBeanServer(java.lang.String) 
bci:36 line:329 (Interpreted frame)
0x01a94054    * 
javax.management.MBeanServerFactory.createMBeanServer(java.lang.String) 
bci:6 line:231 (Interpreted frame)
0x01a94054    * javax.management.MBeanServerFactory.createMBeanServer() 
bci:1 line:192 (Interpreted frame)
0x01a94054    * 
java.lang.management.ManagementFactory.getPlatformMBeanServer() bci:29 
line:468 (Interpreted frame)
0x01a94054    * 
sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer() 
bci:66 line:518 (Interpreted frame)
0x01a94054    * sun.management.Agent.startLocalManagementAgent() bci:13 
line:138 (Interpreted frame)
0x01a940f4    * sun.management.Agent.startAgent(java.util.Properties) 
bci:76 line:260 (Interpreted frame)
0x01a940f4    * sun.management.Agent.agentmain(java.lang.String) bci:45 
line:128 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5bf7e73a    jvm!JVM_GetThreadStateNames + 0x522ea
0x5bf7e993    jvm!JVM_GetThreadStateNames + 0x52543
0x5bf22b03    jvm!_JVM_InvokeMethod at 16 + 0xb3
0x73b23a6e    
java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20 + 0x15
0x01a94054    * 
sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object, 
java.lang.Object[]) bci:100 line:62 (Interpreted frame)
0x01a94054    * 
sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, 
java.lang.Object[]) bci:6 line:43 (Interpreted frame)
0x01a94089    * java.lang.reflect.Method.invoke(java.lang.Object, 
java.lang.Object[]) bci:56 line:483 (Interpreted frame)
0x01a94054    * 
sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lang.String, 
java.lang.String, java.lang.String) bci:192 line:388 (Interpreted frame)
0x01a940f4    * 
sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.lang.String, 
java.lang.String) bci:5 line:411 (Interpreted frame)
0x01a903d7 <StubRoutines>
0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
0x5befe951    jvm!JNI_GetCreatedJavaVMs + 0x71a1
0x5bf01788    jvm!JNI_GetCreatedJavaVMs + 0x9fd8
0x6db62878    instrument!Agent_OnAttach + 0x76b
0x6db63eea    instrument!Agent_OnAttach + 0x1ddd
0x6db6234a    instrument!Agent_OnAttach + 0x23d
0x5bf3c50c    jvm!JVM_GetThreadStateNames + 0x100bc
0x5bf9b05e    jvm!JVM_GetThreadStateNames + 0x6ec0e
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 9 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
0x5bf7424a    jvm!JVM_GetThreadStateNames + 0x47dfa
0x5be9253b    jvm + 0x6253b
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 10 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
0x5bf73ec1    jvm!JVM_GetThreadStateNames + 0x47a71
0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
0x5bf829a5    jvm!JVM_GetThreadStateNames + 0x56555
0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
Locked ownable synchronizers:
     - None
----------------- 11 -----------------
0x77c870f4    ntdll!KiFastSystemCallRet
0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
0x76a9c382    kernel32!WaitForSingleObject + 0x12
0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
0x5bf8f904    jvm!JVM_GetThreadStateNames + 0x634b4
0x5bf8f9a7    jvm!JVM_GetThreadStateNames + 0x63557
0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
0x614dc556    msvcr100!_endthreadex + 0x3a
0x614dc600    msvcr100!_endthreadex + 0xe4
0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2



From davidcholmes at aapt.net.au  Tue Jun 24 07:09:06 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 24 Jun 2014 21:09:06 +1000
Subject: [concurrency-interest] Deadlock
In-Reply-To: <53A951FB.8060506@zeus.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>

Hi Peter,

What a strange coincidence - the fact that the initialization of
ThreadLocalRandom can lead to arbitrary code execution has just been a topic
of discussion, and it looks like your deadlock is related to that.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Firmstone
> Sent: Tuesday, 24 June 2014 8:25 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Deadlock
>
>
> This appears to be a ClassLoader deadlock in Java 7.
>
> The stack trace from the main thread is missing.
>
> Any ideas?
>
> Regards,
>
> Peter.
>
> Attaching to process ID 7124, please wait...
> Debugger attached successfully.
> Client compiler detected.
> JVM version is 25.0-b70
> Deadlock Detection:
>
> Found one Java-level deadlock:
> =============================
>
> "main":
>    waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
> java/lang/Object),
>    which is held by "Thread-1"
> "Thread-1":
>    waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>    which is held by "main"
>
> Found a total of 1 deadlock.
>
> Thread 8: (state = BLOCKED)
>   - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
> line=60 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>   - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> g.Object,
> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>   -
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission,
> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>   -
> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
> ustPermission(java.lang.Class)
> @bci=59, line=1848 (Interpreted frame)
>   -
> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
> n(java.lang.Object,
> javax.management.ObjectName) @bci=25, line=322 (Interpreted frame)
>   - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17, line=1225
> (Interpreted frame)
>   -
> java.security.AccessController.doPrivileged(java.security.Privileg
> edExceptionAction)
> @bci=0 (Interpreted frame)
>   - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25,
> line=1223 (Interpreted frame)
>   - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) @bci=133,
> line=255 (Interpreted frame)
>   -
> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
> boolean) @bci=13, line=1437 (Interpreted frame)
>   - javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
> @bci=4, line=110 (Interpreted frame)
>   - javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
> @bci=36, line=329 (Interpreted frame)
>   -
> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
> @bci=6, line=231 (Interpreted frame)
>   - javax.management.MBeanServerFactory.createMBeanServer() @bci=1,
> line=192 (Interpreted frame)
>   - java.lang.management.ManagementFactory.getPlatformMBeanServer()
> @bci=29, line=468 (Interpreted frame)
>   -
> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
> @bci=66, line=518 (Interpreted frame)
>   - sun.management.Agent.startLocalManagementAgent() @bci=13, line=138
> (Interpreted frame)
>   - sun.management.Agent.startAgent(java.util.Properties) @bci=76,
> line=260 (Interpreted frame)
>   - sun.management.Agent.agentmain(java.lang.String) @bci=45, line=128
> (Interpreted frame)
>   -
> sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method,
> java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
>   - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
> java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
>   - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
> java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
>   - java.lang.reflect.Method.invoke(java.lang.Object,
> java.lang.Object[]) @bci=56, line=483 (Interpreted frame)
>   -
> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
> g.String,
> java.lang.String, java.lang.String) @bci=192, line=388 (Interpreted frame)
>   -
> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
> lang.String,
> java.lang.String) @bci=5, line=411 (Interpreted frame)
>
>
> Thread 7: (state = BLOCKED)
>
>
> Thread 5: (state = BLOCKED)
>   - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
> line=60 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>   - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> g.Object,
> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>   -
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission,
> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>   -
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission)
> @bci=27, line=202 (Interpreted frame)
>   - java.net.NetworkInterface.getHardwareAddress() @bci=18, line=447
> (Interpreted frame)
>   - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116,
> line=158 (Interpreted frame)
>   - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14, line=137
> (Interpreted frame)
>   - java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean)
> @bci=0, line=2526 (Interpreted frame)
>   - java.util.concurrent.ConcurrentHashMap.addCount(long, int) @bci=104,
> line=2266 (Interpreted frame)
>   - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
> java.lang.Object, boolean) @bci=357, line=1070 (Interpreted frame)
>   - java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
> java.lang.Object) @bci=4, line=1535 (Interpreted frame)
>   - java.lang.ClassLoader.getClassLoadingLock(java.lang.String) @bci=23,
> line=463 (Interpreted frame)
>   - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=2,
> line=404 (Interpreted frame)
>   - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=38,
> line=411 (Interpreted frame)
>   - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> boolean) @bci=36, line=308 (Interpreted frame)
>   - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
> (Interpreted frame)
>   -
> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
cliffc.high_scale_lib.NonBlockingHashMap)
> @bci=10, line=1167 (Interpreted frame)
>   - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() @bci=8,
> line=1200 (Interpreted frame)
>   - au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
> @bci=15, line=166 (Interpreted frame)
>   - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4,
> line=511 (Interpreted frame)
>   - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308
> (Interpreted frame)
>   -
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
> eduledFutureTask)
> @bci=1, line=180 (Interpreted frame)
>   -
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> sk.run()
> @bci=37, line=294 (Interpreted frame)
>   -
> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
> rent.ThreadPoolExecutor$Worker)
> @bci=95, line=1142 (Interpreted frame)
>   - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5,
> line=617 (Interpreted frame)
>   - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>
>
> Thread 4: (state = BLOCKED)
>   - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>   - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142
> (Interpreted frame)
>   - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158 (Interpreted
> frame)
>   - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209
> (Interpreted frame)
>
>
> Thread 3: (state = BLOCKED)
>   - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>   - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
>   - java.lang.ref.Reference$ReferenceHandler.run() @bci=36, line=157
> (Interpreted frame)
>
>
> Thread 1: (state = BLOCKED)
>   - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=8,
> line=406 (Interpreted frame)
>   - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> boolean) @bci=36, line=308 (Interpreted frame)
>   - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
> (Interpreted frame)
>   - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
> line=60 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>   - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>   -
> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> g.Object,
> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>   -
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission,
> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>   -
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission)
> @bci=27, line=202 (Interpreted frame)
>   - java.lang.System.checkIO() @bci=18, line=253 (Interpreted frame)
>   - java.lang.System.setErr(java.io.PrintStream) @bci=0, line=199
> (Interpreted frame)
>   - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[]) @bci=9,
> line=84 (Interpreted frame)
>
> The long version:
>
> Attaching to process ID 7124, please wait...
> Debugger attached successfully.
> Client compiler detected.
> JVM version is 25.0-b70
> Deadlock Detection:
>
> Found one Java-level deadlock:
> =============================
>
> "main":
>    waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
> java/lang/Object),
>    which is held by "Thread-1"
> "Thread-1":
>    waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>    which is held by "main"
>
> Found a total of 1 deadlock.
>
> ----------------- 0 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x00e64d7b    java + 0x4d7b
> 0x00e631ca    java + 0x31ca
> 0x00e642ab    java + 0x42ab
> 0x00e63440    java + 0x3440
> 0x00130138        ????????
> ----------------- 1 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
> 0x5bea1b28    jvm + 0x71b28
> 0x01aa1cef    * java.lang.ClassLoader.loadClass(java.lang.String,
> boolean) bci:8 line:406 (Interpreted frame)
> 0x01a94054    *
> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
> bci:36 line:308 (Interpreted frame)
> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
> line:357 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
> 0x5be77d6f    jvm + 0x47d6f
> 0x5be7822a    jvm + 0x4822a
> 0x5be794c0    jvm + 0x494c0
> 0x5be7950a    jvm + 0x4950a
> 0x5bf20de5    jvm!_JVM_FindClassFromClass at 16 + 0x135
> 0x73b515cd    verify + 0x15cd
> 0x73b51d53    verify + 0x1d53
> 0x73b52c67    verify + 0x2c67
> 0x14d6f5e8        ????????
> Locked ownable synchronizers:
>      - None
> ----------------- 2 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
> 0x5bf99671    jvm!JVM_GetThreadStateNames + 0x6d221
> 0x5bf99a32    jvm!JVM_GetThreadStateNames + 0x6d5e2
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> ----------------- 3 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
> 0x01a940f4    * java.lang.Object.wait() bci:2 line:502 (Interpreted frame)
> 0x01a940f4    * java.lang.ref.Reference$ReferenceHandler.run() bci:36
> line:157 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
> 0x5bf1de0f    jvm!jio_printf + 0x9f
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 4 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
> 0x01a940f4    * java.lang.ref.ReferenceQueue.remove(long) bci:44
> line:142 (Interpreted frame)
> 0x01a94054    * java.lang.ref.ReferenceQueue.remove() bci:2 line:158
> (Interpreted frame)
> 0x01a94054    * java.lang.ref.Finalizer$FinalizerThread.run() bci:36
> line:209 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
> 0x5bf1de0f    jvm!jio_printf + 0x9f
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 5 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
> 0x5bee0d10    jvm + 0xb0d10
> 0x5bee2854    jvm + 0xb2854
> 0x5bee3548    jvm + 0xb3548
> 0x5bea5641    jvm + 0x75641
> 0x01aa17be    *
> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
> line:60 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) bci:37 line:128 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) bci:4 line:44 (Interpreted frame)
> 0x01a94089    *
> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
> boolean) bci:7 line:248 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> g.Object,
> java.lang.Object) bci:8 line:67 (Interpreted frame)
> 0x01a94089    *
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission,
> java.lang.Object) bci:161 line:260 (Interpreted frame)
> 0x01a940f4    *
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission)
> bci:27 line:202 (Interpreted frame)
> 0x01a940f4    * java.net.NetworkInterface.getHardwareAddress() bci:18
> line:447 (Interpreted frame)
> 0x01a94054    * java.util.concurrent.ThreadLocalRandom.initialSeed()
> bci:116 line:158 (Interpreted frame)
> 0x01a93e20    * java.util.concurrent.ThreadLocalRandom.<clinit>() bci:14
> line:137 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bee0f44    jvm + 0xb0f44
> 0x5bee2b21    jvm + 0xb2b21
> 0x5bee3548    jvm + 0xb3548
> 0x5bea9796    jvm + 0x79796
> 0x5beaa7b2    jvm + 0x7a7b2
> 0x5bea5dc7    jvm + 0x75dc7
> 0x01aa12ae    *
> java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean) bci:0
> line:2526 (Interpreted frame)
> 0x01a940f4    * java.util.concurrent.ConcurrentHashMap.addCount(long,
> int) bci:104 line:2266 (Interpreted frame)
> 0x01a940f4    *
> java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
> java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
> 0x01a94054    *
> java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
> java.lang.Object) bci:4 line:1535 (Interpreted frame)
> 0x01a94054    *
> java.lang.ClassLoader.getClassLoadingLock(java.lang.String) bci:23
> line:463 (Interpreted frame)
> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
> boolean) bci:2 line:404 (Interpreted frame)
> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
> boolean) bci:38 line:411 (Interpreted frame)
> 0x01a94054    *
> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
> bci:36 line:308 (Interpreted frame)
> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
> line:357 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
> 0x5be77d6f    jvm + 0x47d6f
> 0x5be7822a    jvm + 0x4822a
> 0x5be794c0    jvm + 0x494c0
> 0x5be7950a    jvm + 0x4950a
> 0x5be79f66    jvm + 0x49f66
> 0x5be715c7    jvm + 0x415c7
> 0x5be7a53c    jvm + 0x4a53c
> 0x5be817e2    jvm + 0x517e2
> 0x5be822d9    jvm + 0x522d9
> 0x5be82414    jvm + 0x52414
> 0x5bed85dd    jvm + 0xa85dd
> 0x5bee0d80    jvm + 0xb0d80
> 0x5bee2854    jvm + 0xb2854
> 0x5bee3548    jvm + 0xb3548
> 0x5bea5641    jvm + 0x75641
> 0x01aa17be    *
> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
cliffc.high_scale_lib.NonBlockingHashMap)
> bci:10 line:1167 (Interpreted frame)
> 0x01a940f4    *
> org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8
> line:1200 (Interpreted frame)
> 0x01a94089    *
> au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() bci:15
> line:166 (Interpreted frame)
> 0x01a94129    * java.util.concurrent.Executors$RunnableAdapter.call()
> bci:4 line:511 (Interpreted frame)
> 0x01a94089    * java.util.concurrent.FutureTask.runAndReset() bci:47
> line:308 (Interpreted frame)
> 0x01a93ba0    *
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
> eduledFutureTask)
> bci:1 line:180 (Interpreted frame)
> 0x01a93ba0    *
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> sk.run()
> bci:37 line:294 (Interpreted frame)
> 0x01a94129    *
> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
> rent.ThreadPoolExecutor$Worker)
> bci:95 line:1142 (Interpreted frame)
> 0x01a940f4    * java.util.concurrent.ThreadPoolExecutor$Worker.run()
> bci:5 line:617 (Interpreted frame)
> 0x01a94129    * java.lang.Thread.run() bci:11 line:744 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
> 0x5bf1de0f    jvm!jio_printf + 0x9f
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - <0x03d58650>, (a java/util/concurrent/ThreadPoolExecutor$Worker)
> ----------------- 6 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> ----------------- 7 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd9539    jvm!_JVM_FindSignal at 4 + 0x5269
> 0x5bfd9607    jvm!_JVM_FindSignal at 4 + 0x5337
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 8 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
> 0x5bf7856b    jvm!JVM_GetThreadStateNames + 0x4c11b
> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
> 0x5bee0d10    jvm + 0xb0d10
> 0x5bee2854    jvm + 0xb2854
> 0x5bee3548    jvm + 0xb3548
> 0x5bea5641    jvm + 0x75641
> 0x01aa17be    *
> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
> line:60 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) bci:37 line:128 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> boolean, boolean) bci:4 line:44 (Interpreted frame)
> 0x01a94089    *
> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
> boolean) bci:7 line:248 (Interpreted frame)
> 0x01a94054    *
> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> g.Object,
> java.lang.Object) bci:8 line:67 (Interpreted frame)
> 0x01a94089    *
> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> ion(java.security.Permission,
> java.lang.Object) bci:161 line:260 (Interpreted frame)
> 0x01a940f4    *
> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
> ustPermission(java.lang.Class)
> bci:59 line:1848 (Interpreted frame)
> 0x01a940f4    *
> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
> n(java.lang.Object,
> javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
> 0x01a94089    * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() bci:17
> line:1225 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf299ed    jvm!_JVM_DoPrivileged at 20 + 0x2bd
> 0x73b21047
> java_73b20000!_Java_java_security_AccessController_doPrivileged__L
> java_security_PrivilegedExceptionAction_2 at 12
> + 0x15
> 0x01a94054    * com.sun.jmx.mbeanserver.JmxMBeanServer.initialize()
> bci:25 line:1223 (Interpreted frame)
> 0x01a940f4    *
> com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) bci:133
> line:255 (Interpreted frame)
> 0x01a940f4    *
> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
> boolean) bci:13 line:1437 (Interpreted frame)
> 0x01a94054    *
> javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
> bci:4 line:110 (Interpreted frame)
> 0x01a94054    *
> javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
> bci:36 line:329 (Interpreted frame)
> 0x01a94054    *
> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
> bci:6 line:231 (Interpreted frame)
> 0x01a94054    * javax.management.MBeanServerFactory.createMBeanServer()
> bci:1 line:192 (Interpreted frame)
> 0x01a94054    *
> java.lang.management.ManagementFactory.getPlatformMBeanServer() bci:29
> line:468 (Interpreted frame)
> 0x01a94054    *
> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
> bci:66 line:518 (Interpreted frame)
> 0x01a94054    * sun.management.Agent.startLocalManagementAgent() bci:13
> line:138 (Interpreted frame)
> 0x01a940f4    * sun.management.Agent.startAgent(java.util.Properties)
> bci:76 line:260 (Interpreted frame)
> 0x01a940f4    * sun.management.Agent.agentmain(java.lang.String) bci:45
> line:128 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5bf7e73a    jvm!JVM_GetThreadStateNames + 0x522ea
> 0x5bf7e993    jvm!JVM_GetThreadStateNames + 0x52543
> 0x5bf22b03    jvm!_JVM_InvokeMethod at 16 + 0xb3
> 0x73b23a6e
> java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20 + 0x15
> 0x01a94054    *
> sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
> java.lang.Object[]) bci:100 line:62 (Interpreted frame)
> 0x01a94054    *
> sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
> java.lang.Object[]) bci:6 line:43 (Interpreted frame)
> 0x01a94089    * java.lang.reflect.Method.invoke(java.lang.Object,
> java.lang.Object[]) bci:56 line:483 (Interpreted frame)
> 0x01a94054    *
> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
> g.String,
> java.lang.String, java.lang.String) bci:192 line:388 (Interpreted frame)
> 0x01a940f4    *
> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
> lang.String,
> java.lang.String) bci:5 line:411 (Interpreted frame)
> 0x01a903d7 <StubRoutines>
> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
> 0x5befe951    jvm!JNI_GetCreatedJavaVMs + 0x71a1
> 0x5bf01788    jvm!JNI_GetCreatedJavaVMs + 0x9fd8
> 0x6db62878    instrument!Agent_OnAttach + 0x76b
> 0x6db63eea    instrument!Agent_OnAttach + 0x1ddd
> 0x6db6234a    instrument!Agent_OnAttach + 0x23d
> 0x5bf3c50c    jvm!JVM_GetThreadStateNames + 0x100bc
> 0x5bf9b05e    jvm!JVM_GetThreadStateNames + 0x6ec0e
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 9 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
> 0x5bf7424a    jvm!JVM_GetThreadStateNames + 0x47dfa
> 0x5be9253b    jvm + 0x6253b
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 10 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
> 0x5bf73ec1    jvm!JVM_GetThreadStateNames + 0x47a71
> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
> 0x5bf829a5    jvm!JVM_GetThreadStateNames + 0x56555
> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
> Locked ownable synchronizers:
>      - None
> ----------------- 11 -----------------
> 0x77c870f4    ntdll!KiFastSystemCallRet
> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
> 0x5bf8f904    jvm!JVM_GetThreadStateNames + 0x634b4
> 0x5bf8f9a7    jvm!JVM_GetThreadStateNames + 0x63557
> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
> 0x614dc556    msvcr100!_endthreadex + 0x3a
> 0x614dc600    msvcr100!_endthreadex + 0xe4
> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.levart at gmail.com  Tue Jun 24 10:03:17 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 24 Jun 2014 16:03:17 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>	<53A3FA72.3060706@gmail.com>	<53A418F2.3080201@gmail.com>	<53A43055.5070803@oracle.com>	<53A43EF3.8000206@gmail.com>	<53A44C3A.6000607@oracle.com>	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>
	<CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>
Message-ID: <53A98525.9080908@gmail.com>

Hi Martin,

On 06/22/2014 07:12 PM, Martin Buchholz wrote:
> We know that loading the networking machinery is problematic.  On Linux we
> would be content to hard-code a read from /dev/urandom, which is safer and
> strictly more random than the existing network hardware determination, but
> y'all will reject that as too system-dependent (insufficient machinery!).
> Hmmmm .... maybe not .... as long as we code up a good fallback ...
>
> I learned that SecureRandom by default on Unix uses /dev/random for "seed
> bytes" and /dev/urandom for nextBytes.
>
> Here's my proposal, that in the default case on Unix doesn't load any
> machinery, and as a fallback loads the SecureRandom machinery instead of
> the network machinery, while maintaining the ultra-secure behavior of the
> java.util.secureRandomSeed system property:
>
>
>      private static long initialSeed() {
>          byte[] seedBytes = initialSeedBytes();
>          long s = (long)(seedBytes[0]) & 0xffL;
>          for (int i = 1; i < seedBytes.length; ++i)
>              s = (s << 8) | ((long)(seedBytes[i]) & 0xffL);
>          return s ^ mix64(System.currentTimeMillis()) ^
> mix64(System.nanoTime());
>      }
>
>      private static byte[] initialSeedBytes() {
>          String pp = java.security.AccessController.doPrivileged(
>                  new sun.security.action.GetPropertyAction(
>                          "java.util.secureRandomSeed"));
>          boolean secureRandomSeed = (pp != null &&
> pp.equalsIgnoreCase("true"));
>          if (secureRandomSeed)
>              return java.security.SecureRandom.getSeed(8);
>          final byte[] seedBytes = new byte[8];
>          File seedSource = new File("/dev/urandom");
>          if (seedSource.exists()) {
>              try (FileInputStream stream = new FileInputStream(seedSource)) {
>                  if (stream.read(seedBytes) == 8)
>                      return seedBytes;
>              } catch (IOException ignore) { }
>          }
>          new java.security.SecureRandom().nextBytes(seedBytes);
>          return seedBytes;
>      }

So on platforms lacking "/dev/urandom" special file (Windows only?), the 
fall-back would be to use SecureRandom.nextBytes() whatever default 
SecureRandom PRNG is configured to be on such platform. This might be a 
user-supplied SecureRandom PRNG. The user might want it's own default 
SecureRandom but not use it for TLR's seed computation (unless requested 
by "java.util.secureRandomSeed" system property).

I would rather use SecureRandom.generateSeed() instance method instead 
of SecureRandom.nextBytes(). Why? Because every SecureRandom instance 
has to initialize it's seed 1st before getBytes() can provide the next 
random bytes from the PRNG. Since we only need the 1st 8 bytes from the 
SecureRandom instance to initialize TLR's seeder, we might as well 
directly call the SecureRandom.generateSeed() method. That's one reason. 
The other is the peculiar initialization of default SecureRandom 
algorithm on Windows (see below)...

Even if user does not provide it's own default SecureRandom PRNG, there 
are basically two algorithms that are used by default on OpenJDK:

On Solaris/Linux/Mac/AIX:

the "NativePRNG" algorithm from "SUN" provider (implemented by 
sun.security.provider.NativePRNG) which uses /dev/random for getBytes() 
and /dev/urandom (or whatever is configured with "java.security.egd" or 
"securerandom.source" system properties) for generateSeed(), and

On Windows:

the "SHA1PRNG" algorithm from "SUN" provider (implemented by 
sun.security.provider.SecureRandom) which uses SHA1 message digest for 
generating random numbers with seed computed by gathering system entropy...


The most problematic one is the default on Windows platform (the 
platform that does not have the "/dev/urandom" special file and would be 
used as a fall-back by your proposal) - 
sun.security.provider.SecureRandom. This one seeds itself by 
constructing an instance of itself with the result returned from 
SeedGenerator.getSystemEntropy() method. This method, among other 
things, uses networking code to gather system entropy:

                         ...
                         md.update
(InetAddress.getLocalHost().toString().getBytes());
                         ...

This is problematic since it not only initializes NameService providers 
but also uses them to resolve local host name. This can block for 
several seconds on unusual configurations and was the main motivation to 
replace similar code in TLR with code that uses 
NetworkInterface.getHardwareAddress() instead. Using 
SecureRandom.generateSeed() instead of SecureRandom.getBytes() does not 
invoke SeedGenerator.getSystemEntropy(), but uses just 
SeedGenerator.generateSeed(), which by default on Windows uses 
ThreadedSeedGenerator.getSeedBytes()...

I showed how we could suppress NameService providers initialization 
while still using NetworkInterface.getHardwareAddress() for TLR's seeder 
initialization. If that's not enough and we would like to get-away 
without using networking code at all, then I propose the following:


     private static byte[] initialSeedBytes() {

         String secureRandomSeed = 
java.security.AccessController.doPrivileged(
             new sun.security.action.GetPropertyAction(
                 "java.util.secureRandomSeed", ""))
             .toLowerCase(Locale.ROOT);

         String osName = java.security.AccessController.doPrivileged(
             new sun.security.action.GetPropertyAction(
                 "os.name"))
             .toLowerCase(Locale.ROOT);

         if (!secureRandomSeed.equals("true") && 
!secureRandomSeed.equals("blocking")) {
             secureRandomSeed = "nonblocking"; // default
         }

         SecureRandom srnd = null;

         if (secureRandomSeed.equals("nonblocking")) { // the default
             try {
                 if (osName.startsWith("windows")) {
                     // native implementation using MSCAPI implemented by
                     // sun.security.mscapi.PRNG
                     srnd = SecureRandom.getInstance("Windows-PRNG", 
"SunMSCAPI");
                 } else { // Solaris/Linux/Mac/AIX
                     // a non-blocking native implementation using 
/dev/urandom for both
                     // generateSeed() and nextBytes() implemented by
                     // sun.security.provider.NativePRNG$NonBlocking
                     srnd = 
SecureRandom.getInstance("NativePRNGNonBlocking", "SUN");
                 }
             } catch (NoSuchProviderException | NoSuchAlgorithmException 
ignore) {}
         } else if (secureRandomSeed.equals("blocking")) {
             try {
                 if (osName.startsWith("windows")) {
                     // native implementation using MSCAPI implemented by
                     // sun.security.mscapi.PRNG
                     srnd = SecureRandom.getInstance("Windows-PRNG", 
"SunMSCAPI");
                 } else { // Solaris/Linux/Mac/AIX
                     // a blocking native implementation using 
/dev/random for both
                     // generateSeed() and nextBytes() implemented by
                     // sun.security.provider.NativePRNG$Blocking
                     srnd = 
SecureRandom.getInstance("NativePRNGBlocking", "SUN");
                 }
             } catch (NoSuchProviderException | NoSuchAlgorithmException 
ignore) {}
         } else {
             assert secureRandomSeed.equals("true");
         }

         if (srnd == null) { // fall back to default SecureRandom 
algorithm / provider
             srnd = new SecureRandom();
         }

         return srnd.generateSeed(8);
     }


By default (or when "java.util.secureRandomSeed" is set to "nonblocking" 
or unrecognized value) this would use /dev/urandom on UNIX-es and MSCAPI 
on Windows. More entropy for TLR's initial seeder could be provided on 
UNIX-es by risking some blocking with "java.util.secureRandomSeed" set 
to "blocking". This would still be independend of user's choice of 
default SecureRandom provider. The backward-compatible 
("java.util.secureRandomSeed" set to "true") or fall-back would be to 
use default SecureRandom algorithm / provider.

Regards, Peter

>
>
>
> On Sat, Jun 21, 2014 at 9:05 PM, Martin Buchholz <martinrb at google.com>
> wrote:
>
>> While looking at NativePRNG, I filed
>>
>> https://bugs.openjdk.java.net/browse/JDK-8047769
>>
>> SecureRandom should be more frugal with file descriptors
>>
>> If I run this java program on Linux
>>
>> public class SecureRandoms {
>>      public static void main(String[] args) throws Throwable {
>>          new java.security.SecureRandom();
>>      }
>> }
>>
>> it creates 6 file descriptors for /dev/random and /dev/urandom, as shown
>> by:
>>
>> strace -q -ff -e open java SecureRandoms |& grep /dev/
>> [pid 20769] open("/dev/random", O_RDONLY) = 5
>> [pid 20769] open("/dev/urandom", O_RDONLY) = 6
>> [pid 20769] open("/dev/random", O_RDONLY) = 7
>> [pid 20769] open("/dev/random", O_RDONLY) = 8
>> [pid 20769] open("/dev/urandom", O_RDONLY) = 9
>> [pid 20769] open("/dev/urandom", O_RDONLY) = 10
>>
>> Looking at jdk/src/solaris/classes/sun/security/provider/NativePRNG.java
>> it looks like 2 file descriptors are created for every variant of
>> NativePRNG, whether or not they are ever used. Which is wasteful. In fact,
>> you only ever need at most two file descriptors, one for /dev/random and
>> one for /dev/urandom.
>>
>> Further, it would be nice if the file descriptors were closed when idle
>> and lazily re-created. Especially /dev/random should typically be used at
>> startup and never thereafter.
>>
>>
>> On Fri, Jun 20, 2014 at 7:59 AM, Alan Bateman <Alan.Bateman at oracle.com>
>> wrote:
>>
>>> On 20/06/2014 15:02, Peter Levart wrote:
>>>
>>>> And, as Martin pointed out, it seems to be used for tests that exercise
>>>> particular responses from NameService API to test the behaviour of JDK
>>>> classes. It would be a shame for those tests to go away.
>>>>
>>> We've been talking about removing it for many years because it has been
>>> so troublesome. If we really need to having something for testing then I
>>> don't think it needs to be general purpose, we can get right of the lookup
>>> at least.
>>>
>>> -Alan.
>>>
>>


From peter.levart at gmail.com  Tue Jun 24 10:12:03 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 24 Jun 2014 16:12:03 +0200
Subject: [concurrency-interest] Deadlock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>
Message-ID: <53A98733.4060401@gmail.com>

On 06/24/2014 01:09 PM, David Holmes wrote:
> Hi Peter,
>
> What a strange coincidence - the fact that the initialization of
> ThreadLocalRandom can lead to arbitrary code execution has just been a topic
> of discussion, and it looks like your deadlock is related to that.

Uf, this time it's a combination of a custom SecurityManager being in 
effect when NetworkInterface.getHardwareAddress() is called. It looks 
like we should not use any networking code at all for TLR's initialization.

Regards, Peter

>
> David Holmes
>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
>> Firmstone
>> Sent: Tuesday, 24 June 2014 8:25 PM
>> To: concurrency-interest at cs.oswego.edu
>> Subject: [concurrency-interest] Deadlock
>>
>>
>> This appears to be a ClassLoader deadlock in Java 7.
>>
>> The stack trace from the main thread is missing.
>>
>> Any ideas?
>>
>> Regards,
>>
>> Peter.
>>
>> Attaching to process ID 7124, please wait...
>> Debugger attached successfully.
>> Client compiler detected.
>> JVM version is 25.0-b70
>> Deadlock Detection:
>>
>> Found one Java-level deadlock:
>> =============================
>>
>> "main":
>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>> java/lang/Object),
>>     which is held by "Thread-1"
>> "Thread-1":
>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>     which is held by "main"
>>
>> Found a total of 1 deadlock.
>>
>> Thread 8: (state = BLOCKED)
>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>> line=60 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>> g.Object,
>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>    -
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission,
>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>    -
>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>> ustPermission(java.lang.Class)
>> @bci=59, line=1848 (Interpreted frame)
>>    -
>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>> n(java.lang.Object,
>> javax.management.ObjectName) @bci=25, line=322 (Interpreted frame)
>>    - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17, line=1225
>> (Interpreted frame)
>>    -
>> java.security.AccessController.doPrivileged(java.security.Privileg
>> edExceptionAction)
>> @bci=0 (Interpreted frame)
>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25,
>> line=1223 (Interpreted frame)
>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) @bci=133,
>> line=255 (Interpreted frame)
>>    -
>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>> boolean) @bci=13, line=1437 (Interpreted frame)
>>    - javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>> @bci=4, line=110 (Interpreted frame)
>>    - javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
>> @bci=36, line=329 (Interpreted frame)
>>    -
>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>> @bci=6, line=231 (Interpreted frame)
>>    - javax.management.MBeanServerFactory.createMBeanServer() @bci=1,
>> line=192 (Interpreted frame)
>>    - java.lang.management.ManagementFactory.getPlatformMBeanServer()
>> @bci=29, line=468 (Interpreted frame)
>>    -
>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>> @bci=66, line=518 (Interpreted frame)
>>    - sun.management.Agent.startLocalManagementAgent() @bci=13, line=138
>> (Interpreted frame)
>>    - sun.management.Agent.startAgent(java.util.Properties) @bci=76,
>> line=260 (Interpreted frame)
>>    - sun.management.Agent.agentmain(java.lang.String) @bci=45, line=128
>> (Interpreted frame)
>>    -
>> sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method,
>> java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
>>    - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>> java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
>>    - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>> java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
>>    - java.lang.reflect.Method.invoke(java.lang.Object,
>> java.lang.Object[]) @bci=56, line=483 (Interpreted frame)
>>    -
>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>> g.String,
>> java.lang.String, java.lang.String) @bci=192, line=388 (Interpreted frame)
>>    -
>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>> lang.String,
>> java.lang.String) @bci=5, line=411 (Interpreted frame)
>>
>>
>> Thread 7: (state = BLOCKED)
>>
>>
>> Thread 5: (state = BLOCKED)
>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>> line=60 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>> g.Object,
>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>    -
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission,
>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>    -
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission)
>> @bci=27, line=202 (Interpreted frame)
>>    - java.net.NetworkInterface.getHardwareAddress() @bci=18, line=447
>> (Interpreted frame)
>>    - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116,
>> line=158 (Interpreted frame)
>>    - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14, line=137
>> (Interpreted frame)
>>    - java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean)
>> @bci=0, line=2526 (Interpreted frame)
>>    - java.util.concurrent.ConcurrentHashMap.addCount(long, int) @bci=104,
>> line=2266 (Interpreted frame)
>>    - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>> java.lang.Object, boolean) @bci=357, line=1070 (Interpreted frame)
>>    - java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
>> java.lang.Object) @bci=4, line=1535 (Interpreted frame)
>>    - java.lang.ClassLoader.getClassLoadingLock(java.lang.String) @bci=23,
>> line=463 (Interpreted frame)
>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=2,
>> line=404 (Interpreted frame)
>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=38,
>> line=411 (Interpreted frame)
>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>> boolean) @bci=36, line=308 (Interpreted frame)
>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>> (Interpreted frame)
>>    -
>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
> cliffc.high_scale_lib.NonBlockingHashMap)
>> @bci=10, line=1167 (Interpreted frame)
>>    - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() @bci=8,
>> line=1200 (Interpreted frame)
>>    - au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
>> @bci=15, line=166 (Interpreted frame)
>>    - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4,
>> line=511 (Interpreted frame)
>>    - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308
>> (Interpreted frame)
>>    -
>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>> eduledFutureTask)
>> @bci=1, line=180 (Interpreted frame)
>>    -
>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>> sk.run()
>> @bci=37, line=294 (Interpreted frame)
>>    -
>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>> rent.ThreadPoolExecutor$Worker)
>> @bci=95, line=1142 (Interpreted frame)
>>    - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5,
>> line=617 (Interpreted frame)
>>    - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>>
>>
>> Thread 4: (state = BLOCKED)
>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>    - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142
>> (Interpreted frame)
>>    - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158 (Interpreted
>> frame)
>>    - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209
>> (Interpreted frame)
>>
>>
>> Thread 3: (state = BLOCKED)
>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>    - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
>>    - java.lang.ref.Reference$ReferenceHandler.run() @bci=36, line=157
>> (Interpreted frame)
>>
>>
>> Thread 1: (state = BLOCKED)
>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=8,
>> line=406 (Interpreted frame)
>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>> boolean) @bci=36, line=308 (Interpreted frame)
>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>> (Interpreted frame)
>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>> line=60 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>    -
>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>> g.Object,
>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>    -
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission,
>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>    -
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission)
>> @bci=27, line=202 (Interpreted frame)
>>    - java.lang.System.checkIO() @bci=18, line=253 (Interpreted frame)
>>    - java.lang.System.setErr(java.io.PrintStream) @bci=0, line=199
>> (Interpreted frame)
>>    - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[]) @bci=9,
>> line=84 (Interpreted frame)
>>
>> The long version:
>>
>> Attaching to process ID 7124, please wait...
>> Debugger attached successfully.
>> Client compiler detected.
>> JVM version is 25.0-b70
>> Deadlock Detection:
>>
>> Found one Java-level deadlock:
>> =============================
>>
>> "main":
>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>> java/lang/Object),
>>     which is held by "Thread-1"
>> "Thread-1":
>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>     which is held by "main"
>>
>> Found a total of 1 deadlock.
>>
>> ----------------- 0 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x00e64d7b    java + 0x4d7b
>> 0x00e631ca    java + 0x31ca
>> 0x00e642ab    java + 0x42ab
>> 0x00e63440    java + 0x3440
>> 0x00130138        ????????
>> ----------------- 1 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>> 0x5bea1b28    jvm + 0x71b28
>> 0x01aa1cef    * java.lang.ClassLoader.loadClass(java.lang.String,
>> boolean) bci:8 line:406 (Interpreted frame)
>> 0x01a94054    *
>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>> bci:36 line:308 (Interpreted frame)
>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>> line:357 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>> 0x5be77d6f    jvm + 0x47d6f
>> 0x5be7822a    jvm + 0x4822a
>> 0x5be794c0    jvm + 0x494c0
>> 0x5be7950a    jvm + 0x4950a
>> 0x5bf20de5    jvm!_JVM_FindClassFromClass at 16 + 0x135
>> 0x73b515cd    verify + 0x15cd
>> 0x73b51d53    verify + 0x1d53
>> 0x73b52c67    verify + 0x2c67
>> 0x14d6f5e8        ????????
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 2 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>> 0x5bf99671    jvm!JVM_GetThreadStateNames + 0x6d221
>> 0x5bf99a32    jvm!JVM_GetThreadStateNames + 0x6d5e2
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> ----------------- 3 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>> 0x01a940f4    * java.lang.Object.wait() bci:2 line:502 (Interpreted frame)
>> 0x01a940f4    * java.lang.ref.Reference$ReferenceHandler.run() bci:36
>> line:157 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 4 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>> 0x01a940f4    * java.lang.ref.ReferenceQueue.remove(long) bci:44
>> line:142 (Interpreted frame)
>> 0x01a94054    * java.lang.ref.ReferenceQueue.remove() bci:2 line:158
>> (Interpreted frame)
>> 0x01a94054    * java.lang.ref.Finalizer$FinalizerThread.run() bci:36
>> line:209 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 5 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>> 0x5bee0d10    jvm + 0xb0d10
>> 0x5bee2854    jvm + 0xb2854
>> 0x5bee3548    jvm + 0xb3548
>> 0x5bea5641    jvm + 0x75641
>> 0x01aa17be    *
>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>> line:60 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>> 0x01a94089    *
>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>> boolean) bci:7 line:248 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>> g.Object,
>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>> 0x01a94089    *
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission,
>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>> 0x01a940f4    *
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission)
>> bci:27 line:202 (Interpreted frame)
>> 0x01a940f4    * java.net.NetworkInterface.getHardwareAddress() bci:18
>> line:447 (Interpreted frame)
>> 0x01a94054    * java.util.concurrent.ThreadLocalRandom.initialSeed()
>> bci:116 line:158 (Interpreted frame)
>> 0x01a93e20    * java.util.concurrent.ThreadLocalRandom.<clinit>() bci:14
>> line:137 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bee0f44    jvm + 0xb0f44
>> 0x5bee2b21    jvm + 0xb2b21
>> 0x5bee3548    jvm + 0xb3548
>> 0x5bea9796    jvm + 0x79796
>> 0x5beaa7b2    jvm + 0x7a7b2
>> 0x5bea5dc7    jvm + 0x75dc7
>> 0x01aa12ae    *
>> java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean) bci:0
>> line:2526 (Interpreted frame)
>> 0x01a940f4    * java.util.concurrent.ConcurrentHashMap.addCount(long,
>> int) bci:104 line:2266 (Interpreted frame)
>> 0x01a940f4    *
>> java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>> java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
>> 0x01a94054    *
>> java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
>> java.lang.Object) bci:4 line:1535 (Interpreted frame)
>> 0x01a94054    *
>> java.lang.ClassLoader.getClassLoadingLock(java.lang.String) bci:23
>> line:463 (Interpreted frame)
>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>> boolean) bci:2 line:404 (Interpreted frame)
>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>> boolean) bci:38 line:411 (Interpreted frame)
>> 0x01a94054    *
>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>> bci:36 line:308 (Interpreted frame)
>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>> line:357 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>> 0x5be77d6f    jvm + 0x47d6f
>> 0x5be7822a    jvm + 0x4822a
>> 0x5be794c0    jvm + 0x494c0
>> 0x5be7950a    jvm + 0x4950a
>> 0x5be79f66    jvm + 0x49f66
>> 0x5be715c7    jvm + 0x415c7
>> 0x5be7a53c    jvm + 0x4a53c
>> 0x5be817e2    jvm + 0x517e2
>> 0x5be822d9    jvm + 0x522d9
>> 0x5be82414    jvm + 0x52414
>> 0x5bed85dd    jvm + 0xa85dd
>> 0x5bee0d80    jvm + 0xb0d80
>> 0x5bee2854    jvm + 0xb2854
>> 0x5bee3548    jvm + 0xb3548
>> 0x5bea5641    jvm + 0x75641
>> 0x01aa17be    *
>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
> cliffc.high_scale_lib.NonBlockingHashMap)
>> bci:10 line:1167 (Interpreted frame)
>> 0x01a940f4    *
>> org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8
>> line:1200 (Interpreted frame)
>> 0x01a94089    *
>> au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() bci:15
>> line:166 (Interpreted frame)
>> 0x01a94129    * java.util.concurrent.Executors$RunnableAdapter.call()
>> bci:4 line:511 (Interpreted frame)
>> 0x01a94089    * java.util.concurrent.FutureTask.runAndReset() bci:47
>> line:308 (Interpreted frame)
>> 0x01a93ba0    *
>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>> eduledFutureTask)
>> bci:1 line:180 (Interpreted frame)
>> 0x01a93ba0    *
>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>> sk.run()
>> bci:37 line:294 (Interpreted frame)
>> 0x01a94129    *
>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>> rent.ThreadPoolExecutor$Worker)
>> bci:95 line:1142 (Interpreted frame)
>> 0x01a940f4    * java.util.concurrent.ThreadPoolExecutor$Worker.run()
>> bci:5 line:617 (Interpreted frame)
>> 0x01a94129    * java.lang.Thread.run() bci:11 line:744 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - <0x03d58650>, (a java/util/concurrent/ThreadPoolExecutor$Worker)
>> ----------------- 6 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> ----------------- 7 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd9539    jvm!_JVM_FindSignal at 4 + 0x5269
>> 0x5bfd9607    jvm!_JVM_FindSignal at 4 + 0x5337
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 8 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>> 0x5bf7856b    jvm!JVM_GetThreadStateNames + 0x4c11b
>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>> 0x5bee0d10    jvm + 0xb0d10
>> 0x5bee2854    jvm + 0xb2854
>> 0x5bee3548    jvm + 0xb3548
>> 0x5bea5641    jvm + 0x75641
>> 0x01aa17be    *
>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>> line:60 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>> 0x01a94089    *
>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>> boolean) bci:7 line:248 (Interpreted frame)
>> 0x01a94054    *
>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>> g.Object,
>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>> 0x01a94089    *
>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>> ion(java.security.Permission,
>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>> 0x01a940f4    *
>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>> ustPermission(java.lang.Class)
>> bci:59 line:1848 (Interpreted frame)
>> 0x01a940f4    *
>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>> n(java.lang.Object,
>> javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
>> 0x01a94089    * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() bci:17
>> line:1225 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf299ed    jvm!_JVM_DoPrivileged at 20 + 0x2bd
>> 0x73b21047
>> java_73b20000!_Java_java_security_AccessController_doPrivileged__L
>> java_security_PrivilegedExceptionAction_2 at 12
>> + 0x15
>> 0x01a94054    * com.sun.jmx.mbeanserver.JmxMBeanServer.initialize()
>> bci:25 line:1223 (Interpreted frame)
>> 0x01a940f4    *
>> com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) bci:133
>> line:255 (Interpreted frame)
>> 0x01a940f4    *
>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>> boolean) bci:13 line:1437 (Interpreted frame)
>> 0x01a94054    *
>> javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>> bci:4 line:110 (Interpreted frame)
>> 0x01a94054    *
>> javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
>> bci:36 line:329 (Interpreted frame)
>> 0x01a94054    *
>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>> bci:6 line:231 (Interpreted frame)
>> 0x01a94054    * javax.management.MBeanServerFactory.createMBeanServer()
>> bci:1 line:192 (Interpreted frame)
>> 0x01a94054    *
>> java.lang.management.ManagementFactory.getPlatformMBeanServer() bci:29
>> line:468 (Interpreted frame)
>> 0x01a94054    *
>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>> bci:66 line:518 (Interpreted frame)
>> 0x01a94054    * sun.management.Agent.startLocalManagementAgent() bci:13
>> line:138 (Interpreted frame)
>> 0x01a940f4    * sun.management.Agent.startAgent(java.util.Properties)
>> bci:76 line:260 (Interpreted frame)
>> 0x01a940f4    * sun.management.Agent.agentmain(java.lang.String) bci:45
>> line:128 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5bf7e73a    jvm!JVM_GetThreadStateNames + 0x522ea
>> 0x5bf7e993    jvm!JVM_GetThreadStateNames + 0x52543
>> 0x5bf22b03    jvm!_JVM_InvokeMethod at 16 + 0xb3
>> 0x73b23a6e
>> java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20 + 0x15
>> 0x01a94054    *
>> sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>> java.lang.Object[]) bci:100 line:62 (Interpreted frame)
>> 0x01a94054    *
>> sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>> java.lang.Object[]) bci:6 line:43 (Interpreted frame)
>> 0x01a94089    * java.lang.reflect.Method.invoke(java.lang.Object,
>> java.lang.Object[]) bci:56 line:483 (Interpreted frame)
>> 0x01a94054    *
>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>> g.String,
>> java.lang.String, java.lang.String) bci:192 line:388 (Interpreted frame)
>> 0x01a940f4    *
>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>> lang.String,
>> java.lang.String) bci:5 line:411 (Interpreted frame)
>> 0x01a903d7 <StubRoutines>
>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>> 0x5befe951    jvm!JNI_GetCreatedJavaVMs + 0x71a1
>> 0x5bf01788    jvm!JNI_GetCreatedJavaVMs + 0x9fd8
>> 0x6db62878    instrument!Agent_OnAttach + 0x76b
>> 0x6db63eea    instrument!Agent_OnAttach + 0x1ddd
>> 0x6db6234a    instrument!Agent_OnAttach + 0x23d
>> 0x5bf3c50c    jvm!JVM_GetThreadStateNames + 0x100bc
>> 0x5bf9b05e    jvm!JVM_GetThreadStateNames + 0x6ec0e
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 9 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>> 0x5bf7424a    jvm!JVM_GetThreadStateNames + 0x47dfa
>> 0x5be9253b    jvm + 0x6253b
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 10 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>> 0x5bf73ec1    jvm!JVM_GetThreadStateNames + 0x47a71
>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>> 0x5bf829a5    jvm!JVM_GetThreadStateNames + 0x56555
>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>> Locked ownable synchronizers:
>>       - None
>> ----------------- 11 -----------------
>> 0x77c870f4    ntdll!KiFastSystemCallRet
>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>> 0x5bf8f904    jvm!JVM_GetThreadStateNames + 0x634b4
>> 0x5bf8f9a7    jvm!JVM_GetThreadStateNames + 0x63557
>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.levart at gmail.com  Tue Jun 24 10:21:46 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 24 Jun 2014 16:21:46 +0200
Subject: [concurrency-interest] Deadlock
In-Reply-To: <53A98733.4060401@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>
	<53A98733.4060401@gmail.com>
Message-ID: <53A9897A.7010803@gmail.com>

On 06/24/2014 04:12 PM, Peter Levart wrote:
> On 06/24/2014 01:09 PM, David Holmes wrote:
>> Hi Peter,
>>
>> What a strange coincidence - the fact that the initialization of
>> ThreadLocalRandom can lead to arbitrary code execution has just been 
>> a topic
>> of discussion, and it looks like your deadlock is related to that.
>
> Uf, this time it's a combination of a custom SecurityManager being in 
> effect when NetworkInterface.getHardwareAddress() is called. It looks 
> like we should not use any networking code at all for TLR's 
> initialization.

Or make NetworkInterface.getHardwareAddress() a @CallerSensitive method 
and avoid SecurityManager invocation when called from one of system 
classes. That's still an alternative.

Peter

>
> Regards, Peter
>
>>
>> David Holmes
>>
>>> -----Original Message-----
>>> From: concurrency-interest-bounces at cs.oswego.edu
>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
>>> Firmstone
>>> Sent: Tuesday, 24 June 2014 8:25 PM
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: [concurrency-interest] Deadlock
>>>
>>>
>>> This appears to be a ClassLoader deadlock in Java 7.
>>>
>>> The stack trace from the main thread is missing.
>>>
>>> Any ideas?
>>>
>>> Regards,
>>>
>>> Peter.
>>>
>>> Attaching to process ID 7124, please wait...
>>> Debugger attached successfully.
>>> Client compiler detected.
>>> JVM version is 25.0-b70
>>> Deadlock Detection:
>>>
>>> Found one Java-level deadlock:
>>> =============================
>>>
>>> "main":
>>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>>> java/lang/Object),
>>>     which is held by "Thread-1"
>>> "Thread-1":
>>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>>     which is held by "main"
>>>
>>> Found a total of 1 deadlock.
>>>
>>> Thread 8: (state = BLOCKED)
>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>> line=60 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>> g.Object,
>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>    -
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission,
>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>    -
>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>>> ustPermission(java.lang.Class)
>>> @bci=59, line=1848 (Interpreted frame)
>>>    -
>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>>> n(java.lang.Object,
>>> javax.management.ObjectName) @bci=25, line=322 (Interpreted frame)
>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17, line=1225
>>> (Interpreted frame)
>>>    -
>>> java.security.AccessController.doPrivileged(java.security.Privileg
>>> edExceptionAction)
>>> @bci=0 (Interpreted frame)
>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25,
>>> line=1223 (Interpreted frame)
>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) @bci=133,
>>> line=255 (Interpreted frame)
>>>    -
>>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>> boolean) @bci=13, line=1437 (Interpreted frame)
>>>    - 
>>> javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>>> @bci=4, line=110 (Interpreted frame)
>>>    - 
>>> javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
>>> @bci=36, line=329 (Interpreted frame)
>>>    -
>>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>>> @bci=6, line=231 (Interpreted frame)
>>>    - javax.management.MBeanServerFactory.createMBeanServer() @bci=1,
>>> line=192 (Interpreted frame)
>>>    - java.lang.management.ManagementFactory.getPlatformMBeanServer()
>>> @bci=29, line=468 (Interpreted frame)
>>>    -
>>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>>> @bci=66, line=518 (Interpreted frame)
>>>    - sun.management.Agent.startLocalManagementAgent() @bci=13, line=138
>>> (Interpreted frame)
>>>    - sun.management.Agent.startAgent(java.util.Properties) @bci=76,
>>> line=260 (Interpreted frame)
>>>    - sun.management.Agent.agentmain(java.lang.String) @bci=45, line=128
>>> (Interpreted frame)
>>>    -
>>> sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method,
>>> java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
>>>    - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>>> java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
>>>    - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>>> java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
>>>    - java.lang.reflect.Method.invoke(java.lang.Object,
>>> java.lang.Object[]) @bci=56, line=483 (Interpreted frame)
>>>    -
>>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>>> g.String,
>>> java.lang.String, java.lang.String) @bci=192, line=388 (Interpreted 
>>> frame)
>>>    -
>>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>>> lang.String,
>>> java.lang.String) @bci=5, line=411 (Interpreted frame)
>>>
>>>
>>> Thread 7: (state = BLOCKED)
>>>
>>>
>>> Thread 5: (state = BLOCKED)
>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>> line=60 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>> g.Object,
>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>    -
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission,
>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>    -
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission)
>>> @bci=27, line=202 (Interpreted frame)
>>>    - java.net.NetworkInterface.getHardwareAddress() @bci=18, line=447
>>> (Interpreted frame)
>>>    - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116,
>>> line=158 (Interpreted frame)
>>>    - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14, 
>>> line=137
>>> (Interpreted frame)
>>>    - java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean)
>>> @bci=0, line=2526 (Interpreted frame)
>>>    - java.util.concurrent.ConcurrentHashMap.addCount(long, int) 
>>> @bci=104,
>>> line=2266 (Interpreted frame)
>>>    - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>>> java.lang.Object, boolean) @bci=357, line=1070 (Interpreted frame)
>>>    - 
>>> java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
>>> java.lang.Object) @bci=4, line=1535 (Interpreted frame)
>>>    - java.lang.ClassLoader.getClassLoadingLock(java.lang.String) 
>>> @bci=23,
>>> line=463 (Interpreted frame)
>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=2,
>>> line=404 (Interpreted frame)
>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) 
>>> @bci=38,
>>> line=411 (Interpreted frame)
>>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>>> boolean) @bci=36, line=308 (Interpreted frame)
>>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>>> (Interpreted frame)
>>>    -
>>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
>> cliffc.high_scale_lib.NonBlockingHashMap)
>>> @bci=10, line=1167 (Interpreted frame)
>>>    - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() @bci=8,
>>> line=1200 (Interpreted frame)
>>>    - au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
>>> @bci=15, line=166 (Interpreted frame)
>>>    - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4,
>>> line=511 (Interpreted frame)
>>>    - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308
>>> (Interpreted frame)
>>>    -
>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>>> eduledFutureTask)
>>> @bci=1, line=180 (Interpreted frame)
>>>    -
>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>> sk.run()
>>> @bci=37, line=294 (Interpreted frame)
>>>    -
>>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>>> rent.ThreadPoolExecutor$Worker)
>>> @bci=95, line=1142 (Interpreted frame)
>>>    - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5,
>>> line=617 (Interpreted frame)
>>>    - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>>>
>>>
>>> Thread 4: (state = BLOCKED)
>>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>>    - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142
>>> (Interpreted frame)
>>>    - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158 
>>> (Interpreted
>>> frame)
>>>    - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209
>>> (Interpreted frame)
>>>
>>>
>>> Thread 3: (state = BLOCKED)
>>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>>    - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
>>>    - java.lang.ref.Reference$ReferenceHandler.run() @bci=36, line=157
>>> (Interpreted frame)
>>>
>>>
>>> Thread 1: (state = BLOCKED)
>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=8,
>>> line=406 (Interpreted frame)
>>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>>> boolean) @bci=36, line=308 (Interpreted frame)
>>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>>> (Interpreted frame)
>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>> line=60 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>    -
>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>> g.Object,
>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>    -
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission,
>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>    -
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission)
>>> @bci=27, line=202 (Interpreted frame)
>>>    - java.lang.System.checkIO() @bci=18, line=253 (Interpreted frame)
>>>    - java.lang.System.setErr(java.io.PrintStream) @bci=0, line=199
>>> (Interpreted frame)
>>>    - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[]) 
>>> @bci=9,
>>> line=84 (Interpreted frame)
>>>
>>> The long version:
>>>
>>> Attaching to process ID 7124, please wait...
>>> Debugger attached successfully.
>>> Client compiler detected.
>>> JVM version is 25.0-b70
>>> Deadlock Detection:
>>>
>>> Found one Java-level deadlock:
>>> =============================
>>>
>>> "main":
>>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>>> java/lang/Object),
>>>     which is held by "Thread-1"
>>> "Thread-1":
>>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>>     which is held by "main"
>>>
>>> Found a total of 1 deadlock.
>>>
>>> ----------------- 0 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x00e64d7b    java + 0x4d7b
>>> 0x00e631ca    java + 0x31ca
>>> 0x00e642ab    java + 0x42ab
>>> 0x00e63440    java + 0x3440
>>> 0x00130138        ????????
>>> ----------------- 1 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>> 0x5bea1b28    jvm + 0x71b28
>>> 0x01aa1cef    * java.lang.ClassLoader.loadClass(java.lang.String,
>>> boolean) bci:8 line:406 (Interpreted frame)
>>> 0x01a94054    *
>>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>>> bci:36 line:308 (Interpreted frame)
>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>>> line:357 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>>> 0x5be77d6f    jvm + 0x47d6f
>>> 0x5be7822a    jvm + 0x4822a
>>> 0x5be794c0    jvm + 0x494c0
>>> 0x5be7950a    jvm + 0x4950a
>>> 0x5bf20de5    jvm!_JVM_FindClassFromClass at 16 + 0x135
>>> 0x73b515cd    verify + 0x15cd
>>> 0x73b51d53    verify + 0x1d53
>>> 0x73b52c67    verify + 0x2c67
>>> 0x14d6f5e8        ????????
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 2 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>> 0x5bf99671    jvm!JVM_GetThreadStateNames + 0x6d221
>>> 0x5bf99a32    jvm!JVM_GetThreadStateNames + 0x6d5e2
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> ----------------- 3 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>>> 0x01a940f4    * java.lang.Object.wait() bci:2 line:502 (Interpreted 
>>> frame)
>>> 0x01a940f4    * java.lang.ref.Reference$ReferenceHandler.run() bci:36
>>> line:157 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 4 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>>> 0x01a940f4    * java.lang.ref.ReferenceQueue.remove(long) bci:44
>>> line:142 (Interpreted frame)
>>> 0x01a94054    * java.lang.ref.ReferenceQueue.remove() bci:2 line:158
>>> (Interpreted frame)
>>> 0x01a94054    * java.lang.ref.Finalizer$FinalizerThread.run() bci:36
>>> line:209 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 5 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>>> 0x5bee0d10    jvm + 0xb0d10
>>> 0x5bee2854    jvm + 0xb2854
>>> 0x5bee3548    jvm + 0xb3548
>>> 0x5bea5641    jvm + 0x75641
>>> 0x01aa17be    *
>>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>>> line:60 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>>> 0x01a94089    *
>>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>>> boolean) bci:7 line:248 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>> g.Object,
>>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>>> 0x01a94089    *
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission,
>>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>>> 0x01a940f4    *
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission)
>>> bci:27 line:202 (Interpreted frame)
>>> 0x01a940f4    * java.net.NetworkInterface.getHardwareAddress() bci:18
>>> line:447 (Interpreted frame)
>>> 0x01a94054    * java.util.concurrent.ThreadLocalRandom.initialSeed()
>>> bci:116 line:158 (Interpreted frame)
>>> 0x01a93e20    * java.util.concurrent.ThreadLocalRandom.<clinit>() 
>>> bci:14
>>> line:137 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bee0f44    jvm + 0xb0f44
>>> 0x5bee2b21    jvm + 0xb2b21
>>> 0x5bee3548    jvm + 0xb3548
>>> 0x5bea9796    jvm + 0x79796
>>> 0x5beaa7b2    jvm + 0x7a7b2
>>> 0x5bea5dc7    jvm + 0x75dc7
>>> 0x01aa12ae    *
>>> java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean) 
>>> bci:0
>>> line:2526 (Interpreted frame)
>>> 0x01a940f4    * java.util.concurrent.ConcurrentHashMap.addCount(long,
>>> int) bci:104 line:2266 (Interpreted frame)
>>> 0x01a940f4    *
>>> java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>>> java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
>>> 0x01a94054    *
>>> java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
>>> java.lang.Object) bci:4 line:1535 (Interpreted frame)
>>> 0x01a94054    *
>>> java.lang.ClassLoader.getClassLoadingLock(java.lang.String) bci:23
>>> line:463 (Interpreted frame)
>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>>> boolean) bci:2 line:404 (Interpreted frame)
>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>>> boolean) bci:38 line:411 (Interpreted frame)
>>> 0x01a94054    *
>>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>>> bci:36 line:308 (Interpreted frame)
>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>>> line:357 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>>> 0x5be77d6f    jvm + 0x47d6f
>>> 0x5be7822a    jvm + 0x4822a
>>> 0x5be794c0    jvm + 0x494c0
>>> 0x5be7950a    jvm + 0x4950a
>>> 0x5be79f66    jvm + 0x49f66
>>> 0x5be715c7    jvm + 0x415c7
>>> 0x5be7a53c    jvm + 0x4a53c
>>> 0x5be817e2    jvm + 0x517e2
>>> 0x5be822d9    jvm + 0x522d9
>>> 0x5be82414    jvm + 0x52414
>>> 0x5bed85dd    jvm + 0xa85dd
>>> 0x5bee0d80    jvm + 0xb0d80
>>> 0x5bee2854    jvm + 0xb2854
>>> 0x5bee3548    jvm + 0xb3548
>>> 0x5bea5641    jvm + 0x75641
>>> 0x01aa17be    *
>>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
>> cliffc.high_scale_lib.NonBlockingHashMap)
>>> bci:10 line:1167 (Interpreted frame)
>>> 0x01a940f4    *
>>> org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8
>>> line:1200 (Interpreted frame)
>>> 0x01a94089    *
>>> au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() bci:15
>>> line:166 (Interpreted frame)
>>> 0x01a94129    * java.util.concurrent.Executors$RunnableAdapter.call()
>>> bci:4 line:511 (Interpreted frame)
>>> 0x01a94089    * java.util.concurrent.FutureTask.runAndReset() bci:47
>>> line:308 (Interpreted frame)
>>> 0x01a93ba0    *
>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>>> eduledFutureTask)
>>> bci:1 line:180 (Interpreted frame)
>>> 0x01a93ba0    *
>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>> sk.run()
>>> bci:37 line:294 (Interpreted frame)
>>> 0x01a94129    *
>>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>>> rent.ThreadPoolExecutor$Worker)
>>> bci:95 line:1142 (Interpreted frame)
>>> 0x01a940f4    * java.util.concurrent.ThreadPoolExecutor$Worker.run()
>>> bci:5 line:617 (Interpreted frame)
>>> 0x01a94129    * java.lang.Thread.run() bci:11 line:744 (Interpreted 
>>> frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - <0x03d58650>, (a 
>>> java/util/concurrent/ThreadPoolExecutor$Worker)
>>> ----------------- 6 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> ----------------- 7 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd9539    jvm!_JVM_FindSignal at 4 + 0x5269
>>> 0x5bfd9607    jvm!_JVM_FindSignal at 4 + 0x5337
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 8 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>> 0x5bf7856b    jvm!JVM_GetThreadStateNames + 0x4c11b
>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>>> 0x5bee0d10    jvm + 0xb0d10
>>> 0x5bee2854    jvm + 0xb2854
>>> 0x5bee3548    jvm + 0xb3548
>>> 0x5bea5641    jvm + 0x75641
>>> 0x01aa17be    *
>>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>>> line:60 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>>> 0x01a94089    *
>>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>>> boolean) bci:7 line:248 (Interpreted frame)
>>> 0x01a94054    *
>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>> g.Object,
>>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>>> 0x01a94089    *
>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>> ion(java.security.Permission,
>>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>>> 0x01a940f4    *
>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>>> ustPermission(java.lang.Class)
>>> bci:59 line:1848 (Interpreted frame)
>>> 0x01a940f4    *
>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>>> n(java.lang.Object,
>>> javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
>>> 0x01a94089    * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() bci:17
>>> line:1225 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf299ed    jvm!_JVM_DoPrivileged at 20 + 0x2bd
>>> 0x73b21047
>>> java_73b20000!_Java_java_security_AccessController_doPrivileged__L
>>> java_security_PrivilegedExceptionAction_2 at 12
>>> + 0x15
>>> 0x01a94054    * com.sun.jmx.mbeanserver.JmxMBeanServer.initialize()
>>> bci:25 line:1223 (Interpreted frame)
>>> 0x01a940f4    *
>>> com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) bci:133
>>> line:255 (Interpreted frame)
>>> 0x01a940f4    *
>>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>> boolean) bci:13 line:1437 (Interpreted frame)
>>> 0x01a94054    *
>>> javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>>> bci:4 line:110 (Interpreted frame)
>>> 0x01a94054    *
>>> javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
>>> bci:36 line:329 (Interpreted frame)
>>> 0x01a94054    *
>>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>>> bci:6 line:231 (Interpreted frame)
>>> 0x01a94054    * javax.management.MBeanServerFactory.createMBeanServer()
>>> bci:1 line:192 (Interpreted frame)
>>> 0x01a94054    *
>>> java.lang.management.ManagementFactory.getPlatformMBeanServer() bci:29
>>> line:468 (Interpreted frame)
>>> 0x01a94054    *
>>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>>> bci:66 line:518 (Interpreted frame)
>>> 0x01a94054    * sun.management.Agent.startLocalManagementAgent() bci:13
>>> line:138 (Interpreted frame)
>>> 0x01a940f4    * sun.management.Agent.startAgent(java.util.Properties)
>>> bci:76 line:260 (Interpreted frame)
>>> 0x01a940f4    * sun.management.Agent.agentmain(java.lang.String) bci:45
>>> line:128 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5bf7e73a    jvm!JVM_GetThreadStateNames + 0x522ea
>>> 0x5bf7e993    jvm!JVM_GetThreadStateNames + 0x52543
>>> 0x5bf22b03    jvm!_JVM_InvokeMethod at 16 + 0xb3
>>> 0x73b23a6e
>>> java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20 
>>> + 0x15
>>> 0x01a94054    *
>>> sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>>> java.lang.Object[]) bci:100 line:62 (Interpreted frame)
>>> 0x01a94054    *
>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>>> java.lang.Object[]) bci:6 line:43 (Interpreted frame)
>>> 0x01a94089    * java.lang.reflect.Method.invoke(java.lang.Object,
>>> java.lang.Object[]) bci:56 line:483 (Interpreted frame)
>>> 0x01a94054    *
>>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>>> g.String,
>>> java.lang.String, java.lang.String) bci:192 line:388 (Interpreted 
>>> frame)
>>> 0x01a940f4    *
>>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>>> lang.String,
>>> java.lang.String) bci:5 line:411 (Interpreted frame)
>>> 0x01a903d7 <StubRoutines>
>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>> 0x5befe951    jvm!JNI_GetCreatedJavaVMs + 0x71a1
>>> 0x5bf01788    jvm!JNI_GetCreatedJavaVMs + 0x9fd8
>>> 0x6db62878    instrument!Agent_OnAttach + 0x76b
>>> 0x6db63eea    instrument!Agent_OnAttach + 0x1ddd
>>> 0x6db6234a    instrument!Agent_OnAttach + 0x23d
>>> 0x5bf3c50c    jvm!JVM_GetThreadStateNames + 0x100bc
>>> 0x5bf9b05e    jvm!JVM_GetThreadStateNames + 0x6ec0e
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 9 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>> 0x5bf7424a    jvm!JVM_GetThreadStateNames + 0x47dfa
>>> 0x5be9253b    jvm + 0x6253b
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 10 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>> 0x5bf73ec1    jvm!JVM_GetThreadStateNames + 0x47a71
>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>> 0x5bf829a5    jvm!JVM_GetThreadStateNames + 0x56555
>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>> Locked ownable synchronizers:
>>>       - None
>>> ----------------- 11 -----------------
>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>> 0x5bf8f904    jvm!JVM_GetThreadStateNames + 0x634b4
>>> 0x5bf8f9a7    jvm!JVM_GetThreadStateNames + 0x63557
>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From martinrb at google.com  Tue Jun 24 11:40:18 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 24 Jun 2014 08:40:18 -0700
Subject: [concurrency-interest] Deadlock
In-Reply-To: <53A9897A.7010803@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>
	<53A98733.4060401@gmail.com> <53A9897A.7010803@gmail.com>
Message-ID: <CA+kOe09-9AhEXS_AQSe8uEC6ApYKiD4MWteEOoWZpU4HpdP-SA@mail.gmail.com>

[+openjdk mailing lists]


Yeah, I'm trying to excise all the networking code from TLR and
SplittableRandom.

There is also likely to be a missing wrapping in doPrivileged.


On Tue, Jun 24, 2014 at 7:21 AM, Peter Levart <peter.levart at gmail.com>
wrote:

> On 06/24/2014 04:12 PM, Peter Levart wrote:
>
>> On 06/24/2014 01:09 PM, David Holmes wrote:
>>
>>> Hi Peter,
>>>
>>> What a strange coincidence - the fact that the initialization of
>>> ThreadLocalRandom can lead to arbitrary code execution has just been a
>>> topic
>>> of discussion, and it looks like your deadlock is related to that.
>>>
>>
>> Uf, this time it's a combination of a custom SecurityManager being in
>> effect when NetworkInterface.getHardwareAddress() is called. It looks
>> like we should not use any networking code at all for TLR's initialization.
>>
>
> Or make NetworkInterface.getHardwareAddress() a @CallerSensitive method
> and avoid SecurityManager invocation when called from one of system
> classes. That's still an alternative.
>
> Peter
>
>
>
>> Regards, Peter
>>
>>
>>> David Holmes
>>>
>>>  -----Original Message-----
>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
>>>> Firmstone
>>>> Sent: Tuesday, 24 June 2014 8:25 PM
>>>> To: concurrency-interest at cs.oswego.edu
>>>> Subject: [concurrency-interest] Deadlock
>>>>
>>>>
>>>> This appears to be a ClassLoader deadlock in Java 7.
>>>>
>>>> The stack trace from the main thread is missing.
>>>>
>>>> Any ideas?
>>>>
>>>> Regards,
>>>>
>>>> Peter.
>>>>
>>>> Attaching to process ID 7124, please wait...
>>>> Debugger attached successfully.
>>>> Client compiler detected.
>>>> JVM version is 25.0-b70
>>>> Deadlock Detection:
>>>>
>>>> Found one Java-level deadlock:
>>>> =============================
>>>>
>>>> "main":
>>>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>>>> java/lang/Object),
>>>>     which is held by "Thread-1"
>>>> "Thread-1":
>>>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>>>     which is held by "main"
>>>>
>>>> Found a total of 1 deadlock.
>>>>
>>>> Thread 8: (state = BLOCKED)
>>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>>> line=60 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>>> g.Object,
>>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>>    -
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission,
>>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>>    -
>>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>>>> ustPermission(java.lang.Class)
>>>> @bci=59, line=1848 (Interpreted frame)
>>>>    -
>>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>>>> n(java.lang.Object,
>>>> javax.management.ObjectName) @bci=25, line=322 (Interpreted frame)
>>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17, line=1225
>>>> (Interpreted frame)
>>>>    -
>>>> java.security.AccessController.doPrivileged(java.security.Privileg
>>>> edExceptionAction)
>>>> @bci=0 (Interpreted frame)
>>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25,
>>>> line=1223 (Interpreted frame)
>>>>    - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) @bci=133,
>>>> line=255 (Interpreted frame)
>>>>    -
>>>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>>> boolean) @bci=13, line=1437 (Interpreted frame)
>>>>    - javax.management.MBeanServerBuilder.newMBeanServer(java.lang.
>>>> String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>>>> @bci=4, line=110 (Interpreted frame)
>>>>    - javax.management.MBeanServerFactory.newMBeanServer(java.lang.
>>>> String)
>>>> @bci=36, line=329 (Interpreted frame)
>>>>    -
>>>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>>>> @bci=6, line=231 (Interpreted frame)
>>>>    - javax.management.MBeanServerFactory.createMBeanServer() @bci=1,
>>>> line=192 (Interpreted frame)
>>>>    - java.lang.management.ManagementFactory.getPlatformMBeanServer()
>>>> @bci=29, line=468 (Interpreted frame)
>>>>    -
>>>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>>>> @bci=66, line=518 (Interpreted frame)
>>>>    - sun.management.Agent.startLocalManagementAgent() @bci=13, line=138
>>>> (Interpreted frame)
>>>>    - sun.management.Agent.startAgent(java.util.Properties) @bci=76,
>>>> line=260 (Interpreted frame)
>>>>    - sun.management.Agent.agentmain(java.lang.String) @bci=45, line=128
>>>> (Interpreted frame)
>>>>    -
>>>> sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method,
>>>> java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
>>>>    - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>>>> java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
>>>>    - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>>>> java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
>>>>    - java.lang.reflect.Method.invoke(java.lang.Object,
>>>> java.lang.Object[]) @bci=56, line=483 (Interpreted frame)
>>>>    -
>>>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>>>> g.String,
>>>> java.lang.String, java.lang.String) @bci=192, line=388 (Interpreted
>>>> frame)
>>>>    -
>>>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>>>> lang.String,
>>>> java.lang.String) @bci=5, line=411 (Interpreted frame)
>>>>
>>>>
>>>> Thread 7: (state = BLOCKED)
>>>>
>>>>
>>>> Thread 5: (state = BLOCKED)
>>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>>> line=60 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>>> g.Object,
>>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>>    -
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission,
>>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>>    -
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission)
>>>> @bci=27, line=202 (Interpreted frame)
>>>>    - java.net.NetworkInterface.getHardwareAddress() @bci=18, line=447
>>>> (Interpreted frame)
>>>>    - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116,
>>>> line=158 (Interpreted frame)
>>>>    - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14,
>>>> line=137
>>>> (Interpreted frame)
>>>>    - java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean)
>>>> @bci=0, line=2526 (Interpreted frame)
>>>>    - java.util.concurrent.ConcurrentHashMap.addCount(long, int)
>>>> @bci=104,
>>>> line=2266 (Interpreted frame)
>>>>    - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>>>> java.lang.Object, boolean) @bci=357, line=1070 (Interpreted frame)
>>>>    - java.util.concurrent.ConcurrentHashMap.putIfAbsent(
>>>> java.lang.Object,
>>>> java.lang.Object) @bci=4, line=1535 (Interpreted frame)
>>>>    - java.lang.ClassLoader.getClassLoadingLock(java.lang.String)
>>>> @bci=23,
>>>> line=463 (Interpreted frame)
>>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=2,
>>>> line=404 (Interpreted frame)
>>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean)
>>>> @bci=38,
>>>> line=411 (Interpreted frame)
>>>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>>>> boolean) @bci=36, line=308 (Interpreted frame)
>>>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>>>> (Interpreted frame)
>>>>    -
>>>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
>>>>
>>> cliffc.high_scale_lib.NonBlockingHashMap)
>>>
>>>> @bci=10, line=1167 (Interpreted frame)
>>>>    - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() @bci=8,
>>>> line=1200 (Interpreted frame)
>>>>    - au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
>>>> @bci=15, line=166 (Interpreted frame)
>>>>    - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4,
>>>> line=511 (Interpreted frame)
>>>>    - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308
>>>> (Interpreted frame)
>>>>    -
>>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>>>> eduledFutureTask)
>>>> @bci=1, line=180 (Interpreted frame)
>>>>    -
>>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>>> sk.run()
>>>> @bci=37, line=294 (Interpreted frame)
>>>>    -
>>>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>>>> rent.ThreadPoolExecutor$Worker)
>>>> @bci=95, line=1142 (Interpreted frame)
>>>>    - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5,
>>>> line=617 (Interpreted frame)
>>>>    - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>>>>
>>>>
>>>> Thread 4: (state = BLOCKED)
>>>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>>>    - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142
>>>> (Interpreted frame)
>>>>    - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158
>>>> (Interpreted
>>>> frame)
>>>>    - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209
>>>> (Interpreted frame)
>>>>
>>>>
>>>> Thread 3: (state = BLOCKED)
>>>>    - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
>>>>    - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
>>>>    - java.lang.ref.Reference$ReferenceHandler.run() @bci=36, line=157
>>>> (Interpreted frame)
>>>>
>>>>
>>>> Thread 1: (state = BLOCKED)
>>>>    - java.lang.ClassLoader.loadClass(java.lang.String, boolean) @bci=8,
>>>> line=406 (Interpreted frame)
>>>>    - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
>>>> boolean) @bci=36, line=308 (Interpreted frame)
>>>>    - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3, line=357
>>>> (Interpreted frame)
>>>>    - au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) @bci=229,
>>>> line=60 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=37, line=128 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) @bci=4, line=44 (Interpreted frame)
>>>>    - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
>>>> boolean, boolean) @bci=7, line=248 (Interpreted frame)
>>>>    -
>>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>>> g.Object,
>>>> java.lang.Object) @bci=8, line=67 (Interpreted frame)
>>>>    -
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission,
>>>> java.lang.Object) @bci=161, line=260 (Interpreted frame)
>>>>    -
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission)
>>>> @bci=27, line=202 (Interpreted frame)
>>>>    - java.lang.System.checkIO() @bci=18, line=253 (Interpreted frame)
>>>>    - java.lang.System.setErr(java.io.PrintStream) @bci=0, line=199
>>>> (Interpreted frame)
>>>>    - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[])
>>>> @bci=9,
>>>> line=84 (Interpreted frame)
>>>>
>>>> The long version:
>>>>
>>>> Attaching to process ID 7124, please wait...
>>>> Debugger attached successfully.
>>>> Client compiler detected.
>>>> JVM version is 25.0-b70
>>>> Deadlock Detection:
>>>>
>>>> Found one Java-level deadlock:
>>>> =============================
>>>>
>>>> "main":
>>>>     waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
>>>> java/lang/Object),
>>>>     which is held by "Thread-1"
>>>> "Thread-1":
>>>>     waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
>>>>     which is held by "main"
>>>>
>>>> Found a total of 1 deadlock.
>>>>
>>>> ----------------- 0 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x00e64d7b    java + 0x4d7b
>>>> 0x00e631ca    java + 0x31ca
>>>> 0x00e642ab    java + 0x42ab
>>>> 0x00e63440    java + 0x3440
>>>> 0x00130138        ????????
>>>> ----------------- 1 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>>> 0x5bea1b28    jvm + 0x71b28
>>>> 0x01aa1cef    * java.lang.ClassLoader.loadClass(java.lang.String,
>>>> boolean) bci:8 line:406 (Interpreted frame)
>>>> 0x01a94054    *
>>>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>>>> bci:36 line:308 (Interpreted frame)
>>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>>>> line:357 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>>>> 0x5be77d6f    jvm + 0x47d6f
>>>> 0x5be7822a    jvm + 0x4822a
>>>> 0x5be794c0    jvm + 0x494c0
>>>> 0x5be7950a    jvm + 0x4950a
>>>> 0x5bf20de5    jvm!_JVM_FindClassFromClass at 16 + 0x135
>>>> 0x73b515cd    verify + 0x15cd
>>>> 0x73b51d53    verify + 0x1d53
>>>> 0x73b52c67    verify + 0x2c67
>>>> 0x14d6f5e8        ????????
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 2 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>>> 0x5bf99671    jvm!JVM_GetThreadStateNames + 0x6d221
>>>> 0x5bf99a32    jvm!JVM_GetThreadStateNames + 0x6d5e2
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> ----------------- 3 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>>>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>>>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>>>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>>>> 0x01a940f4    * java.lang.Object.wait() bci:2 line:502 (Interpreted
>>>> frame)
>>>> 0x01a940f4    * java.lang.ref.Reference$ReferenceHandler.run() bci:36
>>>> line:157 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 4 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>>> 0x5bf78f56    jvm!JVM_GetThreadStateNames + 0x4cb06
>>>> 0x5bf8e334    jvm!JVM_GetThreadStateNames + 0x61ee4
>>>> 0x5bf20c15    jvm!_JVM_MonitorWait at 16 + 0x95
>>>> 0x01a9ac63    * java.lang.Object.wait(long) bci:0 (Interpreted frame)
>>>> 0x01a940f4    * java.lang.ref.ReferenceQueue.remove(long) bci:44
>>>> line:142 (Interpreted frame)
>>>> 0x01a94054    * java.lang.ref.ReferenceQueue.remove() bci:2 line:158
>>>> (Interpreted frame)
>>>> 0x01a94054    * java.lang.ref.Finalizer$FinalizerThread.run() bci:36
>>>> line:209 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 5 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>>> 0x5bf7857e    jvm!JVM_GetThreadStateNames + 0x4c12e
>>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>>>> 0x5bee0d10    jvm + 0xb0d10
>>>> 0x5bee2854    jvm + 0xb2854
>>>> 0x5bee3548    jvm + 0xb3548
>>>> 0x5bea5641    jvm + 0x75641
>>>> 0x01aa17be    *
>>>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>>>> line:60 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>>>> 0x01a94089    *
>>>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>>>> boolean) bci:7 line:248 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>>> g.Object,
>>>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>>>> 0x01a94089    *
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission,
>>>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission)
>>>> bci:27 line:202 (Interpreted frame)
>>>> 0x01a940f4    * java.net.NetworkInterface.getHardwareAddress() bci:18
>>>> line:447 (Interpreted frame)
>>>> 0x01a94054    * java.util.concurrent.ThreadLocalRandom.initialSeed()
>>>> bci:116 line:158 (Interpreted frame)
>>>> 0x01a93e20    * java.util.concurrent.ThreadLocalRandom.<clinit>()
>>>> bci:14
>>>> line:137 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bee0f44    jvm + 0xb0f44
>>>> 0x5bee2b21    jvm + 0xb2b21
>>>> 0x5bee3548    jvm + 0xb3548
>>>> 0x5bea9796    jvm + 0x79796
>>>> 0x5beaa7b2    jvm + 0x7a7b2
>>>> 0x5bea5dc7    jvm + 0x75dc7
>>>> 0x01aa12ae    *
>>>> java.util.concurrent.ConcurrentHashMap.fullAddCount(long, boolean)
>>>> bci:0
>>>> line:2526 (Interpreted frame)
>>>> 0x01a940f4    * java.util.concurrent.ConcurrentHashMap.addCount(long,
>>>> int) bci:104 line:2266 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
>>>> java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
>>>> 0x01a94054    *
>>>> java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
>>>> java.lang.Object) bci:4 line:1535 (Interpreted frame)
>>>> 0x01a94054    *
>>>> java.lang.ClassLoader.getClassLoadingLock(java.lang.String) bci:23
>>>> line:463 (Interpreted frame)
>>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>>>> boolean) bci:2 line:404 (Interpreted frame)
>>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String,
>>>> boolean) bci:38 line:411 (Interpreted frame)
>>>> 0x01a94054    *
>>>> sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String, boolean)
>>>> bci:36 line:308 (Interpreted frame)
>>>> 0x01a94054    * java.lang.ClassLoader.loadClass(java.lang.String) bci:3
>>>> line:357 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>>> 0x5bf7258f    jvm!JVM_GetThreadStateNames + 0x4613f
>>>> 0x5be77d6f    jvm + 0x47d6f
>>>> 0x5be7822a    jvm + 0x4822a
>>>> 0x5be794c0    jvm + 0x494c0
>>>> 0x5be7950a    jvm + 0x4950a
>>>> 0x5be79f66    jvm + 0x49f66
>>>> 0x5be715c7    jvm + 0x415c7
>>>> 0x5be7a53c    jvm + 0x4a53c
>>>> 0x5be817e2    jvm + 0x517e2
>>>> 0x5be822d9    jvm + 0x522d9
>>>> 0x5be82414    jvm + 0x52414
>>>> 0x5bed85dd    jvm + 0xa85dd
>>>> 0x5bee0d80    jvm + 0xb0d80
>>>> 0x5bee2854    jvm + 0xb2854
>>>> 0x5bee3548    jvm + 0xb3548
>>>> 0x5bea5641    jvm + 0x75641
>>>> 0x01aa17be    *
>>>> org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
>>>>
>>> cliffc.high_scale_lib.NonBlockingHashMap)
>>>
>>>> bci:10 line:1167 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8
>>>> line:1200 (Interpreted frame)
>>>> 0x01a94089    *
>>>> au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run() bci:15
>>>> line:166 (Interpreted frame)
>>>> 0x01a94129    * java.util.concurrent.Executors$RunnableAdapter.call()
>>>> bci:4 line:511 (Interpreted frame)
>>>> 0x01a94089    * java.util.concurrent.FutureTask.runAndReset() bci:47
>>>> line:308 (Interpreted frame)
>>>> 0x01a93ba0    *
>>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>>> sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
>>>> eduledFutureTask)
>>>> bci:1 line:180 (Interpreted frame)
>>>> 0x01a93ba0    *
>>>> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
>>>> sk.run()
>>>> bci:37 line:294 (Interpreted frame)
>>>> 0x01a94129    *
>>>> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
>>>> rent.ThreadPoolExecutor$Worker)
>>>> bci:95 line:1142 (Interpreted frame)
>>>> 0x01a940f4    * java.util.concurrent.ThreadPoolExecutor$Worker.run()
>>>> bci:5 line:617 (Interpreted frame)
>>>> 0x01a94129    * java.lang.Thread.run() bci:11 line:744 (Interpreted
>>>> frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf724a6    jvm!JVM_GetThreadStateNames + 0x46056
>>>> 0x5bf72517    jvm!JVM_GetThreadStateNames + 0x460c7
>>>> 0x5bf1de0f    jvm!jio_printf + 0x9f
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - <0x03d58650>, (a java/util/concurrent/
>>>> ThreadPoolExecutor$Worker)
>>>> ----------------- 6 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> ----------------- 7 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd9539    jvm!_JVM_FindSignal at 4 + 0x5269
>>>> 0x5bfd9607    jvm!_JVM_FindSignal at 4 + 0x5337
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 8 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>>> 0x5bf7856b    jvm!JVM_GetThreadStateNames + 0x4c11b
>>>> 0x5bf78b23    jvm!JVM_GetThreadStateNames + 0x4c6d3
>>>> 0x5bf8e107    jvm!JVM_GetThreadStateNames + 0x61cb7
>>>> 0x5bf8e6be    jvm!JVM_GetThreadStateNames + 0x6226e
>>>> 0x5bf8e78f    jvm!JVM_GetThreadStateNames + 0x6233f
>>>> 0x5bee0d10    jvm + 0xb0d10
>>>> 0x5bee2854    jvm + 0xb2854
>>>> 0x5bee3548    jvm + 0xb3548
>>>> 0x5bea5641    jvm + 0x75641
>>>> 0x01aa17be    *
>>>> au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
>>>> au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref) bci:229
>>>> line:60 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) bci:37 line:128 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
>>>> boolean, boolean) bci:4 line:44 (Interpreted frame)
>>>> 0x01a94089    *
>>>> au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object, boolean,
>>>> boolean) bci:7 line:248 (Interpreted frame)
>>>> 0x01a94054    *
>>>> au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
>>>> g.Object,
>>>> java.lang.Object) bci:8 line:67 (Interpreted frame)
>>>> 0x01a94089    *
>>>> org.apache.river.api.security.CombinerSecurityManager.checkPermiss
>>>> ion(java.security.Permission,
>>>> java.lang.Object) bci:161 line:260 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
>>>> ustPermission(java.lang.Class)
>>>> bci:59 line:1848 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
>>>> n(java.lang.Object,
>>>> javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
>>>> 0x01a94089    * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() bci:17
>>>> line:1225 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf299ed    jvm!_JVM_DoPrivileged at 20 + 0x2bd
>>>> 0x73b21047
>>>> java_73b20000!_Java_java_security_AccessController_doPrivileged__L
>>>> java_security_PrivilegedExceptionAction_2 at 12
>>>> + 0x15
>>>> 0x01a94054    * com.sun.jmx.mbeanserver.JmxMBeanServer.initialize()
>>>> bci:25 line:1223 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>>> com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean) bci:133
>>>> line:255 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate,
>>>> boolean) bci:13 line:1437 (Interpreted frame)
>>>> 0x01a94054    *
>>>> javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
>>>> javax.management.MBeanServer, javax.management.MBeanServerDelegate)
>>>> bci:4 line:110 (Interpreted frame)
>>>> 0x01a94054    *
>>>> javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
>>>> bci:36 line:329 (Interpreted frame)
>>>> 0x01a94054    *
>>>> javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
>>>> bci:6 line:231 (Interpreted frame)
>>>> 0x01a94054    * javax.management.MBeanServerFactory.createMBeanServer()
>>>> bci:1 line:192 (Interpreted frame)
>>>> 0x01a94054    *
>>>> java.lang.management.ManagementFactory.getPlatformMBeanServer() bci:29
>>>> line:468 (Interpreted frame)
>>>> 0x01a94054    *
>>>> sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
>>>> bci:66 line:518 (Interpreted frame)
>>>> 0x01a94054    * sun.management.Agent.startLocalManagementAgent() bci:13
>>>> line:138 (Interpreted frame)
>>>> 0x01a940f4    * sun.management.Agent.startAgent(java.util.Properties)
>>>> bci:76 line:260 (Interpreted frame)
>>>> 0x01a940f4    * sun.management.Agent.agentmain(java.lang.String) bci:45
>>>> line:128 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5bf7e73a    jvm!JVM_GetThreadStateNames + 0x522ea
>>>> 0x5bf7e993    jvm!JVM_GetThreadStateNames + 0x52543
>>>> 0x5bf22b03    jvm!_JVM_InvokeMethod at 16 + 0xb3
>>>> 0x73b23a6e
>>>> java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20 +
>>>> 0x15
>>>> 0x01a94054    *
>>>> sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
>>>> java.lang.Object[]) bci:100 line:62 (Interpreted frame)
>>>> 0x01a94054    *
>>>> sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
>>>> java.lang.Object[]) bci:6 line:43 (Interpreted frame)
>>>> 0x01a94089    * java.lang.reflect.Method.invoke(java.lang.Object,
>>>> java.lang.Object[]) bci:56 line:483 (Interpreted frame)
>>>> 0x01a94054    *
>>>> sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
>>>> g.String,
>>>> java.lang.String, java.lang.String) bci:192 line:388 (Interpreted frame)
>>>> 0x01a940f4    *
>>>> sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
>>>> lang.String,
>>>> java.lang.String) bci:5 line:411 (Interpreted frame)
>>>> 0x01a903d7 <StubRoutines>
>>>> 0x5bf72285    jvm!JVM_GetThreadStateNames + 0x45e35
>>>> 0x5c0370be    jvm!_JVM_FindSignal at 4 + 0x62dee
>>>> 0x5bf7231e    jvm!JVM_GetThreadStateNames + 0x45ece
>>>> 0x5befe951    jvm!JNI_GetCreatedJavaVMs + 0x71a1
>>>> 0x5bf01788    jvm!JNI_GetCreatedJavaVMs + 0x9fd8
>>>> 0x6db62878    instrument!Agent_OnAttach + 0x76b
>>>> 0x6db63eea    instrument!Agent_OnAttach + 0x1ddd
>>>> 0x6db6234a    instrument!Agent_OnAttach + 0x23d
>>>> 0x5bf3c50c    jvm!JVM_GetThreadStateNames + 0x100bc
>>>> 0x5bf9b05e    jvm!JVM_GetThreadStateNames + 0x6ec0e
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 9 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>>> 0x5bf7424a    jvm!JVM_GetThreadStateNames + 0x47dfa
>>>> 0x5be9253b    jvm + 0x6253b
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 10 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6c49    jvm!_JVM_FindSignal at 4 + 0x2979
>>>> 0x5bf73ec1    jvm!JVM_GetThreadStateNames + 0x47a71
>>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>>> 0x5bf829a5    jvm!JVM_GetThreadStateNames + 0x56555
>>>> 0x5bf945fc    jvm!JVM_GetThreadStateNames + 0x681ac
>>>> 0x5bf94e8a    jvm!JVM_GetThreadStateNames + 0x68a3a
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>> Locked ownable synchronizers:
>>>>       - None
>>>> ----------------- 11 -----------------
>>>> 0x77c870f4    ntdll!KiFastSystemCallRet
>>>> 0x76a9c3d3    kernel32!WaitForSingleObjectEx + 0x43
>>>> 0x76a9c382    kernel32!WaitForSingleObject + 0x12
>>>> 0x5bfd6b3d    jvm!_JVM_FindSignal at 4 + 0x286d
>>>> 0x5bf73ecc    jvm!JVM_GetThreadStateNames + 0x47a7c
>>>> 0x5bf741fc    jvm!JVM_GetThreadStateNames + 0x47dac
>>>> 0x5bf8f904    jvm!JVM_GetThreadStateNames + 0x634b4
>>>> 0x5bf8f9a7    jvm!JVM_GetThreadStateNames + 0x63557
>>>> 0x5bfd9186    jvm!_JVM_FindSignal at 4 + 0x4eb6
>>>> 0x614dc556    msvcr100!_endthreadex + 0x3a
>>>> 0x614dc600    msvcr100!_endthreadex + 0xe4
>>>> 0x76a9ee1c    kernel32!BaseThreadInitThunk + 0x12
>>>> 0x77ca37eb    ntdll!RtlInitializeExceptionChain + 0xef
>>>> 0x77ca37be    ntdll!RtlInitializeExceptionChain + 0xc2
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/8f9d6380/attachment-0001.html>

From martinrb at google.com  Tue Jun 24 12:01:53 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 24 Jun 2014 09:01:53 -0700
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A98525.9080908@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>
	<53A29DC5.1030605@oracle.com>
	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>
	<53A3FA72.3060706@gmail.com> <53A418F2.3080201@gmail.com>
	<53A43055.5070803@oracle.com> <53A43EF3.8000206@gmail.com>
	<53A44C3A.6000607@oracle.com>
	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>
	<CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>
	<53A98525.9080908@gmail.com>
Message-ID: <CA+kOe0-Ke7JF+HimqL2M8Dr=0c4-ux8YCOMRAZi_3k_su8F8Pw@mail.gmail.com>

On Tue, Jun 24, 2014 at 7:03 AM, Peter Levart <peter.levart at gmail.com>
wrote:

>
> I would rather use SecureRandom.generateSeed() instance method instead of
> SecureRandom.nextBytes(). Why? Because every SecureRandom instance has to
> initialize it's seed 1st before getBytes() can provide the next random
> bytes from the PRNG. Since we only need the 1st 8 bytes from the
> SecureRandom instance to initialize TLR's seeder, we might as well directly
> call the SecureRandom.generateSeed() method.
>

If I strace this program on Linux using strace -ff -q java SecureRandoms:

public class SecureRandoms {
    public static void main(String[] args) throws Throwable {
        byte[] bytes = new byte[8];
        new java.security.SecureRandom().nextBytes(bytes);
    }
}

I see a read from /dev/urandom, but not from /dev/random, so I conclude
your intuitive understanding of how the seeding works must be wrong.  It
makes sense that NativePRNG doesn't need to do any special seeding of its
own, since it reuses the operating system's.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/404668bd/attachment.html>

From martinrb at google.com  Tue Jun 24 12:52:35 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 24 Jun 2014 09:52:35 -0700
Subject: [concurrency-interest] Proposal for a CallerRunsExecutor in
	j.u.c.Executors
In-Reply-To: <CACuKZqFb5mkuujCOw8Brk7taJ_x-XsKhNdLkWwzQnsYe3tzEyQ@mail.gmail.com>
References: <CAO9V1MKUEBD6Ea7yqHeqYW98JZX7cLv6zoyDgp7xu7051EHykg@mail.gmail.com>
	<5380DED8.9060103@cs.oswego.edu>
	<CAO9V1MKzSg7W978rqYtP+v-fR0M3+MpjgjUtOpoNgvUeMhXGoA@mail.gmail.com>
	<CAO9V1MJNxG3vFyqoP195pPCF4Ws8WkgQPrLOOZR2dfS0Uth=0Q@mail.gmail.com>
	<CA+kOe09pgFMDQB5gzbc_OTVsqSgrttbJFo+qAZxauxFwH398oA@mail.gmail.com>
	<CACuKZqFb5mkuujCOw8Brk7taJ_x-XsKhNdLkWwzQnsYe3tzEyQ@mail.gmail.com>
Message-ID: <CA+kOe09UY1iT2JDyh0zvuUNSOJn2JswOXcTYEN5Jrj3N14E34g@mail.gmail.com>

On Mon, Jun 23, 2014 at 7:19 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Mon, Jun 23, 2014 at 5:39 PM, Martin Buchholz <martinrb at google.com>
> wrote:
> > Since introducing a plain Executor is much better than doing nothing,
> let's
> > start with that.
>
> Is it necessary though? In java 8, programmers can simply use
>
>
Of course it's not necessary, and that was a reason to not include it back
in 2005.  But it's quite popular, and as Doug says, merely giving it a
standard name has a lot of value.

It would also have value to go further and define an ExecutorService, but
the smart people here need to agree on the semantics.


>     (Executor)Runnable::run
>
> Pre java8, an anonymous class isn't too verbose either
>
>     new Executor(){ public void execute(Runnable r) { r.run(); } }
>
> It doesn't seem to warrant a convenience method in java.*.
>
> Zhong Yu
> bayou.io
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/87fa2df1/attachment.html>

From martinrb at google.com  Tue Jun 24 13:38:39 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 24 Jun 2014 10:38:39 -0700
Subject: [concurrency-interest] micro-benchmark for concurrent
	collections
In-Reply-To: <1938831105.1858614.1403451578986.JavaMail.zimbra@redhat.com>
References: <1350438252.1858561.1403451502639.JavaMail.zimbra@redhat.com>
	<1938831105.1858614.1403451578986.JavaMail.zimbra@redhat.com>
Message-ID: <CA+kOe0-gxwSG_ZiD+WEeU0dyFh3Rhcae_Q7tCaL9hvY+hitv0Q@mail.gmail.com>

Both jsr166 cvs and guava source contains benchmarks that are at least
close to what you are looking for.


On Sun, Jun 22, 2014 at 8:39 AM, Andrig Miller <anmiller at redhat.com> wrote:

> I was wondering if anyone new of a good micro-benchmark for the concurrent
> collections?  I specifically would like to benchmark ConcurrentHashMap,
> against an alternative implementation.  A JMH based one would be preferable.
>
> Thanks.
>
> --
> Andrig (Andy) Miller
> Global Platform Director for JBoss Middle-ware
> Red Hat, Inc.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/95b7e966/attachment.html>

From anmiller at redhat.com  Tue Jun 24 13:50:53 2014
From: anmiller at redhat.com (Andrig Miller)
Date: Tue, 24 Jun 2014 13:50:53 -0400 (EDT)
Subject: [concurrency-interest] micro-benchmark for concurrent
 collections
In-Reply-To: <CA+kOe0-gxwSG_ZiD+WEeU0dyFh3Rhcae_Q7tCaL9hvY+hitv0Q@mail.gmail.com>
References: <1350438252.1858561.1403451502639.JavaMail.zimbra@redhat.com>
	<1938831105.1858614.1403451578986.JavaMail.zimbra@redhat.com>
	<CA+kOe0-gxwSG_ZiD+WEeU0dyFh3Rhcae_Q7tCaL9hvY+hitv0Q@mail.gmail.com>
Message-ID: <19586462.107.1403632249482.JavaMail.andrig@worklaptop.miller.org>

Okay, great. I'll check them out. 

Andy 

----- Original Message -----

> From: "Martin Buchholz" <martinrb at google.com>
> To: "Andrig Miller" <anmiller at redhat.com>
> Cc: "Concurrency-interest" <Concurrency-interest at cs.oswego.edu>
> Sent: Tuesday, June 24, 2014 11:38:39 AM
> Subject: Re: [concurrency-interest] micro-benchmark for concurrent
> collections

> Both jsr166 cvs and guava source contains benchmarks that are at
> least close to what you are looking for.

> On Sun, Jun 22, 2014 at 8:39 AM, Andrig Miller < anmiller at redhat.com
> > wrote:

> > I was wondering if anyone new of a good micro-benchmark for the
> > concurrent collections? I specifically would like to benchmark
> > ConcurrentHashMap, against an alternative implementation. A JMH
> > based one would be preferable.
> 

> > Thanks.
> 

> > --
> 

> > Andrig (Andy) Miller
> 
> > Global Platform Director for JBoss Middle-ware
> 
> > Red Hat, Inc.
> 

> > _______________________________________________
> 
> > Concurrency-interest mailing list
> 
> > Concurrency-interest at cs.oswego.edu
> 
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/3a3e27e1/attachment.html>

From peter.firmstone at zeus.net.au  Tue Jun 24 15:21:27 2014
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Wed, 25 Jun 2014 05:21:27 +1000
Subject: [concurrency-interest] Deadlock
In-Reply-To: <CA+kOe09-9AhEXS_AQSe8uEC6ApYKiD4MWteEOoWZpU4HpdP-SA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFIKHAA.davidcholmes@aapt.net.au>
	<53A98733.4060401@gmail.com> <53A9897A.7010803@gmail.com>
	<CA+kOe09-9AhEXS_AQSe8uEC6ApYKiD4MWteEOoWZpU4HpdP-SA@mail.gmail.com>
Message-ID: <1403637687.9595.5.camel@Nokia-N900>

Interesting coincidence, I'll go over the recent discussion to familiarise myself.

Thanks,

Peter. 

----- Original message -----
> [+openjdk mailing lists]
> 
> 
> Yeah, I'm trying to excise all the networking code from TLR and
> SplittableRandom.
> 
> There is also likely to be a missing wrapping in doPrivileged.
> 
> 
> On Tue, Jun 24, 2014 at 7:21 AM, Peter Levart <peter.levart at gmail.com>
> wrote:
> 
> > On 06/24/2014 04:12 PM, Peter Levart wrote:
> > 
> > > On 06/24/2014 01:09 PM, David Holmes wrote:
> > > 
> > > > Hi Peter,
> > > > 
> > > > What a strange coincidence - the fact that the initialization of
> > > > ThreadLocalRandom can lead to arbitrary code execution has just
> > > > been a topic
> > > > of discussion, and it looks like your deadlock is related to that.
> > > > 
> > > 
> > > Uf, this time it's a combination of a custom SecurityManager being in
> > > effect when NetworkInterface.getHardwareAddress() is called. It looks
> > > like we should not use any networking code at all for TLR's
> > > initialization.
> > > 
> > 
> > Or make NetworkInterface.getHardwareAddress() a @CallerSensitive method
> > and avoid SecurityManager invocation when called from one of system
> > classes. That's still an alternative.
> > 
> > Peter
> > 
> > 
> > 
> > > Regards, Peter
> > > 
> > > 
> > > > David Holmes
> > > > 
> > > > -----Original Message-----
> > > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > > > > Peter Firmstone
> > > > > Sent: Tuesday, 24 June 2014 8:25 PM
> > > > > To: concurrency-interest at cs.oswego.edu
> > > > > Subject: [concurrency-interest] Deadlock
> > > > > 
> > > > > 
> > > > > This appears to be a ClassLoader deadlock in Java 7.
> > > > > 
> > > > > The stack trace from the main thread is missing.
> > > > > 
> > > > > Any ideas?
> > > > > 
> > > > > Regards,
> > > > > 
> > > > > Peter.
> > > > > 
> > > > > Attaching to process ID 7124, please wait...
> > > > > Debugger attached successfully.
> > > > > Client compiler detected.
> > > > > JVM version is 25.0-b70
> > > > > Deadlock Detection:
> > > > > 
> > > > > Found one Java-level deadlock:
> > > > > =============================
> > > > > 
> > > > > "main":
> > > > > waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
> > > > > java/lang/Object),
> > > > > which is held by "Thread-1"
> > > > > "Thread-1":
> > > > > waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
> > > > > which is held by "main"
> > > > > 
> > > > > Found a total of 1 deadlock.
> > > > > 
> > > > > Thread 8: (state = BLOCKED)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> > > > > au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref)
> > > > > @bci=229, line=60 (Interpreted frame) -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=37, line=128 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=4, line=44 (Interpreted frame)
> > > > > - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> > > > > boolean, boolean) @bci=7, line=248 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> > > > > g.Object,
> > > > > java.lang.Object) @bci=8, line=67 (Interpreted frame)
> > > > > -
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission,
> > > > > java.lang.Object) @bci=161, line=260 (Interpreted frame)
> > > > > -
> > > > > com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
> > > > > ustPermission(java.lang.Class)
> > > > > @bci=59, line=1848 (Interpreted frame)
> > > > > -
> > > > > com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
> > > > > n(java.lang.Object,
> > > > > javax.management.ObjectName) @bci=25, line=322 (Interpreted
> > > > > frame) - com.sun.jmx.mbeanserver.JmxMBeanServer$2.run() @bci=17,
> > > > > line=1225 (Interpreted frame)
> > > > > -
> > > > > java.security.AccessController.doPrivileged(java.security.Privileg
> > > > > edExceptionAction)
> > > > > @bci=0 (Interpreted frame)
> > > > > - com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() @bci=25,
> > > > > line=1223 (Interpreted frame)
> > > > > - com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
> > > > > javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate,
> > > > > com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean)
> > > > > @bci=133, line=255 (Interpreted frame) -
> > > > > com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
> > > > > javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate, boolean) @bci=13,
> > > > > line=1437 (Interpreted frame) -
> > > > > javax.management.MBeanServerBuilder.newMBeanServer(java.lang.
> > > > > String, javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate) @bci=4, line=110
> > > > > (Interpreted frame) -
> > > > > javax.management.MBeanServerFactory.newMBeanServer(java.lang.
> > > > > String) @bci=36, line=329 (Interpreted frame)
> > > > > -
> > > > > javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
> > > > > @bci=6, line=231 (Interpreted frame)
> > > > > - javax.management.MBeanServerFactory.createMBeanServer() @bci=1,
> > > > > line=192 (Interpreted frame)
> > > > > - java.lang.management.ManagementFactory.getPlatformMBeanServer()
> > > > > @bci=29, line=468 (Interpreted frame)
> > > > > -
> > > > > sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
> > > > > @bci=66, line=518 (Interpreted frame)
> > > > > - sun.management.Agent.startLocalManagementAgent() @bci=13,
> > > > > line=138 (Interpreted frame)
> > > > > - sun.management.Agent.startAgent(java.util.Properties) @bci=76,
> > > > > line=260 (Interpreted frame)
> > > > > - sun.management.Agent.agentmain(java.lang.String) @bci=45,
> > > > > line=128 (Interpreted frame)
> > > > > -
> > > > > sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method,
> > > > > java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
> > > > > - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
> > > > > java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
> > > > > -
> > > > > sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
> > > > > java.lang.Object[]) @bci=6, line=43 (Interpreted frame) -
> > > > > java.lang.reflect.Method.invoke(java.lang.Object,
> > > > > java.lang.Object[]) @bci=56, line=483 (Interpreted frame) -
> > > > > sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
> > > > > g.String,
> > > > > java.lang.String, java.lang.String) @bci=192, line=388
> > > > > (Interpreted frame)
> > > > > -
> > > > > sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
> > > > > lang.String,
> > > > > java.lang.String) @bci=5, line=411 (Interpreted frame)
> > > > > 
> > > > > 
> > > > > Thread 7: (state = BLOCKED)
> > > > > 
> > > > > 
> > > > > Thread 5: (state = BLOCKED)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> > > > > au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref)
> > > > > @bci=229, line=60 (Interpreted frame) -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=37, line=128 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=4, line=44 (Interpreted frame)
> > > > > - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> > > > > boolean, boolean) @bci=7, line=248 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> > > > > g.Object,
> > > > > java.lang.Object) @bci=8, line=67 (Interpreted frame)
> > > > > -
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission,
> > > > > java.lang.Object) @bci=161, line=260 (Interpreted frame)
> > > > > -
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission)
> > > > > @bci=27, line=202 (Interpreted frame)
> > > > > - java.net.NetworkInterface.getHardwareAddress() @bci=18,
> > > > > line=447 (Interpreted frame)
> > > > > - java.util.concurrent.ThreadLocalRandom.initialSeed() @bci=116,
> > > > > line=158 (Interpreted frame)
> > > > > - java.util.concurrent.ThreadLocalRandom.<clinit>() @bci=14,
> > > > > line=137
> > > > > (Interpreted frame)
> > > > > - java.util.concurrent.ConcurrentHashMap.fullAddCount(long,
> > > > > boolean) @bci=0, line=2526 (Interpreted frame)
> > > > > - java.util.concurrent.ConcurrentHashMap.addCount(long, int)
> > > > > @bci=104,
> > > > > line=2266 (Interpreted frame)
> > > > > - java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
> > > > > java.lang.Object, boolean) @bci=357, line=1070 (Interpreted
> > > > > frame) - java.util.concurrent.ConcurrentHashMap.putIfAbsent(
> > > > > java.lang.Object,
> > > > > java.lang.Object) @bci=4, line=1535 (Interpreted frame)
> > > > > - java.lang.ClassLoader.getClassLoadingLock(java.lang.String)
> > > > > @bci=23,
> > > > > line=463 (Interpreted frame)
> > > > > - java.lang.ClassLoader.loadClass(java.lang.String, boolean)
> > > > > @bci=2, line=404 (Interpreted frame)
> > > > > - java.lang.ClassLoader.loadClass(java.lang.String, boolean)
> > > > > @bci=38,
> > > > > line=411 (Interpreted frame)
> > > > > - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> > > > > boolean) @bci=36, line=308 (Interpreted frame)
> > > > > - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3,
> > > > > line=357 (Interpreted frame)
> > > > > -
> > > > > org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
> > > > > 
> > > > cliffc.high_scale_lib.NonBlockingHashMap)
> > > > 
> > > > > @bci=10, line=1167 (Interpreted frame)
> > > > > - org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator()
> > > > > @bci=8, line=1200 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
> > > > > @bci=15, line=166 (Interpreted frame) -
> > > > > java.util.concurrent.Executors$RunnableAdapter.call() @bci=4,
> > > > > line=511 (Interpreted frame) -
> > > > > java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308
> > > > > (Interpreted frame) -
> > > > > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> > > > > sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
> > > > > eduledFutureTask)
> > > > > @bci=1, line=180 (Interpreted frame)
> > > > > -
> > > > > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> > > > > sk.run()
> > > > > @bci=37, line=294 (Interpreted frame)
> > > > > -
> > > > > java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
> > > > > rent.ThreadPoolExecutor$Worker)
> > > > > @bci=95, line=1142 (Interpreted frame)
> > > > > - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5,
> > > > > line=617 (Interpreted frame)
> > > > > - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
> > > > > 
> > > > > 
> > > > > Thread 4: (state = BLOCKED)
> > > > > - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
> > > > > - java.lang.ref.ReferenceQueue.remove(long) @bci=44, line=142
> > > > > (Interpreted frame)
> > > > > - java.lang.ref.ReferenceQueue.remove() @bci=2, line=158
> > > > > (Interpreted
> > > > > frame)
> > > > > - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209
> > > > > (Interpreted frame)
> > > > > 
> > > > > 
> > > > > Thread 3: (state = BLOCKED)
> > > > > - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
> > > > > - java.lang.Object.wait() @bci=2, line=502 (Interpreted frame)
> > > > > - java.lang.ref.Reference$ReferenceHandler.run() @bci=36,
> > > > > line=157 (Interpreted frame)
> > > > > 
> > > > > 
> > > > > Thread 1: (state = BLOCKED)
> > > > > - java.lang.ClassLoader.loadClass(java.lang.String, boolean)
> > > > > @bci=8, line=406 (Interpreted frame)
> > > > > - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> > > > > boolean) @bci=36, line=308 (Interpreted frame)
> > > > > - java.lang.ClassLoader.loadClass(java.lang.String) @bci=3,
> > > > > line=357 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> > > > > au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref)
> > > > > @bci=229, line=60 (Interpreted frame) -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=37, line=128 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) @bci=4, line=44 (Interpreted frame)
> > > > > - au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> > > > > boolean, boolean) @bci=7, line=248 (Interpreted frame)
> > > > > -
> > > > > au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> > > > > g.Object,
> > > > > java.lang.Object) @bci=8, line=67 (Interpreted frame)
> > > > > -
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission,
> > > > > java.lang.Object) @bci=161, line=260 (Interpreted frame)
> > > > > -
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission)
> > > > > @bci=27, line=202 (Interpreted frame)
> > > > > - java.lang.System.checkIO() @bci=18, line=253 (Interpreted
> > > > > frame) - java.lang.System.setErr(java.io.PrintStream) @bci=0,
> > > > > line=199 (Interpreted frame)
> > > > > - com.sun.jini.qa.harness.MasterTest.main(java.lang.String[])
> > > > > @bci=9,
> > > > > line=84 (Interpreted frame)
> > > > > 
> > > > > The long version:
> > > > > 
> > > > > Attaching to process ID 7124, please wait...
> > > > > Debugger attached successfully.
> > > > > Client compiler detected.
> > > > > JVM version is 25.0-b70
> > > > > Deadlock Detection:
> > > > > 
> > > > > Found one Java-level deadlock:
> > > > > =============================
> > > > > 
> > > > > "main":
> > > > > waiting to lock Monitor at 0x0094bb2c (Object at 0x03d73c38, a
> > > > > java/lang/Object),
> > > > > which is held by "Thread-1"
> > > > > "Thread-1":
> > > > > waiting to lock Monitor at 0x0094c99c (Object at 0x03f02e50, a [I),
> > > > > which is held by "main"
> > > > > 
> > > > > Found a total of 1 deadlock.
> > > > > 
> > > > > ----------------- 0 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x00e64d7b? ? ?  java + 0x4d7b
> > > > > 0x00e631ca? ? ?  java + 0x31ca
> > > > > 0x00e642ab? ? ?  java + 0x42ab
> > > > > 0x00e63440? ? ?  java + 0x3440
> > > > > 0x00130138? ? ? ? ? ? ?  ????????
> > > > > ----------------- 1 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6b3d? ? ?  jvm!_JVM_FindSignal at 4 + 0x286d
> > > > > 0x5bf7857e? ? ?  jvm!JVM_GetThreadStateNames + 0x4c12e
> > > > > 0x5bf78b23? ? ?  jvm!JVM_GetThreadStateNames + 0x4c6d3
> > > > > 0x5bf8e107? ? ?  jvm!JVM_GetThreadStateNames + 0x61cb7
> > > > > 0x5bf8e6be? ? ?  jvm!JVM_GetThreadStateNames + 0x6226e
> > > > > 0x5bea1b28? ? ?  jvm + 0x71b28
> > > > > 0x01aa1cef? ? ?  * java.lang.ClassLoader.loadClass(java.lang.String,
> > > > > boolean) bci:8 line:406 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> > > > > boolean) bci:36 line:308 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > java.lang.ClassLoader.loadClass(java.lang.String) bci:3 line:357
> > > > > (Interpreted frame) 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf724a6? ? ?  jvm!JVM_GetThreadStateNames + 0x46056
> > > > > 0x5bf7258f? ? ?  jvm!JVM_GetThreadStateNames + 0x4613f
> > > > > 0x5be77d6f? ? ?  jvm + 0x47d6f
> > > > > 0x5be7822a? ? ?  jvm + 0x4822a
> > > > > 0x5be794c0? ? ?  jvm + 0x494c0
> > > > > 0x5be7950a? ? ?  jvm + 0x4950a
> > > > > 0x5bf20de5? ? ?  jvm!_JVM_FindClassFromClass at 16 + 0x135
> > > > > 0x73b515cd? ? ?  verify + 0x15cd
> > > > > 0x73b51d53? ? ?  verify + 0x1d53
> > > > > 0x73b52c67? ? ?  verify + 0x2c67
> > > > > 0x14d6f5e8? ? ? ? ? ? ?  ????????
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 2 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6b3d? ? ?  jvm!_JVM_FindSignal at 4 + 0x286d
> > > > > 0x5bf73ecc? ? ?  jvm!JVM_GetThreadStateNames + 0x47a7c
> > > > > 0x5bf741fc? ? ?  jvm!JVM_GetThreadStateNames + 0x47dac
> > > > > 0x5bf99671? ? ?  jvm!JVM_GetThreadStateNames + 0x6d221
> > > > > 0x5bf99a32? ? ?  jvm!JVM_GetThreadStateNames + 0x6d5e2
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > ----------------- 3 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6c49? ? ?  jvm!_JVM_FindSignal at 4 + 0x2979
> > > > > 0x5bf78f56? ? ?  jvm!JVM_GetThreadStateNames + 0x4cb06
> > > > > 0x5bf8e334? ? ?  jvm!JVM_GetThreadStateNames + 0x61ee4
> > > > > 0x5bf20c15? ? ?  jvm!_JVM_MonitorWait at 16 + 0x95
> > > > > 0x01a9ac63? ? ?  * java.lang.Object.wait(long) bci:0 (Interpreted
> > > > > frame) 0x01a940f4? ? ?  * java.lang.Object.wait() bci:2 line:502
> > > > > (Interpreted frame)
> > > > > 0x01a940f4? ? ?  * java.lang.ref.Reference$ReferenceHandler.run()
> > > > > bci:36 line:157 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf724a6? ? ?  jvm!JVM_GetThreadStateNames + 0x46056
> > > > > 0x5bf72517? ? ?  jvm!JVM_GetThreadStateNames + 0x460c7
> > > > > 0x5bf1de0f? ? ?  jvm!jio_printf + 0x9f
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 4 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6c49? ? ?  jvm!_JVM_FindSignal at 4 + 0x2979
> > > > > 0x5bf78f56? ? ?  jvm!JVM_GetThreadStateNames + 0x4cb06
> > > > > 0x5bf8e334? ? ?  jvm!JVM_GetThreadStateNames + 0x61ee4
> > > > > 0x5bf20c15? ? ?  jvm!_JVM_MonitorWait at 16 + 0x95
> > > > > 0x01a9ac63? ? ?  * java.lang.Object.wait(long) bci:0 (Interpreted
> > > > > frame) 0x01a940f4? ? ?  * java.lang.ref.ReferenceQueue.remove(long)
> > > > > bci:44 line:142 (Interpreted frame)
> > > > > 0x01a94054? ? ?  * java.lang.ref.ReferenceQueue.remove() bci:2
> > > > > line:158 (Interpreted frame)
> > > > > 0x01a94054? ? ?  * java.lang.ref.Finalizer$FinalizerThread.run()
> > > > > bci:36 line:209 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf724a6? ? ?  jvm!JVM_GetThreadStateNames + 0x46056
> > > > > 0x5bf72517? ? ?  jvm!JVM_GetThreadStateNames + 0x460c7
> > > > > 0x5bf1de0f? ? ?  jvm!jio_printf + 0x9f
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 5 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6b3d? ? ?  jvm!_JVM_FindSignal at 4 + 0x286d
> > > > > 0x5bf7857e? ? ?  jvm!JVM_GetThreadStateNames + 0x4c12e
> > > > > 0x5bf78b23? ? ?  jvm!JVM_GetThreadStateNames + 0x4c6d3
> > > > > 0x5bf8e107? ? ?  jvm!JVM_GetThreadStateNames + 0x61cb7
> > > > > 0x5bf8e6be? ? ?  jvm!JVM_GetThreadStateNames + 0x6226e
> > > > > 0x5bf8e78f? ? ?  jvm!JVM_GetThreadStateNames + 0x6233f
> > > > > 0x5bee0d10? ? ?  jvm + 0xb0d10
> > > > > 0x5bee2854? ? ?  jvm + 0xb2854
> > > > > 0x5bee3548? ? ?  jvm + 0xb3548
> > > > > 0x5bea5641? ? ?  jvm + 0x75641
> > > > > 0x01aa17be? ? ?  *
> > > > > au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> > > > > au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref)
> > > > > bci:229 line:60 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) bci:37 line:128 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) bci:4 line:44 (Interpreted frame)
> > > > > 0x01a94089? ? ?  *
> > > > > au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> > > > > boolean, boolean) bci:7 line:248 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> > > > > g.Object,
> > > > > java.lang.Object) bci:8 line:67 (Interpreted frame)
> > > > > 0x01a94089? ? ?  *
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission,
> > > > > java.lang.Object) bci:161 line:260 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission)
> > > > > bci:27 line:202 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  * java.net.NetworkInterface.getHardwareAddress()
> > > > > bci:18 line:447 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > java.util.concurrent.ThreadLocalRandom.initialSeed() bci:116
> > > > > line:158 (Interpreted frame) 0x01a93e20? ? ?  *
> > > > > java.util.concurrent.ThreadLocalRandom.<clinit>() bci:14
> > > > > line:137 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bee0f44? ? ?  jvm + 0xb0f44
> > > > > 0x5bee2b21? ? ?  jvm + 0xb2b21
> > > > > 0x5bee3548? ? ?  jvm + 0xb3548
> > > > > 0x5bea9796? ? ?  jvm + 0x79796
> > > > > 0x5beaa7b2? ? ?  jvm + 0x7a7b2
> > > > > 0x5bea5dc7? ? ?  jvm + 0x75dc7
> > > > > 0x01aa12ae? ? ?  *
> > > > > java.util.concurrent.ConcurrentHashMap.fullAddCount(long,
> > > > > boolean) bci:0
> > > > > line:2526 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > java.util.concurrent.ConcurrentHashMap.addCount(long, int)
> > > > > bci:104 line:2266 (Interpreted frame) 0x01a940f4? ? ?  *
> > > > > java.util.concurrent.ConcurrentHashMap.putVal(java.lang.Object,
> > > > > java.lang.Object, boolean) bci:357 line:1070 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > java.util.concurrent.ConcurrentHashMap.putIfAbsent(java.lang.Object,
> > > > > java.lang.Object) bci:4 line:1535 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > java.lang.ClassLoader.getClassLoadingLock(java.lang.String)
> > > > > bci:23 line:463 (Interpreted frame)
> > > > > 0x01a94054? ? ?  * java.lang.ClassLoader.loadClass(java.lang.String,
> > > > > boolean) bci:2 line:404 (Interpreted frame)
> > > > > 0x01a94054? ? ?  * java.lang.ClassLoader.loadClass(java.lang.String,
> > > > > boolean) bci:38 line:411 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > sun.misc.Launcher$AppClassLoader.loadClass(java.lang.String,
> > > > > boolean) bci:36 line:308 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > java.lang.ClassLoader.loadClass(java.lang.String) bci:3 line:357
> > > > > (Interpreted frame) 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf724a6? ? ?  jvm!JVM_GetThreadStateNames + 0x46056
> > > > > 0x5bf7258f? ? ?  jvm!JVM_GetThreadStateNames + 0x4613f
> > > > > 0x5be77d6f? ? ?  jvm + 0x47d6f
> > > > > 0x5be7822a? ? ?  jvm + 0x4822a
> > > > > 0x5be794c0? ? ?  jvm + 0x494c0
> > > > > 0x5be7950a? ? ?  jvm + 0x4950a
> > > > > 0x5be79f66? ? ?  jvm + 0x49f66
> > > > > 0x5be715c7? ? ?  jvm + 0x415c7
> > > > > 0x5be7a53c? ? ?  jvm + 0x4a53c
> > > > > 0x5be817e2? ? ?  jvm + 0x517e2
> > > > > 0x5be822d9? ? ?  jvm + 0x522d9
> > > > > 0x5be82414? ? ?  jvm + 0x52414
> > > > > 0x5bed85dd? ? ?  jvm + 0xa85dd
> > > > > 0x5bee0d80? ? ?  jvm + 0xb0d80
> > > > > 0x5bee2854? ? ?  jvm + 0xb2854
> > > > > 0x5bee3548? ? ?  jvm + 0xb3548
> > > > > 0x5bea5641? ? ?  jvm + 0x75641
> > > > > 0x01aa17be? ? ?  *
> > > > > org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK.<init>(org.
> > > > > 
> > > > cliffc.high_scale_lib.NonBlockingHashMap)
> > > > 
> > > > > bci:10 line:1167 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > org.cliffc.high_scale_lib.NonBlockingHashMap$2.iterator() bci:8
> > > > > line:1200 (Interpreted frame)
> > > > > 0x01a94089? ? ?  *
> > > > > au.net.zeus.collection.ReferenceProcessor$EnqueGarbageTask.run()
> > > > > bci:15 line:166 (Interpreted frame)
> > > > > 0x01a94129? ? ?  *
> > > > > java.util.concurrent.Executors$RunnableAdapter.call() bci:4
> > > > > line:511 (Interpreted frame) 0x01a94089? ? ?  *
> > > > > java.util.concurrent.FutureTask.runAndReset() bci:47 line:308
> > > > > (Interpreted frame) 0x01a93ba0? ? ?  *
> > > > > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> > > > > sk.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$Sch
> > > > > eduledFutureTask)
> > > > > bci:1 line:180 (Interpreted frame)
> > > > > 0x01a93ba0? ? ?  *
> > > > > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTa
> > > > > sk.run()
> > > > > bci:37 line:294 (Interpreted frame)
> > > > > 0x01a94129? ? ?  *
> > > > > java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concur
> > > > > rent.ThreadPoolExecutor$Worker)
> > > > > bci:95 line:1142 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > java.util.concurrent.ThreadPoolExecutor$Worker.run() bci:5
> > > > > line:617 (Interpreted frame) 0x01a94129? ? ?  *
> > > > > java.lang.Thread.run() bci:11 line:744 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf724a6? ? ?  jvm!JVM_GetThreadStateNames + 0x46056
> > > > > 0x5bf72517? ? ?  jvm!JVM_GetThreadStateNames + 0x460c7
> > > > > 0x5bf1de0f? ? ?  jvm!jio_printf + 0x9f
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - <0x03d58650>, (a java/util/concurrent/
> > > > > ThreadPoolExecutor$Worker)
> > > > > ----------------- 6 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > ----------------- 7 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd9539? ? ?  jvm!_JVM_FindSignal at 4 + 0x5269
> > > > > 0x5bfd9607? ? ?  jvm!_JVM_FindSignal at 4 + 0x5337
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 8 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6c49? ? ?  jvm!_JVM_FindSignal at 4 + 0x2979
> > > > > 0x5bf7856b? ? ?  jvm!JVM_GetThreadStateNames + 0x4c11b
> > > > > 0x5bf78b23? ? ?  jvm!JVM_GetThreadStateNames + 0x4c6d3
> > > > > 0x5bf8e107? ? ?  jvm!JVM_GetThreadStateNames + 0x61cb7
> > > > > 0x5bf8e6be? ? ?  jvm!JVM_GetThreadStateNames + 0x6226e
> > > > > 0x5bf8e78f? ? ?  jvm!JVM_GetThreadStateNames + 0x6233f
> > > > > 0x5bee0d10? ? ?  jvm + 0xb0d10
> > > > > 0x5bee2854? ? ?  jvm + 0xb2854
> > > > > 0x5bee3548? ? ?  jvm + 0xb3548
> > > > > 0x5bea5641? ? ?  jvm + 0x75641
> > > > > 0x01aa17be? ? ?  *
> > > > > au.net.zeus.collection.ReferenceFactory.create(java.lang.Object,
> > > > > au.net.zeus.collection.RefQueue, au.net.zeus.collection.Ref)
> > > > > bci:229 line:60 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) bci:37 line:128 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceProcessor.referenced(java.lang.Object,
> > > > > boolean, boolean) bci:4 line:44 (Interpreted frame)
> > > > > 0x01a94089? ? ?  *
> > > > > au.net.zeus.collection.ReferenceMap.wrapKey(java.lang.Object,
> > > > > boolean, boolean) bci:7 line:248 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > au.net.zeus.collection.ReferenceConcurrentMap.putIfAbsent(java.lan
> > > > > g.Object,
> > > > > java.lang.Object) bci:8 line:67 (Interpreted frame)
> > > > > 0x01a94089? ? ?  *
> > > > > org.apache.river.api.security.CombinerSecurityManager.checkPermiss
> > > > > ion(java.security.Permission,
> > > > > java.lang.Object) bci:161 line:260 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTr
> > > > > ustPermission(java.lang.Class)
> > > > > bci:59 line:1848 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBea
> > > > > n(java.lang.Object,
> > > > > javax.management.ObjectName) bci:25 line:322 (Interpreted frame)
> > > > > 0x01a94089? ? ?  * com.sun.jmx.mbeanserver.JmxMBeanServer$2.run()
> > > > > bci:17 line:1225 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf299ed? ? ?  jvm!_JVM_DoPrivileged at 20 + 0x2bd
> > > > > 0x73b21047
> > > > > java_73b20000!_Java_java_security_AccessController_doPrivileged__L
> > > > > java_security_PrivilegedExceptionAction_2 at 12
> > > > > + 0x15
> > > > > 0x01a94054? ? ?  *
> > > > > com.sun.jmx.mbeanserver.JmxMBeanServer.initialize() bci:25
> > > > > line:1223 (Interpreted frame) 0x01a940f4? ? ?  *
> > > > > com.sun.jmx.mbeanserver.JmxMBeanServer.<init>(java.lang.String,
> > > > > javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate,
> > > > > com.sun.jmx.mbeanserver.MBeanInstantiator, boolean, boolean)
> > > > > bci:133 line:255 (Interpreted frame) 0x01a940f4? ? ?  *
> > > > > com.sun.jmx.mbeanserver.JmxMBeanServer.newMBeanServer(java.lang.String,
> > > > > javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate, boolean) bci:13 line:1437
> > > > > (Interpreted frame) 0x01a94054? ? ?  *
> > > > > javax.management.MBeanServerBuilder.newMBeanServer(java.lang.String,
> > > > > javax.management.MBeanServer,
> > > > > javax.management.MBeanServerDelegate) bci:4 line:110
> > > > > (Interpreted frame) 0x01a94054? ? ?  *
> > > > > javax.management.MBeanServerFactory.newMBeanServer(java.lang.String)
> > > > > bci:36 line:329 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > javax.management.MBeanServerFactory.createMBeanServer(java.lang.String)
> > > > > bci:6 line:231 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > javax.management.MBeanServerFactory.createMBeanServer() bci:1
> > > > > line:192 (Interpreted frame) 0x01a94054? ? ?  *
> > > > > java.lang.management.ManagementFactory.getPlatformMBeanServer()
> > > > > bci:29 line:468 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer()
> > > > > bci:66 line:518 (Interpreted frame)
> > > > > 0x01a94054? ? ?  * sun.management.Agent.startLocalManagementAgent()
> > > > > bci:13 line:138 (Interpreted frame)
> > > > > 0x01a940f4? ? ?  *
> > > > > sun.management.Agent.startAgent(java.util.Properties) bci:76
> > > > > line:260 (Interpreted frame) 0x01a940f4? ? ?  *
> > > > > sun.management.Agent.agentmain(java.lang.String) bci:45 line:128
> > > > > (Interpreted frame) 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5bf7e73a? ? ?  jvm!JVM_GetThreadStateNames + 0x522ea
> > > > > 0x5bf7e993? ? ?  jvm!JVM_GetThreadStateNames + 0x52543
> > > > > 0x5bf22b03? ? ?  jvm!_JVM_InvokeMethod at 16 + 0xb3
> > > > > 0x73b23a6e
> > > > > java_73b20000!_Java_sun_reflect_NativeMethodAccessorImpl_invoke0 at 20
> > > > > + 0x15
> > > > > 0x01a94054? ? ?  *
> > > > > sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object,
> > > > > java.lang.Object[]) bci:100 line:62 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object,
> > > > > java.lang.Object[]) bci:6 line:43 (Interpreted frame)
> > > > > 0x01a94089? ? ?  * java.lang.reflect.Method.invoke(java.lang.Object,
> > > > > java.lang.Object[]) bci:56 line:483 (Interpreted frame)
> > > > > 0x01a94054? ? ?  *
> > > > > sun.instrument.InstrumentationImpl.loadClassAndStartAgent(java.lan
> > > > > g.String,
> > > > > java.lang.String, java.lang.String) bci:192 line:388
> > > > > (Interpreted frame) 0x01a940f4? ? ?  *
> > > > > sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(java.
> > > > > lang.String,
> > > > > java.lang.String) bci:5 line:411 (Interpreted frame)
> > > > > 0x01a903d7 <StubRoutines>
> > > > > 0x5bf72285? ? ?  jvm!JVM_GetThreadStateNames + 0x45e35
> > > > > 0x5c0370be? ? ?  jvm!_JVM_FindSignal at 4 + 0x62dee
> > > > > 0x5bf7231e? ? ?  jvm!JVM_GetThreadStateNames + 0x45ece
> > > > > 0x5befe951? ? ?  jvm!JNI_GetCreatedJavaVMs + 0x71a1
> > > > > 0x5bf01788? ? ?  jvm!JNI_GetCreatedJavaVMs + 0x9fd8
> > > > > 0x6db62878? ? ?  instrument!Agent_OnAttach + 0x76b
> > > > > 0x6db63eea? ? ?  instrument!Agent_OnAttach + 0x1ddd
> > > > > 0x6db6234a? ? ?  instrument!Agent_OnAttach + 0x23d
> > > > > 0x5bf3c50c? ? ?  jvm!JVM_GetThreadStateNames + 0x100bc
> > > > > 0x5bf9b05e? ? ?  jvm!JVM_GetThreadStateNames + 0x6ec0e
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 9 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6b3d? ? ?  jvm!_JVM_FindSignal at 4 + 0x286d
> > > > > 0x5bf73ecc? ? ?  jvm!JVM_GetThreadStateNames + 0x47a7c
> > > > > 0x5bf7424a? ? ?  jvm!JVM_GetThreadStateNames + 0x47dfa
> > > > > 0x5be9253b? ? ?  jvm + 0x6253b
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 10 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6c49? ? ?  jvm!_JVM_FindSignal at 4 + 0x2979
> > > > > 0x5bf73ec1? ? ?  jvm!JVM_GetThreadStateNames + 0x47a71
> > > > > 0x5bf741fc? ? ?  jvm!JVM_GetThreadStateNames + 0x47dac
> > > > > 0x5bf829a5? ? ?  jvm!JVM_GetThreadStateNames + 0x56555
> > > > > 0x5bf945fc? ? ?  jvm!JVM_GetThreadStateNames + 0x681ac
> > > > > 0x5bf94e8a? ? ?  jvm!JVM_GetThreadStateNames + 0x68a3a
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > Locked ownable synchronizers:
> > > > > - None
> > > > > ----------------- 11 -----------------
> > > > > 0x77c870f4? ? ?  ntdll!KiFastSystemCallRet
> > > > > 0x76a9c3d3? ? ?  kernel32!WaitForSingleObjectEx + 0x43
> > > > > 0x76a9c382? ? ?  kernel32!WaitForSingleObject + 0x12
> > > > > 0x5bfd6b3d? ? ?  jvm!_JVM_FindSignal at 4 + 0x286d
> > > > > 0x5bf73ecc? ? ?  jvm!JVM_GetThreadStateNames + 0x47a7c
> > > > > 0x5bf741fc? ? ?  jvm!JVM_GetThreadStateNames + 0x47dac
> > > > > 0x5bf8f904? ? ?  jvm!JVM_GetThreadStateNames + 0x634b4
> > > > > 0x5bf8f9a7? ? ?  jvm!JVM_GetThreadStateNames + 0x63557
> > > > > 0x5bfd9186? ? ?  jvm!_JVM_FindSignal at 4 + 0x4eb6
> > > > > 0x614dc556? ? ?  msvcr100!_endthreadex + 0x3a
> > > > > 0x614dc600? ? ?  msvcr100!_endthreadex + 0xe4
> > > > > 0x76a9ee1c? ? ?  kernel32!BaseThreadInitThunk + 0x12
> > > > > 0x77ca37eb? ? ?  ntdll!RtlInitializeExceptionChain + 0xef
> > > > > 0x77ca37be? ? ?  ntdll!RtlInitializeExceptionChain + 0xc2
> > > > > 
> > > > > 
> > > > > _______________________________________________
> > > > > Concurrency-interest mailing list
> > > > > Concurrency-interest at cs.oswego.edu
> > > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > > > 
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at cs.oswego.edu
> > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > > 
> > > 
> > > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140625/a559bb46/attachment-0001.html>

From peter.levart at gmail.com  Tue Jun 24 17:35:37 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Tue, 24 Jun 2014 23:35:37 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <CA+kOe0-Ke7JF+HimqL2M8Dr=0c4-ux8YCOMRAZi_3k_su8F8Pw@mail.gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>	<53A3FA72.3060706@gmail.com>	<53A418F2.3080201@gmail.com>	<53A43055.5070803@oracle.com>	<53A43EF3.8000206@gmail.com>	<53A44C3A.6000607@oracle.com>	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>	<CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>	<53A98525.9080908@gmail.com>
	<CA+kOe0-Ke7JF+HimqL2M8Dr=0c4-ux8YCOMRAZi_3k_su8F8Pw@mail.gmail.com>
Message-ID: <53A9EF29.7030208@gmail.com>


On 06/24/2014 06:01 PM, Martin Buchholz wrote:
>
>
>
> On Tue, Jun 24, 2014 at 7:03 AM, Peter Levart <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>> wrote:
>
>
>     I would rather use SecureRandom.generateSeed() instance method
>     instead of SecureRandom.nextBytes(). Why? Because every
>     SecureRandom instance has to initialize it's seed 1st before
>     getBytes() can provide the next random bytes from the PRNG. Since
>     we only need the 1st 8 bytes from the SecureRandom instance to
>     initialize TLR's seeder, we might as well directly call the
>     SecureRandom.generateSeed() method.
>
>
> If I strace this program on Linux using strace -ff -q java SecureRandoms:
>
> public class SecureRandoms {
>     public static void main(String[] args) throws Throwable {
>         byte[] bytes = new byte[8];
>         new java.security.SecureRandom().nextBytes(bytes);
>     }
> }
>
> I see a read from /dev/urandom, but not from /dev/random, so I 
> conclude your intuitive understanding of how the seeding works must be 
> wrong.  It makes sense that NativePRNG doesn't need to do any special 
> seeding of its own, since it reuses the operating system's.

You're right. I checked again. The  NativePRNG is actually using 
/dev/urandom (by default unless java.security.egd or securerandom.source 
is defined). It's mixing the /dev/urandom stream with the stream 
obtained from SHA1 generator which is seeded by 20 bytes from 
/dev/urandom too. So by default yes, plain NativePRNG (the default on 
UNIX-es) is using /dev/urandom for nextBytes(), but this can be changed 
by defining java.security.egd or securerandom.source system property. I 
still think that for configuration-independent PRNG seed on UNIX-es it's 
better to invoke generateSeed() on NativePRNG$NonBlocking, which 
hard-codes /dev/urandom and doesn't mix it with SHA1 stream.

On Windows, there's a different story, since the default SecureRandom 
algorithm is SHA1, seeded by SeedGenerator.getSystemEntropy() and 
SeedGenerator.generateSeed(). The former call includes invoking 
networking code and resolving local host name. Which we would like to 
avoid. So I think we need a nicer story on windows then just: new 
SecureRandom().nextBytes(). I propose requesting explicit algorithm / 
provider on each particular platform that we know does best what we 
want, rather than using default which can still be used as a fall-back.

Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140624/8de51882/attachment.html>

From radhakrishnan.mohan at gmail.com  Wed Jun 25 01:17:24 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 25 Jun 2014 10:47:24 +0530
Subject: [concurrency-interest] micro-benchmark for concurrent
	collections
Message-ID: <CAOoXFP88zyfVfOyfqqEX+ZU0VkMPdOo4PmDO_fw5DC0rLCtGsg@mail.gmail.com>

I came across this JMH harness on another list.

https://github.com/goldmansachs/gs-collections/releases

Thanks,
Mohan


On Tue, Jun 24, 2014 at 11:20 PM, Andrig Miller <anmiller at redhat.com> wrote:

> Okay, great.  I'll check them out.
>
> Andy
>
> ------------------------------
>
> *From: *"Martin Buchholz" <martinrb at google.com>
> *To: *"Andrig Miller" <anmiller at redhat.com>
> *Cc: *"Concurrency-interest" <Concurrency-interest at cs.oswego.edu>
> *Sent: *Tuesday, June 24, 2014 11:38:39 AM
> *Subject: *Re: [concurrency-interest] micro-benchmark for concurrent
> collections
>
>
> Both jsr166 cvs and guava source contains benchmarks that are at least
> close to what you are looking for.
>
>
> On Sun, Jun 22, 2014 at 8:39 AM, Andrig Miller <anmiller at redhat.com>
> wrote:
>
>> I was wondering if anyone new of a good micro-benchmark for the
>> concurrent collections?  I specifically would like to benchmark
>> ConcurrentHashMap, against an alternative implementation.  A JMH based one
>> would be preferable.
>>
>> Thanks.
>>
>> --
>> Andrig (Andy) Miller
>> Global Platform Director for JBoss Middle-ware
>> Red Hat, Inc.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140625/b1ef55fe/attachment.html>

From anmiller at redhat.com  Wed Jun 25 10:41:04 2014
From: anmiller at redhat.com (Andrig Miller)
Date: Wed, 25 Jun 2014 10:41:04 -0400 (EDT)
Subject: [concurrency-interest] micro-benchmark for
	concurrent	collections
In-Reply-To: <CAOoXFP88zyfVfOyfqqEX+ZU0VkMPdOo4PmDO_fw5DC0rLCtGsg@mail.gmail.com>
References: <CAOoXFP88zyfVfOyfqqEX+ZU0VkMPdOo4PmDO_fw5DC0rLCtGsg@mail.gmail.com>
Message-ID: <11385138.698.1403707261336.JavaMail.andrig@worklaptop.miller.org>

Yes, I saw that one too, but thanks. 

Andy 

----- Original Message -----

> From: "Mohan Radhakrishnan" <radhakrishnan.mohan at gmail.com>
> To: Concurrency-interest at cs.oswego.edu
> Sent: Tuesday, June 24, 2014 11:17:24 PM
> Subject: Re: [concurrency-interest] micro-benchmark for concurrent
> collections

> I came across this JMH harness on another list.

> https://github.com/goldmansachs/gs-collections/releases

> Thanks,
> Mohan

> On Tue, Jun 24, 2014 at 11:20 PM, Andrig Miller < anmiller at redhat.com
> > wrote:

> > Okay, great. I'll check them out.
> 

> > Andy
> 

> > > From: "Martin Buchholz" < martinrb at google.com >
> > 
> 
> > > To: "Andrig Miller" < anmiller at redhat.com >
> > 
> 
> > > Cc: "Concurrency-interest" < Concurrency-interest at cs.oswego.edu >
> > 
> 
> > > Sent: Tuesday, June 24, 2014 11:38:39 AM
> > 
> 
> > > Subject: Re: [concurrency-interest] micro-benchmark for
> > > concurrent
> > > collections
> > 
> 

> > > Both jsr166 cvs and guava source contains benchmarks that are at
> > > least close to what you are looking for.
> > 
> 

> > > On Sun, Jun 22, 2014 at 8:39 AM, Andrig Miller <
> > > anmiller at redhat.com
> > > > wrote:
> > 
> 

> > > > I was wondering if anyone new of a good micro-benchmark for the
> > > > concurrent collections? I specifically would like to benchmark
> > > > ConcurrentHashMap, against an alternative implementation. A JMH
> > > > based one would be preferable.
> > > 
> > 
> 

> > > > Thanks.
> > > 
> > 
> 

> > > > --
> > > 
> > 
> 

> > > > Andrig (Andy) Miller
> > > 
> > 
> 
> > > > Global Platform Director for JBoss Middle-ware
> > > 
> > 
> 
> > > > Red Hat, Inc.
> > > 
> > 
> 

> > > > _______________________________________________
> > > 
> > 
> 
> > > > Concurrency-interest mailing list
> > > 
> > 
> 
> > > > Concurrency-interest at cs.oswego.edu
> > > 
> > 
> 
> > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > 
> > 
> 

> > _______________________________________________
> 
> > Concurrency-interest mailing list
> 
> > Concurrency-interest at cs.oswego.edu
> 
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140625/868d93ad/attachment.html>

From peter.levart at gmail.com  Wed Jun 25 13:41:57 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 25 Jun 2014 19:41:57 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53A9EF29.7030208@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>	<53A3FA72.3060706@gmail.com>	<53A418F2.3080201@gmail.com>	<53A43055.5070803@oracle.com>	<53A43EF3.8000206@gmail.com>	<53A44C3A.6000607@oracle.com>	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>	<CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>	<53A98525.9080908@gmail.com>
	<CA+kOe0-Ke7JF+HimqL2M8Dr=0c4-ux8YCOMRAZi_3k_su8F8Pw@mail.gmail.com>
	<53A9EF29.7030208@gmail.com>
Message-ID: <53AB09E5.9070303@gmail.com>

To sum-up: We have a problem with TLR initialization since by default it 
uses networking code to compute initial "seeder" value which can execute 
user code in at least two situations:

- when "sun.net.spi.nameservice.provider" system property is defined to 
use custom NameService provider
- when custom SecurityManager is in effect while TLR is being initialized
- also, when "java.util.secureRandomSeed" is defined, at least on 
Windows this means that default SecureRandom algorithm will be using 
networking code too to gather system entropy

We could work-around these problems by delaying initialization of 
NameService provider(s), by-passing SecurityManager when obtaining MAC 
address from NetworkInterface and extending the semantics of 
"java.util.secureRandomSeed" property to specify explicit SecureRandom 
algorithm and provider to use when obtaining SecureRandom instance, like 
in the following patch:

http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR.initialSeed/webrev.01/

But on the other hand this seems too many knobs to worry about. Ideally 
one would like to always use OS provided native seed source, but 
SecureRandom (with all the security providers infrastructure) seems too 
heavy-weight to be used in classes like ThreadLocalRandom or 
SplittableRandom by default since they can be initialized very early in 
the start-up sequence. I made an experiment with class-loading. Recent 
JDK9 build loads 381 classes when running the following empty program on 
Linux:

public class test0 {
         public static void main(String[] args) {
         }
}

...ThreadLocalRandom is not among them. But in special configurations 
(like when using java agents) or in the future, it could be. The 
following program:

public class test {
         public static void main(String[] args) {
                 java.util.concurrent.ThreadLocalRandom.current();
         }
}

...loads 403 classes. That's 22 more than an empty program. The 
following classes are loaded in addition:

+ java.util.Random
+ java.util.concurrent.ThreadLocalRandom
+ java.net.NetworkInterface
+ java.net.NetworkInterface$1
+ java.net.InterfaceAddress
+ java.net.InetAddress
+ sun.security.action.GetBooleanAction
+ java.net.InetAddress$1
+ java.net.InetAddress$InetAddressHolder
+ java.net.InetAddress$Cache
+ java.net.InetAddress$Cache$Type
+ java.net.InetAddressImplFactory
+ java.net.InetAddressImpl
+ java.net.Inet6AddressImpl
+ sun.net.spi.nameservice.NameService
+ java.net.InetAddress$2
+ java.net.Inet4Address
+ java.net.Inet6Address
+ java.net.Inet6Address$Inet6AddressHolder
+ java.net.DefaultInterface
+ java.net.NetworkInterface$2
+ sun.nio.ch.Interruptible

If I run the same program but set the "java.util.secureRandomSeed=true", 
it loads 435 classes. Besides 381 classes loaded by an empty program, 
the following 54 classes are loaded in addition:

+ java.util.Random
+ java.util.concurrent.ThreadLocalRandom
+ java.security.SecureRandom
+ sun.security.jca.Providers
+ java.lang.InheritableThreadLocal
+ sun.security.jca.ProviderList
+ sun.security.jca.ProviderConfig
+ java.security.Provider
+ sun.security.jca.ProviderList$3
+ sun.security.jca.ProviderList$1
+ java.security.Provider$ServiceKey
+ java.security.Provider$EngineDescription
+ sun.misc.FloatingDecimal
+ sun.misc.FloatingDecimal$BinaryToASCIIConverter
+ sun.misc.FloatingDecimal$ExceptionalBinaryToASCIIBuffer
+ sun.misc.FloatingDecimal$BinaryToASCIIBuffer
+ sun.misc.FloatingDecimal$1
+ sun.misc.FloatingDecimal$ASCIIToBinaryConverter
+ sun.misc.FloatingDecimal$PreparedASCIIToBinaryBuffer
+ sun.misc.FDBigInteger
+ sun.security.jca.ProviderList$2
+ java.security.Security
+ java.security.Security$1
+ java.util.Properties$LineReader
+ java.util.AbstractList$Itr
+ sun.security.jca.ProviderConfig$2
+ sun.security.provider.Sun
+ sun.security.provider.SunEntries
+ sun.security.provider.SunEntries$1
+ java.security.SecureRandomSpi
+ sun.security.provider.NativePRNG
+ sun.security.provider.NativePRNG$Variant
+ sun.security.provider.NativePRNG$1
+ sun.security.provider.NativePRNG$2
+ java.net.URI
+ java.net.URI$Parser
+ sun.security.provider.NativePRNG$RandomIO
+ sun.security.provider.NativePRNG$Blocking
+ sun.security.provider.NativePRNG$NonBlocking
+ java.util.LinkedHashMap$LinkedEntrySet
+ java.util.LinkedHashMap$LinkedHashIterator
+ java.util.LinkedHashMap$LinkedEntryIterator
+ java.security.Provider$Service
+ java.security.Provider$UString
+ java.util.LinkedHashSet
+ java.util.LinkedHashMap$LinkedValues
+ java.util.LinkedHashMap$LinkedValueIterator
+ java.util.Collections$UnmodifiableSet
+ java.util.Collections$UnmodifiableCollection$1
+ java.util.LinkedHashMap$LinkedKeySet
+ java.util.LinkedHashMap$LinkedKeyIterator
+ sun.security.jca.GetInstance
+ sun.security.jca.GetInstance$Instance
+ sun.nio.ch.Interruptible


This seems too heavy-weight even if the initialization issue on Windows 
where default SecureRandom algorithm is using networking code to gather 
system entropy is worked-around by requesting explicit "Windows-PRNG" 
SecureRandom algorithm from "SunMSCAPI" provider.

Peeking around in the sun.security.provider package, I found there 
already is a minimal internal infrastructure for obtaining random seed. 
It's encapsulated in package-private abstract class 
sun.security.provider.SeedGenerator with 4 implementations. It turns out 
that, besides Java-only fall-back implementation called 
ThreadedSeedGenerator and generic URLSeedGenerator, there are also two 
implementations of NativeSeedGenerator (one for UNIX-es which is just an 
extension of URLSeedGenerator and the other for Windows which uses MS 
CryptoAPI). I made a few tweaks that allow this sub-infrastructure to be 
used directly in ThreadLocalRandom and SplittableRandom:

http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/

The changes are as follows:
- modified SeedGenerator to be a public class (was package-private as 
are still all it's subclasses)
- made its only public static method package-private (was public for no 
reason)
- made its only abstract method public (was package-private)
- made SeedGenerator implement AutoCloseable with empty close() method 
(overriden in URLSeedGenerator to close the underlying stream)
- added public static factory method to return a new instance of 
NativeSeedGenerator (using /dev/urandom on UNIX-es, MSCAPI on Windows) 
and protected it with a runtime check so that it can only be used internally

With these changes and modified TLR, running the test program (see 
above) loads only the following 15 additional classes besides those that 
are loaded by an empty program on Linux (and I assume the number is the 
same on Windows):


+ java.util.Random
+ java.util.concurrent.ThreadLocalRandom
+ sun.security.provider.SeedGenerator
+ sun.security.provider.SunEntries
+ sun.security.provider.SunEntries$1
+ java.security.Security
+ java.security.Security$1
+ java.util.Properties$LineReader
+ sun.security.provider.SeedGenerator$URLSeedGenerator
+ sun.security.provider.NativeSeedGenerator
+ sun.security.provider.SeedGenerator$1
+ sun.security.provider.SeedGenerator$URLSeedGenerator$1
+ java.net.URI
+ java.net.URI$Parser
+ sun.nio.ch.Interruptible


So what do you think is the best direction to go further with this? 
Patching networking or exposing NativeSeedGenerator to internal JDK code?


Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140625/9734239b/attachment.html>

From dms at sosnoski.com  Wed Jun 25 21:05:11 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Thu, 26 Jun 2014 13:05:11 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <539BB459.2040600@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
Message-ID: <53AB71C7.3080006@sosnoski.com>

On 06/14/2014 02:32 PM, Arcadiy Ivanov wrote:
> If memory serves me right, Mr Shipilev mentioned in one of his 
> presentations in Oracle Spb DC re FJP optimization challenges (in 
> Russian, sorry, https://www.youtube.com/watch?v=t0dGLFtRR9c#t=3096) 
> that thread scheduling overhead of "sane OSes" (aka Linux) is approx 
> 50 us on average, while 'certain not-quite-sane OS named starting with 
> "W"' is much more than that.
> Loaded Linux kernel can produce latencies in *tens of seconds* 
> (http://www.versalogic.com/downloads/whitepapers/real-time_linux_benchmark.pdf, 
> page 13) without RT patches, and tens of us with RT ones. YMMV 
> dramatically depending on kernel, kernel version, scheduler, 
> architecture and load.
>

I actually found that Windows 7 did much better at thread switching 
performance than my Linux system with same-era kernel when running on my 
laptop system (Windows 7 Home Premium, Linux 3.4.63,Toshiba Satellite 
P750D with AMD A8-3520M APU). You can see my timing results here: 
http://www.sosnoski.com/thread-linux-windows.png The data block size 
relates to a block of per-thread data run though on every thread switch 
to show caching effects. Threads are executed in strict rotation, each 
notifying the next to run. The actual code is at: 
https://github.com/dsosnoski/concur3/blob/master/src/com/sosnoski/concur/article3/ThreadSwitch.java

So now I'm wondering if recent Windows versions actually have lower 
thread switching overhead in general, or if there are perhaps some 
OS-specific optimizations for the particular hardware (the Windows 
installation came with the laptop; I added Linux myself, generic 
OpenSUSE without any optimizations). Anyone have any thoughts on this?

Thanks,

   - Dennis

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140626/24c5a6b1/attachment.html>

From arcadiy at ivanov.biz  Wed Jun 25 21:35:21 2014
From: arcadiy at ivanov.biz (Arcadiy Ivanov)
Date: Wed, 25 Jun 2014 21:35:21 -0400
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <53AB71C7.3080006@sosnoski.com>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<53AB71C7.3080006@sosnoski.com>
Message-ID: <53AB78D9.3050503@ivanov.biz>

Based on what I've read in the benchmark code supplied, I have a 
sneaking suspicion that the problem is the benchmark itself, since I'm 
not sure it's measuring "thread switching performance". :)

I would *highly* recommend talking to Aleksey about using JMH for all 
your benchmarking needs and would, personally, dramatically simplify the 
benchmark by using exclusively LockSupport.park/unpark if your intention 
is to measure thread parking/unparking time.

Be aware, that System.nanoTime (I would not recommend measuring anything 
faster than your average human heartbeat with System.currentTimeMillis() 
- resolution is 1ms at best) performs weirdly under contention 
(http://shipilev.net/blog/2014/nanotrusting-nanotime/). I.e. you may not 
be able to measure what you want to measure using Java benchmark to 
begin with and may need lower level native OS/CPU metrics tools.

Also, I haven't looked at or, frankly, used synchronized in quite a 
while, but I think it results, assuming lock elision doesn't kick in, in 
libc mutexes of some sort (pthread? libthread? win32 mutex?), i.e. you 
may be measuring lock performance in a libc on the specific OSes, not 
thread switching performance.

Hope this helps,

- Arcadiy

On 2014-06-25 21:05, Dennis Sosnoski wrote:
> On 06/14/2014 02:32 PM, Arcadiy Ivanov wrote:
>> If memory serves me right, Mr Shipilev mentioned in one of his 
>> presentations in Oracle Spb DC re FJP optimization challenges (in 
>> Russian, sorry, https://www.youtube.com/watch?v=t0dGLFtRR9c#t=3096) 
>> that thread scheduling overhead of "sane OSes" (aka Linux) is approx 
>> 50 us on average, while 'certain not-quite-sane OS named starting 
>> with "W"' is much more than that.
>> Loaded Linux kernel can produce latencies in *tens of seconds* 
>> (http://www.versalogic.com/downloads/whitepapers/real-time_linux_benchmark.pdf, 
>> page 13) without RT patches, and tens of us with RT ones. YMMV 
>> dramatically depending on kernel, kernel version, scheduler, 
>> architecture and load.
>>
>
> I actually found that Windows 7 did much better at thread switching 
> performance than my Linux system with same-era kernel when running on 
> my laptop system (Windows 7 Home Premium, Linux 3.4.63,Toshiba 
> Satellite P750D with AMD A8-3520M APU). You can see my timing results 
> here: http://www.sosnoski.com/thread-linux-windows.png The data block 
> size relates to a block of per-thread data run though on every thread 
> switch to show caching effects. Threads are executed in strict 
> rotation, each notifying the next to run. The actual code is at: 
> https://github.com/dsosnoski/concur3/blob/master/src/com/sosnoski/concur/article3/ThreadSwitch.java
>
> So now I'm wondering if recent Windows versions actually have lower 
> thread switching overhead in general, or if there are perhaps some 
> OS-specific optimizations for the particular hardware (the Windows 
> installation came with the laptop; I added Linux myself, generic 
> OpenSUSE without any optimizations). Anyone have any thoughts on this?
>
> Thanks,
>
>   - Dennis
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140625/32f83a60/attachment-0001.html>

From dms at sosnoski.com  Thu Jun 26 08:08:45 2014
From: dms at sosnoski.com (Dennis Sosnoski)
Date: Fri, 27 Jun 2014 00:08:45 +1200
Subject: [concurrency-interest] Blocking vs. non-blocking
In-Reply-To: <53AB78D9.3050503@ivanov.biz>
References: <539B8AD4.8090702@sosnoski.com>	<539B8FEE.8030107@cs.oswego.edu>	<539B9CAE.3010705@sosnoski.com>	<CAHjP37FxTqDGB+xxNJVY1mqJAXr3OrLwL9tQVbqPxGu0m3DY=w@mail.gmail.com>
	<539BAA7A.1020007@sosnoski.com> <539BB459.2040600@ivanov.biz>
	<53AB71C7.3080006@sosnoski.com> <53AB78D9.3050503@ivanov.biz>
Message-ID: <53AC0D4D.1050908@sosnoski.com>

On 06/26/2014 01:35 PM, Arcadiy Ivanov wrote:
> Based on what I've read in the benchmark code supplied, I have a 
> sneaking suspicion that the problem is the benchmark itself, since I'm 
> not sure it's measuring "thread switching performance". :)
>
> I would *highly* recommend talking to Aleksey about using JMH for all 
> your benchmarking needs and would, personally, dramatically simplify 
> the benchmark by using exclusively LockSupport.park/unpark if your 
> intention is to measure thread parking/unparking time.

I'm really looking to get a handle on the overhead involved in blocking 
thread switches. To make this more representative of actual blocking 
operations of the type I'm interested in I've switched the code at 
https://github.com/dsosnoski/concur3/blob/master/src/com/sosnoski/concur/article3/ThreadSwitchCompletable.java 
over to using CompletableFutures for switching between threads, with 
each thread completing the future the next thread is waiting on when the 
first thread is done. That did lower the overhead significantly, so 
clearly CompletableFuture is using more efficient handling than the 
crude old synchronized block approach. If you're interested, you can see 
a comparison between the CompletableFuture and synchronized versions at 
http://sosnoski.com/threads-linux-notebook.png I didn't bother rerunning 
the timing on Windows.

I considered JMH to be overkill for this case, where I want some simple 
standalone code, but I'll definitely give it a try in the future.

>
> Be aware, that System.nanoTime (I would not recommend measuring 
> anything faster than your average human heartbeat with 
> System.currentTimeMillis() - resolution is 1ms at best) performs 
> weirdly under contention 
> (http://shipilev.net/blog/2014/nanotrusting-nanotime/). I.e. you may 
> not be able to measure what you want to measure using Java benchmark 
> to begin with and may need lower level native OS/CPU metrics tools.

In this case the time measurements are in seconds, so 
currentTimeMillis() resolution or accuracy is really not an issue - but 
I changed the code to use nanoTime() and ran a comparison just to make sure.

Thanks,

   - Dennis

>
> Also, I haven't looked at or, frankly, used synchronized in quite a 
> while, but I think it results, assuming lock elision doesn't kick in, 
> in libc mutexes of some sort (pthread? libthread? win32 mutex?), i.e. 
> you may be measuring lock performance in a libc on the specific OSes, 
> not thread switching performance.
>
> Hope this helps,
>
> - Arcadiy
>
> On 2014-06-25 21:05, Dennis Sosnoski wrote:
>> On 06/14/2014 02:32 PM, Arcadiy Ivanov wrote:
>>> If memory serves me right, Mr Shipilev mentioned in one of his 
>>> presentations in Oracle Spb DC re FJP optimization challenges (in 
>>> Russian, sorry, https://www.youtube.com/watch?v=t0dGLFtRR9c#t=3096) 
>>> that thread scheduling overhead of "sane OSes" (aka Linux) is approx 
>>> 50 us on average, while 'certain not-quite-sane OS named starting 
>>> with "W"' is much more than that.
>>> Loaded Linux kernel can produce latencies in *tens of seconds* 
>>> (http://www.versalogic.com/downloads/whitepapers/real-time_linux_benchmark.pdf, 
>>> page 13) without RT patches, and tens of us with RT ones. YMMV 
>>> dramatically depending on kernel, kernel version, scheduler, 
>>> architecture and load.
>>>
>>
>> I actually found that Windows 7 did much better at thread switching 
>> performance than my Linux system with same-era kernel when running on 
>> my laptop system (Windows 7 Home Premium, Linux 3.4.63,Toshiba 
>> Satellite P750D with AMD A8-3520M APU). You can see my timing results 
>> here: http://www.sosnoski.com/thread-linux-windows.png The data block 
>> size relates to a block of per-thread data run though on every thread 
>> switch to show caching effects. Threads are executed in strict 
>> rotation, each notifying the next to run. The actual code is at: 
>> https://github.com/dsosnoski/concur3/blob/master/src/com/sosnoski/concur/article3/ThreadSwitch.java
>>
>> So now I'm wondering if recent Windows versions actually have lower 
>> thread switching overhead in general, or if there are perhaps some 
>> OS-specific optimizations for the particular hardware (the Windows 
>> installation came with the laptop; I added Linux myself, generic 
>> OpenSUSE without any optimizations). Anyone have any thoughts on this?
>>
>> Thanks,
>>
>>   - Dennis
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/45dae2d9/attachment.html>

From dl at cs.oswego.edu  Thu Jun 26 19:10:22 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 26 Jun 2014 19:10:22 -0400
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53AB09E5.9070303@gmail.com>
References: <CA+kOe0_L6Yka6jc00ja3LM3Kk2PHMkXnDtpAns=TZMsjgWF_+A@mail.gmail.com>	<53A29DC5.1030605@oracle.com>	<CA+kOe0-FUP_yB8wCh6xTZXmsWnGqbZngJJuOj4vGSqd4YZGZFQ@mail.gmail.com>	<53A3FA72.3060706@gmail.com>	<53A418F2.3080201@gmail.com>	<53A43055.5070803@oracle.com>	<53A43EF3.8000206@gmail.com>	<53A44C3A.6000607@oracle.com>	<CA+kOe0_P9H0bKcfsCdzwrPRcohFPhwguS=oUm1JQgrStM0UTLw@mail.gmail.com>	<CA+kOe08DZN01JLyVGjWrqNRLkbr92f6AA4EVOZh2jxaaBmCp_w@mail.gmail.com>	<53A98525.9080908@gmail.com>	<CA+kOe0-Ke7JF+HimqL2M8Dr=0c4-ux8YCOMRAZi_3k_su8F8Pw@mail.gmail.com>	<53A9EF29.7030208@gmail.com>
	<53AB09E5.9070303@gmail.com>
Message-ID: <53ACA85E.2030407@cs.oswego.edu>


Peter: Thanks very much for attacking the shocking impact/complexity
of getting a few seed bits.

On 06/25/2014 01:41 PM, Peter Levart wrote:
>
> Peeking around in the sun.security.provider package, I found there already is a
> minimal internal infrastructure for obtaining random seed. It's encapsulated in
> package-private abstract class sun.security.provider.SeedGenerator with 4
> implementations. It turns out that, besides Java-only fall-back implementation
> called ThreadedSeedGenerator and generic URLSeedGenerator, there are also two
> implementations of NativeSeedGenerator (one for UNIX-es which is just an
> extension of URLSeedGenerator and the other for Windows which uses MS
> CryptoAPI). I made a few tweaks that allow this sub-infrastructure to be used
> directly in ThreadLocalRandom and SplittableRandom:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/
>

This seems to be the best idea yet, assuming that people are OK
with the changes to sun.security.provider.SeedGenerator and
NativeSeedGenerator.java

-Doug




From dt at flyingtroika.com  Fri Jun 27 00:08:26 2014
From: dt at flyingtroika.com (DT)
Date: Thu, 26 Jun 2014 21:08:26 -0700
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation to
 handle priority based Callable tasks
Message-ID: <53ACEE3A.5090201@flyingtroika.com>

If we were to control Callable Tasks with Priorities and to manage 
execution of those callable tasks through ThreadPoolExecutor we would 
have to implement custom ThreadPoolExecutor and PriorityCallable (see a 
suggestion below). What other ways to accomplish this do you see ?

public interface PriorityCallable extends Callable<Object> {
     public abstract void setPriority(int priority);
     ...
}

public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
...
...
public <T> List<Future<T>> customInvokeAll(
                 Collection<? extends Callable<T>> tasks, long timeout, 
TimeUnit unit) // pass PriorityCallable
                 throws InterruptedException {
             if (tasks == null || unit == null)
                 throw new NullPointerException();
             long nanos = unit.toNanos(timeout);
             List<Future<T>> futures = new 
ArrayList<Future<T>>(tasks.size());
             boolean done = false;
             try {
                 // handle Priority based Callable tasks here, though 
can expect timing issues
                 // custom logic to group Callable tasks , if (priority 
== 1, 2, 3 create group of callables, etc )
                 for (Callable<T> t : tasks)
                     futures.add(newTaskFor(t));

                 long lastTime = System.nanoTime();

                 // Interleave time checks and calls to execute in case
                 // executor doesn't have any/much parallelism.
                 Iterator<Future<T>> it = futures.iterator();
                 while (it.hasNext()) {
                     execute((Runnable)(it.next())); // should we expect 
futures get executed within the same timeframe for Callables with 
different priorities
                     long now = System.nanoTime();
                     nanos -= now - lastTime;
                     lastTime = now;
                     if (nanos <= 0)
                         return futures;
                 }

                 for (Future<T> f : futures) {
                     if (!f.isDone()) {
                         if (nanos <= 0)
                             return futures;
                         try {
                             f.get(nanos, TimeUnit.NANOSECONDS);
                         } catch (CancellationException ignore) {
                         } catch (ExecutionException ignore) { // Should 
we cancel tasks based on the priority as well?
                         } catch (TimeoutException toe) {
                             return futures;
                         }
                         long now = System.nanoTime();
                         nanos -= now - lastTime;
                         lastTime = now;
                     }
                 }
                 done = true;
                 return futures;
             } finally {
                 if (!done)
                     for (Future<T> f : futures)
                         f.cancel(true);
             }
         }
...
}

Thank you,
dt
http://www.flyingtroika.com/


From davidcholmes at aapt.net.au  Fri Jun 27 00:16:15 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 27 Jun 2014 14:16:15 +1000
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
	to handle priority based Callable tasks
In-Reply-To: <53ACEE3A.5090201@flyingtroika.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEGMKHAA.davidcholmes@aapt.net.au>

Can't you just use your PriorityCallable with a custom PriorityQueue and
standard ThreadPoolExecutor?

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of DT
> Sent: Friday, 27 June 2014 2:08 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
> to handle priority based Callable tasks
>
>
> If we were to control Callable Tasks with Priorities and to manage
> execution of those callable tasks through ThreadPoolExecutor we would
> have to implement custom ThreadPoolExecutor and PriorityCallable (see a
> suggestion below). What other ways to accomplish this do you see ?
>
> public interface PriorityCallable extends Callable<Object> {
>      public abstract void setPriority(int priority);
>      ...
> }
>
> public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
> ...
> ...
> public <T> List<Future<T>> customInvokeAll(
>                  Collection<? extends Callable<T>> tasks, long timeout,
> TimeUnit unit) // pass PriorityCallable
>                  throws InterruptedException {
>              if (tasks == null || unit == null)
>                  throw new NullPointerException();
>              long nanos = unit.toNanos(timeout);
>              List<Future<T>> futures = new
> ArrayList<Future<T>>(tasks.size());
>              boolean done = false;
>              try {
>                  // handle Priority based Callable tasks here, though
> can expect timing issues
>                  // custom logic to group Callable tasks , if (priority
> == 1, 2, 3 create group of callables, etc )
>                  for (Callable<T> t : tasks)
>                      futures.add(newTaskFor(t));
>
>                  long lastTime = System.nanoTime();
>
>                  // Interleave time checks and calls to execute in case
>                  // executor doesn't have any/much parallelism.
>                  Iterator<Future<T>> it = futures.iterator();
>                  while (it.hasNext()) {
>                      execute((Runnable)(it.next())); // should we expect
> futures get executed within the same timeframe for Callables with
> different priorities
>                      long now = System.nanoTime();
>                      nanos -= now - lastTime;
>                      lastTime = now;
>                      if (nanos <= 0)
>                          return futures;
>                  }
>
>                  for (Future<T> f : futures) {
>                      if (!f.isDone()) {
>                          if (nanos <= 0)
>                              return futures;
>                          try {
>                              f.get(nanos, TimeUnit.NANOSECONDS);
>                          } catch (CancellationException ignore) {
>                          } catch (ExecutionException ignore) { // Should
> we cancel tasks based on the priority as well?
>                          } catch (TimeoutException toe) {
>                              return futures;
>                          }
>                          long now = System.nanoTime();
>                          nanos -= now - lastTime;
>                          lastTime = now;
>                      }
>                  }
>                  done = true;
>                  return futures;
>              } finally {
>                  if (!done)
>                      for (Future<T> f : futures)
>                          f.cancel(true);
>              }
>          }
> ...
> }
>
> Thank you,
> dt
> http://www.flyingtroika.com/
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Fri Jun 27 06:12:04 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 27 Jun 2014 12:12:04 +0200
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEGMKHAA.davidcholmes@aapt.net.au>
References: <53ACEE3A.5090201@flyingtroika.com>
	<NFBBKALFDCPFIDBNKAPCOEGMKHAA.davidcholmes@aapt.net.au>
Message-ID: <CANPzfU_zfcQocw7NJvbktw6P5pW2Fcyjes33C=a8iFRe53U6eA@mail.gmail.com>

"  public abstract void setPriority(int priority);" ? Changing priority on
an already submitted task seems strange.

I agree with David, just use a PriorityBlockingQueue [
http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
for the submission queue of the TPE and provide a Comparator that checks
for your PriorityCallable and puts non-PriorityCallable-Callables at an
appropriate default priority.


On Fri, Jun 27, 2014 at 6:16 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

> Can't you just use your PriorityCallable with a custom PriorityQueue and
> standard ThreadPoolExecutor?
>
> David
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of DT
> > Sent: Friday, 27 June 2014 2:08 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
> > to handle priority based Callable tasks
> >
> >
> > If we were to control Callable Tasks with Priorities and to manage
> > execution of those callable tasks through ThreadPoolExecutor we would
> > have to implement custom ThreadPoolExecutor and PriorityCallable (see a
> > suggestion below). What other ways to accomplish this do you see ?
> >
> > public interface PriorityCallable extends Callable<Object> {
> >      public abstract void setPriority(int priority);
> >      ...
> > }
> >
> > public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
> > ...
> > ...
> > public <T> List<Future<T>> customInvokeAll(
> >                  Collection<? extends Callable<T>> tasks, long timeout,
> > TimeUnit unit) // pass PriorityCallable
> >                  throws InterruptedException {
> >              if (tasks == null || unit == null)
> >                  throw new NullPointerException();
> >              long nanos = unit.toNanos(timeout);
> >              List<Future<T>> futures = new
> > ArrayList<Future<T>>(tasks.size());
> >              boolean done = false;
> >              try {
> >                  // handle Priority based Callable tasks here, though
> > can expect timing issues
> >                  // custom logic to group Callable tasks , if (priority
> > == 1, 2, 3 create group of callables, etc )
> >                  for (Callable<T> t : tasks)
> >                      futures.add(newTaskFor(t));
> >
> >                  long lastTime = System.nanoTime();
> >
> >                  // Interleave time checks and calls to execute in case
> >                  // executor doesn't have any/much parallelism.
> >                  Iterator<Future<T>> it = futures.iterator();
> >                  while (it.hasNext()) {
> >                      execute((Runnable)(it.next())); // should we expect
> > futures get executed within the same timeframe for Callables with
> > different priorities
> >                      long now = System.nanoTime();
> >                      nanos -= now - lastTime;
> >                      lastTime = now;
> >                      if (nanos <= 0)
> >                          return futures;
> >                  }
> >
> >                  for (Future<T> f : futures) {
> >                      if (!f.isDone()) {
> >                          if (nanos <= 0)
> >                              return futures;
> >                          try {
> >                              f.get(nanos, TimeUnit.NANOSECONDS);
> >                          } catch (CancellationException ignore) {
> >                          } catch (ExecutionException ignore) { // Should
> > we cancel tasks based on the priority as well?
> >                          } catch (TimeoutException toe) {
> >                              return futures;
> >                          }
> >                          long now = System.nanoTime();
> >                          nanos -= now - lastTime;
> >                          lastTime = now;
> >                      }
> >                  }
> >                  done = true;
> >                  return futures;
> >              } finally {
> >                  if (!done)
> >                      for (Future<T> f : futures)
> >                          f.cancel(true);
> >              }
> >          }
> > ...
> > }
> >
> > Thank you,
> > dt
> > http://www.flyingtroika.com/
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/f59ed7d8/attachment-0001.html>

From dt at flyingtroika.com  Fri Jun 27 11:41:43 2014
From: dt at flyingtroika.com (DT)
Date: Fri, 27 Jun 2014 08:41:43 -0700
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <CANPzfU_zfcQocw7NJvbktw6P5pW2Fcyjes33C=a8iFRe53U6eA@mail.gmail.com>
References: <53ACEE3A.5090201@flyingtroika.com>	<NFBBKALFDCPFIDBNKAPCOEGMKHAA.davidcholmes@aapt.net.au>
	<CANPzfU_zfcQocw7NJvbktw6P5pW2Fcyjes33C=a8iFRe53U6eA@mail.gmail.com>
Message-ID: <53AD90B7.7070904@flyingtroika.com>

                 We see several scenarios how to approach:

1-st approach is to use a PriorityBlockingQueue, provide Comparator for 
Callable tasks to change the order based on the Callable priority. Then 
when we call invokeAll( Collections of Callable tasks) on TPE to execute 
tasks from queue based on the priority, 1-st, 2-d, n which means that 
tasks will be executed based on abstract groups (for instance1-st group 
? all tasks with high priority go first according to TPE scheduling. 
tpe.execute(thread) will be called and tasks will be assigned to 
available tpe worker threads.

Following this logic tpe does not guarantee for sure that all high 
priority tasks will be executed first. Or this guarantee is not enough 
enforced (maybe there are some policy to enforce this)

2-d approach is to modify invokeAll() to handle priority explicitly 
which does not look like a clean solution.

3-d approach is to have multiple TPEs and each of these tpe will handle 
only one type of priority without mix, for example tpe1 will 
invokeAll(tasks priority 1 only) , tpe2 will invokeAll(tasks priority 2 
only). Which tpe should be instantiated -1^st should follow business logic.

Here is an example what we trying to implement. Assuming we have 
different types of tasks which are bounded to get some resources using 
udp/tcp/http/sql. Something like

sqlWorker needs to execute SQLs and return results, httpWorker type has 
to handle http calls and return some results, etc. the issue is that 
even if we assign some priorities to these workers to perform similar 
tasks following some business logic what data needs to get first within 
our workflow we would have to change priorities dynamically just because 
same type of workers mightfinish execution within different timeslot. So 
we have to wait until all workers are executed (practically tune 
timeslot based on the longest execution time) or drop some tasks due to 
the timing limits. If we follow 3-d approach it would be hard to manage 
TPEs. If we follow 2-d approach it would be hard to maintain tasks and 
guarantee execution group by group.And 1-st approach seems does not 
completely satisfy the problem concurrency execution logic.

On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
> "public abstract void setPriority(int priority);" ? Changing priority 
> on an already submitted task seems strange.
>
> I agree with David, just use a PriorityBlockingQueue 
> [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html] 
> for the submission queue of the TPE and provide a Comparator that 
> checks for your PriorityCallable and puts 
> non-PriorityCallable-Callables at an appropriate default priority.
>
>
> On Fri, Jun 27, 2014 at 6:16 AM, David Holmes 
> <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>
>     Can't you just use your PriorityCallable with a custom
>     PriorityQueue and
>     standard ThreadPoolExecutor?
>
>     David
>
>     > -----Original Message-----
>     > From: concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     > [mailto:concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>]On Behalf Of DT
>     > Sent: Friday, 27 June 2014 2:08 PM
>     > To: concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     > Subject: [concurrency-interest] Custom ThreadPoolExecutor
>     implementation
>     > to handle priority based Callable tasks
>     >
>     >
>     > If we were to control Callable Tasks with Priorities and to manage
>     > execution of those callable tasks through ThreadPoolExecutor we
>     would
>     > have to implement custom ThreadPoolExecutor and PriorityCallable
>     (see a
>     > suggestion below). What other ways to accomplish this do you see ?
>     >
>     > public interface PriorityCallable extends Callable<Object> {
>     >      public abstract void setPriority(int priority);
>     >      ...
>     > }
>     >
>     > public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
>     > ...
>     > ...
>     > public <T> List<Future<T>> customInvokeAll(
>     >                  Collection<? extends Callable<T>> tasks, long
>     timeout,
>     > TimeUnit unit) // pass PriorityCallable
>     >                  throws InterruptedException {
>     >              if (tasks == null || unit == null)
>     >                  throw new NullPointerException();
>     >              long nanos = unit.toNanos(timeout);
>     >              List<Future<T>> futures = new
>     > ArrayList<Future<T>>(tasks.size());
>     >              boolean done = false;
>     >              try {
>     >                  // handle Priority based Callable tasks here,
>     though
>     > can expect timing issues
>     >                  // custom logic to group Callable tasks , if
>     (priority
>     > == 1, 2, 3 create group of callables, etc )
>     >                  for (Callable<T> t : tasks)
>     >                      futures.add(newTaskFor(t));
>     >
>     >                  long lastTime = System.nanoTime();
>     >
>     >                  // Interleave time checks and calls to execute
>     in case
>     >                  // executor doesn't have any/much parallelism.
>     >                  Iterator<Future<T>> it = futures.iterator();
>     >                  while (it.hasNext()) {
>     >  execute((Runnable)(it.next())); // should we expect
>     > futures get executed within the same timeframe for Callables with
>     > different priorities
>     >                      long now = System.nanoTime();
>     >                      nanos -= now - lastTime;
>     >                      lastTime = now;
>     >                      if (nanos <= 0)
>     >                          return futures;
>     >                  }
>     >
>     >                  for (Future<T> f : futures) {
>     >                      if (!f.isDone()) {
>     >                          if (nanos <= 0)
>     >                              return futures;
>     >                          try {
>     >                              f.get(nanos, TimeUnit.NANOSECONDS);
>     >                          } catch (CancellationException ignore) {
>     >                          } catch (ExecutionException ignore) {
>     // Should
>     > we cancel tasks based on the priority as well?
>     >                          } catch (TimeoutException toe) {
>     >                              return futures;
>     >                          }
>     >                          long now = System.nanoTime();
>     >                          nanos -= now - lastTime;
>     >                          lastTime = now;
>     >                      }
>     >                  }
>     >                  done = true;
>     >                  return futures;
>     >              } finally {
>     >                  if (!done)
>     >                      for (Future<T> f : futures)
>     >                          f.cancel(true);
>     >              }
>     >          }
>     > ...
>     > }
>     >
>     > Thank you,
>     > dt
>     > http://www.flyingtroika.com/
>     >
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/309cbe9b/attachment-0001.html>

From davidcholmes at aapt.net.au  Fri Jun 27 16:09:56 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 28 Jun 2014 06:09:56 +1000
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
	to handle priority based Callable tasks
In-Reply-To: <53AD90B7.7070904@flyingtroika.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>

Priority can only really be used for the dispatching/queueing mechanism. Once tasks are executing priority is essentially meaningless. Thread priorities have no significance in general.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of DT
  Sent: Saturday, 28 June 2014 1:42 AM
  To: viktor ?lang; dholmes at ieee.org
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] Custom ThreadPoolExecutor implementation to handle priority based Callable tasks


                  We see several scenarios how to approach:

  1-st approach is to use a PriorityBlockingQueue, provide Comparator for Callable tasks to change the order based on the Callable priority. Then when we call invokeAll( Collections of Callable tasks) on TPE to execute tasks from queue based on the priority, 1-st, 2-d, n which means that tasks will be executed based on abstract groups (for instance  1-st group ? all tasks with high priority go first according to TPE scheduling. tpe.execute(thread) will be called and tasks will be assigned to available tpe worker threads. 

  Following this logic tpe does not guarantee for sure that all high priority tasks will be executed first. Or this guarantee is not enough enforced (maybe there are some policy to enforce this)



  2-d approach is to modify invokeAll() to handle priority explicitly which does not look like a clean solution. 



  3-d approach is to have multiple TPEs and each of these tpe will handle only one type of priority without mix, for example tpe1 will invokeAll(tasks priority 1 only) , tpe2 will invokeAll(tasks priority 2 only). Which tpe should be instantiated -1st should follow business logic.





  Here is an example what we trying to implement. Assuming we have different types of tasks which are bounded to get some resources using udp/tcp/http/sql. Something like 

  sqlWorker needs to execute SQLs and return results, httpWorker type has to handle http calls and return some results, etc. the issue is that even if we assign some priorities to these workers to perform similar tasks following some business logic what data needs to get first within our workflow we would have to change priorities dynamically just because same type of workers might  finish execution within different timeslot. So we have to wait until all workers are executed (practically tune timeslot based on the longest execution time) or drop some tasks due to the timing limits. If we follow 3-d approach it would be hard to manage TPEs. If we follow 2-d approach it would be hard to maintain tasks and guarantee execution group by group.  And 1-st approach seems does not completely satisfy the problem concurrency execution logic.

  On 6/27/2014 3:12 AM, ?iktor ?lang wrote:

    "  public abstract void setPriority(int priority);" ? Changing priority on an already submitted task seems strange.

    I agree with David, just use a PriorityBlockingQueue [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html] for the submission queue of the TPE and provide a Comparator that checks for your PriorityCallable and puts non-PriorityCallable-Callables at an appropriate default priority.



    On Fri, Jun 27, 2014 at 6:16 AM, David Holmes <davidcholmes at aapt.net.au> wrote:

      Can't you just use your PriorityCallable with a custom PriorityQueue and
      standard ThreadPoolExecutor?

      David


      > -----Original Message-----
      > From: concurrency-interest-bounces at cs.oswego.edu
      > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of DT
      > Sent: Friday, 27 June 2014 2:08 PM
      > To: concurrency-interest at cs.oswego.edu
      > Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
      > to handle priority based Callable tasks
      >
      >
      > If we were to control Callable Tasks with Priorities and to manage
      > execution of those callable tasks through ThreadPoolExecutor we would
      > have to implement custom ThreadPoolExecutor and PriorityCallable (see a
      > suggestion below). What other ways to accomplish this do you see ?
      >
      > public interface PriorityCallable extends Callable<Object> {
      >      public abstract void setPriority(int priority);
      >      ...
      > }
      >
      > public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
      > ...
      > ...
      > public <T> List<Future<T>> customInvokeAll(
      >                  Collection<? extends Callable<T>> tasks, long timeout,
      > TimeUnit unit) // pass PriorityCallable
      >                  throws InterruptedException {
      >              if (tasks == null || unit == null)
      >                  throw new NullPointerException();
      >              long nanos = unit.toNanos(timeout);
      >              List<Future<T>> futures = new
      > ArrayList<Future<T>>(tasks.size());
      >              boolean done = false;
      >              try {
      >                  // handle Priority based Callable tasks here, though
      > can expect timing issues
      >                  // custom logic to group Callable tasks , if (priority
      > == 1, 2, 3 create group of callables, etc )
      >                  for (Callable<T> t : tasks)
      >                      futures.add(newTaskFor(t));
      >
      >                  long lastTime = System.nanoTime();
      >
      >                  // Interleave time checks and calls to execute in case
      >                  // executor doesn't have any/much parallelism.
      >                  Iterator<Future<T>> it = futures.iterator();
      >                  while (it.hasNext()) {
      >                      execute((Runnable)(it.next())); // should we expect
      > futures get executed within the same timeframe for Callables with
      > different priorities
      >                      long now = System.nanoTime();
      >                      nanos -= now - lastTime;
      >                      lastTime = now;
      >                      if (nanos <= 0)
      >                          return futures;
      >                  }
      >
      >                  for (Future<T> f : futures) {
      >                      if (!f.isDone()) {
      >                          if (nanos <= 0)
      >                              return futures;
      >                          try {
      >                              f.get(nanos, TimeUnit.NANOSECONDS);
      >                          } catch (CancellationException ignore) {
      >                          } catch (ExecutionException ignore) { // Should
      > we cancel tasks based on the priority as well?
      >                          } catch (TimeoutException toe) {
      >                              return futures;
      >                          }
      >                          long now = System.nanoTime();
      >                          nanos -= now - lastTime;
      >                          lastTime = now;
      >                      }
      >                  }
      >                  done = true;
      >                  return futures;
      >              } finally {
      >                  if (!done)
      >                      for (Future<T> f : futures)
      >                          f.cancel(true);
      >              }
      >          }
      > ...
      > }
      >
      > Thank you,
      > dt
      > http://www.flyingtroika.com/
      >
      > _______________________________________________
      > Concurrency-interest mailing list
      > Concurrency-interest at cs.oswego.edu
      > http://cs.oswego.edu/mailman/listinfo/concurrency-interest

      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at cs.oswego.edu
      http://cs.oswego.edu/mailman/listinfo/concurrency-interest






    -- 

    Cheers,
    ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140628/7b4b2838/attachment-0001.html>

From dt at flyingtroika.com  Fri Jun 27 17:04:09 2014
From: dt at flyingtroika.com (DT)
Date: Fri, 27 Jun 2014 14:04:09 -0700
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>
Message-ID: <53ADDC49.9060403@flyingtroika.com>

if we dispatch tasks based on queuing we would not get guarantees that 
the tasks first in line will finish execution first and futures are done 
to return results (in general none of the dispatching mechanism will 
give me such behavior, can be wrong of course, sorry if I am mangled 
callable priorities which I wanted to use to control execution of the 
tasks in some order with overall thread priorities)
I think that I need some sort of scheduling constraints what task should 
be done first so I can use futures results for dispatching next set of 
tasks. I am not sure if for example  CompletableFuture in java 8 meant 
to be used for such problems. Namely tasks have to be executed in 
certain order/deliver results and they can have dependency/relationships 
between each other.

By the way in what circumstances would you recommend to use TPE 
constructor with own ThreadFactory implementation and not to relly on 
the default one?

DT

On 6/27/2014 1:09 PM, David Holmes wrote:
> Priority can only really be used for the dispatching/queueing 
> mechanism. Once tasks are executing priority is essentially 
> meaningless. Thread priorities have no significance in general.
> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *DT
>     *Sent:* Saturday, 28 June 2014 1:42 AM
>     *To:* viktor ?lang; dholmes at ieee.org
>     *Cc:* concurrency-interest
>     *Subject:* Re: [concurrency-interest] Custom ThreadPoolExecutor
>     implementation to handle priority based Callable tasks
>
>                     We see several scenarios how to approach:
>
>     1-st approach is to use a PriorityBlockingQueue, provide
>     Comparator for Callable tasks to change the order based on the
>     Callable priority. Then when we call invokeAll( Collections of
>     Callable tasks) on TPE to execute tasks from queue based on the
>     priority, 1-st, 2-d, n which means that tasks will be executed
>     based on abstract groups (for instance1-st group ? all tasks with
>     high priority go first according to TPE scheduling.
>     tpe.execute(thread) will be called and tasks will be assigned to
>     available tpe worker threads.
>
>     Following this logic tpe does not guarantee for sure that all high
>     priority tasks will be executed first. Or this guarantee is not
>     enough enforced (maybe there are some policy to enforce this)
>
>     2-d approach is to modify invokeAll() to handle priority
>     explicitly which does not look like a clean solution.
>
>     3-d approach is to have multiple TPEs and each of these tpe will
>     handle only one type of priority without mix, for example tpe1
>     will invokeAll(tasks priority 1 only) , tpe2 will invokeAll(tasks
>     priority 2 only). Which tpe should be instantiated -1^st should
>     follow business logic.
>
>     Here is an example what we trying to implement. Assuming we have
>     different types of tasks which are bounded to get some resources
>     using udp/tcp/http/sql. Something like
>
>     sqlWorker needs to execute SQLs and return results, httpWorker
>     type has to handle http calls and return some results, etc. the
>     issue is that even if we assign some priorities to these workers
>     to perform similar tasks following some business logic what data
>     needs to get first within our workflow we would have to change
>     priorities dynamically just because same type of workers
>     mightfinish execution within different timeslot. So we have to
>     wait until all workers are executed (practically tune timeslot
>     based on the longest execution time) or drop some tasks due to the
>     timing limits. If we follow 3-d approach it would be hard to
>     manage TPEs. If we follow 2-d approach it would be hard to
>     maintain tasks and guarantee execution group by group.And 1-st
>     approach seems does not completely satisfy the problem concurrency
>     execution logic.
>
>     On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
>>     "  public abstract void setPriority(int priority);" ? Changing
>>     priority on an already submitted task seems strange.
>>
>>     I agree with David, just use a PriorityBlockingQueue
>>     [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
>>     for the submission queue of the TPE and provide a Comparator that
>>     checks for your PriorityCallable and puts
>>     non-PriorityCallable-Callables at an appropriate default priority.
>>
>>
>>     On Fri, Jun 27, 2014 at 6:16 AM, David Holmes
>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>         Can't you just use your PriorityCallable with a custom
>>         PriorityQueue and
>>         standard ThreadPoolExecutor?
>>
>>         David
>>
>>         > -----Original Message-----
>>         > From: concurrency-interest-bounces at cs.oswego.edu
>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>         > [mailto:concurrency-interest-bounces at cs.oswego.edu
>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]On Behalf
>>         Of DT
>>         > Sent: Friday, 27 June 2014 2:08 PM
>>         > To: concurrency-interest at cs.oswego.edu
>>         <mailto:concurrency-interest at cs.oswego.edu>
>>         > Subject: [concurrency-interest] Custom ThreadPoolExecutor
>>         implementation
>>         > to handle priority based Callable tasks
>>         >
>>         >
>>         > If we were to control Callable Tasks with Priorities and to
>>         manage
>>         > execution of those callable tasks through
>>         ThreadPoolExecutor we would
>>         > have to implement custom ThreadPoolExecutor and
>>         PriorityCallable (see a
>>         > suggestion below). What other ways to accomplish this do
>>         you see ?
>>         >
>>         > public interface PriorityCallable extends Callable<Object> {
>>         >      public abstract void setPriority(int priority);
>>         >      ...
>>         > }
>>         >
>>         > public class CustomThreadPoolExecutor  extends
>>         ThreadPoolExecutor {
>>         > ...
>>         > ...
>>         > public <T> List<Future<T>> customInvokeAll(
>>         >                  Collection<? extends Callable<T>> tasks,
>>         long timeout,
>>         > TimeUnit unit) // pass PriorityCallable
>>         >                  throws InterruptedException {
>>         >              if (tasks == null || unit == null)
>>         >                  throw new NullPointerException();
>>         >              long nanos = unit.toNanos(timeout);
>>         >              List<Future<T>> futures = new
>>         > ArrayList<Future<T>>(tasks.size());
>>         >              boolean done = false;
>>         >              try {
>>         >                  // handle Priority based Callable tasks
>>         here, though
>>         > can expect timing issues
>>         >                  // custom logic to group Callable tasks ,
>>         if (priority
>>         > == 1, 2, 3 create group of callables, etc )
>>         >                  for (Callable<T> t : tasks)
>>         >  futures.add(newTaskFor(t));
>>         >
>>         >                  long lastTime = System.nanoTime();
>>         >
>>         >                  // Interleave time checks and calls to
>>         execute in case
>>         >                  // executor doesn't have any/much parallelism.
>>         >  Iterator<Future<T>> it = futures.iterator();
>>         >                  while (it.hasNext()) {
>>         >  execute((Runnable)(it.next())); // should we expect
>>         > futures get executed within the same timeframe for
>>         Callables with
>>         > different priorities
>>         >                      long now = System.nanoTime();
>>         >                      nanos -= now - lastTime;
>>         >                      lastTime = now;
>>         >                      if (nanos <= 0)
>>         >                          return futures;
>>         >                  }
>>         >
>>         >                  for (Future<T> f : futures) {
>>         >                      if (!f.isDone()) {
>>         >                          if (nanos <= 0)
>>         >                              return futures;
>>         >                          try {
>>         >                              f.get(nanos,
>>         TimeUnit.NANOSECONDS);
>>         >                          } catch (CancellationException
>>         ignore) {
>>         >                          } catch (ExecutionException
>>         ignore) { // Should
>>         > we cancel tasks based on the priority as well?
>>         >                          } catch (TimeoutException toe) {
>>         >                              return futures;
>>         >                          }
>>         >                          long now = System.nanoTime();
>>         >                          nanos -= now - lastTime;
>>         >                          lastTime = now;
>>         >                      }
>>         >                  }
>>         >                  done = true;
>>         >                  return futures;
>>         >              } finally {
>>         >                  if (!done)
>>         >                      for (Future<T> f : futures)
>>         >                          f.cancel(true);
>>         >              }
>>         >          }
>>         > ...
>>         > }
>>         >
>>         > Thank you,
>>         > dt
>>         > http://www.flyingtroika.com/
>>         >
>>         > _______________________________________________
>>         > Concurrency-interest mailing list
>>         > Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     -- 
>>     Cheers,
>>     ?
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/73b5d55a/attachment-0001.html>

From vitalyd at gmail.com  Fri Jun 27 18:05:10 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 27 Jun 2014 18:05:10 -0400
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <53ADDC49.9060403@flyingtroika.com>
References: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>
	<53ADDC49.9060403@flyingtroika.com>
Message-ID: <CAHjP37Ge3Gx3Eiv7pgWu41Bj-yjZYMt79f1qimifgZG7NTKvOg@mail.gmail.com>

Why not do this in continuation passing style? That is, submit items to a
TPE that execute first (I.e. they produce more work) and when they're done
producing work, have them queue up subsequent tasks (and those in turn can
produce further tasks).

Sent from my phone
On Jun 27, 2014 5:21 PM, "DT" <dt at flyingtroika.com> wrote:

>  if we dispatch tasks based on queuing we would not get guarantees that
> the tasks first in line will finish execution first and futures are done to
> return results (in general none of the dispatching mechanism will give me
> such behavior, can be wrong of course, sorry if I am mangled callable
> priorities which I wanted to use to control execution of the tasks in some
> order with overall thread priorities)
> I think that I need some sort of scheduling constraints what task should
> be done first so I can use futures results for dispatching next set of
> tasks. I am not sure if for example  CompletableFuture in java 8 meant to
> be used for such problems. Namely tasks have to be executed in certain
> order/deliver results and they can have dependency/relationships between
> each other.
>
> By the way in what circumstances would you recommend to use TPE
> constructor with own ThreadFactory implementation and not to relly on the
> default one?
>
> DT
>
> On 6/27/2014 1:09 PM, David Holmes wrote:
>
> Priority can only really be used for the dispatching/queueing mechanism.
> Once tasks are executing priority is essentially meaningless. Thread
> priorities have no significance in general.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [
> mailto:concurrency-interest-bounces at cs.oswego.edu
> <concurrency-interest-bounces at cs.oswego.edu>]*On Behalf Of *DT
> *Sent:* Saturday, 28 June 2014 1:42 AM
> *To:* viktor ?lang; dholmes at ieee.org
> *Cc:* concurrency-interest
> *Subject:* Re: [concurrency-interest] Custom ThreadPoolExecutor
> implementation to handle priority based Callable tasks
>
>                  We see several scenarios how to approach:
>
> 1-st approach is to use a PriorityBlockingQueue, provide Comparator for
> Callable tasks to change the order based on the Callable priority. Then
> when we call invokeAll( Collections of Callable tasks) on TPE to execute
> tasks from queue based on the priority, 1-st, 2-d, n which means that tasks
> will be executed based on abstract groups (for instance  1-st group ? all
> tasks with high priority go first according to TPE scheduling.
> tpe.execute(thread) will be called and tasks will be assigned to available
> tpe worker threads.
>
> Following this logic tpe does not guarantee for sure that all high
> priority tasks will be executed first. Or this guarantee is not enough
> enforced (maybe there are some policy to enforce this)
>
>  2-d approach is to modify invokeAll() to handle priority explicitly
> which does not look like a clean solution.
>
>  3-d approach is to have multiple TPEs and each of these tpe will handle
> only one type of priority without mix, for example tpe1 will
> invokeAll(tasks priority 1 only) , tpe2 will invokeAll(tasks priority 2
> only). Which tpe should be instantiated -1st should follow business logic.
>
>   Here is an example what we trying to implement. Assuming we have
> different types of tasks which are bounded to get some resources using
> udp/tcp/http/sql. Something like
>
> sqlWorker needs to execute SQLs and return results, httpWorker type has to
> handle http calls and return some results, etc. the issue is that even if
> we assign some priorities to these workers to perform similar tasks
> following some business logic what data needs to get first within our
> workflow we would have to change priorities dynamically just because same
> type of workers might  finish execution within different timeslot. So we
> have to wait until all workers are executed (practically tune timeslot
> based on the longest execution time) or drop some tasks due to the timing
> limits. If we follow 3-d approach it would be hard to manage TPEs. If we
> follow 2-d approach it would be hard to maintain tasks and guarantee
> execution group by group.  And 1-st approach seems does not completely
> satisfy the problem concurrency execution logic.
> On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
>
> "  public abstract void setPriority(int priority);" ? Changing priority
> on an already submitted task seems strange.
>
> I agree with David, just use a PriorityBlockingQueue [
> http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
> for the submission queue of the TPE and provide a Comparator that checks
> for your PriorityCallable and puts non-PriorityCallable-Callables at an
> appropriate default priority.
>
>
> On Fri, Jun 27, 2014 at 6:16 AM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>
>> Can't you just use your PriorityCallable with a custom PriorityQueue and
>> standard ThreadPoolExecutor?
>>
>> David
>>
>> > -----Original Message-----
>> > From: concurrency-interest-bounces at cs.oswego.edu
>> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of DT
>> > Sent: Friday, 27 June 2014 2:08 PM
>> > To: concurrency-interest at cs.oswego.edu
>> > Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
>> > to handle priority based Callable tasks
>> >
>> >
>> > If we were to control Callable Tasks with Priorities and to manage
>> > execution of those callable tasks through ThreadPoolExecutor we would
>> > have to implement custom ThreadPoolExecutor and PriorityCallable (see a
>> > suggestion below). What other ways to accomplish this do you see ?
>> >
>> > public interface PriorityCallable extends Callable<Object> {
>> >      public abstract void setPriority(int priority);
>> >      ...
>> > }
>> >
>> > public class CustomThreadPoolExecutor  extends ThreadPoolExecutor {
>> > ...
>> > ...
>> > public <T> List<Future<T>> customInvokeAll(
>> >                  Collection<? extends Callable<T>> tasks, long timeout,
>> > TimeUnit unit) // pass PriorityCallable
>> >                  throws InterruptedException {
>> >              if (tasks == null || unit == null)
>> >                  throw new NullPointerException();
>> >              long nanos = unit.toNanos(timeout);
>> >              List<Future<T>> futures = new
>> > ArrayList<Future<T>>(tasks.size());
>> >              boolean done = false;
>> >              try {
>> >                  // handle Priority based Callable tasks here, though
>> > can expect timing issues
>> >                  // custom logic to group Callable tasks , if (priority
>> > == 1, 2, 3 create group of callables, etc )
>> >                  for (Callable<T> t : tasks)
>> >                      futures.add(newTaskFor(t));
>> >
>> >                  long lastTime = System.nanoTime();
>> >
>> >                  // Interleave time checks and calls to execute in case
>> >                  // executor doesn't have any/much parallelism.
>> >                  Iterator<Future<T>> it = futures.iterator();
>> >                  while (it.hasNext()) {
>> >                      execute((Runnable)(it.next())); // should we expect
>> > futures get executed within the same timeframe for Callables with
>> > different priorities
>> >                      long now = System.nanoTime();
>> >                      nanos -= now - lastTime;
>> >                      lastTime = now;
>> >                      if (nanos <= 0)
>> >                          return futures;
>> >                  }
>> >
>> >                  for (Future<T> f : futures) {
>> >                      if (!f.isDone()) {
>> >                          if (nanos <= 0)
>> >                              return futures;
>> >                          try {
>> >                              f.get(nanos, TimeUnit.NANOSECONDS);
>> >                          } catch (CancellationException ignore) {
>> >                          } catch (ExecutionException ignore) { // Should
>> > we cancel tasks based on the priority as well?
>> >                          } catch (TimeoutException toe) {
>> >                              return futures;
>> >                          }
>> >                          long now = System.nanoTime();
>> >                          nanos -= now - lastTime;
>> >                          lastTime = now;
>> >                      }
>> >                  }
>> >                  done = true;
>> >                  return futures;
>> >              } finally {
>> >                  if (!done)
>> >                      for (Future<T> f : futures)
>> >                          f.cancel(true);
>> >              }
>> >          }
>> > ...
>> > }
>> >
>> > Thank you,
>> > dt
>> > http://www.flyingtroika.com/
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
>  --
>  Cheers,
> ?
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/f4dd41ca/attachment-0001.html>

From oleksandr.otenko at oracle.com  Fri Jun 27 18:30:34 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 27 Jun 2014 23:30:34 +0100
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <53ADDC49.9060403@flyingtroika.com>
References: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>
	<53ADDC49.9060403@flyingtroika.com>
Message-ID: <53ADF08A.1070600@oracle.com>

1. Each task must know how many dependencies it has.

2. Each task knows which other tasks depend on it.

3. Upon finishing a task, decrement the counters of all dependent tasks. 
Those that reach zero, get scheduled with the TPE.


If you don't know which tasks depend on which before executing them (ie 
you don't have answer for (2)), there is no efficient way of planning 
their execution.

Alex


On 27/06/2014 22:04, DT wrote:
> if we dispatch tasks based on queuing we would not get guarantees that 
> the tasks first in line will finish execution first and futures are 
> done to return results (in general none of the dispatching mechanism 
> will give me such behavior, can be wrong of course, sorry if I am 
> mangled callable priorities which I wanted to use to control execution 
> of the tasks in some order with overall thread priorities)
> I think that I need some sort of scheduling constraints what task 
> should be done first so I can use futures results for dispatching next 
> set of tasks. I am not sure if for example  CompletableFuture in java 
> 8 meant to be used for such problems. Namely tasks have to be executed 
> in certain order/deliver results and they can have 
> dependency/relationships between each other.
>
> By the way in what circumstances would you recommend to use TPE 
> constructor with own ThreadFactory implementation and not to relly on 
> the default one?
>
> DT
>
> On 6/27/2014 1:09 PM, David Holmes wrote:
>> Priority can only really be used for the dispatching/queueing 
>> mechanism. Once tasks are executing priority is essentially 
>> meaningless. Thread priorities have no significance in general.
>> David
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *DT
>>     *Sent:* Saturday, 28 June 2014 1:42 AM
>>     *To:* viktor ?lang; dholmes at ieee.org
>>     *Cc:* concurrency-interest
>>     *Subject:* Re: [concurrency-interest] Custom ThreadPoolExecutor
>>     implementation to handle priority based Callable tasks
>>
>>                     We see several scenarios how to approach:
>>
>>     1-st approach is to use a PriorityBlockingQueue, provide
>>     Comparator for Callable tasks to change the order based on the
>>     Callable priority. Then when we call invokeAll( Collections of
>>     Callable tasks) on TPE to execute tasks from queue based on the
>>     priority, 1-st, 2-d, n which means that tasks will be executed
>>     based on abstract groups (for instance1-st group -- all tasks
>>     with high priority go first according to TPE scheduling.
>>     tpe.execute(thread) will be called and tasks will be assigned to
>>     available tpe worker threads.
>>
>>     Following this logic tpe does not guarantee for sure that all
>>     high priority tasks will be executed first. Or this guarantee is
>>     not enough enforced (maybe there are some policy to enforce this)
>>
>>     2-d approach is to modify invokeAll() to handle priority
>>     explicitly which does not look like a clean solution.
>>
>>     3-d approach is to have multiple TPEs and each of these tpe will
>>     handle only one type of priority without mix, for example tpe1
>>     will invokeAll(tasks priority 1 only) , tpe2 will invokeAll(tasks
>>     priority 2 only). Which tpe should be instantiated -1^st should
>>     follow business logic.
>>
>>     Here is an example what we trying to implement. Assuming we have
>>     different types of tasks which are bounded to get some resources
>>     using udp/tcp/http/sql. Something like
>>
>>     sqlWorker needs to execute SQLs and return results, httpWorker
>>     type has to handle http calls and return some results, etc. the
>>     issue is that even if we assign some priorities to these workers
>>     to perform similar tasks following some business logic what data
>>     needs to get first within our workflow we would have to change
>>     priorities dynamically just because same type of workers
>>     mightfinish execution within different timeslot. So we have to
>>     wait until all workers are executed (practically tune timeslot
>>     based on the longest execution time) or drop some tasks due to
>>     the timing limits. If we follow 3-d approach it would be hard to
>>     manage TPEs. If we follow 2-d approach it would be hard to
>>     maintain tasks and guarantee execution group by group.And 1-st
>>     approach seems does not completely satisfy the problem
>>     concurrency execution logic.
>>
>>     On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
>>>     "  public abstract void setPriority(int priority);" ? Changing
>>>     priority on an already submitted task seems strange.
>>>
>>>     I agree with David, just use a PriorityBlockingQueue
>>>     [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
>>>     for the submission queue of the TPE and provide a Comparator
>>>     that checks for your PriorityCallable and puts
>>>     non-PriorityCallable-Callables at an appropriate default priority.
>>>
>>>
>>>     On Fri, Jun 27, 2014 at 6:16 AM, David Holmes
>>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>
>>>         Can't you just use your PriorityCallable with a custom
>>>         PriorityQueue and
>>>         standard ThreadPoolExecutor?
>>>
>>>         David
>>>
>>>         > -----Original Message-----
>>>         > From: concurrency-interest-bounces at cs.oswego.edu
>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>         > [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>         Behalf Of DT
>>>         > Sent: Friday, 27 June 2014 2:08 PM
>>>         > To: concurrency-interest at cs.oswego.edu
>>>         <mailto:concurrency-interest at cs.oswego.edu>
>>>         > Subject: [concurrency-interest] Custom ThreadPoolExecutor
>>>         implementation
>>>         > to handle priority based Callable tasks
>>>         >
>>>         >
>>>         > If we were to control Callable Tasks with Priorities and
>>>         to manage
>>>         > execution of those callable tasks through
>>>         ThreadPoolExecutor we would
>>>         > have to implement custom ThreadPoolExecutor and
>>>         PriorityCallable (see a
>>>         > suggestion below). What other ways to accomplish this do
>>>         you see ?
>>>         >
>>>         > public interface PriorityCallable extends Callable<Object> {
>>>         >      public abstract void setPriority(int priority);
>>>         >      ...
>>>         > }
>>>         >
>>>         > public class CustomThreadPoolExecutor  extends
>>>         ThreadPoolExecutor {
>>>         > ...
>>>         > ...
>>>         > public <T> List<Future<T>> customInvokeAll(
>>>         >                  Collection<? extends Callable<T>> tasks,
>>>         long timeout,
>>>         > TimeUnit unit) // pass PriorityCallable
>>>         >                  throws InterruptedException {
>>>         >              if (tasks == null || unit == null)
>>>         >                  throw new NullPointerException();
>>>         >              long nanos = unit.toNanos(timeout);
>>>         >              List<Future<T>> futures = new
>>>         > ArrayList<Future<T>>(tasks.size());
>>>         >              boolean done = false;
>>>         >              try {
>>>         >                  // handle Priority based Callable tasks
>>>         here, though
>>>         > can expect timing issues
>>>         >                  // custom logic to group Callable tasks ,
>>>         if (priority
>>>         > == 1, 2, 3 create group of callables, etc )
>>>         >                  for (Callable<T> t : tasks)
>>>         >  futures.add(newTaskFor(t));
>>>         >
>>>         >                  long lastTime = System.nanoTime();
>>>         >
>>>         >                  // Interleave time checks and calls to
>>>         execute in case
>>>         >                  // executor doesn't have any/much
>>>         parallelism.
>>>         >  Iterator<Future<T>> it = futures.iterator();
>>>         >                  while (it.hasNext()) {
>>>         >  execute((Runnable)(it.next())); // should we expect
>>>         > futures get executed within the same timeframe for
>>>         Callables with
>>>         > different priorities
>>>         >                      long now = System.nanoTime();
>>>         >                      nanos -= now - lastTime;
>>>         >                      lastTime = now;
>>>         >                      if (nanos <= 0)
>>>         >                          return futures;
>>>         >                  }
>>>         >
>>>         >                  for (Future<T> f : futures) {
>>>         >                      if (!f.isDone()) {
>>>         >                          if (nanos <= 0)
>>>         >                              return futures;
>>>         >                          try {
>>>         >                              f.get(nanos,
>>>         TimeUnit.NANOSECONDS);
>>>         >                          } catch (CancellationException
>>>         ignore) {
>>>         >                          } catch (ExecutionException
>>>         ignore) { // Should
>>>         > we cancel tasks based on the priority as well?
>>>         >                          } catch (TimeoutException toe) {
>>>         >                              return futures;
>>>         >                          }
>>>         >                          long now = System.nanoTime();
>>>         >                          nanos -= now - lastTime;
>>>         >                          lastTime = now;
>>>         >                      }
>>>         >                  }
>>>         >                  done = true;
>>>         >                  return futures;
>>>         >              } finally {
>>>         >                  if (!done)
>>>         >                      for (Future<T> f : futures)
>>>         >                          f.cancel(true);
>>>         >              }
>>>         >          }
>>>         > ...
>>>         > }
>>>         >
>>>         > Thank you,
>>>         > dt
>>>         > http://www.flyingtroika.com/
>>>         >
>>>         > _______________________________________________
>>>         > Concurrency-interest mailing list
>>>         > Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>>     -- 
>>>     Cheers,
>>>     ?
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/09addd14/attachment-0001.html>

From dt at flyingtroika.com  Fri Jun 27 23:14:00 2014
From: dt at flyingtroika.com (DT)
Date: Fri, 27 Jun 2014 20:14:00 -0700
Subject: [concurrency-interest] sharing a single bounded or unbounded queue
 instance between several ThreadPoolExecutors
Message-ID: <53AE32F8.7060500@flyingtroika.com>

Did you recall any particular cases when sharing a single bounded/ 
unbounded queue instance between several TPEs was making sense?

Thanks,
DT



From dt at flyingtroika.com  Fri Jun 27 23:49:39 2014
From: dt at flyingtroika.com (DT)
Date: Fri, 27 Jun 2014 20:49:39 -0700
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <53ADF08A.1070600@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>
	<53ADDC49.9060403@flyingtroika.com> <53ADF08A.1070600@oracle.com>
Message-ID: <53AE3B53.9000600@flyingtroika.com>

I believe that
1 -  should be ok to accomplish
2 -  ok to satisfy or at least get very close to it as we know all 
dependencies at the beginning
3 -  I like idea with counters: simple, straight and easy to follow

However, the issue is that all the tasks (with dependency, etc) have to 
finish execution within the same time slot as a whole.  We have to 
enforce some sort of timing constraint. Same task can take different 
time to execute (we can apply some statistical methods to get the 
average for all the tasks based on the historical execution time).

Would it be better to apply some sort of cyclic barriers or counters?

Thanks,
DT

On 6/27/2014 3:30 PM, Oleksandr Otenko wrote:
> 1. Each task must know how many dependencies it has.
>
> 2. Each task knows which other tasks depend on it.
>
> 3. Upon finishing a task, decrement the counters of all dependent 
> tasks. Those that reach zero, get scheduled with the TPE.
>
>
> If you don't know which tasks depend on which before executing them 
> (ie you don't have answer for (2)), there is no efficient way of 
> planning their execution.
>
> Alex
>
>
> On 27/06/2014 22:04, DT wrote:
>> if we dispatch tasks based on queuing we would not get guarantees 
>> that the tasks first in line will finish execution first and futures 
>> are done to return results (in general none of the dispatching 
>> mechanism will give me such behavior, can be wrong of course, sorry 
>> if I am mangled callable priorities which I wanted to use to control 
>> execution of the tasks in some order with overall thread priorities)
>> I think that I need some sort of scheduling constraints what task 
>> should be done first so I can use futures results for dispatching 
>> next set of tasks. I am not sure if for example CompletableFuture in 
>> java 8 meant to be used for such problems. Namely tasks have to be 
>> executed in certain order/deliver results and they can have 
>> dependency/relationships between each other.
>>
>> By the way in what circumstances would you recommend to use TPE 
>> constructor with own ThreadFactory implementation and not to relly on 
>> the default one?
>>
>> DT
>>
>> On 6/27/2014 1:09 PM, David Holmes wrote:
>>> Priority can only really be used for the dispatching/queueing 
>>> mechanism. Once tasks are executing priority is essentially 
>>> meaningless. Thread priorities have no significance in general.
>>> David
>>>
>>>     -----Original Message-----
>>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *DT
>>>     *Sent:* Saturday, 28 June 2014 1:42 AM
>>>     *To:* viktor ?lang; dholmes at ieee.org
>>>     *Cc:* concurrency-interest
>>>     *Subject:* Re: [concurrency-interest] Custom ThreadPoolExecutor
>>>     implementation to handle priority based Callable tasks
>>>
>>>                     We see several scenarios how to approach:
>>>
>>>     1-st approach is to use a PriorityBlockingQueue, provide
>>>     Comparator for Callable tasks to change the order based on the
>>>     Callable priority. Then when we call invokeAll( Collections of
>>>     Callable tasks) on TPE to execute tasks from queue based on the
>>>     priority, 1-st, 2-d, n which means that tasks will be executed
>>>     based on abstract groups (for instance1-st group -- all tasks
>>>     with high priority go first according to TPE scheduling.
>>>     tpe.execute(thread) will be called and tasks will be assigned to
>>>     available tpe worker threads.
>>>
>>>     Following this logic tpe does not guarantee for sure that all
>>>     high priority tasks will be executed first. Or this guarantee is
>>>     not enough enforced (maybe there are some policy to enforce this)
>>>
>>>     2-d approach is to modify invokeAll() to handle priority
>>>     explicitly which does not look like a clean solution.
>>>
>>>     3-d approach is to have multiple TPEs and each of these tpe will
>>>     handle only one type of priority without mix, for example tpe1
>>>     will invokeAll(tasks priority 1 only) , tpe2 will
>>>     invokeAll(tasks priority 2 only). Which tpe should be
>>>     instantiated -1^st should follow business logic.
>>>
>>>     Here is an example what we trying to implement. Assuming we have
>>>     different types of tasks which are bounded to get some resources
>>>     using udp/tcp/http/sql. Something like
>>>
>>>     sqlWorker needs to execute SQLs and return results, httpWorker
>>>     type has to handle http calls and return some results, etc. the
>>>     issue is that even if we assign some priorities to these workers
>>>     to perform similar tasks following some business logic what data
>>>     needs to get first within our workflow we would have to change
>>>     priorities dynamically just because same type of workers
>>>     mightfinish execution within different timeslot. So we have to
>>>     wait until all workers are executed (practically tune timeslot
>>>     based on the longest execution time) or drop some tasks due to
>>>     the timing limits. If we follow 3-d approach it would be hard to
>>>     manage TPEs. If we follow 2-d approach it would be hard to
>>>     maintain tasks and guarantee execution group by group.And 1-st
>>>     approach seems does not completely satisfy the problem
>>>     concurrency execution logic.
>>>
>>>     On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
>>>>     "  public abstract void setPriority(int priority);" ? Changing
>>>>     priority on an already submitted task seems strange.
>>>>
>>>>     I agree with David, just use a PriorityBlockingQueue
>>>>     [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
>>>>     for the submission queue of the TPE and provide a Comparator
>>>>     that checks for your PriorityCallable and puts
>>>>     non-PriorityCallable-Callables at an appropriate default priority.
>>>>
>>>>
>>>>     On Fri, Jun 27, 2014 at 6:16 AM, David Holmes
>>>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>         Can't you just use your PriorityCallable with a custom
>>>>         PriorityQueue and
>>>>         standard ThreadPoolExecutor?
>>>>
>>>>         David
>>>>
>>>>         > -----Original Message-----
>>>>         > From: concurrency-interest-bounces at cs.oswego.edu
>>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>         > [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>         Behalf Of DT
>>>>         > Sent: Friday, 27 June 2014 2:08 PM
>>>>         > To: concurrency-interest at cs.oswego.edu
>>>>         <mailto:concurrency-interest at cs.oswego.edu>
>>>>         > Subject: [concurrency-interest] Custom ThreadPoolExecutor
>>>>         implementation
>>>>         > to handle priority based Callable tasks
>>>>         >
>>>>         >
>>>>         > If we were to control Callable Tasks with Priorities and
>>>>         to manage
>>>>         > execution of those callable tasks through
>>>>         ThreadPoolExecutor we would
>>>>         > have to implement custom ThreadPoolExecutor and
>>>>         PriorityCallable (see a
>>>>         > suggestion below). What other ways to accomplish this do
>>>>         you see ?
>>>>         >
>>>>         > public interface PriorityCallable extends Callable<Object> {
>>>>         >      public abstract void setPriority(int priority);
>>>>         >      ...
>>>>         > }
>>>>         >
>>>>         > public class CustomThreadPoolExecutor  extends
>>>>         ThreadPoolExecutor {
>>>>         > ...
>>>>         > ...
>>>>         > public <T> List<Future<T>> customInvokeAll(
>>>>         >                  Collection<? extends Callable<T>> tasks,
>>>>         long timeout,
>>>>         > TimeUnit unit) // pass PriorityCallable
>>>>         >                  throws InterruptedException {
>>>>         >              if (tasks == null || unit == null)
>>>>         >                  throw new NullPointerException();
>>>>         >              long nanos = unit.toNanos(timeout);
>>>>         >              List<Future<T>> futures = new
>>>>         > ArrayList<Future<T>>(tasks.size());
>>>>         >              boolean done = false;
>>>>         >              try {
>>>>         >                  // handle Priority based Callable tasks
>>>>         here, though
>>>>         > can expect timing issues
>>>>         >                  // custom logic to group Callable tasks
>>>>         , if (priority
>>>>         > == 1, 2, 3 create group of callables, etc )
>>>>         >                  for (Callable<T> t : tasks)
>>>>         >  futures.add(newTaskFor(t));
>>>>         >
>>>>         >                  long lastTime = System.nanoTime();
>>>>         >
>>>>         >                  // Interleave time checks and calls to
>>>>         execute in case
>>>>         >                  // executor doesn't have any/much
>>>>         parallelism.
>>>>         >  Iterator<Future<T>> it = futures.iterator();
>>>>         >                  while (it.hasNext()) {
>>>>         >  execute((Runnable)(it.next())); // should we expect
>>>>         > futures get executed within the same timeframe for
>>>>         Callables with
>>>>         > different priorities
>>>>         >                      long now = System.nanoTime();
>>>>         >                      nanos -= now - lastTime;
>>>>         >                      lastTime = now;
>>>>         >                      if (nanos <= 0)
>>>>         >                          return futures;
>>>>         >                  }
>>>>         >
>>>>         >                  for (Future<T> f : futures) {
>>>>         >                      if (!f.isDone()) {
>>>>         >                          if (nanos <= 0)
>>>>         >                              return futures;
>>>>         >                          try {
>>>>         >                              f.get(nanos,
>>>>         TimeUnit.NANOSECONDS);
>>>>         >                          } catch (CancellationException
>>>>         ignore) {
>>>>         >                          } catch (ExecutionException
>>>>         ignore) { // Should
>>>>         > we cancel tasks based on the priority as well?
>>>>         >                          } catch (TimeoutException toe) {
>>>>         >                              return futures;
>>>>         >                          }
>>>>         >                          long now = System.nanoTime();
>>>>         >                          nanos -= now - lastTime;
>>>>         >                          lastTime = now;
>>>>         >                      }
>>>>         >                  }
>>>>         >                  done = true;
>>>>         >                  return futures;
>>>>         >              } finally {
>>>>         >                  if (!done)
>>>>         >                      for (Future<T> f : futures)
>>>>         >                          f.cancel(true);
>>>>         >              }
>>>>         >          }
>>>>         > ...
>>>>         > }
>>>>         >
>>>>         > Thank you,
>>>>         > dt
>>>>         > http://www.flyingtroika.com/
>>>>         >
>>>>         > _______________________________________________
>>>>         > Concurrency-interest mailing list
>>>>         > Concurrency-interest at cs.oswego.edu
>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu
>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>>     -- 
>>>>     Cheers,
>>>>     ?
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140627/45e09fa1/attachment-0001.html>

From peter.firmstone at zeus.net.au  Sat Jun 28 21:53:50 2014
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Sun, 29 Jun 2014 11:53:50 +1000
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <mailman.132.1403863934.24967.concurrency-interest@cs.oswego.edu>
References: <mailman.132.1403863934.24967.concurrency-interest@cs.oswego.edu>
Message-ID: <1404006830.14661.4.camel@Nokia-N900>

It does look like a good solution.

You might wonder why we still need a custom SecurityManager?

Concurrency.

The ageing java security infrastructure is a huge bottleneck for multithreaded code.

Regards,

Peter.







> Message: 1
> Date: Thu, 26 Jun 2014 19:10:22 -0400
> From: Doug Lea <dl at cs.oswego.edu>
> To: Peter Levart <peter.levart at gmail.com>
> Cc: core-libs-dev <core-libs-dev at openjdk.java.net>,??? OpenJDK
> ??? <security-dev at openjdk.java.net>,??? concurrency-interest
> ??? <concurrency-interest at cs.oswego.edu>
> Subject: Re: [concurrency-interest] ThreadLocalRandom clinit troubles
> Message-ID: <53ACA85E.2030407 at cs.oswego.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>
> Peter: Thanks very much for attacking the shocking impact/complexity
> of getting a few seed bits.
>
> On 06/25/2014 01:41 PM, Peter Levart wrote:
> >
> > Peeking around in the sun.security.provider package, I found there
> > already is a minimal internal infrastructure for obtaining random
> > seed. It's encapsulated in package-private abstract class
> > sun.security.provider.SeedGenerator with 4 implementations. It turns
> > out that, besides Java-only fall-back implementation called
> > ThreadedSeedGenerator and generic URLSeedGenerator, there are also two
> > implementations of NativeSeedGenerator (one for UNIX-es which is just
> > an extension of URLSeedGenerator and the other for Windows which uses
> > MS CryptoAPI). I made a few tweaks that allow this sub-infrastructure
> > to be used directly in ThreadLocalRandom and SplittableRandom:
> >
> > http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/
> >
>
> This seems to be the best idea yet, assuming that people are OK
> with the changes to sun.security.provider.SeedGenerator and
> NativeSeedGenerator.java
>
> -Doug
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140629/4ea053d0/attachment.html>

From peter.levart at gmail.com  Sun Jun 29 05:29:02 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 29 Jun 2014 11:29:02 +0200
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <1404006830.14661.4.camel@Nokia-N900>
References: <mailman.132.1403863934.24967.concurrency-interest@cs.oswego.edu>
	<1404006830.14661.4.camel@Nokia-N900>
Message-ID: <53AFDC5E.5070702@gmail.com>


On 06/29/2014 03:53 AM, Peter Firmstone wrote:
>
> It does look like a good solution.
>
> You might wonder why we still need a custom SecurityManager?
>
> Concurrency.
>
> The ageing java security infrastructure is a huge bottleneck for 
> multithreaded code.
>
> Regards,
>
> Peter.
>

Hi Peter,

If you could identify the most critical bottleneck(s) of default 
SecurityManager, there might be a way to fix them...

Regards, Peter

>
>
>
>
>
>
>
> > Message: 1
> > Date: Thu, 26 Jun 2014 19:10:22 -0400
> > From: Doug Lea <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>>
> > To: Peter Levart <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>>
> > Cc: core-libs-dev <core-libs-dev at openjdk.java.net 
> <mailto:core-libs-dev at openjdk.java.net>>, OpenJDK
> >     <security-dev at openjdk.java.net 
> <mailto:security-dev at openjdk.java.net>>, concurrency-interest
> >     <concurrency-interest at cs.oswego.edu 
> <mailto:concurrency-interest at cs.oswego.edu>>
> > Subject: Re: [concurrency-interest] ThreadLocalRandom clinit troubles
> > Message-ID: <53ACA85E.2030407 at cs.oswego.edu 
> <mailto:53ACA85E.2030407 at cs.oswego.edu>>
> > Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> >
> >
> > Peter: Thanks very much for attacking the shocking impact/complexity
> > of getting a few seed bits.
> >
> > On 06/25/2014 01:41 PM, Peter Levart wrote:
> > >
> > > Peeking around in the sun.security.provider package, I found there
> > > already is a minimal internal infrastructure for obtaining random
> > > seed. It's encapsulated in package-private abstract class
> > > sun.security.provider.SeedGenerator with 4 implementations. It turns
> > > out that, besides Java-only fall-back implementation called
> > > ThreadedSeedGenerator and generic URLSeedGenerator, there are also 
> two
> > > implementations of NativeSeedGenerator (one for UNIX-es which is just
> > > an extension of URLSeedGenerator and the other for Windows which uses
> > > MS CryptoAPI). I made a few tweaks that allow this sub-infrastructure
> > > to be used directly in ThreadLocalRandom and SplittableRandom:
> > >
> > > 
> http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/ 
> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/> 
>
> > >
> >
> > This seems to be the best idea yet, assuming that people are OK
> > with the changes to sun.security.provider.SeedGenerator and
> > NativeSeedGenerator.java
> >
> > -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140629/1660560a/attachment.html>

From peter.levart at gmail.com  Sun Jun 29 19:06:52 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Mon, 30 Jun 2014 01:06:52 +0200
Subject: [concurrency-interest] Custom ThreadPoolExecutor implementation
 to handle priority based Callable tasks
In-Reply-To: <53AE3B53.9000600@flyingtroika.com>
References: <NFBBKALFDCPFIDBNKAPCEEGPKHAA.davidcholmes@aapt.net.au>	<53ADDC49.9060403@flyingtroika.com>
	<53ADF08A.1070600@oracle.com> <53AE3B53.9000600@flyingtroika.com>
Message-ID: <53B09C0C.8020105@gmail.com>


On 06/28/2014 05:49 AM, DT wrote:
> I believe that
> 1 -  should be ok to accomplish
> 2 -  ok to satisfy or at least get very close to it as we know all 
> dependencies at the beginning
> 3 -  I like idea with counters: simple, straight and easy to follow
>
> However, the issue is that all the tasks (with dependency, etc) have 
> to finish execution within the same time slot as a whole.  We have to 
> enforce some sort of timing constraint. Same task can take different 
> time to execute (we can apply some statistical methods to get the 
> average for all the tasks based on the historical execution time).
>
> Would it be better to apply some sort of cyclic barriers or counters?
>
> Thanks,
> DT

Do you know the time slot in advance, when you submit the 1st task in a 
group of dependent tasks? If so, you could combine the Oleksandr's 
suggestion (which is how JDK8 CompletableFuture works) with the notion 
of "deadline" that you assign to a group. Deadline can serve two purposes:
- expires the tree of unfinished dependent tasks in a group when 
deadline is reached, skipping their execution
- can be used to prioritize de-queueing of tasks by TPE that will expire 
earlier (using PriorityBlockingQueue)

See here:

https://github.com/plevart/concurrent-utils/blob/master/src/si/pele/concurrent/ExpirableFutureTask.java

And an example here:

https://github.com/plevart/concurrent-utils/blob/master/src/si/pele/concurrent/test/EFTTest.java


Regards, Peter

> On 6/27/2014 3:30 PM, Oleksandr Otenko wrote:
>> 1. Each task must know how many dependencies it has.
>>
>> 2. Each task knows which other tasks depend on it.
>>
>> 3. Upon finishing a task, decrement the counters of all dependent 
>> tasks. Those that reach zero, get scheduled with the TPE.
>>
>>
>> If you don't know which tasks depend on which before executing them 
>> (ie you don't have answer for (2)), there is no efficient way of 
>> planning their execution.
>>
>> Alex
>>
>>
>> On 27/06/2014 22:04, DT wrote:
>>> if we dispatch tasks based on queuing we would not get guarantees 
>>> that the tasks first in line will finish execution first and futures 
>>> are done to return results (in general none of the dispatching 
>>> mechanism will give me such behavior, can be wrong of course, sorry 
>>> if I am mangled callable priorities which I wanted to use to control 
>>> execution of the tasks in some order with overall thread priorities)
>>> I think that I need some sort of scheduling constraints what task 
>>> should be done first so I can use futures results for dispatching 
>>> next set of tasks. I am not sure if for example CompletableFuture in 
>>> java 8 meant to be used for such problems. Namely tasks have to be 
>>> executed in certain order/deliver results and they can have 
>>> dependency/relationships between each other.
>>>
>>> By the way in what circumstances would you recommend to use TPE 
>>> constructor with own ThreadFactory implementation and not to relly 
>>> on the default one?
>>>
>>> DT
>>>
>>> On 6/27/2014 1:09 PM, David Holmes wrote:
>>>> Priority can only really be used for the dispatching/queueing 
>>>> mechanism. Once tasks are executing priority is essentially 
>>>> meaningless. Thread priorities have no significance in general.
>>>> David
>>>>
>>>>     -----Original Message-----
>>>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf
>>>>     Of *DT
>>>>     *Sent:* Saturday, 28 June 2014 1:42 AM
>>>>     *To:* viktor ?lang; dholmes at ieee.org
>>>>     *Cc:* concurrency-interest
>>>>     *Subject:* Re: [concurrency-interest] Custom ThreadPoolExecutor
>>>>     implementation to handle priority based Callable tasks
>>>>
>>>>                     We see several scenarios how to approach:
>>>>
>>>>     1-st approach is to use a PriorityBlockingQueue, provide
>>>>     Comparator for Callable tasks to change the order based on the
>>>>     Callable priority. Then when we call invokeAll( Collections of
>>>>     Callable tasks) on TPE to execute tasks from queue based on the
>>>>     priority, 1-st, 2-d, n which means that tasks will be executed
>>>>     based on abstract groups (for instance1-st group -- all tasks
>>>>     with high priority go first according to TPE scheduling.
>>>>     tpe.execute(thread) will be called and tasks will be assigned
>>>>     to available tpe worker threads.
>>>>
>>>>     Following this logic tpe does not guarantee for sure that all
>>>>     high priority tasks will be executed first. Or this guarantee
>>>>     is not enough enforced (maybe there are some policy to enforce
>>>>     this)
>>>>
>>>>     2-d approach is to modify invokeAll() to handle priority
>>>>     explicitly which does not look like a clean solution.
>>>>
>>>>     3-d approach is to have multiple TPEs and each of these tpe
>>>>     will handle only one type of priority without mix, for example
>>>>     tpe1 will invokeAll(tasks priority 1 only) , tpe2 will
>>>>     invokeAll(tasks priority 2 only). Which tpe should be
>>>>     instantiated -1^st should follow business logic.
>>>>
>>>>     Here is an example what we trying to implement. Assuming we
>>>>     have different types of tasks which are bounded to get some
>>>>     resources using udp/tcp/http/sql. Something like
>>>>
>>>>     sqlWorker needs to execute SQLs and return results, httpWorker
>>>>     type has to handle http calls and return some results, etc. the
>>>>     issue is that even if we assign some priorities to these
>>>>     workers to perform similar tasks following some business logic
>>>>     what data needs to get first within our workflow we would have
>>>>     to change priorities dynamically just because same type of
>>>>     workers mightfinish execution within different timeslot. So we
>>>>     have to wait until all workers are executed (practically tune
>>>>     timeslot based on the longest execution time) or drop some
>>>>     tasks due to the timing limits. If we follow 3-d approach it
>>>>     would be hard to manage TPEs. If we follow 2-d approach it
>>>>     would be hard to maintain tasks and guarantee execution group
>>>>     by group.And 1-st approach seems does not completely satisfy
>>>>     the problem concurrency execution logic.
>>>>
>>>>     On 6/27/2014 3:12 AM, ?iktor ?lang wrote:
>>>>>     "  public abstract void setPriority(int priority);" ? Changing
>>>>>     priority on an already submitted task seems strange.
>>>>>
>>>>>     I agree with David, just use a PriorityBlockingQueue
>>>>>     [http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/PriorityBlockingQueue.html]
>>>>>     for the submission queue of the TPE and provide a Comparator
>>>>>     that checks for your PriorityCallable and puts
>>>>>     non-PriorityCallable-Callables at an appropriate default priority.
>>>>>
>>>>>
>>>>>     On Fri, Jun 27, 2014 at 6:16 AM, David Holmes
>>>>>     <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>>>>>     wrote:
>>>>>
>>>>>         Can't you just use your PriorityCallable with a custom
>>>>>         PriorityQueue and
>>>>>         standard ThreadPoolExecutor?
>>>>>
>>>>>         David
>>>>>
>>>>>         > -----Original Message-----
>>>>>         > From: concurrency-interest-bounces at cs.oswego.edu
>>>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>         > [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>         Behalf Of DT
>>>>>         > Sent: Friday, 27 June 2014 2:08 PM
>>>>>         > To: concurrency-interest at cs.oswego.edu
>>>>>         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>         > Subject: [concurrency-interest] Custom
>>>>>         ThreadPoolExecutor implementation
>>>>>         > to handle priority based Callable tasks
>>>>>         >
>>>>>         >
>>>>>         > If we were to control Callable Tasks with Priorities and
>>>>>         to manage
>>>>>         > execution of those callable tasks through
>>>>>         ThreadPoolExecutor we would
>>>>>         > have to implement custom ThreadPoolExecutor and
>>>>>         PriorityCallable (see a
>>>>>         > suggestion below). What other ways to accomplish this do
>>>>>         you see ?
>>>>>         >
>>>>>         > public interface PriorityCallable extends Callable<Object> {
>>>>>         >      public abstract void setPriority(int priority);
>>>>>         >      ...
>>>>>         > }
>>>>>         >
>>>>>         > public class CustomThreadPoolExecutor  extends
>>>>>         ThreadPoolExecutor {
>>>>>         > ...
>>>>>         > ...
>>>>>         > public <T> List<Future<T>> customInvokeAll(
>>>>>         >                  Collection<? extends Callable<T>>
>>>>>         tasks, long timeout,
>>>>>         > TimeUnit unit) // pass PriorityCallable
>>>>>         >                  throws InterruptedException {
>>>>>         >              if (tasks == null || unit == null)
>>>>>         >                  throw new NullPointerException();
>>>>>         >              long nanos = unit.toNanos(timeout);
>>>>>         >              List<Future<T>> futures = new
>>>>>         > ArrayList<Future<T>>(tasks.size());
>>>>>         >              boolean done = false;
>>>>>         >              try {
>>>>>         >                  // handle Priority based Callable tasks
>>>>>         here, though
>>>>>         > can expect timing issues
>>>>>         >                  // custom logic to group Callable tasks
>>>>>         , if (priority
>>>>>         > == 1, 2, 3 create group of callables, etc )
>>>>>         >                  for (Callable<T> t : tasks)
>>>>>         >  futures.add(newTaskFor(t));
>>>>>         >
>>>>>         >                  long lastTime = System.nanoTime();
>>>>>         >
>>>>>         >                  // Interleave time checks and calls to
>>>>>         execute in case
>>>>>         >                  // executor doesn't have any/much
>>>>>         parallelism.
>>>>>         >  Iterator<Future<T>> it = futures.iterator();
>>>>>         >                  while (it.hasNext()) {
>>>>>         >  execute((Runnable)(it.next())); // should we expect
>>>>>         > futures get executed within the same timeframe for
>>>>>         Callables with
>>>>>         > different priorities
>>>>>         >                      long now = System.nanoTime();
>>>>>         >                      nanos -= now - lastTime;
>>>>>         >                      lastTime = now;
>>>>>         >                      if (nanos <= 0)
>>>>>         >                          return futures;
>>>>>         >                  }
>>>>>         >
>>>>>         >                  for (Future<T> f : futures) {
>>>>>         >                      if (!f.isDone()) {
>>>>>         >                          if (nanos <= 0)
>>>>>         >                              return futures;
>>>>>         >                          try {
>>>>>         >                              f.get(nanos,
>>>>>         TimeUnit.NANOSECONDS);
>>>>>         >                          } catch (CancellationException
>>>>>         ignore) {
>>>>>         >                          } catch (ExecutionException
>>>>>         ignore) { // Should
>>>>>         > we cancel tasks based on the priority as well?
>>>>>         >                          } catch (TimeoutException toe) {
>>>>>         >                              return futures;
>>>>>         >                          }
>>>>>         >                          long now = System.nanoTime();
>>>>>         >                          nanos -= now - lastTime;
>>>>>         >                          lastTime = now;
>>>>>         >                      }
>>>>>         >                  }
>>>>>         >                  done = true;
>>>>>         >                  return futures;
>>>>>         >              } finally {
>>>>>         >                  if (!done)
>>>>>         >                      for (Future<T> f : futures)
>>>>>         >                          f.cancel(true);
>>>>>         >              }
>>>>>         >          }
>>>>>         > ...
>>>>>         > }
>>>>>         >
>>>>>         > Thank you,
>>>>>         > dt
>>>>>         > http://www.flyingtroika.com/
>>>>>         >
>>>>>         > _______________________________________________
>>>>>         > Concurrency-interest mailing list
>>>>>         > Concurrency-interest at cs.oswego.edu
>>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>         > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>         _______________________________________________
>>>>>         Concurrency-interest mailing list
>>>>>         Concurrency-interest at cs.oswego.edu
>>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>     -- 
>>>>>     Cheers,
>>>>>     ?
>>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140630/adf940ca/attachment-0001.html>

From peter.firmstone at zeus.net.au  Mon Jun 30 06:02:30 2014
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Mon, 30 Jun 2014 20:02:30 +1000
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53AFDC5E.5070702@gmail.com>
References: <mailman.132.1403863934.24967.concurrency-interest@cs.oswego.edu>
	<1404006830.14661.4.camel@Nokia-N900> <53AFDC5E.5070702@gmail.com>
Message-ID: <53B135B6.1030105@zeus.net.au>

Hi Peter,

There are a number of bottlenecks throughout the security 
infrastructure, we have reimplemented it as follows to avoid them and 
have also addressed some long standing issues:

SecurityManager - cache previously checked AccessControlContext's  
(using a cache structure based on Cliff Click's non blocking hash map 
and Doug Lee's concurrent skip list set), to avoid repeately calling the 
policy provider (for example, you have numerous tasks in an 
ExecutorService and each has an identical AccessControlContext and all 
tasks cause a SocketPermission check).

Policy provider - replaced the built in Java policy provider.  The built 
in Java Policy provider will hold a lock while making DNS calls, 
bringing all permission checks to a grinding halt.  It will also hold 
locks while accessing the file system.

To avoid making DNS calls we've implemented our own policy provider, 
originated from Apache Harmony, but modified to use non blocking 
immutability.  It creates PermissionCollection's on demand, they're not 
shared among threads and are ordered in the most favourable order for a 
fast result.  It also supports undocumented Java file policy provider 
functionality.  Because Permission objects are immutable but lazily 
initialized, we call getActions() to ensure their state is completely 
initialized prior to publication.

The policy provider uses a strictly RFC 3986 compliant immutable URI 
class, it performs bit shift operations on ASCII strings during 
normalisation and is used by the policy provider to avoid making DNS 
calls when checking CodeBase policy file permissions.

As a result, the cost of the security infrastructure is less than 1% of 
CPU load during stress tests.

This is part of the Apache River project, JERI (Jini Extensible Remote 
Invocation) performs remote method invocations as tasks running in a 
system threadpool, each task executes concurrently on any exported service.

SecureClassLoader uses CodeSource's as keys in a Map, CodeSource uses 
URL in equals() and hashCode(), so we also have a RFC3986 compliant 
URLClassLoader to avoid making unnecessary DNS calls in SecureClassLoader.

Rather than rely on an external untrusted DNS to determine the identity 
of CodeSource's, we use RFC 3986 compliant normalisation, without making 
DNS calls.  URL's still make DNS calls when retrieving a URL.  The 
difference is, two different host names that previously resolved to an 
identical IP address will no longer be equal, but now we can use dynamic 
dns addresses and fail over replication for domain names that use a 
range of IP addresses to answer for one domain address.  Standard Java 
SecureClassLoader behaviour can be had by setting a system property

This also reduces or avoids calls to the built in java NameServiceProvider.

If this code was in the JVM libraries, we wouldn't need it in our project.

This code is freely available.

Regards,

Peter.

On 29/06/2014 7:29 PM, Peter Levart wrote:
>
> On 06/29/2014 03:53 AM, Peter Firmstone wrote:
>>
>> It does look like a good solution.
>>
>> You might wonder why we still need a custom SecurityManager?
>>
>> Concurrency.
>>
>> The ageing java security infrastructure is a huge bottleneck for 
>> multithreaded code.
>>
>> Regards,
>>
>> Peter.
>>
>
> Hi Peter,
>
> If you could identify the most critical bottleneck(s) of default 
> SecurityManager, there might be a way to fix them...
>
> Regards, Peter
>
>>
>>
>>
>>
>>
>>
>>
>> > Message: 1
>> > Date: Thu, 26 Jun 2014 19:10:22 -0400
>> > From: Doug Lea <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>>
>> > To: Peter Levart <peter.levart at gmail.com 
>> <mailto:peter.levart at gmail.com>>
>> > Cc: core-libs-dev <core-libs-dev at openjdk.java.net 
>> <mailto:core-libs-dev at openjdk.java.net>>,    OpenJDK
>> > <security-dev at openjdk.java.net 
>> <mailto:security-dev at openjdk.java.net>>,    concurrency-interest
>> > <concurrency-interest at cs.oswego.edu 
>> <mailto:concurrency-interest at cs.oswego.edu>>
>> > Subject: Re: [concurrency-interest] ThreadLocalRandom clinit troubles
>> > Message-ID: <53ACA85E.2030407 at cs.oswego.edu 
>> <mailto:53ACA85E.2030407 at cs.oswego.edu>>
>> > Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>> >
>> >
>> > Peter: Thanks very much for attacking the shocking impact/complexity
>> > of getting a few seed bits.
>> >
>> > On 06/25/2014 01:41 PM, Peter Levart wrote:
>> > >
>> > > Peeking around in the sun.security.provider package, I found there
>> > > already is a minimal internal infrastructure for obtaining random
>> > > seed. It's encapsulated in package-private abstract class
>> > > sun.security.provider.SeedGenerator with 4 implementations. It turns
>> > > out that, besides Java-only fall-back implementation called
>> > > ThreadedSeedGenerator and generic URLSeedGenerator, there are 
>> also two
>> > > implementations of NativeSeedGenerator (one for UNIX-es which is 
>> just
>> > > an extension of URLSeedGenerator and the other for Windows which 
>> uses
>> > > MS CryptoAPI). I made a few tweaks that allow this 
>> sub-infrastructure
>> > > to be used directly in ThreadLocalRandom and SplittableRandom:
>> > >
>> > > 
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/ 
>> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/TLR_SR_SeedGenerator/webrev.01/> 
>>
>> > >
>> >
>> > This seems to be the best idea yet, assuming that people are OK
>> > with the changes to sun.security.provider.SeedGenerator and
>> > NativeSeedGenerator.java
>> >
>> > -Doug
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From Alan.Bateman at oracle.com  Mon Jun 30 08:53:38 2014
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Mon, 30 Jun 2014 13:53:38 +0100
Subject: [concurrency-interest] ThreadLocalRandom clinit troubles
In-Reply-To: <53B135B6.1030105@zeus.net.au>
References: <mailman.132.1403863934.24967.concurrency-interest@cs.oswego.edu>	<1404006830.14661.4.camel@Nokia-N900>
	<53AFDC5E.5070702@gmail.com> <53B135B6.1030105@zeus.net.au>
Message-ID: <53B15DD2.8020200@oracle.com>

On 30/06/2014 11:02, Peter Firmstone wrote:
> Hi Peter,
>
> There are a number of bottlenecks throughout the security 
> infrastructure, we have reimplemented it as follows to avoid them and 
> have also addressed some long standing issues:
>
>
> If this code was in the JVM libraries, we wouldn't need it in our 
> project.
>
Have you considered bring some of these patches to OpenJDK?

On RFC 3986 (you mentioned this a number of times) then there were 
previous attempts bring URI up to this, unfortunately had to be backed 
out due to compatibility issues and other breakage. It's definitely 
something that needs to be looked at again.

-Alan


