From dl at cs.oswego.edu  Sun Mar  1 14:47:04 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 01 Mar 2009 14:47:04 -0500
Subject: [concurrency-interest] Fire and forget api for queing vs.
 BlockingQueue interface (TransferQueue will be inefficient?)
In-Reply-To: <8620303.35921235861002700.JavaMail.tgautier@corvette.local>
References: <8620303.35921235861002700.JavaMail.tgautier@corvette.local>
Message-ID: <49AAE638.3070904@cs.oswego.edu>

Taylor Gautier wrote:

> What I mean specifically is that the presence of the consumer operations 
> in the interface forces the queue to always maintain a consistent state 
> - on both "sides" of the "fence" (fence meaning thread boundary, in 
> Terracotta, it's a process boundary usually)
This is a tradeoff in API design, that I've
done both ways (and both multiple times). Is a Queue more
like a Socket end-point or more like a List? Either way you go,
someone is unhappy. Many people complained about my pre-j.u.c.
(dl.u.c) "Channel" API because it was too socket-like and
not enough List-like.

The best defense of using the more encompassing Collection-based
approach is that people building middleware can use it underneath
their own abstractions to implement within-process cases
efficiently, but only if they don't further expose/export the APIs.
I think this is what most people do.

Terracotta ambitiously goes beyond this, to support full APIs across
process boundaries, which is going to be even more challenging
as parallelism support becomes increasingly fine-grained. I don't
know what we can do in java.util.concurrent to make it any less so
though.

-Doug











From mallikap at deshaw.com  Mon Mar  2 00:52:10 2009
From: mallikap at deshaw.com (Mallikarjunaiah, Praveena)
Date: Mon, 2 Mar 2009 11:22:10 +0530
Subject: [concurrency-interest] Reason behind making execute method of
	SwingWorker as final ?
Message-ID: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>

Hi,

I was wondering why execute() method of SwingWorker is made final. In
some cases,  I want certain type of SwingWorker's to use a specific
thread.
Currently, this can be done by explicitly putting the worker in a custom
executor service.  I would like put this logic in execute() method so
that
Generators of SwingWorker need not worry how to execute them.

Am I missing something here ?

Thanks
Praveena


From mallikap at deshaw.com  Mon Mar  2 09:46:16 2009
From: mallikap at deshaw.com (Mallikarjunaiah, Praveena)
Date: Mon, 2 Mar 2009 20:16:16 +0530
Subject: [concurrency-interest] Reason behind making execute method of
	SwingWorker as final ?
In-Reply-To: <49ABEFB3.1080306@wonderly.org>
References: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
	<49ABEFB3.1080306@wonderly.org>
Message-ID: <B911686319FBAC4BA4671AF36F8DC309056F5CC3@mailhyd2.hyd.deshaw.com>

SwingWorker's doInBackground() method will be called from non-EDT
(event-dispatch-thread).
It guarantees that process() method will be called in EDT.

You can control which thread runs doInBackground() using custom
execution service.

My question was how best we can hide this information from the user of
subclass of SwingWorker.
(One way that I thought was overriding execute() method but that is a
final method)

-Praveena

-----Original Message-----
From: Gregg Wonderly [mailto:gregg at wonderly.org] 
Sent: Monday, March 02, 2009 8:10 PM
To: Mallikarjunaiah, Praveena
Subject: Re: [concurrency-interest] Reason behind making execute method
of SwingWorker as final ?

Mallikarjunaiah, Praveena wrote:
> Hi,
> 
> I was wondering why execute() method of SwingWorker is made final. In
> some cases,  I want certain type of SwingWorker's to use a specific
> thread.
> Currently, this can be done by explicitly putting the worker in a
custom
> executor service.  I would like put this logic in execute() method so
> that
> Generators of SwingWorker need not worry how to execute them.

The SwingWorker class is intended to allow execution in only one
specific type 
of thread, an AWT event dispatch thread.  Usually there is exactly one
of those, 
but sometimes, during dialog display, one may be halted and another
created to 
process events in that dialog.  Thus, there is only, exactly one active
to 
execute tasks, and the event queue is where requests go to be responded
to by 
that one active thread.

Are you trying to make work go into the queue of a halted event dispatch
thread?

Gregg Wonderly


From joe.bowbeer at gmail.com  Mon Mar  2 11:00:10 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 2 Mar 2009 08:00:10 -0800
Subject: [concurrency-interest] Reason behind making execute method of
	SwingWorker as final ?
In-Reply-To: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
References: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
Message-ID: <31f2a7bd0903020800v6a8ac4c5h4b7d168d6af0303f@mail.gmail.com>

Praveena,

I see your point.  For your purposes, it would be nice if you could supply
your own executor service, or even thread factory.  If only the
getWorkerExecutorService method was not private static...

Manually submitting the SwingWorker to a custom executor was the solution
envisioned by the designers.

See related discussion:

http://forums.java.net/jive/thread.jspa?messageID=210526

I suggest you contact Igor Kushnirskiy and/or whoever is currently
maintaining SwingWorker.

Joe

On Sun, Mar 1, 2009 at 9:52 PM, Mallikarjunaiah, Praveena wrote:

> Hi,
>
> I was wondering why execute() method of SwingWorker is made final. In
> some cases,  I want certain type of SwingWorker's to use a specific
> thread.
> Currently, this can be done by explicitly putting the worker in a custom
> executor service.  I would like put this logic in execute() method so
> that
> Generators of SwingWorker need not worry how to execute them.
>
> Am I missing something here ?
>
> Thanks
> Praveena
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090302/19ef68f0/attachment.html>

From gregg at cytetech.com  Mon Mar  2 13:04:41 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 02 Mar 2009 12:04:41 -0600
Subject: [concurrency-interest] Reason behind making execute method of
 SwingWorker as final ?
In-Reply-To: <B911686319FBAC4BA4671AF36F8DC309056F5CC3@mailhyd2.hyd.deshaw.com>
References: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
	<49ABEFB3.1080306@wonderly.org>
	<B911686319FBAC4BA4671AF36F8DC309056F5CC3@mailhyd2.hyd.deshaw.com>
Message-ID: <49AC1FB9.1010700@cytetech.com>

I have long used my own private subclass of an old version of swing-worker.  The 
main reason, is that I need to put a Subject and a context ClassLoader in view 
of doInBackground().  We've evolved our patterns over the years based on 
different experiences.

There is a version of this under http://swingutil.dev.java.net called 
org.wonderly.swing.SyncThread.  With this class, you could do what you are 
talking about, I believe.  An illustration of this would be the following code, 
which would perform a local search on some remotely gathered String values and 
then select the first one which matches, if any.

// Somewhere there is an executor visible.
ThreadPoolExecutor exec = ...

public void searchFor( String search ) {

     // Create an instance which uses exec to run the
     // background threads.  Disable comp while it runs.
     final SyncThread th = new SyncThread( comp ) {

         public void schedule( Runnable r ) {
             exec.execute( r );
         }
     };

     // Create a step which will get the values from
     // the remote instance
     th.add( new SyncThread<String[],String[]>() {

         public String[] run() {
             return remote.getValues();
         }

         public void done() {
             comp.setModel( new MyModel( getValue() ) );
         }
     });

     // Add another step to use the data and select the
     // searched for value if found.
     th.add( new SyncThread<String,String>() {

         public String run() {
             String[] dt = th.getLastThreadValue();
             for( String s : dt ) {
                 if( findPattern( search, s ) ) {
                     return s;
                 }
             }
             return null;
         }

         public void done() {
             if( getValue() == null ) {
                 comp.clearSelection();
             } else {
                 comp.setSelectedValue( getValue() );
             }
         }
     });

     // Run all the steps to completion and return
     th.block();
}

Mallikarjunaiah, Praveena wrote:
> SwingWorker's doInBackground() method will be called from non-EDT
> (event-dispatch-thread).
> It guarantees that process() method will be called in EDT.
> 
> You can control which thread runs doInBackground() using custom
> execution service.
> 
> My question was how best we can hide this information from the user of
> subclass of SwingWorker.
> (One way that I thought was overriding execute() method but that is a
> final method)
> 
> -Praveena
> 
> -----Original Message-----
> From: Gregg Wonderly [mailto:gregg at wonderly.org] 
> Sent: Monday, March 02, 2009 8:10 PM
> To: Mallikarjunaiah, Praveena
> Subject: Re: [concurrency-interest] Reason behind making execute method
> of SwingWorker as final ?
> 
> Mallikarjunaiah, Praveena wrote:
>> Hi,
>>
>> I was wondering why execute() method of SwingWorker is made final. In
>> some cases,  I want certain type of SwingWorker's to use a specific
>> thread.
>> Currently, this can be done by explicitly putting the worker in a
> custom
>> executor service.  I would like put this logic in execute() method so
>> that
>> Generators of SwingWorker need not worry how to execute them.
> 
> The SwingWorker class is intended to allow execution in only one
> specific type 
> of thread, an AWT event dispatch thread.  Usually there is exactly one
> of those, 
> but sometimes, during dialog display, one may be halted and another
> created to 
> process events in that dialog.  Thus, there is only, exactly one active
> to 
> execute tasks, and the event queue is where requests go to be responded
> to by 
> that one active thread.
> 
> Are you trying to make work go into the queue of a halted event dispatch
> thread?
> 
> Gregg Wonderly
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


From mallikap at deshaw.com  Mon Mar  2 22:58:19 2009
From: mallikap at deshaw.com (Mallikarjunaiah, Praveena)
Date: Tue, 3 Mar 2009 09:28:19 +0530
Subject: [concurrency-interest] Reason behind making execute method
	ofSwingWorker as final ?
In-Reply-To: <31f2a7bd0903020800v6a8ac4c5h4b7d168d6af0303f@mail.gmail.com>
References: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
	<31f2a7bd0903020800v6a8ac4c5h4b7d168d6af0303f@mail.gmail.com>
Message-ID: <B911686319FBAC4BA4671AF36F8DC309056F5CC4@mailhyd2.hyd.deshaw.com>

After reading that thread, I tend to agree that I should have used
containment rather inheritence. (as my XXXDataLoader is not a
SwingWorker).
 
Thanks for the pointers.
 
-Praveena


________________________________

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Joe
Bowbeer
Sent: Monday, March 02, 2009 9:30 PM
To: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Reason behind making execute method
ofSwingWorker as final ?


Praveena,

I see your point.  For your purposes, it would be nice if you could
supply your own executor service, or even thread factory.  If only the
getWorkerExecutorService method was not private static...

Manually submitting the SwingWorker to a custom executor was the
solution envisioned by the designers.

See related discussion:

http://forums.java.net/jive/thread.jspa?messageID=210526

I suggest you contact Igor Kushnirskiy and/or whoever is currently
maintaining SwingWorker.

Joe


On Sun, Mar 1, 2009 at 9:52 PM, Mallikarjunaiah, Praveena wrote:


	Hi,
	
	I was wondering why execute() method of SwingWorker is made
final. In
	some cases,  I want certain type of SwingWorker's to use a
specific
	thread.
	Currently, this can be done by explicitly putting the worker in
a custom
	executor service.  I would like put this logic in execute()
method so
	that
	Generators of SwingWorker need not worry how to execute them.
	
	Am I missing something here ?
	
	Thanks
	Praveena
	


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090303/ecb7c547/attachment.html>

From mallikap at deshaw.com  Mon Mar  2 23:01:04 2009
From: mallikap at deshaw.com (Mallikarjunaiah, Praveena)
Date: Tue, 3 Mar 2009 09:31:04 +0530
Subject: [concurrency-interest] Reason behind making execute method of
	SwingWorker as final ?
In-Reply-To: <49AC1FB9.1010700@cytetech.com>
References: <B911686319FBAC4BA4671AF36F8DC309056F5CBC@mailhyd2.hyd.deshaw.com>
	<49ABEFB3.1080306@wonderly.org>
	<B911686319FBAC4BA4671AF36F8DC309056F5CC3@mailhyd2.hyd.deshaw.com>
	<49AC1FB9.1010700@cytetech.com>
Message-ID: <B911686319FBAC4BA4671AF36F8DC309056F5CC5@mailhyd2.hyd.deshaw.com>

Looks interesting. I haven't checked in details but definitely there are
good stuffs to be learn from 
your swingutils. 
 
Thanks,
-Praveena

-----Original Message-----
From: Gregg Wonderly [mailto:gregg at cytetech.com] 
Sent: Monday, March 02, 2009 11:35 PM
To: Mallikarjunaiah, Praveena
Cc: Gregg Wonderly; Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Reason behind making execute method
of SwingWorker as final ?

I have long used my own private subclass of an old version of
swing-worker.  The 
main reason, is that I need to put a Subject and a context ClassLoader
in view 
of doInBackground().  We've evolved our patterns over the years based on

different experiences.

There is a version of this under http://swingutil.dev.java.net called 
org.wonderly.swing.SyncThread.  With this class, you could do what you
are 
talking about, I believe.  An illustration of this would be the
following code, 
which would perform a local search on some remotely gathered String
values and 
then select the first one which matches, if any.

// Somewhere there is an executor visible.
ThreadPoolExecutor exec = ...

public void searchFor( String search ) {

     // Create an instance which uses exec to run the
     // background threads.  Disable comp while it runs.
     final SyncThread th = new SyncThread( comp ) {

         public void schedule( Runnable r ) {
             exec.execute( r );
         }
     };

     // Create a step which will get the values from
     // the remote instance
     th.add( new SyncThread<String[],String[]>() {

         public String[] run() {
             return remote.getValues();
         }

         public void done() {
             comp.setModel( new MyModel( getValue() ) );
         }
     });

     // Add another step to use the data and select the
     // searched for value if found.
     th.add( new SyncThread<String,String>() {

         public String run() {
             String[] dt = th.getLastThreadValue();
             for( String s : dt ) {
                 if( findPattern( search, s ) ) {
                     return s;
                 }
             }
             return null;
         }

         public void done() {
             if( getValue() == null ) {
                 comp.clearSelection();
             } else {
                 comp.setSelectedValue( getValue() );
             }
         }
     });

     // Run all the steps to completion and return
     th.block();
}

Mallikarjunaiah, Praveena wrote:
> SwingWorker's doInBackground() method will be called from non-EDT
> (event-dispatch-thread).
> It guarantees that process() method will be called in EDT.
> 
> You can control which thread runs doInBackground() using custom
> execution service.
> 
> My question was how best we can hide this information from the user of
> subclass of SwingWorker.
> (One way that I thought was overriding execute() method but that is a
> final method)
> 
> -Praveena
> 
> -----Original Message-----
> From: Gregg Wonderly [mailto:gregg at wonderly.org] 
> Sent: Monday, March 02, 2009 8:10 PM
> To: Mallikarjunaiah, Praveena
> Subject: Re: [concurrency-interest] Reason behind making execute
method
> of SwingWorker as final ?
> 
> Mallikarjunaiah, Praveena wrote:
>> Hi,
>>
>> I was wondering why execute() method of SwingWorker is made final. In
>> some cases,  I want certain type of SwingWorker's to use a specific
>> thread.
>> Currently, this can be done by explicitly putting the worker in a
> custom
>> executor service.  I would like put this logic in execute() method so
>> that
>> Generators of SwingWorker need not worry how to execute them.
> 
> The SwingWorker class is intended to allow execution in only one
> specific type 
> of thread, an AWT event dispatch thread.  Usually there is exactly one
> of those, 
> but sometimes, during dialog display, one may be halted and another
> created to 
> process events in that dialog.  Thus, there is only, exactly one
active
> to 
> execute tasks, and the event queue is where requests go to be
responded
> to by 
> that one active thread.
> 
> Are you trying to make work go into the queue of a halted event
dispatch
> thread?
> 
> Gregg Wonderly
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 



From cleber at nightcoders.com.br  Tue Mar  3 04:42:26 2009
From: cleber at nightcoders.com.br (Cleber Muramoto)
Date: Tue, 3 Mar 2009 06:42:26 -0300
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 50,
	Issue 1
In-Reply-To: <mailman.1.1235926800.29234.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1235926800.29234.concurrency-interest@cs.oswego.edu>
Message-ID: <668a9da40903030142l80bb497w9c2e6c165ce17cf3@mail.gmail.com>

> Message: 3
> Date: Sat, 28 Feb 2009 14:43:26 -0800 (PST)
> From: Taylor Gautier <tgautier at terracottatech.com>
> Subject: [concurrency-interest] Fire and forget api for queing vs.
>        BlockingQueue interface (TransferQueue will be inefficient?)
> To: concurrency-interest at cs.oswego.edu
> Message-ID:
>        <8620303.35921235861002700.JavaMail.tgautier at corvette.local>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hi.
> <...>

In other words, the fire and forget nature of sockets and message passing
> interfaces (e.g. Actors in Scala and or Erlang) seem more suitable for
> cross-thread communication, and that leaves me wondering what the point of
> TransferQueue is (based on Alex's post, I can see that it is much better at
> thread-thread handoffs than LBQ, which is good, but I wonder if it needs to
> or should have BQ as a superinterface)
>
> Well, I hope you read this far, does any of this make sense or am I just
> way out in left field here?
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090228/d4706853/attachment-0001.html
> >
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> End of Concurrency-interest Digest, Vol 50, Issue 1
> ***************************************************
>
>
Hi, a few days ago I came across a message-passing framework for java (
http://www.malhar.net/sriram/kilim/) , which addresses mainly 1 consumer x N
producers problem. It seems very promising and it tends to rely more on
synchronization primitives instead of more sofisticated constructs such as
j.u.c Locks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090303/b1d84150/attachment.html>

From peter.royal at pobox.com  Tue Mar  3 13:06:29 2009
From: peter.royal at pobox.com (peter royal)
Date: Tue, 3 Mar 2009 10:06:29 -0800
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 50,
 Issue 1
In-Reply-To: <668a9da40903030142l80bb497w9c2e6c165ce17cf3@mail.gmail.com>
References: <mailman.1.1235926800.29234.concurrency-interest@cs.oswego.edu>
	<668a9da40903030142l80bb497w9c2e6c165ce17cf3@mail.gmail.com>
Message-ID: <EC6D266A-B5F8-4293-9989-52E7710F4CED@pobox.com>

On Mar 3, 2009, at 1:42 AM, Cleber Muramoto wrote:
> Hi, a few days ago I came across a message-passing framework for  
> java (http://www.malhar.net/sriram/kilim/) , which addresses mainly  
> 1 consumer x N producers problem. It seems very promising and it  
> tends to rely more on synchronization primitives instead of more  
> sofisticated constructs such as j.u.c Locks.

http://code.google.com/p/jetlang/ is another message-passing framework  
(similar to kilim, just no bytecode swizzling).

-pete

-- 
(peter.royal|osi)@pobox.com - http://fotap.org/~osi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 2454 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090303/b4394725/attachment.bin>

From alexdmiller at yahoo.com  Wed Mar  4 13:19:45 2009
From: alexdmiller at yahoo.com (Alex Miller)
Date: Wed, 4 Mar 2009 10:19:45 -0800 (PST)
Subject: [concurrency-interest] actor frameworks
References: <mailman.1.1236186000.15654.concurrency-interest@cs.oswego.edu>
Message-ID: <112982.3082.qm@web32208.mail.mud.yahoo.com>


FYI, I recently wrote an article on actors in Erlang:

http://www.javaworld.com/javaworld/jw-02-2009/jw-02-actor-concurrency1.html

and I'm working on the followup for mid-late March which will be on actors on the JVM, looking at Scala, possibly GParallelizer in Groovy, and some of the Java actor / message-passing frameworks (Kilim, Jetlang, Actor's Guild, ActorFoundry).  Lots of options these days.  

Alex



On Mar 3, 2009, at 10:06 AM, peter royal wrote:

> On Mar 3, 2009, at 1:42 AM, Cleber Muramoto wrote:
> > Hi, a few days ago I came across a message-passing framework for  
> > java (http://www.malhar.net/sriram/kilim/) , which addresses mainly  
> > 1 consumer x N producers problem. It seems very promising and it  
> > tends to rely more on synchronization primitives instead of more  
> > sofisticated constructs such as j.u.c Locks.

> http://code.google.com/p/jetlang/ is another message-passing framework  
> (similar to kilim, just no bytecode swizzling).
>
> -pete
> 
> -- 
> (peter.royal|osi)@pobox.com - http://fotap.org/~osi

From raould at gmail.com  Wed Mar  4 14:10:18 2009
From: raould at gmail.com (Raoul Duke)
Date: Wed, 4 Mar 2009 11:10:18 -0800
Subject: [concurrency-interest] actor frameworks
In-Reply-To: <112982.3082.qm@web32208.mail.mud.yahoo.com>
References: <mailman.1.1236186000.15654.concurrency-interest@cs.oswego.edu>
	<112982.3082.qm@web32208.mail.mud.yahoo.com>
Message-ID: <91a2ba3e0903041110n63e10f94i1008139ceb9252f9@mail.gmail.com>

> Lots of options these days.

yeah, but the question is, which ones are actually robust? :-)

From alexdmiller at yahoo.com  Wed Mar  4 14:47:34 2009
From: alexdmiller at yahoo.com (Alex Miller)
Date: Wed, 4 Mar 2009 11:47:34 -0800 (PST)
Subject: [concurrency-interest] actor frameworks
References: <mailman.1.1236186000.15654.concurrency-interest@cs.oswego.edu>
	<112982.3082.qm@web32208.mail.mud.yahoo.com>
	<91a2ba3e0903041110n63e10f94i1008139ceb9252f9@mail.gmail.com>
Message-ID: <612993.64112.qm@web32202.mail.mud.yahoo.com>


I think Scala's is mature enough that I'd plan a production app on it (with caveats for early perf testing).  I would want to thrash the others more first.  Kilim does compile-time weaving which I find to be a pain from a tooling point of view, regardless of whether it works.  I'm not sure whether any of the Java frameworks have been tested much if at all on big multi-core machines.  I'm hoping to grab a few cycles to try them at work if we have a machine free.  From the small benchmarking I've done in the past and that I've read from others, the basics like message send are very fast, in the same general order of magnitude with Erlang.  It's really hard to tell how good the scheduling and other critical parts are though without really building an app-level benchmark.




----- Original Message ----
From: Raoul Duke <raould at gmail.com>
To: Alex Miller <alexdmiller at yahoo.com>
Cc: concurrency-interest at cs.oswego.edu
Sent: Wednesday, March 4, 2009 1:10:18 PM
Subject: Re: [concurrency-interest] actor frameworks

> Lots of options these days.

yeah, but the question is, which ones are actually robust? :-)


From david at walend.net  Thu Mar  5 22:40:57 2009
From: david at walend.net (David Walend)
Date: Thu, 5 Mar 2009 22:40:57 -0500
Subject: [concurrency-interest] actor frameworks
In-Reply-To: <mailman.1.1236272400.20595.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1236272400.20595.concurrency-interest@cs.oswego.edu>
Message-ID: <EC176023-FDD9-46DF-810D-F3ABB86E5AD8@walend.net>


On Mar 5, 2009, at 12:00 PM, concurrency-interest- 
request at cs.oswego.edu wrote:

> I think Scala's is mature enough that I'd plan a production app on  
> it (with caveats for early perf testing).

Alex,

Whenever I look at actors, I see the message queues I first saw in big  
banks 15 years ago. They'd been there longer. I was what was new. They  
work great, provide a good trade space between speed and reliability.  
The most common patterns to use are either Actors or Events. When you  
say Actor I hear MessageListener.

The only big change with message queues was their unification of API  
via the JMS spec in 1999. The JMS spec itself is pretty remarkable --  
almost eight years without even a minor revision, and no major  
revision in ten years. (Compare that to the arms race that is JDBC.)

Dave

> I would want to thrash the others more first.  Kilim does compile- 
> time weaving which I find to be a pain from a tooling point of view,  
> regardless of whether it works.  I'm not sure whether any of the  
> Java frameworks have been tested much if at all on big multi-core  
> machines.  I'm hoping to grab a few cycles to try them at work if we  
> have a machine free.  From the small benchmarking I've done in the  
> past and that I've read from others, the basics like message send  
> are very fast, in the same general order of magnitude with Erlang.   
> It's really hard to tell how good the scheduling and other critical  
> parts are though without really building an app-level benchmark.
>
>
>
>
> ----- Original Message ----
> From: Raoul Duke <raould at gmail.com>
> To: Alex Miller <alexdmiller at yahoo.com>
> Cc: concurrency-interest at cs.oswego.edu
> Sent: Wednesday, March 4, 2009 1:10:18 PM
> Subject: Re: [concurrency-interest] actor frameworks
>
>> Lots of options these days.
>
> yeah, but the question is, which ones are actually robust? :-)
>
>
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> End of Concurrency-interest Digest, Vol 50, Issue 5
> ***************************************************


From osvaldo at visionnaire.com.br  Fri Mar  6 08:31:37 2009
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Fri, 06 Mar 2009 10:31:37 -0300
Subject: [concurrency-interest] actor frameworks
In-Reply-To: <EC176023-FDD9-46DF-810D-F3ABB86E5AD8@walend.net>
References: <mailman.1.1236272400.20595.concurrency-interest@cs.oswego.edu>
	<EC176023-FDD9-46DF-810D-F3ABB86E5AD8@walend.net>
Message-ID: <49B125B9.1070304@visionnaire.com.br>

Em 06/03/2009 00:40, David Walend escreveu:
> The only big change with message queues was their unification of API 
> via the JMS spec in 1999. The JMS spec itself is pretty remarkable -- 
> almost eight years without even a minor revision, and no major 
> revision in ten years. (Compare that to the arms race that is JDBC.)
Well, this is not so remarkable considering that JMS provides you a 
simple, weakly-typed data representation: a message is just a Map of 
headers (with a very short selection of types) plus a payload that's a 
simple blob (well, you can choose a binary blog and a text blob!). On 
top of that, JMS doesn't give you easy/standard access to the massive 
complexity of the middleware - look for instance the configuration of a 
IBM WebSphere MQ's queue manager and its queues, there is a bewildering 
number of properties, configurations and facilities for monitoring, 
routing etc.

But I have written massive JMS applications (for banking - what else?) 
and I never needed programmatic access to any feature that's not exposed 
by JMS. I only needed static configs that could be performed on the 
messaging server and/or the application server. This is a big 
difference; when dealing with a DBMS, I typically need dynamic access to 
all sorts of advanced features, so I either use an up-to-date JDBC 
driver with specific APIs, or I'm forced through DBMS-proprietary driver 
APIs or proprietary SQL extensions (at least, good ORM tools will do 
that for me most of the time).

My verdict is that JMS is really a very well designed API, kudos again 
to its authors, but it's a much more tractable domain that say JDBC/RDBMS...

A+
Osvaldo
>
> Dave
>
>> I would want to thrash the others more first.  Kilim does 
>> compile-time weaving which I find to be a pain from a tooling point 
>> of view, regardless of whether it works.  I'm not sure whether any of 
>> the Java frameworks have been tested much if at all on big multi-core 
>> machines.  I'm hoping to grab a few cycles to try them at work if we 
>> have a machine free.  From the small benchmarking I've done in the 
>> past and that I've read from others, the basics like message send are 
>> very fast, in the same general order of magnitude with Erlang.  It's 
>> really hard to tell how good the scheduling and other critical parts 
>> are though without really building an app-level benchmark.
>>
>>
>>
>>
>> ----- Original Message ----
>> From: Raoul Duke <raould at gmail.com>
>> To: Alex Miller <alexdmiller at yahoo.com>
>> Cc: concurrency-interest at cs.oswego.edu
>> Sent: Wednesday, March 4, 2009 1:10:18 PM
>> Subject: Re: [concurrency-interest] actor frameworks
>>
>>> Lots of options these days.
>>
>> yeah, but the question is, which ones are actually robust? :-)
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> End of Concurrency-interest Digest, Vol 50, Issue 5
>> ***************************************************
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                        Visionnaire Virtus S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #226


From gregg at cytetech.com  Fri Mar  6 10:09:42 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Fri, 06 Mar 2009 09:09:42 -0600
Subject: [concurrency-interest] actor frameworks
In-Reply-To: <EC176023-FDD9-46DF-810D-F3ABB86E5AD8@walend.net>
References: <mailman.1.1236272400.20595.concurrency-interest@cs.oswego.edu>
	<EC176023-FDD9-46DF-810D-F3ABB86E5AD8@walend.net>
Message-ID: <49B13CB6.9010609@cytetech.com>

One the simplest strategies for eliminating context switches between senders and 
receivers, is to have sender call into receiver's listener.  If Kilim code 
weaving works, this will work as well.  More importantly, the listener, who 
actually knows how expensive 'his' task is, can dispatch into thread pools or do 
other per message optimizations so that throttling of incomming load, due to 
messages, can be managed.

The Kilim weaving looks interesting.  Look at the old ObjectStore database, 
which did code weaving to implement persistence of objects, automatically.  In 
the end, it didn't really survive as a useful detail, because of several issues. 
  One of those was, of course, the fact that you had to license it.  But, it was 
also a little painful for general reuse because of the multi-step compilation 
and management of the overall build of any package needing it.

I've been using the same "Space" with sender-calls-subscriber implementation for 
many years, and it's never been the performance bottle neck of my broker.

Gregg Wonderly

David Walend wrote:
> 
> On Mar 5, 2009, at 12:00 PM, concurrency-interest-request at cs.oswego.edu 
> wrote:
> 
>> I think Scala's is mature enough that I'd plan a production app on it 
>> (with caveats for early perf testing).
> 
> Alex,
> 
> Whenever I look at actors, I see the message queues I first saw in big 
> banks 15 years ago. They'd been there longer. I was what was new. They 
> work great, provide a good trade space between speed and reliability. 
> The most common patterns to use are either Actors or Events. When you 
> say Actor I hear MessageListener.
> 
> The only big change with message queues was their unification of API via 
> the JMS spec in 1999. The JMS spec itself is pretty remarkable -- almost 
> eight years without even a minor revision, and no major revision in ten 
> years. (Compare that to the arms race that is JDBC.)
> 
> Dave
> 
>> I would want to thrash the others more first.  Kilim does compile-time 
>> weaving which I find to be a pain from a tooling point of view, 
>> regardless of whether it works.  I'm not sure whether any of the Java 
>> frameworks have been tested much if at all on big multi-core 
>> machines.  I'm hoping to grab a few cycles to try them at work if we 
>> have a machine free.  From the small benchmarking I've done in the 
>> past and that I've read from others, the basics like message send are 
>> very fast, in the same general order of magnitude with Erlang.  It's 
>> really hard to tell how good the scheduling and other critical parts 
>> are though without really building an app-level benchmark.
>>
>>
>>
>>
>> ----- Original Message ----
>> From: Raoul Duke <raould at gmail.com>
>> To: Alex Miller <alexdmiller at yahoo.com>
>> Cc: concurrency-interest at cs.oswego.edu
>> Sent: Wednesday, March 4, 2009 1:10:18 PM
>> Subject: Re: [concurrency-interest] actor frameworks
>>
>>> Lots of options these days.
>>
>> yeah, but the question is, which ones are actually robust? :-)
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> End of Concurrency-interest Digest, Vol 50, Issue 5
>> ***************************************************
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


From tgautier at terracottatech.com  Sat Mar  7 12:55:00 2009
From: tgautier at terracottatech.com (Taylor Gautier)
Date: Sat, 7 Mar 2009 09:55:00 -0800 (PST)
Subject: [concurrency-interest] thoughts on ordered, concurrent locking
In-Reply-To: <6596583.889411236448497079.JavaMail.root@mail01.terracottatech.com>
Message-ID: <10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>


Suppose I have a Person object, which has a list of friends, like so: 


Person: 
String name; 
List<Person> friends = new ArrayList<Person>(); 


My question is, let's assume that a business rule requires that relationships are commutative, i.e if Bob is friend of Alice, then Alice is also a friend of Bob. 


This means that if we want to establish that relationship, we need to update both records atomically. So let's try that (naively): 


public static void makeFriends(Person p1, person p2) 
{ 
synchronized (p1) { 
p1.friends.add(p2); 
} 

synchronized (p2) { 
p2.friends.add(p1); 
} 
} 


Uh oh. This looks like a disaster waiting to happen - the operation is not atomic. Let's fix that: 



public static void makeFriends(Person p1, person p2) 
{ 
synchronized (p1) { 
synchronized (p2) { 
p1.friends.add(p2); 
p2.friends.add(p1); 

} 
} 
} 


Ok better, but there is still a possibility of deadlocking this, consider two threads: 


Thread 1: makeFriends(bob, alice); 
Thread 2: makeFriends(alice, bob); 


We have two choices now, 


1) We can find a higher order lock 
2) Order the locks 


Approach #1 - Find a higher order lock 


If we try to do 1, then later, we cannot do fine-grained locking on Person to read what friends they have without acquiring the higher order lock. We also start getting into trouble, what if we decide we want to update the person's name, now what lock do we use, and so on. While it seems like a good goal -- in practice it may not be achievable given the application. 


Approach #2 - Order the locks 


I like this approach better. It lets me do whatever other fine-grained locking on the Person object I would like to do, so it is compatible with a fine-grained approach. But now we get to the crux of the problem - how do we order the locks? 


I am imagining a helper class here: 



public static void makeFriends(final Person p1, final Person p2) 
{ 
orderedSynchronizeOn(new Runnable() { 
public void run() { 
p1.friends.add(p2); 
p2.friends.add(p1); 

} 
}, p1, p2); 
} 


Does anyone know of an implementation of orderedSynchronizeOn? I can imagine writing something (pseudo-code) like: 


public void orderedSynchronizeOn(Runnable cmd, Object... objects) 
{ 
List sortedList = sort objects; 
for (Object o: sortedList) { 
lock (o); 
} 
cmd.run(); 
for (Object o: sortedList) { 
unlock (o); 
} 
} 


Of course my pseudo-code is insufficient and has several problems that will arise which are: 


1) how to sort the objects. Presumably hashcode would be good - but could be unpredictable if the hashcode is not stable 
2) I cannot think of any way to programmatically acquire the monitor for an object that corresponds to synchronized (o); 
3) Of course exceptions have to be handled, and the proper unlocks have to be executed in a finally block, which is rather tricky in the generic case 


So, I can't see how to solve 2 and 3 using programmatic constructs (iterative approach to locking all passed in objects). I can see how to implement say: 


orderedSynchronizeOn1, 
orderedSynchronizeOn2, 
orderedSynchronizeOn3, 
orderedSynchronizeOn4, 
orderedSynchronizeOn5, 


and so on by unrolling the loop and writing the appropriate try/finally with synchronized. 


And then implementing: 



public void orderedSynchronizeOn(Runnable cmd, Object... objects) 
{ 
switch (objects.length) { 
case 1: orderedSynchronized1(cmd, objects[0]); break; 

case 2: orderedSynchronized1(cmd, objects[0], objects 1); break; 
... 
} 
} 

That seems pretty ugly, but solves the problem assuming we can presume stable hash codes. 


Any other thoughts? 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090307/c6191219/attachment.html>

From takeshi10 at gmail.com  Sat Mar  7 13:23:32 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Sat, 7 Mar 2009 15:23:32 -0300
Subject: [concurrency-interest] thoughts on ordered, concurrent locking
In-Reply-To: <10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
References: <6596583.889411236448497079.JavaMail.root@mail01.terracottatech.com>
	<10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
Message-ID: <7288749d0903071023u5f6fa6cbn7c24afe8d0200256@mail.gmail.com>

hi,
lemme try to help you
comments inlined

On Sat, Mar 7, 2009 at 2:55 PM, Taylor Gautier
<tgautier at terracottatech.com> wrote:
> Suppose I have a Person object, which has a list of friends, like so:
> Person:
> ??String name;
> ??List<Person> friends = new ArrayList<Person>();
> My question is, let's assume that a business rule requires that
> relationships are commutative, i.e if Bob is friend of Alice, then Alice is
> also a friend of Bob.
> This means that if we want to establish that relationship, we need to update
> both records atomically. ? So let's try that (naively):
> public static void makeFriends(Person p1, person p2)
> {
> ?? ?synchronized (p1) {
> ?? ? ? ?p1.friends.add(p2);
> ?? ?}
> ?? ?synchronized (p2) {
> ?? ? ? ?p2.friends.add(p1);
> ?? ?}
> }
> Uh oh. ?This looks like a disaster waiting to happen - the operation is not
> atomic. ?Let's fix that:
> public static void makeFriends(Person p1, person p2)
> {
> ?? ?synchronized (p1) {
> ?? ? ? ?synchronized (p2) {
> ?? ? ? ? ? ?p1.friends.add(p2);
> ?? ? ? ? ? ?p2.friends.add(p1);
> ?? ? ? ?}
> ?? ?}
> }
> Ok better, but there is still a possibility of deadlocking this, consider
> two threads:
> Thread 1: makeFriends(bob, alice);
> Thread 2: makeFriends(alice, bob);
> We have two choices now,
> 1) We can find a higher order lock
> 2) Order the locks
> Approach #1 - Find a higher order lock
> If we try to do 1, then later, we cannot do fine-grained locking on Person
> to read what friends they have without acquiring the higher order lock. ?We
> also start getting into trouble, what if we decide we want to update the
> person's name, now what lock do we use, and so on. ?While it seems like a
> good goal -- in practice it may not be achievable given the application.
> Approach #2 - Order the locks
> I like this approach better. ?It lets me do whatever other fine-grained
> locking on the Person object I would like to do, so it is compatible with a
> fine-grained approach. ?But now we get to the crux of the problem - how do
> we order the locks?
> I am imagining a helper class here:
> public static void makeFriends(final Person p1, final Person p2)
> {
> ?? ?orderedSynchronizeOn(new Runnable() {
> ?? ? ? ?public void run() {
> ?? ? ? ? ? ?p1.friends.add(p2);
> ?? ? ? ? ? ?p2.friends.add(p1);
> ?? ? ? ?}
> ?? ?}, p1, p2);
> }
> Does anyone know of an implementation of orderedSynchronizeOn? ?I can
> imagine writing something (pseudo-code) like:
> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
> {
> ?? ?List sortedList = sort objects;
> ?? ?for (Object o: sortedList) {
> ?? ? ? ?lock (o);
> ?? ?}
> ?? ?cmd.run();
> ?? ?for (Object o: sortedList) {
> ?? ? ? ?unlock (o);
> ?? ?}
> }

you probably want to use a recursive function to synchronize on all
objects if you can / want to use simple synchronized blocks, which
might look something like this (assuming objects are already sorted)

private void runLocked(Runnable run, int index, Object[] locks) {
  if(index == locks.length) { run.run(); }
  else {
    synchronized(locks[index]) {
      runLocked(run, index+1, locks);
    }
  }
}

its kind of like what ConcurrentHashMap does (take a look at the
source code for that and more)

> Of course my pseudo-code is insufficient and has several problems that will
> arise which are:
> 1) how to sort the objects. ?Presumably hashcode would be good - but could
> be unpredictable if the hashcode is not stable

you might consider using System.identityHashcode( object ) for sorting
maybe breaking ties with the class hashcode, but im not sure how safe
is that (and most likely not 100% safe)

> 2) I cannot think of any way to programmatically acquire the monitor for an
> object that corresponds to synchronized (o);

like i said before, try a recursive version of the method

> 3) Of course exceptions have to be handled, and the proper unlocks have to
> be executed in a finally block, which is rather tricky in the generic case

if you use plain synchronized blocks, exception are taken care of automatically

i hope that helps

> So, I can't see how to solve 2 and 3 using programmatic constructs
> (iterative approach to locking all passed in objects). ?I can see how to
> implement say:
> orderedSynchronizeOn1,
> orderedSynchronizeOn2,
> orderedSynchronizeOn3,
> orderedSynchronizeOn4,
> orderedSynchronizeOn5,
> and so on by unrolling the loop and writing the appropriate try/finally with
> synchronized.
> And then implementing:
> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
> {
> ?? switch (objects.length) {
> ?? ? ? ?case 1: ?orderedSynchronized1(cmd, objects[0]); break;
> ?? ? ? ?case 2: ?orderedSynchronized1(cmd, objects[0], objects 1); break;
> ?? ? ? ?...
> ??}
> }
>
> ?That seems pretty ugly, but solves the problem assuming we can presume
> stable hash codes.
> Any other thoughts?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>



-- 
[]'s
Marcelo Takeshi Fukushima


From joe.bowbeer at gmail.com  Sat Mar  7 13:31:20 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 7 Mar 2009 10:31:20 -0800
Subject: [concurrency-interest] thoughts on ordered, concurrent locking
In-Reply-To: <10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
References: <6596583.889411236448497079.JavaMail.root@mail01.terracottatech.com>
	<10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
Message-ID: <31f2a7bd0903071031n38c3640ak1d00609f272e0832@mail.gmail.com>

See Chapter 10 "Avoiding Liveness Hazards" in JCiP.

Listing 10.3 uses System.identityHashCode for ordering:

  http://jcip.net/listings/InduceLockOrder.java

Some options not mentioned are: single-threaded-subsystem and
message-passing/queueing.

Joe

On Sat, Mar 7, 2009 at 9:55 AM, Taylor Gautier wrote:

> Suppose I have a Person object, which has a list of friends, like so:
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090307/77b51528/attachment-0001.html>

From tgautier at terracottatech.com  Sat Mar  7 14:35:20 2009
From: tgautier at terracottatech.com (Taylor Gautier)
Date: Sat, 7 Mar 2009 11:35:20 -0800
Subject: [concurrency-interest] thoughts on ordered, concurrent locking
In-Reply-To: <7288749d0903071023u5f6fa6cbn7c24afe8d0200256@mail.gmail.com>
References: <6596583.889411236448497079.JavaMail.root@mail01.terracottatech.com>
	<10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
	<7288749d0903071023u5f6fa6cbn7c24afe8d0200256@mail.gmail.com>
Message-ID: <C473FAE6-14B8-4020-A105-765EC2429111@terracottatech.com>

Thanks that should do!  I guess my aversion to recursion blinded me  
here ;)



On Mar 7, 2009, at 10:23 AM, Marcelo Fukushima <takeshi10 at gmail.com>  
wrote:

> hi,
> lemme try to help you
> comments inlined
>
> On Sat, Mar 7, 2009 at 2:55 PM, Taylor Gautier
> <tgautier at terracottatech.com> wrote:
>> Suppose I have a Person object, which has a list of friends, like so:
>> Person:
>>   String name;
>>   List<Person> friends = new ArrayList<Person>();
>> My question is, let's assume that a business rule requires that
>> relationships are commutative, i.e if Bob is friend of Alice, then  
>> Alice is
>> also a friend of Bob.
>> This means that if we want to establish that relationship, we need  
>> to update
>> both records atomically.   So let's try that (naively):
>> public static void makeFriends(Person p1, person p2)
>> {
>>     synchronized (p1) {
>>         p1.friends.add(p2);
>>     }
>>     synchronized (p2) {
>>         p2.friends.add(p1);
>>     }
>> }
>> Uh oh.  This looks like a disaster waiting to happen - the  
>> operation is not
>> atomic.  Let's fix that:
>> public static void makeFriends(Person p1, person p2)
>> {
>>     synchronized (p1) {
>>         synchronized (p2) {
>>             p1.friends.add(p2);
>>             p2.friends.add(p1);
>>         }
>>     }
>> }
>> Ok better, but there is still a possibility of deadlocking this,  
>> consider
>> two threads:
>> Thread 1: makeFriends(bob, alice);
>> Thread 2: makeFriends(alice, bob);
>> We have two choices now,
>> 1) We can find a higher order lock
>> 2) Order the locks
>> Approach #1 - Find a higher order lock
>> If we try to do 1, then later, we cannot do fine-grained locking on  
>> Person
>> to read what friends they have without acquiring the higher order  
>> lock.  We
>> also start getting into trouble, what if we decide we want to  
>> update the
>> person's name, now what lock do we use, and so on.  While it seems  
>> like a
>> good goal -- in practice it may not be achievable given the  
>> application.
>> Approach #2 - Order the locks
>> I like this approach better.  It lets me do whatever other fine- 
>> grained
>> locking on the Person object I would like to do, so it is  
>> compatible with a
>> fine-grained approach.  But now we get to the crux of the problem -  
>> how do
>> we order the locks?
>> I am imagining a helper class here:
>> public static void makeFriends(final Person p1, final Person p2)
>> {
>>     orderedSynchronizeOn(new Runnable() {
>>         public void run() {
>>             p1.friends.add(p2);
>>             p2.friends.add(p1);
>>         }
>>     }, p1, p2);
>> }
>> Does anyone know of an implementation of orderedSynchronizeOn?  I can
>> imagine writing something (pseudo-code) like:
>> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
>> {
>>     List sortedList = sort objects;
>>     for (Object o: sortedList) {
>>         lock (o);
>>     }
>>     cmd.run();
>>     for (Object o: sortedList) {
>>         unlock (o);
>>     }
>> }
>
> you probably want to use a recursive function to synchronize on all
> objects if you can / want to use simple synchronized blocks, which
> might look something like this (assuming objects are already sorted)
>
> private void runLocked(Runnable run, int index, Object[] locks) {
>  if(index == locks.length) { run.run(); }
>  else {
>    synchronized(locks[index]) {
>      runLocked(run, index+1, locks);
>    }
>  }
> }
>
> its kind of like what ConcurrentHashMap does (take a look at the
> source code for that and more)
>
>> Of course my pseudo-code is insufficient and has several problems  
>> that will
>> arise which are:
>> 1) how to sort the objects.  Presumably hashcode would be good -  
>> but could
>> be unpredictable if the hashcode is not stable
>
> you might consider using System.identityHashcode( object ) for sorting
> maybe breaking ties with the class hashcode, but im not sure how safe
> is that (and most likely not 100% safe)
>
>> 2) I cannot think of any way to programmatically acquire the  
>> monitor for an
>> object that corresponds to synchronized (o);
>
> like i said before, try a recursive version of the method
>
>> 3) Of course exceptions have to be handled, and the proper unlocks  
>> have to
>> be executed in a finally block, which is rather tricky in the  
>> generic case
>
> if you use plain synchronized blocks, exception are taken care of  
> automatically
>
> i hope that helps
>
>> So, I can't see how to solve 2 and 3 using programmatic constructs
>> (iterative approach to locking all passed in objects).  I can see  
>> how to
>> implement say:
>> orderedSynchronizeOn1,
>> orderedSynchronizeOn2,
>> orderedSynchronizeOn3,
>> orderedSynchronizeOn4,
>> orderedSynchronizeOn5,
>> and so on by unrolling the loop and writing the appropriate try/ 
>> finally with
>> synchronized.
>> And then implementing:
>> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
>> {
>>    switch (objects.length) {
>>         case 1:  orderedSynchronized1(cmd, objects[0]); break;
>>         case 2:  orderedSynchronized1(cmd, objects[0], objects 1);  
>> break;
>>         ...
>>   }
>> }
>>
>>  That seems pretty ugly, but solves the problem assuming we can  
>> presume
>> stable hash codes.
>> Any other thoughts?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> -- 
> []'s
> Marcelo Takeshi Fukushima

From alarmnummer at gmail.com  Sun Mar  8 17:18:24 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Sun, 8 Mar 2009 22:18:24 +0100
Subject: [concurrency-interest] thoughts on ordered, concurrent locking
In-Reply-To: <C473FAE6-14B8-4020-A105-765EC2429111@terracottatech.com>
References: <6596583.889411236448497079.JavaMail.root@mail01.terracottatech.com>
	<10752309.889431236448500359.JavaMail.root@mail01.terracottatech.com>
	<7288749d0903071023u5f6fa6cbn7c24afe8d0200256@mail.gmail.com>
	<C473FAE6-14B8-4020-A105-765EC2429111@terracottatech.com>
Message-ID: <1466c1d60903081418q12a31f5ex332608ff3a15129f@mail.gmail.com>

Hi Taylor,

Although it not an answer to your question, this issue could be solved
with software transactional memory: it makes composing atomic
operations a lot easier.

I'm currently working on an implementation and it is nice to see how
some problems are so much easier to solve. I use multiversion
concurrency control with automatic transaction level read consistency
(the oracle version of serialised isolation level) and violations of
isolation are not allowed (although the oracle serialised isolation
level can result in different results than allowed by serialised
execution of transactions).

This is one of the tests. There is a lot of clutter that can be solved
with instrumentation and annotations, but that is besides the point.
Below this test there is another one with waiting on multiple queues
(also a hard problem with classic concurrency control).

/**
 * This test makes sure that all transaction execute isolated from
other transactions
 * <p/>
 * The Test: a shared integer value that is increased by a
modification thread. When the transaction begins,
 * it is increased (so the value can't be divided by 2) there will be
a delay, another increase (so that
 * the value can be divided by 2) and the transaction commits. Another
observing thread that looks at this
 * value should never see a value that can't be divided by 2.
 *
 * @author Peter Veentjer.
 */
public class IsolatedBehaviorTest {

    private MultiversionedStm stm;
    private DefaultMultiversionedHeap heap;
    private long handle;
    private int modifyCount = 300;

    private AtomicInteger modifyCountDown = new AtomicInteger();

    @Before
    public void setUp() {
        heap = new DefaultMultiversionedHeap();
        stm = new MultiversionedStm(heap);
        handle = TestUtils.commit(stm, new IntegerValue());
    }

    @After
    public void tearDown() {
        System.out.println(stm.getStatistics());
        System.out.println(heap.getStatistics());
    }

    @Test
    public void test() {
        modifyCountDown.set(modifyCount);

        ModifyThread modifyThread = new ModifyThread(1);
        ObserveThread observeThread = new ObserveThread(1);

        startAll(modifyThread, observeThread);
        joinAll(modifyThread, observeThread);
    }

    class ModifyThread extends TestThread {
        public ModifyThread(int threadId) {
            super("ModifyThread-" + threadId);
        }

        @Override
        public void run() {
            while (modifyCountDown.decrementAndGet() > 0) {
                new TransactionTemplate(stm) {
                    @Override
                    protected Object execute(Transaction t) throws Exception {
                        IntegerValue value = (IntegerValue) t.read(handle);
                        value.inc();

                        sleepRandomMs(50);

                        value.inc();
                        return null;
                    }
                }.execute();

                sleepRandomMs(1);
            }
        }
    }

    class ObserveThread extends TestThread {
        public ObserveThread(int threadId) {
            super("ObserveThread-" + threadId);
        }

        @Override
        public void run() {
            while (modifyCountDown.get() > 0) {
                new TransactionTemplate(stm) {
                    @Override
                    protected Object execute(Transaction t) throws Exception {
                        IntegerValue value = (IntegerValue) t.read(handle);
                        if (value.get() % 2 != 0)
                            fail();

                        return null;
                    }
                }.execute();

                sleepRandomMs(1);
            }
        }
    }
}

Other problems like listening to multiple queues for example also is very easy:

/**
 * The test checks if a wait can be done on multiple condition
variables. Normally with a BlockingQueue you can only
 * block on 1 queue, if you have multiple queues, waiting on an update
on one of them is not possible, because each
 * queue has his own waitset.
 * <p/>
 * With STM's this limitation doesn't exist. This tests checks if that
works. It does that be creating a
 * bunch of queues and a producer threads random places items in of
the queues, and a consumer thread that
 * waits on the availability of an item on all queues.
 *
 * @author Peter Veentjer.
 */
public class WaitOnMultiConditionVariableTest {

    private MultiversionedStm stm;
    private long[] queues;
    private DefaultMultiversionedHeap heap;

    private int queueCount = 10;
    private int produceCount = 2000;
    private int delayMs = 5;

    @Before
    public void setUp() {
        heap = new DefaultMultiversionedHeap();
        stm = new MultiversionedStm(heap);
    }

    @After
    public void teatDown() {
        System.out.println(stm.getStatistics());
        System.out.println(heap.getStatistics());
    }

    @Test
    public void test() throws InterruptedException {
        queues = createQueues(queueCount);

        ProducerThread producerThread = new ProducerThread();
        producerThread.start();

        ConsumerThread consumerThread = new ConsumerThread();
        consumerThread.start();

        joinAll(producerThread, consumerThread);

        assertQueuesAreEmpty();
        assertEquals(new HashSet(producerThread.producedList), new
HashSet(consumerThread.consumedList));
    }

    public void assertQueuesAreEmpty() {
        Transaction t = stm.startTransaction();
        for (long handle : queues) {
            Queue queue = (Queue) t.read(handle);
            if (!queue.isEmpty())
                fail();
        }

        t.commit();
    }

    private long[] createQueues(int queueCount) {
        Transaction t = stm.startTransaction();
        long[] handles = new long[queueCount];
        for (int k = 0; k < queueCount; k++)
            handles[k] = t.attachAsRoot(new Queue());
        t.commit();
        return handles;
    }

    private class ProducerThread extends TestThread {
        private final List<Integer> producedList = new
ArrayList<Integer>(produceCount);

        public ProducerThread() {
            setName("ProducerThread");
        }

        public void produceOneItem(final int item) {
            new TransactionTemplate(stm) {
                @Override
                protected Object execute(Transaction t) throws Exception {
                    long queueHandle = queues[item % queues.length];
                    Queue<Integer> queue = (Queue<Integer>) t.read(queueHandle);
                    queue.push(item);
                    return null;
                }
            }.execute();

            producedList.add(item);
        }

        public void run() {
            for (int k = 1; k <= produceCount; k++) {
                produceOneItem(k);
                sleepRandomMs(delayMs);
            }
        }
    }

    private class ConsumerThread extends TestThread {
        private final List consumedList = new LinkedList();

        public ConsumerThread() {
            setName("ConsumerThread");
        }

        public int consumeOneItem() {

            return new TransactionTemplate<Integer>(stm) {
                @Override
                protected Integer execute(Transaction t) throws Exception {
                    for (int k = 0; k < queues.length; k++) {
                        Queue<Integer> queue = (Queue) t.read(queues[k]);
                        Integer item = queue.peek();
                        if (item != null)
                            return item;
                    }

                    retry();
                    return null;
                }
            }.execute();
        }

        public void run() {
            for (int k = 0; k < produceCount; k++) {
                int item = consumeOneItem();
                sleepRandomMs(delayMs);
                consumedList.add(item);
            }
        }
    }
}

Stm's could be a nice tool in the toolbox.. But it introduces its own
problems like performance or leaky abstractions from the concurrency
implementation. Certainly very interesting though :)

On Sat, Mar 7, 2009 at 8:35 PM, Taylor Gautier
<tgautier at terracottatech.com> wrote:
> Thanks that should do! ?I guess my aversion to recursion blinded me here ;)
>
>
>
> On Mar 7, 2009, at 10:23 AM, Marcelo Fukushima <takeshi10 at gmail.com> wrote:
>
>> hi,
>> lemme try to help you
>> comments inlined
>>
>> On Sat, Mar 7, 2009 at 2:55 PM, Taylor Gautier
>> <tgautier at terracottatech.com> wrote:
>>>
>>> Suppose I have a Person object, which has a list of friends, like so:
>>> Person:
>>> ?String name;
>>> ?List<Person> friends = new ArrayList<Person>();
>>> My question is, let's assume that a business rule requires that
>>> relationships are commutative, i.e if Bob is friend of Alice, then Alice
>>> is
>>> also a friend of Bob.
>>> This means that if we want to establish that relationship, we need to
>>> update
>>> both records atomically. ? So let's try that (naively):
>>> public static void makeFriends(Person p1, person p2)
>>> {
>>> ? ?synchronized (p1) {
>>> ? ? ? ?p1.friends.add(p2);
>>> ? ?}
>>> ? ?synchronized (p2) {
>>> ? ? ? ?p2.friends.add(p1);
>>> ? ?}
>>> }
>>> Uh oh. ?This looks like a disaster waiting to happen - the operation is
>>> not
>>> atomic. ?Let's fix that:
>>> public static void makeFriends(Person p1, person p2)
>>> {
>>> ? ?synchronized (p1) {
>>> ? ? ? ?synchronized (p2) {
>>> ? ? ? ? ? ?p1.friends.add(p2);
>>> ? ? ? ? ? ?p2.friends.add(p1);
>>> ? ? ? ?}
>>> ? ?}
>>> }
>>> Ok better, but there is still a possibility of deadlocking this, consider
>>> two threads:
>>> Thread 1: makeFriends(bob, alice);
>>> Thread 2: makeFriends(alice, bob);
>>> We have two choices now,
>>> 1) We can find a higher order lock
>>> 2) Order the locks
>>> Approach #1 - Find a higher order lock
>>> If we try to do 1, then later, we cannot do fine-grained locking on
>>> Person
>>> to read what friends they have without acquiring the higher order lock.
>>> ?We
>>> also start getting into trouble, what if we decide we want to update the
>>> person's name, now what lock do we use, and so on. ?While it seems like a
>>> good goal -- in practice it may not be achievable given the application.
>>> Approach #2 - Order the locks
>>> I like this approach better. ?It lets me do whatever other fine-grained
>>> locking on the Person object I would like to do, so it is compatible with
>>> a
>>> fine-grained approach. ?But now we get to the crux of the problem - how
>>> do
>>> we order the locks?
>>> I am imagining a helper class here:
>>> public static void makeFriends(final Person p1, final Person p2)
>>> {
>>> ? ?orderedSynchronizeOn(new Runnable() {
>>> ? ? ? ?public void run() {
>>> ? ? ? ? ? ?p1.friends.add(p2);
>>> ? ? ? ? ? ?p2.friends.add(p1);
>>> ? ? ? ?}
>>> ? ?}, p1, p2);
>>> }
>>> Does anyone know of an implementation of orderedSynchronizeOn? ?I can
>>> imagine writing something (pseudo-code) like:
>>> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
>>> {
>>> ? ?List sortedList = sort objects;
>>> ? ?for (Object o: sortedList) {
>>> ? ? ? ?lock (o);
>>> ? ?}
>>> ? ?cmd.run();
>>> ? ?for (Object o: sortedList) {
>>> ? ? ? ?unlock (o);
>>> ? ?}
>>> }
>>
>> you probably want to use a recursive function to synchronize on all
>> objects if you can / want to use simple synchronized blocks, which
>> might look something like this (assuming objects are already sorted)
>>
>> private void runLocked(Runnable run, int index, Object[] locks) {
>> ?if(index == locks.length) { run.run(); }
>> ?else {
>> ? synchronized(locks[index]) {
>> ? ? runLocked(run, index+1, locks);
>> ? }
>> ?}
>> }
>>
>> its kind of like what ConcurrentHashMap does (take a look at the
>> source code for that and more)
>>
>>> Of course my pseudo-code is insufficient and has several problems that
>>> will
>>> arise which are:
>>> 1) how to sort the objects. ?Presumably hashcode would be good - but
>>> could
>>> be unpredictable if the hashcode is not stable
>>
>> you might consider using System.identityHashcode( object ) for sorting
>> maybe breaking ties with the class hashcode, but im not sure how safe
>> is that (and most likely not 100% safe)
>>
>>> 2) I cannot think of any way to programmatically acquire the monitor for
>>> an
>>> object that corresponds to synchronized (o);
>>
>> like i said before, try a recursive version of the method
>>
>>> 3) Of course exceptions have to be handled, and the proper unlocks have
>>> to
>>> be executed in a finally block, which is rather tricky in the generic
>>> case
>>
>> if you use plain synchronized blocks, exception are taken care of
>> automatically
>>
>> i hope that helps
>>
>>> So, I can't see how to solve 2 and 3 using programmatic constructs
>>> (iterative approach to locking all passed in objects). ?I can see how to
>>> implement say:
>>> orderedSynchronizeOn1,
>>> orderedSynchronizeOn2,
>>> orderedSynchronizeOn3,
>>> orderedSynchronizeOn4,
>>> orderedSynchronizeOn5,
>>> and so on by unrolling the loop and writing the appropriate try/finally
>>> with
>>> synchronized.
>>> And then implementing:
>>> public void orderedSynchronizeOn(Runnable cmd, Object... objects)
>>> {
>>> ? switch (objects.length) {
>>> ? ? ? ?case 1: ?orderedSynchronized1(cmd, objects[0]); break;
>>> ? ? ? ?case 2: ?orderedSynchronized1(cmd, objects[0], objects 1); break;
>>> ? ? ? ?...
>>> ?}
>>> }
>>>
>>> ?That seems pretty ugly, but solves the problem assuming we can presume
>>> stable hash codes.
>>> Any other thoughts?
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>>
>> --
>> []'s
>> Marcelo Takeshi Fukushima
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From alarmnummer at gmail.com  Tue Mar 10 19:07:46 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 11 Mar 2009 00:07:46 +0100
Subject: [concurrency-interest] updating a pure functional tree and CAS
	problems
Message-ID: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>

Hi Guys,

I foresee a scalability/performance problem in a CAS-loop in a
Software Transaction Memory implementation I'm working on, and I'm
looking for some ideas.

The situation:

I use multiversioning as concurrency mechanism, so when changes are
committed to the heap, a new heapsnapshot is created and within a cas
loop it replaces the current one:

so something like this:

boolean success;
do{
     Snapshot beforeCommitSnapshot = snapshotRef.get();
     Snapshot aferCommitSnapshot = beforeCommitSnapshot.update(stuffToCommit);
     success = snapshotRef.compareAndSwap(beforeCommitSnapshot,
afterCommitSnapshot);
}while(!success)

The problem is that this solution suffers from lifelocking if there is
contention. The problems worsens if the number of things that need to
be committed increase because it takes more time to build the new
snapshot. It could even mean that long running transaction never can
commit because some shorter running transaction take less time and let
the long transaction try forever.

I already have done a lot of optimizations in building the heap: the
heapsnapshot is just a balanced tree. The tree is completely
immutable, so an update creates a new tree based on the old one + the
changes (the same way a tree is build in a pure functional programming
language).

My question is:
this cas loop is just an optimistic version of the classic lock and
something different than a wait free version. Does anyone have some
pointers to literature for creating wait-free versions of pure
functional trees?

Other idea's are very much appreciated.

From ben_manes at yahoo.com  Tue Mar 10 19:58:59 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 10 Mar 2009 16:58:59 -0700 (PDT)
Subject: [concurrency-interest] updating a pure functional tree and CAS
	problems
In-Reply-To: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
References: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
Message-ID: <60755.91106.qm@web38805.mail.mud.yahoo.com>

You may wish to read "Transactional Memory" by Larus and Rajwar.  They discuss a number of different implementations and found that lock-free implementations tended to perform worse than lock-based versions.  You could adopt an exponential back-off policy if the optimistic approach fails past a threshold.




________________________________
From: Peter Veentjer <alarmnummer at gmail.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tuesday, March 10, 2009 4:07:46 PM
Subject: [concurrency-interest] updating a pure functional tree and CAS problems

Hi Guys,

I foresee a scalability/performance problem in a CAS-loop in a
Software Transaction Memory implementation I'm working on, and I'm
looking for some ideas.

The situation:

I use multiversioning as concurrency mechanism, so when changes are
committed to the heap, a new heapsnapshot is created and within a cas
loop it replaces the current one:

so something like this:

boolean success;
do{
     Snapshot beforeCommitSnapshot = snapshotRef.get();
     Snapshot aferCommitSnapshot = beforeCommitSnapshot.update(stuffToCommit);
     success = snapshotRef.compareAndSwap(beforeCommitSnapshot,
afterCommitSnapshot);
}while(!success)

The problem is that this solution suffers from lifelocking if there is
contention. The problems worsens if the number of things that need to
be committed increase because it takes more time to build the new
snapshot. It could even mean that long running transaction never can
commit because some shorter running transaction take less time and let
the long transaction try forever.

I already have done a lot of optimizations in building the heap: the
heapsnapshot is just a balanced tree. The tree is completely
immutable, so an update creates a new tree based on the old one + the
changes (the same way a tree is build in a pure functional programming
language).

My question is:
this cas loop is just an optimistic version of the classic lock and
something different than a wait free version. Does anyone have some
pointers to literature for creating wait-free versions of pure
functional trees?

Other idea's are very much appreciated.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090310/198f275f/attachment.html>

From gregg at cytetech.com  Wed Mar 11 09:39:57 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 11 Mar 2009 08:39:57 -0500
Subject: [concurrency-interest] updating a pure functional tree and CAS
 problems
In-Reply-To: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
References: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
Message-ID: <49B7BF2D.2020204@cytetech.com>

Peter can you make each contending add result in a single rebuild with "all the 
stuff"?  I'm thinking that this loop should actually be in a monitor which gets 
a queue of things to rebuild with, always emptying the queue for all items with 
a drainTo() or something similar.

Gregg Wonderly

Peter Veentjer wrote:
> Hi Guys,
> 
> I foresee a scalability/performance problem in a CAS-loop in a
> Software Transaction Memory implementation I'm working on, and I'm
> looking for some ideas.
> 
> The situation:
> 
> I use multiversioning as concurrency mechanism, so when changes are
> committed to the heap, a new heapsnapshot is created and within a cas
> loop it replaces the current one:
> 
> so something like this:
> 
> boolean success;
> do{
>      Snapshot beforeCommitSnapshot = snapshotRef.get();
>      Snapshot aferCommitSnapshot = beforeCommitSnapshot.update(stuffToCommit);
>      success = snapshotRef.compareAndSwap(beforeCommitSnapshot,
> afterCommitSnapshot);
> }while(!success)
> 
> The problem is that this solution suffers from lifelocking if there is
> contention. The problems worsens if the number of things that need to
> be committed increase because it takes more time to build the new
> snapshot. It could even mean that long running transaction never can
> commit because some shorter running transaction take less time and let
> the long transaction try forever.
> 
> I already have done a lot of optimizations in building the heap: the
> heapsnapshot is just a balanced tree. The tree is completely
> immutable, so an update creates a new tree based on the old one + the
> changes (the same way a tree is build in a pure functional programming
> language).
> 
> My question is:
> this cas loop is just an optimistic version of the classic lock and
> something different than a wait free version. Does anyone have some
> pointers to literature for creating wait-free versions of pure
> functional trees?
> 
> Other idea's are very much appreciated.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


From alarmnummer at gmail.com  Wed Mar 11 10:15:23 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 11 Mar 2009 15:15:23 +0100
Subject: [concurrency-interest] updating a pure functional tree and CAS
	problems
In-Reply-To: <49B7BF2D.2020204@cytetech.com>
References: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
	<49B7BF2D.2020204@cytetech.com>
Message-ID: <1466c1d60903110715x48fd7402y522bd81e12fed9d2@mail.gmail.com>

Hi Gregg,

Something I forget to mention: some commits need to fail because a
write conflict has occurred. At the moment I use a very optimistic
approach in my stm,  so a write conflict is quite common. I'm working
on pessimistic locking but that isn't completed yet... and pessimistic
locking if going worsen the cas problem because every pessimistic lock
leads to a new snapshot (a snapshot containing the previous data + the
lock) that will interfere with the cas of longer running transactions.

Check out the stack example on this page:

http://code.google.com/p/multiverse/

Concurrent pushes and pops have a write conflict on the head of the stack.

If I have 2 threads that communicate through a stack in the stm, I
have 35% write conflicts on my dual core machine. So this means that
roughly 1 out of 4 transactions started with the commit, but could not
create a new snapshot to replace the older one and need to retry.

So queuing could be more complicated because one of the items that is
drained from the queue, could ruin it for the others.. but maybe you
are right and this is the way to go. Just letting each transaction do
its thing and let cas worry about the rest is not the silver bullet to
scalability.

On Wed, Mar 11, 2009 at 2:39 PM, Gregg Wonderly <gregg at cytetech.com> wrote:
> Peter can you make each contending add result in a single rebuild with "all
> the stuff"? ?I'm thinking that this loop should actually be in a monitor
> which gets a queue of things to rebuild with, always emptying the queue for
> all items with a drainTo() or something similar.
>
> Gregg Wonderly
>
> Peter Veentjer wrote:
>>
>> Hi Guys,
>>
>> I foresee a scalability/performance problem in a CAS-loop in a
>> Software Transaction Memory implementation I'm working on, and I'm
>> looking for some ideas.
>>
>> The situation:
>>
>> I use multiversioning as concurrency mechanism, so when changes are
>> committed to the heap, a new heapsnapshot is created and within a cas
>> loop it replaces the current one:
>>
>> so something like this:
>>
>> boolean success;
>> do{
>> ? ? Snapshot beforeCommitSnapshot = snapshotRef.get();
>> ? ? Snapshot aferCommitSnapshot =
>> beforeCommitSnapshot.update(stuffToCommit);
>> ? ? success = snapshotRef.compareAndSwap(beforeCommitSnapshot,
>> afterCommitSnapshot);
>> }while(!success)
>>
>> The problem is that this solution suffers from lifelocking if there is
>> contention. The problems worsens if the number of things that need to
>> be committed increase because it takes more time to build the new
>> snapshot. It could even mean that long running transaction never can
>> commit because some shorter running transaction take less time and let
>> the long transaction try forever.
>>
>> I already have done a lot of optimizations in building the heap: the
>> heapsnapshot is just a balanced tree. The tree is completely
>> immutable, so an update creates a new tree based on the old one + the
>> changes (the same way a tree is build in a pure functional programming
>> language).
>>
>> My question is:
>> this cas loop is just an optimistic version of the classic lock and
>> something different than a wait free version. Does anyone have some
>> pointers to literature for creating wait-free versions of pure
>> functional trees?
>>
>> Other idea's are very much appreciated.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>


From alarmnummer at gmail.com  Wed Mar 11 10:18:32 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 11 Mar 2009 15:18:32 +0100
Subject: [concurrency-interest] updating a pure functional tree and CAS
	problems
In-Reply-To: <60755.91106.qm@web38805.mail.mud.yahoo.com>
References: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
	<60755.91106.qm@web38805.mail.mud.yahoo.com>
Message-ID: <1466c1d60903110718t377392f2y721c242bbc621c9f@mail.gmail.com>

The book is under my pillow since it is one of the few resources about
Transactional Memory :) Although I take a completely different
approach, the book is full of useful information.

I'll reread the stuff about lock-free vs lock-based stuff..

Thanks for pointing it out.

On Wed, Mar 11, 2009 at 12:58 AM, Ben Manes <ben_manes at yahoo.com> wrote:
> You may wish to read "Transactional Memory" by Larus and Rajwar.? They
> discuss a number of different implementations and found that lock-free
> implementations tended to perform worse than lock-based versions.? You could
> adopt an exponential back-off policy if the optimistic approach fails past a
> threshold.
>
> ________________________________
> From: Peter Veentjer <alarmnummer at gmail.com>
> To: concurrency-interest at cs.oswego.edu
> Sent: Tuesday, March 10, 2009 4:07:46 PM
> Subject: [concurrency-interest] updating a pure functional tree and CAS
> problems
>
> Hi Guys,
>
> I foresee a scalability/performance problem in a CAS-loop in a
> Software Transaction Memory implementation I'm working on, and I'm
> looking for some ideas.
>
> The situation:
>
> I use multiversioning as concurrency mechanism, so when changes are
> committed to the heap, a new heapsnapshot is created and within a cas
> loop it replaces the current one:
>
> so something like this:
>
> boolean success;
> do{
> ? ? Snapshot beforeCommitSnapshot = snapshotRef.get();
> ? ? Snapshot aferCommitSnapshot =
> beforeCommitSnapshot.update(stuffToCommit);
> ? ? success = snapshotRef.compareAndSwap(beforeCommitSnapshot,
> afterCommitSnapshot);
> }while(!success)
>
> The problem is that this solution suffers from lifelocking if there is
> contention. The problems worsens if the number of things that need to
> be committed increase because it takes more time to build the new
> snapshot. It could even mean that long running transaction never can
> commit because some shorter running transaction take less time and let
> the long transaction try forever.
>
> I already have done a lot of optimizations in building the heap: the
> heapsnapshot is just a balanced tree. The tree is completely
> immutable, so an update creates a new tree based on the old one + the
> changes (the same way a tree is build in a pure functional programming
> language).
>
> My question is:
> this cas loop is just an optimistic version of the classic lock and
> something different than a wait free version. Does anyone have some
> pointers to literature for creating wait-free versions of pure
> functional trees?
>
> Other idea's are very much appreciated.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From jdmarshall at gmail.com  Wed Mar 11 19:44:46 2009
From: jdmarshall at gmail.com (jason marshall)
Date: Wed, 11 Mar 2009 16:44:46 -0700
Subject: [concurrency-interest] updating a pure functional tree and CAS
	problems
In-Reply-To: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
References: <1466c1d60903101607w8cd3be1m4470637a60608ff2@mail.gmail.com>
Message-ID: <3cf41bb90903111644v75aac169re6af4f15ffbfae2b@mail.gmail.com>

On Tue, Mar 10, 2009 at 4:07 PM, Peter Veentjer <alarmnummer at gmail.com>wrote:

> Hi Guys,
>
>   The problems worsens if the number of things that need to
> be committed increase because it takes more time to build the new
> snapshot. It could even mean that long running transaction never can
> commit because some shorter running transaction take less time and let
> the long transaction try forever.
>

You say that like it's a bad thing.  Isn't that the essential complexity of
updating shared state?  The more state you touch, the harder it is for
anybody else to make progress.

In the database world, as you approach the cliff-face you start throwing
things overboard.  Either you rearrange your code so that the duration of
the change is shorter, or you find a way to split your update into two
partial updates, and then you deal with the intermediate state in the rest
of your data model.

I have always just accepted that this situation would happen in an STM
environment as well.  Maybe I'm giving up too quickly, but I don't see any
way around the problem.


-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090311/46eafbae/attachment.html>

From dcholmes at optusnet.com.au  Wed Mar 11 19:59:17 2009
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 12 Mar 2009 09:59:17 +1000
Subject: [concurrency-interest] updating a pure functional tree and
	CASproblems
In-Reply-To: <3cf41bb90903111644v75aac169re6af4f15ffbfae2b@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPPHPAA.dcholmes@optusnet.com.au>

Optimistic concurrency control, whether in databases, STMs or algorithmics
is premised on the assumption that conflict is rare and easily recovered
from. If the assumptions no longer hold ... things don't work so well.

As other more prominent concurrency affecionados have said the real goal is
not to provide mechanisms that handle contention well, but to remove
contention in the first place.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of jason
marshall
  Sent: Thursday, 12 March 2009 9:45 AM
  To: Peter Veentjer
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] updating a pure functional tree and
CASproblems





  On Tue, Mar 10, 2009 at 4:07 PM, Peter Veentjer <alarmnummer at gmail.com>
wrote:

    Hi Guys,

      The problems worsens if the number of things that need to
    be committed increase because it takes more time to build the new
    snapshot. It could even mean that long running transaction never can
    commit because some shorter running transaction take less time and let
    the long transaction try forever.


  You say that like it's a bad thing.  Isn't that the essential complexity
of updating shared state?  The more state you touch, the harder it is for
anybody else to make progress.

  In the database world, as you approach the cliff-face you start throwing
things overboard.  Either you rearrange your code so that the duration of
the change is shorter, or you find a way to split your update into two
partial updates, and then you deal with the intermediate state in the rest
of your data model.

  I have always just accepted that this situation would happen in an STM
environment as well.  Maybe I'm giving up too quickly, but I don't see any
way around the problem.



  --
  - Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090312/3e322739/attachment.html>

From jdmarshall at gmail.com  Thu Mar 12 15:17:43 2009
From: jdmarshall at gmail.com (jason marshall)
Date: Thu, 12 Mar 2009 12:17:43 -0700
Subject: [concurrency-interest] Making ExecutorService return on first
	failure?
Message-ID: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>

I'm trying to use ExecutorService to set up initial conditions for a cluster
of work.

if (Parallel setup)
  Sequential tasks
finally
  Parallel teardown


What I'm seeing is fairly degenerate behavior in a couple of cases that I'd
like to avoid, but I haven't thought of a way to do it within the current
bounds of the j.u.c framework.

The most apparent issue I have is that there is no early abort mechanism.
You can either poll all queued tasks manually, or you can wait for all to
succeed or fail.

If I have 3 worker threads (empirically this completes the fastest on our
4-processor box), and task #2 errors out, it does me no good to dequeue task
#5 and start working on it; the entire exercise is a bust anyway.  What I
want to do is clean up and declare failure ASAP.


Short of going to a fully poll-based arrangement, I don't see a way to get
this behavior.  Well, okay, I see one way to do it, and that's to have the
failing Callable suicide (terminate the Executor).  But I'm not sure that
ExecutorService supports mutual recursion with its own tasks.  In fact now
that I think about it, I would be quite surprised if they do.

Anyone have any ideas or experience to share?

Thanks,
Jason






-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090312/5e00a9dd/attachment.html>

From kpauls at acm.org  Thu Mar 12 16:02:53 2009
From: kpauls at acm.org (Outside - Karl's ACM)
Date: Thu, 12 Mar 2009 13:02:53 -0700
Subject: [concurrency-interest] Making ExecutorService return on
	first	failure?
In-Reply-To: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>
References: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>
Message-ID: <A7CC499CF05307438D4B8EC3A159FA0C01DC46E39B@postoffice.corp.trigeo.com>

ExecutorService can be scheduled or canceled from any thread, but that means wrapping all of your callables in wrappers tooled with the abort code.
 
Is CompletionService suitable for your needs? It too wraps all callables you submit to it inside some task management code so you won't have to.
 
// -- begin
ExecutorService exec = Executors.newFixedThreadPool(3);
ExecutorCompletionService<?> completion = new ExecutorCompletionService<?>(exec);
// submit 2 ok quick running tasks, 1 quick excepting task
// submit 1 LONG running task
 
while(false == exec.isShutdown()) {
    try {
        Future<?> f = completion.take();
    } catch (Exception e) {
        exec.shutdownNow();
    }
}
// -- end
 
That will do what you want in a procedural manner... except that it shuts down all tasks as soon as you hit an exception. So you will need to define a new executor for each batch of dependent tasks. It looks like that is acceptible.

I've started to have some doubt of the universal utility of CompletionService - feeling that it may be better in most cases to go down to implementing with blocking queues themselves instead of composing nested or inter-dependent tasks inside of the CompletionService (there's a blog post brewing in this after I explore the topic).
 
-karl


From jdmarshall at gmail.com  Fri Mar 13 17:06:46 2009
From: jdmarshall at gmail.com (jason marshall)
Date: Fri, 13 Mar 2009 14:06:46 -0700
Subject: [concurrency-interest] Making ExecutorService return on first
	failure?
In-Reply-To: <A7CC499CF05307438D4B8EC3A159FA0C01DC46E39B@postoffice.corp.trigeo.com>
References: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>
	<A7CC499CF05307438D4B8EC3A159FA0C01DC46E39B@postoffice.corp.trigeo.com>
Message-ID: <3cf41bb90903131406h708fcffar8b48ad0120f4de71@mail.gmail.com>

I tried this out.  Catch block in the Callable, pass the Executor in as an
argument, call shutdownNow() in the catch block. Catch block fires, this
much I can see in the logs.  What I can also see in the thread dump is that
invokeAll() is still waiting for a ship that will never come.

Looks like I'll have to be looking at CompletionService, although it looks a
bit messier.  I'll have to manage the timeout values myself, for one.



On Thu, Mar 12, 2009 at 1:02 PM, Outside - Karl's ACM <kpauls at acm.org>wrote:

> ExecutorService can be scheduled or canceled from any thread, but that
> means wrapping all of your callables in wrappers tooled with the abort code.
>
> Is CompletionService suitable for your needs? It too wraps all callables
> you submit to it inside some task management code so you won't have to.
>
> // -- begin
> ExecutorService exec = Executors.newFixedThreadPool(3);
> ExecutorCompletionService<?> completion = new
> ExecutorCompletionService<?>(exec);
> // submit 2 ok quick running tasks, 1 quick excepting task
> // submit 1 LONG running task
>
> while(false == exec.isShutdown()) {
>    try {
>        Future<?> f = completion.take();
>    } catch (Exception e) {
>        exec.shutdownNow();
>    }
> }
> // -- end
>
> That will do what you want in a procedural manner... except that it shuts
> down all tasks as soon as you hit an exception. So you will need to define a
> new executor for each batch of dependent tasks. It looks like that is
> acceptible.
>
> I've started to have some doubt of the universal utility of
> CompletionService - feeling that it may be better in most cases to go down
> to implementing with blocking queues themselves instead of composing nested
> or inter-dependent tasks inside of the CompletionService (there's a blog
> post brewing in this after I explore the topic).
>
> -karl
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090313/80010bfc/attachment.html>

From joe.bowbeer at gmail.com  Fri Mar 13 17:49:59 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 13 Mar 2009 14:49:59 -0700
Subject: [concurrency-interest] Making ExecutorService return on first
	failure?
In-Reply-To: <3cf41bb90903131406h708fcffar8b48ad0120f4de71@mail.gmail.com>
References: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>
	<A7CC499CF05307438D4B8EC3A159FA0C01DC46E39B@postoffice.corp.trigeo.com>
	<3cf41bb90903131406h708fcffar8b48ad0120f4de71@mail.gmail.com>
Message-ID: <31f2a7bd0903131449s4887c903vffd493cd3cc5573e@mail.gmail.com>

shutdownNow will interrupt actively executing tasks, and return a list of
pending (queued) tasks.

If I follow you scenario, the caller of shutdownNow should also cancel()
each of the returned tasks.

Your tasks should also be responsive to interrupt, but they will be canceled
nonetheless, which should satisfy invokeAll.  invokeAll will not wait on
canceled tasks.

Joe

On Fri, Mar 13, 2009 at 2:06 PM, jason marshall wrote:

> I tried this out.  Catch block in the Callable, pass the Executor in as an
> argument, call shutdownNow() in the catch block. Catch block fires, this
> much I can see in the logs.  What I can also see in the thread dump is that
> invokeAll() is still waiting for a ship that will never come.
>
> Looks like I'll have to be looking at CompletionService, although it looks
> a bit messier.  I'll have to manage the timeout values myself, for one.
>
>
>
>
> On Thu, Mar 12, 2009 at 1:02 PM, Outside - Karl's ACM wrote:
>
>> ExecutorService can be scheduled or canceled from any thread, but that
>> means wrapping all of your callables in wrappers tooled with the abort code.
>>
>> Is CompletionService suitable for your needs? It too wraps all callables
>> you submit to it inside some task management code so you won't have to.
>>
>> // -- begin
>> ExecutorService exec = Executors.newFixedThreadPool(3);
>> ExecutorCompletionService<?> completion = new
>> ExecutorCompletionService<?>(exec);
>> // submit 2 ok quick running tasks, 1 quick excepting task
>> // submit 1 LONG running task
>>
>> while(false == exec.isShutdown()) {
>>    try {
>>        Future<?> f = completion.take();
>>    } catch (Exception e) {
>>        exec.shutdownNow();
>>    }
>> }
>> // -- end
>>
>> That will do what you want in a procedural manner... except that it shuts
>> down all tasks as soon as you hit an exception. So you will need to define a
>> new executor for each batch of dependent tasks. It looks like that is
>> acceptible.
>>
>> I've started to have some doubt of the universal utility of
>> CompletionService - feeling that it may be better in most cases to go down
>> to implementing with blocking queues themselves instead of composing nested
>> or inter-dependent tasks inside of the CompletionService (there's a blog
>> post brewing in this after I explore the topic).
>>
>> -karl
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090313/d8b87b8c/attachment.html>

From jdmarshall at gmail.com  Sat Mar 14 17:42:49 2009
From: jdmarshall at gmail.com (jason marshall)
Date: Sat, 14 Mar 2009 14:42:49 -0700
Subject: [concurrency-interest] Making ExecutorService return on first
	failure?
In-Reply-To: <31f2a7bd0903131449s4887c903vffd493cd3cc5573e@mail.gmail.com>
References: <3cf41bb90903121217h27a630b4v3daa9042f47d7f37@mail.gmail.com>
	<A7CC499CF05307438D4B8EC3A159FA0C01DC46E39B@postoffice.corp.trigeo.com>
	<3cf41bb90903131406h708fcffar8b48ad0120f4de71@mail.gmail.com>
	<31f2a7bd0903131449s4887c903vffd493cd3cc5573e@mail.gmail.com>
Message-ID: <3cf41bb90903141442r1fe46058v4e2f32865c60403e@mail.gmail.com>

Okay.  That means I'm doing what shutdownNow would normally do, in order to
keep from getting deadlock.

I ended up going with Karl's suggestion.  It's not as unreadable as I
feared.  In fact it reads better than the other two solutions (all of the
executor lifecycle management is in the same method).

Thanks!
Jason

On Fri, Mar 13, 2009 at 2:49 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> shutdownNow will interrupt actively executing tasks, and return a list of
> pending (queued) tasks.
>
> If I follow you scenario, the caller of shutdownNow should also cancel()
> each of the returned tasks.
>
> Your tasks should also be responsive to interrupt, but they will be
> canceled nonetheless, which should satisfy invokeAll.  invokeAll will not
> wait on canceled tasks.
>
> Joe
>
> On Fri, Mar 13, 2009 at 2:06 PM, jason marshall wrote:
>
>> I tried this out.  Catch block in the Callable, pass the Executor in as an
>> argument, call shutdownNow() in the catch block. Catch block fires, this
>> much I can see in the logs.  What I can also see in the thread dump is that
>> invokeAll() is still waiting for a ship that will never come.
>>
>> Looks like I'll have to be looking at CompletionService, although it looks
>> a bit messier.  I'll have to manage the timeout values myself, for one.
>>
>>
>>
>>
>> On Thu, Mar 12, 2009 at 1:02 PM, Outside - Karl's ACM wrote:
>>
>>> ExecutorService can be scheduled or canceled from any thread, but that
>>> means wrapping all of your callables in wrappers tooled with the abort code.
>>>
>>> Is CompletionService suitable for your needs? It too wraps all callables
>>> you submit to it inside some task management code so you won't have to.
>>>
>>> // -- begin
>>> ExecutorService exec = Executors.newFixedThreadPool(3);
>>> ExecutorCompletionService<?> completion = new
>>> ExecutorCompletionService<?>(exec);
>>> // submit 2 ok quick running tasks, 1 quick excepting task
>>> // submit 1 LONG running task
>>>
>>> while(false == exec.isShutdown()) {
>>>    try {
>>>        Future<?> f = completion.take();
>>>    } catch (Exception e) {
>>>        exec.shutdownNow();
>>>    }
>>> }
>>> // -- end
>>>
>>> That will do what you want in a procedural manner... except that it shuts
>>> down all tasks as soon as you hit an exception. So you will need to define a
>>> new executor for each batch of dependent tasks. It looks like that is
>>> acceptible.
>>>
>>> I've started to have some doubt of the universal utility of
>>> CompletionService - feeling that it may be better in most cases to go down
>>> to implementing with blocking queues themselves instead of composing nested
>>> or inter-dependent tasks inside of the CompletionService (there's a blog
>>> post brewing in this after I explore the topic).
>>>
>>> -karl
>>>
>>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090314/b32e990b/attachment.html>

From gregg at cytetech.com  Tue Mar 24 10:52:00 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 24 Mar 2009 09:52:00 -0500
Subject: [concurrency-interest] Revisit of the early GC issue that Hans
	brought up
Message-ID: <49C8F390.8050901@cytetech.com>

I have a JDBC factory/connection caching class which I've used for more than a 
decade.  Its basic usage is something like

DatabaseManager mgr = SQLFactory.getConnection( url, driver, user, passwd );
try {
	ResultSet rs = mgr.executeQuery(...);
	while( rs.next() ) {
	}
	rs = mgr.executeQuery( ... );
	if( rs.next() == false ) {
		mgr.executeUpdate(...);
	}
} finally {
	// close Statement, ResultSet etc., but cache the Connection.
	mgr.release();
}

It tracks all ResultSet and Statement usage internally and closes things before 
creating new ones to eliminate all the try{} finally{ closeSomething() } nesting
that is typically necessary.

Recently, while using this in another project, a new developer on my team had 
some complex code where a long lived bug was causing some stale Connection 
objects to not be closed correctly.  I decided to introduce the use of my 
ReferenceTracker class to manage the closing of those "lost" Connection instances.

What I found, was that this mostly worked, except that the behavior which Hans 
detailed about premature GC became visible, and connections where getting 
"freed" before the mgr.release() call had been made, and the GC path into the 
release of those objects was causing Connections to be aborted/closed before the 
mgr.release() call occured.

So, I had to take that back out, and I'm trying to decide if there is a way to 
still make this work without massive changes in code already using this class to 
add synchronized( mgr ){} everywhere.

Gregg Wonderly

From gregg at cytetech.com  Wed Mar 25 12:19:27 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 25 Mar 2009 11:19:27 -0500
Subject: [concurrency-interest] Garbage First vs a counting collector
Message-ID: <49CA598F.7070003@cytetech.com>

One of the things about concurrent programming that bothers me the most is 
latency control.  GC activity can often introduce unwanted latency by causing 
arbitrary contention for resources that a thread may not be able to recognize as 
contentious.  A long time ago, I created a language with a counting collector 
which I found to be very easy to do on a uniprocessor environment.  With the 
advent of CAS, it seems at casual grant pretty straight forward to do a counting 
collector on a multi-processor machine.

The upcomming introduction of the garbage first collector intrigues me from the 
perspective that there is a "ton" of managed resources that it uses to make 
itself smart enough to try and accurately estimate and manage the cost of GC 
activity.  There is use of CAS, plus space and time based isolation schemes to 
try and reduce latency that is introduced into the application.

However, it seems to me that there is going to be a new cost introduced into 
every assignment for mutator tracking that might just be as expensive as a 
counting collector is.

I am not really familiar with the real costs of much of the concurrency 
management instructions, can anyone on the list give me some pointers to more 
information or some insight into whether the amount of "tracking" that the 
garbage first collector will use, is still cheaper than a CAS on every reference 
change to a global object?

Gregg Wonderly

From david.lloyd at redhat.com  Wed Mar 25 13:10:56 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Wed, 25 Mar 2009 12:10:56 -0500
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
Message-ID: <49CA65A0.1080201@redhat.com>

I've run into a minor issue with CopyOnWriteArrayList and have come up with 
a simple solution for it.  The issue is that you want to perform more than 
one operation on the list (for instance, a size() followed by a get() with 
index, which is otherwise not terribly useful on this class), and you need 
the operations to be consistent with one another.  Using an iterator does 
provide some ability to do this kind of thing, since it works on an 
immutable snapshot of the array, but of course you are then limited to the 
basic iterator operations, which do not include random access.  You can get 
a copy of a snapshot using toArray(), but I thought it would be handy to 
have a more generalized snapshot() method which doesn't do a copy of all 
the list data.

Here's a simple five-minute patch which adds a snapshot() method, which 
returns an immutable List based on the array as it was.  Thoughts?

diff -r dde3fe2e8164 
src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
--- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java	Wed 
Feb 25 14:32:01 2009 +0000
+++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java	Wed 
Mar 25 11:11:19 2009 -0500
@@ -988,6 +988,44 @@
          return new COWIterator<E>(elements, index);
      }

+    /**
+     * Returns a snapshot view of this list.  The returned list provides
+     * a snapshot of the state of the list when the method was called.  No
+     * synchronization is needed while calling the list methods.  The list
+     * is read-only; any methods which modify the state of the list will
+     * throw <tt>UnsupportedOperationException</tt>.
+     *
+     * @return a snapshot of this list
+     */
+    public List<E> snapshot() {
+        final Object[] snapshot = getArray();
+        return new AbstractList<E>() {
+            public E get(final int index) {
+                return CopyOnWriteArrayList.this.get(snapshot, index);
+            }
+
+            public int size() {
+                return snapshot.length;
+            }
+
+            public Iterator<E> iterator() {
+                return new COWIterator<E>(snapshot, 0);
+            }
+
+            public ListIterator<E> listIterator() {
+                return new COWIterator<E>(snapshot, 0);
+            }
+
+            public ListIterator<E> listIterator(final int index) {
+                Object[] elements = snapshot;
+                int len = elements.length;
+                if (index<0 || index>len)
+                    throw new IndexOutOfBoundsException("Index: "+index);
+                return new COWIterator<E>(elements, index);
+            }
+        };
+    }
+
      private static class COWIterator<E> implements ListIterator<E> {
          /** Snapshot of the array **/
          private final Object[] snapshot;

From sberlin at gmail.com  Wed Mar 25 13:40:38 2009
From: sberlin at gmail.com (Sam Berlin)
Date: Wed, 25 Mar 2009 13:40:38 -0400
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <49CA65A0.1080201@redhat.com>
References: <49CA65A0.1080201@redhat.com>
Message-ID: <19196d860903251040u4a4cad9tc036adc759258c63@mail.gmail.com>

Would it be possible to achieve much the same thing by calling code doing:

 List snapshot = Arrays.unmodifiableList(Arrays.asList(cowList.toArray()));

Sam

On Wed, Mar 25, 2009 at 1:10 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
> I've run into a minor issue with CopyOnWriteArrayList and have come up with
> a simple solution for it. ?The issue is that you want to perform more than
> one operation on the list (for instance, a size() followed by a get() with
> index, which is otherwise not terribly useful on this class), and you need
> the operations to be consistent with one another. ?Using an iterator does
> provide some ability to do this kind of thing, since it works on an
> immutable snapshot of the array, but of course you are then limited to the
> basic iterator operations, which do not include random access. ?You can get
> a copy of a snapshot using toArray(), but I thought it would be handy to
> have a more generalized snapshot() method which doesn't do a copy of all the
> list data.
>
> Here's a simple five-minute patch which adds a snapshot() method, which
> returns an immutable List based on the array as it was. ?Thoughts?
>
> diff -r dde3fe2e8164
> src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
> --- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Feb 25 14:32:01 2009 +0000
> +++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Mar 25 11:11:19 2009 -0500
> @@ -988,6 +988,44 @@
> ? ? ? ? return new COWIterator<E>(elements, index);
> ? ? }
>
> + ? ?/**
> + ? ? * Returns a snapshot view of this list. ?The returned list provides
> + ? ? * a snapshot of the state of the list when the method was called. ?No
> + ? ? * synchronization is needed while calling the list methods. ?The list
> + ? ? * is read-only; any methods which modify the state of the list will
> + ? ? * throw <tt>UnsupportedOperationException</tt>.
> + ? ? *
> + ? ? * @return a snapshot of this list
> + ? ? */
> + ? ?public List<E> snapshot() {
> + ? ? ? ?final Object[] snapshot = getArray();
> + ? ? ? ?return new AbstractList<E>() {
> + ? ? ? ? ? ?public E get(final int index) {
> + ? ? ? ? ? ? ? ?return CopyOnWriteArrayList.this.get(snapshot, index);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public int size() {
> + ? ? ? ? ? ? ? ?return snapshot.length;
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public Iterator<E> iterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator(final int index) {
> + ? ? ? ? ? ? ? ?Object[] elements = snapshot;
> + ? ? ? ? ? ? ? ?int len = elements.length;
> + ? ? ? ? ? ? ? ?if (index<0 || index>len)
> + ? ? ? ? ? ? ? ? ? ?throw new IndexOutOfBoundsException("Index: "+index);
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(elements, index);
> + ? ? ? ? ? ?}
> + ? ? ? ?};
> + ? ?}
> +
> ? ? private static class COWIterator<E> implements ListIterator<E> {
> ? ? ? ? /** Snapshot of the array **/
> ? ? ? ? private final Object[] snapshot;
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From david.lloyd at redhat.com  Wed Mar 25 13:53:30 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Wed, 25 Mar 2009 12:53:30 -0500
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <19196d860903251040u4a4cad9tc036adc759258c63@mail.gmail.com>
References: <49CA65A0.1080201@redhat.com>
	<19196d860903251040u4a4cad9tc036adc759258c63@mail.gmail.com>
Message-ID: <49CA6F9A.9010409@redhat.com>

Yeah, semantically, but toArray() makes a copy of the list data (not just 
the array ref) and then you've got a couple more layers of indirection as 
well.  I'm not sure what the absolute performance effect would be, but 
surely not copying should be better than copying in any case.

- DML

On 03/25/2009 12:40 PM, Sam Berlin wrote:
> Would it be possible to achieve much the same thing by calling code doing:
> 
>  List snapshot = Arrays.unmodifiableList(Arrays.asList(cowList.toArray()));
> 
> Sam
> 
> On Wed, Mar 25, 2009 at 1:10 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
>> I've run into a minor issue with CopyOnWriteArrayList and have come up with
>> a simple solution for it.  The issue is that you want to perform more than
>> one operation on the list (for instance, a size() followed by a get() with
>> index, which is otherwise not terribly useful on this class), and you need
>> the operations to be consistent with one another.  Using an iterator does
>> provide some ability to do this kind of thing, since it works on an
>> immutable snapshot of the array, but of course you are then limited to the
>> basic iterator operations, which do not include random access.  You can get
>> a copy of a snapshot using toArray(), but I thought it would be handy to
>> have a more generalized snapshot() method which doesn't do a copy of all the
>> list data.
>>
>> Here's a simple five-minute patch which adds a snapshot() method, which
>> returns an immutable List based on the array as it was.  Thoughts?
>>
>> diff -r dde3fe2e8164
>> src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
>> --- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java  Wed
>> Feb 25 14:32:01 2009 +0000
>> +++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java  Wed
>> Mar 25 11:11:19 2009 -0500
>> @@ -988,6 +988,44 @@
>>         return new COWIterator<E>(elements, index);
>>     }
>>
>> +    /**
>> +     * Returns a snapshot view of this list.  The returned list provides
>> +     * a snapshot of the state of the list when the method was called.  No
>> +     * synchronization is needed while calling the list methods.  The list
>> +     * is read-only; any methods which modify the state of the list will
>> +     * throw <tt>UnsupportedOperationException</tt>.
>> +     *
>> +     * @return a snapshot of this list
>> +     */
>> +    public List<E> snapshot() {
>> +        final Object[] snapshot = getArray();
>> +        return new AbstractList<E>() {
>> +            public E get(final int index) {
>> +                return CopyOnWriteArrayList.this.get(snapshot, index);
>> +            }
>> +
>> +            public int size() {
>> +                return snapshot.length;
>> +            }
>> +
>> +            public Iterator<E> iterator() {
>> +                return new COWIterator<E>(snapshot, 0);
>> +            }
>> +
>> +            public ListIterator<E> listIterator() {
>> +                return new COWIterator<E>(snapshot, 0);
>> +            }
>> +
>> +            public ListIterator<E> listIterator(final int index) {
>> +                Object[] elements = snapshot;
>> +                int len = elements.length;
>> +                if (index<0 || index>len)
>> +                    throw new IndexOutOfBoundsException("Index: "+index);
>> +                return new COWIterator<E>(elements, index);
>> +            }
>> +        };
>> +    }
>> +
>>     private static class COWIterator<E> implements ListIterator<E> {
>>         /** Snapshot of the array **/
>>         private final Object[] snapshot;
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

From Darron_Shaffer at stercomm.com  Wed Mar 25 14:16:05 2009
From: Darron_Shaffer at stercomm.com (Shaffer, Darron)
Date: Wed, 25 Mar 2009 14:16:05 -0400
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <19196d860903251040u4a4cad9tc036adc759258c63@mail.gmail.com>
Message-ID: <FC30D8A2D3DEE64D93E8DA54A1DB349A067A1657@IWDUBCORMSG007.sci.local>

Or even:

  List snapshot = Collections.unmodifiableList(cowList);

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Sam Berlin
Sent: Wednesday, March 25, 2009 12:41 PM
To: David M. Lloyd
Cc: concurrency-interest
Subject: Re: [concurrency-interest] CopyOnWriteArrayList and snapshots

Would it be possible to achieve much the same thing by calling code doing:

 List snapshot = Arrays.unmodifiableList(Arrays.asList(cowList.toArray()));

Sam

On Wed, Mar 25, 2009 at 1:10 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
> I've run into a minor issue with CopyOnWriteArrayList and have come up with
> a simple solution for it. ?The issue is that you want to perform more than
> one operation on the list (for instance, a size() followed by a get() with
> index, which is otherwise not terribly useful on this class), and you need
> the operations to be consistent with one another. ?Using an iterator does
> provide some ability to do this kind of thing, since it works on an
> immutable snapshot of the array, but of course you are then limited to the
> basic iterator operations, which do not include random access. ?You can get
> a copy of a snapshot using toArray(), but I thought it would be handy to
> have a more generalized snapshot() method which doesn't do a copy of all the
> list data.
>
> Here's a simple five-minute patch which adds a snapshot() method, which
> returns an immutable List based on the array as it was. ?Thoughts?
>
> diff -r dde3fe2e8164
> src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
> --- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Feb 25 14:32:01 2009 +0000
> +++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Mar 25 11:11:19 2009 -0500
> @@ -988,6 +988,44 @@
> ? ? ? ? return new COWIterator<E>(elements, index);
> ? ? }
>
> + ? ?/**
> + ? ? * Returns a snapshot view of this list. ?The returned list provides
> + ? ? * a snapshot of the state of the list when the method was called. ?No
> + ? ? * synchronization is needed while calling the list methods. ?The list
> + ? ? * is read-only; any methods which modify the state of the list will
> + ? ? * throw <tt>UnsupportedOperationException</tt>.
> + ? ? *
> + ? ? * @return a snapshot of this list
> + ? ? */
> + ? ?public List<E> snapshot() {
> + ? ? ? ?final Object[] snapshot = getArray();
> + ? ? ? ?return new AbstractList<E>() {
> + ? ? ? ? ? ?public E get(final int index) {
> + ? ? ? ? ? ? ? ?return CopyOnWriteArrayList.this.get(snapshot, index);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public int size() {
> + ? ? ? ? ? ? ? ?return snapshot.length;
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public Iterator<E> iterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator(final int index) {
> + ? ? ? ? ? ? ? ?Object[] elements = snapshot;
> + ? ? ? ? ? ? ? ?int len = elements.length;
> + ? ? ? ? ? ? ? ?if (index<0 || index>len)
> + ? ? ? ? ? ? ? ? ? ?throw new IndexOutOfBoundsException("Index: "+index);
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(elements, index);
> + ? ? ? ? ? ?}
> + ? ? ? ?};
> + ? ?}
> +
> ? ? private static class COWIterator<E> implements ListIterator<E> {
> ? ? ? ? /** Snapshot of the array **/
> ? ? ? ? private final Object[] snapshot;
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From Darron_Shaffer at stercomm.com  Wed Mar 25 14:16:54 2009
From: Darron_Shaffer at stercomm.com (Shaffer, Darron)
Date: Wed, 25 Mar 2009 14:16:54 -0400
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
Message-ID: <FC30D8A2D3DEE64D93E8DA54A1DB349A067A1659@IWDUBCORMSG007.sci.local>

Sorry, I realized as soon as I sent this that it doesn't have the correct semantics.

-----Original Message-----
From: Shaffer, Darron 
Sent: Wednesday, March 25, 2009 1:16 PM
To: 'Sam Berlin'; David M. Lloyd
Cc: concurrency-interest
Subject: RE: [concurrency-interest] CopyOnWriteArrayList and snapshots

Or even:

  List snapshot = Collections.unmodifiableList(cowList);

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Sam Berlin
Sent: Wednesday, March 25, 2009 12:41 PM
To: David M. Lloyd
Cc: concurrency-interest
Subject: Re: [concurrency-interest] CopyOnWriteArrayList and snapshots

Would it be possible to achieve much the same thing by calling code doing:

 List snapshot = Arrays.unmodifiableList(Arrays.asList(cowList.toArray()));

Sam

On Wed, Mar 25, 2009 at 1:10 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
> I've run into a minor issue with CopyOnWriteArrayList and have come up with
> a simple solution for it. ?The issue is that you want to perform more than
> one operation on the list (for instance, a size() followed by a get() with
> index, which is otherwise not terribly useful on this class), and you need
> the operations to be consistent with one another. ?Using an iterator does
> provide some ability to do this kind of thing, since it works on an
> immutable snapshot of the array, but of course you are then limited to the
> basic iterator operations, which do not include random access. ?You can get
> a copy of a snapshot using toArray(), but I thought it would be handy to
> have a more generalized snapshot() method which doesn't do a copy of all the
> list data.
>
> Here's a simple five-minute patch which adds a snapshot() method, which
> returns an immutable List based on the array as it was. ?Thoughts?
>
> diff -r dde3fe2e8164
> src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
> --- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Feb 25 14:32:01 2009 +0000
> +++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java ?Wed
> Mar 25 11:11:19 2009 -0500
> @@ -988,6 +988,44 @@
> ? ? ? ? return new COWIterator<E>(elements, index);
> ? ? }
>
> + ? ?/**
> + ? ? * Returns a snapshot view of this list. ?The returned list provides
> + ? ? * a snapshot of the state of the list when the method was called. ?No
> + ? ? * synchronization is needed while calling the list methods. ?The list
> + ? ? * is read-only; any methods which modify the state of the list will
> + ? ? * throw <tt>UnsupportedOperationException</tt>.
> + ? ? *
> + ? ? * @return a snapshot of this list
> + ? ? */
> + ? ?public List<E> snapshot() {
> + ? ? ? ?final Object[] snapshot = getArray();
> + ? ? ? ?return new AbstractList<E>() {
> + ? ? ? ? ? ?public E get(final int index) {
> + ? ? ? ? ? ? ? ?return CopyOnWriteArrayList.this.get(snapshot, index);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public int size() {
> + ? ? ? ? ? ? ? ?return snapshot.length;
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public Iterator<E> iterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator() {
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(snapshot, 0);
> + ? ? ? ? ? ?}
> +
> + ? ? ? ? ? ?public ListIterator<E> listIterator(final int index) {
> + ? ? ? ? ? ? ? ?Object[] elements = snapshot;
> + ? ? ? ? ? ? ? ?int len = elements.length;
> + ? ? ? ? ? ? ? ?if (index<0 || index>len)
> + ? ? ? ? ? ? ? ? ? ?throw new IndexOutOfBoundsException("Index: "+index);
> + ? ? ? ? ? ? ? ?return new COWIterator<E>(elements, index);
> + ? ? ? ? ? ?}
> + ? ? ? ?};
> + ? ?}
> +
> ? ? private static class COWIterator<E> implements ListIterator<E> {
> ? ? ? ? /** Snapshot of the array **/
> ? ? ? ? private final Object[] snapshot;
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jeremy.manson at gmail.com  Wed Mar 25 14:17:52 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Wed, 25 Mar 2009 11:17:52 -0700
Subject: [concurrency-interest] Revisit of the early GC issue that Hans
	brought up
In-Reply-To: <49C8F390.8050901@cytetech.com>
References: <49C8F390.8050901@cytetech.com>
Message-ID: <1631da7d0903251117q74726208o91844aff03107c4a@mail.gmail.com>

My recollection is that the easiest way to prohibit this behavior is
by placing a reference to mgr somewhere in the heap, where it can be
accessed by following a chain of references from a static field.

However, it seems to me that you would want to use synchronization to
make sure that you were done with the connection before it could be
finalized.  I, personally, would go with the synchronization solution.

Jeremy

On Tue, Mar 24, 2009 at 7:52 AM, Gregg Wonderly <gregg at cytetech.com> wrote:
> I have a JDBC factory/connection caching class which I've used for more than
> a decade. ?Its basic usage is something like
>
> DatabaseManager mgr = SQLFactory.getConnection( url, driver, user, passwd );
> try {
> ? ? ? ?ResultSet rs = mgr.executeQuery(...);
> ? ? ? ?while( rs.next() ) {
> ? ? ? ?}
> ? ? ? ?rs = mgr.executeQuery( ... );
> ? ? ? ?if( rs.next() == false ) {
> ? ? ? ? ? ? ? ?mgr.executeUpdate(...);
> ? ? ? ?}
> } finally {
> ? ? ? ?// close Statement, ResultSet etc., but cache the Connection.
> ? ? ? ?mgr.release();
> }
>
> It tracks all ResultSet and Statement usage internally and closes things
> before creating new ones to eliminate all the try{} finally{
> closeSomething() } nesting
> that is typically necessary.
>
> Recently, while using this in another project, a new developer on my team
> had some complex code where a long lived bug was causing some stale
> Connection objects to not be closed correctly. ?I decided to introduce the
> use of my ReferenceTracker class to manage the closing of those "lost"
> Connection instances.
>
> What I found, was that this mostly worked, except that the behavior which
> Hans detailed about premature GC became visible, and connections where
> getting "freed" before the mgr.release() call had been made, and the GC path
> into the release of those objects was causing Connections to be
> aborted/closed before the mgr.release() call occured.
>
> So, I had to take that back out, and I'm trying to decide if there is a way
> to still make this work without massive changes in code already using this
> class to add synchronized( mgr ){} everywhere.
>
> Gregg Wonderly
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From jim.andreou at gmail.com  Wed Mar 25 14:25:52 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Wed, 25 Mar 2009 20:25:52 +0200
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <FC30D8A2D3DEE64D93E8DA54A1DB349A067A1657@IWDUBCORMSG007.sci.local>
References: <19196d860903251040u4a4cad9tc036adc759258c63@mail.gmail.com>
	<FC30D8A2D3DEE64D93E8DA54A1DB349A067A1657@IWDUBCORMSG007.sci.local>
Message-ID: <7d7138c10903251125xee6a07di2cbcf898735ec42a@mail.gmail.com>

This doesn't solve the possible inconsistency between size() and get(int),
since the underlying cowList may change.
I actually think David's fix makes sense. The culprit is depending on
toArray methods to get snapshots, which return arrays, which are mutable and
force the copying.

2009/3/25 Shaffer, Darron <Darron_Shaffer at stercomm.com>

> Or even:
>
>  List snapshot = Collections.unmodifiableList(cowList);
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Sam Berlin
> Sent: Wednesday, March 25, 2009 12:41 PM
> To: David M. Lloyd
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] CopyOnWriteArrayList and snapshots
>
> Would it be possible to achieve much the same thing by calling code doing:
>
>  List snapshot = Arrays.unmodifiableList(Arrays.asList(cowList.toArray()));
>
> Sam
>
> On Wed, Mar 25, 2009 at 1:10 PM, David M. Lloyd <david.lloyd at redhat.com>
> wrote:
> > I've run into a minor issue with CopyOnWriteArrayList and have come up
> with
> > a simple solution for it.  The issue is that you want to perform more
> than
> > one operation on the list (for instance, a size() followed by a get()
> with
> > index, which is otherwise not terribly useful on this class), and you
> need
> > the operations to be consistent with one another.  Using an iterator does
> > provide some ability to do this kind of thing, since it works on an
> > immutable snapshot of the array, but of course you are then limited to
> the
> > basic iterator operations, which do not include random access.  You can
> get
> > a copy of a snapshot using toArray(), but I thought it would be handy to
> > have a more generalized snapshot() method which doesn't do a copy of all
> the
> > list data.
> >
> > Here's a simple five-minute patch which adds a snapshot() method, which
> > returns an immutable List based on the array as it was.  Thoughts?
> >
> > diff -r dde3fe2e8164
> > src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
> > --- a/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
>  Wed
> > Feb 25 14:32:01 2009 +0000
> > +++ b/src/share/classes/java/util/concurrent/CopyOnWriteArrayList.java
>  Wed
> > Mar 25 11:11:19 2009 -0500
> > @@ -988,6 +988,44 @@
> >         return new COWIterator<E>(elements, index);
> >     }
> >
> > +    /**
> > +     * Returns a snapshot view of this list.  The returned list provides
> > +     * a snapshot of the state of the list when the method was called.
>  No
> > +     * synchronization is needed while calling the list methods.  The
> list
> > +     * is read-only; any methods which modify the state of the list will
> > +     * throw <tt>UnsupportedOperationException</tt>.
> > +     *
> > +     * @return a snapshot of this list
> > +     */
> > +    public List<E> snapshot() {
> > +        final Object[] snapshot = getArray();
> > +        return new AbstractList<E>() {
> > +            public E get(final int index) {
> > +                return CopyOnWriteArrayList.this.get(snapshot, index);
> > +            }
> > +
> > +            public int size() {
> > +                return snapshot.length;
> > +            }
> > +
> > +            public Iterator<E> iterator() {
> > +                return new COWIterator<E>(snapshot, 0);
> > +            }
> > +
> > +            public ListIterator<E> listIterator() {
> > +                return new COWIterator<E>(snapshot, 0);
> > +            }
> > +
> > +            public ListIterator<E> listIterator(final int index) {
> > +                Object[] elements = snapshot;
> > +                int len = elements.length;
> > +                if (index<0 || index>len)
> > +                    throw new IndexOutOfBoundsException("Index:
> "+index);
> > +                return new COWIterator<E>(elements, index);
> > +            }
> > +        };
> > +    }
> > +
> >     private static class COWIterator<E> implements ListIterator<E> {
> >         /** Snapshot of the array **/
> >         private final Object[] snapshot;
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090325/67dcc756/attachment.html>

From jeremy.manson at gmail.com  Wed Mar 25 14:32:56 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Wed, 25 Mar 2009 11:32:56 -0700
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CA598F.7070003@cytetech.com>
References: <49CA598F.7070003@cytetech.com>
Message-ID: <1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>

I'm not a G1 expert, but I'm not sure why it wouldn't be?  As I
understand it, there are three cases:

1) In the case where you are doing an assignment in the same region,
G1's barrier is only a few bit-twiddling instructions and an
if-statement that checks which region you are writing.

2) In the case where you are writing to a region you've already
written, it is 1) plus a memory read and another condition to check if
you have already written to the region.

3) In the case where you are writing to a region you haven't already
written, it is 2) plus a memory write to record the fact that you are
writing to another region.

4) Once in a great while, there is some maintenance to organize the
list of regions you have written.

Even 3) is orders of magnitude cheaper than a CAS.  I'm not sure how
expensive 4) is, but it doesn't happen all that often.

Also, proof by politics: If G1 were as expensive as a CAS on every
write, no one would even be thinking about using it.

Jeremy

On Wed, Mar 25, 2009 at 9:19 AM, Gregg Wonderly <gregg at cytetech.com> wrote:
> One of the things about concurrent programming that bothers me the most is
> latency control. ?GC activity can often introduce unwanted latency by
> causing arbitrary contention for resources that a thread may not be able to
> recognize as contentious. ?A long time ago, I created a language with a
> counting collector which I found to be very easy to do on a uniprocessor
> environment. ?With the advent of CAS, it seems at casual grant pretty
> straight forward to do a counting collector on a multi-processor machine.
>
> The upcomming introduction of the garbage first collector intrigues me from
> the perspective that there is a "ton" of managed resources that it uses to
> make itself smart enough to try and accurately estimate and manage the cost
> of GC activity. ?There is use of CAS, plus space and time based isolation
> schemes to try and reduce latency that is introduced into the application.
>
> However, it seems to me that there is going to be a new cost introduced into
> every assignment for mutator tracking that might just be as expensive as a
> counting collector is.
>
> I am not really familiar with the real costs of much of the concurrency
> management instructions, can anyone on the list give me some pointers to
> more information or some insight into whether the amount of "tracking" that
> the garbage first collector will use, is still cheaper than a CAS on every
> reference change to a global object?
>
> Gregg Wonderly
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From jason_mehrens at hotmail.com  Wed Mar 25 15:19:48 2009
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Wed, 25 Mar 2009 14:19:48 -0500
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <49CA65A0.1080201@redhat.com>
References: <49CA65A0.1080201@redhat.com>
Message-ID: <BLU134-W9CC620E383FE60A42D53883900@phx.gbl>


I think CopyOnWriteArrayList.clone() will provide the snapshot behavior you want.  Clone doesn't copy the backing array and only creates one list object.

 

Jason
 
> 
> + /**
> + * Returns a snapshot view of this list. The returned list provides
> + * a snapshot of the state of the list when the method was called. No
> + * synchronization is needed while calling the list methods. The list
> + * is read-only; any methods which modify the state of the list will
> + * throw <tt>UnsupportedOperationException</tt>.
> + *
> + * @return a snapshot of this list
> + */
> + public List<E> snapshot() {
> + final Object[] snapshot = getArray();
> + return new AbstractList<E>() {
> + public E get(final int index) {
> + return CopyOnWriteArrayList.this.get(snapshot, index);
> + }
> +
> + public int size() {
> + return snapshot.length;
> + }
> +
> + public Iterator<E> iterator() {
> + return new COWIterator<E>(snapshot, 0);
> + }
> +
> + public ListIterator<E> listIterator() {
> + return new COWIterator<E>(snapshot, 0);
> + }
> +
> + public ListIterator<E> listIterator(final int index) {
> + Object[] elements = snapshot;
> + int len = elements.length;
> + if (index<0 || index>len)
> + throw new IndexOutOfBoundsException("Index: "+index);
> + return new COWIterator<E>(elements, index);
> + }
> + };
> + }
> +
> private static class COWIterator<E> implements ListIterator<E> {
> /** Snapshot of the array **/
> private final Object[] snapshot;
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_________________________________________________________________
Get quick access to your favorite MSN content with Internet Explorer 8. 
http://ie8.msn.com/microsoft/internet-explorer-8/en-us/ie8.aspx?ocid=B037MSN55C0701A
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090325/0798b57e/attachment-0001.html>

From david.lloyd at redhat.com  Wed Mar 25 15:52:20 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Wed, 25 Mar 2009 14:52:20 -0500
Subject: [concurrency-interest] CopyOnWriteArrayList and snapshots
In-Reply-To: <BLU134-W9CC620E383FE60A42D53883900@phx.gbl>
References: <49CA65A0.1080201@redhat.com>
	<BLU134-W9CC620E383FE60A42D53883900@phx.gbl>
Message-ID: <49CA8B74.4050709@redhat.com>

Hm, you're right!  Cool.  It does clone the lock as well though, which 
might not be good (it uses some scary-looking Unsafe stuff, not to mention 
that the lock is not needed anyway).  I'll have to run some tests I guess.

Either way, it would be nice if that method covariantly returned COWAL<E> 
rather than Object.

- DML

On 03/25/2009 02:19 PM, Jason Mehrens wrote:
> I think CopyOnWriteArrayList.clone() will provide the snapshot behavior 
> you want.  Clone doesn't copy the backing array and only creates one 
> list object.
>  
> Jason
>  
>>
>>  + /**
>>  + * Returns a snapshot view of this list. The returned list provides
>>  + * a snapshot of the state of the list when the method was called. No
>>  + * synchronization is needed while calling the list methods. The list
>>  + * is read-only; any methods which modify the state of the list will
>>  + * throw <tt>UnsupportedOperationException</tt>.
>>  + *
>>  + * @return a snapshot of this list
>>  + */
>>  + public List<E> snapshot() {
>>  + final Object[] snapshot = getArray();
>>  + return new AbstractList<E>() {
>>  + public E get(final int index) {
>>  + return CopyOnWriteArrayList.this.get(snapshot, index);
>>  + }
>>  +
>>  + public int size() {
>>  + return snapshot.length;
>>  + }
>>  +
>>  + public Iterator<E> iterator() {
>>  + return new COWIterator<E>(snapshot, 0);
>>  + }
>>  +
>>  + public ListIterator<E> listIterator() {
>>  + return new COWIterator<E>(snapshot, 0);
>>  + }
>>  +
>>  + public ListIterator<E> listIterator(final int index) {
>>  + Object[] elements = snapshot;
>>  + int len = elements.length;
>>  + if (index<0 || index>len)
>>  + throw new IndexOutOfBoundsException("Index: "+index);
>>  + return new COWIterator<E>(elements, index);
>>  + }
>>  + };
>>  + }
>>  +
>>  private static class COWIterator<E> implements ListIterator<E> {
>>  /** Snapshot of the array **/
>>  private final Object[] snapshot;
>>  _______________________________________________
>>  Concurrency-interest mailing list
>>  Concurrency-interest at cs.oswego.edu
>>  http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> ------------------------------------------------------------------------
> Get quick access to your favorite MSN content with Internet Explorer 8. 
> Download FREE now! 
> <http://ie8.msn.com/microsoft/internet-explorer-8/en-us/ie8.aspx?ocid=B037MSN55C0701A>

From joe.bowbeer at gmail.com  Wed Mar 25 16:29:45 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 25 Mar 2009 13:29:45 -0700
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
Message-ID: <31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>

Can you point us to a good reference on the G1 you are referring to?  (Not a
handset, I assume.)

On Wed, Mar 25, 2009 at 11:32 AM, Jeremy Manson wrote:

> I'm not a G1 expert, but I'm not sure why it wouldn't be?  As I
> understand it, there are three cases:
>
> 1) In the case where you are doing an assignment in the same region,
> G1's barrier is only a few bit-twiddling instructions and an
> if-statement that checks which region you are writing.
>
> 2) In the case where you are writing to a region you've already
> written, it is 1) plus a memory read and another condition to check if
> you have already written to the region.
>
> 3) In the case where you are writing to a region you haven't already
> written, it is 2) plus a memory write to record the fact that you are
> writing to another region.
>
> 4) Once in a great while, there is some maintenance to organize the
> list of regions you have written.
>
> Even 3) is orders of magnitude cheaper than a CAS.  I'm not sure how
> expensive 4) is, but it doesn't happen all that often.
>
> Also, proof by politics: If G1 were as expensive as a CAS on every
> write, no one would even be thinking about using it.
>
> Jeremy
>
> On Wed, Mar 25, 2009 at 9:19 AM, Gregg Wonderly wrote:
> > One of the things about concurrent programming that bothers me the most
> is
> > latency control.  GC activity can often introduce unwanted latency by
> > causing arbitrary contention for resources that a thread may not be able
> to
> > recognize as contentious.  A long time ago, I created a language with a
> > counting collector which I found to be very easy to do on a uniprocessor
> > environment.  With the advent of CAS, it seems at casual grant pretty
> > straight forward to do a counting collector on a multi-processor machine.
> >
> > The upcomming introduction of the garbage first collector intrigues me
> from
> > the perspective that there is a "ton" of managed resources that it uses
> to
> > make itself smart enough to try and accurately estimate and manage the
> cost
> > of GC activity.  There is use of CAS, plus space and time based isolation
> > schemes to try and reduce latency that is introduced into the
> application.
> >
> > However, it seems to me that there is going to be a new cost introduced
> into
> > every assignment for mutator tracking that might just be as expensive as
> a
> > counting collector is.
> >
> > I am not really familiar with the real costs of much of the concurrency
> > management instructions, can anyone on the list give me some pointers to
> > more information or some insight into whether the amount of "tracking"
> that
> > the garbage first collector will use, is still cheaper than a CAS on
> every
> > reference change to a global object?
> >
> > Gregg Wonderly
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090325/826fb99d/attachment.html>

From mlists at juma.me.uk  Wed Mar 25 16:40:48 2009
From: mlists at juma.me.uk (Ismael Juma)
Date: Wed, 25 Mar 2009 20:40:48 +0000
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>
Message-ID: <1238013648.7827.1.camel@localhost.localdomain>

On Wed, 2009-03-25 at 13:29 -0700, Joe Bowbeer wrote:
> Can you point us to a good reference on the G1 you are referring to?
> (Not a handset, I assume.)

JavaOne technical session link:

http://developers.sun.com/learning/javaoneonline/j1sessn.jsp?sessn=TS-5419&yr=2008&track=javase

Best,
Ismael


From takeshi10 at gmail.com  Wed Mar 25 17:40:08 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Wed, 25 Mar 2009 18:40:08 -0300
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <1238013648.7827.1.camel@localhost.localdomain>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>
	<1238013648.7827.1.camel@localhost.localdomain>
Message-ID: <7288749d0903251440x3a9927cfo4939bfb414414a71@mail.gmail.com>

theres also this paper (linked from James Gosling's blog)
http://research.sun.com/jtech/pubs/04-g1-paper-ismm.pdf

by the way, g1 refers to garbage first

On Wed, Mar 25, 2009 at 5:40 PM, Ismael Juma <mlists at juma.me.uk> wrote:
> On Wed, 2009-03-25 at 13:29 -0700, Joe Bowbeer wrote:
>> Can you point us to a good reference on the G1 you are referring to?
>> (Not a handset, I assume.)
>
> JavaOne technical session link:
>
> http://developers.sun.com/learning/javaoneonline/j1sessn.jsp?sessn=TS-5419&yr=2008&track=javase
>
> Best,
> Ismael
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
[]'s
Marcelo Takeshi Fukushima

From geoffrey.wiseman at gmail.com  Wed Mar 25 20:52:17 2009
From: geoffrey.wiseman at gmail.com (Geoffrey Wiseman)
Date: Wed, 25 Mar 2009 20:52:17 -0400
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<31f2a7bd0903251329t393440d7geb08724fd1072946@mail.gmail.com>
Message-ID: <835d522e0903251752r56fe29aga1b733372a8cc599@mail.gmail.com>

On Wed, Mar 25, 2009 at 4:29 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> Can you point us to a good reference on the G1 you are referring to?  (Not
> a handset, I assume.)
>

And, more recently:
http://openjdk.java.net/projects/jdk7/features/#f230

-- 
Geoffrey Wiseman
http://www.geoffreywiseman.ca/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090325/2b120e5f/attachment.html>

From mubeenshah at gmail.com  Thu Mar 26 09:47:17 2009
From: mubeenshah at gmail.com (Mubeen Shah)
Date: Thu, 26 Mar 2009 14:47:17 +0100
Subject: [concurrency-interest] need advise in concurrent threads
In-Reply-To: <c8c377010903260606m93de244m98eaa23cbecf88df@mail.gmail.com>
References: <c8c377010903260606m93de244m98eaa23cbecf88df@mail.gmail.com>
Message-ID: <c8c377010903260647x5659a7b0t4ca287d2b0424c9e@mail.gmail.com>

 Hello,

Hope you all doing very well.

I have a software (spring app) which is basically crawling the web pages,
and I want to control that crawling execution (start, stop and check status)
from other application using web-service, I need to expose three operations:
start, stop and check. Please check the design below:

I have one Crawler class extending the Thread class (Singleton):

public class Crawler extends Thread {

// ... some code here

private static Crawler obj;

private volatile boolean isRunning = false;

private Crawler(){

}

public synchronized static Crawler getInstance(){

if(obj == null){

obj = new BusinessObject();

}

return obj;

}

public void run(){

while(isRunning){

// Crawling the webpages and storing html in DB.

}

}

public void stopCrawler(){

isRunning = false;

}

public boolean status(){

return isRunning;

}

}

}

I have one web-service class extending ServletEndpointSupport (spring
web-service):

public class CrawlerManagerService extends ServletEndpointSupport {

Crawler crawler = Crawler.getInstance();

public String start(){

if( !crawler.status() ){

crawler.start();

}

return "RUNNING";

}

public String stop(){

if(crawler.status()){

crawler.stopCrawler();

}

return "NOT-RUNNING";

}

public String status(){

return ( ( crawler.status )?"RUNNING":"NOT-RUNNING");

}

}



I exposed 3 methods:

start(); // to start the process in thread (i just want a single thread)
stop(); // to stop the thread
status(); // check the current status of that thread

But everytime i am calling this webservice its creating a new thread and
starting service. for now i did one workaround to fix this issue:

I am searching all running threads:

Thread[] allSystemThreads; // suppose i have all running threads in system

den:

Crawler crl = null;

for(Thread t : allSystemThreads){

if(t instanceof Crawler){

crl = (Crawler) t;

break;

}

}

if(crl != null){

// i found the thread now i can start, stop and check status here

}



but i am not sure if its a good way to search for all threads and do the
required operation. can you please advise any possiblity in
java.util.concurrent package to utilize it in a standard way? so that i dont
need to go deeply to manage the threads. Please help me.

Looking forward to hear from you.

Regards,
Mubeen Shah
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090326/38540f3e/attachment-0001.html>

From bronee at gmail.com  Thu Mar 26 11:07:37 2009
From: bronee at gmail.com (Brian S O'Neill)
Date: Thu, 26 Mar 2009 08:07:37 -0700
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CA598F.7070003@cytetech.com>
References: <49CA598F.7070003@cytetech.com>
Message-ID: <49CB9A39.4010504@gmail.com>

How did your collector deal with reference cycles? Was it slow enough to 
not be a problem, or did the language prohibit cycles from arising?

Gregg Wonderly wrote:
> One of the things about concurrent programming that bothers me the 
> most is latency control.  GC activity can often introduce unwanted 
> latency by causing arbitrary contention for resources that a thread 
> may not be able to recognize as contentious.  A long time ago, I 
> created a language with a counting collector which I found to be very 
> easy to do on a uniprocessor environment.  With the advent of CAS, it 
> seems at casual grant pretty straight forward to do a counting 
> collector on a multi-processor machine.
>
> The upcomming introduction of the garbage first collector intrigues me 
> from the perspective that there is a "ton" of managed resources that 
> it uses to make itself smart enough to try and accurately estimate and 
> manage the cost of GC activity.  There is use of CAS, plus space and 
> time based isolation schemes to try and reduce latency that is 
> introduced into the application.
>
> However, it seems to me that there is going to be a new cost 
> introduced into every assignment for mutator tracking that might just 
> be as expensive as a counting collector is.
>
> I am not really familiar with the real costs of much of the 
> concurrency management instructions, can anyone on the list give me 
> some pointers to more information or some insight into whether the 
> amount of "tracking" that the garbage first collector will use, is 
> still cheaper than a CAS on every reference change to a global object?
>
> Gregg Wonderly
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From gregg at cytetech.com  Thu Mar 26 11:55:30 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 26 Mar 2009 10:55:30 -0500
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CB9A39.4010504@gmail.com>
References: <49CA598F.7070003@cytetech.com> <49CB9A39.4010504@gmail.com>
Message-ID: <49CBA572.4090603@cytetech.com>

Brian S O'Neill wrote:
> How did your collector deal with reference cycles? Was it slow enough to 
> not be a problem, or did the language prohibit cycles from arising?

Practically, we didn't write software using this language which had cycles. This 
language was an automation language (on the 5ESS switch) which tied into the UI 
mechanisms and provide parallel process management (fork->exec tracking) so that 
we could take programs and scripts and stitch together procedures for software 
updates/retrofits etc.  It provided forward and reverse execution sequencing to 
do and undo steps repeatedly to restrict how the switch changed states.

I guess everyone knows how counting can be used to track references?
Every assignment, or pass of a value to a method call, created an explicit 
decrement on the lost reference and an increment on the new reference.  Anytime 
the count went to zero, something was freed, and there was an explicit decrement 
of all references within that 'object' too.  Reference cycles were not handled 
explicitly, so they would have been a problem which I never saw materialize in 
the small software modules that were developed using the language.

For example if you had a cycle (with counts shown) such as

F->A(2)->B(1)->C(1)->A(2)

and you drop the F reference to A, A's count goes to 1, it is no longer globally 
referenced and yet you don't free it because the count doesn't go to zero.

I think this is the issue you are referring to right?

As a bit of history, initially, the language had no objects, only numeric and 
string values and things like pipe and process etc, that all went one way in 
terms of reference.  So, there was never a cycle reference issue.  Only 3 years 
after I wrote first wrote it, did I add objects as an extension of maps.  At 
that time, it became possible for circular references to be created.  We just 
didn't have object structures that complicated to see any issues with that 
happening.

Gregg Wonderly

> Gregg Wonderly wrote:
>> One of the things about concurrent programming that bothers me the 
>> most is latency control.  GC activity can often introduce unwanted 
>> latency by causing arbitrary contention for resources that a thread 
>> may not be able to recognize as contentious.  A long time ago, I 
>> created a language with a counting collector which I found to be very 
>> easy to do on a uniprocessor environment.  With the advent of CAS, it 
>> seems at casual grant pretty straight forward to do a counting 
>> collector on a multi-processor machine.
>>
>> The upcomming introduction of the garbage first collector intrigues me 
>> from the perspective that there is a "ton" of managed resources that 
>> it uses to make itself smart enough to try and accurately estimate and 
>> manage the cost of GC activity.  There is use of CAS, plus space and 
>> time based isolation schemes to try and reduce latency that is 
>> introduced into the application.
>>
>> However, it seems to me that there is going to be a new cost 
>> introduced into every assignment for mutator tracking that might just 
>> be as expensive as a counting collector is.
>>
>> I am not really familiar with the real costs of much of the 
>> concurrency management instructions, can anyone on the list give me 
>> some pointers to more information or some insight into whether the 
>> amount of "tracking" that the garbage first collector will use, is 
>> still cheaper than a CAS on every reference change to a global object?
>>
>> Gregg Wonderly
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> 
> 


From Online at Stolsvik.com  Thu Mar 26 13:59:04 2009
From: Online at Stolsvik.com (=?UTF-8?Q?Endre_St=C3=B8lsvik?=)
Date: Thu, 26 Mar 2009 18:59:04 +0100
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CBA572.4090603@cytetech.com>
References: <49CA598F.7070003@cytetech.com> <49CB9A39.4010504@gmail.com> 
	<49CBA572.4090603@cytetech.com>
Message-ID: <1501fdf40903261059q22e6bf8at61d0c70b4c2f947@mail.gmail.com>

Way on the fringe of my knowledge, but I've long wondered: Would it be
an idea to make a GCer that is a combination of reference counting and
tracking? I'm musing that one then would have three types of
collections: The two types in a generational collector, but below
this, a "nonzero copy", which was utterly dumb and simply copies all
objects that have a nonzero reference count. This would be the one
running most often - so the characteristics of this collector would
probably shape the overall performance. The "real", reference tracked
collector would only really be necessary for collecting object cycles
every once and then (The real GC'er could note which objects' classes
are prone to being collected with zero in reference count, possibly
use this for some optimization? Or do some statistics on how often a
real collection should be done, based on counts of collected such
objects? Count in particular the "cycle prone" type instantiations,
and compare this to the amount of collected such objects, trigger a
real GC on some threshold?). Has something like this been tried? Or
would this just obviously create too much overhead because of the
necessary added counting, where following references only when needed
is less costly than continuously updating counts?

Endre.

On Thu, Mar 26, 2009 at 16:55, Gregg Wonderly <gregg at cytetech.com> wrote:
> Brian S O'Neill wrote:
>>
>> How did your collector deal with reference cycles? Was it slow enough to
>> not be a problem, or did the language prohibit cycles from arising?
>
> Practically, we didn't write software using this language which had cycles.
> This language was an automation language (on the 5ESS switch) which tied
> into the UI mechanisms and provide parallel process management (fork->exec
> tracking) so that we could take programs and scripts and stitch together
> procedures for software updates/retrofits etc. ?It provided forward and
> reverse execution sequencing to do and undo steps repeatedly to restrict how
> the switch changed states.
>
> I guess everyone knows how counting can be used to track references?
> Every assignment, or pass of a value to a method call, created an explicit
> decrement on the lost reference and an increment on the new reference.
> ?Anytime the count went to zero, something was freed, and there was an
> explicit decrement of all references within that 'object' too. ?Reference
> cycles were not handled explicitly, so they would have been a problem which
> I never saw materialize in the small software modules that were developed
> using the language.
>
> For example if you had a cycle (with counts shown) such as
>
> F->A(2)->B(1)->C(1)->A(2)
>
> and you drop the F reference to A, A's count goes to 1, it is no longer
> globally referenced and yet you don't free it because the count doesn't go
> to zero.
>
> I think this is the issue you are referring to right?
>
> As a bit of history, initially, the language had no objects, only numeric
> and string values and things like pipe and process etc, that all went one
> way in terms of reference. ?So, there was never a cycle reference issue.
> ?Only 3 years after I wrote first wrote it, did I add objects as an
> extension of maps. ?At that time, it became possible for circular references
> to be created. ?We just didn't have object structures that complicated to
> see any issues with that happening.
>
> Gregg Wonderly
>
>> Gregg Wonderly wrote:
>>>
>>> One of the things about concurrent programming that bothers me the most
>>> is latency control. ?GC activity can often introduce unwanted latency by
>>> causing arbitrary contention for resources that a thread may not be able to
>>> recognize as contentious. ?A long time ago, I created a language with a
>>> counting collector which I found to be very easy to do on a uniprocessor
>>> environment. ?With the advent of CAS, it seems at casual grant pretty
>>> straight forward to do a counting collector on a multi-processor machine.
>>>
>>> The upcomming introduction of the garbage first collector intrigues me
>>> from the perspective that there is a "ton" of managed resources that it uses
>>> to make itself smart enough to try and accurately estimate and manage the
>>> cost of GC activity. ?There is use of CAS, plus space and time based
>>> isolation schemes to try and reduce latency that is introduced into the
>>> application.
>>>
>>> However, it seems to me that there is going to be a new cost introduced
>>> into every assignment for mutator tracking that might just be as expensive
>>> as a counting collector is.
>>>
>>> I am not really familiar with the real costs of much of the concurrency
>>> management instructions, can anyone on the list give me some pointers to
>>> more information or some insight into whether the amount of "tracking" that
>>> the garbage first collector will use, is still cheaper than a CAS on every
>>> reference change to a global object?
>>>
>>> Gregg Wonderly
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From jeremy.manson at gmail.com  Thu Mar 26 14:29:42 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Thu, 26 Mar 2009 11:29:42 -0700
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <1501fdf40903261059q22e6bf8at61d0c70b4c2f947@mail.gmail.com>
References: <49CA598F.7070003@cytetech.com> <49CB9A39.4010504@gmail.com>
	<49CBA572.4090603@cytetech.com>
	<1501fdf40903261059q22e6bf8at61d0c70b4c2f947@mail.gmail.com>
Message-ID: <1631da7d0903261129u540e7146g232b64ac6023811f@mail.gmail.com>

I recall David Bacon doing some work on this.  Here's a link to the
first paper by him on this topic that Google turned up:

http://www.research.ibm.com/people/d/dfb/papers/Bacon01Concurrent.pdf

I'm sure there is much more.

Jeremy

2009/3/26 Endre St?lsvik <Online at stolsvik.com>:
> Way on the fringe of my knowledge, but I've long wondered: Would it be
> an idea to make a GCer that is a combination of reference counting and
> tracking? I'm musing that one then would have three types of
> collections: The two types in a generational collector, but below
> this, a "nonzero copy", which was utterly dumb and simply copies all
> objects that have a nonzero reference count. This would be the one
> running most often - so the characteristics of this collector would
> probably shape the overall performance. The "real", reference tracked
> collector would only really be necessary for collecting object cycles
> every once and then (The real GC'er could note which objects' classes
> are prone to being collected with zero in reference count, possibly
> use this for some optimization? Or do some statistics on how often a
> real collection should be done, based on counts of collected such
> objects? Count in particular the "cycle prone" type instantiations,
> and compare this to the amount of collected such objects, trigger a
> real GC on some threshold?). Has something like this been tried? Or
> would this just obviously create too much overhead because of the
> necessary added counting, where following references only when needed
> is less costly than continuously updating counts?
>
> Endre.
>
> On Thu, Mar 26, 2009 at 16:55, Gregg Wonderly <gregg at cytetech.com> wrote:
>> Brian S O'Neill wrote:
>>>
>>> How did your collector deal with reference cycles? Was it slow enough to
>>> not be a problem, or did the language prohibit cycles from arising?
>>
>> Practically, we didn't write software using this language which had cycles.
>> This language was an automation language (on the 5ESS switch) which tied
>> into the UI mechanisms and provide parallel process management (fork->exec
>> tracking) so that we could take programs and scripts and stitch together
>> procedures for software updates/retrofits etc. ?It provided forward and
>> reverse execution sequencing to do and undo steps repeatedly to restrict how
>> the switch changed states.
>>
>> I guess everyone knows how counting can be used to track references?
>> Every assignment, or pass of a value to a method call, created an explicit
>> decrement on the lost reference and an increment on the new reference.
>> ?Anytime the count went to zero, something was freed, and there was an
>> explicit decrement of all references within that 'object' too. ?Reference
>> cycles were not handled explicitly, so they would have been a problem which
>> I never saw materialize in the small software modules that were developed
>> using the language.
>>
>> For example if you had a cycle (with counts shown) such as
>>
>> F->A(2)->B(1)->C(1)->A(2)
>>
>> and you drop the F reference to A, A's count goes to 1, it is no longer
>> globally referenced and yet you don't free it because the count doesn't go
>> to zero.
>>
>> I think this is the issue you are referring to right?
>>
>> As a bit of history, initially, the language had no objects, only numeric
>> and string values and things like pipe and process etc, that all went one
>> way in terms of reference. ?So, there was never a cycle reference issue.
>> ?Only 3 years after I wrote first wrote it, did I add objects as an
>> extension of maps. ?At that time, it became possible for circular references
>> to be created. ?We just didn't have object structures that complicated to
>> see any issues with that happening.
>>
>> Gregg Wonderly
>>
>>> Gregg Wonderly wrote:
>>>>
>>>> One of the things about concurrent programming that bothers me the most
>>>> is latency control. ?GC activity can often introduce unwanted latency by
>>>> causing arbitrary contention for resources that a thread may not be able to
>>>> recognize as contentious. ?A long time ago, I created a language with a
>>>> counting collector which I found to be very easy to do on a uniprocessor
>>>> environment. ?With the advent of CAS, it seems at casual grant pretty
>>>> straight forward to do a counting collector on a multi-processor machine.
>>>>
>>>> The upcomming introduction of the garbage first collector intrigues me
>>>> from the perspective that there is a "ton" of managed resources that it uses
>>>> to make itself smart enough to try and accurately estimate and manage the
>>>> cost of GC activity. ?There is use of CAS, plus space and time based
>>>> isolation schemes to try and reduce latency that is introduced into the
>>>> application.
>>>>
>>>> However, it seems to me that there is going to be a new cost introduced
>>>> into every assignment for mutator tracking that might just be as expensive
>>>> as a counting collector is.
>>>>
>>>> I am not really familiar with the real costs of much of the concurrency
>>>> management instructions, can anyone on the list give me some pointers to
>>>> more information or some insight into whether the amount of "tracking" that
>>>> the garbage first collector will use, is still cheaper than a CAS on every
>>>> reference change to a global object?
>>>>
>>>> Gregg Wonderly
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From fw at deneb.enyo.de  Thu Mar 26 17:20:54 2009
From: fw at deneb.enyo.de (Florian Weimer)
Date: Thu, 26 Mar 2009 22:20:54 +0100
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	(Jeremy Manson's message of "Wed, 25 Mar 2009 11:32:56 -0700")
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
Message-ID: <87k56cj809.fsf@mid.deneb.enyo.de>

* Jeremy Manson:

> 3) In the case where you are writing to a region you haven't already
> written, it is 2) plus a memory write to record the fact that you are
> writing to another region.

> Even 3) is orders of magnitude cheaper than a CAS.  I'm not sure how
> expensive 4) is, but it doesn't happen all that often.

Depends on the CAS implementation.  CAS (and presumably atomic
increment/decrement on x86) on non-shared cache lines can be made
quite cheap.

One thing to consider is that reference counting only solves the
problem of reachability (ignoring cycles).  It does not help with
fragmentation.

From david.lloyd at redhat.com  Thu Mar 26 17:26:23 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 26 Mar 2009 16:26:23 -0500
Subject: [concurrency-interest] Minor generics nit in AtomicReferenceArray
Message-ID: <49CBF2FF.4090908@redhat.com>

It would be nice if the "expect" parameter of the two compareAndSet methods 
in AtomicReferenceArray would be declared as "Object" rather than "E". 
It's sometimes the case that the expect value is of an unknown class, and 
this fact doesn't affect operation of the method in any way, yet one still 
must annoyingly cast the parameter.

Here's a patch which illustrates the change.  As far as I'm aware, this 
won't affect compatibilty in any way.

- DML

diff -r dde3fe2e8164 
src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
--- 
a/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java 
Wed Feb 25 14:32:01 2009 +0000
+++ 
b/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java 
Thu Mar 26 16:18:34 2009 -0500
@@ -159,7 +159,7 @@
       * @return true if successful. False return indicates that
       * the actual value was not equal to the expected value.
       */
-    public final boolean compareAndSet(int i, E expect, E update) {
+    public final boolean compareAndSet(int i, Object expect, E update) {
          return unsafe.compareAndSwapObject(array, rawIndex(i),
                                           expect, update);
      }
@@ -177,7 +177,7 @@
       * @param update the new value
       * @return true if successful.
       */
-    public final boolean weakCompareAndSet(int i, E expect, E update) {
+    public final boolean weakCompareAndSet(int i, Object expect, E update) {
          return compareAndSet(i, expect, update);
      }



From gregg at cytetech.com  Thu Mar 26 17:33:44 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 26 Mar 2009 16:33:44 -0500
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <87k56cj809.fsf@mid.deneb.enyo.de>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<87k56cj809.fsf@mid.deneb.enyo.de>
Message-ID: <49CBF4B8.5040809@cytetech.com>

Florian Weimer wrote:
> * Jeremy Manson:
> 
>> 3) In the case where you are writing to a region you haven't already
>> written, it is 2) plus a memory write to record the fact that you are
>> writing to another region.
> 
>> Even 3) is orders of magnitude cheaper than a CAS.  I'm not sure how
>> expensive 4) is, but it doesn't happen all that often.
> 
> Depends on the CAS implementation.  CAS (and presumably atomic
> increment/decrement on x86) on non-shared cache lines can be made
> quite cheap.
> 
> One thing to consider is that reference counting only solves the
> problem of reachability (ignoring cycles).  It does not help with
> fragmentation.

Yes, in my implementation, I was using the malloc libraries and just allowing 
them to internally manage grouping.  My collector had nothing to deal with 
compaction or otherwise manage fragmentation.

In particular there are very real issues where small amounts of memory are used 
and freed frequently with just as many larger chunks of memory being allocated 
more permanently.  String concatenation from loops like

	InputStream rd = ...
	int i;
	byte buf[] = ...
	String str = "";
	while( ( i = rd.read(buf) ) > 0 ) {
		str += new String( buf, 0, i );
	}

are great at creating small free structures intermingled with larger permanent 
structures which can quickly fragment memory into unusable segments.

Compaction is something that is vital to long lived highly dynamic application.

Gregg Wonderly

From Online at Stolsvik.com  Thu Mar 26 17:48:17 2009
From: Online at Stolsvik.com (=?UTF-8?Q?Endre_St=C3=B8lsvik?=)
Date: Thu, 26 Mar 2009 22:48:17 +0100
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <1631da7d0903261129u540e7146g232b64ac6023811f@mail.gmail.com>
References: <49CA598F.7070003@cytetech.com> <49CB9A39.4010504@gmail.com> 
	<49CBA572.4090603@cytetech.com>
	<1501fdf40903261059q22e6bf8at61d0c70b4c2f947@mail.gmail.com> 
	<1631da7d0903261129u540e7146g232b64ac6023811f@mail.gmail.com>
Message-ID: <1501fdf40903261448h26263af8p6cdd9d010b90a50@mail.gmail.com>

Thanks!

2009/3/26 Jeremy Manson <jeremy.manson at gmail.com>:
> I recall David Bacon doing some work on this. ?Here's a link to the
> first paper by him on this topic that Google turned up:
>
> http://www.research.ibm.com/people/d/dfb/papers/Bacon01Concurrent.pdf
>
> I'm sure there is much more.
>
> Jeremy
>
> 2009/3/26 Endre St?lsvik <Online at stolsvik.com>:
>> Way on the fringe of my knowledge, but I've long wondered: Would it be
>> an idea to make a GCer that is a combination of reference counting and
>> tracking? I'm musing that one then would have three types of
>> collections: The two types in a generational collector, but below
>> this, a "nonzero copy", which was utterly dumb and simply copies all
>> objects that have a nonzero reference count. This would be the one
>> running most often - so the characteristics of this collector would
>> probably shape the overall performance. The "real", reference tracked
>> collector would only really be necessary for collecting object cycles
>> every once and then (The real GC'er could note which objects' classes
>> are prone to being collected with zero in reference count, possibly
>> use this for some optimization? Or do some statistics on how often a
>> real collection should be done, based on counts of collected such
>> objects? Count in particular the "cycle prone" type instantiations,
>> and compare this to the amount of collected such objects, trigger a
>> real GC on some threshold?). Has something like this been tried? Or
>> would this just obviously create too much overhead because of the
>> necessary added counting, where following references only when needed
>> is less costly than continuously updating counts?
>>
>> Endre.
>>
>> On Thu, Mar 26, 2009 at 16:55, Gregg Wonderly <gregg at cytetech.com> wrote:
>>> Brian S O'Neill wrote:
>>>>
>>>> How did your collector deal with reference cycles? Was it slow enough to
>>>> not be a problem, or did the language prohibit cycles from arising?
>>>
>>> Practically, we didn't write software using this language which had cycles.
>>> This language was an automation language (on the 5ESS switch) which tied
>>> into the UI mechanisms and provide parallel process management (fork->exec
>>> tracking) so that we could take programs and scripts and stitch together
>>> procedures for software updates/retrofits etc. ?It provided forward and
>>> reverse execution sequencing to do and undo steps repeatedly to restrict how
>>> the switch changed states.
>>>
>>> I guess everyone knows how counting can be used to track references?
>>> Every assignment, or pass of a value to a method call, created an explicit
>>> decrement on the lost reference and an increment on the new reference.
>>> ?Anytime the count went to zero, something was freed, and there was an
>>> explicit decrement of all references within that 'object' too. ?Reference
>>> cycles were not handled explicitly, so they would have been a problem which
>>> I never saw materialize in the small software modules that were developed
>>> using the language.
>>>
>>> For example if you had a cycle (with counts shown) such as
>>>
>>> F->A(2)->B(1)->C(1)->A(2)
>>>
>>> and you drop the F reference to A, A's count goes to 1, it is no longer
>>> globally referenced and yet you don't free it because the count doesn't go
>>> to zero.
>>>
>>> I think this is the issue you are referring to right?
>>>
>>> As a bit of history, initially, the language had no objects, only numeric
>>> and string values and things like pipe and process etc, that all went one
>>> way in terms of reference. ?So, there was never a cycle reference issue.
>>> ?Only 3 years after I wrote first wrote it, did I add objects as an
>>> extension of maps. ?At that time, it became possible for circular references
>>> to be created. ?We just didn't have object structures that complicated to
>>> see any issues with that happening.
>>>
>>> Gregg Wonderly
>>>
>>>> Gregg Wonderly wrote:
>>>>>
>>>>> One of the things about concurrent programming that bothers me the most
>>>>> is latency control. ?GC activity can often introduce unwanted latency by
>>>>> causing arbitrary contention for resources that a thread may not be able to
>>>>> recognize as contentious. ?A long time ago, I created a language with a
>>>>> counting collector which I found to be very easy to do on a uniprocessor
>>>>> environment. ?With the advent of CAS, it seems at casual grant pretty
>>>>> straight forward to do a counting collector on a multi-processor machine.
>>>>>
>>>>> The upcomming introduction of the garbage first collector intrigues me
>>>>> from the perspective that there is a "ton" of managed resources that it uses
>>>>> to make itself smart enough to try and accurately estimate and manage the
>>>>> cost of GC activity. ?There is use of CAS, plus space and time based
>>>>> isolation schemes to try and reduce latency that is introduced into the
>>>>> application.
>>>>>
>>>>> However, it seems to me that there is going to be a new cost introduced
>>>>> into every assignment for mutator tracking that might just be as expensive
>>>>> as a counting collector is.
>>>>>
>>>>> I am not really familiar with the real costs of much of the concurrency
>>>>> management instructions, can anyone on the list give me some pointers to
>>>>> more information or some insight into whether the amount of "tracking" that
>>>>> the garbage first collector will use, is still cheaper than a CAS on every
>>>>> reference change to a global object?
>>>>>
>>>>> Gregg Wonderly
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From kevinb at google.com  Thu Mar 26 18:01:37 2009
From: kevinb at google.com (Kevin Bourrillion)
Date: Thu, 26 Mar 2009 15:01:37 -0700
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <49CBF2FF.4090908@redhat.com>
References: <49CBF2FF.4090908@redhat.com>
Message-ID: <108fcdeb0903261501q5a85f8e8s6161ba576bfc2d0a@mail.gmail.com>

Interesting.  I'll just note that the standard set by the Collections
Framework agrees with you:  only parameters which might cause harm are
restricted to E, never the innocuous ones.  Some, for example Bill Pugh,
disagree with this, saying that because it's so rare to need to query with a
non-E, the benefits of supporting that scenario are fewer than those of
catching more bugs in the usual use cases.



On Thu, Mar 26, 2009 at 2:26 PM, David M. Lloyd <david.lloyd at redhat.com>wrote:

> It would be nice if the "expect" parameter of the two compareAndSet methods
> in AtomicReferenceArray would be declared as "Object" rather than "E". It's
> sometimes the case that the expect value is of an unknown class, and this
> fact doesn't affect operation of the method in any way, yet one still must
> annoyingly cast the parameter.
>
> Here's a patch which illustrates the change.  As far as I'm aware, this
> won't affect compatibilty in any way.
>
> - DML
>
> diff -r dde3fe2e8164
> src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> ---
> a/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> Wed Feb 25 14:32:01 2009 +0000
> +++
> b/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> Thu Mar 26 16:18:34 2009 -0500
> @@ -159,7 +159,7 @@
>      * @return true if successful. False return indicates that
>      * the actual value was not equal to the expected value.
>      */
> -    public final boolean compareAndSet(int i, E expect, E update) {
> +    public final boolean compareAndSet(int i, Object expect, E update) {
>         return unsafe.compareAndSwapObject(array, rawIndex(i),
>                                          expect, update);
>     }
> @@ -177,7 +177,7 @@
>      * @param update the new value
>      * @return true if successful.
>      */
> -    public final boolean weakCompareAndSet(int i, E expect, E update) {
> +    public final boolean weakCompareAndSet(int i, Object expect, E update)
> {
>         return compareAndSet(i, expect, update);
>     }
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Kevin Bourrillion @ Google
internal:  http://go/javalibraries
google-collections.googlecode.com
google-guice.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090326/74d408ae/attachment.html>

From hans.boehm at hp.com  Thu Mar 26 18:16:05 2009
From: hans.boehm at hp.com (Boehm, Hans)
Date: Thu, 26 Mar 2009 22:16:05 +0000
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CBF4B8.5040809@cytetech.com>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<87k56cj809.fsf@mid.deneb.enyo.de> <49CBF4B8.5040809@cytetech.com>
Message-ID: <238A96A773B3934685A7269CC8A8D042426B732CF9@GVW0436EXB.americas.hpqcorp.net>

[Little to do with concurrency, but ...]

> Yes, in my implementation, I was using the malloc libraries 
> and just allowing them to internally manage grouping.  My 
> collector had nothing to deal with compaction or otherwise 
> manage fragmentation.
> 
> In particular there are very real issues where small amounts 
> of memory are used and freed frequently with just as many 
> larger chunks of memory being allocated more permanently.  
> String concatenation from loops like
> 
> 	InputStream rd = ...
> 	int i;
> 	byte buf[] = ...
> 	String str = "";
> 	while( ( i = rd.read(buf) ) > 0 ) {
> 		str += new String( buf, 0, i );
> 	}
> 
> are great at creating small free structures intermingled with 
> larger permanent structures which can quickly fragment memory 
> into unusable segments.
> 
> Compaction is something that is vital to long lived highly 
> dynamic application.
> 
This really depends on the underlying allocator (malloc) implementation.

A well-know simple and asymptotically optimal strategy is to round up all allocation requests to the closest power of two, and allocate each size class in separate memory regions, which never shrink.  The total space use is the sum for each n of

<max total space required for size 2**n objects at any point in time>

This can't be more than NlogN, where N is the maximum number of bytes in use, since there are at most logN distinct size classes, and the total size of each class clearly can't exceed N.  If you know that the distribution of objects among the size classes doesn't change too much, you get closer to a linear bound.  If the ratios between the numbers of objects in any two different size classes doesn't ever change by more than a constant factor c, you get a linear bound.  Thus noncompacting scheme can clearly guarantee space bounds for long running programs.  Whether or not you'll like those bounds probably depends on the application.

Real implementations tend to optimize more for the expected case, and sometimes do worse than this in the worst case.

Certain forms of reference counting may introduce worse challenges.  If you try to do a constant amount of work per allocation and pointer assignment, you end up with a quadratic heap size bound instead of NlogN (See http://portal.acm.org/citation.cfm?doid=964001.964019 )

Hans

From david.lloyd at redhat.com  Thu Mar 26 18:27:05 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 26 Mar 2009 17:27:05 -0500
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <108fcdeb0903261501q5a85f8e8s6161ba576bfc2d0a@mail.gmail.com>
References: <49CBF2FF.4090908@redhat.com>
	<108fcdeb0903261501q5a85f8e8s6161ba576bfc2d0a@mail.gmail.com>
Message-ID: <49CC0139.7020208@redhat.com>

He may have a valid point there.  It was, in fact, the collections 
framework that got me into the mess in the first place.  On the other hand, 
having a strong generic parameter in this case has not yet helped me catch 
a single bug (that I'm aware of), but it has caused a problem several times 
for me today alone.  Not that I've had tons of occasions to use 
AtomicReferenceArray, to be fair.

- DML

On 03/26/2009 05:01 PM, Kevin Bourrillion wrote:
> Interesting.  I'll just note that the standard set by the Collections 
> Framework agrees with you:  only parameters which might cause harm are 
> restricted to E, never the innocuous ones.  Some, for example Bill Pugh, 
> disagree with this, saying that because it's so rare to need to query 
> with a non-E, the benefits of supporting that scenario are fewer than 
> those of catching more bugs in the usual use cases.
> 
> 
> 
> On Thu, Mar 26, 2009 at 2:26 PM, David M. Lloyd <david.lloyd at redhat.com 
> <mailto:david.lloyd at redhat.com>> wrote:
> 
>     It would be nice if the "expect" parameter of the two compareAndSet
>     methods in AtomicReferenceArray would be declared as "Object" rather
>     than "E". It's sometimes the case that the expect value is of an
>     unknown class, and this fact doesn't affect operation of the method
>     in any way, yet one still must annoyingly cast the parameter.
> 
>     Here's a patch which illustrates the change.  As far as I'm aware,
>     this won't affect compatibilty in any way.
> 
>     - DML
> 
>     diff -r dde3fe2e8164
>     src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>     ---
>     a/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>     Wed Feb 25 14:32:01 2009 +0000
>     +++
>     b/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>     Thu Mar 26 16:18:34 2009 -0500
>     @@ -159,7 +159,7 @@
>          * @return true if successful. False return indicates that
>          * the actual value was not equal to the expected value.
>          */
>     -    public final boolean compareAndSet(int i, E expect, E update) {
>     +    public final boolean compareAndSet(int i, Object expect, E
>     update) {
>             return unsafe.compareAndSwapObject(array, rawIndex(i),
>                                              expect, update);
>         }
>     @@ -177,7 +177,7 @@
>          * @param update the new value
>          * @return true if successful.
>          */
>     -    public final boolean weakCompareAndSet(int i, E expect, E update) {
>     +    public final boolean weakCompareAndSet(int i, Object expect, E
>     update) {
>             return compareAndSet(i, expect, update);
>         }
> 
> 
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> -- 
> Kevin Bourrillion @ Google
> internal:  http://go/javalibraries
> google-collections.googlecode.com <http://google-collections.googlecode.com>
> google-guice.googlecode.com <http://google-guice.googlecode.com>
> 

From martinrb at google.com  Thu Mar 26 18:31:08 2009
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 26 Mar 2009 15:31:08 -0700
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <49CBF2FF.4090908@redhat.com>
References: <49CBF2FF.4090908@redhat.com>
Message-ID: <1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>

One difference between collections and Atomic* is that the Atomic classes
operate on object identity comparisons, not on .equals() method invocations.
So if the type parameter E is accurate, expect must be an E.

Martin

On Thu, Mar 26, 2009 at 14:26, David M. Lloyd <david.lloyd at redhat.com> wrote:
> It would be nice if the "expect" parameter of the two compareAndSet methods
> in AtomicReferenceArray would be declared as "Object" rather than "E". It's
> sometimes the case that the expect value is of an unknown class, and this
> fact doesn't affect operation of the method in any way, yet one still must
> annoyingly cast the parameter.
>
> Here's a patch which illustrates the change. ?As far as I'm aware, this
> won't affect compatibilty in any way.
>
> - DML
>
> diff -r dde3fe2e8164
> src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> ---
> a/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> Wed Feb 25 14:32:01 2009 +0000
> +++
> b/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
> Thu Mar 26 16:18:34 2009 -0500
> @@ -159,7 +159,7 @@
> ? ? ?* @return true if successful. False return indicates that
> ? ? ?* the actual value was not equal to the expected value.
> ? ? ?*/
> - ? ?public final boolean compareAndSet(int i, E expect, E update) {
> + ? ?public final boolean compareAndSet(int i, Object expect, E update) {
> ? ? ? ? return unsafe.compareAndSwapObject(array, rawIndex(i),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?expect, update);
> ? ? }
> @@ -177,7 +177,7 @@
> ? ? ?* @param update the new value
> ? ? ?* @return true if successful.
> ? ? ?*/
> - ? ?public final boolean weakCompareAndSet(int i, E expect, E update) {
> + ? ?public final boolean weakCompareAndSet(int i, Object expect, E update)
> {
> ? ? ? ? return compareAndSet(i, expect, update);
> ? ? }
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From david.lloyd at redhat.com  Thu Mar 26 18:43:19 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 26 Mar 2009 17:43:19 -0500
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
References: <49CBF2FF.4090908@redhat.com>
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
Message-ID: <49CC0507.2050803@redhat.com>

But comparisons based on object identity need not have matching types.  In 
other words, given: "Object foo; T bar;", "foo == bar" is a valid expression.

- DML

On 03/26/2009 05:31 PM, Martin Buchholz wrote:
> One difference between collections and Atomic* is that the Atomic classes
> operate on object identity comparisons, not on .equals() method invocations.
> So if the type parameter E is accurate, expect must be an E.
> 
> Martin
> 
> On Thu, Mar 26, 2009 at 14:26, David M. Lloyd <david.lloyd at redhat.com> wrote:
>> It would be nice if the "expect" parameter of the two compareAndSet methods
>> in AtomicReferenceArray would be declared as "Object" rather than "E". It's
>> sometimes the case that the expect value is of an unknown class, and this
>> fact doesn't affect operation of the method in any way, yet one still must
>> annoyingly cast the parameter.
>>
>> Here's a patch which illustrates the change.  As far as I'm aware, this
>> won't affect compatibilty in any way.
>>
>> - DML
>>
>> diff -r dde3fe2e8164
>> src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>> ---
>> a/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>> Wed Feb 25 14:32:01 2009 +0000
>> +++
>> b/src/share/classes/java/util/concurrent/atomic/AtomicReferenceArray.java
>> Thu Mar 26 16:18:34 2009 -0500
>> @@ -159,7 +159,7 @@
>>      * @return true if successful. False return indicates that
>>      * the actual value was not equal to the expected value.
>>      */
>> -    public final boolean compareAndSet(int i, E expect, E update) {
>> +    public final boolean compareAndSet(int i, Object expect, E update) {
>>         return unsafe.compareAndSwapObject(array, rawIndex(i),
>>                                          expect, update);
>>     }
>> @@ -177,7 +177,7 @@
>>      * @param update the new value
>>      * @return true if successful.
>>      */
>> -    public final boolean weakCompareAndSet(int i, E expect, E update) {
>> +    public final boolean weakCompareAndSet(int i, Object expect, E update)
>> {
>>         return compareAndSet(i, expect, update);
>>     }
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

From gregg at cytetech.com  Thu Mar 26 19:03:55 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 26 Mar 2009 18:03:55 -0500
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <238A96A773B3934685A7269CC8A8D042426B732CF9@GVW0436EXB.americas.hpqcorp.net>
References: <49CA598F.7070003@cytetech.com>
	<1631da7d0903251132v60b96bf6g29671a065c151f98@mail.gmail.com>
	<87k56cj809.fsf@mid.deneb.enyo.de> <49CBF4B8.5040809@cytetech.com>
	<238A96A773B3934685A7269CC8A8D042426B732CF9@GVW0436EXB.americas.hpqcorp.net>
Message-ID: <49CC09DB.5040703@cytetech.com>

Boehm, Hans wrote:
> [Little to do with concurrency, but ...]
> 
>> Yes, in my implementation, I was using the malloc libraries 
>> and just allowing them to internally manage grouping.  My 
>> collector had nothing to deal with compaction or otherwise 
>> manage fragmentation.
>>
>> In particular there are very real issues where small amounts 
>> of memory are used and freed frequently with just as many 
>> larger chunks of memory being allocated more permanently.  
>> String concatenation from loops like
>>
>> 	InputStream rd = ...
>> 	int i;
>> 	byte buf[] = ...
>> 	String str = "";
>> 	while( ( i = rd.read(buf) ) > 0 ) {
>> 		str += new String( buf, 0, i );
>> 	}
>>
>> are great at creating small free structures intermingled with 
>> larger permanent structures which can quickly fragment memory 
>> into unusable segments.
>>
>> Compaction is something that is vital to long lived highly 
>> dynamic application.
>>
> This really depends on the underlying allocator (malloc) implementation.

Compaction can occur as either an implicit or explicit strategy in the overall 
management of allocations.  Your paper illustrates one way to manage the type of 
issue that my example would create with the original malloc() allocator that C 
started with.  That didn't last long, and pools of fixed size did become visible 
quite a long time ago, in the '80s as I recall.

It's great to see all the continued research and work on trying to make GC 
really not be an impediment to latency estimates in software design.

Gregg Wonderly

From dhanji at gmail.com  Thu Mar 26 20:57:21 2009
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Fri, 27 Mar 2009 11:57:21 +1100
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <49CC0507.2050803@redhat.com>
References: <49CBF2FF.4090908@redhat.com>
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
	<49CC0507.2050803@redhat.com>
Message-ID: <aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>

On Fri, Mar 27, 2009 at 9:43 AM, David M. Lloyd <david.lloyd at redhat.com>wrote:

> But comparisons based on object identity need not have matching types.  In
> other words, given: "Object foo; T bar;", "foo == bar" is a valid
> expression.


Yea but Martin's point is that that expression will only ever be true if foo
and bar are of exactly the same type. Which, is not the case with equals and
collections, both of whom will work with covariant types.

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090327/ff818586/attachment.html>

From david.lloyd at redhat.com  Thu Mar 26 21:33:23 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 26 Mar 2009 20:33:23 -0500
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>
References: <49CBF2FF.4090908@redhat.com>	
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>	
	<49CC0507.2050803@redhat.com>
	<aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>
Message-ID: <49CC2CE3.4040809@redhat.com>

On 03/26/2009 07:57 PM, Dhanji R. Prasanna wrote:
> 
> 
> On Fri, Mar 27, 2009 at 9:43 AM, David M. Lloyd <david.lloyd at redhat.com 
> <mailto:david.lloyd at redhat.com>> wrote:
> 
>     But comparisons based on object identity need not have matching
>     types.  In other words, given: "Object foo; T bar;", "foo == bar" is
>     a valid expression.
> 
> 
> Yea but Martin's point is that that expression will only ever be true if 
> foo and bar are of exactly the same type. Which, is not the case with 
> equals and collections, both of whom will work with covariant types.

But plain type paramters like E *are* covariant.  Any variable that holds 
an E can also hold a ? extends E.  Case in point: an 
AtomicReferenceArray<Object> can hold more than just Object instances, and 
the identity comparison will work just fine.

In any case, if you're using a AtomicReferenceArray<T>, unless you have a 
Class<? extends T> handy, you'll never be able to test that the type is 
compatible; AtomicReferenceArray on the other hand has such a mechanism 
built-in (the identity comparison).  So imagine this situation.  I'm 
implementing ConcurrentMap<K, V>.remove(Object key, Object value).  My 
AtomicReferenceArray's type parameter is V.  What can I do?  I *know* that 
the expression will only ever be true if "value" is a V, but I have no way 
to test for it.  I can cast the "value" parameter to V and suppress the 
warning, which will work (the cast is erased), but it's ugly.

It's a matter of debate whether ConcurrentMap is too lax or 
AtomicReferenceArray is too strict, but of those two choices, 
AtomicReferenceArray is the only one that can be fixed in a 
backwards-compatible fashion.  Though it's also worth noting that in 
contrast to remove(Object,Object), ConcurrentMap.replace(K key, V oldValue, 
V newValue) uses strongly typed parameters where it *could* use Object for 
"oldValue" safely.

- DML

From dhanji at gmail.com  Thu Mar 26 22:01:17 2009
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Fri, 27 Mar 2009 13:01:17 +1100
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <49CC2CE3.4040809@redhat.com>
References: <49CBF2FF.4090908@redhat.com>
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
	<49CC0507.2050803@redhat.com>
	<aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>
	<49CC2CE3.4040809@redhat.com>
Message-ID: <aa067ea10903261901w2b89b98dx593ef3bb4e18ed40@mail.gmail.com>

On Fri, Mar 27, 2009 at 12:33 PM, David M. Lloyd <david.lloyd at redhat.com>wrote:

> AtomicReferenceArray's type parameter is V.  What can I do?  I *know* that
> the expression will only ever be true if "value" is a V, but I have no way
> to test for it.  I can cast the "value" parameter to V and suppress the
> warning, which will work (the cast is erased), but it's ugly.
>
> It's a matter of debate whether ConcurrentMap is too lax or
> AtomicReferenceArray is too strict, but of those two choices,
> AtomicReferenceArray is the only one that can be fixed in a
> backwards-compatible fashion.
>

I don't know. I think the balance between an erased cast in this
(admittedly) rare case and weakening the type signature of
AtomicReferenceArray tips in the former's direction, don't you?

At the very least for the sake of clarity and tools...

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090327/4a7075f4/attachment.html>

From david.lloyd at redhat.com  Thu Mar 26 22:13:03 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 26 Mar 2009 21:13:03 -0500
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <aa067ea10903261901w2b89b98dx593ef3bb4e18ed40@mail.gmail.com>
References: <49CBF2FF.4090908@redhat.com>	
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>	
	<49CC0507.2050803@redhat.com>	
	<aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>	
	<49CC2CE3.4040809@redhat.com>
	<aa067ea10903261901w2b89b98dx593ef3bb4e18ed40@mail.gmail.com>
Message-ID: <49CC362F.8020407@redhat.com>

On 03/26/2009 09:01 PM, Dhanji R. Prasanna wrote:
> 
> 
> On Fri, Mar 27, 2009 at 12:33 PM, David M. Lloyd <david.lloyd at redhat.com 
> <mailto:david.lloyd at redhat.com>> wrote:
> 
>     AtomicReferenceArray's type parameter is V.  What can I do?  I
>     *know* that the expression will only ever be true if "value" is a V,
>     but I have no way to test for it.  I can cast the "value" parameter
>     to V and suppress the warning, which will work (the cast is erased),
>     but it's ugly.
> 
>     It's a matter of debate whether ConcurrentMap is too lax or
>     AtomicReferenceArray is too strict, but of those two choices,
>     AtomicReferenceArray is the only one that can be fixed in a
>     backwards-compatible fashion.  
> 
> 
> I don't know. I think the balance between an erased cast in this 
> (admittedly) rare case and weakening the type signature of 
> AtomicReferenceArray tips in the former's direction, don't you?
> 
> At the very least for the sake of clarity and tools...

Only if you think that weakening the type signature is inherently a bad 
thing.  I don't.  I see no concrete evidence that using a strong type for 
this parameter is a good thing (it has certainly never helped me).  On the 
other hand, my personal experience shows that it can be a hinderance.

- DML

From takeshi10 at gmail.com  Thu Mar 26 23:56:33 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Fri, 27 Mar 2009 00:56:33 -0300
Subject: [concurrency-interest] Minor generics nit in
	AtomicReferenceArray
In-Reply-To: <49CC362F.8020407@redhat.com>
References: <49CBF2FF.4090908@redhat.com>
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
	<49CC0507.2050803@redhat.com>
	<aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>
	<49CC2CE3.4040809@redhat.com>
	<aa067ea10903261901w2b89b98dx593ef3bb4e18ed40@mail.gmail.com>
	<49CC362F.8020407@redhat.com>
Message-ID: <7288749d0903262056s63ddbb74id8b7d6c1b041ff61@mail.gmail.com>

of the top of my head, i can only think of one example: when you have
a Map<Long, ?> and you fetch with int literal
or more generally, i guess it would be better if it'd accept anything
super V instead of V or Object - that way the compiler would block
calls that would always fail (preserving the type check) and you could
call compareAndSet with any type that can possibly be cast down to the
actual type T

On Thu, Mar 26, 2009 at 11:13 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
> On 03/26/2009 09:01 PM, Dhanji R. Prasanna wrote:
>>
>>
>> On Fri, Mar 27, 2009 at 12:33 PM, David M. Lloyd <david.lloyd at redhat.com
>> <mailto:david.lloyd at redhat.com>> wrote:
>>
>> ? ?AtomicReferenceArray's type parameter is V. ?What can I do? ?I
>> ? ?*know* that the expression will only ever be true if "value" is a V,
>> ? ?but I have no way to test for it. ?I can cast the "value" parameter
>> ? ?to V and suppress the warning, which will work (the cast is erased),
>> ? ?but it's ugly.
>>
>> ? ?It's a matter of debate whether ConcurrentMap is too lax or
>> ? ?AtomicReferenceArray is too strict, but of those two choices,
>> ? ?AtomicReferenceArray is the only one that can be fixed in a
>> ? ?backwards-compatible fashion.
>>
>> I don't know. I think the balance between an erased cast in this
>> (admittedly) rare case and weakening the type signature of
>> AtomicReferenceArray tips in the former's direction, don't you?
>>
>> At the very least for the sake of clarity and tools...
>
> Only if you think that weakening the type signature is inherently a bad
> thing. ?I don't. ?I see no concrete evidence that using a strong type for
> this parameter is a good thing (it has certainly never helped me). ?On the
> other hand, my personal experience shows that it can be a hinderance.
>
> - DML
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
[]'s
Marcelo Takeshi Fukushima


From davidcholmes at aapt.net.au  Fri Mar 27 20:27:23 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 28 Mar 2009 10:27:23 +1000
Subject: [concurrency-interest] Garbage First vs a counting collector
In-Reply-To: <49CA598F.7070003@cytetech.com>
Message-ID: <ABEHILABNFKEAJNKLENCMEPECGAA.davidcholmes@aapt.net.au>

<posted on behalf of Tony Printezis>

Gregg,

Some thoughts on the G1 vs. RC subject. I'm not on the list so thanks to 
David Holmes for forwarding your post and posting my reply. If you want, 
we can carry on the conversation on hotspot-gc-dev at openjdk.java.net.

It's true that in G1 we have a non-trivial (in the worst case) write 
barrier that does make writes more expensive. The write barrier has 
three levels of overhead on its path: fast, slow, slower. The fast 
happens, I'd guess 90%-95% of the time and it involves no writes (just a 
read). The slow path is basically when we do a local write, with no 
synchronization needed (queue up a write to a thread-local buffer). 
Slower is when we have to make a full buffer globally available for 
processing, which does involve synchronization. But It's very, very rare.

Sure, I understand that maintenance of RCs can be done easier with a 
CAS. And CASes are relatively cheap these days. However, for heavily 
referenced objects, CASes will fail, which will introduce retrying 
overhead. I personally would much prefer the approach of buffering 
writes and updating RCs in bulk (an extra advantage of this is that some 
of the RC updates might cancel each other out). But, this would look 
very much like what we have in G1, with the exception (maybe!) of not 
being able to filter out as many of the writes as we can.

Still, I wouldn't be in a hurry to implement a GC based on RC for a 
couple of reasons.

First, you have to deal with cycles. Yes, there are techniques to do so. 
Still, they add code and complexity.

Second, and most importantly, RCed GCs are typically non-moving (i.e., 
you de-allocate in-place), which can create fragmentation. And my 10+ 
years experience of implementing GCs has taught me that compaction is 
really very desirable. Maybe you didn't hit any such issues in your 
language. But fragmentation is really a major problem that some of our 
customers that use CMS hit every now and then. With G1, it mostly goes 
away. And it will allow us and our customers to sleep better at night.

Interestingly, I know the GC policies of at least 6 product-quality JVMs 
and none are using RC and I'd guess it's due to some of the issues I 
presented above.

Regards,

Tony Printezis, HotSpot GC Group


From mubeenshah at gmail.com  Sat Mar 28 08:42:17 2009
From: mubeenshah at gmail.com (Mubeen Shah)
Date: Sat, 28 Mar 2009 17:42:17 +0500
Subject: [concurrency-interest] thread cancellation prob
Message-ID: <c8c377010903280542k70f47988pd62d49190cd65d75@mail.gmail.com>

Hello,

Hope you all doing very well.

I have a software (spring app) which is basically crawling the web pages,
and I want to control that crawling execution (start, stop and check status)
from other application using web-service, I need to expose three operations:
start, stop and check. Please check the design below:

I have one Crawler class extending the Thread class (Singleton):

public class Crawler extends Thread {

// ... some code here

private static Crawler obj;

private volatile boolean isRunning = false;

private Crawler(){

}

public synchronized static Crawler getInstance(){

if(obj == null){

obj = new BusinessObject();

}

return obj;

}

public void run(){

while(isRunning){

// Crawling the webpages and storing html in DB.

}

}

public void stopCrawler(){

isRunning = false;

}

public boolean status(){

return isRunning;

}

}

}

I have one web-service class extending ServletEndpointSupport (spring
web-service):

public class CrawlerManagerService extends ServletEndpointSupport {

Crawler crawler = Crawler.getInstance();

public String start(){

if( !crawler.status() ){

crawler.start();

}

return "RUNNING";

}

public String stop(){

if(crawler.status()){

crawler.stopCrawler();

}

return "NOT-RUNNING";

}

public String status(){

return ( ( crawler.status )?"RUNNING":"NOT-RUNNING");

}

}



I exposed 3 methods:

start(); // to start the process in thread (i just want a single thread)
stop(); // to stop the thread
status(); // check the current status of that thread

But everytime i am calling this webservice its creating a new thread and
starting service. for now i did one workaround to fix this issue:

I am searching all running threads:

Thread[] allSystemThreads; // suppose i have all running threads in system

den:

Crawler crl = null;

for(Thread t : allSystemThreads){

if(t instanceof Crawler){

crl = (Crawler) t;

break;

}

}

if(crl != null){

// i found the thread now i can start, stop and check status here

}



but i am not sure if its a good way to search for all threads and do the
required operation. can you please advise any possiblity in
java.util.concurrent package to utilize it in a standard way? so that i dont
need to go deeply to manage the threads. Please help me.

Looking forward to hear from you.

Regards,
Mubeen Shah
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090328/1b20d990/attachment.html>

From tim at peierls.net  Sat Mar 28 12:06:20 2009
From: tim at peierls.net (Tim Peierls)
Date: Sat, 28 Mar 2009 12:06:20 -0400
Subject: [concurrency-interest] thread cancellation prob
In-Reply-To: <c8c377010903280542k70f47988pd62d49190cd65d75@mail.gmail.com>
References: <c8c377010903280542k70f47988pd62d49190cd65d75@mail.gmail.com>
Message-ID: <63b4e4050903280906i3885af9hd648b839627094dd@mail.gmail.com>

Some observations:

   - The use of a guarded static field to hold a singleton instance is
   technically OK, but the initialization on demand holder idiom is simpler.
   - Your test of status before starting the crawler thread is not atomic;
   this needs to be fixed. One way to write this kind of thing safely is using
   compare-and-set on an AtomicReference to an enum that holds the possible
   states of your object.
   - It's almost always better to separate the Thread from the Runnable --
   that way you can try out different execution policies later.
   - If your crawling involves blocking on long operations, consider making
   your crawl logic responsive to interruption.

Combining these ideas:

    public class Crawler implements Runnable {

        // Singleton

        public static Crawler getInstance() {
            return LazyHolder.instance;
        }

        private static class LazyHolder {
            private static final Crawler instance = new Crawler();
        }

        private Crawler() {}


        // Lifecycle

        public void start() {
            if (state.compareAndSet(State.NEW, State.STARTING)) {
                // If Crawler stops being a singleton, consider
                //
                //     Future<?> f = executorService.submit(this);
                //
                // and in stop(), instead of thread.interrupt(), use this:
                //
                //     f.cancel(true);

                (this.thread = new Thread(this)).start();
                state.set(State.RUNNING);
            }
        }

        public void stop() {
            if (state.compareAndSet(State.RUNNING, State.STOPPED)) {
                this.thread.interrupt();
                this.thread = null;
            }
        }

        public boolean isRunning() {
            State s = state.get();
            return s == State.STARTING || s == State.RUNNING;
        }


        // Runnable

        public void run() {
            while (isRunning()) {
                try {
                    crawl();
                } catch (InterruptedException e) {
                    break;
                }
            }
        }

        void crawl() throws InterruptedException {
            // Interrupt-responsive crawl logic
        }


        // Implementation

        enum State { NEW, STARTING, RUNNING, STOPPED }
        private final AtomicReference<State> state = new
AtomicReference<State>(State.NEW);
        private volatile Thread thread;
    }

--tim


On Sat, Mar 28, 2009 at 8:42 AM, Mubeen Shah <mubeenshah at gmail.com> wrote:

> Hello,
>
> Hope you all doing very well.
>
> I have a software (spring app) which is basically crawling the web pages,
> and I want to control that crawling execution (start, stop and check status)
> from other application using web-service, I need to expose three operations:
> start, stop and check. Please check the design below:
>
> I have one Crawler class extending the Thread class (Singleton):
>
> public class Crawler extends Thread {
>
> // ... some code here
>
> private static Crawler obj;
>
> private volatile boolean isRunning = false;
>
> private Crawler(){
>
> }
>
> public synchronized static Crawler getInstance(){
>
> if(obj == null){
>
> obj = new BusinessObject();
>
> }
>
> return obj;
>
> }
>
> public void run(){
>
> while(isRunning){
>
> // Crawling the webpages and storing html in DB.
>
> }
>
> }
>
> public void stopCrawler(){
>
> isRunning = false;
>
> }
>
> public boolean status(){
>
> return isRunning;
>
> }
>
> }
>
> }
>
> I have one web-service class extending ServletEndpointSupport (spring
> web-service):
>
> public class CrawlerManagerService extends ServletEndpointSupport {
>
> Crawler crawler = Crawler.getInstance();
>
> public String start(){
>
> if( !crawler.status() ){
>
> crawler.start();
>
> }
>
> return "RUNNING";
>
> }
>
> public String stop(){
>
> if(crawler.status()){
>
> crawler.stopCrawler();
>
> }
>
> return "NOT-RUNNING";
>
> }
>
> public String status(){
>
> return ( ( crawler.status )?"RUNNING":"NOT-RUNNING");
>
> }
>
> }
>
>
>
> I exposed 3 methods:
>
> start(); // to start the process in thread (i just want a single thread)
> stop(); // to stop the thread
> status(); // check the current status of that thread
>
> But everytime i am calling this webservice its creating a new thread and
> starting service. for now i did one workaround to fix this issue:
>
> I am searching all running threads:
>
> Thread[] allSystemThreads; // suppose i have all running threads in system
>
> den:
>
> Crawler crl = null;
>
> for(Thread t : allSystemThreads){
>
> if(t instanceof Crawler){
>
> crl = (Crawler) t;
>
> break;
>
> }
>
> }
>
> if(crl != null){
>
> // i found the thread now i can start, stop and check status here
>
> }
>
>
>
> but i am not sure if its a good way to search for all threads and do the
> required operation. can you please advise any possiblity in
> java.util.concurrent package to utilize it in a standard way? so that i dont
> need to go deeply to manage the threads. Please help me.
>
> Looking forward to hear from you.
>
> Regards,
> Mubeen Shah
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090328/df1b2b42/attachment.html>

From rob.griffin at quest.com  Sun Mar 29 18:12:22 2009
From: rob.griffin at quest.com (Rob Griffin)
Date: Sun, 29 Mar 2009 15:12:22 -0700
Subject: [concurrency-interest] Minor generics nit
	in	AtomicReferenceArray
In-Reply-To: <7288749d0903262056s63ddbb74id8b7d6c1b041ff61@mail.gmail.com>
References: <49CBF2FF.4090908@redhat.com>
	<1ccfd1c10903261531k7f11928ao2bb99533e829450f@mail.gmail.com>
	<49CC0507.2050803@redhat.com>
	<aa067ea10903261757jd487465o1d28fb1a73ef1fd9@mail.gmail.com>
	<49CC2CE3.4040809@redhat.com>
	<aa067ea10903261901w2b89b98dx593ef3bb4e18ed40@mail.gmail.com>
	<49CC362F.8020407@redhat.com>
	<7288749d0903262056s63ddbb74id8b7d6c1b041ff61@mail.gmail.com>
Message-ID: <9B56A0DB74E164469FE0F25F4B1E9E6C016721F874@alvxmbw05.prod.quest.corp>

That won't work because new Long(0).equals(new Integer(0)) returns false. 

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Marcelo Fukushima
Sent: Friday, 27 March 2009 2:57 PM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Minor generics nit in AtomicReferenceArray

of the top of my head, i can only think of one example: when you have
a Map<Long, ?> and you fetch with int literal
or more generally, i guess it would be better if it'd accept anything
super V instead of V or Object - that way the compiler would block
calls that would always fail (preserving the type check) and you could
call compareAndSet with any type that can possibly be cast down to the
actual type T

On Thu, Mar 26, 2009 at 11:13 PM, David M. Lloyd <david.lloyd at redhat.com> wrote:
> On 03/26/2009 09:01 PM, Dhanji R. Prasanna wrote:
>>
>>
>> On Fri, Mar 27, 2009 at 12:33 PM, David M. Lloyd <david.lloyd at redhat.com
>> <mailto:david.lloyd at redhat.com>> wrote:
>>
>> ? ?AtomicReferenceArray's type parameter is V. ?What can I do? ?I
>> ? ?*know* that the expression will only ever be true if "value" is a V,
>> ? ?but I have no way to test for it. ?I can cast the "value" parameter
>> ? ?to V and suppress the warning, which will work (the cast is erased),
>> ? ?but it's ugly.
>>
>> ? ?It's a matter of debate whether ConcurrentMap is too lax or
>> ? ?AtomicReferenceArray is too strict, but of those two choices,
>> ? ?AtomicReferenceArray is the only one that can be fixed in a
>> ? ?backwards-compatible fashion.
>>
>> I don't know. I think the balance between an erased cast in this
>> (admittedly) rare case and weakening the type signature of
>> AtomicReferenceArray tips in the former's direction, don't you?
>>
>> At the very least for the sake of clarity and tools...
>
> Only if you think that weakening the type signature is inherently a bad
> thing. ?I don't. ?I see no concrete evidence that using a strong type for
> this parameter is a good thing (it has certainly never helped me). ?On the
> other hand, my personal experience shows that it can be a hinderance.
>
> - DML
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
[]'s
Marcelo Takeshi Fukushima

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


