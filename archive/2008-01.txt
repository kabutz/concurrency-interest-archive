From dcholmes at optusnet.com.au  Tue Jan  1 04:34:13 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 1 Jan 2008 19:34:13 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor schdeuling
	problem ?
In-Reply-To: <47795C0E.5080702@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEPAHJAA.dcholmes@optusnet.com.au>

A few general comments:

As you noticed you have to be very careful about trying to measure
timer-based library functions using an "external" clock source. Even with
nanoTime you only get an approximation of measuring what you want to
measure. currentTimeMillis() is typically only updated every 10ms hence the
apparent 10ms "early release".

The API's used for clocks and timers are inherently broken to varying
degrees on all operating systems used by Java: linux, Windows and even
Solaris. See my blog entry for some of the issues on Windows:

http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks

and you have to be clear on the difference between the timer mechanisms used
to trigger time-based events, versus the clock mechanisms used to read
elapsed or current time. Most OSes only support low resolution timers at the
"user" level.

nanoTime is a more expensive operation on many newer systems these days. For
a brief period the TSC on uniprocessor systems offered a very fast high
resolution time source. But the TSC on MP systems is fundamentally broken
until new chips provide TSC synchronization across cores and with stable
frequencies, and so is no longer used for a high resolution time source by
many OSes. Most OSes provide a "time-of-day" value (used by
currentTimeMillis) that is basically a global variable and so reading it
just involves accessing a memory location. Whereas the high resolution
timers used by nanoTime require, in many cases, going out to a device that
is more complicated to access (a memory-mapped HPET is not too expensive,
about the same as the local APIC timer, but the ACPI power management timer
and/or old PIT timer can involve slow IO instructions.)

Aside: hotspot recently introduced code in Java 7 to cache the value used by
currentTimeMillis() to avoid excessive calls to gettimeofday, which were
proving expensive in some use cases. The downside of that is that the
resolution falls to about 50ms and so you have to enable it explicitly.

Be wary of trying to establish accurate absolute times - even if API's
appear to support them. The way in which OSes manipulate absolute times is
fundamentally broken in some cases, as they switch between absolute and
relative at different layers of the OS.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> Sent: Tuesday, 1 January 2008 7:16 AM
> To: Hanson Char
> Cc: ferraro at users.sourceforge.net; John Xiao (ex-Amazon);
> concurrency-interest
> Subject: Re: [concurrency-interest] ScheduledThreadPoolExecutor
> schdeuling problem ?
>
>
> Hanson Char wrote:
> > Oops, not accuracy but precision, as stated in the
> System.nanoTime javadoc:
> >
> >     "This method provides nanosecond precision, but not necessarily
> > nanosecond accuracy"
> >
> > But still, I would imagine it would costs more to compute the
> > nano-time than milli-time.
>
> Generally, the opposite, but there are no guarantees.
> On most platforms nanoTime is cheaper than currentTimeMillis,
> on others about the same. But I don't think there
> are any platforms on which the performance
> difference is big enough in either direction to
> cause anyone to choose one versus the other on performance
> grounds alone.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dcholmes at optusnet.com.au  Tue Jan  1 04:39:23 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 1 Jan 2008 19:39:23 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor
	schdeulingproblem ?
In-Reply-To: <ca53c8f80712311317g5b416f91ue4a3f13daa31c76f@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPAHJAA.dcholmes@optusnet.com.au>

Just to make this point clearer ...

> The design of the CronThreadPoolExecutor
> ...
> is to try to figure out an absolute time in the future to execute by
> calculating the difference of the future time from now.

Conversion of relative times to absolute times is extremely risky, unless
you can guarantee no preemption between the point where you determine the
desired value of the relative time and the point where you measure "now".

Also note that relative time sources and timing mechanisms should be
unaffected by changes to the "system time", whereas absolute ones should be
affected. Unfortunately there are also a lot of bugs in this area too.

David Holmes


From jseigh_cp00 at xemaps.com  Tue Jan  1 10:12:46 2008
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Tue, 01 Jan 2008 10:12:46 -0500
Subject: [concurrency-interest] WeakReference overhead
Message-ID: <477A586E.2050405@xemaps.com>

On a hunch, I replaced the WeakReference PDR hack in my experimental STM 
implementation
with reference counting.  It knocked down the GC times by about 2/3's.  
So it would seem that
the Java Reference implementation has lots of GC overhead and should not 
be used on short
lived objects.  Overall the reduction in STM runtime was about 1/3.

The next experiment would probably be using hazard pointers instead of 
reference counting
(which is a huge pain to do in Java) and maybe object recycling since 
explicit PDR is being
used.  Kind of interesting that even though Java has GC,  explicit 
memory management can
still be useful in some situations.

--
Joe Seigh

From hanson.char at gmail.com  Tue Jan  1 14:23:46 2008
From: hanson.char at gmail.com (Hanson Char)
Date: Tue, 1 Jan 2008 11:23:46 -0800
Subject: [concurrency-interest] ScheduledThreadPoolExecutor schdeuling
	problem ?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEPAHJAA.dcholmes@optusnet.com.au>
References: <47795C0E.5080702@cs.oswego.edu>
	<NFBBKALFDCPFIDBNKAPCCEPAHJAA.dcholmes@optusnet.com.au>
Message-ID: <ca53c8f80801011123v1934b831r8dd3f65a0161dc04@mail.gmail.com>

Hi David,

In the context of a particular machine, assuming there is an imaginery
real absolute current clock time C, is it always true that
System.currentTimeMillis() is less than or equal to C ?

Or can I not even make such assumption ?

Hanson Char

On Jan 1, 2008 1:34 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> A few general comments:
>
> As you noticed you have to be very careful about trying to measure
> timer-based library functions using an "external" clock source. Even with
> nanoTime you only get an approximation of measuring what you want to
> measure. currentTimeMillis() is typically only updated every 10ms hence the
> apparent 10ms "early release".
>
> The API's used for clocks and timers are inherently broken to varying
> degrees on all operating systems used by Java: linux, Windows and even
> Solaris. See my blog entry for some of the issues on Windows:
>
> http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks
>
> and you have to be clear on the difference between the timer mechanisms used
> to trigger time-based events, versus the clock mechanisms used to read
> elapsed or current time. Most OSes only support low resolution timers at the
> "user" level.
>
> nanoTime is a more expensive operation on many newer systems these days. For
> a brief period the TSC on uniprocessor systems offered a very fast high
> resolution time source. But the TSC on MP systems is fundamentally broken
> until new chips provide TSC synchronization across cores and with stable
> frequencies, and so is no longer used for a high resolution time source by
> many OSes. Most OSes provide a "time-of-day" value (used by
> currentTimeMillis) that is basically a global variable and so reading it
> just involves accessing a memory location. Whereas the high resolution
> timers used by nanoTime require, in many cases, going out to a device that
> is more complicated to access (a memory-mapped HPET is not too expensive,
> about the same as the local APIC timer, but the ACPI power management timer
> and/or old PIT timer can involve slow IO instructions.)
>
> Aside: hotspot recently introduced code in Java 7 to cache the value used by
> currentTimeMillis() to avoid excessive calls to gettimeofday, which were
> proving expensive in some use cases. The downside of that is that the
> resolution falls to about 50ms and so you have to enable it explicitly.
>
> Be wary of trying to establish accurate absolute times - even if API's
> appear to support them. The way in which OSes manipulate absolute times is
> fundamentally broken in some cases, as they switch between absolute and
> relative at different layers of the OS.
>
> Cheers,
> David Holmes
>
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> > Sent: Tuesday, 1 January 2008 7:16 AM
> > To: Hanson Char
> > Cc: ferraro at users.sourceforge.net; John Xiao (ex-Amazon);
> > concurrency-interest
> > Subject: Re: [concurrency-interest] ScheduledThreadPoolExecutor
> > schdeuling problem ?
> >
> >
> > Hanson Char wrote:
> > > Oops, not accuracy but precision, as stated in the
> > System.nanoTime javadoc:
> > >
> > >     "This method provides nanosecond precision, but not necessarily
> > > nanosecond accuracy"
> > >
> > > But still, I would imagine it would costs more to compute the
> > > nano-time than milli-time.
> >
> > Generally, the opposite, but there are no guarantees.
> > On most platforms nanoTime is cheaper than currentTimeMillis,
> > on others about the same. But I don't think there
> > are any platforms on which the performance
> > difference is big enough in either direction to
> > cause anyone to choose one versus the other on performance
> > grounds alone.
> >
> > -Doug
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>

From dcholmes at optusnet.com.au  Tue Jan  1 17:59:44 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 2 Jan 2008 08:59:44 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor
	schdeulingproblem ?
In-Reply-To: <ca53c8f80801011123v1934b831r8dd3f65a0161dc04@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEPCHJAA.dcholmes@optusnet.com.au>

Hanson,

I'm not sure exactly what you mean. If C has infinite resolution and follows
wall-clock time (ie DST changes, leap years, leap seconds etc) then an
implementation of currentTimeMillis() that simply reads the current value of
C will always return a value less than or equal to C at the instant C was
read. But a value just returned by currentTimeMillis() could be greater than
C an instant later if C was just adjusted backward for DST.

And in the caching implementation I mentioned for hotspot, C could already
have been adjusted backward while currentTimeMillis() still returns an old
value of C.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> Char
> Sent: Wednesday, 2 January 2008 5:24 AM
> To: dholmes at ieee.org
> Cc: ferraro at users.sourceforge.net; Doug Lea; concurrency-interest; John
> Xiao (ex-Amazon)
> Subject: Re: [concurrency-interest] ScheduledThreadPoolExecutor
> schdeulingproblem ?
>
>
> Hi David,
>
> In the context of a particular machine, assuming there is an imaginery
> real absolute current clock time C, is it always true that
> System.currentTimeMillis() is less than or equal to C ?
>
> Or can I not even make such assumption ?
>
> Hanson Char
>
> On Jan 1, 2008 1:34 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > A few general comments:
> >
> > As you noticed you have to be very careful about trying to measure
> > timer-based library functions using an "external" clock source.
> Even with
> > nanoTime you only get an approximation of measuring what you want to
> > measure. currentTimeMillis() is typically only updated every
> 10ms hence the
> > apparent 10ms "early release".
> >
> > The API's used for clocks and timers are inherently broken to varying
> > degrees on all operating systems used by Java: linux, Windows and even
> > Solaris. See my blog entry for some of the issues on Windows:
> >
> > http://blogs.sun.com/dholmes/entry/inside_the_hotspot_vm_clocks
> >
> > and you have to be clear on the difference between the timer
> mechanisms used
> > to trigger time-based events, versus the clock mechanisms used to read
> > elapsed or current time. Most OSes only support low resolution
> timers at the
> > "user" level.
> >
> > nanoTime is a more expensive operation on many newer systems
> these days. For
> > a brief period the TSC on uniprocessor systems offered a very fast high
> > resolution time source. But the TSC on MP systems is
> fundamentally broken
> > until new chips provide TSC synchronization across cores and with stable
> > frequencies, and so is no longer used for a high resolution
> time source by
> > many OSes. Most OSes provide a "time-of-day" value (used by
> > currentTimeMillis) that is basically a global variable and so reading it
> > just involves accessing a memory location. Whereas the high resolution
> > timers used by nanoTime require, in many cases, going out to a
> device that
> > is more complicated to access (a memory-mapped HPET is not too
> expensive,
> > about the same as the local APIC timer, but the ACPI power
> management timer
> > and/or old PIT timer can involve slow IO instructions.)
> >
> > Aside: hotspot recently introduced code in Java 7 to cache the
> value used by
> > currentTimeMillis() to avoid excessive calls to gettimeofday, which were
> > proving expensive in some use cases. The downside of that is that the
> > resolution falls to about 50ms and so you have to enable it explicitly.
> >
> > Be wary of trying to establish accurate absolute times - even if API's
> > appear to support them. The way in which OSes manipulate
> absolute times is
> > fundamentally broken in some cases, as they switch between absolute and
> > relative at different layers of the OS.
> >
> > Cheers,
> > David Holmes
> >
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf
> Of Doug Lea
> > > Sent: Tuesday, 1 January 2008 7:16 AM
> > > To: Hanson Char
> > > Cc: ferraro at users.sourceforge.net; John Xiao (ex-Amazon);
> > > concurrency-interest
> > > Subject: Re: [concurrency-interest] ScheduledThreadPoolExecutor
> > > schdeuling problem ?
> > >
> > >
> > > Hanson Char wrote:
> > > > Oops, not accuracy but precision, as stated in the
> > > System.nanoTime javadoc:
> > > >
> > > >     "This method provides nanosecond precision, but not necessarily
> > > > nanosecond accuracy"
> > > >
> > > > But still, I would imagine it would costs more to compute the
> > > > nano-time than milli-time.
> > >
> > > Generally, the opposite, but there are no guarantees.
> > > On most platforms nanoTime is cheaper than currentTimeMillis,
> > > on others about the same. But I don't think there
> > > are any platforms on which the performance
> > > difference is big enough in either direction to
> > > cause anyone to choose one versus the other on performance
> > > grounds alone.
> > >
> > > -Doug
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Wed Jan  2 03:00:05 2008
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 2 Jan 2008 00:00:05 -0800
Subject: [concurrency-interest] ScheduledThreadPoolExecutor schdeuling
	problem ?
In-Reply-To: <ca53c8f80712311317g5b416f91ue4a3f13daa31c76f@mail.gmail.com>
References: <ca53c8f80712291440x60cf4f22na81040f108198f7e@mail.gmail.com>
	<4778F5CB.40209@cs.oswego.edu>
	<ca53c8f80712310901q59c51ce8n54a1cb86c2c8ba7f@mail.gmail.com>
	<ca53c8f80712311110t7bb030ddm63ff0b0a6f5f6db@mail.gmail.com>
	<ca53c8f80712311119ud46f3fet36e5f16728e18865@mail.gmail.com>
	<477942C7.9070409@cs.oswego.edu>
	<ca53c8f80712311317g5b416f91ue4a3f13daa31c76f@mail.gmail.com>
Message-ID: <ca53c8f80801020000i439fef2bt9cddc0deed07dd5a@mail.gmail.com>

On Dec 31, 2007 1:17 PM, Hanson Char <hanson.char at gmail.com> wrote:
> Should the task got executed by the scheduler happened earlier than
> the target/absolute time, the proper solution would probably be to
> skip the execution but immediately reschedule the task to execute at
> the same target/absolute time again (by calculating the difference
> between the then current time and the target time, both only available
> in millisec).

On 2nd thought, the task executed by the scheduler actually took place
at the correct target time.  It's the System.currentTimeMillis() at
that moment that could return a value which is not up-to-date enough
and therefore makes it appears as if the task got executed earlier
than it should.

Should such scheduled task appears to take place earlier than the
current/original target time, it should still execute (since that is
actually the right moment despite the outdated value from
System.currentTimeMillis()), and then be scheduled, if necessary, for
the next execution with a delay equal to the difference between the
next target time and the current/original target time.

Hanson Char

From hanson.char at gmail.com  Wed Jan  2 05:06:27 2008
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 2 Jan 2008 02:06:27 -0800
Subject: [concurrency-interest] ScheduledThreadPoolExecutor schdeuling
	problem ?
In-Reply-To: <ca53c8f80801020000i439fef2bt9cddc0deed07dd5a@mail.gmail.com>
References: <ca53c8f80712291440x60cf4f22na81040f108198f7e@mail.gmail.com>
	<4778F5CB.40209@cs.oswego.edu>
	<ca53c8f80712310901q59c51ce8n54a1cb86c2c8ba7f@mail.gmail.com>
	<ca53c8f80712311110t7bb030ddm63ff0b0a6f5f6db@mail.gmail.com>
	<ca53c8f80712311119ud46f3fet36e5f16728e18865@mail.gmail.com>
	<477942C7.9070409@cs.oswego.edu>
	<ca53c8f80712311317g5b416f91ue4a3f13daa31c76f@mail.gmail.com>
	<ca53c8f80801020000i439fef2bt9cddc0deed07dd5a@mail.gmail.com>
Message-ID: <ca53c8f80801020206l3250a5e6y621d7199493306cf@mail.gmail.com>

For scheduling purposes, I wonder if it would make sense to
instantiate a clock (see below) that can provide consistent
currentTimeMilli based on nano time, and pass the clock instance
around.  Places that need to invoke System.currentTimeMilli (for
scheduling purposes) would then instead invoke the clock's
currentTimeMilli to obtain a consistent view of time.  This clock's
currentTimeMilli would be immune to the out-of-date refresh problem of
System.currentTimeMilli.  However, since the System.nanoTime could be
implemented on a different hardware device than
System.currentTimeMilli, such clock would probably gradually diverge
from the System.currentTimeMilli with no upper bound :-(

Hanson Char

import static java.util.concurrent.TimeUnit.NANOSECONDS;
import net.jcip.annotations.Immutable;

@Immutable
public class Clock {
	private final long startNano = System.nanoTime();
	private final long startMilli = System.currentTimeMillis();
	
	public long currentTimeMilli() {
		return startMilli + NANOSECONDS.toMillis(System.nanoTime() - startNano);
	}
}

From dcholmes at optusnet.com.au  Wed Jan  2 07:07:25 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 2 Jan 2008 22:07:25 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor
	schdeulingproblem ?
In-Reply-To: <ca53c8f80801020206l3250a5e6y621d7199493306cf@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEPEHJAA.dcholmes@optusnet.com.au>

Hanson,

I'm unclear on what exactly you are trying to achieve. A high resolution
clock that started out tied to the system clock is of somewhat limited use
in my view - even though the Real-time Specification for Java defines such
as clock. :) What do you achieve by knowing that this clock was at least
once consistent with wall-clock time? In my view you either need absolute
times or relative and if absolute then you need to track wall-clock time.

With current hardware plus OS exposed services you can have either an
absolute time source, or a high resolution one, but not both it seems.

As for the drift between nanoTime and currentTimeMillis ... I don't know the
math for expressing this. I did come across (was sent a link to) a really
good presentation on this but I've lost it and can't remember enough detail
to have google locate it. But google will locate an awful lot on clock
errors and drift :)

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hanson
> Char
> Sent: Wednesday, 2 January 2008 8:06 PM
> To: concurrency-interest
> Subject: Re: [concurrency-interest] ScheduledThreadPoolExecutor
> schdeulingproblem ?
>
>
> For scheduling purposes, I wonder if it would make sense to
> instantiate a clock (see below) that can provide consistent
> currentTimeMilli based on nano time, and pass the clock instance
> around.  Places that need to invoke System.currentTimeMilli (for
> scheduling purposes) would then instead invoke the clock's
> currentTimeMilli to obtain a consistent view of time.  This clock's
> currentTimeMilli would be immune to the out-of-date refresh problem of
> System.currentTimeMilli.  However, since the System.nanoTime could be
> implemented on a different hardware device than
> System.currentTimeMilli, such clock would probably gradually diverge
> from the System.currentTimeMilli with no upper bound :-(
>
> Hanson Char
>
> import static java.util.concurrent.TimeUnit.NANOSECONDS;
> import net.jcip.annotations.Immutable;
>
> @Immutable
> public class Clock {
> 	private final long startNano = System.nanoTime();
> 	private final long startMilli = System.currentTimeMillis();
>
> 	public long currentTimeMilli() {
> 		return startMilli +
> NANOSECONDS.toMillis(System.nanoTime() - startNano);
> 	}
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From hans.boehm at hp.com  Wed Jan  2 13:28:42 2008
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 2 Jan 2008 18:28:42 +0000
Subject: [concurrency-interest] WeakReference overhead
In-Reply-To: <477A586E.2050405@xemaps.com>
References: <477A586E.2050405@xemaps.com>
Message-ID: <EB8E0FF63AB2414693DB20D50E863AE809196F5B@G3W0634.americas.hpqcorp.net>

> -----Original Message-----
> From:  Joseph Seigh
>
> On a hunch, I replaced the WeakReference PDR hack in my
> experimental STM implementation with reference counting.  It
> knocked down the GC times by about 2/3's.
> So it would seem that
> the Java Reference implementation has lots of GC overhead and
> should not be used on short lived objects.  Overall the
> reduction in STM runtime was about 1/3.
>
I would expect Java WeakReference and finalization to be implementated similarly, and to both be rather slow.  Most implementations assume (usually correctly) that a small fraction of objects is affected and instead optimize for the normal case (few weak references, trivial finalizers).  There are some simple measuremetns for finalization on slide 6 of http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/java_finalizers.pdf , which is now several years old.

Hans


From gkorland at gmail.com  Wed Jan  2 22:40:33 2008
From: gkorland at gmail.com (Guy Korland)
Date: Thu, 3 Jan 2008 05:40:33 +0200
Subject: [concurrency-interest] JSR-1 and JSR-166
Message-ID: <79be5fa30801021940s770f28e6qf511b954d1b9f697@mail.gmail.com>

Hi,
Is there any work to integrate the two JSRs?
e.g. RealTime threads and thread pools?

Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080103/d3bcf0c2/attachment.html 

From dcholmes at optusnet.com.au  Thu Jan  3 00:21:53 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 3 Jan 2008 15:21:53 +1000
Subject: [concurrency-interest] JSR-1 and JSR-166
In-Reply-To: <79be5fa30801021940s770f28e6qf511b954d1b9f697@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPGHJAA.dcholmes@optusnet.com.au>

Hello Guy,

Short answer: no. There's no active JSR work in this area, though a number
of people are no doubt thinking about some of the issues.

You should be able to use a ThreadPoolExecutor with real-time threads
"simply" by using an appropriate ThreadFactory, but of course configuration
of real-time threads is a little more involved then for regular Java
threads. Plus you are likely to want to prioritize the work that you pass to
the executor and have it execute in a suitable RTT. That can be done by
having each Runnable/Callable do the necessary configuration itself, but of
course this would run at the default priority of the pool threads (or the
priority they were left in). A priority-aware thread pool would be a
somewhat different beast than JSR-166's ThreadPoolExecutor (see Real-time
Corba's "lanes" based thread pool for something that might be more
suitable).

That said, as with any of the core libraries, you are likely to encounter
problem if you try to use NoHeapRealtimeThreads as part of a pool; similarly
you may encounter problems if you try to create and/or use a pool from
ScopedMemory.

I'm not aware of anyone actually trying to use JSR-166 thread pools with an
RTSJ implementation.

Cheers,
David Holmes
JSR-166 EG Member, JSR-1 Technical Interpretation Committee Member, JSR-282
(RTSJ 1.1) EG Member
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Guy Korland
  Sent: Thursday, 3 January 2008 1:41 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] JSR-1 and JSR-166


  Hi,
  Is there any work to integrate the two JSRs?
  e.g. RealTime threads and thread pools?

  Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080103/7cf2d996/attachment.html 

From notorand at gmail.com  Fri Jan  4 00:07:37 2008
From: notorand at gmail.com (BJ Low)
Date: Fri, 4 Jan 2008 13:07:37 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
Message-ID: <c1dcd6d20801032107l512b43c6w90a2c96b4b9ad542@mail.gmail.com>

Hi all,

I am seeing some bizarre behavior in the ConcurrentHashMap where one
thread constructs an objects and puts it into a the map and another
thread gets the object and sees it as null. Has any one encountered
this problem before. I believe this problem is posted sometime ago by
Eric Zoerner to this mailing list however there is no reply.

Any help is greatly appreciated.

-- 
Regards,
BJ Low

From dcholmes at optusnet.com.au  Fri Jan  4 00:58:40 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 4 Jan 2008 15:58:40 +1000
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801032107l512b43c6w90a2c96b4b9ad542@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEPJHJAA.dcholmes@optusnet.com.au>

BJ,

Can you provide further information: code sketch, exception stack trace
details. I'm unclear whether get() is returning null unexpectedly or whether
get() is throwing the NPE. The usual source for the latter is misbehaving
equals() methods.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low
> Sent: Friday, 4 January 2008 3:08 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
>
>
> Hi all,
>
> I am seeing some bizarre behavior in the ConcurrentHashMap where one
> thread constructs an objects and puts it into a the map and another
> thread gets the object and sees it as null. Has any one encountered
> this problem before. I believe this problem is posted sometime ago by
> Eric Zoerner to this mailing list however there is no reply.
>
> Any help is greatly appreciated.
>
> --
> Regards,
> BJ Low
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From notorand at gmail.com  Fri Jan  4 01:41:01 2008
From: notorand at gmail.com (BJ Low)
Date: Fri, 4 Jan 2008 14:41:01 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEPJHJAA.dcholmes@optusnet.com.au>
References: <c1dcd6d20801032107l512b43c6w90a2c96b4b9ad542@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEPJHJAA.dcholmes@optusnet.com.au>
Message-ID: <c1dcd6d20801032241g1d24f6ceycd3e3e2a325c712d@mail.gmail.com>

Hi,

What I have implemented is an NIO wrapper that is similar to Apache
MINA. In this, there are multiple n threads that is handling all the m
sockets reads/writes. However, it is guaranteed that only 1 thread can
notify the listener of each connections IO events. For example
Thread-1 notify listener onNewConnection(), and Thread-2 notify
listener onRead(), however Thread-1 and Thread-2 can never notify
concurrently, multithreaded underneath, but appears monothreaded

Right now, I am suspecting that it might be the case that Thread-1
when onNewConnection() constructs the key X and stores Y into the
ConcurrentHashMap, Thread-2 fails to see the key as initialized due to
Java Memory Model(even though Thread-2 executes after Thread-1),
resulting in null that is passed to CHM.get() and therefore resulting
in null return value

On Jan 4, 2008 1:58 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> BJ,
>
> Can you provide further information: code sketch, exception stack trace
> details. I'm unclear whether get() is returning null unexpectedly or whether
> get() is throwing the NPE. The usual source for the latter is misbehaving
> equals() methods.
>
> Cheers,
> David Holmes
>
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low
> > Sent: Friday, 4 January 2008 3:08 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
> >
> >
> > Hi all,
> >
> > I am seeing some bizarre behavior in the ConcurrentHashMap where one
> > thread constructs an objects and puts it into a the map and another
> > thread gets the object and sees it as null. Has any one encountered
> > this problem before. I believe this problem is posted sometime ago by
> > Eric Zoerner to this mailing list however there is no reply.
> >
> > Any help is greatly appreciated.
> >
> > --
> > Regards,
> > BJ Low
>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>



-- 
Regards,
BJ Low

From dcholmes at optusnet.com.au  Fri Jan  4 01:46:32 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 4 Jan 2008 16:46:32 +1000
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801032241g1d24f6ceycd3e3e2a325c712d@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEPJHJAA.dcholmes@optusnet.com.au>

How is the key published from Thread-1 to Thread-2?

Java Memory Model issues tend to manifest through agressive optimizations in
the VM rather than actual memory consistency problems. Are you running the
server VM or client?

Cheers,
David Holmes

> -----Original Message-----
> From: BJ Low [mailto:notorand at gmail.com]
> Sent: Friday, 4 January 2008 4:41 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ConcurrentHashMap
> NullPointerException
>
>
> Hi,
>
> What I have implemented is an NIO wrapper that is similar to Apache
> MINA. In this, there are multiple n threads that is handling all the m
> sockets reads/writes. However, it is guaranteed that only 1 thread can
> notify the listener of each connections IO events. For example
> Thread-1 notify listener onNewConnection(), and Thread-2 notify
> listener onRead(), however Thread-1 and Thread-2 can never notify
> concurrently, multithreaded underneath, but appears monothreaded
>
> Right now, I am suspecting that it might be the case that Thread-1
> when onNewConnection() constructs the key X and stores Y into the
> ConcurrentHashMap, Thread-2 fails to see the key as initialized due to
> Java Memory Model(even though Thread-2 executes after Thread-1),
> resulting in null that is passed to CHM.get() and therefore resulting
> in null return value
>
> On Jan 4, 2008 1:58 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > BJ,
> >
> > Can you provide further information: code sketch, exception stack trace
> > details. I'm unclear whether get() is returning null
> unexpectedly or whether
> > get() is throwing the NPE. The usual source for the latter is
> misbehaving
> > equals() methods.
> >
> > Cheers,
> > David Holmes
> >
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low
> > > Sent: Friday, 4 January 2008 3:08 PM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
> > >
> > >
> > > Hi all,
> > >
> > > I am seeing some bizarre behavior in the ConcurrentHashMap where one
> > > thread constructs an objects and puts it into a the map and another
> > > thread gets the object and sees it as null. Has any one encountered
> > > this problem before. I believe this problem is posted sometime ago by
> > > Eric Zoerner to this mailing list however there is no reply.
> > >
> > > Any help is greatly appreciated.
> > >
> > > --
> > > Regards,
> > > BJ Low
> >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
>
>
>
> --
> Regards,
> BJ Low
>


From notorand at gmail.com  Fri Jan  4 02:22:08 2008
From: notorand at gmail.com (BJ Low)
Date: Fri, 4 Jan 2008 15:22:08 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEPJHJAA.dcholmes@optusnet.com.au>
References: <c1dcd6d20801032241g1d24f6ceycd3e3e2a325c712d@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEPJHJAA.dcholmes@optusnet.com.au>
Message-ID: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>

According to this
http://java.sun.com/j2se/1.5.0/docs/guide/vm/server-class.html, since my
server is a quad-core processsor with 4g ram, it is running in server mode
then.

At time t1, Thread-1 will create the key X, put the value Y to CHM, and
store the key to another object Z
At time t2, Thread-2 will then take out the key X from object Z, get the
value Y from CHM using key X, where t2 > t1

The storing of key X to object Z is during object Z constructor method. the
retrieval of key X is a simple getter() method without any synchronization
or volatile.

However, i notice another additional thing after inspecting the code again,
that is before Thread-1 enter the method to create the key X etc, it is
synchronized around an object SS, same thing for Thread-2. Therefore, it
cannot be the case of Java Memory Model interfering. If it is not JMM, then
what could it be that causes ConcurrentHashMap to return null?

On Jan 4, 2008 2:46 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> How is the key published from Thread-1 to Thread-2?
>
> Java Memory Model issues tend to manifest through agressive optimizations
in
> the VM rather than actual memory consistency problems. Are you running the
> server VM or client?
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
>
> > From: BJ Low [mailto:notorand at gmail.com]
> > Sent: Friday, 4 January 2008 4:41 PM
> > To: dholmes at ieee.org
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] ConcurrentHashMap
> > NullPointerException
> >
> >
> > Hi,
> >
> > What I have implemented is an NIO wrapper that is similar to Apache
> > MINA. In this, there are multiple n threads that is handling all the m
> > sockets reads/writes. However, it is guaranteed that only 1 thread can
> > notify the listener of each connections IO events. For example
> > Thread-1 notify listener onNewConnection(), and Thread-2 notify
> > listener onRead(), however Thread-1 and Thread-2 can never notify
> > concurrently, multithreaded underneath, but appears monothreaded
> >
> > Right now, I am suspecting that it might be the case that Thread-1
> > when onNewConnection() constructs the key X and stores Y into the
> > ConcurrentHashMap, Thread-2 fails to see the key as initialized due to
> > Java Memory Model(even though Thread-2 executes after Thread-1),
> > resulting in null that is passed to CHM.get() and therefore resulting
> > in null return value
> >
> > On Jan 4, 2008 1:58 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > > BJ,
> > >
> > > Can you provide further information: code sketch, exception stack
trace
> > > details. I'm unclear whether get() is returning null
> > unexpectedly or whether
> > > get() is throwing the NPE. The usual source for the latter is
> > misbehaving
> > > equals() methods.
> > >
> > > Cheers,
> > > David Holmes
> > >
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ
Low
> > > > Sent: Friday, 4 January 2008 3:08 PM
> > > > To: concurrency-interest at cs.oswego.edu
> > > > Subject: [concurrency-interest] ConcurrentHashMap
NullPointerException
> > > >
> > > >
> > > > Hi all,
> > > >
> > > > I am seeing some bizarre behavior in the ConcurrentHashMap where one
> > > > thread constructs an objects and puts it into a the map and another
> > > > thread gets the object and sees it as null. Has any one encountered
> > > > this problem before. I believe this problem is posted sometime ago
by
> > > > Eric Zoerner to this mailing list however there is no reply.
> > > >
> > > > Any help is greatly appreciated.
> > > >
> > > > --
> > > > Regards,
> > > > BJ Low
> > >
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at altair.cs.oswego.edu
> > > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >
> > >
> > >
> >
> >
> >
> > --
> > Regards,
> > BJ Low
> >
>
>



-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080104/9eedd15e/attachment.html 

From dcholmes at optusnet.com.au  Fri Jan  4 02:27:50 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Fri, 4 Jan 2008 17:27:50 +1000
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>

BJ,

It isn't clear what the exact sequence of events is in the two threads, nor
where this locking on SS is applied.

Is it certain that Y is not null when you try to store <x, y> into the map?
(Just checking.)

Is it certain that Y is in the map before the key X is made available to
thread-2?

It's very hard to debug this via thought-experiment. :)

Cheers,
David Holmes
  -----Original Message-----
  From: BJ Low [mailto:notorand at gmail.com]
  Sent: Friday, 4 January 2008 5:22 PM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ConcurrentHashMap NullPointerException


  According to this
http://java.sun.com/j2se/1.5.0/docs/guide/vm/server-class.html, since my
server is a quad-core processsor with 4g ram, it is running in server mode
then.

  At time t1, Thread-1 will create the key X, put the value Y to CHM, and
store the key to another object Z
  At time t2, Thread-2 will then take out the key X from object Z, get the
value Y from CHM using key X, where t2 > t1

  The storing of key X to object Z is during object Z constructor method.
the retrieval of key X is a simple getter() method without any
synchronization or volatile.

  However, i notice another additional thing after inspecting the code
again, that is before Thread-1 enter the method to create the key X etc, it
is synchronized around an object SS, same thing for Thread-2. Therefore, it
cannot be the case of Java Memory Model interfering. If it is not JMM, then
what could it be that causes ConcurrentHashMap to return null?

  On Jan 4, 2008 2:46 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
  > How is the key published from Thread-1 to Thread-2?
  >
  > Java Memory Model issues tend to manifest through agressive
optimizations in
  > the VM rather than actual memory consistency problems. Are you running
the
  > server VM or client?
  >
  > Cheers,
  > David Holmes
  >
  > > -----Original Message-----
  >
  > > From: BJ Low [mailto: notorand at gmail.com]
  > > Sent: Friday, 4 January 2008 4:41 PM
  > > To: dholmes at ieee.org
  > > Cc: concurrency-interest at cs.oswego.edu
  > > Subject: Re: [concurrency-interest] ConcurrentHashMap
  > > NullPointerException
  > >
  > >
  > > Hi,
  > >
  > > What I have implemented is an NIO wrapper that is similar to Apache
  > > MINA. In this, there are multiple n threads that is handling all the m
  > > sockets reads/writes. However, it is guaranteed that only 1 thread can
  > > notify the listener of each connections IO events. For example
  > > Thread-1 notify listener onNewConnection(), and Thread-2 notify
  > > listener onRead(), however Thread-1 and Thread-2 can never notify
  > > concurrently, multithreaded underneath, but appears monothreaded
  > >
  > > Right now, I am suspecting that it might be the case that Thread-1
  > > when onNewConnection() constructs the key X and stores Y into the
  > > ConcurrentHashMap, Thread-2 fails to see the key as initialized due to
  > > Java Memory Model(even though Thread-2 executes after Thread-1),
  > > resulting in null that is passed to CHM.get() and therefore resulting
  > > in null return value
  > >
  > > On Jan 4, 2008 1:58 PM, David Holmes < dcholmes at optusnet.com.au>
wrote:
  > > > BJ,
  > > >
  > > > Can you provide further information: code sketch, exception stack
trace
  > > > details. I'm unclear whether get() is returning null
  > > unexpectedly or whether
  > > > get() is throwing the NPE. The usual source for the latter is
  > > misbehaving
  > > > equals() methods.
  > > >
  > > > Cheers,
  > > > David Holmes
  > > >
  > > >
  > > > > -----Original Message-----
  > > > > From: concurrency-interest-bounces at cs.oswego.edu
  > > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ
Low
  > > > > Sent: Friday, 4 January 2008 3:08 PM
  > > > > To: concurrency-interest at cs.oswego.edu
  > > > > Subject: [concurrency-interest] ConcurrentHashMap
NullPointerException
  > > > >
  > > > >
  > > > > Hi all,
  > > > >
  > > > > I am seeing some bizarre behavior in the ConcurrentHashMap where
one
  > > > > thread constructs an objects and puts it into a the map and
another
  > > > > thread gets the object and sees it as null. Has any one
encountered
  > > > > this problem before. I believe this problem is posted sometime ago
by
  > > > > Eric Zoerner to this mailing list however there is no reply.
  > > > >
  > > > > Any help is greatly appreciated.
  > > > >
  > > > > --
  > > > > Regards,
  > > > > BJ Low
  > > >
  > > > > _______________________________________________
  > > > > Concurrency-interest mailing list
  > > > > Concurrency-interest at altair.cs.oswego.edu
  > > > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
  > > > >
  > > >
  > > >
  > >
  > >
  > >
  > > --
  > > Regards,
  > > BJ Low
  > >
  >
  >



  --
  Regards,
  BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080104/657c2116/attachment-0001.html 

From notorand at gmail.com  Fri Jan  4 22:48:53 2008
From: notorand at gmail.com (BJ Low)
Date: Sat, 5 Jan 2008 11:48:53 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>
References: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>
Message-ID: <c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>

Hi,

I am pretty sure of below. It is very hard for me to post the code cause the
code is proprietary, but perhaps let me ask this in another way

Suppose I have a class below

class X {
     int i = 0;

     void changeVal(int i) {
        this.i = i;
     }

     int readVal() {
        return this.i;
     }
}

At time t1, Thread-X submits a Runnable to threadpool,
At time t2, Thread-1 from the threadpool runs the Runnable and call
changeVal(1);
At time t3, Thread-X submits another Runnable to threadpool
At time t4, Thread-2 from the threadpool runs the Runnable and call
readVal();

The question is, will Thread-2 see the value of i as 0 or 1? Cause I am not
quite sure of this statement from the javadoc

"Actions in a thread prior to the submission of a Runnable to an Executor *
happen-before* its execution begins. Similarly for Callables submitted to an
ExecutorService"

On Jan 4, 2008 3:27 PM, David Holmes <dcholmes at optusnet.com.au> wrote:

>  BJ,
>
> It isn't clear what the exact sequence of events is in the two threads,
> nor where this locking on SS is applied.
>
> Is it certain that Y is not null when you try to store <x, y> into the
> map? (Just checking.)
>
> Is it certain that Y is in the map before the key X is made available to
> thread-2?
>
> It's very hard to debug this via thought-experiment. :)
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* BJ Low [mailto:notorand at gmail.com]
> *Sent:* Friday, 4 January 2008 5:22 PM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> NullPointerException
>
> According to this
> http://java.sun.com/j2se/1.5.0/docs/guide/vm/server-class.html, since my
> server is a quad-core processsor with 4g ram, it is running in server mode
> then.
>
> At time t1, Thread-1 will create the key X, put the value Y to CHM, and
> store the key to another object Z
> At time t2, Thread-2 will then take out the key X from object Z, get the
> value Y from CHM using key X, where t2 > t1
>
> The storing of key X to object Z is during object Z constructor method.
> the retrieval of key X is a simple getter() method without any
> synchronization or volatile.
>
> However, i notice another additional thing after inspecting the code
> again, that is before Thread-1 enter the method to create the key X etc, it
> is synchronized around an object SS, same thing for Thread-2. Therefore, it
> cannot be the case of Java Memory Model interfering. If it is not JMM, then
> what could it be that causes ConcurrentHashMap to return null?
>
> On Jan 4, 2008 2:46 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > How is the key published from Thread-1 to Thread-2?
> >
> > Java Memory Model issues tend to manifest through agressive
> optimizations in
> > the VM rather than actual memory consistency problems. Are you running
> the
> > server VM or client?
> >
> > Cheers,
> > David Holmes
> >
> > > -----Original Message-----
> >
> > > From: BJ Low [mailto: notorand at gmail.com]
> > > Sent: Friday, 4 January 2008 4:41 PM
> > > To: dholmes at ieee.org
> > > Cc: concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] ConcurrentHashMap
> > > NullPointerException
> > >
> > >
> > > Hi,
> > >
> > > What I have implemented is an NIO wrapper that is similar to Apache
> > > MINA. In this, there are multiple n threads that is handling all the m
> > > sockets reads/writes. However, it is guaranteed that only 1 thread can
> > > notify the listener of each connections IO events. For example
> > > Thread-1 notify listener onNewConnection(), and Thread-2 notify
> > > listener onRead(), however Thread-1 and Thread-2 can never notify
> > > concurrently, multithreaded underneath, but appears monothreaded
> > >
> > > Right now, I am suspecting that it might be the case that Thread-1
> > > when onNewConnection() constructs the key X and stores Y into the
> > > ConcurrentHashMap, Thread-2 fails to see the key as initialized due to
>
> > > Java Memory Model(even though Thread-2 executes after Thread-1),
> > > resulting in null that is passed to CHM.get() and therefore resulting
> > > in null return value
> > >
> > > On Jan 4, 2008 1:58 PM, David Holmes < dcholmes at optusnet.com.au>
> wrote:
> > > > BJ,
> > > >
> > > > Can you provide further information: code sketch, exception stack
> trace
> > > > details. I'm unclear whether get() is returning null
> > > unexpectedly or whether
> > > > get() is throwing the NPE. The usual source for the latter is
> > > misbehaving
> > > > equals() methods.
> > > >
> > > > Cheers,
> > > > David Holmes
> > > >
> > > >
> > > > > -----Original Message-----
> > > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ
> Low
> > > > > Sent: Friday, 4 January 2008 3:08 PM
> > > > > To: concurrency-interest at cs.oswego.edu
> > > > > Subject: [concurrency-interest] ConcurrentHashMap
> NullPointerException
> > > > >
> > > > >
> > > > > Hi all,
> > > > >
> > > > > I am seeing some bizarre behavior in the ConcurrentHashMap where
> one
> > > > > thread constructs an objects and puts it into a the map and
> another
> > > > > thread gets the object and sees it as null. Has any one
> encountered
> > > > > this problem before. I believe this problem is posted sometime ago
> by
> > > > > Eric Zoerner to this mailing list however there is no reply.
> > > > >
> > > > > Any help is greatly appreciated.
> > > > >
> > > > > --
> > > > > Regards,
> > > > > BJ Low
> > > >
> > > > > _______________________________________________
> > > > > Concurrency-interest mailing list
> > > > > Concurrency-interest at altair.cs.oswego.edu
> > > > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > > >
> > > >
> > > >
> > >
> > >
> > >
> > > --
> > > Regards,
> > > BJ Low
> > >
> >
> >
>
>
>
> --
> Regards,
> BJ Low
>
>


-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080105/62b7efe3/attachment.html 

From tim at peierls.net  Fri Jan  4 23:36:26 2008
From: tim at peierls.net (Tim Peierls)
Date: Fri, 4 Jan 2008 23:36:26 -0500
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>
References: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>
	<c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>
Message-ID: <63b4e4050801042036q642e446ds6d77b9da44345dd4@mail.gmail.com>

Thread 2 might see either 0 or 1. Although the submission of the first
Runnable *happens-before* the call to changeVal, and the submission of the
second Runnable *happens-before* the call to readVal, you cannot conclude
that the call to changeVal *happens-before* either the submission of the
second Runnable or the call to readVal.

If the field were volatile, or if both methods of X were synchronized, then
the write to the field *would* *happen-before* the read of the field.

The javadoc snippet that you quoted implies that the write to the field
would *happen-before* the read of the field if the sequence was:

t1: in Thread-X, call changeVal(1)  -- write to field
t2: submit Runnable to thread pool from Thread-X
t3: in Thread-1 (of thread pool), Runnable.run calls readVal  -- read of
field

--tim

On Jan 4, 2008 10:48 PM, BJ Low <notorand at gmail.com> wrote:

> Hi,
>
> I am pretty sure of below. It is very hard for me to post the code cause
> the code is proprietary, but perhaps let me ask this in another way
>
> Suppose I have a class below
>
> class X {
>      int i = 0;
>
>      void changeVal(int i) {
>         this.i = i;
>      }
>
>      int readVal() {
>         return this.i;
>      }
> }
>
> At time t1, Thread-X submits a Runnable to threadpool,
> At time t2, Thread-1 from the threadpool runs the Runnable and call
> changeVal(1);
> At time t3, Thread-X submits another Runnable to threadpool
> At time t4, Thread-2 from the threadpool runs the Runnable and call
> readVal();
>
> The question is, will Thread-2 see the value of i as 0 or 1? Cause I am
> not quite sure of this statement from the javadoc
>
> "Actions in a thread prior to the submission of a Runnable to an Executor
> *happen-before* its execution begins. Similarly for Callables submitted to
> an ExecutorService"
>
>
> On Jan 4, 2008 3:27 PM, David Holmes <dcholmes at optusnet.com.au > wrote:
>
> >  BJ,
> >
> > It isn't clear what the exact sequence of events is in the two threads,
> > nor where this locking on SS is applied.
> >
> > Is it certain that Y is not null when you try to store <x, y> into the
> > map? (Just checking.)
> >
> > Is it certain that Y is in the map before the key X is made available to
> > thread-2?
> >
> > It's very hard to debug this via thought-experiment. :)
> >
> > Cheers,
> > David Holmes
> >
> > -----Original Message-----
> > *From:* BJ Low [mailto:notorand at gmail.com]
> > *Sent:* Friday, 4 January 2008 5:22 PM
> > *To:* dholmes at ieee.org
> > *Cc:* concurrency-interest at cs.oswego.edu
> > *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> > NullPointerException
> >
> > According to this
> > http://java.sun.com/j2se/1.5.0/docs/guide/vm/server-class.html, since my
> > server is a quad-core processsor with 4g ram, it is running in server mode
> > then.
> >
> > At time t1, Thread-1 will create the key X, put the value Y to CHM, and
> > store the key to another object Z
> > At time t2, Thread-2 will then take out the key X from object Z, get the
> > value Y from CHM using key X, where t2 > t1
> >
> > The storing of key X to object Z is during object Z constructor method.
> > the retrieval of key X is a simple getter() method without any
> > synchronization or volatile.
> >
> > However, i notice another additional thing after inspecting the code
> > again, that is before Thread-1 enter the method to create the key X etc, it
> > is synchronized around an object SS, same thing for Thread-2. Therefore, it
> > cannot be the case of Java Memory Model interfering. If it is not JMM, then
> > what could it be that causes ConcurrentHashMap to return null?
> >
> > On Jan 4, 2008 2:46 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > > How is the key published from Thread-1 to Thread-2?
> > >
> > > Java Memory Model issues tend to manifest through agressive
> > optimizations in
> > > the VM rather than actual memory consistency problems. Are you running
> > the
> > > server VM or client?
> > >
> > > Cheers,
> > > David Holmes
> > >
> > > > -----Original Message-----
> > >
> > > > From: BJ Low [mailto: notorand at gmail.com]
> > > > Sent: Friday, 4 January 2008 4:41 PM
> > > > To: dholmes at ieee.org
> > > > Cc: concurrency-interest at cs.oswego.edu
> > > > Subject: Re: [concurrency-interest] ConcurrentHashMap
> > > > NullPointerException
> > > >
> > > >
> > > > Hi,
> > > >
> > > > What I have implemented is an NIO wrapper that is similar to Apache
> > > > MINA. In this, there are multiple n threads that is handling all the
> > m
> > > > sockets reads/writes. However, it is guaranteed that only 1 thread
> > can
> > > > notify the listener of each connections IO events. For example
> > > > Thread-1 notify listener onNewConnection(), and Thread-2 notify
> > > > listener onRead(), however Thread-1 and Thread-2 can never notify
> > > > concurrently, multithreaded underneath, but appears monothreaded
> > > >
> > > > Right now, I am suspecting that it might be the case that Thread-1
> > > > when onNewConnection() constructs the key X and stores Y into the
> > > > ConcurrentHashMap, Thread-2 fails to see the key as initialized due
> > to
> > > > Java Memory Model(even though Thread-2 executes after Thread-1),
> > > > resulting in null that is passed to CHM.get() and therefore
> > resulting
> > > > in null return value
> > > >
> > > > On Jan 4, 2008 1:58 PM, David Holmes < dcholmes at optusnet.com.au>
> > wrote:
> > > > > BJ,
> > > > >
> > > > > Can you provide further information: code sketch, exception stack
> > trace
> > > > > details. I'm unclear whether get() is returning null
> > > > unexpectedly or whether
> > > > > get() is throwing the NPE. The usual source for the latter is
> > > > misbehaving
> > > > > equals() methods.
> > > > >
> > > > > Cheers,
> > > > > David Holmes
> > > > >
> > > > >
> > > > > > -----Original Message-----
> > > > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > BJ Low
> > > > > > Sent: Friday, 4 January 2008 3:08 PM
> > > > > > To: concurrency-interest at cs.oswego.edu
> > > > > > Subject: [concurrency-interest] ConcurrentHashMap
> > NullPointerException
> > > > > >
> > > > > >
> > > > > > Hi all,
> > > > > >
> > > > > > I am seeing some bizarre behavior in the ConcurrentHashMap where
> > one
> > > > > > thread constructs an objects and puts it into a the map and
> > another
> > > > > > thread gets the object and sees it as null. Has any one
> > encountered
> > > > > > this problem before. I believe this problem is posted sometime
> > ago by
> > > > > > Eric Zoerner to this mailing list however there is no reply.
> > > > > >
> > > > > > Any help is greatly appreciated.
> > > > > >
> > > > > > --
> > > > > > Regards,
> > > > > > BJ Low
> > > > >
> > > > > > _______________________________________________
> > > > > > Concurrency-interest mailing list
> > > > > > Concurrency-interest at altair.cs.oswego.edu
> > > > > >
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > > > >
> > > > >
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Regards,
> > > > BJ Low
> > > >
> > >
> > >
> >
> >
> >
> > --
> > Regards,
> > BJ Low
> >
> >
>
>
> --
> Regards,
> BJ Low
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080104/d30c6263/attachment-0001.html 

From Online at stolsvik.com  Sat Jan  5 06:52:48 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Sat, 05 Jan 2008 12:52:48 +0100
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>
References: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>
	<c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>
Message-ID: <477F6F90.6050605@Stolsvik.com>

BJ Low wrote:
> Hi,
> 
> I am pretty sure of below. It is very hard for me to post the code cause 
> the code is proprietary, but perhaps let me ask this in another way
> 
> Suppose I have a class below
> 
> class X {
>      int i = 0;
>     
>      void changeVal(int i) {
>         this.i = i;
>      }
> 
>      int readVal() {
>         return this.i;
>      }
> }
> 
> At time t1, Thread-X submits a Runnable to threadpool,
> At time t2, Thread-1 from the threadpool runs the Runnable and call 
> changeVal(1);
> At time t3, Thread-X submits another Runnable to threadpool
> At time t4, Thread-2 from the threadpool runs the Runnable and call 
> readVal();
> 
> The question is, will Thread-2 see the value of i as 0 or 1? 

"Thread-X" - is that supposed to be the same thread at the two times? 
Because I personally use "X" as "some".

But lets assumes that (it doesn't really matter either - this is broken 
no matter!).

There's no reason to argue complex memory situations and happens-before 
or anything like that here - this is plain as day: Thread X works on its 
own, and thus basically submits two jobs right after each other. For the 
sake of the argument: The first runnable, in Thread-1, takes 3 hours to 
complete, finally doing changeVal(1). The second Runnable runs readVal() 
about .001 ms after submit. What is the answer?

And the time labels "t[1-4]" is of no use what so ever when interleaved 
between threads that doesn't do explicit synchronization. Assuming again 
that Thread-X is the same in both instances, there is a "t, t+x" 
situation between the two submits (the first submit /happens-before/ the 
second submit, by way of code order).
   However, one cannot argue anything about Thread-1 (other than that it 
happens AFTER the submit of itself, which is at "t"), and Thread-2 
(other than that is happens AFTER the submit of itself, which is at "t+x").
   The order of _when_ those two runnables are run on their respective 
worker threads, is fully non-deterministic: both the work they do (the 
time it takes), the inner workings of the thread pool (e.g. whether a 
new Thread has to be made for one of the submissions, perhaps the first, 
not the second) - and finally, the operating system: it might decide 
based on some cosmic reasons, that Thread-1 shouldn't run, or is 
pre-empted before the changeVal() while a whole bunch of other threads 
gets time slices, while Thread-2 by the same unfair magic gets scheduled 
right away.

These are really basic multi-threading issues, not having anything to do 
with complex code-reorderings or anything like that.

What you want here, is synchronized code in class X, and some flag that 
denotes whether the job is done. The flag is set to true when 
"changeVal()" is run, and then the /this X/ is .notify()ed (within 
synchronized on /this X/, of course). The readVal() method checks 
(within synchronzied on /this X/, of course) whether the flag is true. 
If it isn't it goes into .wait() on /this X/, looping until flag is true 
(must loop due to "spurious wakeups"). Hey presto.. Also check out 
Callable vs. Future - it does just this.

Endre.

From notorand at gmail.com  Sat Jan  5 09:14:38 2008
From: notorand at gmail.com (BJ Low)
Date: Sat, 5 Jan 2008 22:14:38 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <477F6F90.6050605@Stolsvik.com>
References: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>
	<c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>
	<477F6F90.6050605@Stolsvik.com>
Message-ID: <c1dcd6d20801050614g6128cc20x373aac218e3fd000@mail.gmail.com>

I think perhaps I never explain myself properly, Tim Peierls however did
understood what i am trying to say.

At time t1, Thread-X submits a Runnable to threadpool,
At time t2, Thread-1 from the threadpool runs the Runnable and call
changeVal(1);

AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....

At time t3, Thread-X submits another Runnable to threadpool
At time t4, Thread-2 from the threadpool runs the Runnable and call
readVal();

.... i missed out the red statement above. I think in above case, the
happens-before property is very important, cause if at t3, it is Thread-1,
but not Thread-X that submits the Runnable, then there will not be any
memory consistency errors.

On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:

> BJ Low wrote:
> > Hi,
> >
> > I am pretty sure of below. It is very hard for me to post the code cause
> > the code is proprietary, but perhaps let me ask this in another way
> >
> > Suppose I have a class below
> >
> > class X {
> >      int i = 0;
> >
> >      void changeVal(int i) {
> >         this.i = i;
> >      }
> >
> >      int readVal() {
> >         return this.i;
> >      }
> > }
> >
> > At time t1, Thread-X submits a Runnable to threadpool,
> > At time t2, Thread-1 from the threadpool runs the Runnable and call
> > changeVal(1);
> > At time t3, Thread-X submits another Runnable to threadpool
> > At time t4, Thread-2 from the threadpool runs the Runnable and call
> > readVal();
> >
> > The question is, will Thread-2 see the value of i as 0 or 1?
>
> "Thread-X" - is that supposed to be the same thread at the two times?
> Because I personally use "X" as "some".
>
> But lets assumes that (it doesn't really matter either - this is broken
> no matter!).
>
> There's no reason to argue complex memory situations and happens-before
> or anything like that here - this is plain as day: Thread X works on its
> own, and thus basically submits two jobs right after each other. For the
> sake of the argument: The first runnable, in Thread-1, takes 3 hours to
> complete, finally doing changeVal(1). The second Runnable runs readVal()
> about .001 ms after submit. What is the answer?
>
> And the time labels "t[1-4]" is of no use what so ever when interleaved
> between threads that doesn't do explicit synchronization. Assuming again
> that Thread-X is the same in both instances, there is a "t, t+x"
> situation between the two submits (the first submit /happens-before/ the
> second submit, by way of code order).
>   However, one cannot argue anything about Thread-1 (other than that it
> happens AFTER the submit of itself, which is at "t"), and Thread-2
> (other than that is happens AFTER the submit of itself, which is at
> "t+x").
>   The order of _when_ those two runnables are run on their respective
> worker threads, is fully non-deterministic: both the work they do (the
> time it takes), the inner workings of the thread pool (e.g. whether a
> new Thread has to be made for one of the submissions, perhaps the first,
> not the second) - and finally, the operating system: it might decide
> based on some cosmic reasons, that Thread-1 shouldn't run, or is
> pre-empted before the changeVal() while a whole bunch of other threads
> gets time slices, while Thread-2 by the same unfair magic gets scheduled
> right away.
>
> These are really basic multi-threading issues, not having anything to do
> with complex code-reorderings or anything like that.
>
> What you want here, is synchronized code in class X, and some flag that
> denotes whether the job is done. The flag is set to true when
> "changeVal()" is run, and then the /this X/ is .notify()ed (within
> synchronized on /this X/, of course). The readVal() method checks
> (within synchronzied on /this X/, of course) whether the flag is true.
> If it isn't it goes into .wait() on /this X/, looping until flag is true
> (must loop due to "spurious wakeups"). Hey presto.. Also check out
> Callable vs. Future - it does just this.
>
> Endre.
>



-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080105/8601bcc9/attachment.html 

From Online at stolsvik.com  Sat Jan  5 11:14:44 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Sat, 05 Jan 2008 17:14:44 +0100
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801050614g6128cc20x373aac218e3fd000@mail.gmail.com>
References: <c1dcd6d20801032322p22e60c8bvdb2c60fabbea2c2@mail.gmail.com>	
	<NFBBKALFDCPFIDBNKAPCGEPKHJAA.dcholmes@optusnet.com.au>	
	<c1dcd6d20801041948m5d905f1crc4f1c8e3184a97ab@mail.gmail.com>	
	<477F6F90.6050605@Stolsvik.com>
	<c1dcd6d20801050614g6128cc20x373aac218e3fd000@mail.gmail.com>
Message-ID: <477FACF4.7060204@Stolsvik.com>

BJ Low wrote:

> 
> At time t1, Thread-X submits a Runnable to threadpool,
> At time t2, Thread-1 from the threadpool runs the Runnable and call 
> changeVal(1);
> 
> AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....
> 
> At time t3, Thread-X submits another Runnable to threadpool
> At time t4, Thread-2 from the threadpool runs the Runnable and call 
> readVal();
> 
> .... i missed out the red statement above.

Pretty vital little piece, don't you think?

> I think in above case, the 
> happens-before property is very important, cause if at t3, it is 
> Thread-1, but not Thread-X that submits the Runnable, then there will 
> not be any memory consistency errors.

How do you KNOW that the "red statement" has happened? That is, that the 
changeVal(1) from Thread-1 is completed??

Because I can't quite see how that information is transmitted _without_ 
a happens-before edge being established at the same time - thereby 
ensuring that Thread-2 will see the 1.

Endre.

From dcholmes at optusnet.com.au  Sun Jan  6 17:32:00 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 7 Jan 2008 08:32:00 +1000
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801050614g6128cc20x373aac218e3fd000@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEPNHJAA.dcholmes@optusnet.com.au>

BJ,

I'm still missing two key parts to this:

1. As Endre asked, how do you know that Thread-1 has completed its action

2. How is the instance of X accessed from two different Runnables

Also, returning to the original issue, the use of the ConcurrentHashMap is
significant here as well, as it also introduces happens-before
relationships.

So I still need more detail on the code to commemnt further.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low
  Sent: Sunday, 6 January 2008 12:15 AM
  To: Endre St?lsvik
  Cc: concurrency-interest at cs.oswego.edu; dholmes at ieee.org
  Subject: Re: [concurrency-interest] ConcurrentHashMap NullPointerException


  I think perhaps I never explain myself properly, Tim Peierls however did
understood what i am trying to say.

  At time t1, Thread-X submits a Runnable to threadpool,
  At time t2, Thread-1 from the threadpool runs the Runnable and call
changeVal(1);

  AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....

  At time t3, Thread-X submits another Runnable to threadpool
  At time t4, Thread-2 from the threadpool runs the Runnable and call
readVal();

  .... i missed out the red statement above. I think in above case, the
happens-before property is very important, cause if at t3, it is Thread-1,
but not Thread-X that submits the Runnable, then there will not be any
memory consistency errors.


  On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:

    BJ Low wrote:
    > Hi,
    >
    > I am pretty sure of below. It is very hard for me to post the code
cause
    > the code is proprietary, but perhaps let me ask this in another way
    >
    > Suppose I have a class below
    >
    > class X {
    >      int i = 0;
    >
    >      void changeVal(int i) {
    >         this.i = i;
    >      }
    >
    >      int readVal() {
    >         return this.i;
    >      }
    > }
    >
    > At time t1, Thread-X submits a Runnable to threadpool,
    > At time t2, Thread-1 from the threadpool runs the Runnable and call
    > changeVal(1);
    > At time t3, Thread-X submits another Runnable to threadpool
    > At time t4, Thread-2 from the threadpool runs the Runnable and call
    > readVal();
    >
    > The question is, will Thread-2 see the value of i as 0 or 1?


    "Thread-X" - is that supposed to be the same thread at the two times?
    Because I personally use "X" as "some".

    But lets assumes that (it doesn't really matter either - this is broken
    no matter!).

    There's no reason to argue complex memory situations and happens-before
    or anything like that here - this is plain as day: Thread X works on its
    own, and thus basically submits two jobs right after each other. For the
    sake of the argument: The first runnable, in Thread-1, takes 3 hours to
    complete, finally doing changeVal(1). The second Runnable runs readVal()
    about .001 ms after submit. What is the answer?

    And the time labels "t[1-4]" is of no use what so ever when interleaved
    between threads that doesn't do explicit synchronization. Assuming again
    that Thread-X is the same in both instances, there is a "t, t+x"
    situation between the two submits (the first submit /happens-before/ the
    second submit, by way of code order).
      However, one cannot argue anything about Thread-1 (other than that it
    happens AFTER the submit of itself, which is at "t"), and Thread-2
    (other than that is happens AFTER the submit of itself, which is at
"t+x").
      The order of _when_ those two runnables are run on their respective
    worker threads, is fully non-deterministic: both the work they do (the
    time it takes), the inner workings of the thread pool (e.g. whether a
    new Thread has to be made for one of the submissions, perhaps the first,
    not the second) - and finally, the operating system: it might decide
    based on some cosmic reasons, that Thread-1 shouldn't run, or is
    pre-empted before the changeVal() while a whole bunch of other threads
    gets time slices, while Thread-2 by the same unfair magic gets scheduled
    right away.

    These are really basic multi-threading issues, not having anything to do
    with complex code-reorderings or anything like that.

    What you want here, is synchronized code in class X, and some flag that
    denotes whether the job is done. The flag is set to true when
    "changeVal()" is run, and then the /this X/ is .notify()ed (within
    synchronized on /this X/, of course). The readVal() method checks
    (within synchronzied on /this X/, of course) whether the flag is true.
    If it isn't it goes into .wait() on /this X/, looping until flag is true
    (must loop due to "spurious wakeups"). Hey presto.. Also check out
    Callable vs. Future - it does just this.

    Endre.




  --
  Regards,
  BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/f222b943/attachment.html 

From notorand at gmail.com  Sun Jan  6 20:19:59 2008
From: notorand at gmail.com (BJ Low)
Date: Mon, 7 Jan 2008 09:19:59 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEPNHJAA.dcholmes@optusnet.com.au>
References: <c1dcd6d20801050614g6128cc20x373aac218e3fd000@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEPNHJAA.dcholmes@optusnet.com.au>
Message-ID: <c1dcd6d20801061719s4fd0263bwc7e04938a38eb393@mail.gmail.com>

On Jan 7, 2008 6:32 AM, David Holmes <dcholmes at optusnet.com.au> wrote:

>  BJ,
>
> I'm still missing two key parts to this:
>
> 1. As Endre asked, how do you know that Thread-1 has completed its action
>

class Upstream implements Runnable {

        private Logger logger = Logger.getLogger(Conn.Upstream.class);

        private ReentrantLock lockBuffer = new ReentrantLock();
        private ArrayDeque<EventIO> buffer = new ArrayDeque<EventIO>();

        private boolean streamInProc = false;
        private boolean eof = false;

        private Upstream() {
        }

        private void add(EventIO eventIO) {
            try {
                // prevent case where Event exist in buffer, but not
submitted to threadpool
                // - Thread_1, + IOHandlerThreadPool
                //
                // + run()
                // + if (this.buffer.size() != 0) test false
                // - add(EventIO eventIO)
                // - this.buffer.add(eventIO)
                // - if (!this.streamInProc) test false
                // + this.streamInProc = false
                // event in buffer but not submitted
                //
                // prevent concurrent access to buffer as ArrayDeque is not
thread-safe
                // - Thread_1, + IOHandlerThreadPool
                //
                // - add(EventIO eventIO)
                // - this.buffer.add(eventIO)
                // + run()
                // + eventIO = this.buffer.poll()
                this.lockBuffer.lock();

                // to prevent out-of-memory by not adding, within lockBuffer
to prevent memory consistency errors
                if (!this.eof) {

                    this.buffer.add(eventIO);

                    if (!this.streamInProc) {
                        Conn.this.ioHandlerThreadPool.submit(this);
                        this.streamInProc = true;
                    }

                    // CLOSE, CONNECT_FAIL will be the last event to be
processed, therefore any further add to the back add()/front close() of the
buffer is
                    // redundant
                    if ((eventIO == EventIO.CLOSE) || (eventIO ==
EventIO.CONNECT_FAIL)) {
                        this.eof = true;
                    }
                }
            }
            finally {
                this.lockBuffer.unlock();
            }
        }

        @Override
        public void run() {
            try {
                int granularity = 0;

                // stop delivery when granularity is reached, or no more
EventIO left in buffer to deliver
                boolean endLoop = false;
                boolean closed = false;
                while (!endLoop && !closed) {

                    EventIO eventIO = null;
                    try {
                        // prevent concurrent access to buffer as ArrayDeque
is not thread-safe
                        // - Thread_1, + IOHandlerThreadPool
                        //
                        // - add(EventIO eventIO)
                        // - this.buffer.add(eventIO)
                        // + run()
                        // + eventIO = this.buffer.poll()
                        this.lockBuffer.lock();

                        // remove an Object from buffer
                        eventIO = this.buffer.poll();
                    }
                    finally {
                        this.lockBuffer.unlock();
                    }

                    if (eventIO == null) {
                        endLoop = true;
                    }
                    else {
                        // prevent memory consistency errors whereby values
written by current thread from IOHandlerThreadPool is not flushed, causing
the next
                        // run() reading stale values if it is a different
thread from this current thread
                        synchronized (this) {

                            // delivery
                            if (eventIO == EventIO.OPEN) {
                                Conn.this.handleOpen();
                            }
                            else if (eventIO == EventIO.READ) {
                                Conn.this.handleRead();
                            }
                            else if ((eventIO == EventIO.IDLE_READ) ||
(eventIO == EventIO.IDLE_WRITE)) {
                                Conn.this.handleIdle(eventIO);
                            }
                            else if (eventIO == EventIO.CLOSE) {
                                Conn.this.handleClose();
                                closed = true;
                            }
                            else if (eventIO == EventIO.CONNECT_FAIL) {
                                Conn.this.handleConnectFail();
                                closed = true;
                            }
                        }

                        // update granularity
                        granularity++;
                        if (granularity == 10) {
                            endLoop = true;
                        }
                    }
                }

                // if EventIO.CLOSE is reached, then permanently
streamInProc stays true, ensuring no more EventIO will be delivered
                if (!closed) {
                    try {
                        // prevent case where Event exist in buffer, but not
submitted to threadpool
                        // - Thread_1, + IOHandlerThreadPool
                        //
                        // + run()
                        // + if (this.buffer.size() != 0) test false
                        // - add(EventIO eventIO)
                        // - this.buffer.add(eventIO)
                        // - if (!this.streamInProc) test false
                        // + this.streamInProc = false
                        // event in buffer but not submitted
                        this.lockBuffer.lock();

                        if (this.buffer.size() != 0) {
                            Conn.this.ioHandlerThreadPool.submit(this);
                        }
                        else {
                            this.streamInProc = false;
                        }
                    }
                    finally {
                        this.lockBuffer.unlock();
                    }
                }
            }
            catch (Throwable e) {
                // log FATAL, critical thread dies, node unable to function
                LoggerProxy.fatal(this.logger, "SYSTEM", "Died of unchecked
exception, node terminating", e);
                // fatal, terminate the program
                System.exit(1);
            }
        }
    }

As you can see above, EventIO is deposited into the buffer, and a thread
from threadpool is awakened to process the event, however it is only
possible for only 1 thread at any instance to do the run() method by using
the streamInProc boolean. Therefore there will only be 1 single thread
processing Upstream in any single instance


> 2. How is the instance of X accessed from two different Runnables
>
> Also, returning to the original issue, the use of the ConcurrentHashMap is
> significant here as well, as it also introduces happens-before
> relationships.
>
>
The thing is that during event delivery, thread-1 from threadpool might be
doing the run() method, and the next time round, thread-2 from threadpool
might be doing the run() method also. ConcurrentHashMap is accessed during
event delivery methods like Conn.this.handleOpen(), Conn.this.handleRead()
etc. There is this time when CHM is accessed, it returns null, when in fact
the element is put into the CHM already. It is a very rare occurrance. I
have run rigourous tests on the code day and night and it never happens,
there is only once when i am doing simple testing (under very insignifcant
load) that it occurs. I am not very sure if it is fixed, but it seems that
someone else has also encountered the same kind of bug
http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html


> So I still need more detail on the code to commemnt further.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *BJ Low
> *Sent:* Sunday, 6 January 2008 12:15 AM
> *To:* Endre St?lsvik
> *Cc:* concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> NullPointerException
>
> I think perhaps I never explain myself properly, Tim Peierls however did
> understood what i am trying to say.
>
> At time t1, Thread-X submits a Runnable to threadpool,
> At time t2, Thread-1 from the threadpool runs the Runnable and call
> changeVal(1);
>
> AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....
>
> At time t3, Thread-X submits another Runnable to threadpool
> At time t4, Thread-2 from the threadpool runs the Runnable and call
> readVal();
>
> .... i missed out the red statement above. I think in above case, the
> happens-before property is very important, cause if at t3, it is Thread-1,
> but not Thread-X that submits the Runnable, then there will not be any
> memory consistency errors.
>
> On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:
>
> > BJ Low wrote:
> > > Hi,
> > >
> > > I am pretty sure of below. It is very hard for me to post the code
> > cause
> > > the code is proprietary, but perhaps let me ask this in another way
> > >
> > > Suppose I have a class below
> > >
> > > class X {
> > >      int i = 0;
> > >
> > >      void changeVal(int i) {
> > >         this.i = i;
> > >      }
> > >
> > >      int readVal() {
> > >         return this.i;
> > >      }
> > > }
> > >
> > > At time t1, Thread-X submits a Runnable to threadpool,
> > > At time t2, Thread-1 from the threadpool runs the Runnable and call
> > > changeVal(1);
> > > At time t3, Thread-X submits another Runnable to threadpool
> > > At time t4, Thread-2 from the threadpool runs the Runnable and call
> > > readVal();
> > >
> > > The question is, will Thread-2 see the value of i as 0 or 1?
> >
> > "Thread-X" - is that supposed to be the same thread at the two times?
> > Because I personally use "X" as "some".
> >
> > But lets assumes that (it doesn't really matter either - this is broken
> > no matter!).
> >
> > There's no reason to argue complex memory situations and happens-before
> > or anything like that here - this is plain as day: Thread X works on its
> > own, and thus basically submits two jobs right after each other. For the
> > sake of the argument: The first runnable, in Thread-1, takes 3 hours to
> > complete, finally doing changeVal(1). The second Runnable runs readVal()
> > about .001 ms after submit. What is the answer?
> >
> > And the time labels "t[1-4]" is of no use what so ever when interleaved
> > between threads that doesn't do explicit synchronization. Assuming again
> >
> > that Thread-X is the same in both instances, there is a "t, t+x"
> > situation between the two submits (the first submit /happens-before/ the
> > second submit, by way of code order).
> >   However, one cannot argue anything about Thread-1 (other than that it
> > happens AFTER the submit of itself, which is at "t"), and Thread-2
> > (other than that is happens AFTER the submit of itself, which is at
> > "t+x").
> >   The order of _when_ those two runnables are run on their respective
> > worker threads, is fully non-deterministic: both the work they do (the
> > time it takes), the inner workings of the thread pool (e.g. whether a
> > new Thread has to be made for one of the submissions, perhaps the first,
> >
> > not the second) - and finally, the operating system: it might decide
> > based on some cosmic reasons, that Thread-1 shouldn't run, or is
> > pre-empted before the changeVal() while a whole bunch of other threads
> > gets time slices, while Thread-2 by the same unfair magic gets scheduled
> > right away.
> >
> > These are really basic multi-threading issues, not having anything to do
> > with complex code-reorderings or anything like that.
> >
> > What you want here, is synchronized code in class X, and some flag that
> > denotes whether the job is done. The flag is set to true when
> > "changeVal()" is run, and then the /this X/ is .notify()ed (within
> > synchronized on /this X/, of course). The readVal() method checks
> > (within synchronzied on /this X/, of course) whether the flag is true.
> > If it isn't it goes into .wait() on /this X/, looping until flag is true
> >
> > (must loop due to "spurious wakeups"). Hey presto.. Also check out
> > Callable vs. Future - it does just this.
> >
> > Endre.
> >
>
>
>
> --
> Regards,
> BJ Low
>
>


-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/79aa3aa7/attachment-0001.html 

From dcholmes at optusnet.com.au  Sun Jan  6 21:05:03 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 7 Jan 2008 12:05:03 +1000
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801061719s4fd0263bwc7e04938a38eb393@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEPOHJAA.dcholmes@optusnet.com.au>

BJ,

The original problem involved the construction and publication of the key
object X. I still can not see where/how this key object is created and
published.

> It is a very rare occurrance. I have run rigourous tests on the code day
and
> night and it never happens, there is only once when i am doing simple
testing
> (under very insignifcant load) that it occurs.

That is the opposite of what you would expect with a JMM issue. It is more
what you would expect with a "simple" race condition.

> I am not very sure if it is fixed, but it seems that someone else has also
> encountered the same kind of bug
http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html

Unfortunately after having been told that CHM does establish some JMM
happens-before relationships, the original reporter didn't take this any
further, so we have no way to know what actually happened in his case.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low
  Sent: Monday, 7 January 2008 11:20 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ConcurrentHashMap NullPointerException





  On Jan 7, 2008 6:32 AM, David Holmes <dcholmes at optusnet.com.au> wrote:

    BJ,

    I'm still missing two key parts to this:

    1. As Endre asked, how do you know that Thread-1 has completed its
action

  class Upstream implements Runnable {

          private Logger logger = Logger.getLogger(Conn.Upstream.class);

          private ReentrantLock lockBuffer = new ReentrantLock();
          private ArrayDeque<EventIO> buffer = new ArrayDeque<EventIO>();

          private boolean streamInProc = false;
          private boolean eof = false;

          private Upstream() {
          }

          private void add(EventIO eventIO) {
              try {
                  // prevent case where Event exist in buffer, but not
submitted to threadpool
                  // - Thread_1, + IOHandlerThreadPool
                  //
                  // + run()
                  // + if (this.buffer.size() != 0) test false
                  // - add(EventIO eventIO)
                  // - this.buffer.add(eventIO)
                  // - if (!this.streamInProc) test false
                  // + this.streamInProc = false
                  // event in buffer but not submitted
                  //
                  // prevent concurrent access to buffer as ArrayDeque is
not thread-safe
                  // - Thread_1, + IOHandlerThreadPool
                  //
                  // - add(EventIO eventIO)
                  // - this.buffer.add(eventIO)
                  // + run()
                  // + eventIO = this.buffer.poll()
                  this.lockBuffer.lock();

                  // to prevent out-of-memory by not adding, within
lockBuffer to prevent memory consistency errors
                  if (!this.eof) {

                      this.buffer.add(eventIO);

                      if (!this.streamInProc) {
                          Conn.this.ioHandlerThreadPool.submit(this);
                          this.streamInProc = true;
                      }

                      // CLOSE, CONNECT_FAIL will be the last event to be
processed, therefore any further add to the back add()/front close() of the
buffer is
                      // redundant
                      if ((eventIO == EventIO.CLOSE) || (eventIO ==
EventIO.CONNECT_FAIL)) {
                          this.eof = true;
                      }
                  }
              }
              finally {
                  this.lockBuffer.unlock();
              }
          }

          @Override
          public void run() {
              try {
                  int granularity = 0;

                  // stop delivery when granularity is reached, or no more
EventIO left in buffer to deliver
                  boolean endLoop = false;
                  boolean closed = false;
                  while (!endLoop && !closed) {

                      EventIO eventIO = null;
                      try {
                          // prevent concurrent access to buffer as
ArrayDeque is not thread-safe
                          // - Thread_1, + IOHandlerThreadPool
                          //
                          // - add(EventIO eventIO)
                          // - this.buffer.add(eventIO)
                          // + run()
                          // + eventIO = this.buffer.poll()
                          this.lockBuffer.lock();

                          // remove an Object from buffer
                          eventIO = this.buffer.poll();
                      }
                      finally {
                          this.lockBuffer.unlock();
                      }

                      if (eventIO == null) {
                          endLoop = true;
                      }
                      else {
                          // prevent memory consistency errors whereby
values written by current thread from IOHandlerThreadPool is not flushed,
causing the next
                          // run() reading stale values if it is a different
thread from this current thread
                          synchronized (this) {

                              // delivery
                              if (eventIO == EventIO.OPEN) {
                                  Conn.this.handleOpen();
                              }
                              else if (eventIO == EventIO.READ) {
                                  Conn.this.handleRead ();
                              }
                              else if ((eventIO == EventIO.IDLE_READ) ||
(eventIO == EventIO.IDLE_WRITE)) {
                                  Conn.this.handleIdle(eventIO);
                              }
                              else if (eventIO == EventIO.CLOSE) {
                                  Conn.this.handleClose();
                                  closed = true;
                              }
                              else if (eventIO == EventIO.CONNECT_FAIL) {
                                  Conn.this.handleConnectFail();
                                  closed = true;
                              }
                          }

                          // update granularity
                          granularity++;
                          if (granularity == 10) {
                              endLoop = true;
                          }
                      }
                  }

                  // if EventIO.CLOSE is reached, then permanently
streamInProc stays true, ensuring no more EventIO will be delivered
                  if (!closed) {
                      try {
                          // prevent case where Event exist in buffer, but
not submitted to threadpool
                          // - Thread_1, + IOHandlerThreadPool
                          //
                          // + run()
                          // + if (this.buffer.size() != 0) test false
                          // - add(EventIO eventIO)
                          // - this.buffer.add(eventIO)
                          // - if (!this.streamInProc) test false
                          // + this.streamInProc = false
                          // event in buffer but not submitted
                          this.lockBuffer.lock();

                          if (this.buffer.size() != 0) {
                              Conn.this.ioHandlerThreadPool.submit(this);
                          }
                          else {
                              this.streamInProc = false;
                          }
                      }
                      finally {
                          this.lockBuffer.unlock ();
                      }
                  }
              }
              catch (Throwable e) {
                  // log FATAL, critical thread dies, node unable to
function
                  LoggerProxy.fatal(this.logger , "SYSTEM", "Died of
unchecked exception, node terminating", e);
                  // fatal, terminate the program
                  System.exit(1);
              }
          }
      }

  As you can see above, EventIO is deposited into the buffer, and a thread
from threadpool is awakened to process the event, however it is only
possible for only 1 thread at any instance to do the run() method by using
the streamInProc boolean. Therefore there will only be 1 single thread
processing Upstream in any single instance



    2. How is the instance of X accessed from two different Runnables

    Also, returning to the original issue, the use of the ConcurrentHashMap
is significant here as well, as it also introduces happens-before
relationships.

  The thing is that during event delivery, thread-1 from threadpool might be
doing the run() method, and the next time round, thread-2 from threadpool
might be doing the run() method also. ConcurrentHashMap is accessed during
event delivery methods like Conn.this.handleOpen(), Conn.this.handleRead()
etc. There is this time when CHM is accessed, it returns null, when in fact
the element is put into the CHM already. It is a very rare occurrance. I
have run rigourous tests on the code day and night and it never happens,
there is only once when i am doing simple testing (under very insignifcant
load) that it occurs. I am not very sure if it is fixed, but it seems that
someone else has also encountered the same kind of bug
http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html

    So I still need more detail on the code to commemnt further.

    Cheers,
    David Holmes
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of BJ Low

      Sent: Sunday, 6 January 2008 12:15 AM
      To: Endre St?lsvik
      Cc: concurrency-interest at cs.oswego.edu; dholmes at ieee.org
      Subject: Re: [concurrency-interest] ConcurrentHashMap
NullPointerException


      I think perhaps I never explain myself properly, Tim Peierls however
did understood what i am trying to say.

      At time t1, Thread-X submits a Runnable to threadpool,
      At time t2, Thread-1 from the threadpool runs the Runnable and call
changeVal(1);

      AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....

      At time t3, Thread-X submits another Runnable to threadpool
      At time t4, Thread-2 from the threadpool runs the Runnable and call
readVal();

      .... i missed out the red statement above. I think in above case, the
happens-before property is very important, cause if at t3, it is Thread-1,
but not Thread-X that submits the Runnable, then there will not be any
memory consistency errors.


      On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:

        BJ Low wrote:
        > Hi,
        >
        > I am pretty sure of below. It is very hard for me to post the code
cause
        > the code is proprietary, but perhaps let me ask this in another
way
        >
        > Suppose I have a class below
        >
        > class X {
        >      int i = 0;
        >
        >      void changeVal(int i) {
        >         this.i = i;
        >      }
        >
        >      int readVal() {
        >         return this.i;
        >      }
        > }
        >
        > At time t1, Thread-X submits a Runnable to threadpool,
        > At time t2, Thread-1 from the threadpool runs the Runnable and
call
        > changeVal(1);
        > At time t3, Thread-X submits another Runnable to threadpool
        > At time t4, Thread-2 from the threadpool runs the Runnable and
call
        > readVal();
        >
        > The question is, will Thread-2 see the value of i as 0 or 1?


        "Thread-X" - is that supposed to be the same thread at the two
times?
        Because I personally use "X" as "some".

        But lets assumes that (it doesn't really matter either - this is
broken
        no matter!).

        There's no reason to argue complex memory situations and
happens-before
        or anything like that here - this is plain as day: Thread X works on
its
        own, and thus basically submits two jobs right after each other. For
the
        sake of the argument: The first runnable, in Thread-1, takes 3 hours
to
        complete, finally doing changeVal(1). The second Runnable runs
readVal()
        about .001 ms after submit. What is the answer?

        And the time labels "t[1-4]" is of no use what so ever when
interleaved
        between threads that doesn't do explicit synchronization. Assuming
again
        that Thread-X is the same in both instances, there is a "t, t+x"
        situation between the two submits (the first submit /happens-before/
the
        second submit, by way of code order).
          However, one cannot argue anything about Thread-1 (other than that
it
        happens AFTER the submit of itself, which is at "t"), and Thread-2
        (other than that is happens AFTER the submit of itself, which is at
"t+x").
          The order of _when_ those two runnables are run on their
respective
        worker threads, is fully non-deterministic: both the work they do
(the
        time it takes), the inner workings of the thread pool (e.g. whether
a
        new Thread has to be made for one of the submissions, perhaps the
first,
        not the second) - and finally, the operating system: it might decide
        based on some cosmic reasons, that Thread-1 shouldn't run, or is
        pre-empted before the changeVal() while a whole bunch of other
threads
        gets time slices, while Thread-2 by the same unfair magic gets
scheduled
        right away.

        These are really basic multi-threading issues, not having anything
to do
        with complex code-reorderings or anything like that.

        What you want here, is synchronized code in class X, and some flag
that
        denotes whether the job is done. The flag is set to true when
        "changeVal()" is run, and then the /this X/ is .notify()ed (within
        synchronized on /this X/, of course). The readVal() method checks
        (within synchronzied on /this X/, of course) whether the flag is
true.
        If it isn't it goes into .wait() on /this X/, looping until flag is
true
        (must loop due to "spurious wakeups"). Hey presto.. Also check out
        Callable vs. Future - it does just this.

        Endre.




      --
      Regards,
      BJ Low



  --
  Regards,
  BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/d3168a7f/attachment-0001.html 

From notorand at gmail.com  Sun Jan  6 21:24:16 2008
From: notorand at gmail.com (BJ Low)
Date: Mon, 7 Jan 2008 10:24:16 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEPOHJAA.dcholmes@optusnet.com.au>
References: <c1dcd6d20801061719s4fd0263bwc7e04938a38eb393@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEPOHJAA.dcholmes@optusnet.com.au>
Message-ID: <c1dcd6d20801061824u69b71568k58be556ff05e7f91@mail.gmail.com>

On Jan 7, 2008 10:05 AM, David Holmes <dcholmes at optusnet.com.au> wrote:

>  BJ,
>
> The original problem involved the construction and publication of the key
> object X. I still can not see where/how this key object is created and
> published.
>

The key is created in the listener during onOpen()

    public void onOpen(Upstream upstream) {

        // create new Member1 and store to Upstream-Member1 mapping
        this.mapOfMembers.put(upstream, new Member1());
    }

and removed during

    public void onClose(Upstream upstream) {

        // remove the Upstream-Member1 mapping
        Member1 member1 = this.mapOfMembers.remove(upstream);
    }

however during accessing it during

    public void onRead(Upstream upstream) {

        // get the Upstream-Member1 mapping
        Member1 member1 = this.mapOfMembers.get(upstream);
         .....
         .....
    }

it returns null instead, and it is ensured that ordering onOpen -> onRead()
-> .... -> onRead() -> onClose()
In fact, it is not important how the key is published cause everytime i do
an event delivery i will synchronized(this) to ensure that any values that
is created will be a write-through cache.

> It is a very rare occurrance. I have run rigourous tests on the code day
> and
> > night and it never happens, there is only once when i am doing simple
> testing
> > (under very insignifcant load) that it occurs.
>
> That is the opposite of what you would expect with a JMM issue. It is more
> what you would expect with a "simple" race condition.
>

I think JMM issues are harder to arise. Frequently I have not declared a
boolean variable to to be volatile, and memory consistency issues do not
arise at all. Well i have not done this kind of tests under the server mode
jvm but in client mode, this kind of memory consistency issues seldom occur.
In fact, race condition deadlocks and such is easier to detect when the code
is put under rigorous day and night load tests


> > I am not very sure if it is fixed, but it seems that someone else has
> also
> > encountered the same kind of bug
> http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html
> Unfortunately after having been told that CHM does establish some JMM
> happens-before relationships, the original reporter didn't take this any
> further, so we have no way to know what actually happened in his case.
>
>

Unfortunately there is no contact for this reporter, but I think it is very
hard to reproduce the same error again


> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *BJ Low
> *Sent:* Monday, 7 January 2008 11:20 AM
> *To:* dholmes at ieee.org
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> NullPointerException
>
>
>
> On Jan 7, 2008 6:32 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> >  BJ,
> >
> > I'm still missing two key parts to this:
> >
> > 1. As Endre asked, how do you know that Thread-1 has completed its
> > action
> >
>
> class Upstream implements Runnable {
>
>         private Logger logger = Logger.getLogger(Conn.Upstream.class);
>
>         private ReentrantLock lockBuffer = new ReentrantLock();
>         private ArrayDeque<EventIO> buffer = new ArrayDeque<EventIO>();
>
>         private boolean streamInProc = false;
>         private boolean eof = false;
>
>         private Upstream() {
>         }
>
>         private void add(EventIO eventIO) {
>             try {
>                 // prevent case where Event exist in buffer, but not
> submitted to threadpool
>                 // - Thread_1, + IOHandlerThreadPool
>                 //
>                 // + run()
>                 // + if (this.buffer.size() != 0) test false
>                 // - add(EventIO eventIO)
>                 // - this.buffer.add(eventIO)
>                 // - if (!this.streamInProc) test false
>                 // + this.streamInProc = false
>                 // event in buffer but not submitted
>                 //
>                 // prevent concurrent access to buffer as ArrayDeque is
> not thread-safe
>                 // - Thread_1, + IOHandlerThreadPool
>                 //
>                 // - add(EventIO eventIO)
>                 // - this.buffer.add(eventIO)
>                 // + run()
>                 // + eventIO = this.buffer.poll()
>                 this.lockBuffer.lock();
>
>                 // to prevent out-of-memory by not adding, within
> lockBuffer to prevent memory consistency errors
>                 if (!this.eof) {
>
>                     this.buffer.add(eventIO);
>
>                     if (!this.streamInProc) {
>                         Conn.this.ioHandlerThreadPool.submit(this);
>                         this.streamInProc = true;
>                     }
>
>                     // CLOSE, CONNECT_FAIL will be the last event to be
> processed, therefore any further add to the back add()/front close() of the
> buffer is
>                     // redundant
>                     if ((eventIO == EventIO.CLOSE) || (eventIO ==
> EventIO.CONNECT_FAIL)) {
>                         this.eof = true;
>                     }
>                 }
>             }
>             finally {
>                 this.lockBuffer.unlock();
>             }
>         }
>
>         @Override
>         public void run() {
>             try {
>                 int granularity = 0;
>
>                 // stop delivery when granularity is reached, or no more
> EventIO left in buffer to deliver
>                 boolean endLoop = false;
>                 boolean closed = false;
>                 while (!endLoop && !closed) {
>
>                     EventIO eventIO = null;
>                     try {
>                         // prevent concurrent access to buffer as
> ArrayDeque is not thread-safe
>                         // - Thread_1, + IOHandlerThreadPool
>                         //
>                         // - add(EventIO eventIO)
>                         // - this.buffer.add(eventIO)
>                         // + run()
>                         // + eventIO = this.buffer.poll()
>                         this.lockBuffer.lock();
>
>                         // remove an Object from buffer
>                         eventIO = this.buffer.poll();
>                     }
>                     finally {
>                         this.lockBuffer.unlock();
>                     }
>
>                     if (eventIO == null) {
>                         endLoop = true;
>                     }
>                     else {
>                         // prevent memory consistency errors whereby
> values written by current thread from IOHandlerThreadPool is not flushed,
> causing the next
>                         // run() reading stale values if it is a different
> thread from this current thread
>                         synchronized (this) {
>
>                             // delivery
>                             if (eventIO == EventIO.OPEN) {
>                                 Conn.this.handleOpen();
>                             }
>                             else if (eventIO == EventIO.READ) {
>                                 Conn.this.handleRead ();
>                             }
>                             else if ((eventIO == EventIO.IDLE_READ) ||
> (eventIO == EventIO.IDLE_WRITE)) {
>                                 Conn.this.handleIdle(eventIO);
>                             }
>                             else if (eventIO == EventIO.CLOSE) {
>                                 Conn.this.handleClose();
>                                 closed = true;
>                             }
>                             else if (eventIO == EventIO.CONNECT_FAIL) {
>                                 Conn.this.handleConnectFail();
>                                 closed = true;
>                             }
>                         }
>
>                         // update granularity
>                         granularity++;
>                         if (granularity == 10) {
>                             endLoop = true;
>                         }
>                     }
>                 }
>
>                 // if EventIO.CLOSE is reached, then permanently
> streamInProc stays true, ensuring no more EventIO will be delivered
>                 if (!closed) {
>                     try {
>                         // prevent case where Event exist in buffer, but
> not submitted to threadpool
>                         // - Thread_1, + IOHandlerThreadPool
>                         //
>                         // + run()
>                         // + if (this.buffer.size() != 0) test false
>                         // - add(EventIO eventIO)
>                         // - this.buffer.add(eventIO)
>                         // - if (!this.streamInProc) test false
>                         // + this.streamInProc = false
>                         // event in buffer but not submitted
>                         this.lockBuffer.lock();
>
>                         if (this.buffer.size() != 0) {
>                             Conn.this.ioHandlerThreadPool.submit(this);
>                         }
>                         else {
>                             this.streamInProc = false;
>                         }
>                     }
>                     finally {
>                         this.lockBuffer.unlock ();
>                     }
>                 }
>             }
>             catch (Throwable e) {
>                 // log FATAL, critical thread dies, node unable to
> function
>                 LoggerProxy.fatal(this.logger , "SYSTEM", "Died of
> unchecked exception, node terminating", e);
>                 // fatal, terminate the program
>                 System.exit(1);
>             }
>         }
>     }
>
> As you can see above, EventIO is deposited into the buffer, and a thread
> from threadpool is awakened to process the event, however it is only
> possible for only 1 thread at any instance to do the run() method by using
> the streamInProc boolean. Therefore there will only be 1 single thread
> processing Upstream in any single instance
>
>
> > 2. How is the instance of X accessed from two different Runnables
> >
> > Also, returning to the original issue, the use of the ConcurrentHashMap
> > is significant here as well, as it also introduces happens-before
> > relationships.
> >
> >
> The thing is that during event delivery, thread-1 from threadpool might be
> doing the run() method, and the next time round, thread-2 from threadpool
> might be doing the run() method also. ConcurrentHashMap is accessed during
> event delivery methods like Conn.this.handleOpen(), Conn.this.handleRead()
> etc. There is this time when CHM is accessed, it returns null, when in fact
> the element is put into the CHM already. It is a very rare occurrance. I
> have run rigourous tests on the code day and night and it never happens,
> there is only once when i am doing simple testing (under very insignifcant
> load) that it occurs. I am not very sure if it is fixed, but it seems that
> someone else has also encountered the same kind of bug
> http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html
>
>
> >  So I still need more detail on the code to commemnt further.
> >
> > Cheers,
> > David Holmes
> >
> >  -----Original Message-----
> > *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> > concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *BJ Low
> > *Sent:* Sunday, 6 January 2008 12:15 AM
> > *To:* Endre St?lsvik
> > *Cc:* concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> > *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> > NullPointerException
> >
> >  I think perhaps I never explain myself properly, Tim Peierls however
> > did understood what i am trying to say.
> >
> > At time t1, Thread-X submits a Runnable to threadpool,
> > At time t2, Thread-1 from the threadpool runs the Runnable and call
> > changeVal(1);
> >
> > AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....
> >
> > At time t3, Thread-X submits another Runnable to threadpool
> > At time t4, Thread-2 from the threadpool runs the Runnable and call
> > readVal();
> >
> > .... i missed out the red statement above. I think in above case, the
> > happens-before property is very important, cause if at t3, it is Thread-1,
> > but not Thread-X that submits the Runnable, then there will not be any
> > memory consistency errors.
> >
> > On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:
> >
> > > BJ Low wrote:
> > > > Hi,
> > > >
> > > > I am pretty sure of below. It is very hard for me to post the code
> > > cause
> > > > the code is proprietary, but perhaps let me ask this in another way
> > > >
> > > > Suppose I have a class below
> > > >
> > > > class X {
> > > >      int i = 0;
> > > >
> > > >      void changeVal(int i) {
> > > >         this.i = i;
> > > >      }
> > > >
> > > >      int readVal() {
> > > >         return this.i;
> > > >      }
> > > > }
> > > >
> > > > At time t1, Thread-X submits a Runnable to threadpool,
> > > > At time t2, Thread-1 from the threadpool runs the Runnable and call
> > > > changeVal(1);
> > > > At time t3, Thread-X submits another Runnable to threadpool
> > > > At time t4, Thread-2 from the threadpool runs the Runnable and call
> > > > readVal();
> > > >
> > > > The question is, will Thread-2 see the value of i as 0 or 1?
> > >
> > > "Thread-X" - is that supposed to be the same thread at the two times?
> > > Because I personally use "X" as "some".
> > >
> > > But lets assumes that (it doesn't really matter either - this is
> > > broken
> > > no matter!).
> > >
> > > There's no reason to argue complex memory situations and
> > > happens-before
> > > or anything like that here - this is plain as day: Thread X works on
> > > its
> > > own, and thus basically submits two jobs right after each other. For
> > > the
> > > sake of the argument: The first runnable, in Thread-1, takes 3 hours
> > > to
> > > complete, finally doing changeVal(1). The second Runnable runs
> > > readVal()
> > > about .001 ms after submit. What is the answer?
> > >
> > > And the time labels "t[1-4]" is of no use what so ever when
> > > interleaved
> > > between threads that doesn't do explicit synchronization. Assuming
> > > again
> > > that Thread-X is the same in both instances, there is a "t, t+x"
> > > situation between the two submits (the first submit /happens-before/
> > > the
> > > second submit, by way of code order).
> > >   However, one cannot argue anything about Thread-1 (other than that
> > > it
> > > happens AFTER the submit of itself, which is at "t"), and Thread-2
> > > (other than that is happens AFTER the submit of itself, which is at
> > > "t+x").
> > >   The order of _when_ those two runnables are run on their respective
> > > worker threads, is fully non-deterministic: both the work they do (the
> > > time it takes), the inner workings of the thread pool (e.g. whether a
> > > new Thread has to be made for one of the submissions, perhaps the
> > > first,
> > > not the second) - and finally, the operating system: it might decide
> > > based on some cosmic reasons, that Thread-1 shouldn't run, or is
> > > pre-empted before the changeVal() while a whole bunch of other threads
> > > gets time slices, while Thread-2 by the same unfair magic gets
> > > scheduled
> > > right away.
> > >
> > > These are really basic multi-threading issues, not having anything to
> > > do
> > > with complex code-reorderings or anything like that.
> > >
> > > What you want here, is synchronized code in class X, and some flag
> > > that
> > > denotes whether the job is done. The flag is set to true when
> > > "changeVal()" is run, and then the /this X/ is .notify()ed (within
> > > synchronized on /this X/, of course). The readVal() method checks
> > > (within synchronzied on /this X/, of course) whether the flag is true.
> > > If it isn't it goes into .wait() on /this X/, looping until flag is
> > > true
> > > (must loop due to "spurious wakeups"). Hey presto.. Also check out
> > > Callable vs. Future - it does just this.
> > >
> > > Endre.
> > >
> >
> >
> >
> > --
> > Regards,
> > BJ Low
> >
> >
>
>
> --
> Regards,
> BJ Low
>
>


-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/0080f246/attachment-0001.html 

From notorand at gmail.com  Sun Jan  6 22:04:05 2008
From: notorand at gmail.com (BJ Low)
Date: Mon, 7 Jan 2008 11:04:05 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801061853s6e5d155fh4c4b3d0a42dca805@mail.gmail.com>
References: <c1dcd6d20801061824u69b71568k58be556ff05e7f91@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEPPHJAA.dcholmes@optusnet.com.au>
	<c1dcd6d20801061853s6e5d155fh4c4b3d0a42dca805@mail.gmail.com>
Message-ID: <c1dcd6d20801061904r4adb1325i80f2d34fd6ab08b4@mail.gmail.com>

Sorry it shld be this

    public void onOpen(Conn conn) {

        // create new Member1 and store to Conn-Member1 mapping
        this.mapOfMembers.put(conn, new Member1());
    }

and removed during

    public void onClose(Conn conn) {

        // remove the Conn-Member1 mapping
        Member1 member1 = this.mapOfMembers.remove(conn);
    }

however during accessing it during

    public void onRead(Conn conn) {

        // get the Conn-Member1 mapping
        Member1 member1 = this.mapOfMembers.get(conn);
         .....
         .....
    }

It shld be Conn not Upstream that is passed as the parameter. Conn is the
parent class of Upstream. Upstream is the inner class of Conn. However like
i say, it is not impt of how the key is constructed, as i did a
synchronized(this) before every event delivery, therefore even if another
object class X is constructed during onOpen() as the key, it shld also be
visible

class Conn {
   ....
   ....- Hide quoted text -


   class Upstream implements Runnable {

        private Logger logger = Logger.getLogger(Conn.Upstream.class);

        private ReentrantLock lockBuffer = new ReentrantLock();
        private ArrayDeque<EventIO> buffer = new ArrayDeque<EventIO>();

        private boolean streamInProc = false;
        private boolean eof = false;

        private Upstream() {
        }

        private void add(EventIO eventIO) {
            try {
                // prevent case where Event exist in buffer, but not
submitted to threadpool
                // - Thread_1, + IOHandlerThreadPool
                //
                // + run()
                // + if (this.buffer.size() != 0) test false
                // - add(EventIO eventIO)
                // - this.buffer.add(eventIO)
                // - if (!this.streamInProc) test false
                // + this.streamInProc = false
                // event in buffer but not submitted
                //
                // prevent concurrent access to buffer as ArrayDeque is not
thread-safe
                // - Thread_1, + IOHandlerThreadPool
                //
                // - add(EventIO eventIO)
                // - this.buffer.add(eventIO)
                // + run()
                // + eventIO = this.buffer.poll()
                this.lockBuffer.lock();

                // to prevent out-of-memory by not adding, within lockBuffer
to prevent memory consistency errors
                if (!this.eof) {

                    this.buffer.add(eventIO);

                    if (!this.streamInProc) {
                        Conn.this.ioHandlerThreadPool.submit(this);
                        this.streamInProc = true;
                    }

                    // CLOSE, CONNECT_FAIL will be the last event to be
processed, therefore any further add to the back add()/front close() of the
buffer is
                    // redundant
                    if ((eventIO == EventIO.CLOSE) || (eventIO ==
EventIO.CONNECT_FAIL)) {
                        this.eof = true;
                    }
                }
            }
            finally {
                this.lockBuffer.unlock();
            }
        }

        @Override
        public void run() {
            try {
                int granularity = 0;

                // stop delivery when granularity is reached, or no more
EventIO left in buffer to deliver
                boolean endLoop = false;
                boolean closed = false;
                while (!endLoop && !closed) {

                    EventIO eventIO = null;
                    try {
                        // prevent concurrent access to buffer as ArrayDeque
is not thread-safe
                        // - Thread_1, + IOHandlerThreadPool
                        //
                        // - add(EventIO eventIO)
                        // - this.buffer.add(eventIO)
                        // + run()
                        // + eventIO = this.buffer.poll()
                        this.lockBuffer.lock();

                        // remove an Object from buffer
                        eventIO = this.buffer.poll();
                    }
                    finally {
                        this.lockBuffer.unlock();
                    }

                    if (eventIO == null) {
                        endLoop = true;
                    }
                    else {
                        // prevent memory consistency errors whereby values
written by current thread from IOHandlerThreadPool is not flushed, causing
the next
                        // run() reading stale values if it is a different
thread from this current thread
                        synchronized (this) {

                            // delivery
                            if (eventIO == EventIO.OPEN) {
                                Conn.this.handleOpen();
                            }
                            else if (eventIO == EventIO.READ) {
                                Conn.this.handleRead ();
                            }
                            else if ((eventIO == EventIO.IDLE_READ) ||
(eventIO == EventIO.IDLE_WRITE)) {
                                Conn.this.handleIdle(eventIO);
                            }
                            else if (eventIO == EventIO.CLOSE) {
                                Conn.this.handleClose();
                                closed = true;
                            }
                            else if (eventIO == EventIO.CONNECT_FAIL) {
                                Conn.this.handleConnectFail();
                                closed = true;
                            }
                        }

                        // update granularity
                        granularity++;
                        if (granularity == 10) {
                            endLoop = true;
                        }
                    }
                }

                // if EventIO.CLOSE is reached, then permanently
streamInProc stays true, ensuring no more EventIO will be delivered
                if (!closed) {
                    try {
                        // prevent case where Event exist in buffer, but not
submitted to threadpool
                        // - Thread_1, + IOHandlerThreadPool
                        //
                        // + run()
                        // + if (this.buffer.size() != 0) test false
                        // - add(EventIO eventIO)
                        // - this.buffer.add(eventIO)
                        // - if (!this.streamInProc) test false
                        // + this.streamInProc = false
                        // event in buffer but not submitted
                        this.lockBuffer.lock();

                        if (this.buffer.size() != 0) {
                            Conn.this.ioHandlerThreadPool.submit(this);
                        }
                        else {
                            this.streamInProc = false;
                        }
                    }
                    finally {
                        this.lockBuffer.unlock ();
                    }
                }
            }
            catch (Throwable e) {
                // log FATAL, critical thread dies, node unable to function
                LoggerProxy.fatal( this.logger , "SYSTEM", "Died of
unchecked exception, node terminating", e);
                // fatal, terminate the program
                System.exit(1);
            }
        }
    }

}


> On Jan 7, 2008 10:39 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> >  BJ,
> >
> > The upstream parameter is being used as the key in put/get. Where does
> > this come from?
> >
> > David
> >
> > -----Original Message-----
> > *From:* BJ Low [mailto:notorand at gmail.com]
> > *Sent:* Monday, 7 January 2008 12:24 PM
> > *To:* dholmes at ieee.org
> > *Cc:* concurrency-interest at cs.oswego.edu
> > *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> > NullPointerException
> >
> >
> >
> > On Jan 7, 2008 10:05 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> >
> > >  BJ,
> > >
> > > The original problem involved the construction and publication of the
> > > key object X. I still can not see where/how this key object is created and
> > > published.
> > >
> >
> > The key is created in the listener during onOpen()
> >
> >     public void onOpen(Upstream upstream) {
> >
> >         // create new Member1 and store to Upstream-Member1 mapping
> >         this.mapOfMembers.put(upstream, new Member1());
> >     }
> >
> > and removed during
> >
> >     public void onClose(Upstream upstream) {
> >
> >         // remove the Upstream-Member1 mapping
> >         Member1 member1 = this.mapOfMembers.remove(upstream);
> >     }
> >
> > however during accessing it during
> >
> >     public void onRead(Upstream upstream) {
> >
> >         // get the Upstream-Member1 mapping
> >         Member1 member1 = this.mapOfMembers.get(upstream);
> >          .....
> >          .....
> >     }
> >
> > it returns null instead, and it is ensured that ordering onOpen ->
> > onRead() -> .... -> onRead() -> onClose()
> > In fact, it is not important how the key is published cause everytime i
> > do an event delivery i will synchronized(this) to ensure that any values
> > that is created will be a write-through cache.
> >
> >   > It is a very rare occurrance. I have run rigourous tests on the code
> > > day and
> > > > night and it never happens, there is only once when i am doing
> > > simple testing
> > > > (under very insignifcant load) that it occurs.
> > >
> > > That is the opposite of what you would expect with a JMM issue. It is
> > > more what you would expect with a "simple" race condition.
> > >
> >
> > I think JMM issues are harder to arise. Frequently I have not declared a
> > boolean variable to to be volatile, and memory consistency issues do not
> > arise at all. Well i have not done this kind of tests under the server mode
> > jvm but in client mode, this kind of memory consistency issues seldom occur.
> > In fact, race condition deadlocks and such is easier to detect when the code
> > is put under rigorous day and night load tests
> >
> >
> > > > I am not very sure if it is fixed, but it seems that someone else
> > > has also
> > > > encountered the same kind of bug http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html
> > >
> > > Unfortunately after having been told that CHM does establish some JMM
> > > happens-before relationships, the original reporter didn't take this any
> > > further, so we have no way to know what actually happened in his case.
> > >
> > >
> >
> > Unfortunately there is no contact for this reporter, but I think it is
> > very hard to reproduce the same error again
> >
> >
> > >  David Holmes
> > >
> > >  -----Original Message-----
> > > *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu
> > > ]*On Behalf Of *BJ Low
> > > *Sent:* Monday, 7 January 2008 11:20 AM
> > > *To:* dholmes at ieee.org
> > > *Cc:* concurrency-interest at cs.oswego.edu
> > >  *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> > > NullPointerException
> > >
> > >
> > >
> > > On Jan 7, 2008 6:32 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > >
> > > >  BJ,
> > > >
> > > > I'm still missing two key parts to this:
> > > >
> > > > 1. As Endre asked, how do you know that Thread-1 has completed its
> > > > action
> > > >
> > >
> > > class Upstream implements Runnable {
> > >
> > >         private Logger logger = Logger.getLogger(Conn.Upstream.class);
> > >
> > >         private ReentrantLock lockBuffer = new ReentrantLock();
> > >         private ArrayDeque<EventIO> buffer = new
> > > ArrayDeque<EventIO>();
> > >
> > >         private boolean streamInProc = false;
> > >         private boolean eof = false;
> > >
> > >         private Upstream() {
> > >         }
> > >
> > >         private void add(EventIO eventIO) {
> > >             try {
> > >                 // prevent case where Event exist in buffer, but not
> > > submitted to threadpool
> > >                 // - Thread_1, + IOHandlerThreadPool
> > >                 //
> > >                 // + run()
> > >                 // + if (this.buffer.size() != 0) test false
> > >                 // - add(EventIO eventIO)
> > >                 // - this.buffer.add(eventIO)
> > >                 // - if (!this.streamInProc) test false
> > >                 // + this.streamInProc = false
> > >                 // event in buffer but not submitted
> > >                 //
> > >                 // prevent concurrent access to buffer as ArrayDeque
> > > is not thread-safe
> > >                 // - Thread_1, + IOHandlerThreadPool
> > >                 //
> > >                 // - add(EventIO eventIO)
> > >                 // - this.buffer.add(eventIO)
> > >                 // + run()
> > >                 // + eventIO = this.buffer.poll()
> > >                 this.lockBuffer.lock();
> > >
> > >                 // to prevent out-of-memory by not adding, within
> > > lockBuffer to prevent memory consistency errors
> > >                 if (!this.eof) {
> > >
> > >                     this.buffer.add(eventIO);
> > >
> > >                     if (!this.streamInProc) {
> > >                         Conn.this.ioHandlerThreadPool.submit(this);
> > >                         this.streamInProc = true;
> > >                     }
> > >
> > >                     // CLOSE, CONNECT_FAIL will be the last event to
> > > be processed, therefore any further add to the back add()/front close() of
> > > the buffer is
> > >                     // redundant
> > >                     if ((eventIO == EventIO.CLOSE) || (eventIO ==
> > > EventIO.CONNECT_FAIL)) {
> > >                         this.eof = true;
> > >                     }
> > >                 }
> > >             }
> > >             finally {
> > >                 this.lockBuffer.unlock();
> > >             }
> > >         }
> > >
> > >         @Override
> > >         public void run() {
> > >             try {
> > >                 int granularity = 0;
> > >
> > >                 // stop delivery when granularity is reached, or no
> > > more EventIO left in buffer to deliver
> > >                 boolean endLoop = false;
> > >                 boolean closed = false;
> > >                 while (!endLoop && !closed) {
> > >
> > >                     EventIO eventIO = null;
> > >                     try {
> > >                         // prevent concurrent access to buffer as
> > > ArrayDeque is not thread-safe
> > >                         // - Thread_1, + IOHandlerThreadPool
> > >                         //
> > >                         // - add(EventIO eventIO)
> > >                         // - this.buffer.add(eventIO)
> > >                         // + run()
> > >                         // + eventIO = this.buffer.poll()
> > >                         this.lockBuffer.lock();
> > >
> > >                         // remove an Object from buffer
> > >                         eventIO = this.buffer.poll();
> > >                     }
> > >                     finally {
> > >                         this.lockBuffer.unlock();
> > >                     }
> > >
> > >                     if (eventIO == null) {
> > >                         endLoop = true;
> > >                     }
> > >                     else {
> > >                         // prevent memory consistency errors whereby
> > > values written by current thread from IOHandlerThreadPool is not flushed,
> > > causing the next
> > >                         // run() reading stale values if it is a
> > > different thread from this current thread
> > >                         synchronized (this) {
> > >
> > >                             // delivery
> > >                             if (eventIO == EventIO.OPEN) {
> > >                                 Conn.this.handleOpen();
> > >                             }
> > >                             else if (eventIO == EventIO.READ) {
> > >                                 Conn.this.handleRead ();
> > >                             }
> > >                             else if ((eventIO == EventIO.IDLE_READ) ||
> > > (eventIO == EventIO.IDLE_WRITE)) {
> > >                                 Conn.this.handleIdle(eventIO);
> > >                             }
> > >                             else if (eventIO == EventIO.CLOSE) {
> > >                                 Conn.this.handleClose();
> > >                                 closed = true;
> > >                             }
> > >                             else if (eventIO == EventIO.CONNECT_FAIL)
> > > {
> > >                                 Conn.this.handleConnectFail();
> > >                                 closed = true;
> > >                             }
> > >                         }
> > >
> > >                         // update granularity
> > >                         granularity++;
> > >                         if (granularity == 10) {
> > >                             endLoop = true;
> > >                         }
> > >                     }
> > >                 }
> > >
> > >                 // if EventIO.CLOSE is reached, then permanently
> > > streamInProc stays true, ensuring no more EventIO will be delivered
> > >                 if (!closed) {
> > >                     try {
> > >                         // prevent case where Event exist in buffer,
> > > but not submitted to threadpool
> > >                         // - Thread_1, + IOHandlerThreadPool
> > >                         //
> > >                         // + run()
> > >                         // + if (this.buffer.size() != 0) test false
> > >                         // - add(EventIO eventIO)
> > >                         // - this.buffer.add(eventIO)
> > >                         // - if (!this.streamInProc) test false
> > >                         // + this.streamInProc = false
> > >                         // event in buffer but not submitted
> > >                         this.lockBuffer.lock();
> > >
> > >                         if (this.buffer.size() != 0) {
> > >                             Conn.this.ioHandlerThreadPool.submit
> > > (this);
> > >                         }
> > >                         else {
> > >                             this.streamInProc = false;
> > >                         }
> > >                     }
> > >                     finally {
> > >                         this.lockBuffer.unlock ();
> > >                     }
> > >                 }
> > >             }
> > >             catch (Throwable e) {
> > >                 // log FATAL, critical thread dies, node unable to
> > > function
> > >                 LoggerProxy.fatal(this.logger , "SYSTEM", "Died of
> > > unchecked exception, node terminating", e);
> > >                 // fatal, terminate the program
> > >                 System.exit(1);
> > >             }
> > >         }
> > >     }
> > >
> > > As you can see above, EventIO is deposited into the buffer, and a
> > > thread from threadpool is awakened to process the event, however it is only
> > > possible for only 1 thread at any instance to do the run() method by using
> > > the streamInProc boolean. Therefore there will only be 1 single thread
> > > processing Upstream in any single instance
> > >
> > >
> > > > 2. How is the instance of X accessed from two different Runnables
> > > >
> > > > Also, returning to the original issue, the use of the
> > > > ConcurrentHashMap is significant here as well, as it also introduces
> > > > happens-before relationships.
> > > >
> > > >
> > > The thing is that during event delivery, thread-1 from threadpool
> > > might be doing the run() method, and the next time round, thread-2 from
> > > threadpool might be doing the run() method also. ConcurrentHashMap is
> > > accessed during event delivery methods like Conn.this.handleOpen(),
> > > Conn.this.handleRead() etc. There is this time when CHM is accessed,
> > > it returns null, when in fact the element is put into the CHM already. It is
> > > a very rare occurrance. I have run rigourous tests on the code day and night
> > > and it never happens, there is only once when i am doing simple testing
> > > (under very insignifcant load) that it occurs. I am not very sure if it is
> > > fixed, but it seems that someone else has also encountered the same kind of
> > > bug http://osdir.com/ml/java.jsr.166-concurrency/2003-12/msg00018.html
> > >
> > >
> > > >  So I still need more detail on the code to commemnt further.
> > > >
> > > > Cheers,
> > > > David Holmes
> > > >
> > > >  -----Original Message-----
> > > > *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu
> > > > ]*On Behalf Of *BJ Low
> > > > *Sent:* Sunday, 6 January 2008 12:15 AM
> > > > *To:* Endre St?lsvik
> > > > *Cc:* concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> > > > *Subject:* Re: [concurrency-interest] ConcurrentHashMap
> > > > NullPointerException
> > > >
> > > >  I think perhaps I never explain myself properly, Tim Peierlshowever did understood what i am trying to say.
> > > >
> > > > At time t1, Thread-X submits a Runnable to threadpool,
> > > > At time t2, Thread-1 from the threadpool runs the Runnable and call
> > > > changeVal(1);
> > > >
> > > > AFTER changeVal(1) from Thread-1 is completed, then at time t3 ....
> > > >
> > > > At time t3, Thread-X submits another Runnable to threadpool
> > > > At time t4, Thread-2 from the threadpool runs the Runnable and call
> > > > readVal();
> > > >
> > > > .... i missed out the red statement above. I think in above case,
> > > > the happens-before property is very important, cause if at t3, it is
> > > > Thread-1, but not Thread-X that submits the Runnable, then there will not be
> > > > any memory consistency errors.
> > > >
> > > > On Jan 5, 2008 7:52 PM, Endre St?lsvik <Online at stolsvik.com> wrote:
> > > >
> > > > > BJ Low wrote:
> > > > > > Hi,
> > > > > >
> > > > > > I am pretty sure of below. It is very hard for me to post the
> > > > > code cause
> > > > > > the code is proprietary, but perhaps let me ask this in another
> > > > > way
> > > > > >
> > > > > > Suppose I have a class below
> > > > > >
> > > > > > class X {
> > > > > >      int i = 0;
> > > > > >
> > > > > >      void changeVal(int i) {
> > > > > >         this.i = i;
> > > > > >      }
> > > > > >
> > > > > >      int readVal() {
> > > > > >         return this.i;
> > > > > >      }
> > > > > > }
> > > > > >
> > > > > > At time t1, Thread-X submits a Runnable to threadpool,
> > > > > > At time t2, Thread-1 from the threadpool runs the Runnable and
> > > > > call
> > > > > > changeVal(1);
> > > > > > At time t3, Thread-X submits another Runnable to threadpool
> > > > > > At time t4, Thread-2 from the threadpool runs the Runnable and
> > > > > call
> > > > > > readVal();
> > > > > >
> > > > > > The question is, will Thread-2 see the value of i as 0 or 1?
> > > > >
> > > > > "Thread-X" - is that supposed to be the same thread at the two
> > > > > times?
> > > > > Because I personally use "X" as "some".
> > > > >
> > > > > But lets assumes that (it doesn't really matter either - this is
> > > > > broken
> > > > > no matter!).
> > > > >
> > > > > There's no reason to argue complex memory situations and
> > > > > happens-before
> > > > > or anything like that here - this is plain as day: Thread X works
> > > > > on its
> > > > > own, and thus basically submits two jobs right after each other.
> > > > > For the
> > > > > sake of the argument: The first runnable, in Thread-1, takes 3
> > > > > hours to
> > > > > complete, finally doing changeVal(1). The second Runnable runs
> > > > > readVal()
> > > > > about .001 ms after submit. What is the answer?
> > > > >
> > > > > And the time labels "t[1-4]" is of no use what so ever when
> > > > > interleaved
> > > > > between threads that doesn't do explicit synchronization. Assuming
> > > > > again
> > > > > that Thread-X is the same in both instances, there is a "t, t+x"
> > > > > situation between the two submits (the first submit
> > > > > /happens-before/ the
> > > > > second submit, by way of code order).
> > > > >   However, one cannot argue anything about Thread-1 (other than
> > > > > that it
> > > > > happens AFTER the submit of itself, which is at "t"), and Thread-2
> > > > > (other than that is happens AFTER the submit of itself, which is
> > > > > at "t+x").
> > > > >   The order of _when_ those two runnables are run on their
> > > > > respective
> > > > > worker threads, is fully non-deterministic: both the work they do
> > > > > (the
> > > > > time it takes), the inner workings of the thread pool (e.g.
> > > > > whether a
> > > > > new Thread has to be made for one of the submissions, perhaps the
> > > > > first,
> > > > > not the second) - and finally, the operating system: it might
> > > > > decide
> > > > > based on some cosmic reasons, that Thread-1 shouldn't run, or is
> > > > > pre-empted before the changeVal() while a whole bunch of other
> > > > > threads
> > > > > gets time slices, while Thread-2 by the same unfair magic gets
> > > > > scheduled
> > > > > right away.
> > > > >
> > > > > These are really basic multi-threading issues, not having anything
> > > > > to do
> > > > > with complex code-reorderings or anything like that.
> > > > >
> > > > > What you want here, is synchronized code in class X, and some flag
> > > > > that
> > > > > denotes whether the job is done. The flag is set to true when
> > > > > "changeVal()" is run, and then the /this X/ is .notify()ed (within
> > > > >
> > > > > synchronized on /this X/, of course). The readVal() method checks
> > > > > (within synchronzied on /this X/, of course) whether the flag is
> > > > > true.
> > > > > If it isn't it goes into .wait() on /this X/, looping until flag
> > > > > is true
> > > > > (must loop due to "spurious wakeups"). Hey presto.. Also check out
> > > > > Callable vs. Future - it does just this.
> > > > >
> > > > > Endre.
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Regards,
> > > > BJ Low
> > > >
> > > >
> > >
> > >
> > > --
> > > Regards,
> > > BJ Low
> > >
> > >
> >
> >
> > --
> > Regards,
> > BJ Low
> >
> >
>
>
> --
> Regards,
> BJ Low




-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/98f177dd/attachment-0001.html 

From jed at atlassian.com  Mon Jan  7 00:24:29 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Mon, 07 Jan 2008 16:24:29 +1100
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <c1dcd6d20801061904r4adb1325i80f2d34fd6ab08b4@mail.gmail.com>
References: <c1dcd6d20801061824u69b71568k58be556ff05e7f91@mail.gmail.com>	<NFBBKALFDCPFIDBNKAPCCEPPHJAA.dcholmes@optusnet.com.au>	<c1dcd6d20801061853s6e5d155fh4c4b3d0a42dca805@mail.gmail.com>
	<c1dcd6d20801061904r4adb1325i80f2d34fd6ab08b4@mail.gmail.com>
Message-ID: <4781B78D.4020909@atlassian.com>

BJ Low wrote:
> Sorry it shld be this
>
> ...
>
> class Conn {
>    ....
>    ....
> - Hide quoted text -

BJ, you never did show your key class's equals and hashcode methods or 
whether the class is immutable (as regards equality at least).

cheers,
jed.

From bingjiang.low at fresbo.com  Mon Jan  7 01:30:53 2008
From: bingjiang.low at fresbo.com (BJ Low)
Date: Mon, 7 Jan 2008 14:30:53 +0800
Subject: [concurrency-interest] ConcurrentHashMap NullPointerException
In-Reply-To: <4781B78D.4020909@atlassian.com>
References: <c1dcd6d20801061824u69b71568k58be556ff05e7f91@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEPPHJAA.dcholmes@optusnet.com.au>
	<c1dcd6d20801061853s6e5d155fh4c4b3d0a42dca805@mail.gmail.com>
	<c1dcd6d20801061904r4adb1325i80f2d34fd6ab08b4@mail.gmail.com>
	<4781B78D.4020909@atlassian.com>
Message-ID: <c1dcd6d20801062230g79a80cb4j68b5448108879f5f@mail.gmail.com>

It is Object.hashcode() and Object.equals()

On Jan 7, 2008 1:24 PM, Jed Wesley-Smith <jed at atlassian.com> wrote:

> BJ Low wrote:
> > Sorry it shld be this
> >
> > ...
> >
> > class Conn {
> >    ....
> >    ....
> > - Hide quoted text -
>
> BJ, you never did show your key class's equals and hashcode methods or
> whether the class is immutable (as regards equality at least).
>
> cheers,
> jed.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Regards,
BJ Low
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080107/c74b79ea/attachment.html 

From alarmnummer at gmail.com  Mon Jan  7 03:44:59 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 7 Jan 2008 09:44:59 +0100
Subject: [concurrency-interest] Example from JCIP contains visibility
	problem?
Message-ID: <1466c1d60801070044h11e84ae7rbcfc3338c3ecf56@mail.gmail.com>

Hi Guys,

I have a question about an example from JCIP. This example was used in
a presentation within our company, but I think the example contains a
visibility problem.

  @ThreadSafe
public class ListHelper<E> {

    public List<E> list = Collections.synchronizedList(new ArrayList<E>());

    // ...

    public boolean putIfAbsent(E x) {
        synchronized (list) {
            boolean absent = !list.contains(x);
            if (absent)
                list.add(x);
            return absent;
        }
    }
}

There is no happens before relation between the write of list and the
read of list, so there is no guarantee that the value read for the
synchronized block, contains the value written when this class is
initialized.

The fix is simple: make list final.

Is my assumption correct?

From dcholmes at optusnet.com.au  Mon Jan  7 05:27:36 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 7 Jan 2008 20:27:36 +1000
Subject: [concurrency-interest] Example from JCIP contains
	visibilityproblem?
In-Reply-To: <1466c1d60801070044h11e84ae7rbcfc3338c3ecf56@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEACHKAA.dcholmes@optusnet.com.au>

Peter,

The example doesn't show how the instance of ListHelper is created or
shared. The ListHelper instance needs to be safely published.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Veentjer
> Sent: Monday, 7 January 2008 6:45 PM
> To: concurrency-interest
> Subject: [concurrency-interest] Example from JCIP contains
> visibilityproblem?
>
>
> Hi Guys,
>
> I have a question about an example from JCIP. This example was used in
> a presentation within our company, but I think the example contains a
> visibility problem.
>
>   @ThreadSafe
> public class ListHelper<E> {
>
>     public List<E> list = Collections.synchronizedList(new
> ArrayList<E>());
>
>     // ...
>
>     public boolean putIfAbsent(E x) {
>         synchronized (list) {
>             boolean absent = !list.contains(x);
>             if (absent)
>                 list.add(x);
>             return absent;
>         }
>     }
> }
>
> There is no happens before relation between the write of list and the
> read of list, so there is no guarantee that the value read for the
> synchronized block, contains the value written when this class is
> initialized.
>
> The fix is simple: make list final.
>
> Is my assumption correct?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From alarmnummer at gmail.com  Mon Jan  7 05:53:13 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 7 Jan 2008 11:53:13 +0100
Subject: [concurrency-interest] Example from JCIP contains
	visibilityproblem?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEACHKAA.dcholmes@optusnet.com.au>
References: <1466c1d60801070044h11e84ae7rbcfc3338c3ecf56@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEACHKAA.dcholmes@optusnet.com.au>
Message-ID: <1466c1d60801070253m7d9a9e0r65aa5bf5e5d890a2@mail.gmail.com>

Hi David,

thanks. I understand that the example could be safely used when the
variable pointing to the helper is safely published. The problem is
that this isn't very clear from the example (nothing is mentioned
about it) and that most developers don't understand the JMM. When
people see this example, they think this is the correct way to use
this class without knowing anything about the hidden/additional
requirements. Personally I prefer to localize this whenever I can and
in this case it could be solved by making the list variable final (or
volatile). Localizing also makes is easier to reason about concurrent
objects because you don't need to know how it is going to be used.

On Jan 7, 2008 11:27 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> Peter,
>
> The example doesn't show how the instance of ListHelper is created or
> shared. The ListHelper instance needs to be safely published.
>
> Cheers,
> David Holmes
>
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> > Veentjer
> > Sent: Monday, 7 January 2008 6:45 PM
> > To: concurrency-interest
> > Subject: [concurrency-interest] Example from JCIP contains
> > visibilityproblem?
> >
> >
> > Hi Guys,
> >
> > I have a question about an example from JCIP. This example was used in
> > a presentation within our company, but I think the example contains a
> > visibility problem.
> >
> >   @ThreadSafe
> > public class ListHelper<E> {
> >
> >     public List<E> list = Collections.synchronizedList(new
> > ArrayList<E>());
> >
> >     // ...
> >
> >     public boolean putIfAbsent(E x) {
> >         synchronized (list) {
> >             boolean absent = !list.contains(x);
> >             if (absent)
> >                 list.add(x);
> >             return absent;
> >         }
> >     }
> > }
> >
> > There is no happens before relation between the write of list and the
> > read of list, so there is no guarantee that the value read for the
> > synchronized block, contains the value written when this class is
> > initialized.
> >
> > The fix is simple: make list final.
> >
> > Is my assumption correct?
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>

From dcholmes at optusnet.com.au  Mon Jan  7 06:23:34 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 7 Jan 2008 21:23:34 +1000
Subject: [concurrency-interest] Example from JCIP
	containsvisibilityproblem?
In-Reply-To: <1466c1d60801070253m7d9a9e0r65aa5bf5e5d890a2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEACHKAA.dcholmes@optusnet.com.au>

Peter,

I understand what you are saying, and I'd rewrite the example differently,
but the basic issue remains unchanged. Given a threadsafe class X you still
have to, in the general case, safely publish instances of X for use by
different threads. Otherwise there is a race between construction of the
object in one thread and use of it in another. As we've discussed on this
list in the past, it is extremely difficult, in general to a make a class
that is safe in the face of unsafe publication, and generally not worth the
effort.

In this case a final field would suffice. But in a sense that might lead the
programmer into a false sense of security as they may not recognize the
significance of the final field in the example, and then extrapolate to a
context where they don't have an object with all final instance fields.

Plus, I wouldn't want to encourage anyone to use unsafe publication :)

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Veentjer
> Sent: Monday, 7 January 2008 8:53 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] Example from JCIP
> containsvisibilityproblem?
>
>
> Hi David,
>
> thanks. I understand that the example could be safely used when the
> variable pointing to the helper is safely published. The problem is
> that this isn't very clear from the example (nothing is mentioned
> about it) and that most developers don't understand the JMM. When
> people see this example, they think this is the correct way to use
> this class without knowing anything about the hidden/additional
> requirements. Personally I prefer to localize this whenever I can and
> in this case it could be solved by making the list variable final (or
> volatile). Localizing also makes is easier to reason about concurrent
> objects because you don't need to know how it is going to be used.
>
> On Jan 7, 2008 11:27 AM, David Holmes <dcholmes at optusnet.com.au> wrote:
> > Peter,
> >
> > The example doesn't show how the instance of ListHelper is created or
> > shared. The ListHelper instance needs to be safely published.
> >
> > Cheers,
> > David Holmes
> >
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> > > Veentjer
> > > Sent: Monday, 7 January 2008 6:45 PM
> > > To: concurrency-interest
> > > Subject: [concurrency-interest] Example from JCIP contains
> > > visibilityproblem?
> > >
> > >
> > > Hi Guys,
> > >
> > > I have a question about an example from JCIP. This example was used in
> > > a presentation within our company, but I think the example contains a
> > > visibility problem.
> > >
> > >   @ThreadSafe
> > > public class ListHelper<E> {
> > >
> > >     public List<E> list = Collections.synchronizedList(new
> > > ArrayList<E>());
> > >
> > >     // ...
> > >
> > >     public boolean putIfAbsent(E x) {
> > >         synchronized (list) {
> > >             boolean absent = !list.contains(x);
> > >             if (absent)
> > >                 list.add(x);
> > >             return absent;
> > >         }
> > >     }
> > > }
> > >
> > > There is no happens before relation between the write of list and the
> > > read of list, so there is no guarantee that the value read for the
> > > synchronized block, contains the value written when this class is
> > > initialized.
> > >
> > > The fix is simple: make list final.
> > >
> > > Is my assumption correct?
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dl at cs.oswego.edu  Mon Jan  7 11:05:44 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 07 Jan 2008 11:05:44 -0500
Subject: [concurrency-interest] In-progress ParallelArray changes
In-Reply-To: <4772835D.6060202@cs.oswego.edu>
References: <4772835D.6060202@cs.oswego.edu>
Message-ID: <47824DD8.4080600@cs.oswego.edu>

After a few distractions, the "version 2" ParallelArray API files
are now available. See the usual places:

API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar
CVS sources: http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

Below is pasted reminder about main changes.
Which forgot to mention full cascade support:
   pa.withFilter(p1).withFilter(p1).withMapping(m1).withMapping(m2)...
(Yes, I did once say that I wasn't going to do this, but decided
that people were right about it being very inconvenient to do this
manually.)

Also, here are a few questions for those of you using these APIs.

1. It is now easy to use the default global ForkJoinExecutor,
but should it be made even easier, by supporting static factory
methods that omit it as an argument? The main reason for making
people pay attention to the executor argument is to force at least
a bit of thought about whether you need isolation from other parts
of a system that might be abusing the default pool.

2. The prefix classes (WithFilter, WithMapping etc) do not themselves
support support Iterable. So for example, to iterate through some,
you'd need to do pa.withFilter(pred).all().iterator(). This is not
done to be annoying, but because there are two perfectly reasonable
expectations people might have about constructions like:
   for(T e: pa.withFilter(pred)) ...
Since iterators are sequential, should this mean to just
sequentially evaluate filters as elements are produced, or
should it perform a full parallel mapping first, and then produce
the iteration elements without further processing? Currently, there
is no way to obtain the first behavior. Should there be?



Doug Lea wrote:
> 
> * A full-featured List view accessed via asList: 
> * Static factory methods instead of constructors
> * A static defaultExecutor method 
> * Elimination of "Int" specializations. 
> * Better support for set-like operations: allUniqueElements,
>    WithFilter.removeAll, binarySearch on sorted arrays, and
>    a few others.
> * A few method renamings to make the above a bit more consistent.
> * Corresponding changes to ParallelDoubleArray and ParallelLongArray
>  

From David.Biesack at sas.com  Mon Jan  7 14:39:00 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 7 Jan 2008 14:39:00 -0500 (EST)
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 36,
	Issue 11
In-Reply-To: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <200801071939.m07Jd036011683@cs.oswego.edu>

> From: concurrency-interest-request at cs.oswego.edu
> Date: Mon, 07 Jan 2008 12:00:02 -0500
> 
> Date: Mon, 07 Jan 2008 11:05:44 -0500
> From: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] In-progress ParallelArray changes
> 
> After a few distractions, the "version 2" ParallelArray API files
> are now available. See the usual places:
> 
> API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
> jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar
> CVS sources: http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

cool - thanks
 
> Below is pasted reminder about main changes.
> Which forgot to mention full cascade support:
>    pa.withFilter(p1).withFilter(p1).withMapping(m1).withMapping(m2)...
> (Yes, I did once say that I wasn't going to do this, but decided
> that people were right about it being very inconvenient to do this
> manually.)

Nice; I like the chaining.
 
> Also, here are a few questions for those of you using these APIs.
> 
> 1. It is now easy to use the default global ForkJoinExecutor,
> but should it be made even easier, by supporting static factory
> methods that omit it as an argument? 

I'd prefer to see a smaller API footprint, so I recommend leaving the parameter there rather than overloading, and simply use the default executor if the caller passes null.

> 2. The prefix classes (WithFilter, WithMapping etc) do not themselves
> support support Iterable. So for example, to iterate through some,
> you'd need to do pa.withFilter(pred).all().iterator(). This is not
> done to be annoying, but because there are two perfectly reasonable
> expectations people might have about constructions like:
>    for(T e: pa.withFilter(pred)) ...
> Since iterators are sequential, should this mean to just
> sequentially evaluate filters as elements are produced, or
> should it perform a full parallel mapping first, and then produce
> the iteration elements without further processing? Currently, there
> is no way to obtain the first behavior. Should there be?

Taking a hint from Fortress and other such languages with parallel loops, where a parallel loop
    for (item <- generator)
becomes sequential with
    for (item <- sequential(generator))

could some sort of sequential operator or method be added to achieve the behavior
of delayed execution of the mappings, i.e. with a FutureTask or something?

    for(T e: pa.withFilter(p1).withFilter(p2).withMapping(m1).sequentially()) ...

instead of

    for(T e: pa.withFilter(p1).withFilter(p2).withMapping(m1).all()) ...

The returned instance would be an Iterable but would not fork. I've not played with PA enough to know if this would work, but it seems more natural from an API and client usage perspective.

I also have some general comments on the class/interface naming conventions, which differ depending on whether the signature involves a generic type parameter T or not. I don't see a strong reason for the disparity and recommend a consistent naming pattern

  <FromType>To<ToType>Mapper
  <Type>Predicate
  <Type>Comparator
  To<Type>Generator
  Mapper

such as

  Ops.IntToIntMapper   becomes Ops.TypeToIntMapper<T> with int map(T t)
  Ops.MapperFromInt<T> becomes Ops.IntToTMapper<T> with <T> map(int t)
  Ops.Mapper<T,U>      becomes Ops.TToUMapper<T,U>  with <U> map(<T> t)
  etc.

Documentation wise, for mappers, T and U should be used consistently for the input and output types and parameter names.

For example, given

  Ops.Mapper<T,U>       :: U    map(T t)
  "An object with a function accepting objects of type T and returning those of type U"

then

  Ops.MapperFromLong<T> :: T    map(long t)
  "A mapper accepting a long argument"

should be

  Ops.MapperFromLong<U> :: U    map(long t) 
  "A mapper accepting a long argument t and returning objects of type U"

Or, if there is not a strong reason for using T and U generic type names, I suggest T for a "to" type and F for a "from" type, as in

  Ops.Mapper<F,T>       :: T    map(F from)
  Ops.Predicate<F>      :: boolean evaluate(F from)
  Ops.Combiner<F,G,T>   :: T    combine(F f, G g) 

and so on.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From kasper at kav.dk  Mon Jan  7 15:22:06 2008
From: kasper at kav.dk (Kasper Nielsen)
Date: Mon, 07 Jan 2008 21:22:06 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 36,
 Issue 11
In-Reply-To: <200801071939.m07Jd036011683@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>
	<200801071939.m07Jd036011683@cs.oswego.edu>
Message-ID: <478289EE.6040706@kav.dk>

David J. Biesack wrote:
>  
>> Below is pasted reminder about main changes.
>> Which forgot to mention full cascade support:
>>    pa.withFilter(p1).withFilter(p1).withMapping(m1).withMapping(m2)...
>> (Yes, I did once say that I wasn't going to do this, but decided
>> that people were right about it being very inconvenient to do this
>> manually.)
> 
> Nice; I like the chaining.
>  
>> Also, here are a few questions for those of you using these APIs.
>>
>> 1. It is now easy to use the default global ForkJoinExecutor,
>> but should it be made even easier, by supporting static factory
>> methods that omit it as an argument? 
> 
> I'd prefer to see a smaller API footprint, so I recommend leaving the parameter there rather than overloading, and simply use the default executor if the caller passes null.
Yes I like forcing the user to think just a little bit. So keep it as it 
is. But I don't think null should be used to indicate the default 
executor. It is bad API design in my opinion.

> 
> Taking a hint from Fortress and other such languages with parallel loops, where a parallel loop
>     for (item <- generator)
> becomes sequential with
>     for (item <- sequential(generator))
> 
> could some sort of sequential operator or method be added to achieve the behavior
> of delayed execution of the mappings, i.e. with a FutureTask or something?
> 
>     for(T e: pa.withFilter(p1).withFilter(p2).withMapping(m1).sequentially()) ...

I like it.

> I also have some general comments on the class/interface naming conventions, which differ depending on whether the signature involves a generic type parameter T or not. I don't see a strong reason for the disparity and recommend a consistent naming pattern
> 
>   <FromType>To<ToType>Mapper
>   <Type>Predicate
>   <Type>Comparator
>   To<Type>Generator
>   Mapper
Yup this is important. I still have to look at the javadocs each time I use
TimeUnit.someunit.convert(), because I can't remember if it converts to 
or from the specified TimeUnit. Now if it was named convertFrom it would 
be a lot easier to remember.

> Or, if there is not a strong reason for using T and U generic type names, I suggest T for a "to" type and F for a "from" type, as in

> 
>   Ops.Mapper<F,T>       :: T    map(F from)
>   Ops.Predicate<F>      :: boolean evaluate(F from)
>   Ops.Combiner<F,G,T>   :: T    combine(F f, G g) 

I like the F, T naming scheme and use it myself. I also know that the 
Google collection library uses it.

Cheers
   Kasper


From dl at cs.oswego.edu  Mon Jan  7 15:31:08 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 07 Jan 2008 15:31:08 -0500
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 36,
 Issue 11
In-Reply-To: <200801071939.m07Jd036011683@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>
	<200801071939.m07Jd036011683@cs.oswego.edu>
Message-ID: <47828C0C.4090302@cs.oswego.edu>

David J. Biesack wrote:
>

> 
>     for(T e: pa.withFilter(p1).withFilter(p2).withMapping(m1).sequentially()) ...
> 

Good idea!

(Slightly relatedly: Does anyone who uses any of those filtering
iterator frameworks out there have an opinion about how this meshes with
them. Using a ParallelArray for such purposes, without ever actually
triggering parallel computations becomes an unexpected application.)

> 
> I also have some general comments on the class/interface naming conventions, 

Thanks. You are right that these need to be more regular.
But I don't know a consistent scheme that also keeps most names short
and readable, especially given all the wildcard clutter.

I started with a scheme like the one you suggest, but then decided
that no one wants to look at a declaration:
   TToUMapper<? super T, ? extends U?>
The current Mapper<? super T, ? extends U?> is bad enough as it is :-)

Does anyone have any other ideas that at least arrange that the most common
types are reasonably pleasant to use?

Neal Gafter's proposal for functional types helps in some cases,
but others like "DoubleReducer" and "DoubleComparator" seem both
more informative and more  readable than functional versions:
"double, double => double", "double, double => int". Hopefully
someone will come up with a best of both worlds compromise.

In any case, for present purposes, I'm trying to stay out of
the language issues, and to make something that people can and
will get experience using now, not just down the road in Java7.
All suggestions for helping to get the type names more usable so people
aren't so scared off from this are welcome.


-Doug

From joe.bowbeer at gmail.com  Mon Jan  7 17:18:27 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 7 Jan 2008 16:18:27 -0600
Subject: [concurrency-interest] Exception handling with ParallelArray
In-Reply-To: <15e8b9d20712280705n526515a3q9a34995a31c1ba47@mail.gmail.com>
References: <f9cec2830712271439v555c91e5o8b9d896dd6c3c59c@mail.gmail.com>
	<4774E9FC.7070808@cs.oswego.edu>
	<15e8b9d20712280550u2ab43fcetb2974ba40920431d@mail.gmail.com>
	<477500CE.7010601@cs.oswego.edu>
	<15e8b9d20712280645q562c825bof1a3fc318c0f574a@mail.gmail.com>
	<15e8b9d20712280705n526515a3q9a34995a31c1ba47@mail.gmail.com>
Message-ID: <31f2a7bd0801071418r3a8b03d9m8e7e43f0ef988397@mail.gmail.com>

On Dec 28, 2007 9:05 AM, Neal Gafter <neal at gafter.com> wrote:
>
> Just to be perfectly clear, using BGGA closures one can define apply this
> way:
>

Since BGGA has never been defined on concurrency-interest, I include this link:

 Closures for the Java Programming Language
 http://www.javac.info/

--Joe

From forax at univ-mlv.fr  Mon Jan  7 18:50:52 2008
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 08 Jan 2008 00:50:52 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 36,
 Issue 11
In-Reply-To: <47828C0C.4090302@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>	<200801071939.m07Jd036011683@cs.oswego.edu>
	<47828C0C.4090302@cs.oswego.edu>
Message-ID: <4782BADC.8010306@univ-mlv.fr>

Doug Lea a ?crit :
> David J. Biesack wrote:
>   
>
>   
>>     for(T e: pa.withFilter(p1).withFilter(p2).withMapping(m1).sequentially()) ...
>>
>>     
>
> Good idea!
>
> (Slightly relatedly: Does anyone who uses any of those filtering
> iterator frameworks out there have an opinion about how this meshes with
> them. Using a ParallelArray for such purposes, without ever actually
> triggering parallel computations becomes an unexpected application.)
>
>   
>> I also have some general comments on the class/interface naming conventions, 
>>     
>
> Thanks. You are right that these need to be more regular.
> But I don't know a consistent scheme that also keeps most names short
> and readable, especially given all the wildcard clutter.
>
> I started with a scheme like the one you suggest, but then decided
> that no one wants to look at a declaration:
>    TToUMapper<? super T, ? extends U?>
> The current Mapper<? super T, ? extends U?> is bad enough as it is :-)
>
> Does anyone have any other ideas that at least arrange that the most common
> types are reasonably pleasant to use?
>
> Neal Gafter's proposal for functional types helps in some cases,
> but others like "DoubleReducer" and "DoubleComparator" seem both
> more informative and more  readable than functional versions:
> "double, double => double", "double, double => int". Hopefully
> someone will come up with a best of both worlds compromise.
>
> In any case, for present purposes, I'm trying to stay out of
> the language issues, and to make something that people can and
> will get experience using now, not just down the road in Java7.
> All suggestions for helping to get the type names more usable so people
> aren't so scared off from this are welcome.
>   
Why not using internal classes for all specialized types like
java.awt.geom do.

something like:
Reducer.Double, Reducer.Long, etc.
and Comparator.Double, Comparator.Int, etc.
>
> -Doug
>   
R?mi

From dl at cs.oswego.edu  Mon Jan  7 20:25:39 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 07 Jan 2008 20:25:39 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <4782BADC.8010306@univ-mlv.fr>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>	<200801071939.m07Jd036011683@cs.oswego.edu>
	<47828C0C.4090302@cs.oswego.edu> <4782BADC.8010306@univ-mlv.fr>
Message-ID: <4782D113.4020101@cs.oswego.edu>

R?mi Forax wrote:
> Why not using internal classes for all specialized types like
> java.awt.geom do.
> 
> something like:
> Reducer.Double, Reducer.Long, etc.
> and Comparator.Double, Comparator.Int, etc.
>>

The names that people seem to like the least are the
ones that cross types, which this doesn't seem to help.

That is, while DoubleMapper sounds/reads fine,
the variants that take or return other types all look and sound
awful:
   MapperFromDouble<U>
   MapperToDouble<T>
   MapperFromDoubleToLong
   MapperFromLongToDouble

(These are the ones for which Neal's function type language proposal
works much better for -- see
http://gafter.blogspot.com/2007/12/what-flavor-of-closures.html)

A possible small improvement is to use a variant of David Biesack's
scheme only for these mixed types:
   DoubleToObject<U>
   ObjectToDouble<T>
   DoubleToLong
   LongToDouble

These seem only a little better if at all.
But maybe some of you have better ideas along these lines?

Notice also that Ops does not even try to define the various
scalar specializations of Combiners. Which here might look like,
for example:
   DoubleXLongToDouble
(Luckily none of the ParallelArray classes use such types.)

Aside: all of these naming schemes have the flaw that they look
like they apply to boxed types ("Double") not scalars ("double"),
but don't; and in fact autoboxing usually won't work on them...

Further aside: Note that these naming and usage issues crop up
because of the need to support scalar long and double versions.
(Without them, just "Mapper", "Predicate", etc suffice.)
So people using them are doing so for the sake of performance.
As I've mentioned before though, the performance differences
of, for example,  boxed Longs vs scalar longs are magnified
by parallelism, so it is not uncommon to see scalar versions
of parallel map, reduce, sort, etc run, say, four times faster
than boxed versions. So I'd like to minimize the hurdles people
have to go through to use the more efficient versions.
(Maybe eventually boxing will be comparable to scalar, but there
are some huge obstacles to overcome, so it won't be soon.)

-Doug







From richard.zschech at velsys.com  Mon Jan  7 23:54:50 2008
From: richard.zschech at velsys.com (Richard Zschech)
Date: Tue, 8 Jan 2008 15:24:50 +1030
Subject: [concurrency-interest] Managing subscription aggregation
Message-ID: <9595F39E2D27654A9184E2F7476D0F173D70C4@velmail03.velsys.local>

Hi,

 

I have a problem where I want to managing subscription aggregation. I
have multiple clients subscribing to multiple topics in my system and I
want to establish a single subscription to another system per topic.

 

To handle setup the subscriptions I'm using a Memoizer
(http://www.javaconcurrencyinpractice.com/listings/Memoizer.java) style
system where the first client subscription for a topic establishes the
subscription to the other system. My Computable establishes the
subscription and  returns a list of clients which get added to for
subsequent subscriptions:

 

public void subscribe(String topic, String client) {

                List<Subscription> list = subscriptions. compute(topic);

                list.add(client);

}

 

public class Subcriber implements Computable<String, List<String>> {

                public List<String> compute(String topic) {

                                otherSystem.subscribe(topic);

                                return new
CopyOnWriteArrayList<String>();

                }

}

 

This works nicely but the problem comes when trying to handle the
unsubscriptions. I'm not sure how I can atomically remove the other
system subscription when the last client subscription is removed.
Somehow I need to do the following atomically:

 

public void unsubscribe(String topic, String client) {

                List<Subscription> list = subscriptions.get(topic);

                If(list.remove(client) {

                                If(list.isEmpty()) {

 
subscriptions.remove(list);

 
otherSystem.unsubscribe(topic);

                                }

}

}

 

Obviously I can stick synchronized on the methods to get them to happen
atomically but I would like a more concurrent solution.

 

I was wondering if someone has come up with an aggregation management
class which manages when the first subscribe request comes in some user
code can be invoked and when the last unsubscribe request comes in some
user code can be executed.

 

Thanks in advance,

>From Richard.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080108/1aebca23/attachment-0001.html 

From dl at cs.oswego.edu  Tue Jan  8 07:22:37 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 08 Jan 2008 07:22:37 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <4782D113.4020101@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>	<200801071939.m07Jd036011683@cs.oswego.edu>	<47828C0C.4090302@cs.oswego.edu>
	<4782BADC.8010306@univ-mlv.fr> <4782D113.4020101@cs.oswego.edu>
Message-ID: <47836B0D.3090102@cs.oswego.edu>

Doug Lea wrote:
> Notice also that Ops does not even try to define the various
> scalar specializations of Combiners. Which here might look like,
> for example:
>    DoubleXLongToDouble
> (Luckily none of the ParallelArray classes use such types.)
> 

I should have noted that this is also subject to change.
Currently, operations on Combiners are not integrated as nicely
as those using filters and mappings. You'd like to be able to
write, for example:
   a.withCombination(b, multiplier).max()
rather than
   a.combine(b, multiplier).max();
to find the maximum value of products of elements in a and b.
This would be in keeping with the idea that ParallelArray allows
you to build up expressions that can be performed in a single
parallel step. This saves time by eliminating the need for
multiple parallel passes, and saves space by avoiding storage
of intermediate arrays. (Plus, down the road, one can imagine
people coming up with expression optimizers that take various
With* elements and produce evaluation orders likely to be fastest.
This is similar to database query optimization.)

The main reason this isn't supported (yet?) is that it creates
another combinatorial API and implementation blowup if done
completely orthogonally, As in:
a.withBounds(l,h).withFilter(f).withMapping(m).withCombination(b,c).max()
(which would entail creating internal classes such as
WithBoundedFilteredMappedCombination to maintain all the bookkeeping
needed to flatten out the leaf computations, which is needed to
get good parallel performance.)

Plus it needs type names AXBToC for A, B, C in {Object, long, double}.
Plus a zillion compoundCombiner methods to allow cascading.

Given all the obstacles in supporting a fully integrated version,
I'm still considering alternative ways of providing this kind of
functionality. Suggestions welcome.
Until then, people can always use multi-step expressions.

-Doug

From peter.kovacs.1.0rc at gmail.com  Tue Jan  8 09:57:06 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 8 Jan 2008 15:57:06 +0100
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
Message-ID: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>

Hi,

I am implementing multi-threaded routines in a Java library to be used
via Java API. By default, my library "silently" creates the ThreadPool
it needs. (The library provides API for the user to use whatever
Executor it wishes to override the default ThreadPool, but the point
here is the default behavior.) The thing is that the default
keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
application is wound down, however, the threads in the pool are
waiting until their keepAliveTimes expire. That's is fine so far: I
can provide a handle to shut the TP down without delay at the end of
the application. But there is this assimmetry which bugs me: I
silently create something which then needs to be shutdown explicitly
by the innocent user of the API. Am I the only one to feel
uncomfortable with this? What is recommended procedure in such cases?

I've just checked that System.exit(...) doesn't wait for the thread
pool to wind down. Does this make a difference to my problem? Can I
rely on the application developer calling System.exit(...)?

Also, does anyone have it on top their head: how does the existence of
non-daemon threads affect the termination of an application-context in
an application container such as Tomcat? (I. e. the case when my
library is used in a WEB application.)

Thanks a lot,
Peter

From elihusmails at gmail.com  Tue Jan  8 11:06:40 2008
From: elihusmails at gmail.com (Mark)
Date: Tue, 8 Jan 2008 11:06:40 -0500
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
In-Reply-To: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
Message-ID: <9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>

you could add a shutdown hook to the JVM.  Another idea would be to expose a
method for the user to shutdown the API.  This way you are not exposing the
innards of your thread pool.

On Jan 8, 2008 9:57 AM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> Hi,
>
> I am implementing multi-threaded routines in a Java library to be used
> via Java API. By default, my library "silently" creates the ThreadPool
> it needs. (The library provides API for the user to use whatever
> Executor it wishes to override the default ThreadPool, but the point
> here is the default behavior.) The thing is that the default
> keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
> application is wound down, however, the threads in the pool are
> waiting until their keepAliveTimes expire. That's is fine so far: I
> can provide a handle to shut the TP down without delay at the end of
> the application. But there is this assimmetry which bugs me: I
> silently create something which then needs to be shutdown explicitly
> by the innocent user of the API. Am I the only one to feel
> uncomfortable with this? What is recommended procedure in such cases?
>
> I've just checked that System.exit(...) doesn't wait for the thread
> pool to wind down. Does this make a difference to my problem? Can I
> rely on the application developer calling System.exit(...)?
>
> Also, does anyone have it on top their head: how does the existence of
> non-daemon threads affect the termination of an application-context in
> an application container such as Tomcat? (I. e. the case when my
> library is used in a WEB application.)
>
> Thanks a lot,
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
--------------------------------
Talent hits a target no one else can hit; Genius hits a target no one else
can see.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080108/a1b535dd/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Tue Jan  8 11:47:26 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 8 Jan 2008 17:47:26 +0100
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
In-Reply-To: <b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>
	<b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>
Message-ID: <b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>

Thinking about it a bit more, one gotcha may be: is the shutdown hook
not called only after after the last non-daemon thread completed? If
so, it could be useless for my purpose.

Thanks
Peter

On Jan 8, 2008 5:32 PM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> Thanks for the tips!
>
> I had thought the shutdown hook is called only for Control-C/SIGINT et
> al. based on the description of the -Xrs swith of java: "The JVM
> watches for console control events to implement shutdown hooks for
> abnormal JVM termination." But now I realize that the console control
> events may be listened to only to detect abnormal termination and the
> shutdown hook is also called for normal program termination -- on the
> main function returning or the System.exit() being called. Is this
> correct?
>
> Shutting down the entire API is also an interesting approach, but the
> shutdown hook appears to be the less intrusive on the user of the two.
> (The API shutdown is probably a more natural fit for device control
> APIs or similar, which is not my case...)
>
> Thanks,
> Peter
>
>
> On Jan 8, 2008 5:06 PM, Mark <elihusmails at gmail.com> wrote:
> > you could add a shutdown hook to the JVM.  Another idea would be to expose a
> > method for the user to shutdown the API.  This way you are not exposing the
> > innards of your thread pool.
> >
> >
> >
> > On Jan 8, 2008 9:57 AM, Peter Kovacs < peter.kovacs.1.0rc at gmail.com> wrote:
> > >
> > >
> > >
> > > Hi,
> > >
> > > I am implementing multi-threaded routines in a Java library to be used
> > > via Java API. By default, my library "silently" creates the ThreadPool
> > > it needs. (The library provides API for the user to use whatever
> > > Executor it wishes to override the default ThreadPool, but the point
> > > here is the default behavior.) The thing is that the default
> > > keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
> > > application is wound down, however, the threads in the pool are
> > > waiting until their keepAliveTimes expire. That's is fine so far: I
> > > can provide a handle to shut the TP down without delay at the end of
> > > the application. But there is this assimmetry which bugs me: I
> > > silently create something which then needs to be shutdown explicitly
> > > by the innocent user of the API. Am I the only one to feel
> > > uncomfortable with this? What is recommended procedure in such cases?
> > >
> > > I've just checked that System.exit(...) doesn't wait for the thread
> > > pool to wind down. Does this make a difference to my problem? Can I
> > > rely on the application developer calling System.exit(...)?
> > >
> > > Also, does anyone have it on top their head: how does the existence of
> > > non-daemon threads affect the termination of an application-context in
> > > an application container such as Tomcat? (I. e. the case when my
> > > library is used in a WEB application.)
> > >
> > > Thanks a lot,
> > > Peter
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at altair.cs.oswego.edu
> > > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> >
> >
> > --
> > --------------------------------
> > Talent hits a target no one else can hit; Genius hits a target no one else
> > can see.
>

From peter.kovacs.1.0rc at gmail.com  Tue Jan  8 11:32:25 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 08 Jan 2008 17:32:25 +0100
Subject: [concurrency-interest] "Best practice" for ThreadPool
 creation/run-down
In-Reply-To: <9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>
Message-ID: <b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>

Thanks for the tips!

I had thought the shutdown hook is called only for Control-C/SIGINT et
al. based on the description of the -Xrs swith of java: "The JVM
watches for console control events to implement shutdown hooks for
abnormal JVM termination." But now I realize that the console control
events may be listened to only to detect abnormal termination and the
shutdown hook is also called for normal program termination -- on the
main function returning or the System.exit() being called. Is this
correct?

Shutting down the entire API is also an interesting approach, but the
shutdown hook appears to be the less intrusive on the user of the two.
(The API shutdown is probably a more natural fit for device control
APIs or similar, which is not my case...)

Thanks,
Peter

On Jan 8, 2008 5:06 PM, Mark <elihusmails at gmail.com> wrote:
> you could add a shutdown hook to the JVM.  Another idea would be to expose a
> method for the user to shutdown the API.  This way you are not exposing the
> innards of your thread pool.
>
>
>
> On Jan 8, 2008 9:57 AM, Peter Kovacs < peter.kovacs.1.0rc at gmail.com> wrote:
> >
> >
> >
> > Hi,
> >
> > I am implementing multi-threaded routines in a Java library to be used
> > via Java API. By default, my library "silently" creates the ThreadPool
> > it needs. (The library provides API for the user to use whatever
> > Executor it wishes to override the default ThreadPool, but the point
> > here is the default behavior.) The thing is that the default
> > keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
> > application is wound down, however, the threads in the pool are
> > waiting until their keepAliveTimes expire. That's is fine so far: I
> > can provide a handle to shut the TP down without delay at the end of
> > the application. But there is this assimmetry which bugs me: I
> > silently create something which then needs to be shutdown explicitly
> > by the innocent user of the API. Am I the only one to feel
> > uncomfortable with this? What is recommended procedure in such cases?
> >
> > I've just checked that System.exit(...) doesn't wait for the thread
> > pool to wind down. Does this make a difference to my problem? Can I
> > rely on the application developer calling System.exit(...)?
> >
> > Also, does anyone have it on top their head: how does the existence of
> > non-daemon threads affect the termination of an application-context in
> > an application container such as Tomcat? (I. e. the case when my
> > library is used in a WEB application.)
> >
> > Thanks a lot,
> > Peter
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
> --
> --------------------------------
> Talent hits a target no one else can hit; Genius hits a target no one else
> can see.

From aaron at mindwidgets.com  Tue Jan  8 13:16:38 2008
From: aaron at mindwidgets.com (Aaron)
Date: Tue, 08 Jan 2008 13:16:38 -0500
Subject: [concurrency-interest] "Best practice" for
	ThreadPool	creation/run-down
In-Reply-To: <b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>	<b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>
	<b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>
Message-ID: <4783BE06.2070109@mindwidgets.com>

Peter,
   I had a chat with a co-worker about this. If exposing a lifecycle 
interface isn't an option (probably the best route in cases where a 
thread pool is created), a PhantomReference may do what you want. When 
no other references to your pool-holding object exist, you can shutdown 
your thread pool.

http://java.sun.com/j2se/1.5.0/docs/api/java/lang/ref/PhantomReference.html

Thanks,
Aaron


Peter Kovacs wrote:
> Thinking about it a bit more, one gotcha may be: is the shutdown hook
> not called only after after the last non-daemon thread completed? If
> so, it could be useless for my purpose.
> 
> Thanks
> Peter
> 
> On Jan 8, 2008 5:32 PM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
>> Thanks for the tips!
>>
>> I had thought the shutdown hook is called only for Control-C/SIGINT et
>> al. based on the description of the -Xrs swith of java: "The JVM
>> watches for console control events to implement shutdown hooks for
>> abnormal JVM termination." But now I realize that the console control
>> events may be listened to only to detect abnormal termination and the
>> shutdown hook is also called for normal program termination -- on the
>> main function returning or the System.exit() being called. Is this
>> correct?
>>
>> Shutting down the entire API is also an interesting approach, but the
>> shutdown hook appears to be the less intrusive on the user of the two.
>> (The API shutdown is probably a more natural fit for device control
>> APIs or similar, which is not my case...)
>>
>> Thanks,
>> Peter
>>
>>
>> On Jan 8, 2008 5:06 PM, Mark <elihusmails at gmail.com> wrote:
>>> you could add a shutdown hook to the JVM.  Another idea would be to expose a
>>> method for the user to shutdown the API.  This way you are not exposing the
>>> innards of your thread pool.
>>>
>>>
>>>
>>> On Jan 8, 2008 9:57 AM, Peter Kovacs < peter.kovacs.1.0rc at gmail.com> wrote:
>>>>
>>>>
>>>> Hi,
>>>>
>>>> I am implementing multi-threaded routines in a Java library to be used
>>>> via Java API. By default, my library "silently" creates the ThreadPool
>>>> it needs. (The library provides API for the user to use whatever
>>>> Executor it wishes to override the default ThreadPool, but the point
>>>> here is the default behavior.) The thing is that the default
>>>> keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
>>>> application is wound down, however, the threads in the pool are
>>>> waiting until their keepAliveTimes expire. That's is fine so far: I
>>>> can provide a handle to shut the TP down without delay at the end of
>>>> the application. But there is this assimmetry which bugs me: I
>>>> silently create something which then needs to be shutdown explicitly
>>>> by the innocent user of the API. Am I the only one to feel
>>>> uncomfortable with this? What is recommended procedure in such cases?
>>>>
>>>> I've just checked that System.exit(...) doesn't wait for the thread
>>>> pool to wind down. Does this make a difference to my problem? Can I
>>>> rely on the application developer calling System.exit(...)?
>>>>
>>>> Also, does anyone have it on top their head: how does the existence of
>>>> non-daemon threads affect the termination of an application-context in
>>>> an application container such as Tomcat? (I. e. the case when my
>>>> library is used in a WEB application.)
>>>>
>>>> Thanks a lot,
>>>> Peter
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at altair.cs.oswego.edu
>>>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>> --
>>> --------------------------------
>>> Talent hits a target no one else can hit; Genius hits a target no one else
>>> can see.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From peter.kovacs.1.0rc at gmail.com  Tue Jan  8 16:51:20 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 8 Jan 2008 22:51:20 +0100
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
In-Reply-To: <4783BE06.2070109@mindwidgets.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>
	<b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>
	<b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>
	<4783BE06.2070109@mindwidgets.com>
Message-ID: <b6e8f2e80801081351s10237c0br2a2d6dbc9e8005c0@mail.gmail.com>

Thank you, Aaron.

I guess I'll have to read-up on the java.lang.ref package. (I kind of
suspect that this will not work for me, because the thread pool used
is ultimately referenced as a static variable in my library. I'll see
if this is a problem for the PhantomReference scheme.)

Thanks
Peter

On Jan 8, 2008 7:16 PM, Aaron <aaron at mindwidgets.com> wrote:
> Peter,
>    I had a chat with a co-worker about this. If exposing a lifecycle
> interface isn't an option (probably the best route in cases where a
> thread pool is created), a PhantomReference may do what you want. When
> no other references to your pool-holding object exist, you can shutdown
> your thread pool.
>
> http://java.sun.com/j2se/1.5.0/docs/api/java/lang/ref/PhantomReference.html
>
> Thanks,
> Aaron
>
>
>
> Peter Kovacs wrote:
> > Thinking about it a bit more, one gotcha may be: is the shutdown hook
> > not called only after after the last non-daemon thread completed? If
> > so, it could be useless for my purpose.
> >
> > Thanks
> > Peter
> >
> > On Jan 8, 2008 5:32 PM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:
> >> Thanks for the tips!
> >>
> >> I had thought the shutdown hook is called only for Control-C/SIGINT et
> >> al. based on the description of the -Xrs swith of java: "The JVM
> >> watches for console control events to implement shutdown hooks for
> >> abnormal JVM termination." But now I realize that the console control
> >> events may be listened to only to detect abnormal termination and the
> >> shutdown hook is also called for normal program termination -- on the
> >> main function returning or the System.exit() being called. Is this
> >> correct?
> >>
> >> Shutting down the entire API is also an interesting approach, but the
> >> shutdown hook appears to be the less intrusive on the user of the two.
> >> (The API shutdown is probably a more natural fit for device control
> >> APIs or similar, which is not my case...)
> >>
> >> Thanks,
> >> Peter
> >>
> >>
> >> On Jan 8, 2008 5:06 PM, Mark <elihusmails at gmail.com> wrote:
> >>> you could add a shutdown hook to the JVM.  Another idea would be to expose a
> >>> method for the user to shutdown the API.  This way you are not exposing the
> >>> innards of your thread pool.
> >>>
> >>>
> >>>
> >>> On Jan 8, 2008 9:57 AM, Peter Kovacs < peter.kovacs.1.0rc at gmail.com> wrote:
> >>>>
> >>>>
> >>>> Hi,
> >>>>
> >>>> I am implementing multi-threaded routines in a Java library to be used
> >>>> via Java API. By default, my library "silently" creates the ThreadPool
> >>>> it needs. (The library provides API for the user to use whatever
> >>>> Executor it wishes to override the default ThreadPool, but the point
> >>>> here is the default behavior.) The thing is that the default
> >>>> keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
> >>>> application is wound down, however, the threads in the pool are
> >>>> waiting until their keepAliveTimes expire. That's is fine so far: I
> >>>> can provide a handle to shut the TP down without delay at the end of
> >>>> the application. But there is this assimmetry which bugs me: I
> >>>> silently create something which then needs to be shutdown explicitly
> >>>> by the innocent user of the API. Am I the only one to feel
> >>>> uncomfortable with this? What is recommended procedure in such cases?
> >>>>
> >>>> I've just checked that System.exit(...) doesn't wait for the thread
> >>>> pool to wind down. Does this make a difference to my problem? Can I
> >>>> rely on the application developer calling System.exit(...)?
> >>>>
> >>>> Also, does anyone have it on top their head: how does the existence of
> >>>> non-daemon threads affect the termination of an application-context in
> >>>> an application container such as Tomcat? (I. e. the case when my
> >>>> library is used in a WEB application.)
> >>>>
> >>>> Thanks a lot,
> >>>> Peter
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at altair.cs.oswego.edu
> >>>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>
> >>>
> >>>
> >>> --
> >>> --------------------------------
> >>> Talent hits a target no one else can hit; Genius hits a target no one else
> >>> can see.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From gregg at cytetech.com  Tue Jan  8 17:02:03 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 08 Jan 2008 16:02:03 -0600
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
In-Reply-To: <4783BE06.2070109@mindwidgets.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>
	<b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>
	<b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>
	<4783BE06.2070109@mindwidgets.com>
Message-ID: <4783F2DB.2010106@cytetech.com>

Aaron wrote:
> Peter,
>    I had a chat with a co-worker about this. If exposing a lifecycle 
> interface isn't an option (probably the best route in cases where a 
> thread pool is created), a PhantomReference may do what you want. When 
> no other references to your pool-holding object exist, you can shutdown 
> your thread pool.
> 
> http://java.sun.com/j2se/1.5.0/docs/api/java/lang/ref/PhantomReference.html

I posted a class that provides use of PhantomReference mechanism to track 
things.  I can send it to anyone directly that wants it.  The usage is to create 
a subclass that accepts the object to track and the object to cleanup.

class MyTracker extends ReferenceTracker<RefObjectType,CleanupObjectType> {
	public void release( CleanupObjectType obj ) {
		... do something with obj to cleanup ...
	}
}

The cleanup object can not have a strong reference to the tracked object.  Then, 
you can use the instance as in
	
class MyClassThatCreatesObjectsThatNeedCleanup {
	private static final MyTracker tracker = new MyTracker();

	public RefObjectType creatorMethod() {
		CleanupObjectType refToThingToCleanup = ...initialize...;
		// refToThingToCleanup is typically referenced by
		// RefObjectType instances
		RefObjectType obj = ...create object...( ... );
		tracker.trackReference( obj, refToThingToCleanup );
		return obj;
	}
}

In Peter's case, I am not sure what "thing" is the always referenced object 
whose loss of reference would trigger the cleanup.  The Threads in the 
ThreadPool stay referenced even if they are not running anything.  So, it seems 
that another thing would need to be referenced and then when that reference 
dies, the thread pool would be shutdown.

Gregg Wonderly

From peter.kovacs.1.0rc at gmail.com  Tue Jan  8 17:07:49 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 8 Jan 2008 23:07:49 +0100
Subject: [concurrency-interest] "Best practice" for ThreadPool
	creation/run-down
In-Reply-To: <22ec15240801081033w52c6dce2w96577269f2070132@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
	<22ec15240801081033w52c6dce2w96577269f2070132@mail.gmail.com>
Message-ID: <b6e8f2e80801081407w1c2a6665u656a1ceb2d10b13e@mail.gmail.com>

On Jan 8, 2008 7:33 PM, Matthias Ernst <ernst.matthias at gmail.com> wrote:
> > But there is this assimmetry which bugs me:
>
> In such a case I've always found it helpful to get rid of the implicit creation
> and  introduce symmetry: have the application initalize your API, inject
> that object where needed and tear it down after usage.

This is definitely the solution most appealing to me personally. The
reason why I am trying to find the least intrusive solution possible
is that the library already has a number of existing users, and we'd
like to introduce the performance improvements through concurrent
execution without adding to perceived complexity -- the motivation is
actually a mixture of trying to be simple and backward compatible.
Also, we have an extensive and convoluted API which makes it
challenging to find a good place for documenting such
"infrastructural" features. (Meaning that the current structure of the
documentation is poor enough to make this a challenging task. :-) [or
should I rather make a :(- ])

Thanks
Peter

>
> Matthias
>

From Online at stolsvik.com  Tue Jan  8 18:17:11 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Wed, 09 Jan 2008 00:17:11 +0100
Subject: [concurrency-interest] "Best practice" for
	ThreadPool	creation/run-down
In-Reply-To: <b6e8f2e80801081351s10237c0br2a2d6dbc9e8005c0@mail.gmail.com>
References: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>	<9f066ee90801080806g3776ba4ehd723a9aebe663fb0@mail.gmail.com>	<b6e8f2e80801080832h7a544634s82ad98886669b746@mail.gmail.com>	<b6e8f2e80801080847p710dffcdl2d92dca2ee817f9b@mail.gmail.com>	<4783BE06.2070109@mindwidgets.com>
	<b6e8f2e80801081351s10237c0br2a2d6dbc9e8005c0@mail.gmail.com>
Message-ID: <47840477.4070407@Stolsvik.com>

Peter Kovacs wrote:
> Thank you, Aaron.
> 
> I guess I'll have to read-up on the java.lang.ref package. (I kind of
> suspect that this will not work for me, because the thread pool used
> is ultimately referenced as a static variable in my library. I'll see
> if this is a problem for the PhantomReference scheme.)

Get rid of the static - library-thingies with statics in them are 
annoying, in my opinion. I'd rather like to keep a reference to your 
service-/something/, than to rely on you magically handling things using 
those dreaded memory retaining annoyances which statics are.

And I also like to be able to shut down this /something/ explicitly. I 
positively hate when java databases and message queues and what have 
you, don't let you explicitly shut then fully down. What if I want to 
implement a "reboot" algorithm - cycling the entire application as if 
the JVM terminated, and then fire it up again? (If your memory 
consumption doesn't increase after a bunch of such cycles, and you then 
are able to terminate the application without calling System.exit(x), 
chances are you have every resource under control). This goes doubly for 
the "new-style" stuff using OSGi - here modules are taken up and brought 
down all the time - and I don't like that I cannot explicitly clean up.

Furthermore, I think you should _clearly_, in bold and underline, state 
in the javadocs and docs in general that there IS such a default 
handling using a default thread pool - so that the users know that when 
using your something, a bunch of threads will in any way be created. 
Very good, though, that you provide a way for the user to provide an 
executor themselves - don't then go ahead a stick that into some static!

Finally, you could possibly have a magic clean up procedure that made it 
shut cleanly down if no one was using anymore - as a nod to those people 
that aren't quite that worried about explicit resource handling. But I 
think those reference-ideas won't guarantee that the JVM will be able to 
shut down in a timely fashion without a System.exit(): I don't think the 
JVM instantly enqueues abandoned objects - I believe this is done in the 
same fashion as with garbage collection, and we all know how what 
happens if you rely on finalization for resource shutdown, don't we? :)
   However, you can make a ThreadFactory for your default pool, which 
explicitly sets all those threads to deamon threads. (And please also 
name your threads - that makes it SO much nicer when running the 
application within a JVMTI-hooked IDE (e.g. Eclipse, when using debug 
instead of run, which I though everybody did always), and when actually 
debugging.) Then at least the JVM shutdown aspect would be fixed.

Endre.

From dcholmes at optusnet.com.au  Tue Jan  8 19:23:33 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 9 Jan 2008 10:23:33 +1000
Subject: [concurrency-interest] "Best practice" for
	ThreadPoolcreation/run-down
In-Reply-To: <b6e8f2e80801080657h7b08a026kdfaa0dd51344faba@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEAMHKAA.dcholmes@optusnet.com.au>

Peter,

I'm unclear on what the actual problem is here, is it that as the
application logically completes the idle pool is keeping the VM alive until
all the threads timeout ?

The hardest part of lifecycle management is clearly identifying the end of
the lifecycle. Daemon threads might be the answer, as Endre suggested, as
long as you can ensure that the application won't terminate while the pool
is still processing things.

Providing an explicit shutdown API is the "best practice" - you want people
to have the control they need over these things.

The next issue is whether you can provide a more responsive cleanup for
those people who don't want to clean up after themselves. This becomes
trickier and you typically have no choice but to resort to some kind of
"weak" reference scheme (as described by Gregg) or finalization scheme -
incumbent with all the issues that weak references and finalization bring to
the table. We looked at this in jsr-166 itself, where
Executors.newSingleThreadedExecutor returns an executor instance that has a
finalizer that shuts down the TPE it delegates to. But you have to be very
careful that not having a reference implies the executor is idle (you always
need a wrapper object becuase the threads in the executor keep the executor
strongly referenced) - for example given:


   Future  calculateComplexStuff() {
        Executor e = new ThreadPoolExecutor(...);
        Future result = MyFuture(e, ...);
           // result.get() returns the result and also
           // performs e.shutdown() once the result is
           // available

        // break problem into pieces p
        // for each piece do: e.execute(p);

        return result;
   }

when the reference 'e' is lost the pool is not idle and it would be very
wrong to use a custom TPE that performed shutdown() as a finalization
action.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Kovacs
> Sent: Wednesday, 9 January 2008 12:57 AM
> To: concurrency-interest
> Subject: [concurrency-interest] "Best practice" for
> ThreadPoolcreation/run-down
>
>
> Hi,
>
> I am implementing multi-threaded routines in a Java library to be used
> via Java API. By default, my library "silently" creates the ThreadPool
> it needs. (The library provides API for the user to use whatever
> Executor it wishes to override the default ThreadPool, but the point
> here is the default behavior.) The thing is that the default
> keepAliveTime of the TP is 60 seconds which is (I think) fine. As the
> application is wound down, however, the threads in the pool are
> waiting until their keepAliveTimes expire. That's is fine so far: I
> can provide a handle to shut the TP down without delay at the end of
> the application. But there is this assimmetry which bugs me: I
> silently create something which then needs to be shutdown explicitly
> by the innocent user of the API. Am I the only one to feel
> uncomfortable with this? What is recommended procedure in such cases?
>
> I've just checked that System.exit(...) doesn't wait for the thread
> pool to wind down. Does this make a difference to my problem? Can I
> rely on the application developer calling System.exit(...)?
>
> Also, does anyone have it on top their head: how does the existence of
> non-daemon threads affect the termination of an application-context in
> an application container such as Tomcat? (I. e. the case when my
> library is used in a WEB application.)
>
> Thanks a lot,
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From neal at gafter.com  Tue Jan  8 22:41:05 2008
From: neal at gafter.com (Neal Gafter)
Date: Tue, 8 Jan 2008 19:41:05 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <47836B0D.3090102@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>
	<200801071939.m07Jd036011683@cs.oswego.edu>
	<47828C0C.4090302@cs.oswego.edu> <4782BADC.8010306@univ-mlv.fr>
	<4782D113.4020101@cs.oswego.edu> <47836B0D.3090102@cs.oswego.edu>
Message-ID: <15e8b9d20801081941p53716afeobe16221342b9d966@mail.gmail.com>

On Jan 8, 2008 4:22 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> The main reason this isn't supported (yet?) is that it creates
> another combinatorial API and implementation blowup if done
> completely orthogonally, As in:
> a.withBounds(l,h).withFilter(f).withMapping(m).withCombination(b,c).max()
> (which would entail creating internal classes such as
> WithBoundedFilteredMappedCombination to maintain all the bookkeeping
> needed to flatten out the leaf computations, which is needed to
> get good parallel performance.)


One strategy for something like this is to build expression trees for
intermediate results, and then generate the top-level bytecode at runtime
just before evaluating it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080108/2f69155c/attachment.html 

From kasper at kav.dk  Wed Jan  9 14:56:54 2008
From: kasper at kav.dk (Kasper Nielsen)
Date: Wed, 09 Jan 2008 20:56:54 +0100
Subject: [concurrency-interest] Adding a createIfAbsent() API?
In-Reply-To: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
References: <6E88AC4207ED7245BA40032D5772AB6409378377@LNWEXMB25.msad.ms.com>
Message-ID: <47852706.7020402@kav.dk>

Sorry for bringing up this old discussion, but since we have Ops.Mapper 
now. Wouldn't it make sense to add

V createIfAbsent(K key, Ops.Generator<? extends V> generator)
and
V createIfAbsent(K key, Ops.Mapper<? super K, ? extends V> mapper)

to ConcurrentHashMap and ConcurrentSkipListMap

- Kasper

Rowlands, Ben (IT) wrote:
> I often find a need for an API like:
> 
>   public V createIfAbsent( K key, Callable<V> creator ) throws
> ExcecutionException
> 
> Similar in operation to putIfAbsent() but taking a callback that is used
> to resolve the value if one isn't found at at the key. 
> 

From Grace.Kwok at mscibarra.com  Wed Jan  9 16:54:42 2008
From: Grace.Kwok at mscibarra.com (Kwok, Grace (MSCIBARRA))
Date: Wed, 9 Jan 2008 16:54:42 -0500
Subject: [concurrency-interest] Question: Concurrent Memoizer pattern
	with SoftHashMap
In-Reply-To: <35AA7F4D68E917459C165ED9558B44454A15@uhclem.uhclemex.firesign.dev>
References: <35AA7F4D68E917459C165ED9558B44454A15@uhclem.uhclemex.firesign.dev>
Message-ID: <937C75B544E7E8428436C67056A3A1730586BA79@NYWEXMB83.msad.ms.com>

>>>>> You could build a Memoizer from that [google's referenceMap].
 
If I have a referenceMap with Strong key and Soft value combining with
the memoizer pattern, the soft reference will be on the FutureTask. We
would never have any hard reference to a FutureTask despite the fact
that there might be additional hard reference to the value inside the
FutureTask as it is returned. That means even if there is additional
hard reference to the value inside the FutureTask as value is returned,
the FutureTask itself (along with the value) inside the map is subject
to garbage collection. That would not be what I want. Does anyone have
suggestions of ways around it?

Thanks, Grace

> public V compute(final A arg) throws Exception{

> Future<V> f = cache.get(arg);

> if(f==null){

> Callable<V> eval = new Callable<V>(){....}

>

> FutureTask<V> ft = new FutureTask<V>(eval);

> f = cache.putIfAbsent(arg, ft);

> if(f == null){

> f = ft;

> ft.run();

> }

> }

> f.get();

> }



________________________________

From: tpeierls at gmail.com [mailto:tpeierls at gmail.com] On Behalf Of Tim
Peierls
Sent: Wednesday, November 21, 2007 11:31 AM
To: Kwok, Grace (MSCIBARRA)
Cc: Charles Fry; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Question: Concurrent Memoizer
pattern with SoftHashMap


Grace.Kwok at mscibarra.com> wrote: 


	Thanks all for the feedbacks. 
	
	1) I went to the GUICE javadoc but do not see a ReferenceCache
class 
	there. 
	http://google-guice.googlecode.com/svn/trunk/javadoc/index.html 


ReferenceCache and AbstractReferenceCache are internal classes to Guice,
but the source is available and only lightly coupled to the rest of
Guice. The maintainers said they intend to release these classes
separately, but I don't think it has happened yet. 




	
<http://google-guice.googlecode.com/svn/trunk/javadoc/index.html> I do
see a ReferenceMap class in the collections package.


You could build a Memoizer from that. 

  


	2) Are the the google collections and guice library both in
Alpha version? 
	


No, only one of them is alpha, Google Collections (0.5). Guice is 1.0. 

--tim
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080109/5444cd02/attachment.html 

From ckessel at c-cor.com  Wed Jan  9 17:16:29 2008
From: ckessel at c-cor.com (Kessel, Chris)
Date: Wed, 9 Jan 2008 14:16:29 -0800
Subject: [concurrency-interest] Strong/Soft/Weak/Phantom reference primer?
In-Reply-To: <937C75B544E7E8428436C67056A3A1730586BA79@NYWEXMB83.msad.ms.com>
References: <35AA7F4D68E917459C165ED9558B44454A15@uhclem.uhclemex.firesign.dev>
	<937C75B544E7E8428436C67056A3A1730586BA79@NYWEXMB83.msad.ms.com>
Message-ID: <865DFAF9D8383048B78645C41663939F0CA32E@beoexch1.NTSCD.C-COR.com>

The latest run of questions about the various reference types have made me realize I'm really ignorant on the subject. I've read through the javadoc on Reference, but I'm not grokking how they come into play or when you'd want to specifically create something like a WeakReference object or what you do with it.  I get hard is a direct reference, but the other flavors get fuzzy in my mind as to why 'd need them.

Does someone recommend a website for a good explanation and examples of each Reference type and the kinds of problems they solve?

Thanks,

Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080109/dadcab1a/attachment.html 

From timmyc at hotmail.com  Wed Jan  9 18:56:21 2008
From: timmyc at hotmail.com (Tim Clendenen)
Date: Wed, 9 Jan 2008 23:56:21 +0000
Subject: [concurrency-interest] Strong/Soft/Weak/Phantom reference
 primer?
Message-ID: <BAY116-W513EA67B7F5F018F1D13DC8490@phx.gbl>


http://weblogs.java.net/blog/enicholas/archive/2006/05/understanding_w.html
http://developers.sun.com/learning/javaoneonline/j1sessn.jsp?sessn=TS-2707&yr=2007&track=5

Kessel, Chris wrote:
>
> The latest run of questions about the various reference types have 
> made me realize I?m really ignorant on the subject. I?ve read through 
> the javadoc on Reference, but I?m not grokking how they come into play 
> or when you?d want to specifically create something like a 
> WeakReference object or what you do with it. I get hard is a direct 
> reference, but the other flavors get fuzzy in my mind as to why ?d 
> need them.
>
> Does someone recommend a website for a good explanation and examples 
> of each Reference type and the kinds of problems they solve?
>
> Thanks,
>
> Chris
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>   



_________________________________________________________________
Get the power of Windows + Web with the new Windows Live.
http://www.windowslive.com?ocid=TXT_TAGHM_Wave2_powerofwindows_012008
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080109/2a9c8e89/attachment.html 

From tim at peierls.net  Wed Jan  9 20:22:40 2008
From: tim at peierls.net (Tim Peierls)
Date: Wed, 9 Jan 2008 20:22:40 -0500
Subject: [concurrency-interest] Question: Concurrent Memoizer pattern
	with SoftHashMap
In-Reply-To: <937C75B544E7E8428436C67056A3A1730586BA79@NYWEXMB83.msad.ms.com>
References: <35AA7F4D68E917459C165ED9558B44454A15@uhclem.uhclemex.firesign.dev>
	<937C75B544E7E8428436C67056A3A1730586BA79@NYWEXMB83.msad.ms.com>
Message-ID: <63b4e4050801091722ie4d4eaej9d3fe48c7c82d069@mail.gmail.com>

On Jan 9, 2008 4:54 PM, Kwok, Grace (MSCIBARRA) <Grace.Kwok at mscibarra.com>
wrote:

>  >>>>> [Tim Peierls wrote:] You could build a Memoizer from that [google's
> referenceMap].
>
> f I have a referenceMap with Strong key and Soft value combining with the
> memoizer pattern, the soft reference will be on the FutureTask. We would
> never have any hard reference to a FutureTask despite the fact that there
> might be additional hard reference to the value inside the FutureTask as it
> is returned. That means even if there is additional hard reference to the
> value inside the FutureTask as value is returned, the FutureTask itself
> (along with the value) inside the map is subject to garbage collection. That
> would not be what I want. Does anyone have suggestions of ways around it?
>
I didn't mean to use ReferenceMap<K, Future<V>>. Check out the Guice
ReferenceCache classes. They are internal to Guice, but they are close to
what you want.

It would be nice if the Guice ReferenceCache stuff were part of Google
Collections, hint hint.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080109/bbc16841/attachment-0001.html 

From dl at cs.oswego.edu  Fri Jan 11 10:37:56 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 11 Jan 2008 10:37:56 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <47836B0D.3090102@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>	<200801071939.m07Jd036011683@cs.oswego.edu>	<47828C0C.4090302@cs.oswego.edu>	<4782BADC.8010306@univ-mlv.fr>
	<4782D113.4020101@cs.oswego.edu> <47836B0D.3090102@cs.oswego.edu>
Message-ID: <47878D54.1020001@cs.oswego.edu>


Courtesy of some suggestions by Josh Bloch, I'll be revamping
Ops type names in the near future. Plus incorporate new methods such as:
   WithMapping<V> withMapping(BinaryOp<T, U, V>, ParallelArray<U> other)
     (BinaryOp was "Combiner"; wildcards omitted here for clarity.)
which replaces the "combine" methods with more flexible operation
prefix support.

Sorry as always for the disruption to those of you using
this framework. Hopefully we are getting near the end of
these kinds of incompatible changes.

-Doug



From sberlin at gmail.com  Fri Jan 11 22:50:30 2008
From: sberlin at gmail.com (Sam Berlin)
Date: Fri, 11 Jan 2008 22:50:30 -0500
Subject: [concurrency-interest] Impossible Exception?
Message-ID: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>

We have a simple class that's intended to lazily load a singleton,
throwing an exception if it detects a circular construction
dependency.  However, occasionally a bug report is sent with the
exception being thrown, but the stack trace shows no sign of circular
dependency.  This is the class:

---
public abstract class AbstractLazySingletonProvider<T> implements Provider<T> {

    /** The backing object. */
    private T obj;

    /** Whether or not construction has already started. */
    private boolean constructing;

    /** Retrieves the reference, creating it if necessary. */
    public synchronized T get() {
        if(obj == null) {
            if(constructing)
                throw new IllegalStateException("constructing again!");
            constructing = true;
            obj = createObject();
        }
        return obj;
    }

    /** Creates the object this reference will use. */
    protected abstract T createObject();

}
---

It protects against concurrent access by get() being synchronized, so
another thread attempting to retrieve should block until the first one
is done.  (Yes, this could potentially create deadlocks in
multi-threaded circular access, but fortunately that isn't happening.)

This is an example stack trace we're seeing:
--
java.lang.IllegalStateException: constructing again!
    at org.limewire.concurrent.AbstractLazySingletonProvider.get(AbstractLazySingletonProvider.java:28)
    at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
    at org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(TLSNIOSocket.java:85)
    at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
    at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
    at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:17)
    at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:13)
    at org.limewire.net.LimitedSocketController.connectPlain(LimitedSocketController.java:75)
    at org.limewire.net.SimpleSocketController.connect(SimpleSocketController.java:46)
    at org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java:48)
    at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:485)
    at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:453)
    at com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConnection(ConnectionManagerImpl.java:1893)
    at com.limegroup.gnutella.ConnectionManagerImpl.access$1500(ConnectionManagerImpl.java:104)
    at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.handleEndpoint(ConnectionManagerImpl.java:2340)
    at com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java:1039)
    at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.connect(ConnectionManagerImpl.java:2285)
    at com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetchers(ConnectionManagerImpl.java:1821)
    at com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedConnection(ConnectionManagerImpl.java:1915)
    at com.limegroup.gnutella.ConnectionManagerImpl.access$1900(ConnectionManagerImpl.java:104)
    at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shutdown(ConnectionManagerImpl.java:2360)
    at com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshakeConnecter.shutdown(GnutellaConnection.java:1257)
    at org.limewire.net.LimitedSocketController$DelegateConnector.shutdown(LimitedSocketController.java:237)
    at org.limewire.nio.AbstractNBSocket.shutdownObservers(AbstractNBSocket.java:535)
    at org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java:515)
    at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
    at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
    at org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(NIODispatcher.java:989)
    at org.limewire.nio.timeout.TimeoutController.processTimeouts(TimeoutController.java:56)
    at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
    at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
    at java.lang.Thread.run(Unknown Source)
--

Can anyone explain how the exception could possibly be thrown?  It's
either something simple that I'm overlooking, or impossible
behavior... but at this point, I can't tell.

Thanks much,
 Sam

From dl at cs.oswego.edu  Sun Jan 13 19:21:07 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 13 Jan 2008 19:21:07 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <47836B0D.3090102@cs.oswego.edu>
References: <mailman.1.1199725202.4216.concurrency-interest@altair.cs.oswego.edu>	<200801071939.m07Jd036011683@cs.oswego.edu>	<47828C0C.4090302@cs.oswego.edu>	<4782BADC.8010306@univ-mlv.fr>
	<4782D113.4020101@cs.oswego.edu> <47836B0D.3090102@cs.oswego.edu>
Message-ID: <478AAAF3.60608@cs.oswego.edu>


Overhauled versions of type names, plus full cascadable binary
mappings are now in the usual places:
API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar
Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

The type naming scheme is more regular and terse. It is also
probably more useful whether or not we see any language support.
Comments welcome, although I hope not to change it much further.

As always, the path to using ParallelArray etc pleasantly is
to follow the style of the included example, giving names to
any embedded predicates and mappings used, and then doing
most of the work in only a few (usually dotted) ParallelArray expressions.
(We need more good stylistic examples to include in
javadocs; contributions welcome.)

A couple of people have argued for re-introducing Int versions.
Maybe. It would add a lot of bulk, and is not usually a big
performance win on 64bit CPUs. But sometimes is.

-Doug

From crazybob at crazybob.org  Sun Jan 13 20:42:55 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Sun, 13 Jan 2008 17:42:55 -0800
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
Message-ID: <a74683f90801131742j6fc77d46jf6ea903cec09407@mail.gmail.com>

You could try throwing NPE if createObject() returns null.

Bob

On Jan 11, 2008 7:50 PM, Sam Berlin <sberlin at gmail.com> wrote:

> We have a simple class that's intended to lazily load a singleton,
> throwing an exception if it detects a circular construction
> dependency.  However, occasionally a bug report is sent with the
> exception being thrown, but the stack trace shows no sign of circular
> dependency.  This is the class:
>
> ---
> public abstract class AbstractLazySingletonProvider<T> implements
> Provider<T> {
>
>    /** The backing object. */
>    private T obj;
>
>    /** Whether or not construction has already started. */
>    private boolean constructing;
>
>    /** Retrieves the reference, creating it if necessary. */
>    public synchronized T get() {
>        if(obj == null) {
>            if(constructing)
>                throw new IllegalStateException("constructing again!");
>            constructing = true;
>            obj = createObject();
>        }
>        return obj;
>    }
>
>    /** Creates the object this reference will use. */
>    protected abstract T createObject();
>
> }
> ---
>
> It protects against concurrent access by get() being synchronized, so
> another thread attempting to retrieve should block until the first one
> is done.  (Yes, this could potentially create deadlocks in
> multi-threaded circular access, but fortunately that isn't happening.)
>
> This is an example stack trace we're seeing:
> --
> java.lang.IllegalStateException: constructing again!
>    at org.limewire.concurrent.AbstractLazySingletonProvider.get(
> AbstractLazySingletonProvider.java:28)
>    at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
>    at org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(
> TLSNIOSocket.java:85)
>    at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
>    at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
>    at org.limewire.nio.ssl.TLSSocketFactory.createSocket(
> TLSSocketFactory.java:17)
>    at org.limewire.nio.ssl.TLSSocketFactory.createSocket(
> TLSSocketFactory.java:13)
>    at org.limewire.net.LimitedSocketController.connectPlain(
> LimitedSocketController.java:75)
>    at org.limewire.net.SimpleSocketController.connect(
> SimpleSocketController.java:46)
>    at org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java
> :48)
>    at com.limegroup.gnutella.connection.GnutellaConnection.initialize(
> GnutellaConnection.java:485)
>    at com.limegroup.gnutella.connection.GnutellaConnection.initialize(
> GnutellaConnection.java:453)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConnection(
> ConnectionManagerImpl.java:1893)
>    at com.limegroup.gnutella.ConnectionManagerImpl.access$1500(
> ConnectionManagerImpl.java:104)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.handleEndpoint
> (ConnectionManagerImpl.java:2340)
>    at com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java
> :1039)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.connect(
> ConnectionManagerImpl.java:2285)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetchers(
> ConnectionManagerImpl.java:1821)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedConnection
> (ConnectionManagerImpl.java:1915)
>    at com.limegroup.gnutella.ConnectionManagerImpl.access$1900(
> ConnectionManagerImpl.java:104)
>    at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shutdown(
> ConnectionManagerImpl.java:2360)
>    at
> com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshakeConnecter.shutdown
> (GnutellaConnection.java:1257)
>    at org.limewire.net.LimitedSocketController$DelegateConnector.shutdown(
> LimitedSocketController.java:237)
>    at org.limewire.nio.AbstractNBSocket.shutdownObservers(
> AbstractNBSocket.java:535)
>    at org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java
> :515)
>    at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
>    at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
>    at org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(
> NIODispatcher.java:989)
>    at org.limewire.nio.timeout.TimeoutController.processTimeouts(
> TimeoutController.java:56)
>    at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
>    at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
>    at java.lang.Thread.run(Unknown Source)
> --
>
> Can anyone explain how the exception could possibly be thrown?  It's
> either something simple that I'm overlooking, or impossible
> behavior... but at this point, I can't tell.
>
> Thanks much,
>  Sam
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080113/1c0b5212/attachment.html 

From crazybob at crazybob.org  Sun Jan 13 20:44:07 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Sun, 13 Jan 2008 17:44:07 -0800
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <a74683f90801131742j6fc77d46jf6ea903cec09407@mail.gmail.com>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
	<a74683f90801131742j6fc77d46jf6ea903cec09407@mail.gmail.com>
Message-ID: <a74683f90801131744r1197468alffd0b41100d54aa7@mail.gmail.com>

createObject() could also have thrown an exception.

Bob

On Jan 13, 2008 5:42 PM, Bob Lee <crazybob at crazybob.org> wrote:

> You could try throwing NPE if createObject() returns null.
>
> Bob
>
>
> On Jan 11, 2008 7:50 PM, Sam Berlin <sberlin at gmail.com> wrote:
>
> > We have a simple class that's intended to lazily load a singleton,
> > throwing an exception if it detects a circular construction
> > dependency.  However, occasionally a bug report is sent with the
> > exception being thrown, but the stack trace shows no sign of circular
> > dependency.  This is the class:
> >
> > ---
> > public abstract class AbstractLazySingletonProvider<T> implements
> > Provider<T> {
> >
> >    /** The backing object. */
> >    private T obj;
> >
> >    /** Whether or not construction has already started. */
> >    private boolean constructing;
> >
> >    /** Retrieves the reference, creating it if necessary. */
> >    public synchronized T get() {
> >        if(obj == null) {
> >            if(constructing)
> >                throw new IllegalStateException("constructing again!");
> >            constructing = true;
> >            obj = createObject();
> >        }
> >        return obj;
> >    }
> >
> >    /** Creates the object this reference will use. */
> >    protected abstract T createObject();
> >
> > }
> > ---
> >
> > It protects against concurrent access by get() being synchronized, so
> > another thread attempting to retrieve should block until the first one
> > is done.  (Yes, this could potentially create deadlocks in
> > multi-threaded circular access, but fortunately that isn't happening.)
> >
> > This is an example stack trace we're seeing:
> > --
> > java.lang.IllegalStateException: constructing again!
> >    at org.limewire.concurrent.AbstractLazySingletonProvider.get (
> > AbstractLazySingletonProvider.java:28)
> >    at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
> >    at org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(
> > TLSNIOSocket.java:85)
> >    at org.limewire.nio.NIOSocket .<init>(NIOSocket.java:57)
> >    at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
> >    at org.limewire.nio.ssl.TLSSocketFactory.createSocket(
> > TLSSocketFactory.java:17)
> >    at org.limewire.nio.ssl.TLSSocketFactory.createSocket (
> > TLSSocketFactory.java:13)
> >    at org.limewire.net.LimitedSocketController.connectPlain(
> > LimitedSocketController.java:75)
> >    at org.limewire.net.SimpleSocketController.connect(
> > SimpleSocketController.java:46)
> >    at org.limewire.net.SocketsManagerImpl.connect(
> > SocketsManagerImpl.java:48)
> >    at com.limegroup.gnutella.connection.GnutellaConnection.initialize(
> > GnutellaConnection.java:485)
> >    at com.limegroup.gnutella.connection.GnutellaConnection.initialize (
> > GnutellaConnection.java:453)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConnection
> > (ConnectionManagerImpl.java:1893)
> >    at com.limegroup.gnutella.ConnectionManagerImpl.access$1500(
> > ConnectionManagerImpl.java :104)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.handleEndpoint
> > (ConnectionManagerImpl.java:2340)
> >    at com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java
> > :1039)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.connect (
> > ConnectionManagerImpl.java:2285)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetchers(
> > ConnectionManagerImpl.java:1821)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedConnection(
> > ConnectionManagerImpl.java:1915)
> >    at com.limegroup.gnutella.ConnectionManagerImpl.access$1900(
> > ConnectionManagerImpl.java:104)
> >    at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shutdown(
> > ConnectionManagerImpl.java :2360)
> >    at
> > com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshakeConnecter.shutdown
> > (GnutellaConnection.java:1257)
> >    at
> > org.limewire.net.LimitedSocketController$DelegateConnector.shutdown(
> > LimitedSocketController.java :237)
> >    at org.limewire.nio.AbstractNBSocket.shutdownObservers(
> > AbstractNBSocket.java:535)
> >    at org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java
> > :515)
> >    at org.limewire.nio.NIODispatcher.cancel (NIODispatcher.java:403)
> >    at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
> >    at org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(
> > NIODispatcher.java:989)
> >    at org.limewire.nio.timeout.TimeoutController.processTimeouts (
> > TimeoutController.java:56)
> >    at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
> >    at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
> >    at java.lang.Thread.run(Unknown Source)
> > --
> >
> > Can anyone explain how the exception could possibly be thrown?  It's
> > either something simple that I'm overlooking, or impossible
> > behavior... but at this point, I can't tell.
> >
> > Thanks much,
> >  Sam
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080113/48254b0a/attachment-0001.html 

From dcholmes at optusnet.com.au  Sun Jan 13 20:44:56 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 14 Jan 2008 11:44:56 +1000
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEBJHKAA.dcholmes@optusnet.com.au>

Sam,

Any chance that createObject could throw an exception that's not being seen?
That would leave constructing set to true and hence cause the failure on a
second get().

Otherwise which classes call get() ?

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> Berlin
> Sent: Saturday, 12 January 2008 1:51 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Impossible Exception?
>
>
> We have a simple class that's intended to lazily load a singleton,
> throwing an exception if it detects a circular construction
> dependency.  However, occasionally a bug report is sent with the
> exception being thrown, but the stack trace shows no sign of circular
> dependency.  This is the class:
>
> ---
> public abstract class AbstractLazySingletonProvider<T> implements
> Provider<T> {
>
>     /** The backing object. */
>     private T obj;
>
>     /** Whether or not construction has already started. */
>     private boolean constructing;
>
>     /** Retrieves the reference, creating it if necessary. */
>     public synchronized T get() {
>         if(obj == null) {
>             if(constructing)
>                 throw new IllegalStateException("constructing again!");
>             constructing = true;
>             obj = createObject();
>         }
>         return obj;
>     }
>
>     /** Creates the object this reference will use. */
>     protected abstract T createObject();
>
> }
> ---
>
> It protects against concurrent access by get() being synchronized, so
> another thread attempting to retrieve should block until the first one
> is done.  (Yes, this could potentially create deadlocks in
> multi-threaded circular access, but fortunately that isn't happening.)
>
> This is an example stack trace we're seeing:
> --
> java.lang.IllegalStateException: constructing again!
>     at
> org.limewire.concurrent.AbstractLazySingletonProvider.get(Abstract
> LazySingletonProvider.java:28)
>     at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
>     at
> org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(TLSNIOSocket.java:85)
>     at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
>     at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
>     at
> org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactor
> y.java:17)
>     at
> org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactor
> y.java:13)
>     at
> org.limewire.net.LimitedSocketController.connectPlain(LimitedSocke
> tController.java:75)
>     at
> org.limewire.net.SimpleSocketController.connect(SimpleSocketContro
> ller.java:46)
>     at
> org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java:48)
>     at
> com.limegroup.gnutella.connection.GnutellaConnection.initialize(Gn
> utellaConnection.java:485)
>     at
> com.limegroup.gnutella.connection.GnutellaConnection.initialize(Gn
> utellaConnection.java:453)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConn
> ection(ConnectionManagerImpl.java:1893)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl.access$1500(Connectio
> nManagerImpl.java:104)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.han
> dleEndpoint(ConnectionManagerImpl.java:2340)
>     at
> com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java:1039)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.con
> nect(ConnectionManagerImpl.java:2285)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetch
> ers(ConnectionManagerImpl.java:1821)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedC
> onnection(ConnectionManagerImpl.java:1915)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl.access$1900(Connectio
> nManagerImpl.java:104)
>     at
> com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shu
> tdown(ConnectionManagerImpl.java:2360)
>     at
> com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshak
> eConnecter.shutdown(GnutellaConnection.java:1257)
>     at
> org.limewire.net.LimitedSocketController$DelegateConnector.shutdow
> n(LimitedSocketController.java:237)
>     at
> org.limewire.nio.AbstractNBSocket.shutdownObservers(AbstractNBSock
> et.java:535)
>     at
> org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java:515)
>     at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
>     at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
>     at
> org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(NIODispatc
> her.java:989)
>     at
> org.limewire.nio.timeout.TimeoutController.processTimeouts(Timeout
> Controller.java:56)
>     at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
>     at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
>     at java.lang.Thread.run(Unknown Source)
> --
>
> Can anyone explain how the exception could possibly be thrown?  It's
> either something simple that I'm overlooking, or impossible
> behavior... but at this point, I can't tell.
>
> Thanks much,
>  Sam
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From sberlin at gmail.com  Sun Jan 13 22:05:35 2008
From: sberlin at gmail.com (Sam Berlin)
Date: Sun, 13 Jan 2008 22:05:35 -0500
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEBJHKAA.dcholmes@optusnet.com.au>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEBJHKAA.dcholmes@optusnet.com.au>
Message-ID: <19196d860801131905y43cad6d2kb378322766c06b20@mail.gmail.com>

Wow --  Thanks very much for pointing that out, David & Bob.  We in
fact have had errors reported from constructing that singleton...  I
never thought to connect the two, but it definitely explains things.

Sorry for the list clutter!
  Sam

On Jan 13, 2008 8:44 PM, David Holmes <dcholmes at optusnet.com.au> wrote:
> Sam,
>
> Any chance that createObject could throw an exception that's not being seen?
> That would leave constructing set to true and hence cause the failure on a
> second get().
>
> Otherwise which classes call get() ?
>
> Cheers,
> David Holmes
>
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Sam
> > Berlin
> > Sent: Saturday, 12 January 2008 1:51 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Impossible Exception?
> >
> >
> > We have a simple class that's intended to lazily load a singleton,
> > throwing an exception if it detects a circular construction
> > dependency.  However, occasionally a bug report is sent with the
> > exception being thrown, but the stack trace shows no sign of circular
> > dependency.  This is the class:
> >
> > ---
> > public abstract class AbstractLazySingletonProvider<T> implements
> > Provider<T> {
> >
> >     /** The backing object. */
> >     private T obj;
> >
> >     /** Whether or not construction has already started. */
> >     private boolean constructing;
> >
> >     /** Retrieves the reference, creating it if necessary. */
> >     public synchronized T get() {
> >         if(obj == null) {
> >             if(constructing)
> >                 throw new IllegalStateException("constructing again!");
> >             constructing = true;
> >             obj = createObject();
> >         }
> >         return obj;
> >     }
> >
> >     /** Creates the object this reference will use. */
> >     protected abstract T createObject();
> >
> > }
> > ---
> >
> > It protects against concurrent access by get() being synchronized, so
> > another thread attempting to retrieve should block until the first one
> > is done.  (Yes, this could potentially create deadlocks in
> > multi-threaded circular access, but fortunately that isn't happening.)
> >
> > This is an example stack trace we're seeing:
> > --
> > java.lang.IllegalStateException: constructing again!
> >     at
> > org.limewire.concurrent.AbstractLazySingletonProvider.get(Abstract
> > LazySingletonProvider.java:28)
> >     at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
> >     at
> > org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(TLSNIOSocket.java:85)
> >     at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
> >     at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
> >     at
> > org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactor
> > y.java:17)
> >     at
> > org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactor
> > y.java:13)
> >     at
> > org.limewire.net.LimitedSocketController.connectPlain(LimitedSocke
> > tController.java:75)
> >     at
> > org.limewire.net.SimpleSocketController.connect(SimpleSocketContro
> > ller.java:46)
> >     at
> > org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java:48)
> >     at
> > com.limegroup.gnutella.connection.GnutellaConnection.initialize(Gn
> > utellaConnection.java:485)
> >     at
> > com.limegroup.gnutella.connection.GnutellaConnection.initialize(Gn
> > utellaConnection.java:453)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConn
> > ection(ConnectionManagerImpl.java:1893)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl.access$1500(Connectio
> > nManagerImpl.java:104)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.han
> > dleEndpoint(ConnectionManagerImpl.java:2340)
> >     at
> > com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java:1039)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.con
> > nect(ConnectionManagerImpl.java:2285)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetch
> > ers(ConnectionManagerImpl.java:1821)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedC
> > onnection(ConnectionManagerImpl.java:1915)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl.access$1900(Connectio
> > nManagerImpl.java:104)
> >     at
> > com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shu
>
> > tdown(ConnectionManagerImpl.java:2360)
> >     at
> > com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshak
> > eConnecter.shutdown(GnutellaConnection.java:1257)
> >     at
> > org.limewire.net.LimitedSocketController$DelegateConnector.shutdow
> > n(LimitedSocketController.java:237)
> >     at
> > org.limewire.nio.AbstractNBSocket.shutdownObservers(AbstractNBSock
> > et.java:535)
> >     at
> > org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java:515)
> >     at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
> >     at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
> >     at
> > org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(NIODispatc
> > her.java:989)
> >     at
> > org.limewire.nio.timeout.TimeoutController.processTimeouts(Timeout
> > Controller.java:56)
> >     at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
> >     at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
> >     at java.lang.Thread.run(Unknown Source)
> > --
> >
> > Can anyone explain how the exception could possibly be thrown?  It's
> > either something simple that I'm overlooking, or impossible
> > behavior... but at this point, I can't tell.
> >
> > Thanks much,
> >  Sam
>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>

From conivek at gmail.com  Mon Jan 14 08:25:34 2008
From: conivek at gmail.com (Kevin Condon)
Date: Mon, 14 Jan 2008 08:25:34 -0500
Subject: [concurrency-interest]  Impossible Exception?
Message-ID: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>

Hi Sam,

Isn't the statement "constructing = false;" missing after
createObject() is invoked?  All get() calls after the first one will
throw the exception.

Regards,
Kevin

On Jan 13, 2008 8:44 PM,  <concurrency-interest-request at cs.oswego.edu> wrote:
> ---------- Forwarded message ----------
> From: "Sam Berlin" <sberlin at gmail.com>
> To: concurrency-interest at cs.oswego.edu
> Date: Fri, 11 Jan 2008 22:50:30 -0500
> Subject: [concurrency-interest] Impossible Exception?
> We have a simple class that's intended to lazily load a singleton,
> throwing an exception if it detects a circular construction
> dependency.  However, occasionally a bug report is sent with the
> exception being thrown, but the stack trace shows no sign of circular
> dependency.  This is the class:
>
> ---
> public abstract class AbstractLazySingletonProvider<T> implements Provider<T> {
>
>     /** The backing object. */
>     private T obj;
>
>     /** Whether or not construction has already started. */
>     private boolean constructing;
>
>     /** Retrieves the reference, creating it if necessary. */
>     public synchronized T get() {
>         if(obj == null) {
>             if(constructing)
>                 throw new IllegalStateException("constructing again!");
>             constructing = true;
>             obj = createObject();
>         }
>         return obj;
>     }
>
>     /** Creates the object this reference will use. */
>     protected abstract T createObject();
>
> }
> ---
>
> It protects against concurrent access by get() being synchronized, so
> another thread attempting to retrieve should block until the first one
> is done.  (Yes, this could potentially create deadlocks in
> multi-threaded circular access, but fortunately that isn't happening.)
>
> This is an example stack trace we're seeing:
> --
> java.lang.IllegalStateException: constructing again!
>     at org.limewire.concurrent.AbstractLazySingletonProvider.get(AbstractLazySingletonProvider.java:28)
>     at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
>     at org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(TLSNIOSocket.java:85)
>     at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
>     at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
>     at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:17)
>     at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:13)
>     at org.limewire.net.LimitedSocketController.connectPlain(LimitedSocketController.java:75)
>     at org.limewire.net.SimpleSocketController.connect(SimpleSocketController.java:46)
>     at org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java:48)
>     at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:485)
>     at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:453)
>     at com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConnection(ConnectionManagerImpl.java:1893)
>     at com.limegroup.gnutella.ConnectionManagerImpl.access$1500(ConnectionManagerImpl.java:104)
>     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.handleEndpoint(ConnectionManagerImpl.java:2340)
>     at com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java:1039)
>     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.connect(ConnectionManagerImpl.java:2285)
>     at com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetchers(ConnectionManagerImpl.java:1821)
>     at com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedConnection(ConnectionManagerImpl.java:1915)
>     at com.limegroup.gnutella.ConnectionManagerImpl.access$1900(ConnectionManagerImpl.java:104)
>     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shutdown(ConnectionManagerImpl.java:2360)
>     at com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshakeConnecter.shutdown(GnutellaConnection.java:1257)
>     at org.limewire.net.LimitedSocketController$DelegateConnector.shutdown(LimitedSocketController.java:237)
>     at org.limewire.nio.AbstractNBSocket.shutdownObservers(AbstractNBSocket.java:535)
>     at org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java:515)
>     at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
>     at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
>     at org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(NIODispatcher.java:989)
>     at org.limewire.nio.timeout.TimeoutController.processTimeouts(TimeoutController.java:56)
>     at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
>     at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
>     at java.lang.Thread.run(Unknown Source)
> --
>
> Can anyone explain how the exception could possibly be thrown?  It's
> either something simple that I'm overlooking, or impossible
> behavior... but at this point, I can't tell.
>
> Thanks much,
>  Sam

From Thomas.Hawtin at Sun.COM  Mon Jan 14 08:56:31 2008
From: Thomas.Hawtin at Sun.COM (Thomas Hawtin)
Date: Mon, 14 Jan 2008 13:56:31 +0000
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
Message-ID: <478B6A0F.6030707@Sun.COM>

Sam Berlin wrote:
> 
>     /** Retrieves the reference, creating it if necessary. */
>     public synchronized T get() {
>         if(obj == null) {
>             if(constructing)
>                 throw new IllegalStateException("constructing again!");
>             constructing = true;
>             obj = createObject();
>         }
>         return obj;
>     }

In addition to exceptions from createObject there is another way that it 
is possible for the IllegalStateException to be thrown. because the lock 
is reentrant, createObject could call get. Alternatively createObject 
could wait on the lock, and another thread could then enter the method. 
More "unlikely", a subclass could implement Cloneable, createObject or 
another thread could then clone.

Tom Hawtin

From conivek at gmail.com  Mon Jan 14 09:21:19 2008
From: conivek at gmail.com (Kevin Condon)
Date: Mon, 14 Jan 2008 09:21:19 -0500
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
References: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
Message-ID: <2e780ac60801140621w73d9ca77o4ed2d19fd49eb36e@mail.gmail.com>

Oops, a colleague just pointed out that I missed the "obj == null"
check.  Never mind.

Kevin

On Jan 14, 2008 8:25 AM, Kevin Condon <conivek at gmail.com> wrote:
> Hi Sam,
>
> Isn't the statement "constructing = false;" missing after
> createObject() is invoked?  All get() calls after the first one will
> throw the exception.
>
> Regards,
> Kevin
>
> On Jan 13, 2008 8:44 PM,  <concurrency-interest-request at cs.oswego.edu> wrote:
> > ---------- Forwarded message ----------
> > From: "Sam Berlin" <sberlin at gmail.com>
> > To: concurrency-interest at cs.oswego.edu
> > Date: Fri, 11 Jan 2008 22:50:30 -0500
> > Subject: [concurrency-interest] Impossible Exception?
> > We have a simple class that's intended to lazily load a singleton,
> > throwing an exception if it detects a circular construction
> > dependency.  However, occasionally a bug report is sent with the
> > exception being thrown, but the stack trace shows no sign of circular
> > dependency.  This is the class:
> >
> > ---
> > public abstract class AbstractLazySingletonProvider<T> implements Provider<T> {
> >
> >     /** The backing object. */
> >     private T obj;
> >
> >     /** Whether or not construction has already started. */
> >     private boolean constructing;
> >
> >     /** Retrieves the reference, creating it if necessary. */
> >     public synchronized T get() {
> >         if(obj == null) {
> >             if(constructing)
> >                 throw new IllegalStateException("constructing again!");
> >             constructing = true;
> >             obj = createObject();
> >         }
> >         return obj;
> >     }
> >
> >     /** Creates the object this reference will use. */
> >     protected abstract T createObject();
> >
> > }
> > ---
> >
> > It protects against concurrent access by get() being synchronized, so
> > another thread attempting to retrieve should block until the first one
> > is done.  (Yes, this could potentially create deadlocks in
> > multi-threaded circular access, but fortunately that isn't happening.)
> >
> > This is an example stack trace we're seeing:
> > --
> > java.lang.IllegalStateException: constructing again!
> >     at org.limewire.concurrent.AbstractLazySingletonProvider.get(AbstractLazySingletonProvider.java:28)
> >     at org.limewire.nio.ssl.SSLUtils.getTLSContext(SSLUtils.java:56)
> >     at org.limewire.nio.ssl.TLSNIOSocket.initOutgoingSocket(TLSNIOSocket.java:85)
> >     at org.limewire.nio.NIOSocket.<init>(NIOSocket.java:57)
> >     at org.limewire.nio.ssl.TLSNIOSocket.<init>(TLSNIOSocket.java:45)
> >     at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:17)
> >     at org.limewire.nio.ssl.TLSSocketFactory.createSocket(TLSSocketFactory.java:13)
> >     at org.limewire.net.LimitedSocketController.connectPlain(LimitedSocketController.java:75)
> >     at org.limewire.net.SimpleSocketController.connect(SimpleSocketController.java:46)
> >     at org.limewire.net.SocketsManagerImpl.connect(SocketsManagerImpl.java:48)
> >     at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:485)
> >     at com.limegroup.gnutella.connection.GnutellaConnection.initialize(GnutellaConnection.java:453)
> >     at com.limegroup.gnutella.ConnectionManagerImpl.initializeFetchedConnection(ConnectionManagerImpl.java:1893)
> >     at com.limegroup.gnutella.ConnectionManagerImpl.access$1500(ConnectionManagerImpl.java:104)
> >     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.handleEndpoint(ConnectionManagerImpl.java:2340)
> >     at com.limegroup.gnutella.HostCatcher.getAnEndpoint(HostCatcher.java:1039)
> >     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.connect(ConnectionManagerImpl.java:2285)
> >     at com.limegroup.gnutella.ConnectionManagerImpl.adjustConnectionFetchers(ConnectionManagerImpl.java:1821)
> >     at com.limegroup.gnutella.ConnectionManagerImpl.cleanupBrokenFetchedConnection(ConnectionManagerImpl.java:1915)
> >     at com.limegroup.gnutella.ConnectionManagerImpl.access$1900(ConnectionManagerImpl.java:104)
> >     at com.limegroup.gnutella.ConnectionManagerImpl$ConnectionFetcher.shutdown(ConnectionManagerImpl.java:2360)
> >     at com.limegroup.gnutella.connection.GnutellaConnection$AsyncHandshakeConnecter.shutdown(GnutellaConnection.java:1257)
> >     at org.limewire.net.LimitedSocketController$DelegateConnector.shutdown(LimitedSocketController.java:237)
> >     at org.limewire.nio.AbstractNBSocket.shutdownObservers(AbstractNBSocket.java:535)
> >     at org.limewire.nio.AbstractNBSocket.shutdown(AbstractNBSocket.java:515)
> >     at org.limewire.nio.NIODispatcher.cancel(NIODispatcher.java:403)
> >     at org.limewire.nio.NIODispatcher.access$1000(NIODispatcher.java:93)
> >     at org.limewire.nio.NIODispatcher$Attachment.notifyTimeout(NIODispatcher.java:989)
> >     at org.limewire.nio.timeout.TimeoutController.processTimeouts(TimeoutController.java:56)
> >     at org.limewire.nio.NIODispatcher.process(NIODispatcher.java:656)
> >     at org.limewire.nio.NIODispatcher.run(NIODispatcher.java:867)
> >     at java.lang.Thread.run(Unknown Source)
> > --
> >
> > Can anyone explain how the exception could possibly be thrown?  It's
> > either something simple that I'm overlooking, or impossible
> > behavior... but at this point, I can't tell.
> >
> > Thanks much,
> >  Sam
>

From gregg at cytetech.com  Mon Jan 14 10:01:22 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 14 Jan 2008 09:01:22 -0600
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <19196d860801131905y43cad6d2kb378322766c06b20@mail.gmail.com>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEBJHKAA.dcholmes@optusnet.com.au>
	<19196d860801131905y43cad6d2kb378322766c06b20@mail.gmail.com>
Message-ID: <478B7942.5090904@cytetech.com>

Sam Berlin wrote:
> Wow --  Thanks very much for pointing that out, David & Bob.  We in
> fact have had errors reported from constructing that singleton...  I
> never thought to connect the two, but it definitely explains things.

There is also a path if createObject() recursively enters get() it seems to me.
But it sounds like that path wouldn't happen.

Gregg Wonderly

From sberlin at gmail.com  Mon Jan 14 10:04:28 2008
From: sberlin at gmail.com (Sam Berlin)
Date: Mon, 14 Jan 2008 10:04:28 -0500
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <478B7942.5090904@cytetech.com>
References: <19196d860801111950q4a339423g83c7214ad007a8df@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCKEBJHKAA.dcholmes@optusnet.com.au>
	<19196d860801131905y43cad6d2kb378322766c06b20@mail.gmail.com>
	<478B7942.5090904@cytetech.com>
Message-ID: <19196d860801140704s36864b46u96a564e77758d120@mail.gmail.com>

Yes, this is exactly what the check is intended for (essentially a
circular dependency).  That's why the stack trace threw me for a loop
-- if it was recursively enterring get, it would have appeared in the
trace.

Sam

On Jan 14, 2008 10:01 AM, Gregg Wonderly <gregg at cytetech.com> wrote:
> Sam Berlin wrote:
> > Wow --  Thanks very much for pointing that out, David & Bob.  We in
> > fact have had errors reported from constructing that singleton...  I
> > never thought to connect the two, but it definitely explains things.
>
> There is also a path if createObject() recursively enters get() it seems to me.
> But it sounds like that path wouldn't happen.
>
> Gregg Wonderly
>

From Thomas.Hawtin at Sun.COM  Mon Jan 14 10:25:00 2008
From: Thomas.Hawtin at Sun.COM (Thomas Hawtin)
Date: Mon, 14 Jan 2008 15:25:00 +0000
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
References: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
Message-ID: <478B7ECC.6050301@Sun.COM>

Kevin Condon wrote:
> 
> Isn't the statement "constructing = false;" missing after
> createObject() is invoked?  All get() calls after the first one will
> throw the exception.

No, the test "obj == null" should be false after a successful 
initialisation and therefore "constructing" will not be read.

Tom Hawtin

> On Jan 13, 2008 8:44 PM,  <concurrency-interest-request at cs.oswego.edu> wrote:
>> ---------- Forwarded message ----------
>> From: "Sam Berlin" <sberlin at gmail.com>
>> [...]
>>         if(obj == null) {
>>             if(constructing)
>>                 throw new IllegalStateException("constructing again!");
>>             constructing = true;
>>             obj = createObject();
>>         }

From joe.bowbeer at gmail.com  Mon Jan 14 11:44:01 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 14 Jan 2008 08:44:01 -0800
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <478B7ECC.6050301@Sun.COM>
References: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
	<478B7ECC.6050301@Sun.COM>
Message-ID: <31f2a7bd0801140844j60a4da1cp9bcf150cebbd1751@mail.gmail.com>

constructing could/should be reset if obj is not created:

  constructing = true;
  try {
    obj = createObject();
  } finally {
    if (obj != null)
      constructing = false;
  }

Though I suspect constructing was only added was to investigate this case of
the missing exception...

On Jan 14, 2008 7:25 AM, Thomas Hawtin <Thomas.Hawtin at sun.com> wrote:

> Kevin Condon wrote:
> >
> > Isn't the statement "constructing = false;" missing after
> > createObject() is invoked?  All get() calls after the first one will
> > throw the exception.
>
> No, the test "obj == null" should be false after a successful
> initialisation and therefore "constructing" will not be read.
>
> Tom Hawtin
>
> > On Jan 13, 2008 8:44 PM,  <concurrency-interest-request at cs.oswego.edu>
> wrote:
> >> ---------- Forwarded message ----------
> >> From: "Sam Berlin" <sberlin at gmail.com>
> >> [...]
> >>         if(obj == null) {
> >>             if(constructing)
> >>                 throw new IllegalStateException("constructing again!");
> >>             constructing = true;
> >>             obj = createObject();
> >>         }
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080114/c3b1ebb2/attachment.html 

From joe.bowbeer at gmail.com  Mon Jan 14 11:47:00 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 14 Jan 2008 08:47:00 -0800
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <31f2a7bd0801140844j60a4da1cp9bcf150cebbd1751@mail.gmail.com>
References: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
	<478B7ECC.6050301@Sun.COM>
	<31f2a7bd0801140844j60a4da1cp9bcf150cebbd1751@mail.gmail.com>
Message-ID: <31f2a7bd0801140847n585cdf56x20935d8bac9c72fa@mail.gmail.com>

Err..

constructing could/should be reset if obj is *not* created:

  constructing = true;
  try {
    obj = createObject();
  } finally {
    if (obj == null)
      constructing = false;
  }

Or simply:

  constructing = true;
  try {
    obj = createObject();
  } finally {
    constructing = false;
  }


On Jan 14, 2008 8:44 AM, Joe Bowbeer wrote:

> constructing could/should be reset if obj is not created:
>
>   constructing = true;
>   try {
>     obj = createObject();
>   } finally {
>     if (obj != null)
>       constructing = false;
>   }
>
> Though I suspect constructing was only added was to investigate this case
> of the missing exception...
>
>
> On Jan 14, 2008 7:25 AM, Thomas Hawtin <Thomas.Hawtin at sun.com> wrote:
>
> > Kevin Condon wrote:
> > >
> > > Isn't the statement "constructing = false;" missing after
> > > createObject() is invoked?  All get() calls after the first one will
> > > throw the exception.
> >
> > No, the test "obj == null" should be false after a successful
> > initialisation and therefore "constructing" will not be read.
> >
> > Tom Hawtin
> >
> > > On Jan 13, 2008 8:44 PM,  < concurrency-interest-request at cs.oswego.edu>
> > wrote:
> > >> ---------- Forwarded message ----------
> > >> From: "Sam Berlin" < sberlin at gmail.com>
> > >> [...]
> > >>         if(obj == null) {
> > >>             if(constructing)
> > >>                 throw new IllegalStateException("constructing
> > again!");
> > >>             constructing = true;
> > >>             obj = createObject();
> > >>         }
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080114/5f2b4b4d/attachment.html 

From sberlin at gmail.com  Mon Jan 14 12:15:42 2008
From: sberlin at gmail.com (Sam Berlin)
Date: Mon, 14 Jan 2008 12:15:42 -0500
Subject: [concurrency-interest] Impossible Exception?
In-Reply-To: <31f2a7bd0801140847n585cdf56x20935d8bac9c72fa@mail.gmail.com>
References: <2e780ac60801140525o11619f76l2a3fbabd8d160a37@mail.gmail.com>
	<478B7ECC.6050301@Sun.COM>
	<31f2a7bd0801140844j60a4da1cp9bcf150cebbd1751@mail.gmail.com>
	<31f2a7bd0801140847n585cdf56x20935d8bac9c72fa@mail.gmail.com>
Message-ID: <19196d860801140915p3201f28fk8185472696d499c0@mail.gmail.com>

This would defeat the 'singleton' purpose. :-)

Thanks very much to everyone for their tips & pointers.

We'll likely fix this one by catching exceptions thrown from
createObject and rethrowing a new exception upon later gets.

Sam

On 1/14/08, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Err..
>
> constructing could/should be reset if obj is *not* created:
>
>   constructing = true;
>   try {
>     obj = createObject();
>   } finally {
>     if (obj == null)
>       constructing = false;
>   }
>
> Or simply:
>
>   constructing = true;
>   try {
>     obj = createObject();
>   } finally {
>     constructing = false;
>
>   }
>
>
> On Jan 14, 2008 8:44 AM, Joe Bowbeer wrote:
> > constructing could/should be reset if obj is not created:
> >
> >   constructing = true;
> >   try {
> >     obj = createObject();
> >   } finally {
> >     if (obj != null)
> >       constructing = false;
> >   }
> >
> > Though I suspect constructing was only added was to investigate this case
> of the missing exception...
> >
> >
> >
> >
> >
> > On Jan 14, 2008 7:25 AM, Thomas Hawtin <Thomas.Hawtin at sun.com> wrote:
> >
> > >
> > > Kevin Condon wrote:
> > > >
> > > > Isn't the statement "constructing = false;" missing after
> > > > createObject() is invoked?  All get() calls after the first one will
> > > > throw the exception.
> > >
> > > No, the test "obj == null" should be false after a successful
> > > initialisation and therefore "constructing" will not be read.
> > >
> > > Tom Hawtin
> > >
> > >
> > > > On Jan 13, 2008 8:44 PM,  <
> concurrency-interest-request at cs.oswego.edu> wrote:
> > > >> ---------- Forwarded message ----------
> > > >> From: "Sam Berlin" < sberlin at gmail.com>
> > >
> > > >> [...]
> > > >>         if(obj == null) {
> > > >>             if(constructing)
> > > >>                 throw new
> IllegalStateException("constructing again!");
> > > >>             constructing = true;
> > > >>             obj = createObject();
> > > >>         }
> > >
> >
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From David.Biesack at sas.com  Mon Jan 14 17:15:39 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 14 Jan 2008 17:15:39 -0500 (EST)
Subject: [concurrency-interest] Ops type names
In-Reply-To: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <200801142215.m0EMFdED002211@cs.oswego.edu>


> Date: Fri, 11 Jan 2008 10:37:56 -0500
> From: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] Ops type names
> To: concurrency-interest at cs.oswego.edu
> 
> Courtesy of some suggestions by Josh Bloch, I'll be revamping
> Ops type names in the near future. Plus incorporate new methods such as:
>    WithMapping<V> withMapping(BinaryOp<T, U, V>, ParallelArray<U> other)
>      (BinaryOp was "Combiner"; wildcards omitted here for clarity.)
> which replaces the "combine" methods with more flexible operation
> prefix support.
> 
> Sorry as always for the disruption to those of you using
> this framework. Hopefully we are getting near the end of
> these kinds of incompatible changes.
> 
> -Doug
 
While in general I find the new naming scheme to be a big improvement,
and I like the generic types names A (argument) and R (result)
over the previous non-mnemonic names or the F/T (from/to) names I
posted earlier, it pains me to say I have a small disagreement with one 
part of the new names. I think there is still inconsistency that can 
be removed.

While we have

  Ops.IntToDouble :: double op(int a) 
  Ops.IntToLong   :: long op(int a) 
  Ops.IntToObject :: R op(int a) 
and
  Ops.ObjectToInt :: int op(A a) 

there is

  Ops.IntOp ::  int op(int a) 
 
which, to me, sticks out like a sore thumb. I contend that 

  Ops.IntToInt ::  int op(int a) 

would be more consistent in the long run.
(Similarly for DoubleOp => DoubleToDouble, LongOp => LongToLong.)

I think diverging from the {arg-types}To{result-type} pattern will
cause a lot of confusion down the road. The name IntOp just does
not indicate whether the argument or the result type is int,
and the fact that its both does not really help.

[Side note: At first, I thought

  Ops.Op :: R op(A a) 
  Ops.BinaryOp :: R op(A a, B b) 

should become

  Ops.ObjectToObject :: R op(A a) 
  Ops.ObjectAndObjectToObject :: R op(A a)

to further enforce consisteny, but after thinking more, 
I agree with the names Ops.Op/Ops.BinaryOp Yes, I realize
that I'm being inconsistent!]

Humbly,
  djb

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From neal at gafter.com  Mon Jan 14 18:59:07 2008
From: neal at gafter.com (Neal Gafter)
Date: Mon, 14 Jan 2008 15:59:07 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <200801142215.m0EMFdED002211@cs.oswego.edu>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
Message-ID: <15e8b9d20801141559t2b39a2efsedd5cb3970d4aa80@mail.gmail.com>

On Jan 14, 2008 2:15 PM, David J. Biesack <David.Biesack at sas.com> wrote:

>
> > Date: Fri, 11 Jan 2008 10:37:56 -0500
> > From: Doug Lea <dl at cs.oswego.edu>
> > Subject: Re: [concurrency-interest] Ops type names
> > To: concurrency-interest at cs.oswego.edu
> >
> > Courtesy of some suggestions by Josh Bloch, I'll be revamping
> > Ops type names in the near future. Plus incorporate new methods such as:
> >    WithMapping<V> withMapping(BinaryOp<T, U, V>, ParallelArray<U> other)
> >      (BinaryOp was "Combiner"; wildcards omitted here for clarity.)
> > which replaces the "combine" methods with more flexible operation
> > prefix support.
> >
> > Sorry as always for the disruption to those of you using
> > this framework. Hopefully we are getting near the end of
> > these kinds of incompatible changes.
> >
> > -Doug
>
> While in general I find the new naming scheme to be a big improvement,
> and I like the generic types names A (argument) and R (result)
> over the previous non-mnemonic names or the F/T (from/to) names I
> posted earlier, it pains me to say I have a small disagreement with one
> part of the new names. I think there is still inconsistency that can
> be removed.
>
> While we have
>
>  Ops.IntToDouble :: double op(int a)
>  Ops.IntToLong   :: long op(int a)
>  Ops.IntToObject :: R op(int a)
> and
>  Ops.ObjectToInt :: int op(A a)
>
> there is
>
>  Ops.IntOp ::  int op(int a)
>
> which, to me, sticks out like a sore thumb. I contend that
>
>  Ops.IntToInt ::  int op(int a)
>
> would be more consistent in the long run.
> (Similarly for DoubleOp => DoubleToDouble, LongOp => LongToLong.)
>
> I think diverging from the {arg-types}To{result-type} pattern will
> cause a lot of confusion down the road. The name IntOp just does
> not indicate whether the argument or the result type is int,
> and the fact that its both does not really help.
>
> [Side note: At first, I thought
>
>  Ops.Op :: R op(A a)
>  Ops.BinaryOp :: R op(A a, B b)
>
> should become
>
>  Ops.ObjectToObject :: R op(A a)
>  Ops.ObjectAndObjectToObject :: R op(A a)
>
> to further enforce consisteny, but after thinking more,
> I agree with the names Ops.Op/Ops.BinaryOp Yes, I realize
> that I'm being inconsistent!]


I wonder if we could provide some sort of small language extension to make
these names easier to remember, write, and read. So, for example, instead of
making people write

Ops.ObjectAndIntToObject<? Super String, ? extends Student>

we could allow them to alternatively indicate the type by writing some
syntax like

{ String, int => Student }
 or
( String, int ) => Student

-Neal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080114/bff777b0/attachment.html 

From dl at cs.oswego.edu  Mon Jan 14 19:07:46 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 14 Jan 2008 19:07:46 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <200801142215.m0EMFdED002211@cs.oswego.edu>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
Message-ID: <478BF952.20301@cs.oswego.edu>

David J. Biesack wrote:
> it pains me to say I have a small disagreement with one 
> part of the new names. I think there is still inconsistency that can 
> be removed.
> 
> While we have
> 
>   Ops.IntToDouble :: double op(int a) 
>   Ops.IntToLong   :: long op(int a) 
>   Ops.IntToObject :: R op(int a) 
> and
>   Ops.ObjectToInt :: int op(A a) 
> 
> there is
> 
>   Ops.IntOp ::  int op(int a) 
>  
> which, to me, sticks out like a sore thumb. I contend that 
> 
>   Ops.IntToInt ::  int op(int a) 
> 
> would be more consistent in the long run.
> (Similarly for DoubleOp => DoubleToDouble, LongOp => LongToLong.)
> 
> I think diverging from the {arg-types}To{result-type} pattern will
> cause a lot of confusion down the road. The name IntOp just does
> not indicate whether the argument or the result type is int,
> and the fact that its both does not really help.
> 
> [Side note: At first, I thought
> 
>   Ops.Op :: R op(A a) 
>   Ops.BinaryOp :: R op(A a, B b) 
> 
> should become
> 
>   Ops.ObjectToObject :: R op(A a) 
>   Ops.ObjectAndObjectToObject :: R op(A a)
> 
> to further enforce consisteny, but after thinking more, 
> I agree with the names Ops.Op/Ops.BinaryOp Yes, I realize
> that I'm being inconsistent!]
> 

Yes, and this is exactly the line of thought that led to IntOp
and BinaryIntOp -- that is, which of these patterns should the
simplest and by far most common scalar cases conform to?
It could go either way, but for these common ones,
better-sounding-ness seems to win out.

Since it could go either way though, if enough others agree
with you, I'd be happy to change them.

-Doug

From josh at bloch.us  Mon Jan 14 19:53:07 2008
From: josh at bloch.us (Joshua Bloch)
Date: Mon, 14 Jan 2008 16:53:07 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <200801142215.m0EMFdED002211@cs.oswego.edu>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
Message-ID: <b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>

David,

Hi.  I understand your desire consistency.  That said, I was inconsistent
"with my eyes open."  Worse, I violated the norms in mathematics.  When a
mathematician speaks of a real-function, he speaks of the range (result
type), irrespective of the domain.  That said, when it comes to designing
APIs, I like to take the nice, short names for the common cases, and I
believe that the case of functions whose range and domain types are the same
will predominate (whether it's int-to-int, long-to-long, or
double-to-double).  So, I stole the nice names for the common homogeneous
function types.

         Josh

On Jan 14, 2008 2:15 PM, David J. Biesack <David.Biesack at sas.com> wrote:

>
> > Date: Fri, 11 Jan 2008 10:37:56 -0500
> > From: Doug Lea < dl at cs.oswego.edu>
> > Subject: Re: [concurrency-interest] Ops type names
> > To: concurrency-interest at cs.oswego.edu
> >
> > Courtesy of some suggestions by Josh Bloch, I'll be revamping
> > Ops type names in the near future. Plus incorporate new methods such as:
> >    WithMapping<V> withMapping(BinaryOp<T, U, V>, ParallelArray<U> other)
>
> >      (BinaryOp was "Combiner"; wildcards omitted here for clarity.)
> > which replaces the "combine" methods with more flexible operation
> > prefix support.
> >
> > Sorry as always for the disruption to those of you using
> > this framework. Hopefully we are getting near the end of
> > these kinds of incompatible changes.
> >
> > -Doug
>
> While in general I find the new naming scheme to be a big improvement,
> and I like the generic types names A (argument) and R (result)
> over the previous non-mnemonic names or the F/T (from/to) names I
> posted earlier, it pains me to say I have a small disagreement with one
> part of the new names. I think there is still inconsistency that can
> be removed.
>
> While we have
>
>  Ops.IntToDouble :: double op(int a)
>  Ops.IntToLong   :: long op(int a)
>  Ops.IntToObject :: R op(int a)
> and
>  Ops.ObjectToInt :: int op(A a)
>
> there is
>
>  Ops.IntOp ::  int op(int a)
>
> which, to me, sticks out like a sore thumb. I contend that
>
>  Ops.IntToInt ::  int op(int a)
>
> would be more consistent in the long run.
> (Similarly for DoubleOp => DoubleToDouble, LongOp => LongToLong.)
>
> I think diverging from the {arg-types}To{result-type} pattern will
> cause a lot of confusion down the road. The name IntOp just does
> not indicate whether the argument or the result type is int,
> and the fact that its both does not really help.
>
> [Side note: At first, I thought
>
>  Ops.Op :: R op(A a)
>  Ops.BinaryOp :: R op(A a, B b)
>
> should become
>
>  Ops.ObjectToObject :: R op(A a)
>  Ops.ObjectAndObjectToObject :: R op(A a)
>
> to further enforce consisteny, but after thinking more,
> I agree with the names Ops.Op/Ops.BinaryOp Yes, I realize
> that I'm being inconsistent!]
>
> Humbly,
>  djb
>
> --
> David J. Biesack     SAS Institute Inc.
> (919) 531-7771       SAS Campus Drive
> http://www.sas.com   Cary, NC 27513
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080114/303649bc/attachment.html 

From dl at cs.oswego.edu  Tue Jan 15 08:50:31 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 15 Jan 2008 08:50:31 -0500
Subject: [concurrency-interest] Ops type names
In-Reply-To: <15e8b9d20801141559t2b39a2efsedd5cb3970d4aa80@mail.gmail.com>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<15e8b9d20801141559t2b39a2efsedd5cb3970d4aa80@mail.gmail.com>
Message-ID: <478CBA27.4050703@cs.oswego.edu>

Neal Gafter wrote:
> I wonder if we could provide some sort of small language extension to 
> make these names easier to remember, write, and read. So, for example, 
> instead of making people write
> 
> Ops.ObjectAndIntToObject<? Super String, ? extends Student>
> 
> we could allow them to alternatively indicate the type by writing some 
> syntax like
> 
> { String, int => Student }
> or
> ( String, int ) => Student
> 

Note to others: I assume you are all keeping up with the various
controversies about closure and function type syntax. If for some
reason you've been hiding in a cave and don't know what this
is about, see Neal's blog http://gafter.blogspot.com/ among
too many other places.

What many of you don't know though is that discussions
with Neal, Josh, and others of my initial plans for parallel
APIs (including ParallelArray) two years ago were among the main
instigators in creating all this controversy. As we continue
to get components into usable form, and some of you use them,
opinions based on real experience are among the most valuable
inputs when making decisions about language changes.
I encourage those of you using this stuff to participate in
these discussions. (Although probably best in blogs, blog
comments, or discussions elsewhere, not usually on this
concurrency-interest list unless it has something to do
with the concurrency aspects themselves.)

-Doug


From gergg at cox.net  Tue Jan 15 11:06:17 2008
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 15 Jan 2008 10:06:17 -0600
Subject: [concurrency-interest] Ops type names
In-Reply-To: <b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
Message-ID: <478CD9F9.8060609@cox.net>

Joshua Bloch wrote:
> Hi.  I understand your desire consistency.  That said, I was 
> inconsistent "with my eyes open."  Worse, I violated the norms in 
> mathematics.  When a mathematician speaks of a real-function, he speaks 
> of the range (result type), irrespective of the domain.  That said, when 
> it comes to designing APIs, I like to take the nice, short names for the 
> common cases, and I believe that the case of functions whose range and 
> domain types are the same will predominate (whether it's int-to-int, 
> long-to-long, or double-to-double).  So, I stole the nice names for the 
> common homogeneous function types.

Is there any useful readability gains from using more prepositional words like 
"with" or "on" instead of "Op", as in

onInt( 42 ).onInt( doubleToInt( 45.0 ) )

or

withInt( 42 ).withInt( doubleToInt( 45.0 ) )

since "to" is already prepositional in english?

Gregg Wonderly

From josh at bloch.us  Tue Jan 15 11:12:10 2008
From: josh at bloch.us (Joshua Bloch)
Date: Tue, 15 Jan 2008 08:12:10 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <478CD9F9.8060609@cox.net>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
Message-ID: <b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>

Gregg,

Hmmm... the onInt and withInt don't really feel right to me.  If people
don't like intOp (or intFn), then I think we should go with David's
inclination (intToInt).

          Josh

On Jan 15, 2008 8:06 AM, Gregg Wonderly <gergg at cox.net> wrote:

> Joshua Bloch wrote:
> > Hi.  I understand your desire consistency.  That said, I was
> > inconsistent "with my eyes open."  Worse, I violated the norms in
> > mathematics.  When a mathematician speaks of a real-function, he speaks
> > of the range (result type), irrespective of the domain.  That said, when
> > it comes to designing APIs, I like to take the nice, short names for the
> > common cases, and I believe that the case of functions whose range and
> > domain types are the same will predominate (whether it's int-to-int,
> > long-to-long, or double-to-double).  So, I stole the nice names for the
> > common homogeneous function types.
>
> Is there any useful readability gains from using more prepositional words
> like
> "with" or "on" instead of "Op", as in
>
> onInt( 42 ).onInt( doubleToInt( 45.0 ) )
>
> or
>
> withInt( 42 ).withInt( doubleToInt( 45.0 ) )
>
> since "to" is already prepositional in english?
>
> Gregg Wonderly
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080115/e68f5726/attachment.html 

From David.Biesack at sas.com  Tue Jan 15 15:38:17 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 15 Jan 2008 15:38:17 -0500 (EST)
Subject: [concurrency-interest] Ops type names
In-Reply-To: <b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
	(josh@bloch.us)
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
Message-ID: <200801152038.m0FKcH2U002143@cs.oswego.edu>


I too am torn between usability and consistency; I certainly
see both sides of the issue. (I agree onInt or withInt don't
seem to fit, either.)

Just to get a high level view for the Ops.* API, one can see the layout at
 
  http://spreadsheets.google.com/ccc?key=pAoqbvjWjniKlWCMhVnW-ZA&hl=en

There, I highlighted the names which do not follow the pattern.

A table such as this (other layouts may be better) may be a nice addition
to the Javadoc. (For compactness, I left off the Ops. prefix.)

> Date: Tue, 15 Jan 2008 08:12:10 -0800
> From: "Joshua Bloch" <josh at bloch.us>
> 
> Gregg,
> 
> Hmmm... the onInt and withInt don't really feel right to me.  If people
> don't like intOp (or intFn), then I think we should go with David's
> inclination (intToInt).
> 
>           Josh

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From josh at bloch.us  Tue Jan 15 15:52:25 2008
From: josh at bloch.us (Joshua Bloch)
Date: Tue, 15 Jan 2008 12:52:25 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <200801152038.m0FKcH2U002143@cs.oswego.edu>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
	<200801152038.m0FKcH2U002143@cs.oswego.edu>
Message-ID: <b097ac510801151252s766783cej47210d00404d3ed7@mail.gmail.com>

David,

Thanks.  I agree that such a table would look nice in the JavaDoc.  And just
so that others beside Doug and I way in on this, does anyone else have a
preference among: Ops, Op, Fns, Fn?

          Josh

On Jan 15, 2008 12:38 PM, David J. Biesack <David.Biesack at sas.com> wrote:

>
> I too am torn between usability and consistency; I certainly
> see both sides of the issue. (I agree onInt or withInt don't
> seem to fit, either.)
>
> Just to get a high level view for the Ops.* API, one can see the layout at
>
>  http://spreadsheets.google.com/ccc?key=pAoqbvjWjniKlWCMhVnW-ZA&hl=en
>
> There, I highlighted the names which do not follow the pattern.
>
> A table such as this (other layouts may be better) may be a nice addition
> to the Javadoc. (For compactness, I left off the Ops. prefix.)
>
> > Date: Tue, 15 Jan 2008 08:12:10 -0800
> > From: "Joshua Bloch" <josh at bloch.us>
> >
> > Gregg,
> >
> > Hmmm... the onInt and withInt don't really feel right to me.  If people
> > don't like intOp (or intFn), then I think we should go with David's
> > inclination (intToInt).
> >
> >           Josh
>
> --
>  David J. Biesack     SAS Institute Inc.
> (919) 531-7771       SAS Campus Drive
> http://www.sas.com   Cary, NC 27513
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080115/ab5a46cb/attachment.html 

From gergg at cox.net  Tue Jan 15 16:25:38 2008
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 15 Jan 2008 15:25:38 -0600
Subject: [concurrency-interest] Ops type names
In-Reply-To: <b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>	
	<200801142215.m0EMFdED002211@cs.oswego.edu>	
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>	
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
Message-ID: <478D24D2.5080700@cox.net>

Joshua Bloch wrote:
> Gregg,
>  
> Hmmm... the onInt and withInt don't really feel right to me.  If people 
> don't like intOp (or intFn), then I think we should go with David's 
> inclination (intToInt).

I'm just thinking out loud here...  The main focus is that these are operations 
on one type that produce another type.  Thus the doubleToInt etc names feel 
good.  The use of intToInt seems okay, but perhaps doubleToDouble is just a lot 
of typing and becomes a bit verbose.  The use of overloading in java allows the 
parameterization to change but not the return type, so we are motivated by that 
to come up with unique names such as intToDouble and shortToDouble because we 
can't do

	double op( int s );
	double op( short s );

I'm not sure where overloading sits in all of these discussions.  My previous 
suggestion was about a prefix, but perhaps a suffix notation is better, as in

	double doubleFor( int s );
	double doubleFor( short s );

or

	double doubleFrom( int s );
	double doubleFrom( short s );

or

	double doubleOn( int s );
	double doubleOn( short s );

or even just using the single name that Josh suggested for all of the result 
type operations by relying on overloading to resolve the implementation.

	double doubleOp( int s );
	double doubleOp( short s );

There are other suffixes besides 'For' and 'From', such as 'With', 'Of' etc.  I 
have some casual attraction to the 'On' form because I think of the sentence "I 
want a double value, resulting from an operation on ...".

Probably you have gone over this viewpoint already, so sorry for repeating if 
so.  Just trying to think about how to get to simple names that are effective, 
but not overwhelming to draw into conversation.

Gregg Wonderly

From josh at bloch.us  Tue Jan 15 17:05:16 2008
From: josh at bloch.us (Joshua Bloch)
Date: Tue, 15 Jan 2008 14:05:16 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <478D24D2.5080700@cox.net>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
	<478D24D2.5080700@cox.net>
Message-ID: <b097ac510801151405i74b11a92v97304891e23877a3@mail.gmail.com>

Gregg,

These are classes, not methods.  I'm afraid I confused you when I
accidentally typed some lowercase letters earlier on.

           Josh

On Jan 15, 2008 1:25 PM, Gregg Wonderly <gergg at cox.net> wrote:

> Joshua Bloch wrote:
> > Gregg,
> >
> > Hmmm... the onInt and withInt don't really feel right to me.  If people
> > don't like intOp (or intFn), then I think we should go with David's
> > inclination (intToInt).
>
> I'm just thinking out loud here...  The main focus is that these are
> operations
> on one type that produce another type.  Thus the doubleToInt etc names
> feel
> good.  The use of intToInt seems okay, but perhaps doubleToDouble is just
> a lot
> of typing and becomes a bit verbose.  The use of overloading in java
> allows the
> parameterization to change but not the return type, so we are motivated by
> that
> to come up with unique names such as intToDouble and shortToDouble because
> we
> can't do
>
>        double op( int s );
>        double op( short s );
>
> I'm not sure where overloading sits in all of these discussions.  My
> previous
> suggestion was about a prefix, but perhaps a suffix notation is better, as
> in
>
>        double doubleFor( int s );
>        double doubleFor( short s );
>
> or
>
>        double doubleFrom( int s );
>        double doubleFrom( short s );
>
> or
>
>        double doubleOn( int s );
>        double doubleOn( short s );
>
> or even just using the single name that Josh suggested for all of the
> result
> type operations by relying on overloading to resolve the implementation.
>
>        double doubleOp( int s );
>        double doubleOp( short s );
>
> There are other suffixes besides 'For' and 'From', such as 'With', 'Of'
> etc.  I
> have some casual attraction to the 'On' form because I think of the
> sentence "I
> want a double value, resulting from an operation on ...".
>
> Probably you have gone over this viewpoint already, so sorry for repeating
> if
> so.  Just trying to think about how to get to simple names that are
> effective,
> but not overwhelming to draw into conversation.
>
> Gregg Wonderly
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080115/acc75f63/attachment.html 

From dl at cs.oswego.edu  Thu Jan 17 19:47:36 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 17 Jan 2008 19:47:36 -0500
Subject: [concurrency-interest] ParallelArray updates du jour
Message-ID: <478FF728.9000700@cs.oswego.edu>


For those playing along. (And if you are not, why not?! :-)

1. Prefix classes have been promoted to top-level classes
    (as in ParallelArrayWithFilter, not ParallelArray.WithFilter).
    This mainly enables the following improvements (*),
    without affecting (normal) usages (except maybe Kaspar's (sorry!)).
2. Arguments to binary operations (withMapping etc) may be
    any kind of bounded/filtered/mapped ParallelArray,
    not just the plain kind.
3. Aggregate Operations that previously returned void now
    "return this", which enables nicer usage usage;
    as in:  pa.replaceWithMapping(f).sort(); (Thanks to Tim
    for forcing me to do this.)

Comments welcome as always.

Next up, and the last major aspects of planned functionality, are
operations involving binary predicates; as in finding
all elements such that a[i] == b[i] (ParallelArrays a and b).

(*) In case you are curious, try compiling this
     class PA extends PA.WithBounds { static class WithBounds {} }

All at the usual places:
API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar
Browsable CVS sources:
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/



-Doug

From dhanji at gmail.com  Fri Jan 18 17:37:28 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sat, 19 Jan 2008 08:37:28 +1000
Subject: [concurrency-interest] thread queueing qn
Message-ID: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>

Hi

I am trying to sequence/queue HTTP requests in a semantic user
"conversation":


Incoming Request -> Filter (Identify by cookie or rewritten URL) -> Read( by
Id from ConversationStore ) -> setActive ( ConversationContext )



Each conversation is modeled as a ConversationContext object that may be
stored in a permanent storage medium (custom impl by a user). My solution is
to obtain the ConversationContext from a store (creating a new one as
necessary) and then synchronizing on it while processing the request:


doFilter( ...) {


   ConversationContext con = readFromStoreById(..);

   synchronized(con) {
         filterChain.doFilter(...);     //process request normally
   }


}



This gives me queueing so that no two requests belonging to the *same* user
conversation are processed concurrently. However I see a couple of
drawbacks:

- synchronizing on a public object from a store is potentially dangerous, as
poorly written user impls can deadlock or starve request threads
- as an alternative, I don't want to force/trust users to expose a locking
API




One alternative I thought of was to keep a private registry of active
conversation keys (j.u.c.l.Locks in a hashtable) and lock the keys instead.
These work for the majority of cases, but there are times when a
conversation needs to be "merged" into a prior context, say from the
permanent store (key "collapsing", if you will). In this case the locks need
to be merged too--what is the best way to do this?

And does anyone have a better solution than locking by keys?

Thank you,

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080119/7a68c706/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Fri Jan 18 18:25:16 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Sat, 19 Jan 2008 00:25:16 +0100
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <478FF728.9000700@cs.oswego.edu>
References: <478FF728.9000700@cs.oswego.edu>
Message-ID: <b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>

On Jan 18, 2008 1:47 AM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> For those playing along. (And if you are not, why not?! :-)


Hearing your friendly call, I started to try making sense of the fork/join
stuff and found that the only comprehensive source of information beyond the
very basics (http://jcp.org/en/jsr/detail?id=166) is the draft API. I wonder
if there is any source of intermediary information available -- intermediary
between the terse mission statement in
http://jcp.org/en/jsr/detail?id=166and the complex draft API --
explaining how the purpose stated in the
mission statement is met by the API and its implementation.

In more concrete terms: I feel I could make good use of a high-level
explanation of how the new API is helping me (the "concurrency dummy") solve
problems more easily and more safely than the already existing concurrency
infrastructure. (I am not even sure which is the head and which is the tail
of this API beast.)

Thanks
Peter


>
>
> 1. Prefix classes have been promoted to top-level classes
>    (as in ParallelArrayWithFilter, not ParallelArray.WithFilter).
>    This mainly enables the following improvements (*),
>    without affecting (normal) usages (except maybe Kaspar's (sorry!)).
> 2. Arguments to binary operations (withMapping etc) may be
>    any kind of bounded/filtered/mapped ParallelArray,
>    not just the plain kind.
> 3. Aggregate Operations that previously returned void now
>    "return this", which enables nicer usage usage;
>    as in:  pa.replaceWithMapping(f).sort(); (Thanks to Tim
>    for forcing me to do this.)
>
> Comments welcome as always.
>
> Next up, and the last major aspects of planned functionality, are
> operations involving binary predicates; as in finding
> all elements such that a[i] == b[i] (ParallelArrays a and b).
>
> (*) In case you are curious, try compiling this
>     class PA extends PA.WithBounds { static class WithBounds {} }
>
> All at the usual places:
> API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
> jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar
> Browsable CVS sources:
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/
>
>
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080119/51d02e28/attachment.html 

From forax at univ-mlv.fr  Fri Jan 18 20:14:02 2008
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sat, 19 Jan 2008 02:14:02 +0100
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
Message-ID: <47914EDA.9020806@univ-mlv.fr>

Dhanji R. Prasanna a ?crit :
> Hi 
>
>  
> I am trying to sequence/queue HTTP requests in a semantic user 
> "conversation":
>
>  
> Incoming Request -> Filter (Identify by cookie or rewritten URL) -> 
> Read( by Id from ConversationStore ) -> setActive ( ConversationContext )
>
>  
>
> Each conversation is modeled as a ConversationContext object that may 
> be stored in a permanent storage medium (custom impl by a user). My 
> solution is to obtain the ConversationContext from a store (creating a 
> new one as necessary) and then synchronizing on it while processing 
> the request:
>
>  
> doFilter( ...) {
>
>  
>    ConversationContext con = readFromStoreById(..);
>
>    synchronized(con) {
>          filterChain.doFilter(...);     //process request normally
>    }
>
>  
> }
>
>
>  
> This gives me queueing so that no two requests belonging to the *same* 
> user conversation are processed concurrently. However I see a couple 
> of drawbacks:
>
> - synchronizing on a public object from a store is potentially 
> dangerous, as poorly written user impls can deadlock or starve request 
> threads
> - as an alternative, I don't want to force/trust users to expose a 
> locking API
and it can don't work at all because lot of persistence storages use 
equals() semantics (two persistent objects are equals using equals())
and synchronized use == semantic.

...
> Thank you,
>
> Dhanji.
R?mi

From dhanji at gmail.com  Sat Jan 19 18:30:46 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sun, 20 Jan 2008 09:30:46 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <47914EDA.9020806@univ-mlv.fr>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
	<47914EDA.9020806@univ-mlv.fr>
Message-ID: <aa067ea10801191530n331e6ba2nbd5f7c5e07eb658e@mail.gmail.com>

On 1/19/08, R?mi Forax <forax at univ-mlv.fr> wrote:
>
> Dhanji R. Prasanna a ?crit :
> > - as an alternative, I don't want to force/trust users to expose a
> > locking API
> and it can don't work at all because lot of persistence storages use
> equals() semantics (two persistent objects are equals using equals())
> and synchronized use == semantic.


Oh that's a very important point! Thank you, Remi =)

Dhanji
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080120/4ff6c52c/attachment.html 

From tim at peierls.net  Sun Jan 20 15:28:54 2008
From: tim at peierls.net (Tim Peierls)
Date: Sun, 20 Jan 2008 15:28:54 -0500
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
Message-ID: <63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>

On Jan 18, 2008 6:25 PM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> In more concrete terms: I feel I could make good use of a high-level
> explanation of how the new API is helping me (the "concurrency dummy") solve
> problems more easily and more safely than the already existing concurrency
> infrastructure.
>

I think the question is: For what problems is this new API better-suited
than existing tools? The class javadocs for ForkJoinTask, RecursiveAction,
and RecursiveTask sort of answer this.

http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/forkjoin/ForkJoinTask.html

Crude paraphrase: Use fork-join when you can express a big computation as
lots of fine-grained tasks that can wait for other such tasks to complete
but otherwise never (or very rarely) block. And don't expect too much from
this stuff on a uniprocessor.

For example, fork-join would not work well for full request-to-response
handling in a server (use existing tools for that), but it might be useful
to implement a compute-bound stage of such a server.


 (I am not even sure which is the head and which is the tail of this API
> beast.)
>

One thing that might not be clear from the javadocs is that the
ParallelArray stuff is written on top of the fork-join stuff; it's an
application of fork-join. It's a little confusing because everything is in
one package currently.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080120/54c0234f/attachment.html 

From tim at peierls.net  Sun Jan 20 17:48:46 2008
From: tim at peierls.net (Tim Peierls)
Date: Sun, 20 Jan 2008 17:48:46 -0500
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
Message-ID: <63b4e4050801201448p4b9c6367yaf80d5b1cf600304@mail.gmail.com>

On Jan 18, 2008 5:37 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

> Each conversation is modeled as a ConversationContext object that may be
> stored in a permanent storage medium (custom impl by a user). My solution is
> to obtain the ConversationContext from a store (creating a new one as
> necessary) and then synchronizing on it while processing the request:
>
> doFilter( ...) {
>    ConversationContext con = readFromStoreById(..);
>    synchronized(con) {
>          filterChain.doFilter(...);     //process request normally
>    }
> }
>

This is fine if readFromStoreById really always returns the identical
ConversationContext object for the same conversation. But your exchange with
R?mi suggests that this is not likely.


This gives me queueing so that no two requests belonging to the *same* user
> conversation are processed concurrently. However I see a couple of
> drawbacks:
>
> - synchronizing on a public object from a store is potentially dangerous,
> as poorly written user impls can deadlock or starve request threads
>

They can do this whether or not you synchronize on the object that they
return. readFromStoreById needs to be thread-safe, regardless of your
strategy for preventing two requests from the same conversation from being
processed concurrently.


One alternative I thought of was to keep a private registry of active
> conversation keys (j.u.c.l.Locks in a hashtable) and lock the keys
> instead. These work for the majority of cases, but there are times when a
> conversation needs to be "merged" into a prior context, say from the
> permanent store (key "collapsing", if you will). In this case the locks need
> to be merged too--what is the best way to do this?
>

You could have a ConcurrentMap<Key, Object> and synchronize on the *value*
Objects, not the Keys. Use putIfAbsent to add key/object pairs atomically.
Merge is less common, easier to make it synchronized to avoid dealing with
simultaneous merges of different pairs. Sample code:

  interface KeyedLock<K> {
      Object lockFor(K key);
      void mergeKeys(K key1, K key2);
  }

  class KeyedLockImpl<K> implements KeyedLock<K> {

      public Object lockFor(K key) {
          Object lock = map.get(key);
          if (lock == null) {
              lock = new Object();
              Object prev = map.putIfAbsent(key, lock);
              if (prev != null) lock = prev;
          }
          return lock;
      }

      public synchronized void mergeKeys(K key1, K key2) {
          map.replace(key2, lockFor(key2), lockFor(key1));
      }

      private final ConcurrentMap<K, Object> map =
          new ConcurrentHashMap<K, Object>();
  }

Then you can write:

    void doFilter(Request req, Response rsp, FilterChain filterChain) {
        String key = conversationKeyFrom(req);
        synchronized (conversationLocks.lockFor(key)) {
            filterChain.doFilter(req, rsp);
        }
    }

    final KeyedLock<String> conversationLocks = new KeyedLockImpl<String>();

If you need to wait for handling on a conversation to complete before
merging it into another conversation, you could use Lock instead of Object,
and do things like tryLock during a merge attempt to see whether it's OK to
merge. Or you could wait on a Condition -- but this is starting to get
complicated. Depends on how frequent merges are, and how critical it is that
processing be completed on a conversation before the merge happens.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080120/0259f48e/attachment.html 

From jeffrey.elrod at complexsive.com  Sun Jan 20 18:43:04 2008
From: jeffrey.elrod at complexsive.com (Jeffrey Elrod)
Date: Sun, 20 Jan 2008 15:43:04 -0800 (PST)
Subject: [concurrency-interest] Parallel Genetic Algorithms on Multi-core
	Processors
Message-ID: <155720.9972.qm@web914.biz.mail.mud.yahoo.com>

Hi everyone,

I'm  building an AI engine for games, simulations, animations, etc.  One of the features I would like to have in my AI engine is a genetic algorithm library that would allow the AI programmer to build simple and parallel genetic algorithms (PGAs). But most PGAs are done with multiprocessor systems and not multicore systems. If you read some of the papers on PGAs, the researcher are using multi-processor systems and the number of populations (population per processor) can be massive.

Is it practical to allow the AI developer to build PGAs on one machine using a multi-core processor?

Jeff
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080120/94556a77/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Mon Jan 21 06:44:43 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 21 Jan 2008 12:44:43 +0100
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>
Message-ID: <b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>

Thank you for the clarification!

It appears that one of the main characteristics required of the sub-tasks is
their non-blocking nature. The doc for FJTask distinguishes three types of
blocking:

"The computation defined in the compute method should not in general perform
any other form of blocking synchronization, should not perform IO, and
should be independent of other tasks."

The kind of blocking which I feel could be more closely defined is: IO.
Naively, I would define IO as operations involving reading from, or writing
to a physical device. Is main system memory (RAM) to be considered a
physical device in this context? If so, I assume FJTask instances must be
fine-grained enough for the working set of any individual FJTask instance
to  fit into the on-CPU cache of the processor the FJTask starts being
scheduled on.

A corollary requirement is then that FJTask instances should complete
quickly enough so as to reduce the probability of
(a) the OS "migrating the instance" to another CPU due to rescheduling
(b) the instance being rescheduled in general - in case the on-CPU cache is
not large enough to hold the working sets of multiple instances.

Is this correct?

Thanks
Peter

On Jan 20, 2008 9:28 PM, Tim Peierls <tim at peierls.net> wrote:

> On Jan 18, 2008 6:25 PM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com>
> wrote:
>
> > In more concrete terms: I feel I could make good use of a high-level
> > explanation of how the new API is helping me (the "concurrency dummy") solve
> > problems more easily and more safely than the already existing concurrency
> > infrastructure.
> >
>
> I think the question is: For what problems is this new API better-suited
> than existing tools? The class javadocs for ForkJoinTask, RecursiveAction,
> and RecursiveTask sort of answer this.
>
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/forkjoin/ForkJoinTask.html
>
> Crude paraphrase: Use fork-join when you can express a big computation as
> lots of fine-grained tasks that can wait for other such tasks to complete
> but otherwise never (or very rarely) block. And don't expect too much from
> this stuff on a uniprocessor.
>
> For example, fork-join would not work well for full request-to-response
> handling in a server (use existing tools for that), but it might be useful
> to implement a compute-bound stage of such a server.
>
>
>  (I am not even sure which is the head and which is the tail of this API
> > beast.)
> >
>
> One thing that might not be clear from the javadocs is that the
> ParallelArray stuff is written on top of the fork-join stuff; it's an
> application of fork-join. It's a little confusing because everything is in
> one package currently.
>
> --tim
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/89d086f8/attachment-0001.html 

From tim at peierls.net  Mon Jan 21 07:31:31 2008
From: tim at peierls.net (Tim Peierls)
Date: Mon, 21 Jan 2008 07:31:31 -0500
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>
	<b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>
Message-ID: <63b4e4050801210431o35ba1a13x7fbe50e230c23138@mail.gmail.com>

On Jan 21, 2008 6:44 AM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> The kind of blocking which I feel could be more closely defined is: IO.
> Naively, I would define IO as operations involving reading from, or writing
> to a physical device. Is main system memory (RAM) to be considered a
> physical device in this context?


No, I'm pretty sure this means I/O in the plain old boring sense of network
and file I/O.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/699c7d90/attachment.html 

From dl at cs.oswego.edu  Mon Jan 21 07:40:22 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jan 2008 07:40:22 -0500 (EST)
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
Message-ID: <40571.24.58.109.230.1200919222.squirrel@cs.oswego.edu>

> On Jan 18, 2008 1:47 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
> In more concrete terms: I feel I could make good use of a high-level
> explanation of how the new API is helping me (the "concurrency dummy")
> solve
> problems more easily and more safely than the already existing concurrency
> infrastructure. (I am not even sure which is the head and which is the
> tail
> of this API beast.)
>

Tim Peierls answered in terms of underlying mechanisms,  (BTW,
Tim is playing a big role in developing the APIs for
these classes.)

Another way of answering is that Parallel*Array
(and planned follow-ons) provide an easier/better way of
routinely programming to take advantage of dozens to
hundreds of processors/cores: If you can think about a
programming problem in terms of aggregate operations
on collections of elements, then we can automate parallel execution.
This generally pays off if either you have lots of elements,
(in which case, it works well even if the operations are
small/cheap), or if each of the operations
are time consuming (in which case it works well
even if there are not a lot of elements).
To take advantage of this though, the
aggregate processing must have a regular structure, which
means that you must be able to express things in terms of
apply, reduce, filter, map, cumulate, sort, uniquify,
paired mappings, and so on. So that's what Parallel*Array
does. Some people (especially those with experience
with either database programming or functional programming)
like this style anyway, and might use this  API
even without the parallelism benefits. But in turn,
the fact that this style can be awkward to write out
has led to all the language extension controversies
about closures, function types, and related syntactic
support.

-Doug







From dl at cs.oswego.edu  Mon Jan 21 08:09:51 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jan 2008 08:09:51 -0500 (EST)
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
Message-ID: <40621.24.58.109.230.1200920991.squirrel@cs.oswego.edu>

> On Jan 18, 2008 1:47 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> In more concrete terms: I feel I could make good use of a high-level
> explanation of how the new API is helping me (the "concurrency dummy")
> solve
> problems more easily and more safely than the already existing concurrency
> infrastructure.

As we've done for all JSR166 components, we've been developing trial
APIs and posting about them only on concurrency-interest list
to get help from a more manageable base of brave early users
before trying to commit to JDK. (The feedback we've gotten
from you folks over the years has been a big ingredient in
success!)

For forkjoin and its derivatives, we haven't done much so
far developing good high-level descriptions, usage examples,
and so on. We'd like your help on this too. Tim Peierls
just set up a wiki that we invite you all to use for
these kinds of contributions, at:
http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W1

Everyone: Please do feel free to add advice, examples, proposed
documentation, or anything else along these lines.
(Thanks to David Biesack for suggesting we do this.)

-Doug



From dl at cs.oswego.edu  Mon Jan 21 08:32:03 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jan 2008 08:32:03 -0500 (EST)
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>
	<b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>
Message-ID: <59666.24.58.109.230.1200922323.squirrel@cs.oswego.edu>

>
>
> "The computation defined in the compute method should not in general
> perform
> any other form of blocking synchronization, should not perform IO, and
> should be independent of other tasks."
>
> The kind of blocking which I feel could be more closely defined is: IO.
> Naively, I would define IO as operations involving reading from, or
> writing
> to a physical device. Is main system memory (RAM) to be considered a
> physical device in this context? If so, I assume FJTask instances must be
> fine-grained enough for the working set of any individual FJTask instance
> to  fit into the on-CPU cache of the processor the FJTask starts being
> scheduled on.
>
> A corollary requirement is then that FJTask instances should complete
> quickly enough so as to reduce the probability of
> (a) the OS "migrating the instance" to another CPU due to rescheduling
> (b) the instance being rescheduled in general - in case the on-CPU cache
> is
> not large enough to hold the working sets of multiple instances.
>
> Is this correct?
>

More or less. Like all lightweight-task frameworks, FJ does
not explicitly cope with blocked IO: If a worker thread
blocks on IO, then (1) it is not available to help process
other tasks (2) Other worker threads waiting for the task
to complete (i.e., to join it) may run out of work and waste
CPU cycles. Neither of these issues completely eliminates
potential use, but they do require a lot of explicit care.
For example, you could place tasks that may experience
sustained blockages in their own small ForkJoinPools.
(The fortress folks do something along these lines
mapping fortress "fair" threads onto forkjoin.) You
can also dynamically increase worker pool sizes (we
have methods to do this) when blockages may occur.
All in all though, the reason for the restrictions and
advice are that we do not have good automated support
for these kinds of cases, and don't yet know of the
best practices, or whether it is a good idea at all.

-Doug



From dl at cs.oswego.edu  Mon Jan 21 09:09:07 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jan 2008 09:09:07 -0500 (EST)
Subject: [concurrency-interest] Parallel Genetic Algorithms on
 Multi-core Processors
In-Reply-To: <155720.9972.qm@web914.biz.mail.mud.yahoo.com>
References: <155720.9972.qm@web914.biz.mail.mud.yahoo.com>
Message-ID: <40938.24.58.109.230.1200924547.squirrel@cs.oswego.edu>

> Hi everyone,
>
> I'm  building an AI engine for games, simulations, animations, etc.  One
> of the features I would like to have in my AI engine is a genetic
> algorithm library that would allow the AI programmer to build simple and
> parallel genetic algorithms (PGAs). But most PGAs are done with
> multiprocessor systems and not multicore systems. If you read some of the
> papers on PGAs, the researcher are using multi-processor systems and the
> number of populations (population per processor) can be massive.
>
> Is it practical to allow the AI developer to build PGAs on one machine
> using a multi-core processor?
>

The differences between shared caches (multicore) versus
separate ones (multiprocessor) versus mixtures (MPs of multicores)
do show up in some applications but not others, so it is hard to
give a good answer. There's some research showing that some of
of these effects can be reduced by using different task scheduling
algorithms across the different cases (which BTW may show up
someday in forkjoin framework). But even so, there seem to
be many (perhaps most) applications where it doesn't make
a huge difference -- caches are neither overly polluted
nor overly contended to make enough difference to address.
I don't know if the kinds of parallel genetic algorithms
you are looking at fall into this category or not.

Relatedly, Bill Scherer and I put together a PGA demo
using the updated Java6 version of Exchanger. See
TSPExchangerTest in
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
(We haven't put together a lightweight FJ version
of Exchanger yet, but it is a thought...)

-Doug



From peter.kovacs.1.0rc at gmail.com  Mon Jan 21 09:48:22 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Mon, 21 Jan 2008 15:48:22 +0100
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <40621.24.58.109.230.1200920991.squirrel@cs.oswego.edu>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<40621.24.58.109.230.1200920991.squirrel@cs.oswego.edu>
Message-ID: <b6e8f2e80801210648m1ffba463td336ae47f7fad5e3@mail.gmail.com>

Thank you, Doug, for the exhaustive answers.

Is one supposed to be logged in on the Wiki, before adding content? (I
haven't found any "Register" menu items.)

Thanks
Peter

On Jan 21, 2008 2:09 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> > On Jan 18, 2008 1:47 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
> > In more concrete terms: I feel I could make good use of a high-level
> > explanation of how the new API is helping me (the "concurrency dummy")
> > solve
> > problems more easily and more safely than the already existing
> concurrency
> > infrastructure.
>
> As we've done for all JSR166 components, we've been developing trial
> APIs and posting about them only on concurrency-interest list
> to get help from a more manageable base of brave early users
> before trying to commit to JDK. (The feedback we've gotten
> from you folks over the years has been a big ingredient in
> success!)
>
> For forkjoin and its derivatives, we haven't done much so
> far developing good high-level descriptions, usage examples,
> and so on. We'd like your help on this too. Tim Peierls
> just set up a wiki that we invite you all to use for
> these kinds of contributions, at:
> http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W1
>
> Everyone: Please do feel free to add advice, examples, proposed
> documentation, or anything else along these lines.
> (Thanks to David Biesack for suggesting we do this.)
>
> -Doug
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/bbaa50db/attachment.html 

From dl at cs.oswego.edu  Mon Jan 21 09:50:45 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jan 2008 09:50:45 -0500 (EST)
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <59666.24.58.109.230.1200922323.squirrel@cs.oswego.edu>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<63b4e4050801201228p1b74f4a4t580eabb1299f6574@mail.gmail.com>
	<b6e8f2e80801210344v5240370ao5c38f0d7b2b69c6e@mail.gmail.com>
	<59666.24.58.109.230.1200922323.squirrel@cs.oswego.edu>
Message-ID: <57657.24.58.109.230.1200927045.squirrel@cs.oswego.edu>

... back to the topic of the subject line:

1. The common predefined ops that were once in Ops are now
in CommonOps

2. Binary and indexed filters are now supported, leading to some
minor rearrangements of some other methods.

Upcoming: Now that all those With* classes are top-level,
we might do something about the strange-sounding
names. While users will never declare any objects of
these types, they do come into play as parameter types.
And it is probably not completely obvious to people
that accepting a "ParalleDoubleArrayWithDoubleMapping"
(as holds in some combining methods) means that you can
use any prefixed ParallelDoubleArray so long as it
doesn't yield a mapping from doubles to some other type.

-Doug



From tim at peierls.net  Mon Jan 21 10:07:26 2008
From: tim at peierls.net (Tim Peierls)
Date: Mon, 21 Jan 2008 10:07:26 -0500
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801210648m1ffba463td336ae47f7fad5e3@mail.gmail.com>
References: <478FF728.9000700@cs.oswego.edu>
	<b6e8f2e80801181525t52c7a604xf602901b548c6e36@mail.gmail.com>
	<40621.24.58.109.230.1200920991.squirrel@cs.oswego.edu>
	<b6e8f2e80801210648m1ffba463td336ae47f7fad5e3@mail.gmail.com>
Message-ID: <63b4e4050801210707x2517bb83w2c915c48ae8c6196@mail.gmail.com>

On Jan 21, 2008 9:48 AM, Peter Kovacs <peter.kovacs.1.0rc at gmail.com> wrote:

> Is one supposed to be logged in on the Wiki, before adding content? (I
> haven't found any "Register" menu items.)
>

It's open to all, with no need to register. I encourage people to create
some structure. Sign your work if you want to be contacted about changes. If
anyone has a reasonable pre-fab policy doc for this kind of wiki, please add
it.

If that doesn't work, we'll go to a more restricted format, where edits are
limited to registered users. (In which case, write to me to register.)

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/9efcc520/attachment.html 

From gregg at cytetech.com  Mon Jan 21 15:49:04 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 21 Jan 2008 14:49:04 -0600
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801191530n331e6ba2nbd5f7c5e07eb658e@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
	<47914EDA.9020806@univ-mlv.fr>
	<aa067ea10801191530n331e6ba2nbd5f7c5e07eb658e@mail.gmail.com>
Message-ID: <47950540.5060404@cytetech.com>

Dhanji R. Prasanna wrote:
> 
> 
> On 1/19/08, *R?mi Forax* <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>> 
> wrote:
> 
>     Dhanji R. Prasanna a ?crit :
>      > - as an alternative, I don't want to force/trust users to expose a
>      > locking API
>     and it can don't work at all because lot of persistence storages use
>     equals() semantics (two persistent objects are equals using equals())
>     and synchronized use == semantic.
> 
> 
> Oh that's a very important point! Thank you, Remi =)

ConcurrentHashTable and Futures can often help in these kinds of situations. 
You can use the equals() semantics to pick a unique entry in a map (the Future) 
to use for locking.  Here's something that I hope conveys what I mean.  I'm 
coding this on the fly...

ConcurrentHashMap<KeyValue,Future> map =
	new ConcurrentHashMap<KeyValue,Future>();

public Object doWorkFor( KeyValue key, Runnable work ) {
	Object o = null;
	do {
		// Wrap the runnable for execution
		Future f = new FutureTask<Void>( work );

		// Try to reserve the right to work on "key"
		Future nf = map.putIfAbsent( key, f );

		if( nf != null ) {
			// Someone already working, wait for other
			// user to finish
			nf.get();
			// There is another thread that needs to remove
			// their future from the map, yield to that
			// activity.
			Thread.yield();
		} else {
			try {
				// We got in, run our work
				o = f.run();
			} finally {
				// Remove our key.  There might be some
				// spinning of other threads between the
				// time that the future is valid and the
				// key is removed.
				map.remove( key );
			}
		}
	} while( nf != null );

	// Return the result of our work.
	return o;
}

The equals()/hashcode() semantics select the lock to use.  There is no thread 
pool, so you see synchronous execution which provides automatic throttling.

Gregg Wonderly

From dcholmes at optusnet.com.au  Mon Jan 21 19:39:24 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 22 Jan 2008 10:39:24 +1000
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <59666.24.58.109.230.1200922323.squirrel@cs.oswego.edu>
Message-ID: <ABEHILABNFKEAJNKLENCEEELCGAA.dcholmes@optusnet.com.au>

But to clarify Doug's answer, "blocked I/O" is as Tim referred to - disk /
network / console ie traditional IO devices. It does not concern memory
access or cpu scheduling issues.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> Sent: Monday, 21 January 2008 11:32 PM
> To: Peter Kovacs
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ParallelArray updates du jour
>
>
> >
> >
> > "The computation defined in the compute method should not in general
> > perform
> > any other form of blocking synchronization, should not perform IO, and
> > should be independent of other tasks."
> >
> > The kind of blocking which I feel could be more closely defined is: IO.
> > Naively, I would define IO as operations involving reading from, or
> > writing
> > to a physical device. Is main system memory (RAM) to be considered a
> > physical device in this context? If so, I assume FJTask
> instances must be
> > fine-grained enough for the working set of any individual
> FJTask instance
> > to  fit into the on-CPU cache of the processor the FJTask starts being
> > scheduled on.
> >
> > A corollary requirement is then that FJTask instances should complete
> > quickly enough so as to reduce the probability of
> > (a) the OS "migrating the instance" to another CPU due to rescheduling
> > (b) the instance being rescheduled in general - in case the on-CPU cache
> > is
> > not large enough to hold the working sets of multiple instances.
> >
> > Is this correct?
> >
>
> More or less. Like all lightweight-task frameworks, FJ does
> not explicitly cope with blocked IO: If a worker thread
> blocks on IO, then (1) it is not available to help process
> other tasks (2) Other worker threads waiting for the task
> to complete (i.e., to join it) may run out of work and waste
> CPU cycles. Neither of these issues completely eliminates
> potential use, but they do require a lot of explicit care.
> For example, you could place tasks that may experience
> sustained blockages in their own small ForkJoinPools.
> (The fortress folks do something along these lines
> mapping fortress "fair" threads onto forkjoin.) You
> can also dynamically increase worker pool sizes (we
> have methods to do this) when blockages may occur.
> All in all though, the reason for the restrictions and
> advice are that we do not have good automated support
> for these kinds of cases, and don't yet know of the
> best practices, or whether it is a good idea at all.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From crazybob at crazybob.org  Mon Jan 21 19:56:26 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 21 Jan 2008 16:56:26 -0800
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
Message-ID: <a74683f90801211656l321fefd8ice36f45ab429a690@mail.gmail.com>

Dhanji,

On Jan 18, 2008 2:37 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

>    ConversationContext con = readFromStoreById(..);
>
>    synchronized(con) {
>          filterChain.doFilter(...);     //process request normally
>    }
>

FWIW, you should also try to keep the requests in the same order. Instead of
a straight synchronized block, you could use a LinkedList of threads and let
them through FIFO style.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/7b16310e/attachment.html 

From dhanji at gmail.com  Mon Jan 21 20:38:07 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 22 Jan 2008 11:38:07 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <a74683f90801211656l321fefd8ice36f45ab429a690@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
	<a74683f90801211656l321fefd8ice36f45ab429a690@mail.gmail.com>
Message-ID: <aa067ea10801211738sdf74221j70b334c43f1a5ecc@mail.gmail.com>

On 1/22/08, Bob Lee <crazybob at crazybob.org> wrote:
>
> Dhanji,
>
> On Jan 18, 2008 2:37 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
>
> >    ConversationContext con = readFromStoreById(..);
> >
> >    synchronized(con) {
> >          filterChain.doFilter(...);     //process request normally
> >    }
> >
>
> FWIW, you should also try to keep the requests in the same order. Instead
> of a straight synchronized block, you could use a LinkedList of threads and
> let them through FIFO style.
>

Bob wont thread waiting give me FIFO semantics anyway? What am I missing
here? My implementation looks a lot like Tim's code (i.e. hashtable of
keys->locks).

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/3f2cf14a/attachment.html 

From crazybob at crazybob.org  Mon Jan 21 20:54:53 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 21 Jan 2008 17:54:53 -0800
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801211738sdf74221j70b334c43f1a5ecc@mail.gmail.com>
References: <aa067ea10801181437x35c5db55y3508199d9e0e602d@mail.gmail.com>
	<a74683f90801211656l321fefd8ice36f45ab429a690@mail.gmail.com>
	<aa067ea10801211738sdf74221j70b334c43f1a5ecc@mail.gmail.com>
Message-ID: <a74683f90801211754w43196434pcf177cbbed0a9566@mail.gmail.com>

On Jan 21, 2008 5:38 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

> Bob wont thread waiting give me FIFO semantics anyway?
>

Oops. I think you're right. I was thinking of wait()/notify(). Does this
statement from the JLS (
http://java.sun.com/docs/books/jls/second_edition/html/memory.doc.html) mean
that threads enter the synchronized block in FIFO fashion?

"With respect to a lock, the *lock* and *unlock* actions performed by all
the threads are performed in some total sequential order. This total order
must be consistent with the total order on the actions of each thread."

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/d365637c/attachment.html 

From dcholmes at optusnet.com.au  Mon Jan 21 21:11:13 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 22 Jan 2008 12:11:13 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <a74683f90801211754w43196434pcf177cbbed0a9566@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>

No it doesn't mean that. There's no guarantee of FIFO access to a
synchronized region.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Bob Lee
  Sent: Tuesday, 22 January 2008 11:55 AM
  To: Dhanji R. Prasanna
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] thread queueing qn


  On Jan 21, 2008 5:38 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

    Bob wont thread waiting give me FIFO semantics anyway?

  Oops. I think you're right. I was thinking of wait()/notify(). Does this
statement from the JLS (
http://java.sun.com/docs/books/jls/second_edition/html/memory.doc.html) mean
that threads enter the synchronized block in FIFO fashion?

  "With respect to a lock, the lock and unlock actions performed by all the
threads are performed in some total sequential order. This total order must
be consistent with the total order on the actions of each thread."

  Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/89648ad9/attachment.html 

From crazybob at crazybob.org  Mon Jan 21 21:17:26 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 21 Jan 2008 18:17:26 -0800
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>
References: <a74683f90801211754w43196434pcf177cbbed0a9566@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>
Message-ID: <a74683f90801211817i2015c66xb31377ca96ad1312@mail.gmail.com>

Phew. I was worried there for a second.

Bob

On Jan 21, 2008 6:11 PM, David Holmes <dcholmes at optusnet.com.au> wrote:

>  No it doesn't mean that. There's no guarantee of FIFO access to a
> synchronized region.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Bob Lee
> *Sent:* Tuesday, 22 January 2008 11:55 AM
> *To:* Dhanji R. Prasanna
> *Cc:* concurrency-interest
> *Subject:* Re: [concurrency-interest] thread queueing qn
>
> On Jan 21, 2008 5:38 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
>
> >  Bob wont thread waiting give me FIFO semantics anyway?
> >
>
> Oops. I think you're right. I was thinking of wait()/notify(). Does this
> statement from the JLS (http://java.sun.com/docs/books/jls/second_edition/html/memory.doc.html)
> mean that threads enter the synchronized block in FIFO fashion?
>
> "With respect to a lock, the *lock* and *unlock* actions performed by all
> the threads are performed in some total sequential order. This total order
> must be consistent with the total order on the actions of each thread."
>
> Bob
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/1aca5fa2/attachment-0001.html 

From dhanji at gmail.com  Mon Jan 21 21:20:38 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 22 Jan 2008 12:20:38 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>
References: <a74683f90801211754w43196434pcf177cbbed0a9566@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>

On 1/22/08, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  No it doesn't mean that. There's no guarantee of FIFO access to a
> synchronized region.
>

I don't think I follow. Let's do this in the abstract (i.e. not necessarily
Java):

Threads: [A, B] Locks: [L]

- Thread A acquires L
- Thread B attempts L, but L is locked, so it blocks
- Thread A completes critical section and releases L
- Thread B is notified, and continues into the critical section

A came first, A exited first. B came last, B exited last.

Does j.u.c.l.Lock or java monitors not guarantee such ordering (i.e. on
acquisition or release of locks)?

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/c5861464/attachment.html 

From crazybob at crazybob.org  Mon Jan 21 21:29:01 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 21 Jan 2008 18:29:01 -0800
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
References: <a74683f90801211754w43196434pcf177cbbed0a9566@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEDFHKAA.dcholmes@optusnet.com.au>
	<aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
Message-ID: <a74683f90801211829i71554f9al5979952e304286fa@mail.gmail.com>

Try [A, B, C].

- Thread A acquires L
- Thread B attempts L, but L is locked, so it blocks
- Thread C attempts L, but L is locked, so it blocks
- Thread A completes critical section and releases L
- Thread B or C is notified, and continues into the critical section

Bob

On Jan 21, 2008 6:20 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

>
>
> On 1/22/08, David Holmes <dcholmes at optusnet.com.au> wrote:
> >
> >  No it doesn't mean that. There's no guarantee of FIFO access to a
> > synchronized region.
> >
>
> I don't think I follow. Let's do this in the abstract (i.e. not
> necessarily Java):
>
> Threads: [A, B] Locks: [L]
>
> - Thread A acquires L
> - Thread B attempts L, but L is locked, so it blocks
> - Thread A completes critical section and releases L
> - Thread B is notified, and continues into the critical section
>
> A came first, A exited first. B came last, B exited last.
>
> Does j.u.c.l.Lock or java monitors not guarantee such ordering (i.e. on
> acquisition or release of locks)?
>
> Dhanji.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/06effb40/attachment.html 

From dcholmes at optusnet.com.au  Mon Jan 21 21:30:16 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 22 Jan 2008 12:30:16 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEDGHKAA.dcholmes@optusnet.com.au>

If there are only two threads then what you describe is correct. But let
there be three threads:

- Thread A acquires L
- Thread B attepts L, but L is locked, so it blocks
- Thread C attepts L, but L is locked, so it blocks
- Thread A releases L

At this point there is no guarantee whether B will be woken to try and
acquire L, or whether C will be woken, or both. Even if B or C were awoken,
thread D might barge in and grab L first.

It's all up to the implementation.

Cheers,
David Holmes
  -----Original Message-----
  From: Dhanji R. Prasanna [mailto:dhanji at gmail.com]
  Sent: Tuesday, 22 January 2008 12:21 PM
  To: dholmes at ieee.org
  Cc: Bob Lee; concurrency-interest
  Subject: Re: [concurrency-interest] thread queueing qn





  On 1/22/08, David Holmes <dcholmes at optusnet.com.au> wrote:
    No it doesn't mean that. There's no guarantee of FIFO access to a
synchronized region.


  I don't think I follow. Let's do this in the abstract (i.e. not
necessarily Java):


  Threads: [A, B] Locks: [L]


  - Thread A acquires L
  - Thread B attempts L, but L is locked, so it blocks
  - Thread A completes critical section and releases L
  - Thread B is notified, and continues into the critical section


  A came first, A exited first. B came last, B exited last.


  Does j.u.c.l.Lock or java monitors not guarantee such ordering (i.e. on
acquisition or release of locks)?


  Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/f550fbfa/attachment.html 

From dhanji at gmail.com  Mon Jan 21 21:44:52 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 22 Jan 2008 12:44:52 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEDGHKAA.dcholmes@optusnet.com.au>
References: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEDGHKAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10801211844t52798841gb1d0e58167ee8b12@mail.gmail.com>

Hmm, good call!
Some time ago I had considered using a fair lock--new ReentrantLock(true);

"When set true, under contention, locks favor granting access to the
longest-waiting thread. "


Does this mean longest-waiting threads with be notified first? Given that a
request thread is unlikely to reenter a held lock, this should provide me
with FIFO semantics should it not?

Dhanji.

On 1/22/08, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  If there are only two threads then what you describe is correct. But let
> there be three threads:
>
> - Thread A acquires L
> - Thread B attepts L, but L is locked, so it blocks
> - Thread C attepts L, but L is locked, so it blocks
> - Thread A releases L
>
> At this point there is no guarantee whether B will be woken to try and
> acquire L, or whether C will be woken, or both. Even if B or C were awoken,
> thread D might barge in and grab L first.
>
> It's all up to the implementation.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> *From:* Dhanji R. Prasanna [mailto:dhanji at gmail.com]
> *Sent:* Tuesday, 22 January 2008 12:21 PM
> *To:* dholmes at ieee.org
> *Cc:* Bob Lee; concurrency-interest
> *Subject:* Re: [concurrency-interest] thread queueing qn
>
>
>
> On 1/22/08, David Holmes <dcholmes at optusnet.com.au> wrote:
> >
> >  No it doesn't mean that. There's no guarantee of FIFO access to a
> > synchronized region.
> >
>
>
> I don't think I follow. Let's do this in the abstract (i.e. not
> necessarily Java):
>
>
> Threads: [A, B] Locks: [L]
>
>
> - Thread A acquires L
> - Thread B attempts L, but L is locked, so it blocks
> - Thread A completes critical section and releases L
> - Thread B is notified, and continues into the critical section
>
>
> A came first, A exited first. B came last, B exited last.
>
>
> Does j.u.c.l.Lock or java monitors not guarantee such ordering (i.e. on
> acquisition or release of locks)?
>
>
> Dhanji.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/a3e2592b/attachment.html 

From crazybob at crazybob.org  Mon Jan 21 21:48:26 2008
From: crazybob at crazybob.org (Bob Lee)
Date: Mon, 21 Jan 2008 18:48:26 -0800
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <aa067ea10801211844t52798841gb1d0e58167ee8b12@mail.gmail.com>
References: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEDGHKAA.dcholmes@optusnet.com.au>
	<aa067ea10801211844t52798841gb1d0e58167ee8b12@mail.gmail.com>
Message-ID: <a74683f90801211848t10de7dc7jd8faa478a6927c51@mail.gmail.com>

On Jan 21, 2008 6:44 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

> Does this mean longest-waiting threads with be notified first? Given that
> a request thread is unlikely to reenter a held lock, this should provide me
> with FIFO semantics should it not?
>

This may not be an issue for you, but the thread could re-enter if you use a
request dispatcher.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080121/24ba3804/attachment-0001.html 

From dhanji at gmail.com  Mon Jan 21 22:17:33 2008
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Tue, 22 Jan 2008 13:17:33 +1000
Subject: [concurrency-interest] thread queueing qn
In-Reply-To: <a74683f90801211848t10de7dc7jd8faa478a6927c51@mail.gmail.com>
References: <aa067ea10801211820s1209e842m4122a269f2e09088@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEDGHKAA.dcholmes@optusnet.com.au>
	<aa067ea10801211844t52798841gb1d0e58167ee8b12@mail.gmail.com>
	<a74683f90801211848t10de7dc7jd8faa478a6927c51@mail.gmail.com>
Message-ID: <aa067ea10801211917h315c7f19h54c7bd699c94deae@mail.gmail.com>

On 1/22/08, Bob Lee <crazybob at crazybob.org> wrote:
>
> On Jan 21, 2008 6:44 PM, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
>
> > Does this mean longest-waiting threads with be notified first? Given
> > that a request thread is unlikely to reenter a held lock, this should
> > provide me with FIFO semantics should it not?
> >
>
> This may not be an issue for you, but the thread could re-enter if you use
> a request dispatcher.
>

Indeed that has been keeping me up at night, but I'm ignoring it for two
reasons:

- currently, my framework does not honor dispatcher (if I can't see it it's
not there, jk =)
- the request is already bound a conv, so reentering the conv filter will
dilute the lock's queue but should not affect the FIFO semantic with regard
to unique threads (right?)

Thanks everyone for your insights!

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/b877fd1f/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Tue Jan 22 04:20:47 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Tue, 22 Jan 2008 10:20:47 +0100
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <ABEHILABNFKEAJNKLENCEEELCGAA.dcholmes@optusnet.com.au>
References: <59666.24.58.109.230.1200922323.squirrel@cs.oswego.edu>
	<ABEHILABNFKEAJNKLENCEEELCGAA.dcholmes@optusnet.com.au>
Message-ID: <b6e8f2e80801220120s7238059ci3aaab0c7468ef9fa@mail.gmail.com>

Thank you, David, for the clarification!

Obviously, disk and network have blocking potential by orders of magnitude
greater than main memory. Still, looking at the discussions at large about
hardware architectures (from the optimal location of the memory controller
to attempts to memory access optimizations such as the fully-buffered DIMMs)
as well as the efforts put by OS designers into "memory placement
optimization" frameworks -- I'd candidly think that the overhead of
accessing main memory will count at the end of the day. (Especially so that
we're talking about hundreds of CPUs here with a proportionately large
aggregate working set to manage.)

Or is the assumption here that by the time the FJ framework goes into
full-scale production, the problem of main memory access will have been
dealt with efficiently enough by the lower level stuff? Or (not necessarily
alternatively) does the FJ framework's implementation contain logic that
deals with this kind of blockings?

(I am not arguing for or against something, I am just trying to collect the
bits of information I need to understand the system.)

(I know almost nothing of video subsystems, but is not writing to the
console roughly equivalent to writing to main memory? Is it not that the CPU
writes to the video memory and forgets about it? The video subsystem then
processes the input asynchronously on its own. Is it not that simple?)

Thanks
Peter

On Jan 22, 2008 1:39 AM, David Holmes <dcholmes at optusnet.com.au> wrote:

> But to clarify Doug's answer, "blocked I/O" is as Tim referred to - disk /
> network / console ie traditional IO devices. It does not concern memory
> access or cpu scheduling issues.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> > Sent: Monday, 21 January 2008 11:32 PM
> > To: Peter Kovacs
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] ParallelArray updates du jour
> >
> >
> > >
> > >
> > > "The computation defined in the compute method should not in general
> > > perform
> > > any other form of blocking synchronization, should not perform IO, and
> > > should be independent of other tasks."
> > >
> > > The kind of blocking which I feel could be more closely defined is:
> IO.
> > > Naively, I would define IO as operations involving reading from, or
> > > writing
> > > to a physical device. Is main system memory (RAM) to be considered a
> > > physical device in this context? If so, I assume FJTask
> > instances must be
> > > fine-grained enough for the working set of any individual
> > FJTask instance
> > > to  fit into the on-CPU cache of the processor the FJTask starts being
> > > scheduled on.
> > >
> > > A corollary requirement is then that FJTask instances should complete
> > > quickly enough so as to reduce the probability of
> > > (a) the OS "migrating the instance" to another CPU due to rescheduling
> > > (b) the instance being rescheduled in general - in case the on-CPU
> cache
> > > is
> > > not large enough to hold the working sets of multiple instances.
> > >
> > > Is this correct?
> > >
> >
> > More or less. Like all lightweight-task frameworks, FJ does
> > not explicitly cope with blocked IO: If a worker thread
> > blocks on IO, then (1) it is not available to help process
> > other tasks (2) Other worker threads waiting for the task
> > to complete (i.e., to join it) may run out of work and waste
> > CPU cycles. Neither of these issues completely eliminates
> > potential use, but they do require a lot of explicit care.
> > For example, you could place tasks that may experience
> > sustained blockages in their own small ForkJoinPools.
> > (The fortress folks do something along these lines
> > mapping fortress "fair" threads onto forkjoin.) You
> > can also dynamically increase worker pool sizes (we
> > have methods to do this) when blockages may occur.
> > All in all though, the reason for the restrictions and
> > advice are that we do not have good automated support
> > for these kinds of cases, and don't yet know of the
> > best practices, or whether it is a good idea at all.
> >
> > -Doug
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/33374988/attachment.html 

From dcholmes at optusnet.com.au  Tue Jan 22 04:30:49 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 22 Jan 2008 19:30:49 +1000
Subject: [concurrency-interest] ParallelArray updates du jour
In-Reply-To: <b6e8f2e80801220120s7238059ci3aaab0c7468ef9fa@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEDIHKAA.dcholmes@optusnet.com.au>

Peter,

These things will impact performance but they do not consitute blocking as
proscribed by the framework. A cache miss is not considered a blocking
operation, even though a system could "swap out" one thread/process for
another while it is handled. There is very little you can do about this, as
an application programmer, without being unduly familiar with the VM, it's
native compilation scheme (object layouts etc) and even the OS. I don't
believe there is any intention for the framework to aid you at this level of
detail.

Regarding the console, I was thinking about the I part of IO :)

Cheers,
David

 -----Original Message-----
From: peter.kovacs.benomuki at gmail.com
[mailto:peter.kovacs.benomuki at gmail.com]On Behalf Of Peter Kovacs
Sent: Tuesday, 22 January 2008 7:21 PM
To: dholmes at ieee.org
Cc: Doug Lea; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] ParallelArray updates du jour


  Thank you, David, for the clarification!

  Obviously, disk and network have blocking potential by orders of magnitude
greater than main memory. Still, looking at the discussions at large about
hardware architectures (from the optimal location of the memory controller
to attempts to memory access optimizations such as the fully-buffered DIMMs)
as well as the efforts put by OS designers into "memory placement
optimization" frameworks -- I'd candidly think that the overhead of
accessing main memory will count at the end of the day. (Especially so that
we're talking about hundreds of CPUs here with a proportionately large
aggregate working set to manage.)

  Or is the assumption here that by the time the FJ framework goes into
full-scale production, the problem of main memory access will have been
dealt with efficiently enough by the lower level stuff? Or (not necessarily
alternatively) does the FJ framework's implementation contain logic that
deals with this kind of blockings?

  (I am not arguing for or against something, I am just trying to collect
the bits of information I need to understand the system.)

  (I know almost nothing of video subsystems, but is not writing to the
console roughly equivalent to writing to main memory? Is it not that the CPU
writes to the video memory and forgets about it? The video subsystem then
processes the input asynchronously on its own. Is it not that simple?)

  Thanks
  Peter


  On Jan 22, 2008 1:39 AM, David Holmes <dcholmes at optusnet.com.au> wrote:

    But to clarify Doug's answer, "blocked I/O" is as Tim referred to - disk
/
    network / console ie traditional IO devices. It does not concern memory
    access or cpu scheduling issues.

    Cheers,
    David Holmes


    > -----Original Message-----
    > From: concurrency-interest-bounces at cs.oswego.edu
    > [mailto: concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug
Lea
    > Sent: Monday, 21 January 2008 11:32 PM
    > To: Peter Kovacs
    > Cc: concurrency-interest at cs.oswego.edu
    > Subject: Re: [concurrency-interest] ParallelArray updates du jour
    >
    >
    > >
    > >
    > > "The computation defined in the compute method should not in general
    > > perform
    > > any other form of blocking synchronization, should not perform IO,
and
    > > should be independent of other tasks."
    > >
    > > The kind of blocking which I feel could be more closely defined is:
IO.
    > > Naively, I would define IO as operations involving reading from, or
    > > writing
    > > to a physical device. Is main system memory (RAM) to be considered a
    > > physical device in this context? If so, I assume FJTask
    > instances must be
    > > fine-grained enough for the working set of any individual
    > FJTask instance
    > > to  fit into the on-CPU cache of the processor the FJTask starts
being
    > > scheduled on.
    > >
    > > A corollary requirement is then that FJTask instances should
complete
    > > quickly enough so as to reduce the probability of
    > > (a) the OS "migrating the instance" to another CPU due to
rescheduling
    > > (b) the instance being rescheduled in general - in case the on-CPU
cache
    > > is
    > > not large enough to hold the working sets of multiple instances.
    > >
    > > Is this correct?
    > >
    >
    > More or less. Like all lightweight-task frameworks, FJ does
    > not explicitly cope with blocked IO: If a worker thread
    > blocks on IO, then (1) it is not available to help process
    > other tasks (2) Other worker threads waiting for the task
    > to complete (i.e., to join it) may run out of work and waste
    > CPU cycles. Neither of these issues completely eliminates
    > potential use, but they do require a lot of explicit care.
    > For example, you could place tasks that may experience
    > sustained blockages in their own small ForkJoinPools.
    > (The fortress folks do something along these lines
    > mapping fortress "fair" threads onto forkjoin.) You
    > can also dynamically increase worker pool sizes (we
    > have methods to do this) when blockages may occur.
    > All in all though, the reason for the restrictions and
    > advice are that we do not have good automated support
    > for these kinds of cases, and don't yet know of the
    > best practices, or whether it is a good idea at all.
    >
    > -Doug
    >
    >

    > _______________________________________________
    > Concurrency-interest mailing list
    > Concurrency-interest at altair.cs.oswego.edu
    > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
    >



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/4d72feba/attachment-0001.html 

From tim at peierls.net  Tue Jan 22 11:59:21 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 22 Jan 2008 11:59:21 -0500
Subject: [concurrency-interest] More FJ/PA examples and documentation needed
Message-ID: <63b4e4050801220859x607d3543raf97c01fe77b6aad@mail.gmail.com>

I'd like encourage folks who have any experience with or enthusiasm for the
new jsr166y classes to contribute articles to the wiki at

http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W1

Anything about fork-join, ParallelArray, and friends is fair game: examples
of use (real or artificial), tools, documentation aids, and any other
observations. In addition, over the years this mailing list has generated a
lot of potentially useful concurrency-related code snippets that have never
been gathered in an organized way. Please feel free to use this wiki to
remedy that situation as well.

Jacques DeFarge has already done some great work putting in a basic
structure. (Thanks, Jacques!)  Don't be shy -- if you've run some code and
it appears to do something useful or instructive, it's probably worth
sharing with the community, even (perhaps especially!) if it has flaws.

Please limit code contributions to snippets that are not fettered by any
licensing issues. If you want to include licensed code in your examples,
provide links to it instead and put a warning to this effect in the link
text. (I'd appreciate advice on whether a less restrictive policy is
feasible.)

There's nothing preventing anonymous contributions, but if possible, leave
contact info so others can consult you before making revisions to your
articles.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/5c0429bf/attachment.html 

From David.Biesack at sas.com  Tue Jan 22 14:13:15 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 22 Jan 2008 14:13:15 -0500 (EST)
Subject: [concurrency-interest] More FJ/PA examples and documentation
	needed (Tim Peierls)
In-Reply-To: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <200801221913.m0MJDFWe004203@cs.oswego.edu>


> Date: Tue, 22 Jan 2008 11:59:21 -0500
> From: Tim Peierls <tim at peierls.net>
> Subject: [concurrency-interest] More FJ/PA examples and documentation needed
> 
> I'd like encourage folks who have any experience with or enthusiasm for the
> new jsr166y classes to contribute articles to the wiki at
> 
> http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W1

Thanks for putting this up, Tim. 

I added some more very basic examples to the Examples pages : http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W6 :

  Creating arrays: http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W17

  Initializing arrays: http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W18

  Modifying arrays: http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W19

and put in placeh olders for othe examples:

    Combining arrays
    Using subarrays
    Filtering arrays
    Chaining Mappings, Filters, and Bounds  

Is there any way to alter the stylesheet of the wiki so that the page width is a bit wider (i.e. less padding on the left and right)? The narrow page setting is causing code snippets to wrap at unfortunate line boundaries, and this is not evident in the WYSIWYG edit mode, only when you save pages.

> --tim

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From tim at peierls.net  Tue Jan 22 14:21:36 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 22 Jan 2008 14:21:36 -0500
Subject: [concurrency-interest] More FJ/PA examples and documentation
	needed (Tim Peierls)
In-Reply-To: <200801221913.m0MJDFWe004203@cs.oswego.edu>
References: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
	<200801221913.m0MJDFWe004203@cs.oswego.edu>
Message-ID: <63b4e4050801221121i6397665cxd14f327db8c8be77@mail.gmail.com>

On Jan 22, 2008 2:13 PM, David J. Biesack <David.Biesack at sas.com> wrote:

> I added some more very basic examples to the Examples pages :


Thanks, David!


Is there any way to alter the stylesheet of the wiki so that the page width
> is a bit wider (i.e. less padding on the left and right)? The narrow page
> setting is causing code snippets to wrap at unfortunate line boundaries, and
> this is not evident in the WYSIWYG edit mode, only when you save pages.
>

The width was at 640px, and I just changed it to 740px. Is that enough? Too
much?

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/f60a196f/attachment.html 

From David.Biesack at sas.com  Tue Jan 22 14:39:00 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 22 Jan 2008 14:39:00 -0500 (EST)
Subject: [concurrency-interest] More FJ/PA examples and documentation
	needed (Tim Peierls)
In-Reply-To: <63b4e4050801221121i6397665cxd14f327db8c8be77@mail.gmail.com>
	(tim@peierls.net)
References: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
	<200801221913.m0MJDFWe004203@cs.oswego.edu>
	<63b4e4050801221121i6397665cxd14f327db8c8be77@mail.gmail.com>
Message-ID: <200801221939.m0MJd03x005693@cs.oswego.edu>

> Date: Tue, 22 Jan 2008 14:21:36 -0500
> From: "Tim Peierls" <tim at peierls.net>
> Cc: concurrency-interest at cs.oswego.edu
> 
> Is there any way to alter the stylesheet of the wiki so that the page width
> > is a bit wider (i.e. less padding on the left and right)? 
> 
> The width was at 640px, and I just changed it to 740px. Is that enough? Too
> much?

That looks better. I have a widescreen monitor and so I have plenty more room, but 740 is adequate for on screen, and it seems to work very nicely if I export the pages to a PDF file. Does it look ok for others?

thanks

> --tim

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From gregg at cytetech.com  Tue Jan 22 16:59:45 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Tue, 22 Jan 2008 15:59:45 -0600
Subject: [concurrency-interest] More FJ/PA examples and documentation
 needed (Tim Peierls)
In-Reply-To: <200801221939.m0MJd03x005693@cs.oswego.edu>
References: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
	<200801221913.m0MJDFWe004203@cs.oswego.edu>
	<63b4e4050801221121i6397665cxd14f327db8c8be77@mail.gmail.com>
	<200801221939.m0MJd03x005693@cs.oswego.edu>
Message-ID: <47966751.6040007@cytetech.com>

David J. Biesack wrote:
>> Date: Tue, 22 Jan 2008 14:21:36 -0500
>> From: "Tim Peierls" <tim at peierls.net>
>> Cc: concurrency-interest at cs.oswego.edu
>>
>> Is there any way to alter the stylesheet of the wiki so that the page width
>>> is a bit wider (i.e. less padding on the left and right)? 
>> The width was at 640px, and I just changed it to 740px. Is that enough? Too
>> much?
> 
> That looks better. I have a widescreen monitor and so I have plenty more room, but 740 is adequate for on screen, and it seems to work very nicely if I export the pages to a PDF file. Does it look ok for others?

Narrow screens, for technologists would seem to be a thing of the past.  Is it 
possible to set widths on the left and right sides, and allow the middle to be 
unconstrained to "fit" into the available space so that it can be as wide as 
someone has screen space to use?

Gregg Wonderly

From tim at peierls.net  Tue Jan 22 17:08:55 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 22 Jan 2008 17:08:55 -0500
Subject: [concurrency-interest] More FJ/PA examples and documentation
	needed (Tim Peierls)
In-Reply-To: <47966751.6040007@cytetech.com>
References: <mailman.3.1201021200.22842.concurrency-interest@altair.cs.oswego.edu>
	<200801221913.m0MJDFWe004203@cs.oswego.edu>
	<63b4e4050801221121i6397665cxd14f327db8c8be77@mail.gmail.com>
	<200801221939.m0MJd03x005693@cs.oswego.edu>
	<47966751.6040007@cytetech.com>
Message-ID: <63b4e4050801221408y238a6964p24282cc245ae5910@mail.gmail.com>

On Jan 22, 2008 4:59 PM, Gregg Wonderly <gregg at cytetech.com> wrote:

> Is it possible to set widths on the left and right sides, and allow the
> middle to be unconstrained to "fit" into the available space so that it can
> be as wide as someone has screen space to use?
>

Probably, but not by me with my limited skills and even more limited time.

I've appended two files below, the HTML template and the CSS. The template
parameters are surrounded by $, e.g., $headline$. Anyone who knows how to
make fluid layouts, please feel free to tweak these and send me the
modifications.

Here's the HTML template:

<!--
Customize the layout of an entire Wiki by editing this template.
This basic template displays the article headline, a small timestamp, and
the article body.
-->

<div class="center"><div id="idContainer">

    <div class='wikiSearch'>
        <table cellspacing='0' cellpadding='0' border='0'><tr><td>
            <label for='wikiSearchFor'>Search this wiki</label><br />
        </td></tr><tr><td>$search$</td></tr></table>
    </div>

    <h1>$headline$</h1>

    <div id="idMeta">
        <table cellpadding="0" cellspacing="0" border="0"
width="100%"><tr><td>
            <span class="color32">
            <i>$lastmodified$<br/>$subscribelink$</i>
            </span>
        </td><td align="right">
            $rsslink$
        </td></tr></table>
    </div>

    $body$

    <div id="idFooter">
        <table cellpadding="0" cellspacing="0" border="0"
width="100%"><tr><td>
            <span class="color32">
            <i>Home: <a href="$homeurl$">$homeheadline$</a></i>
            </span>
        </td><td align="right">
            <span class="color32">
            <i>What's new: <a href="$recenturl$">Recently changed
articles</a></i>
            </span>
        </td></tr><tr><td>
                        <span class="color32">
                        <i>Admin: <a href="mailto:tim at peierls.net">Tim
Peierls</a></i>
                        </span>
        </td></tr></table>
    </div>

</div></div>

And here's the CSS:

/* Customize the styles of an entire Wiki by editing this stylesheet. */

/* Font Families */
    span.Arial { font-family: Arial, Helvetica, sans-serif }
    span.Helvetica { font-family: Helvetica, Arial, sans-serif }
    span.ArialBlack { font-family: Arial Black, Gadget, sans-serif }
    span.Comic { font-family: Comic Sans MS, cursive }
    span.Courier { font-family: Courier, Courier New, monospace }
    span.Georgia { font-family: Georgia, serif }
    span.Impact { font-family: Impact, Charcoal, sans-serif }
    span.Console { font-family: Lucida Console, Monaco, monospace }
    span.Palatino { font-family: Palatino Linotype, Book Antiqua, Palatino,
serif }
    span.Tahoma { font-family: Tahoma, Geneva, sans-serif }
    span.Times { font-family: Times New Roman, Times, serif }
    span.Verdana { font-family: Verdana, Geneva, sans-serif }

/* Font Sizes */
    span.LudicrousHuge { font-size: 128px }
    span.OutrageouslyHuge { font-size: 64px }
    span.VeryBig { font-size: 26px }
    span.Big { font-size: 20px }
    span.Small { font-size: 12px }
    span.VerySmall { font-size: 10px }
    span.Microscopic { font-size: 6px }

/* Paragraph Styles */
    /* Example: p.ExtraPadding { padding: 25px; } */

/* Heading Styles */
    /* Example: h1.HugeBlue { font-size:100px; color: blue; } */

/* Image Styles */
    img.FloatLeft { float: left; }
    img.FloatRight { float: right; }
    img.Outset {
        border-top: 1px solid #C7C7C7;
        border-left: 1px solid #C7C7C7;
        border-right: 1px solid #444444;
        border-bottom: 1px solid #444444;
    }

/* Table Styles */
    table.Basic { BORDER-COLLAPSE: collapse }
    table.Basic TR TD { border:1px solid black; }
    table.Basic TR TH { border:1px solid black; background-color: #B3EEEE; }

    table.LightBlue { BORDER-COLLAPSE: collapse; }

    table.LightBlue th {
        font: bold 12px Arial, Helvetica, Verdana, sans-serif;
        color: black;
        border: 1px solid black;
        background-color: #99C1E9;
        text-transform: uppercase;
        text-align: center;
        padding: 4px;
    }

    table.LightBlue td {
        color: black;
        border: 1px solid black;
        background-color: #D6E6F6;
        padding: 4px;
        text-align: left;
    }

    table.YellowHighlight { BORDER-COLLAPSE: collapse; }

    table.YellowHighlight th {
        font: bold 12px Arial, Helvetica, Verdana, sans-serif;
        color: black;
        border: 2px solid white;
        background-color: #E9FDD6;
        text-transform: uppercase;
        text-align: center;
        padding: 4px;
    }

    table.YellowHighlight td {
        color: black;
        border: 2px solid white;
        background-color: #FDFDD6;
        padding: 4px;
        text-align: left;
    }

    table.DarkBold { BORDER-COLLAPSE: collapse;    }

    table.DarkBold th {
        font: bold 14px Arial, Helvetica, Verdana, sans-serif;
        color: white;
        border: 1px solid black;
        background-color: black;
        text-transform: uppercase;
        text-align: center;
        padding: 4px;
    }

    table.DarkBold td {
        font-weight: bold;
        color: #9BADBA;
        border: 1px solid black;
        background-color: #053353;
        padding: 4px;
        text-align: left;
    }

    table td.Header { font-size: 20px; }
    table td.Highlight { background-color: yellow; }

    h1 { margin: 0; }

    .center { text-align: center; }

    #idContainer {
        width: 740px;
        margin-left: auto;
        margin-right: auto;
        text-align: left;
    }

    #idMeta, #idFooter {
        padding: 6px 0;
        font-size: 11px;
    }

    #idMeta {
        border-bottom: 2px solid #E9F0F6;
    }

    #idFooter {
        border-top: 2px solid #E9F0F6;
    }


/* Palette Colors */
    span.color10           { color:            rgb(255,255,255) }
    span.color10_highlight { background-color: rgb(255,255,255) }

    span.color11           { color:            rgb(0,0,0) }
    span.color11_highlight { background-color: rgb(0,0,0) }

    span.color12           { color:            rgb(250,243,232) }
    span.color12_highlight { background-color: rgb(250,243,232) }

    span.color13           { color:            rgb(31,73,125) }
    span.color13_highlight { background-color: rgb(31,73,125) }

    span.color14           { color:            rgb(92,131,180) }
    span.color14_highlight { background-color: rgb(92,131,180) }

    span.color15           { color:            rgb(192,80,77) }
    span.color15_highlight { background-color: rgb(192,80,77) }

    span.color16           { color:            rgb(157,187,97) }
    span.color16_highlight { background-color: rgb(157,187,97) }

    span.color17           { color:            rgb(128,102,160) }
    span.color17_highlight { background-color: rgb(128,102,160) }

    span.color18           { color:            rgb(75,172,198) }
    span.color18_highlight { background-color: rgb(75,172,198) }

    span.color19           { color:            rgb(245,157,86) }
    span.color19_highlight { background-color: rgb(245,157,86) }

    span.color20           { color:            rgb(216,216,216) }
    span.color20_highlight { background-color: rgb(216,216,216) }

    span.color21           { color:            rgb(127,127,127) }
    span.color21_highlight { background-color: rgb(127,127,127) }

    span.color22           { color:            rgb(187,182,174) }
    span.color22_highlight { background-color: rgb(187,182,174) }

    span.color23           { color:            rgb(199,209,222) }
    span.color23_highlight { background-color: rgb(199,209,222) }

    span.color24           { color:            rgb(214,224,236) }
    span.color24_highlight { background-color: rgb(214,224,236) }

    span.color25           { color:            rgb(239,211,210) }
    span.color25_highlight { background-color: rgb(239,211,210) }

    span.color26           { color:            rgb(230,238,215) }
    span.color26_highlight { background-color: rgb(230,238,215) }

    span.color27           { color:            rgb(223,216,231) }
    span.color27_highlight { background-color: rgb(223,216,231) }

    span.color28           { color:            rgb(210,234,240) }
    span.color28_highlight { background-color: rgb(210,234,240) }

    span.color29           { color:            rgb(252,230,212) }
    span.color29_highlight { background-color: rgb(252,230,212) }

    span.color30           { color:            rgb(191,191,191) }
    span.color30_highlight { background-color: rgb(191,191,191) }

    span.color31           { color:            rgb(114,114,114) }
    span.color31_highlight { background-color: rgb(114,114,114) }

    span.color32           { color:            rgb(162,157,150) }
    span.color32_highlight { background-color: rgb(162,157,150) }

    span.color33           { color:            rgb(143,164,190) }
    span.color33_highlight { background-color: rgb(143,164,190) }

    span.color34           { color:            rgb(173,193,217) }
    span.color34_highlight { background-color: rgb(173,193,217) }

    span.color35           { color:            rgb(223,167,166) }
    span.color35_highlight { background-color: rgb(223,167,166) }

    span.color36           { color:            rgb(206,221,176) }
    span.color36_highlight { background-color: rgb(206,221,176) }

    span.color37           { color:            rgb(191,178,207) }
    span.color37_highlight { background-color: rgb(191,178,207) }

    span.color38           { color:            rgb(165,213,226) }
    span.color38_highlight { background-color: rgb(165,213,226) }

    span.color39           { color:            rgb(250,206,170) }
    span.color39_highlight { background-color: rgb(250,206,170) }

    span.color40           { color:            rgb(165,165,165) }
    span.color40_highlight { background-color: rgb(165,165,165) }

    span.color41           { color:            rgb(89,89,89) }
    span.color41_highlight { background-color: rgb(89,89,89) }

    span.color42           { color:            rgb(125,121,116) }
    span.color42_highlight { background-color: rgb(125,121,116) }

    span.color43           { color:            rgb(87,118,157) }
    span.color43_highlight { background-color: rgb(87,118,157) }

    span.color44           { color:            rgb(132,162,198) }
    span.color44_highlight { background-color: rgb(132,162,198) }

    span.color45           { color:            rgb(207,123,121) }
    span.color45_highlight { background-color: rgb(207,123,121) }

    span.color46           { color:            rgb(181,204,136) }
    span.color46_highlight { background-color: rgb(181,204,136) }

    span.color47           { color:            rgb(159,140,183) }
    span.color47_highlight { background-color: rgb(159,140,183) }

    span.color48           { color:            rgb(120,192,212) }
    span.color48_highlight { background-color: rgb(120,192,212) }

    span.color49           { color:            rgb(247,181,128) }
    span.color49_highlight { background-color: rgb(247,181,128) }

    span.color50           { color:            rgb(140,140,140) }
    span.color50_highlight { background-color: rgb(140,140,140) }

    span.color51           { color:            rgb(63,63,63) }
    span.color51_highlight { background-color: rgb(63,63,63) }

    span.color52           { color:            rgb(87,85,81) }
    span.color52_highlight { background-color: rgb(87,85,81) }

    span.color53           { color:            rgb(23,54,93) }
    span.color53_highlight { background-color: rgb(23,54,93) }

    span.color54           { color:            rgb(69,98,135) }
    span.color54_highlight { background-color: rgb(69,98,135) }

    span.color55           { color:            rgb(144,60,57) }
    span.color55_highlight { background-color: rgb(144,60,57) }

    span.color56           { color:            rgb(117,140,72) }
    span.color56_highlight { background-color: rgb(117,140,72) }

    span.color57           { color:            rgb(96,76,120) }
    span.color57_highlight { background-color: rgb(96,76,120) }

    span.color58           { color:            rgb(56,129,148) }
    span.color58_highlight { background-color: rgb(56,129,148) }

    span.color59           { color:            rgb(183,117,64) }
    span.color59_highlight { background-color: rgb(183,117,64) }

    span.color60           { color:            rgb(127,127,127) }
    span.color60_highlight { background-color: rgb(127,127,127) }

    span.color61           { color:            rgb(38,38,38) }
    span.color61_highlight { background-color: rgb(38,38,38) }

    span.color62           { color:            rgb(62,60,58) }
    span.color62_highlight { background-color: rgb(62,60,58) }

    span.color63           { color:            rgb(15,36,62) }
    span.color63_highlight { background-color: rgb(15,36,62) }

    span.color64           { color:            rgb(46,65,90) }
    span.color64_highlight { background-color: rgb(46,65,90) }

    span.color65           { color:            rgb(96,40,38) }
    span.color65_highlight { background-color: rgb(96,40,38) }

    span.color66           { color:            rgb(78,93,48) }
    span.color66_highlight { background-color: rgb(78,93,48) }

    span.color67           { color:            rgb(64,51,80) }
    span.color67_highlight { background-color: rgb(64,51,80) }

    span.color68           { color:            rgb(37,86,99) }
    span.color68_highlight { background-color: rgb(37,86,99) }

    span.color69           { color:            rgb(122,78,43) }
    span.color69_highlight { background-color: rgb(122,78,43) }


    @media print {
        /* Customize the styles of your printed articles by adding styles
within this @media block. */
    }

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080122/9fee976b/attachment-0001.html 

From unmesh_joshi at hotmail.com  Tue Jan 22 23:01:08 2008
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 23 Jan 2008 04:01:08 +0000
Subject: [concurrency-interest] Synchronization blocks, locks and reorderings
Message-ID: <BAY140-W2CD565C224013454FA98FEF3F0@phx.gbl>


Hi,
 
I was reading http://today.java.net/pub/a/today/2004/04/13/JSR133.html. Discussing reordering there, 
 
class Reordering {  int x = 0, y = 0;  Object l = new Object();  public void writer() {    x = 1;    synchronized (l) {      y = 2;    }  }  public void reader() {    synchronized (l) {      int r1 = y;      int r2 = x;    }  }}
 
In the happens-before discussion it is stated that, 
 
"A thread calling reader() will now see the values of x and y placed there by the thread calling writer(). The writer() method contains four actions -- write to x, lock l, write to y, and unlock l. By the program order rule, the writes to x and y happen before the unlock of l. Similarly, the reader() method contains four actions -- lock l, read x, read y, and unlock l, and again by the program order rule the reads of x and y happen after the lock operation. Since by the monitor rule, the unlock operation in writer() happens before the lock operation in reader(), we can see (by transitivity) that the writes to x and y in writer() happen before the reads of x and y in reader(), and therefore the correct values are visible to the thread calling reader()."
 
I am little confused here, 
1. Because variable x is never read in synchronized block of writer, it isn't compiler free to reorder read to x after write to y? Or there are no reordering allowed around synchronization blocks?
 
2. In the discussion, its stated that "the unlock operation in writer() happens before the lock operation in reader()". How can this be guaranteed? It can very well be exactly opposite, right?
 
Thanks,
Unmesh
_________________________________________________________________
Post ads for free - to sell, rent or even buy.www.yello.in
http://ss1.richmedia.in/recurl.asp?pid=186
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/b0c168e0/attachment.html 

From unmesh_joshi at hotmail.com  Tue Jan 22 23:09:12 2008
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 23 Jan 2008 04:09:12 +0000
Subject: [concurrency-interest] Cloning in CachingFactorizer in Java
	Concurrency in Practice
In-Reply-To: <mailman.29.1201039863.28502.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.29.1201039863.28502.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <BAY140-W276F25B68F72174377A08FEF3F0@phx.gbl>


Hi,
 
I just started reading Java Concurrency in practice. In the following CachingFactorizer example
 
BigInteger i = extractFromRequest(req);
BigInteger[] factors = null;
synchronized (this) {
++hits;
if (i.equals(lastNumber)) {
++cacheHits;
factors = lastFactors.clone();
}
}
if (factors == null) {
factors = factor(i);
synchronized (this) {
lastNumber = i;
lastFactors = factors.clone();
}
}
encodeIntoResponse(resp, factors);
}
 
factors and lastFactors are cloned in the synchronized blocks, but there is no explanation at that point why they are cloned. In the Object Sharing section, stack confinement is discussed, but using a different example. I think it will help reader if a note is added at that point saying that cloning here is for stack confinement, because assignments to factors or lastfactors is indirectly publishing the array to other thread which can be processing the array in encodeIntoResponse method.
 
Thanks,
Unmesh
_________________________________________________________________
Tried the new MSN Messenger? It?s cool! Download now.
http://messenger.msn.com/Download/Default.aspx?mkt=en-in
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/b686d8c0/attachment.html 

From dcholmes at optusnet.com.au  Tue Jan 22 23:36:02 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jan 2008 14:36:02 +1000
Subject: [concurrency-interest] Synchronization blocks,
	locks and reorderings
In-Reply-To: <BAY140-W2CD565C224013454FA98FEF3F0@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEDNHKAA.dcholmes@optusnet.com.au>

Hi Unmesh,

Ans #1: The write to x can move into the synchronized block, but it can't
move past it. In the memory model this is informally known as the "Roach
Motel" property - "you can move in but you can't move out". I don't recall
what formal rule defines this property; it might be a consequence of
maintaining "program order".

Ans #2: writer() holds the lock when the unlock occurs therefore the unlock
must happen before any subsequent lock by another thread - by the mutual
exclusion properties of locks. Now reader() could get the lock before
writer() but that wasn't the scenario being discussed. In general you have
to be careful about the logical notion of "happens before" and the
memory-model happens-before relationship.

Hope this clarifies things somewhat.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
  Sent: Wednesday, 23 January 2008 2:01 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Synchronization blocks, locks and
reorderings


  Hi,

  I was reading http://today.java.net/pub/a/today/2004/04/13/JSR133.html.
Discussing reordering there,

  class Reordering {
    int x = 0, y = 0;
    Object l = new Object();

    public void writer() {
      x = 1;
      synchronized (l) {
        y = 2;
      }
    }

    public void reader() {
      synchronized (l) {
        int r1 = y;
        int r2 = x;
      }
    }
  }

  In the happens-before discussion it is stated that,

  "A thread calling reader() will now see the values of x and y placed there
by the thread calling writer(). The writer() method contains four actions --
write to x, lock l, write to y, and unlock l. By the program order rule, the
writes to x and y happen before the unlock of l. Similarly, the reader()
method contains four actions -- lock l, read x, read y, and unlock l, and
again by the program order rule the reads of x and y happen after the lock
operation. Since by the monitor rule, the unlock operation in writer()
happens before the lock operation in reader(), we can see (by transitivity)
that the writes to x and y in writer() happen before the reads of x and y in
reader(), and therefore the correct values are visible to the thread calling
reader()."

  I am little confused here,
  1. Because variable x is never read in synchronized block of writer, it
isn't compiler free to reorder read to x after write to y? Or there are no
reordering allowed around synchronization blocks?

  2. In the discussion, its stated that "the unlock operation in writer()
happens before the lock operation in reader()". How can this be guaranteed?
It can very well be exactly opposite, right?

  Thanks,
  Unmesh


----------------------------------------------------------------------------
--
  Post free auto ads on Yello Classifieds now! Try it now!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/53685f8c/attachment.html 

From dcholmes at optusnet.com.au  Tue Jan 22 23:40:41 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jan 2008 14:40:41 +1000
Subject: [concurrency-interest] Cloning in CachingFactorizer in
	JavaConcurrency in Practice
In-Reply-To: <BAY140-W276F25B68F72174377A08FEF3F0@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEDNHKAA.dcholmes@optusnet.com.au>

The cloning isn't for concurrency reasons but just the usual defensive
copying so that the receiver of the array can't mess with the original
contents.

Effective Java item 24.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
  Sent: Wednesday, 23 January 2008 2:09 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice


  Hi,

  I just started reading Java Concurrency in practice. In the following
CachingFactorizer example


  BigInteger i = extractFromRequest(req);

  BigInteger[] factors = null;

  synchronized (this) {

  ++hits;

  if (i.equals(lastNumber)) {

  ++cacheHits;

  factors = lastFactors.clone();

  }

  }

  if (factors == null) {

  factors = factor(i);

  synchronized (this) {

  lastNumber = i;

  lastFactors = factors.clone();

  }

  }

  encodeIntoResponse(resp, factors);

  }



  factors and lastFactors are cloned in the synchronized blocks, but there
is no explanation at that point why they are cloned. In the Object Sharing
section, stack confinement is discussed, but using a different example. I
think it will help reader if a note is added at that point saying that
cloning here is for stack confinement, because assignments to factors or
lastfactors is indirectly publishing the array to other thread which can be
processing the array in encodeIntoResponse method.



  Thanks,

  Unmesh



----------------------------------------------------------------------------
--
  Live the life in style with MSN Lifestyle. Check out! Try it now!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/45c1de5d/attachment-0001.html 

From unmesh_joshi at hotmail.com  Wed Jan 23 00:09:51 2008
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 23 Jan 2008 05:09:51 +0000
Subject: [concurrency-interest] Cloning in CachingFactorizer in
 JavaConcurrency in Practice
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEDNHKAA.dcholmes@optusnet.com.au>
References: <BAY140-W276F25B68F72174377A08FEF3F0@phx.gbl>
	<NFBBKALFDCPFIDBNKAPCIEDNHKAA.dcholmes@optusnet.com.au>
Message-ID: <BAY140-W85234F666FDAD22B4C839EF3F0@phx.gbl>



But isn't that receiver of the array is another thread? So if encodeIntoResponse can mess up array, there can be concurency issues?
From: dcholmes at optusnet.com.au
To: unmesh_joshi at hotmail.com; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in JavaConcurrency in Practice
Date: Wed, 23 Jan 2008 14:40:41 +1000










The 
cloning isn't for concurrency reasons but just the usual defensive copying 
so that the receiver of the array can't mess with the original 
contents.
 
Effective Java item 24.
 
Cheers,
David 
Holmes

  -----Original Message-----
From: 
  concurrency-interest-bounces at cs.oswego.edu 
  [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh 
  joshi
Sent: Wednesday, 23 January 2008 2:09 PM
To: 
  concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] 
  Cloning in CachingFactorizer in JavaConcurrency in 
  Practice

Hi,
 
I just started reading Java 
  Concurrency in practice. In the following CachingFactorizer 
  example
 

  BigInteger i = extractFromRequest(req);
  BigInteger[] factors = null;
  synchronized (this) {
  ++hits;
  if (i.equals(lastNumber)) {
  ++cacheHits;
  factors = lastFactors.clone();
  }
  }
  if (factors == null) {
  factors = factor(i);
  synchronized (this) {
  lastNumber = i;
  lastFactors = factors.clone();
  }
  }
  encodeIntoResponse(resp, factors);
  }
   
  factors and lastFactors are cloned in the synchronized blocks, 
  but there is no explanation at that point why they are cloned. In the Object 
  Sharing section, stack confinement is discussed, but using a different 
  example. I think it will help reader if a note is added at that point saying 
  that cloning here is for stack confinement, because assignments to factors or 
  lastfactors is indirectly publishing the array to other thread which can be 
  processing the array in encodeIntoResponse method.
   
  Thanks,
  Unmesh

  
  Live the life in style with MSN Lifestyle. Check out! Try it now! 


_________________________________________________________________
Post ads for free - to sell, rent or even buy.www.yello.in
http://ss1.richmedia.in/recurl.asp?pid=186
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/ea0236fe/attachment.html 

From dcholmes at optusnet.com.au  Wed Jan 23 00:17:01 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jan 2008 15:17:01 +1000
Subject: [concurrency-interest] Cloning in CachingFactorizer in
	JavaConcurrency in Practice
In-Reply-To: <BAY140-W85234F666FDAD22B4C839EF3F0@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEDOHKAA.dcholmes@optusnet.com.au>

The immediate receiver is encodeIntoResponse, which is called in the same
thread. We don't know how it does what it does, or what other code gets
involved. Ultimately the array may end up being accessed by another thread,
but the defensive copying is done to protect against the code that can
access the array, not the thread.

Put another way, if we trusted all the code that could access the array,
then given these array contents are immutable once set, there would be no
need for cloning, no matter how many threads were involved.

Cheers,
David Holmes
  -----Original Message-----
  From: Unmesh joshi [mailto:unmesh_joshi at hotmail.com]
  Sent: Wednesday, 23 January 2008 3:10 PM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice



  But isn't that receiver of the array is another thread? So if
encodeIntoResponse can mess up array, there can be concurency issues?


----------------------------------------------------------------------------
    From: dcholmes at optusnet.com.au
    To: unmesh_joshi at hotmail.com; concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice
    Date: Wed, 23 Jan 2008 14:40:41 +1000


    The cloning isn't for concurrency reasons but just the usual defensive
copying so that the receiver of the array can't mess with the original
contents.

    Effective Java item 24.

    Cheers,
    David Holmes
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
      Sent: Wednesday, 23 January 2008 2:09 PM
      To: concurrency-interest at cs.oswego.edu
      Subject: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice


      Hi,

      I just started reading Java Concurrency in practice. In the following
CachingFactorizer example


      BigInteger i = extractFromRequest(req);

      BigInteger[] factors = null;

      synchronized (this) {

      ++hits;

      if (i.equals(lastNumber)) {

      ++cacheHits;

      factors = lastFactors.clone();

      }

      }

      if (factors == null) {

      factors = factor(i);

      synchronized (this) {

      lastNumber = i;

      lastFactors = factors.clone();

      }

      }

      encodeIntoResponse(resp, factors);

      }



      factors and lastFactors are cloned in the synchronized blocks, but
there is no explanation at that point why they are cloned. In the Object
Sharing section, stack confinement is discussed, but using a different
example. I think it will help reader if a note is added at that point saying
that cloning here is for stack confinement, because assignments to factors
or lastfactors is indirectly publishing the array to other thread which can
be processing the array in encodeIntoResponse method.



      Thanks,

      Unmesh



--------------------------------------------------------------------------
      Live the life in style with MSN Lifestyle. Check out! Try it now!


----------------------------------------------------------------------------
--
  Post free auto ads on Yello Classifieds now! Try it now!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/09e6c18d/attachment.html 

From unmesh_joshi at hotmail.com  Wed Jan 23 00:35:00 2008
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 23 Jan 2008 05:35:00 +0000
Subject: [concurrency-interest] Cloning in CachingFactorizer in
 JavaConcurrency in Practice
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEDOHKAA.dcholmes@optusnet.com.au>
References: <BAY140-W85234F666FDAD22B4C839EF3F0@phx.gbl>
	<NFBBKALFDCPFIDBNKAPCEEDOHKAA.dcholmes@optusnet.com.au>
Message-ID: <BAY140-W31EC69EA69289C09F446D0EF3F0@phx.gbl>


Well, then just to make code more intentional, do you think following will help?

      BigInteger i = extractFromRequest(req);
      BigInteger[] factors = null;
      synchronized 
      (this) {
      ++hits;
      if 
      (i.equals(lastNumber)) {
      ++cacheHits;
      factors = 
      lastFactors;
      }
      }
      if (factors == 
      null) {
      factors = 
      factor(i);
      synchronized 
      (this) {
      lastNumber = 
      i;
      lastFactors = 
      factors;
      }
      }
      encodeIntoResponse(resp, factors.clone()); 
}

From: dcholmes at optusnet.com.au
To: unmesh_joshi at hotmail.com; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in JavaConcurrency in Practice
Date: Wed, 23 Jan 2008 15:17:01 +1000










The 
immediate receiver is encodeIntoResponse, which is called in the same 
thread. We don't know how it does what it does, or what other code gets 
involved. Ultimately the array may end up being accessed by another thread, but 
the defensive copying is done to protect against the code that can access the 
array, not the thread.
 
Put 
another way, if we trusted all the code that could access the array, then given 
these array contents are immutable once set, there would be no need for cloning, 
no matter how many threads were involved.
 
Cheers,
David 
Holmes

  -----Original Message-----
From: Unmesh joshi 
  [mailto:unmesh_joshi at hotmail.com]
Sent: Wednesday, 23 January 2008 
  3:10 PM
To: dholmes at ieee.org; 
  concurrency-interest at cs.oswego.edu
Subject: RE: 
  [concurrency-interest] Cloning in CachingFactorizer in JavaConcurrency in 
  Practice


But isn't that receiver of the array is 
  another thread? So if encodeIntoResponse can mess up array, there can be concurency 
  issues?

  
    
    From: dcholmes at optusnet.com.au
To: unmesh_joshi at hotmail.com; 
    concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] 
    Cloning in CachingFactorizer in JavaConcurrency in Practice
Date: Wed, 23 
    Jan 2008 14:40:41 +1000


    
    

    The cloning isn't for concurrency reasons but just the 
    usual defensive copying so that the receiver of the array can't mess with 
    the original contents.
     
    Effective Java item 24.
     
    Cheers,
    David Holmes
    
      -----Original Message-----
From: 
      concurrency-interest-bounces at cs.oswego.edu 
      [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of 
      Unmesh joshi
Sent: Wednesday, 23 January 2008 2:09 
      PM
To: concurrency-interest at cs.oswego.edu
Subject: 
      [concurrency-interest] Cloning in CachingFactorizer in JavaConcurrency in 
      Practice

Hi,
 
I just started reading Java 
      Concurrency in practice. In the following CachingFactorizer 
      example
 

      BigInteger i = extractFromRequest(req);
      BigInteger[] factors = null;
      synchronized 
      (this) {
      ++hits;
      if 
      (i.equals(lastNumber)) {
      ++cacheHits;
      factors = 
      lastFactors.clone();
      }
      }
      if (factors == 
      null) {
      factors = 
      factor(i);
      synchronized 
      (this) {
      lastNumber = 
      i;
      lastFactors = 
      factors.clone();
      }
      }
      encodeIntoResponse(resp, factors);
      }
       
      factors and 
      lastFactors are cloned in the synchronized blocks, but there is no 
      explanation at that point why they are cloned. In the Object Sharing 
      section, stack confinement is discussed, but using a different example. I 
      think it will help reader if a note is added at that point saying that 
      cloning here is for stack confinement, because assignments to factors or 
      lastfactors is indirectly publishing the array to other thread which can 
      be processing the array in encodeIntoResponse 
      method.
       
      Thanks,
      Unmesh

      
      Live the life in style with MSN Lifestyle. Check out! Try it 
      now! 

  
  Post free auto ads on Yello Classifieds now! Try it now! 


_________________________________________________________________
Post ads for free - to sell, rent or even buy.www.yello.in
http://ss1.richmedia.in/recurl.asp?pid=186
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/3fbc848a/attachment-0001.html 

From dcholmes at optusnet.com.au  Wed Jan 23 01:00:50 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jan 2008 16:00:50 +1000
Subject: [concurrency-interest] Cloning in CachingFactorizer in
	JavaConcurrency in Practice
In-Reply-To: <BAY140-W31EC69EA69289C09F446D0EF3F0@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEDPHKAA.dcholmes@optusnet.com.au>

That change does seem a little more intentional.

David

 -----Original Message-----
From: Unmesh joshi [mailto:unmesh_joshi at hotmail.com]
Sent: Wednesday, 23 January 2008 3:35 PM
To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice


  Well, then just to make code more intentional, do you think following will
help?

  BigInteger i = extractFromRequest(req);

  BigInteger[] factors = null;

  synchronized (this) {

  ++hits;

  if (i.equals(lastNumber)) {

  ++cacheHits;

  factors = lastFactors;

  }

  }

  if (factors == null) {

  factors = factor(i);

  synchronized (this) {

  lastNumber = i;

  lastFactors = factors;

  }

  }

  encodeIntoResponse(resp, factors.clone());


  }





----------------------------------------------------------------------------
    From: dcholmes at optusnet.com.au
    To: unmesh_joshi at hotmail.com; concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice
    Date: Wed, 23 Jan 2008 15:17:01 +1000


    The immediate receiver is encodeIntoResponse, which is called in the
same thread. We don't know how it does what it does, or what other code gets
involved. Ultimately the array may end up being accessed by another thread,
but the defensive copying is done to protect against the code that can
access the array, not the thread.

    Put another way, if we trusted all the code that could access the array,
then given these array contents are immutable once set, there would be no
need for cloning, no matter how many threads were involved.

    Cheers,
    David Holmes
      -----Original Message-----
      From: Unmesh joshi [mailto:unmesh_joshi at hotmail.com]
      Sent: Wednesday, 23 January 2008 3:10 PM
      To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
      Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice



      But isn't that receiver of the array is another thread? So if
encodeIntoResponse can mess up array, there can be concurency issues?


------------------------------------------------------------------------
        From: dcholmes at optusnet.com.au
        To: unmesh_joshi at hotmail.com; concurrency-interest at cs.oswego.edu
        Subject: RE: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice
        Date: Wed, 23 Jan 2008 14:40:41 +1000


        The cloning isn't for concurrency reasons but just the usual
defensive copying so that the receiver of the array can't mess with the
original contents.

        Effective Java item 24.

        Cheers,
        David Holmes
          -----Original Message-----
          From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
          Sent: Wednesday, 23 January 2008 2:09 PM
          To: concurrency-interest at cs.oswego.edu
          Subject: [concurrency-interest] Cloning in CachingFactorizer in
JavaConcurrency in Practice


          Hi,

          I just started reading Java Concurrency in practice. In the
following CachingFactorizer example


          BigInteger i = extractFromRequest(req);

          BigInteger[] factors = null;

          synchronized (this) {

          ++hits;

          if (i.equals(lastNumber)) {

          ++cacheHits;

          factors = lastFactors.clone();

          }

          }

          if (factors == null) {

          factors = factor(i);

          synchronized (this) {

          lastNumber = i;

          lastFactors = factors.clone();

          }

          }

          encodeIntoResponse(resp, factors);

          }



          factors and lastFactors are cloned in the synchronized blocks, but
there is no explanation at that point why they are cloned. In the Object
Sharing section, stack confinement is discussed, but using a different
example. I think it will help reader if a note is added at that point saying
that cloning here is for stack confinement, because assignments to factors
or lastfactors is indirectly publishing the array to other thread which can
be processing the array in encodeIntoResponse method.



          Thanks,

          Unmesh



----------------------------------------------------------------------
          Live the life in style with MSN Lifestyle. Check out! Try it now!


--------------------------------------------------------------------------
      Post free auto ads on Yello Classifieds now! Try it now!


----------------------------------------------------------------------------
--
  Post free auto ads on Yello Classifieds now! Try it now!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/f9e0f394/attachment.html 

From David.Biesack at sas.com  Wed Jan 23 16:07:53 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Wed, 23 Jan 2008 16:07:53 -0500 (EST)
Subject: [concurrency-interest] jsr166y Parallel*Array
	withMapping/withFilter chaining
Message-ID: <200801232107.m0NL7rEi025390@cs.oswego.edu>


I find that I cannot do the following

   public ParallelDoubleArray chain(int size) {
        return = ParallelDoubleArray.create(size, myForkJoinExecutor)
         .replaceWithGeneratedValue(myGenerator)
         .withMapping(myMapping)
         .withFilter(myFilter)
         .withMapping(myOtherMapping).all();
    }

Instead, I am forced to construct an intermediate ParallelArray because withMapping returns a ParallelDoubleArrayWithMapping and that class does not provide a withFilter(Ops.DoublePredicate) method.

    public ParallelDoubleArray chain(int size) {
        ParallelDoubleArray intermediate;
        intermediate = ParallelDoubleArray.create(size, myForkJoinExecutor)
         .replaceWithGeneratedValue(myGenerator)
         .withMapping(myMapping).all();
         intermediate = intermediate.withFilter(myFilter)
         .withMapping(myOtherMapping).all();
        return intermediate;
    }

It appears to force premature allocation of the intermediate buffer and consequently higher intermediate memory consumption, a concern for larger arrays.

Is this by design (or necessity), or an accidental omission? I suppose I can see how a filter normally changes the number of elements and thus must be run completely before applying a next step (mapping), but even so, it would be nice for the framework to internalize this so that client code is not forced to express possibly inefficient paths that prevent future optimization.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From jeffrey.elrod at complexsive.com  Wed Jan 23 16:42:02 2008
From: jeffrey.elrod at complexsive.com (Jeffrey Elrod)
Date: Wed, 23 Jan 2008 13:42:02 -0800 (PST)
Subject: [concurrency-interest] Help with ThreadPools
Message-ID: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>

I'm hoping someone could point me in the right direction.  You will probably figure out that I'm new to Java concurrency.

I have a virtual world with a fixed number of autonomous agents (AA) and each agent has the ability to do numerous tasks (AAT) simultaneously.  Seems like it keeps executing the AAs again before each AA's AATs completes.  I was thinking about using a custom ThreadPoolExecutor and a CountDownLatch to not execute the AAs again until their AATs complete but can't see how.  Just point me in the right direction.  Thanks.  Jeff

Here is my example:

public abstract class AAT implements Runnable {
    public AAT() {}

    // run method in subclasses
}

public class AA implements Runnable {
    private Vector<AAT> aats;
    private Executor executor;

    public AA() {
        executor = Executors.newCachedThreadPool();
    }

    public void addAAT(AAT aat) {
        aats.add(aat);
    }

    public void run() {
        for (AAT aat: aats) executor.execute(aat);
    }
}

public class VirtualWorld {
    private Vector<AA> aas;
    private Executor executor;

    public VirtualWorld(Vector<AA> aas) {
        this.aas = aas;
        executor = Executors.newCachedThreadPool();
    }

     public void step() {
        for (AA aa: aas) executor.execute(aa);
    }
}

public VirtualWorldTest {
    public static void main(String[] args) {
        world = new VirtualWorld(Vector<AA> aas);
        while (// no reason to stop) world.step();
    }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/9c369bae/attachment.html 

From dl at cs.oswego.edu  Wed Jan 23 16:45:00 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 23 Jan 2008 16:45:00 -0500
Subject: [concurrency-interest] jsr166y
 Parallel*Array	withMapping/withFilter chaining
In-Reply-To: <200801232107.m0NL7rEi025390@cs.oswego.edu>
References: <200801232107.m0NL7rEi025390@cs.oswego.edu>
Message-ID: <4797B55C.8020808@cs.oswego.edu>

David J. Biesack wrote:
> I find that I cannot do the following
> 
>    public ParallelDoubleArray chain(int size) {
>         return = ParallelDoubleArray.create(size, myForkJoinExecutor)
>          .replaceWithGeneratedValue(myGenerator)
>          .withMapping(myMapping)
>          .withFilter(myFilter)
>          .withMapping(myOtherMapping).all();
>     }
> 

I've been waiting to get reaction on this. We now have two complaints
about it (you and Kasper Nielsen), so it might be worth reconsidering.

The current internal support is set up to allow at most one
(parallel) selection per expression, which
I think is a good rule because it provides an understandable
(and efficient) performance model -- it doesn't secretly require
multiple temporary workspaces or multiple per-element evaluations of
mapping functions. Bear in mind that fast parallel filtering is
inherently a two-phase operation (sometimes with internal pipelined
overlap): Find indices of all matching elements,
and then when you know how many there are, create and put them in new array.
(That's one downside of arrays as opposed to other data structures --
you need to know size before you can create.)

Note that the above case differs in that the all() call must evaluate
mappings, and then put elements somewhere to collect into
returned array in case they pass filter. It is possible to either do
slower filtering to avoid multiple calls to mapping functions
that would otherwise be needed in this case, or to create extra
internal workspace to hold evaluated elements. But in keeping
with desire for simple performance model, since there are two options
I cruelly make you be explicit about it. To get the evaluate-and-store
version, use all(). To do the slower-filter version, rewrite the
filter so that it internally does the mapping needed to decide
whether to keep the element.

There might be a good always-acceptable approach for this case
though, which would make for a better argument for allowing it.
I'll explore the possibilities.

Further complicating this story is that if all you want is a reduction,
then these concerns don't even apply, and we might as well
support it, but doing this leads to an even less regular API,
so it is currently out just on those grounds.


-Doug


From tim at peierls.net  Wed Jan 23 16:47:39 2008
From: tim at peierls.net (Tim Peierls)
Date: Wed, 23 Jan 2008 16:47:39 -0500
Subject: [concurrency-interest] jsr166y Parallel*Array
	withMapping/withFilter chaining
In-Reply-To: <200801232107.m0NL7rEi025390@cs.oswego.edu>
References: <200801232107.m0NL7rEi025390@cs.oswego.edu>
Message-ID: <63b4e4050801231347o95e53f6gf9dc51bc0dec45ef@mail.gmail.com>

It is by design. The return types of the methods restrict you to chains that
can be performed efficiently in one recursive fork-join "pass". The calls to
specify bounds, filters, or mappings just set things up; the real work
starts when you call an "action" method like all, reduce, replace, etc.

But in your example, since you aren't keeping the original array, you could
avoid the intermediate allocation by using replaceWithMapping. In other
words, convert this code:

  pa.withBounds(b).withMapping(m1).all()  // allocates a new PA
    .withFilter(f).withMapping(m2).all(); // allocates another new PA

into

  pa.withBounds(b).replaceWithMapping(m1) // no new allocation
    .withFilter(f).withMapping(m2).all(); // allocates a new PA

The latter allocates only one array besides pa, where the former allocates
two additional.

--tim


On Jan 23, 2008 4:07 PM, David J. Biesack <David.Biesack at sas.com> wrote:

> I find that I cannot do the following
>
>   public ParallelDoubleArray chain(int size) {
>        return = ParallelDoubleArray.create(size, myForkJoinExecutor)
>         .replaceWithGeneratedValue(myGenerator)
>         .withMapping(myMapping)
>         .withFilter(myFilter)
>         .withMapping(myOtherMapping).all();
>    }
>
> Instead, I am forced to construct an intermediate ParallelArray because
> withMapping returns a ParallelDoubleArrayWithMapping and that class does not
> provide a withFilter(Ops.DoublePredicate) method.
>
>    public ParallelDoubleArray chain(int size) {
>        ParallelDoubleArray intermediate;
>        intermediate = ParallelDoubleArray.create(size, myForkJoinExecutor)
>         .replaceWithGeneratedValue(myGenerator)
>         .withMapping(myMapping).all();
>         intermediate = intermediate.withFilter(myFilter)
>         .withMapping(myOtherMapping).all();
>        return intermediate;
>    }
>
> It appears to force premature allocation of the intermediate buffer and
> consequently higher intermediate memory consumption, a concern for larger
> arrays.
>
> Is this by design (or necessity), or an accidental omission? I suppose I
> can see how a filter normally changes the number of elements and thus must
> be run completely before applying a next step (mapping), but even so, it
> would be nice for the framework to internalize this so that client code is
> not forced to express possibly inefficient paths that prevent future
> optimization.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/9461c33b/attachment.html 

From jnguyen at automotive.com  Wed Jan 23 17:16:55 2008
From: jnguyen at automotive.com (J Nguyen)
Date: Wed, 23 Jan 2008 14:16:55 -0800
Subject: [concurrency-interest] Help with ThreadPools
In-Reply-To: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
References: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
Message-ID: <A7487BEC58632D46B8C7E8BC69B3EB1206534921@mail-001.corp.automotive.com>

You could use Future waiting for the job done.  

 

"Seems like it keeps executing the AAs again before each AA's AATs
completes."

This was caused by calling step(0 in the loop.   "for (AA aa: aas)
executor.execute(aa);" executes quickly and return the control back to
the while loop in VirtualWorld

 

 

________________________________

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Jeffrey
Elrod
Sent: Wednesday, January 23, 2008 1:42 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Help with ThreadPools

 

I'm hoping someone could point me in the right direction.  You will
probably figure out that I'm new to Java concurrency.

 

I have a virtual world with a fixed number of autonomous agents (AA) and
each agent has the ability to do numerous tasks (AAT) simultaneously.
Seems like it keeps executing the AAs again before each AA's AATs
completes.  I was thinking about using a custom ThreadPoolExecutor and a
CountDownLatch to not execute the AAs again until their AATs complete
but can't see how.  Just point me in the right direction.  Thanks.  Jeff

 

Here is my example:

 

public abstract class AAT implements Runnable {

    public AAT() {}

 

    // run method in subclasses

}

 

public class AA implements Runnable {

    private Vector<AAT> aats;

    private Executor executor;

 

    public AA() {

        executor = Executors.newCachedThreadPool();

    }

 

    public void addAAT(AAT aat) {

        aats.add(aat);

    }

 

    public void run() {

        for (AAT aat: aats) executor.execute(aat);

    }

}

 

public class VirtualWorld {

    private Vector<AA> aas;

    private Executor executor;

 

    public VirtualWorld(Vector<AA> aas) {

        this.aas = aas;

        executor = Executors.newCachedThreadPool();

    }

 

     public void step() {

        for (AA aa: aas) executor.execute(aa);

    }

}

 

public VirtualWorldTest {

    public static void main(String[] args) {

        world = new VirtualWorld(Vector<AA> aas);

        while (// no reason to stop) world.step();

    }

}

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/25ddee7f/attachment-0001.html 

From alarmnummer at gmail.com  Wed Jan 23 17:26:04 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 23 Jan 2008 23:26:04 +0100
Subject: [concurrency-interest] Help with ThreadPools
In-Reply-To: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
References: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
Message-ID: <1466c1d60801231426s65c88f6y643db0544b640dab@mail.gmail.com>

You could have a look at Future's and at the ExecutorService (or at
the FutureTask)

an (probably non compiling) example:

//start all tasks
List<Future> futureList = new LinkedList<Future>();
for(Runnable task: tasks){
    Future future = executorService.invoke(task);
    futureList.add(future);
}

//now wait for completion of the tasks
for(Future future: futureList)
   future.get();

On Jan 23, 2008 10:42 PM, Jeffrey Elrod <jeffrey.elrod at complexsive.com> wrote:
>
> I'm hoping someone could point me in the right direction.  You will probably
> figure out that I'm new to Java concurrency.
>
> I have a virtual world with a fixed number of autonomous agents (AA) and
> each agent has the ability to do numerous tasks (AAT) simultaneously.  Seems
> like it keeps executing the AAs again before each AA's AATs completes.  I
> was thinking about using a custom ThreadPoolExecutor and a CountDownLatch to
> not execute the AAs again until their AATs complete but can't see how.  Just
> point me in the right direction.  Thanks.  Jeff
>
> Here is my example:
>
> public abstract class AAT implements Runnable {
>     public AAT() {}
>
>     // run method in subclasses
> }
>
> public class AA implements Runnable {
>     private Vector<AAT> aats;
>     private Executor executor;
>
>     public AA() {
>         executor = Executors.newCachedThreadPool();
>     }
>
>     public void addAAT(AAT aat) {
>         aats.add(aat);
>     }
>
>     public void run() {
>         for (AAT aat: aats) executor.execute(aat);
>     }
> }
>
> public class VirtualWorld {
>     private Vector<AA> aas;
>
>     private Executor executor;
>
>     public VirtualWorld(Vector<AA> aas) {
>         this.aas = aas;
>         executor = Executors.newCachedThreadPool();
>     }
>
>      public void step() {
>         for (AA aa: aas) executor.execute(aa);
>     }
> }
>
> public VirtualWorldTest {
>     public static void main(String[] args) {
>         world = new VirtualWorld(Vector<AA> aas);
>         while (// no reason to stop) world.step();
>     }
> }
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From joe.bowbeer at gmail.com  Wed Jan 23 17:32:00 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 23 Jan 2008 14:32:00 -0800
Subject: [concurrency-interest] Help with ThreadPools
In-Reply-To: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
References: <106294.81012.qm@web912.biz.mail.mud.yahoo.com>
Message-ID: <31f2a7bd0801231432u1d9cf226w64326775bf6b21b3@mail.gmail.com>

The following response is based on your description and not on your code:

1. Look at ExecutorService.invokeAll().  This would force AA to wait
until its subtasks have completed.

2. Alternatively, look at ExecutorCompletionService.

--Joe

On Jan 23, 2008 1:42 PM, Jeffrey Elrod <jeffrey.elrod at complexsive.com> wrote:
>
> I'm hoping someone could point me in the right direction.  You will probably
> figure out that I'm new to Java concurrency.
>
> I have a virtual world with a fixed number of autonomous agents (AA) and
> each agent has the ability to do numerous tasks (AAT) simultaneously.  Seems
> like it keeps executing the AAs again before each AA's AATs completes.  I
> was thinking about using a custom ThreadPoolExecutor and a CountDownLatch to
> not execute the AAs again until their AATs complete but can't see how.  Just
> point me in the right direction.  Thanks.  Jeff
>
> Here is my example:
>
> public abstract class AAT implements Runnable {
>     public AAT() {}
>
>     // run method in subclasses
> }
>
> public class AA implements Runnable {
>     private Vector<AAT> aats;
>     private Executor executor;
>
>     public AA() {
>         executor = Executors.newCachedThreadPool();
>     }
>
>     public void addAAT(AAT aat) {
>         aats.add(aat);
>     }
>
>     public void run() {
>         for (AAT aat: aats) executor.execute(aat);
>     }
> }
>
> public class VirtualWorld {
>     private Vector<AA> aas;
>
>     private Executor executor;
>
>     public VirtualWorld(Vector<AA> aas) {
>         this.aas = aas;
>         executor = Executors.newCachedThreadPool();
>     }
>
>      public void step() {
>         for (AA aa: aas) executor.execute(aa);
>     }
> }
>
> public VirtualWorldTest {
>     public static void main(String[] args) {
>         world = new VirtualWorld(Vector<AA> aas);
>         while (// no reason to stop) world.step();
>     }
> }
>

From szabolcs.ferenczi at gmail.com  Wed Jan 23 17:41:25 2008
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Wed, 23 Jan 2008 23:41:25 +0100
Subject: [concurrency-interest] Fwd:  Synchronization blocks,
 locks and reorderings
In-Reply-To: <c8955b000801231017w67afd671ob607deaa05b5dd2@mail.gmail.com>
References: <BAY140-W2CD565C224013454FA98FEF3F0@phx.gbl>
	<c8955b000801231017w67afd671ob607deaa05b5dd2@mail.gmail.com>
Message-ID: <c8955b000801231441i459c9b24u4ffda42a91b4df34@mail.gmail.com>

F.Y.I.

---------- Forwarded message ----------
From: Szabolcs Ferenczi <szabolcs.ferenczi at gmail.com>
Date: 23 Jan 2008 19:17
Subject: Re: [concurrency-interest] Synchronization blocks, locks and
reorderings
To: Unmesh joshi <unmesh_joshi at hotmail.com>

On 23/01/2008, Unmesh joshi <unmesh_joshi at hotmail.com > wrote:
> Hi,
>
> I was reading
> http://today.java.net/pub/a/today/2004/04/13/JSR133.html .
> Discussing reordering there,
>
> class Reordering {
>   int x = 0, y = 0;
>   Object l = new Object();
>
>   public void writer() {
>     x = 1;
>     synchronized (l) {
>       y = 2;
>     }
>   }
>
>   public void reader() {
>     synchronized (l) {
>       int r1 = y;
>       int r2 = x;
>     }
>   }
> }
>
> In the happens-before discussion it is stated that,
>
> "A thread calling reader() will now see the values of x and y placed there
> by the thread calling writer(). The writer() method contains four actions
-- 
> write to x, lock l, write to y, and unlock l. By the program order rule,
the
> writes to x and y happen before the unlock of l. Similarly, the reader()
> method contains four actions -- lock l, read x, read y, and unlock l, and
> again by the program order rule the reads of x and y happen after the lock
> operation. Since by the monitor rule, the unlock operation in writer()
> happens before the lock operation in reader(), we can see (by
transitivity)
> that the writes to x and y in writer() happen before the reads of x and y
in
> reader(), and therefore the correct values are visible to the thread
calling
> reader()."
>
> I am little confused here,

If I understand it correctly, the text explains this scenario:

time writer()        reader()
---- --------        --------
t1   write to x
t2   lock l
t3   write to y
t4   unlock l
t5                   lock l
t6                   read y
t7                   read x
t8                   unlock l

There is nothing special about it except for that the shared variable x is
only handled correctly because it appears just before a critical section and
the change has some latch effect. The somewhat more interesting scenario is
this:

time writer()        reader()
---- --------        --------
t1                   lock l
t2                   read y
t3   write to x
t4                   read x
t5                   unlock l
t6   lock l
t7   write to y
t8   unlock l

Now what value of x will the reader read? According to the happens-before
stuff, value 0 will be read from x despite that x has actually value 1
already.

Despite of any "happens-before" issue, this piece of code is simply not
correct from the old fashioned concurrency point of view.---It is only
correct if you move the write to x inside the critical section. Then
compilers are free to optimize as they wish.

Let me elaborate it a little bit: This class has two pieces of "local"
resource, which are the integer variables x and y. At least one of the
methods of the class contains the `synchronized' keyword, hence the class is
meant to be a shared one and its local resources are meant to be critical
resources. Hence it could be: a monitor.---No, wait a minute. It is a Java
monitor but that is not a proper one as defined by Hoare and Brinch Hansen
in the '70s. This is why it is allowed that a piece of critical resource can
appear outside of the critical section. *It is a concurrency bug designed
into the Java language.* Now, with the fancy "happens-before" rules they are
trying to fix the problem.

The referred article claims: `Many developers mistakenly assume that
synchronization is simply a shorthand for "critical section" or
"mutex".'---Well, I am one of them. At least the keyword `synchronized'
should mark a block which is a critical section and a critical section can
be built with help of mutexes too. Perhaps Java has again some
re-interpretation of the concepts, which are traditionally used in
concurrent programming. So what is expressed in the code above is that one
of the critical resource (namely variable x) is accessed outside of the
critical section. It is a typical concurrency bug leading to hazardous
behaviour.

However, with the fancy "happens-before" interpretation of Java, even the
following non-sense piece of code is "correct":

class Reordering_2 {
  int x = 0, y = 0;
  Object l = new Object();

  public void writer() {
    x = 1;
    y = 2;
    synchronized (l) {
    }
  }

  public void reader() {
    synchronized (l) {
      int r1 = y;
      int r2 = x;
    }
  }
}

Just take the following possible interleaving:

time writer()        reader()
---- --------        --------
t1   write to x
t2   write to y
t3   lock l
t4   unlock l
t5                   lock l
t6                   read y
t7                   read x
t8                   unlock l

After this interleaving the result will be r1==2, r2==1 as can be expected.
Now let us take a different interleaving:

time writer()        reader()
---- --------        --------
t1   write to x
t2                   lock l
t3   write to y
t4                   read y
t5                   read x
t6                   unlock l
t7   lock l
t8   unlock l

After this scenario, on the other hand, the result will be, I guess, r1==0,
r2==0 which is something extra ordinary. What "happened-before" defines in
Java is not what happened before.

I hope this helps.

Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/56ece9a6/attachment.html 

From dcholmes at optusnet.com.au  Wed Jan 23 18:36:16 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 24 Jan 2008 09:36:16 +1000
Subject: [concurrency-interest] Fwd:  Synchronization blocks,
	locks and reorderings
In-Reply-To: <c8955b000801231441i459c9b24u4ffda42a91b4df34@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEECHKAA.dcholmes@optusnet.com.au>

> the somewhat more interesting scenario is this:
>
> time writer()        reader()
> ---- --------        --------
> t1                   lock l
> t2                   read y
> t3   write to x
> t4                   read x
> t5                   unlock l
> t6   lock l
> t7   write to y
> t8   unlock l
>
> Now what value of x will the reader read? According to the happens-before
stuff, value 0 will be > read from x despite that x has actually value 1
already.

No, the absence of a happens-before ordering between the read of x at t4 and
write of x at t3 means that the read can return either 1 or 0

David Holmes


From larryr at saturn.sdsu.edu  Wed Jan 23 19:31:22 2008
From: larryr at saturn.sdsu.edu (Larry Riedel)
Date: Wed, 23 Jan 2008 16:31:22 -0800
Subject: [concurrency-interest] Synchronization blocks,
	locks and reorderings
In-Reply-To: <c8955b000801231441i459c9b24u4ffda42a91b4df34@mail.gmail.com>
Message-ID: <1201134682.027955.9663.nullmailer@home35>


> >   public void writer() {
> >     x = 1;
> >     synchronized (l) {
> >       y = 2;
> >     }
> >   }
> >   public void reader() {
> >     synchronized (l) {
> >       int r1 = y;
> >       int r2 = x;
> >     }
> >   }
> 
> If I understand it correctly, the text explains this scenario:
> 
> time writer()        reader()
> ---- --------        --------
> t1   write to x
> t2   lock l
> t3   write to y
> t4   unlock l
> t5                   lock l
> t6                   read y
> t7                   read x
> t8                   unlock l
> 
> There is nothing special about it except for that the shared
> variable x is only handled correctly because it appears just
> before a critical section and the change has some latch effect.

I think of that latch effect as a major fundamental feature
associated with "synchronized", which makes it do more than just
synchronize thread sequencing, it also synchronizes thread state.


> time writer()        reader()
> ---- --------        --------
> t1                   lock l
> t2                   read y
> t3   write to x
> t4                   read x
> t5                   unlock l
> t6   lock l
> t7   write to y
> t8   unlock l
> 
> Now what value of x will the reader read? According to
> the happens-before stuff, value 0 will be read from x
> despite that x has actually value 1 already.

I think by putting the write to x before the synchronized
block, I am saying it is ok for another thread to see the
change to x before the change to y, but not vice versa.


> with the fancy "happens-before" interpretation of Java,
> even the following non-sense piece of code is "correct":
>   [...]
>   public void writer() {
>     x = 1;
>     y = 2;
>     synchronized (l) {
>     }
>   }

Maybe if it was 
    public void writer() {
        x = 1;
        y = 2;
        synchronized (l);
    }
it would seem less like nonsense, because it is more
clearly saying I want other threads synchronizing state
with me through l to see the changes I made to x and y
no later than the next time they do synchronized(l),


> time writer()        reader()
> ---- --------        --------
> t1   write to x
> t2                   lock l
> t3   write to y
> t4                   read y
> t5                   read x
> t6                   unlock l
> t7   lock l
> t8   unlock l
> 
> After this scenario, on the other hand, the result will be, I
> guess, r1==0, r2==0 which is something extra ordinary. What
> "happened-before" defines in Java is not what happened before.

"Happened before" confuses me too; I think of it more
as "was published before" as far as seeing state changes.


> The referred article claims: `Many developers
> mistakenly assume that synchronization is simply a
> shorthand for "critical section" or "mutex".'---Well,
> I am one of them. At least the keyword `synchronized'
> should mark a block which is a critical section [...]

Maybe it would be better to say they mistakenly presume
that "synchronized" is /only/ used as critical sections,
when it is also used as a mechanism for threads to
synchronize their state.  I am not sure if having an
additional semantically distinct construct would have
made reading or writing programs any easier in practice.


Larry


From Grace.Kwok at mscibarra.com  Wed Jan 23 19:47:30 2008
From: Grace.Kwok at mscibarra.com (Kwok, Grace (MSCIBARRA))
Date: Wed, 23 Jan 2008 19:47:30 -0500
Subject: [concurrency-interest] Why does FutureTask hold reference to the
	Callable object forever?
Message-ID: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>

Hi,
 
 
      After a FutureTask is run and result is set to a local variable
internally inside FutureTask, I would think that the Callable object
should not be needed anymore.   I would think that it would be best the
reference to the Callable object be set to null.
 
 
      Without nullifying the reference to the Callable object, it seems
to me that this can cause memory leak.  
 
      When implementing cache using the Memoizer pattern, the cache
becomes a map that not only holds strong references to the resulting
values, but also strong references to whatever that was needed for the
computation.  
 
 
      Any thought on this?  A simple way to nullify the reference to the
callable inside FutureTask after "run" would be appreciated.
 
 
Thanks, Grace
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/1acbd520/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Jan 23 20:40:40 2008
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Thu, 24 Jan 2008 02:40:40 +0100
Subject: [concurrency-interest] Fwd: Synchronization blocks,
	locks and reorderings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEECHKAA.dcholmes@optusnet.com.au>
References: <c8955b000801231441i459c9b24u4ffda42a91b4df34@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEECHKAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000801231740r479df775uea1983963f6041c@mail.gmail.com>

On 24/01/2008, David Holmes <dcholmes at optusnet.com.au> wrote:
>
> > the somewhat more interesting scenario is this:
> >
> > time writer()        reader()
> > ---- --------        --------
> > t1                   lock l
> > t2                   read y
> > t3   write to x
> > t4                   read x
> > t5                   unlock l
> > t6   lock l
> > t7   write to y
> > t8   unlock l
> >
> > Now what value of x will the reader read? According to the
> happens-before
> stuff, value 0 will be > read from x despite that x has actually value 1
> already.
>
> No, the absence of a happens-before ordering between the read of x at t4
> and
> write of x at t3 means that the read can return either 1 or 0


Well, I agree with you and I also said that the code is not correct from the
concurrency point of view. However, you should check it with the author of
http://today.java.net/pub/a/today/2004/04/13/JSR133.html
<http://today.java.net/pub/a/today/2004/04/13/JSR133.html> who
contradicts you.

Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/ee99de79/attachment.html 

From dcholmes at optusnet.com.au  Wed Jan 23 20:49:17 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 24 Jan 2008 11:49:17 +1000
Subject: [concurrency-interest] Fwd: Synchronization blocks,
	locks and reorderings
In-Reply-To: <c8955b000801231740r479df775uea1983963f6041c@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEEFHKAA.dcholmes@optusnet.com.au>

I believe the article was intending to refer to the simple case where
execution of writer() in one thread completes before execution of reader()
in another. It doesn't discuss the possibilities if writer() and reader()
are interleaved.

David Holmes
  -----Original Message-----
  From: Szabolcs Ferenczi [mailto:szabolcs.ferenczi at gmail.com]
  Sent: Thursday, 24 January 2008 11:41 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Fwd: Synchronization blocks, locks and
reorderings


  On 24/01/2008, David Holmes <dcholmes at optusnet.com.au > wrote:
    > the somewhat more interesting scenario is this:
    >
    > time writer()        reader()
    > ---- --------        --------
    > t1                   lock l
    > t2                   read y
    > t3   write to x
    > t4                   read x
    > t5                   unlock l
    > t6   lock l
    > t7   write to y
    > t8   unlock l
    >
    > Now what value of x will the reader read? According to the
happens-before
    stuff, value 0 will be > read from x despite that x has actually value 1
    already.

    No, the absence of a happens-before ordering between the read of x at t4
and
    write of x at t3 means that the read can return either 1 or 0

  Well, I agree with you and I also said that the code is not correct from
the concurrency point of view. However, you should check it with the author
of http://today.java.net/pub/a/today/2004/04/13/JSR133.html  who contradicts
you.

  Best Regards,
  Szabolcs


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/3c262aef/attachment.html 

From szabolcs.ferenczi at gmail.com  Wed Jan 23 21:08:34 2008
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Thu, 24 Jan 2008 03:08:34 +0100
Subject: [concurrency-interest] Fwd: Synchronization blocks,
	locks and reorderings
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEEFHKAA.dcholmes@optusnet.com.au>
References: <c8955b000801231740r479df775uea1983963f6041c@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEEFHKAA.dcholmes@optusnet.com.au>
Message-ID: <c8955b000801231808v568cca15i4bca4161dceb3b95@mail.gmail.com>

On 24/01/2008, David Holmes <dcholmes at optusnet.com.au > wrote:
>
> I believe the article was intending to refer to the simple case where
> execution of writer() in one thread completes before execution of reader()
> in another. It doesn't discuss the possibilities if writer() and reader()
> are interleaved.
>

Hmmm.... I must tell you that it might well happen with asynchronous
concurrent processes that actions of two processes are interleaved. That is
why we must enforce synchronization and mutual exclusion when two or more
processes interact via shared resources. You can believe that it will not
happen, though. Then you write buggy code and talk about happen-before as
before.

Just check it with the author of the article.

 Best Regards,
Szabolcs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/fb0cd83f/attachment.html 

From joe.bowbeer at gmail.com  Wed Jan 23 22:04:08 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 23 Jan 2008 19:04:08 -0800
Subject: [concurrency-interest] Why does FutureTask hold reference to
	the Callable object forever?
In-Reply-To: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
Message-ID: <31f2a7bd0801231904r1b5a3716hc248e075724c8ce7@mail.gmail.com>

On Jan 23, 2008 4:47 PM, Kwok, Grace (MSCIBARRA) wrote:
>
>       After a FutureTask is run and result is set to a local variable
> internally inside FutureTask, I would think that the Callable object should
> not be needed anymore.   I would think that it would be best the reference
> to the Callable object be set to null.
>
>       Without nullifying the reference to the Callable object, it seems to
> me that this can cause memory leak.
>
>       When implementing cache using the Memoizer pattern, the cache becomes
> a map that not only holds strong references to the resulting values, but
> also strong references to whatever that was needed for the computation.
>
>       Any thought on this?  A simple way to nullify the reference to the
> callable inside FutureTask after "run" would be appreciated.
>

I follow your reasoning.

Note that FutureTask is also used for tasks that are scheduled to
execute repeatedly.  See the "runAndReset" method.  That's one reason,
in addition to ease of implementation, for retaining the reference to
the Callable.

A workaround for memoize-like applications is to have the Callable
release its references after it is called, or to extend FutureTask's
"done" method to notifyl the Callable to release its resources.

--Joe

From gykwok at gmail.com  Thu Jan 24 02:23:32 2008
From: gykwok at gmail.com (Grace Kwok)
Date: Wed, 23 Jan 2008 23:23:32 -0800
Subject: [concurrency-interest] Why does FutureTask hold reference to
	the Callable object forever?
In-Reply-To: <31f2a7bd0801231904r1b5a3716hc248e075724c8ce7@mail.gmail.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
	<31f2a7bd0801231904r1b5a3716hc248e075724c8ce7@mail.gmail.com>
Message-ID: <cbd4e1ab0801232323r5022f59aq92957c9096771a00@mail.gmail.com>

>>A workaround for memoize-like applications is to have the Callable
>>release its references after it is called, or to extend FutureTask's
>>"done" method to notifyl the Callable to release its resources.

Yes..
but in cases like below, "c" is not set to a local variable inside the
Callable but it is indeed referenced.  Nothing prevents us to do this and it
was a suggested pattern...


         Future<V> f = cache.get(arg);
         if (f == null) {
            Callable<V> eval = new Callable<V>() {
               public V call() throws IntrruptedException {
                  return c.compute(arg);
               }
            };

Thanks, Grace


On Jan 23, 2008 7:04 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> On Jan 23, 2008 4:47 PM, Kwok, Grace (MSCIBARRA) wrote:
> >
> >       After a FutureTask is run and result is set to a local variable
> > internally inside FutureTask, I would think that the Callable object
> should
> > not be needed anymore.   I would think that it would be best the
> reference
> > to the Callable object be set to null.
> >
> >       Without nullifying the reference to the Callable object, it seems
> to
> > me that this can cause memory leak.
> >
> >       When implementing cache using the Memoizer pattern, the cache
> becomes
> > a map that not only holds strong references to the resulting values, but
> > also strong references to whatever that was needed for the computation.
> >
> >       Any thought on this?  A simple way to nullify the reference to the
> > callable inside FutureTask after "run" would be appreciated.
> >
>
> I follow your reasoning.
>
> Note that FutureTask is also used for tasks that are scheduled to
> execute repeatedly.  See the "runAndReset" method.  That's one reason,
> in addition to ease of implementation, for retaining the reference to
> the Callable.
>
> A workaround for memoize-like applications is to have the Callable
> release its references after it is called, or to extend FutureTask's
> "done" method to notifyl the Callable to release its resources.
>
> --Joe
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080123/5016ca6e/attachment-0001.html 

From Online at stolsvik.com  Thu Jan 24 05:18:49 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Thu, 24 Jan 2008 11:18:49 +0100
Subject: [concurrency-interest] Why does FutureTask hold reference to
 the	Callable object forever?
In-Reply-To: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
Message-ID: <47986609.4040306@Stolsvik.com>

Kwok, Grace (MSCIBARRA) wrote:
> Hi,
>  
>  
>       After a FutureTask is run and result is set to a local variable 
> internally inside FutureTask, I would think that the Callable object 
> should not be needed anymore.   I would think that it would be best the 
> reference to the Callable object be set to null.

Good point.

http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6213323

FutureTask was/is bugridden in several ways: check out the 
implementation of run() vs. setException() and that "inner"-stuff (which 
feels like being coded in an obtuse way "just because"). Hint: when will 
"outer".setException ever be invoked?

Oops, now you got me started on ScheduledThreadPoolExecutor.. First of 
all, not having a proper cron-style schedule makes it next to worthless, 
IMO. Furthermore, it feels to me like it was hacked up without much testing:
   You'd expect its extension point afterExecute(Runnable r, Throwable 
t) to give you any throwables the task raised, right? But no, it doesn't 
(and the javadoc now also tries somewhat awkwardly to explain this 
rather fine point) - the extension of FutureTask (ScheduledFutureTask) 
swallows the Exception, although it is a non-static private internal 
class to STPE, and hence perfectly well could have been hooked.
   Check decorateTask(...): please enlighten me on exactly HOW you're 
supposed to use those methods to really decorate your task, while still 
honoring the contract under which the Runnable/Callable was enqueued. 
Hint: where's the parameters under which the job was enqueued? Even 
proxying/wrapping magic seems impossible: the STPE internal NONO_ORIGIN 
and now() is private, as is the class mentioned (Do note that I might 
just have missed the obvious - so don't take my word for it).

Although I love the work of these guys, I find this particular bunch of 
classes and interfaces to be rather unreasonable.

If you're into self-inflicted pain, here's the "dialogues" about these 
issues in Sun's bugbase:
   http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6459119
   http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6464365

Endre.

From rjohns at nortel.com  Thu Jan 24 11:20:46 2008
From: rjohns at nortel.com (Richard Johns)
Date: Thu, 24 Jan 2008 11:20:46 -0500
Subject: [concurrency-interest] Frequently canceled timers
Message-ID: <4798BADE.1020007@nortel.com>

I have an application that retransmits messages when they don't get a 
timely response .  Usually, of course, that's not necessary and their 
timers are canceled.  This is a traffic generator so message rate is 
high and we need to remove the canceled timers.

Is there a timer implementation that efficiently cleans up canceled 
timers?  DelayQueue uses a binary heap so it's very fast otherwise, but 
it uses a sequential search for remove().  ScheduledThreadPoolExecutor 
uses DelayQueue, and Timer also uses a binary heap.

-- 
Rick 


From tim at peierls.net  Thu Jan 24 11:21:12 2008
From: tim at peierls.net (Tim Peierls)
Date: Thu, 24 Jan 2008 11:21:12 -0500
Subject: [concurrency-interest] Why does FutureTask hold reference to
	the Callable object forever?
In-Reply-To: <47986609.4040306@Stolsvik.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
	<47986609.4040306@Stolsvik.com>
Message-ID: <63b4e4050801240821h594855f4t4d46bb9016e4155d@mail.gmail.com>

On Jan 24, 2008 5:18 AM, Endre St?lsvik <Online at stolsvik.com> wrote:

> Check decorateTask(...): please enlighten me on exactly HOW you're
> supposed to use those methods to really decorate your task, while still
> honoring the contract under which the Runnable/Callable was enqueued.
>

"Task" in decorateTask (and in AbstractExecutorService.newTaskFor) refers to
the Runnable(Scheduled)Future, not to the submitted Runnable/Callable. These
methods probably should have been named "decorateFuture" and "newFutureFor".


The point of these methods is to give subclasses a chance to supply a
different concrete type for the Runnable(Scheduled)Future returned when a
Runnable/Callable is submitted. Without these methods, there's no way to do
this that doesn't involve a huge amount of reimplementation of existing
code.

I added an example to the wiki of using decorateTask to provide cancellation
behavior in a custom scheduled executor service:

http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W30

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/c8bf7125/attachment.html 

From joe.bowbeer at gmail.com  Thu Jan 24 12:42:23 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 24 Jan 2008 09:42:23 -0800
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <4798BADE.1020007@nortel.com>
References: <4798BADE.1020007@nortel.com>
Message-ID: <31f2a7bd0801240942m44a915c2te0fb342c2fac963f@mail.gmail.com>

It should be more efficient to call executor.purge() periodically than
to call remove() frequently.  Will this work in your case?

On Jan 24, 2008 8:20 AM, Richard Johns wrote:
> I have an application that retransmits messages when they don't get a
> timely response .  Usually, of course, that's not necessary and their
> timers are canceled.  This is a traffic generator so message rate is
> high and we need to remove the canceled timers.
>
> Is there a timer implementation that efficiently cleans up canceled
> timers?  DelayQueue uses a binary heap so it's very fast otherwise, but
> it uses a sequential search for remove().  ScheduledThreadPoolExecutor
> uses DelayQueue, and Timer also uses a binary heap.
>
> --
> Rick

From David.Biesack at sas.com  Thu Jan 24 17:23:05 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Thu, 24 Jan 2008 17:23:05 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
Message-ID: <200801242223.m0OMN5oP012652@cs.oswego.edu>


Been working with the API more and I have a few more comments/suggestions assembled.

Rather than duplicating defaultExecutor() in each Parallel*Array class, provide a single ForkJoinExecutor.Factory static class with a getInstance() method. I like to see the creation API closer to the interface. However, this would require an extra import per use, so I' not pushing it too hard - just seems to be unnecessary duplication.

Even if not, the javadoc in ForkJoinExecutor should indicate how to create and instance and include a {@link ParallelArray#defaultExecutor()}.

The create*() methods should state that the FJE must be non-null.

I find createFromCopy and createWithHandoff method names to be awkward; I have to think through the name each time I use them and tend to want to write .createFromHandoff(). To keep names consistent, I recommend renaming the create*() factor methods as in the following examples

  ParallelDoubleArray pa;
  pa = ParallelDoubleArray.withCopy(myArray, myForkJoinExecutor); // or withCopyOf
  pa = ParallelDoubleArray.withArray(myArray, myForkJoinExecutor);
  pa = ParallelDoubleArray.withSize(n, myForkJoinExecutor);
  pa = ParallelDoubleArray.withCapacity(m, myForkJoinExecutor);

  Thus, code reads more like:
   "pa is a ParallelDoubleArray with a copy of myArray"
   "pa is a ParallelDoubleArray with array myArray"
   "pa is a ParallelDoubleArray with size n"
   "pa is a ParallelDoubleArray with capacity m"

Rename CommonOps.compoundOp as CommonOps.compositeOp as per the well-known Composite design pattern.

Rename the withBounds/withMapping/withFilter methods to simpler bound(...), map(...), and filter(...).

Remove "Indexed" from the withIndexedFilter()/withIndexedMapping() methods; let the overload resolution deal with that. It will make changing code easier - if I decide a filter needs the index, I can simply change its implements clause and implementation and not change all the invocations -- especially true if I defined factory methods to get such filters/mappings.

Having used this a while, I personally don't like the liberal use of "withThis" this and "withThat" throughout the API; it makes it more verbose without really adding much. As per Kent Beck's recommendations (Implementation Patterns, p. 24, Qualified Subclass Name: "Prepend one or more qualifiers to the superclass name to form a subclass name"), rename the resulting ParallelArray*WithBounds, *WithMapping, WithFilter to BoundedParallel*Array, MappedParallel*Array, FilteredParallel*Array. I realize these are not subclasses, but conceptually, they are derivations of Parallel*Array.

  FilteredParallelDoubleArray pa = a.filter(myIndexFilter);

Rename CommonOps.identityPredicate() and nonidentityPredicate() to identicalPredicate() and notIdenticalPredicate();
this seems like the wrong use of "identity" which is normally an op : 

   Object identity(Object x) { return x; }. 

Although System.identityHashCode(Object) is the closest match, but I don't think these methods are implemented in terms of that). In particular, "nonidentity" is not a well known term.

(equalityPredicate/inequalityPredicate are ok)

That's all for today :-)

Thanks

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From joe.bowbeer at gmail.com  Thu Jan 24 18:19:17 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 24 Jan 2008 15:19:17 -0800
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <4798EBE4.1070903@nortel.com>
References: <4798BADE.1020007@nortel.com>
	<31f2a7bd0801240942m44a915c2te0fb342c2fac963f@mail.gmail.com>
	<4798EBE4.1070903@nortel.com>
Message-ID: <31f2a7bd0801241519j3d9ca827s9e4fd850b9c1346@mail.gmail.com>

> Richard Johns wrote:
>
> I have an application that retransmits messages when they don't get a
> timely response . Usually, of course, that's not necessary and their
> timers are canceled. This is a traffic generator so message rate is
> high and we need to remove the canceled timers.
>
> Is there a timer implementation that efficiently cleans up canceled
> timers? DelayQueue uses a binary heap so it's very fast otherwise, but
> it uses a sequential search for remove(). ScheduledThreadPoolExecutor
> uses DelayQueue, and Timer also uses a binary heap.
>
> Joe Bowbeer wrote:
>
> It should be more efficient to call executor.purge() periodically than
> to call remove() frequently. Will this work in your case?
>
> Richard Johns wrote:
>
> No, ThreadPoolExecutor.purge() just gets the queue and calls remove() for
> each canceled Future.  That would be worse, it would take the hit all at
> once.

Now I see.

TPE.purge() iterates through the queue and calls iterator.remove() at
the appropriate times.

However, DelayQueue's Iterator implementation re-walks the queue
(again) for each item that is removed.

So I no longer think that ScheduledThreadPoolExecutor.purge() is more
efficient than removing each item separately -- and I'm unhappy.

--Joe

From Online at stolsvik.com  Thu Jan 24 18:25:16 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Fri, 25 Jan 2008 00:25:16 +0100
Subject: [concurrency-interest] Why does FutureTask hold reference to
 the Callable object forever?
In-Reply-To: <63b4e4050801240821h594855f4t4d46bb9016e4155d@mail.gmail.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>	
	<47986609.4040306@Stolsvik.com>
	<63b4e4050801240821h594855f4t4d46bb9016e4155d@mail.gmail.com>
Message-ID: <47991E5C.9020208@Stolsvik.com>

Tim Peierls wrote:
> On Jan 24, 2008 5:18 AM, Endre St?lsvik <Online at stolsvik.com 
> <mailto:Online at stolsvik.com>> wrote:
> 
>     Check decorateTask(...): please enlighten me on exactly HOW you're
>     supposed to use those methods to really decorate your task, while
>     still honoring the contract under which the Runnable/Callable was
>     enqueued.
> 
> 
> "Task" in decorateTask (and in AbstractExecutorService.newTaskFor) 
> refers to the Runnable(Scheduled)Future, not to the submitted 
> Runnable/Callable. These methods probably should have been named 
> "decorateFuture" and "newFutureFor".
> 
> The point of these methods is to give subclasses a chance to supply a 
> different concrete type for the Runnable(Scheduled)Future returned when 
> a Runnable/Callable is submitted.

This much is obvious from the method, and when you check the code for 
STPE. However, you _have to_ make a wrapper that forwards all calls, as 
you cannot yourself implement the actual needed behavior of the 
RunnableScheduledFuture, since STPE's implementation of it, 
ScheduledFutureTask, relies on the innards of STPE itself (and since you 
aren't supplied with the arguments of the initial submit). At least it 
seems so to me..

> I added an example to the wiki of using decorateTask to provide 
> cancellation behavior in a custom scheduled executor service:
> 
> http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W30

I tried using this feature (the decorateTask-methods) to implement 
Exception-catching by wrapping and overriding run(), but didn't manage 
to do it in any way (it hits me now that you could possibly proxy it and 
use the reflection stuff to change visibility of some of those private 
methods to make it possible to invoke them?).

But such amazing wizardry is not what those methods are meant to enable 
you to do, then?

NB: Maybe put some @Overrides in that example code?

Kind regards,
Endre.

From dl at cs.oswego.edu  Thu Jan 24 19:25:19 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 24 Jan 2008 19:25:19 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <200801242223.m0OMN5oP012652@cs.oswego.edu>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
Message-ID: <47992C6F.6010606@cs.oswego.edu>

David J. Biesack wrote:
> Been working with the API more and I have a few more comments/suggestions
> assembled.

Thanks! These are great! Please keep them coming! I hope to do
another renaming etc pass sometime based on the already good
suggestions stemming from last one.

Along these lines: We've been thinking of
separating these from base FJ support and placing in new
subpackage java.util.concurrent.forkjoin.collections.
(or for now jsr166y.forkjoin.collections). Any opinions?

Some notes about some of them...

> 
> Rather than duplicating defaultExecutor() in each Parallel*Array class,
> provide a single ForkJoinExecutor.Factory static class with a getInstance()
> method. I like to see the creation API closer to the interface. However, this
> would require an extra import per use, so I' not pushing it too hard - just
> seems to be unnecessary duplication.

This is currently our compromise between supporting factories
that allow you to just use default vs making you write an
uglier expression to specify the default global one. I suspect
we will end up doing the former someday so might want to get it
over with now, in which case the default could be pushed up
as a toplevel standalone singleton class.

> 
> I find createFromCopy and createWithHandoff method names to be awkward; 

> ParallelDoubleArray pa; pa = ParallelDoubleArray.withCopy(myArray,
> myForkJoinExecutor); 

I agree about the problem; hopefully we'll find a nicer solution.

> 
> Rename CommonOps.compoundOp as CommonOps.compositeOp as per the well-known
> Composite design pattern.
> 
> Rename the withBounds/withMapping/withFilter methods to simpler bound(...),
> map(...), and filter(...).

Or I think a little better: bounding(l,h), filtering(pred), mapping(op).
I think we'll do this.

> Having used this a while, I personally don't like the liberal use of
> "withThis" this and "withThat" throughout the API;

(Well, except for your suggested use in factories above :-)

  it makes it more verbose
> without really adding much. As per Kent Beck's recommendations
> (Implementation Patterns, p. 24, Qualified Subclass Name: "Prepend one or
> more qualifiers to the superclass name to form a subclass name"), rename the
> resulting ParallelArray*WithBounds, *WithMapping, WithFilter to
> BoundedParallel*Array, MappedParallel*Array, FilteredParallel*Array. I
> realize these are not subclasses, but conceptually, they are derivations of
> Parallel*Array.
> 
> FilteredParallelDoubleArray pa = a.filter(myIndexFilter);

Note that it should be very rare to give a name to (thus mention the
type of) to this kind of expression though.

-Doug

From rjohns at nortel.com  Thu Jan 24 21:15:08 2008
From: rjohns at nortel.com (Richard Johns)
Date: Thu, 24 Jan 2008 21:15:08 -0500
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <31f2a7bd0801241519j3d9ca827s9e4fd850b9c1346@mail.gmail.com>
References: <4798BADE.1020007@nortel.com>
	<31f2a7bd0801240942m44a915c2te0fb342c2fac963f@mail.gmail.com>
	<4798EBE4.1070903@nortel.com>
	<31f2a7bd0801241519j3d9ca827s9e4fd850b9c1346@mail.gmail.com>
Message-ID: <4799462C.3070008@nortel.com>

An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/8232f1f4/attachment.html 

From tim at peierls.net  Thu Jan 24 22:50:04 2008
From: tim at peierls.net (Tim Peierls)
Date: Thu, 24 Jan 2008 22:50:04 -0500
Subject: [concurrency-interest] Why does FutureTask hold reference to
	the Callable object forever?
In-Reply-To: <47991E5C.9020208@Stolsvik.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>
	<47986609.4040306@Stolsvik.com>
	<63b4e4050801240821h594855f4t4d46bb9016e4155d@mail.gmail.com>
	<47991E5C.9020208@Stolsvik.com>
Message-ID: <63b4e4050801241950y70a989eu639fa1871f25404b@mail.gmail.com>

On Jan 24, 2008 6:25 PM, Endre St?lsvik <Online at stolsvik.com> wrote:

> ... you _have to_ make a wrapper that forwards all calls, as you cannot
> yourself implement the actual needed behavior of the
> RunnableScheduledFuture, since STPE's implementation of it,
> ScheduledFutureTask, relies on the innards of STPE itself


It's true, you do have to make a forwarding wrapper. I put one on the wiki
just now, but it would be nice to have something like this in the standard
library:

http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W36



> (and since you aren't supplied with the arguments of the initial submit).
>

Not sure how being supplied with those arguments would help you avoid the
need for a forwarding wrapper.


I tried using this feature (the decorateTask-methods) to implement
> Exception-catching by wrapping and overriding run(), but didn't manage to do
> it in any way (it hits me now that you could possibly proxy it and use the
> reflection stuff to change visibility of some of those private methods to
> make it possible to invoke them?).
>
> But such amazing wizardry is not what those methods are meant to enable
> you to do, then?


No.

If you want to wrap submitted Runnables, why not wrap them *before*
submission? If you want to encapsulate that behavior in a
ScheduledExecutorService, you could write a
RunnableWrappingScheduledExecutorService that forwards to an underlying
STPE, but wraps any submitted Runnables using a protected method,
wrap(Runnable) that by default just returns the Runnable itself.




> Maybe put some @Overrides in that example code?


Oops, thanks, just did.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080124/e293ebce/attachment.html 

From kasper at kav.dk  Fri Jan 25 05:37:11 2008
From: kasper at kav.dk (Kasper Nielsen)
Date: Fri, 25 Jan 2008 11:37:11 +0100
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <47992C6F.6010606@cs.oswego.edu>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu>
Message-ID: <4799BBD7.5080709@kav.dk>

Doug Lea wrote:
> David J. Biesack wrote:
>> Been working with the API more and I have a few more comments/suggestions
>> assembled.
> 
> Thanks! These are great! Please keep them coming! I hope to do
> another renaming etc pass sometime based on the already good
> suggestions stemming from last one.
> 
> Along these lines: We've been thinking of
> separating these from base FJ support and placing in new
> subpackage java.util.concurrent.forkjoin.collections.
> (or for now jsr166y.forkjoin.collections). Any opinions?

Sure, go for it. I think once ParallelMap and ParallelBigArray arrives 
it would make sense.

> 
>> I find createFromCopy and createWithHandoff method names to be awkward; 
> 
>> ParallelDoubleArray pa; pa = ParallelDoubleArray.withCopy(myArray,
>> myForkJoinExecutor); 
> 
> I agree about the problem; hopefully we'll find a nicer solution.

I would prefer plain vanilla createFrom() over createWithHandoff(). I 
think handoff really doesn't make sense for most people with English as 
a secondary language.


>> Rename CommonOps.compoundOp as CommonOps.compositeOp as per the well-known
>> Composite design pattern.
>>
>> Rename the withBounds/withMapping/withFilter methods to simpler bound(...),
>> map(...), and filter(...).
> 
> Or I think a little better: bounding(l,h), filtering(pred), mapping(op).
> I think we'll do this.

I must admit I really like fluent interfaces and the withThis and 
withThat syntax. I think this paper sums up most of the benefits of 
using fluent interfaces like this 
http://www.mockobjects.com/files/evolving_an_edsl.ooplsa2006.pdf
I also remember martin fowler, writing something about the fluent 
interface api style.

> 
>> Having used this a while, I personally don't like the liberal use of
>> "withThis" this and "withThat" throughout the API;
> 
> (Well, except for your suggested use in factories above :-)
> 
>   it makes it more verbose
>> without really adding much. As per Kent Beck's recommendations
>> (Implementation Patterns, p. 24, Qualified Subclass Name: "Prepend one or
>> more qualifiers to the superclass name to form a subclass name"), rename the
>> resulting ParallelArray*WithBounds, *WithMapping, WithFilter to
>> BoundedParallel*Array, MappedParallel*Array, FilteredParallel*Array. I
>> realize these are not subclasses, but conceptually, they are derivations of
>> Parallel*Array.
>>
>> FilteredParallelDoubleArray pa = a.filter(myIndexFilter);
> 
> Note that it should be very rare to give a name to (thus mention the
> type of) to this kind of expression though.
I agree.

-Kasper

From Online at stolsvik.com  Fri Jan 25 06:16:58 2008
From: Online at stolsvik.com (=?UTF-8?B?RW5kcmUgU3TDuGxzdmlr?=)
Date: Fri, 25 Jan 2008 12:16:58 +0100
Subject: [concurrency-interest] Why does FutureTask hold reference to
 the Callable object forever?
In-Reply-To: <63b4e4050801241950y70a989eu639fa1871f25404b@mail.gmail.com>
References: <937C75B544E7E8428436C67056A3A17305A8EE6F@NYWEXMB83.msad.ms.com>	
	<47986609.4040306@Stolsvik.com>	
	<63b4e4050801240821h594855f4t4d46bb9016e4155d@mail.gmail.com>	
	<47991E5C.9020208@Stolsvik.com>
	<63b4e4050801241950y70a989eu639fa1871f25404b@mail.gmail.com>
Message-ID: <4799C52A.3040806@Stolsvik.com>

Tim Peierls wrote:
>  
> 
>     (and since you aren't supplied with the arguments of the initial
>     submit).
> 
> 
> Not sure how being supplied with those arguments would help you avoid 
> the need for a forwarding wrapper.

You could create the timing and reschedule-behaviour yourself, I 
envisioned. It was just one of many tries to get at that stupid 
Exception I obviously had in my code, but which STPE happily swallowed 
whole all the time.

> 
> 
>     I tried using this feature (the decorateTask-methods) to implement
>     Exception-catching by wrapping and overriding run(), but didn't
>     manage to do it in any way (it hits me now that you could possibly
>     proxy it and use the reflection stuff to change visibility of some
>     of those private methods to make it possible to invoke them?).
> 
>     But such amazing wizardry is not what those methods are meant to
>     enable you to do, then?
> 
> 
> No.
> 
> If you want to wrap submitted Runnables, why not wrap them *before* 
> submission? If you want to encapsulate that behavior in a 
> ScheduledExecutorService, you could write a 
> RunnableWrappingScheduledExecutorService that forwards to an underlying 
> STPE, but wraps any submitted Runnables using a protected method, 
> wrap(Runnable) that by default just returns the Runnable itself.

As mentioned, check:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6459119
   (The synopsis ain't mine - someone changed it.)

There I made a ScheduledThreadPoolExecutorWithExceptionListening.

   " However, after hours of banging my head while looking in vain for 
appropriate extension-points or listener-registration possibilities, I 
finally came up with an (obvious?) extension that simply overrides all 
submit-methods by wrapping up the submitted Callable or Runnable in a 
new instance of the same, which invokes the run/call in a try-catch, and 
runs notification to registered TaskExceptionListeners before throwing 
on (which hopefully should preserve contract - any Callables or 
Runnables laying in the queue are already "hidden" behind the internal 
RunnableScheduledFuture) "

And all this lard just because afterExecute wasn't made to include the 
Exception, but instead swallowing it. The workaround that Doug added 
2006-08-18 is still not a part of the javadoc as he suggested, and it 
also assumes that get() is idempotent.

See, my point is: when you SCHEDULE a task to be run in the future, or 
repeatedly, you don't sit around waiting for the Future. You fire and 
forget. And that class in its default setting simply swallows any 
badness happening, making bug hunting a nightmare, obviously in 
particular if you don't know about this, and don't quite see it coming.
   In the TPE, using execute(Runnable), first you get the Exception in 
afterExecture, THEN it is thrown on, so that the running Thread dies, 
spitting out the Exception on stderr per default. But with STPE, 
everything is *completely* different in these regards, even if you 
employ that same method.

To furthermore complicate the matter, one have the FutureTask's handling 
of "setException" - it doesn't work - there's a bug, it is acknowledged, 
a fix is made, and this was in 2006-08-26:
   http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6464365

.. Read my description there: there is TWO things: first the obvious 
*bug*, but also a lack of some "getException" that could have been used 
in a "done()" override since the obvious option is broken. Although, if 
get() is idempotent, it would have worked to implement the same 
workaround as Doug describes, mentioned above

This set of classes and interfaces are not very straightforward, IMO. 
You pretty much HAVE to read the code to understand the workings, and 
doing that isn't all that easy with all the different interfaces and 
implementations of Callables, Runnables and Futures and whatnots. I 
personally feel I know those things now (which for STPE's case amounts 
to "don't use!"), but I'm just thinking poor newbies.

Thanks,
Endre.

From mike_edwards at uk.ibm.com  Fri Jan 25 08:05:57 2008
From: mike_edwards at uk.ibm.com (Mike Edwards)
Date: Fri, 25 Jan 2008 13:05:57 +0000
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <mailman.46.1201257457.28502.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <OF09BD3C3E.B501D5A6-ON802573DB.0046C08F-802573DB.0047F527@uk.ibm.com>

> Date: Thu, 24 Jan 2008 09:42:23 -0800
> From: "Joe Bowbeer" <joe.bowbeer at gmail.com>
> Subject: Re: [concurrency-interest] Frequently canceled timers
> To: concurrency-interest <concurrency-interest at cs.oswego.edu>
> Message-ID:
>    <31f2a7bd0801240942m44a915c2te0fb342c2fac963f at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> It should be more efficient to call executor.purge() periodically than
> to call remove() frequently.  Will this work in your case?
> 
> On Jan 24, 2008 8:20 AM, Richard Johns wrote:
> > I have an application that retransmits messages when they don't get a
> > timely response .  Usually, of course, that's not necessary and their
> > timers are canceled.  This is a traffic generator so message rate is
> > high and we need to remove the canceled timers.
> >
> > Is there a timer implementation that efficiently cleans up canceled
> > timers?  DelayQueue uses a binary heap so it's very fast otherwise, 
but
> > it uses a sequential search for remove().  ScheduledThreadPoolExecutor
> > uses DelayQueue, and Timer also uses a binary heap.
> >
> > --
> > Rick
> Date: Thu, 24 Jan 2008 15:19:17 -0800
> From: "Joe Bowbeer" <joe.bowbeer at gmail.com>
> Subject: Re: [concurrency-interest] Frequently canceled timers
> To: concurrency-interest <concurrency-interest at cs.oswego.edu>
> Message-ID:
>    <31f2a7bd0801241519j3d9ca827s9e4fd850b9c1346 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> > Richard Johns wrote:
> >
> > I have an application that retransmits messages when they don't get a
> > timely response . Usually, of course, that's not necessary and their
> > timers are canceled. This is a traffic generator so message rate is
> > high and we need to remove the canceled timers.
> >
> > Is there a timer implementation that efficiently cleans up canceled
> > timers? DelayQueue uses a binary heap so it's very fast otherwise, but
> > it uses a sequential search for remove(). ScheduledThreadPoolExecutor
> > uses DelayQueue, and Timer also uses a binary heap.
> >
> > Joe Bowbeer wrote:
> >
> > It should be more efficient to call executor.purge() periodically than
> > to call remove() frequently. Will this work in your case?
> >
> > Richard Johns wrote:
> >
> > No, ThreadPoolExecutor.purge() just gets the queue and calls remove() 
for
> > each canceled Future.  That would be worse, it would take the hit all 
at
> > once.
> 
> Now I see.
> 
> TPE.purge() iterates through the queue and calls iterator.remove() at
> the appropriate times.
> 
> However, DelayQueue's Iterator implementation re-walks the queue
> (again) for each item that is removed.
> 
> So I no longer think that ScheduledThreadPoolExecutor.purge() is more
> efficient than removing each item separately -- and I'm unhappy.
> 
> --Joe
Folks,

When I implemented the AIO4J async IO package, I ran into the same problem
concerning cancelled Timers - I/O operations having a timeout applied 
would
in general complete before the Timer expired, requiring the Timer to be 
cancelled in 99.99% of cases.  The standard Timer implementation in the 
JRE
doesn't handle high rates of allocation/cancellation of Timers at all 
well,
resulting in the heap filling with cancelled Timer objects.

The way I got around this was to reimplement the Timer related classes 
providing for immediate removal of a Timer object from its related holder
structure and enabling efficient garbage collection.  This required a fast
remove operation and to achieve this I implemented the holder structure 
based on a skip list permitting both efficient insertion and removal of
Timer objects.

Once this was done, the code could sustain very high rates of async I/O
method calls, where each call had a timeout and as a result an associated
Timer object.


Yours,  Mike.

Strategist - Emerging Technologies, SCA & SDO.
Co Chair OASIS SCA Assembly TC.
IBM Hursley Park, Mail Point 146, Winchester, SO21 2JN, Great Britain.
Phone & FAX: +44-1962-818014    Mobile: +44-7802-467431 
Email:  mike_edwards at uk.ibm.com





Unless stated otherwise above:
IBM United Kingdom Limited - Registered in England and Wales with number 
741598. 
Registered office: PO Box 41, North Harbour, Portsmouth, Hampshire PO6 3AU





-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/79bee17c/attachment.html 

From osvaldo at visionnaire.com.br  Fri Jan 25 10:05:00 2008
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Fri, 25 Jan 2008 12:05:00 -0300
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <4799BBD7.5080709@kav.dk>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>
Message-ID: <4799FA9C.1040906@visionnaire.com.br>

Kasper Nielsen escreveu:
> Doug Lea wrote:
>   
>> David J. Biesack wrote:
>>     
>>> Been working with the API more and I have a few more comments/suggestions
>>> assembled.
>>>       
>> Thanks! These are great! Please keep them coming! I hope to do
>> another renaming etc pass sometime based on the already good
>> suggestions stemming from last one.
>>
>> Along these lines: We've been thinking of
>> separating these from base FJ support and placing in new
>> subpackage java.util.concurrent.forkjoin.collections.
>> (or for now jsr166y.forkjoin.collections). Any opinions?
>>     
> Sure, go for it. I think once ParallelMap and ParallelBigArray arrives 
> it would make sense.
>   
Having a subpackage of collections would look weird, first because it's 
different from tradition: today, common collections are in java.util 
(together with lots of other non-collection stuff), and all concurrent 
collections are in java.util.concurrent (together with with lots of 
other non-collection stuff). Not that I think that List and Locale 
belong in the same package; java.util is a messy bag of unrelated 
utilites, but that's a design that comes from JDK 1.0 - including the 
first general collections like Vector. But in a second argument, for 
more specialized packages like j.u.c and forkjoin, I think it makes 
sense to co-locate special collections with the APIs that are used 
together with them. Packages should reflect the tight coupling between 
these APIs.

Notice that that tight coupling appears in the /interfaces/, not only in 
the implementations. For one thing, the Parallel*Array* classes are 
shock-full of methods that expose Ops.* interfaces in their signatures. 
This is very different, for example, from java.util.concurrent.atomic. 
The Atomic* objects are used massively in the /implementation/ of 
classes from the entire JSR166 APIs, but they do not appear as 
arguments, return values or super-types of anything. I think the same is 
true (or at least mostly true) for java.util.concurrent.lock.

A+
Osvaldo

-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/e6c73024/attachment.html 

From David.Biesack at sas.com  Fri Jan 25 09:56:28 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Fri, 25 Jan 2008 09:56:28 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <47992C6F.6010606@cs.oswego.edu> (message from Doug Lea on Thu,
	24 Jan 2008 19:25:19 -0500)
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu>
Message-ID: <200801251456.m0PEuS9P001077@cs.oswego.edu>

> Date: Thu, 24 Jan 2008 19:25:19 -0500
> From: Doug Lea <dl at cs.oswego.edu>
> CC: concurrency-interest at cs.oswego.edu
> 
> David J. Biesack wrote:
> > Been working with the API more and I have a few more comments/suggestions
> > assembled.
> 
> Thanks! These are great! Please keep them coming! I hope to do
> another renaming etc pass sometime based on the already good
> suggestions stemming from last one.

thank you for the opportunity to observe and comment.
 
> > Having used this a while, I personally don't like the liberal use of
> > "withThis" this and "withThat" throughout the API;
> 
> (Well, except for your suggested use in factories above :-)

I've been corrupted :-)
 
>   rename the
> > resulting ParallelArray*WithBounds, *WithMapping, WithFilter to
> > BoundedParallel*Array, MappedParallel*Array, FilteredParallel*Array. 
> > 
> > FilteredParallelDoubleArray pa = a.filter(myIndexFilter);
> 
> Note that it should be very rare to give a name to (thus mention the
> type of) to this kind of expression though.

The use case I was thinking of was to build a chain of filters/ops and
then save a reference to them.

  FilteredParallelDoubleArray fpa = a
      .filtered(myIndexFilter)
      .mapped(myMap)
      .filtered(mySecondFilter)
      .mapped(mySecondMap)
      .filtered(myThirdFilter);
  
Once this is done, I can obtain the result based on a's current contents:

   ParallelDoubleArray b = fpa.all();

Now I can change the underlying array a:

   a.replaceContents(myCombiner, x); // was: replaceWithMapping

and then extract the new derived array which is based on the modified contents of a :

   ParallelDoubleArray c = fpa.all();

Ditto for reductions, etc. If I'm really careful, I can also modify the filters and mappings between steps
(but certainly not when a step is running).

The hope is that the framework can optimize/combine the steps as necessary (there were earlier mentions of dynamic code generation) and by reusing the intermediate object, can bypass that extra optimization step and object allocations.

It's all the benefits of "rinse, lather, repeat" without having to lather again.

Is this a reasonable use of forkjoin structures?

> -Doug

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From szabolcs.ferenczi at gmail.com  Fri Jan 25 10:09:11 2008
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Fri, 25 Jan 2008 16:09:11 +0100
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <4798BADE.1020007@nortel.com>
References: <4798BADE.1020007@nortel.com>
Message-ID: <c8955b000801250709q441a5a9fvff773d83c89563ea@mail.gmail.com>

On 24/01/2008, Richard Johns <rjohns at nortel.com> wrote:
>
> I have an application that retransmits messages when they don't get a
> timely response .  Usually, of course, that's not necessary and their
> timers are canceled.  This is a traffic generator so message rate is
> high and we need to remove the canceled timers.
>
> Is there a timer implementation that efficiently cleans up canceled
> timers?


How about re-using the timer instead of throwing it away?
Reset it and use it again.
Best Regards,
Szabolcs

DelayQueue uses a binary heap so it's very fast otherwise, but
> it uses a sequential search for remove().  ScheduledThreadPoolExecutor
> uses DelayQueue, and Timer also uses a binary heap.
>
> --
> Rick
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/5ca6909b/attachment.html 

From rjohns at nortel.com  Fri Jan 25 10:39:30 2008
From: rjohns at nortel.com (Richard Johns)
Date: Fri, 25 Jan 2008 10:39:30 -0500
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <c8955b000801250709q441a5a9fvff773d83c89563ea@mail.gmail.com>
References: <4798BADE.1020007@nortel.com>
	<c8955b000801250709q441a5a9fvff773d83c89563ea@mail.gmail.com>
Message-ID: <479A02B2.1040903@nortel.com>

An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/c07630f0/attachment.html 

From jdmarshall at gmail.com  Fri Jan 25 12:17:28 2008
From: jdmarshall at gmail.com (jason marshall)
Date: Fri, 25 Jan 2008 09:17:28 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <4799FA9C.1040906@visionnaire.com.br>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>
	<4799FA9C.1040906@visionnaire.com.br>
Message-ID: <3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>

On Jan 25, 2008 7:05 AM, Osvaldo Pinali Doederlein <
osvaldo at visionnaire.com.br> wrote:

>
> Having a subpackage of collections would look weird, first because it's
> different from tradition: today, common collections are in java.util(together with lots of other non-collection stuff), and all concurrent
> collections are in java.util.concurrent (together with with lots of other
> non-collection stuff). Not that I think that List and Locale belong in the
> same package; java.util is a messy bag of unrelated utilites, but that's a
> design that comes from JDK 1.0 - including the first general collections
> like Vector. But in a second argument, for more specialized packages like
> j.u.c and forkjoin, I think it makes sense to co-locate special
> collections with the APIs that are used together with them. Packages should
> reflect the tight coupling between these APIs.
>

I'm not sure I can agree with this.  As a counterexample, I would cite more
complex APIs, which are split along functional areas.  Swing is perhaps an
ad absurdum example of this, but there are more moderate ones, like XML or
the cryptography libraries.  My main issue with the API so far, and the
reason Joe invited me to comment on it, relates to my strong negative
initial impression, which in a nutshell was this:

What the hell are these guys doing?  Specialized primitive implementations?
You've got to be joking.  It's not 1997, you know.

When I came to look at the ForkJoin code, I didn't expect the surface area
of the API to be so large. And when you pull up the Javadoc, the biggest
thing I notice is all of the Int-Int, Int-Long, Long-Int etc classes and
methods.  It's too much.  No, to be perfectly honest, it's a lttle shocking,
actually.  And the only way to solve that problem, short of removing them
entirely, is to segregate the core of ForkJoin from the logical next steps
(practical and obvious implementations).   So that when I look at the API
for the first time, I'm willing to give it a chance.

In other words, I should not have noticed the Array type specializations
first in an API.  That's not what ForkJoin is, right?

-Jason

PS:

Also, as a tangent back to my motivation for subscribing:  I don't agree
that a 2x increase in performance (no actual numbers were cited, just
'noticeably faster') is worth all of this extra code.  Haven't we learned by
now not to fight the JVM?  Wouldn't a better solution be to figure out how
we can -help- the JVM optimize the code instead of trying to do the job for
it?  And aren't the Number Objects allocated for the Object array likely to
have locality of reference anyway, because they will have temporal locality
(be allocated sequentially)?





> Notice that that tight coupling appears in the *interfaces*, not only in
> the implementations. For one thing, the Parallel*Array* classes are
> shock-full of methods that expose Ops.* interfaces in their signatures. This
> is very different, for example, from java.util.concurrent.atomic. The
> Atomic* objects are used massively in the *implementation* of classes from
> the entire JSR166 APIs, but they do not appear as arguments, return values
> or super-types of anything. I think the same is true (or at least mostly
> true) for java.util.concurrent.lock.
>
> A+
> Osvaldo
>
> --
> -----------------------------------------------------------------------
> Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/Aosvaldo at visionnaire.com.br                http://www.visionnaire.com.br
> Arquiteto de Tecnologia                          +55 (41) 337-1000 #223
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/408cfdac/attachment.html 

From dl at cs.oswego.edu  Fri Jan 25 12:54:21 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 25 Jan 2008 12:54:21 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>	
	<4799FA9C.1040906@visionnaire.com.br>
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
Message-ID: <479A224D.1050805@cs.oswego.edu>

jason marshall wrote:

> Also, as a tangent back to my motivation for subscribing:  I don't agree 
> that a 2x increase in performance (no actual numbers were cited, just 
> 'noticeably faster') is worth all of this extra code. 

Often 4X and up to 16X in some cases, which is enough to
outweigh benefits of parallelism on the majority of platforms (i.e.,
less than 16-ways) it will run on for the next few years at least.

Yes, it is ugly. Please help us find ways to overcome the past
decade's lack of attention to properly integrating scalars.

> Haven't we 
> learned by now not to fight the JVM?  Wouldn't a better solution be to 
> figure out how we can -help- the JVM optimize the code instead of trying 
> to do the job for it? 

Maybe so, but the only way to put pressure on language and JVM folks
to take on this unglamorous topic is to actually make something that
runs well but is awkward to use, and in some ways ugly even to look at
(but we are trying hard on that front).

> And aren't the Number Objects allocated for the 
> Object array likely to have locality of reference anyway, because they 
> will have temporal locality (be allocated sequentially)?
> 

That's only the tip of the iceberg. Other issues include
(1) It adds significant GC overhead clearing large arrays of refs.
(2) card-marking GC (google it) creates serious scalability
issues because of card table write contention (this is often the
biggest performance issue).  (3) It increases method
call chain length to access actual values, which interacts poorly
with JVM inlining rules. (4) When combined with function interfaces (like
the ones in Ops) it offers few opportunities to bypass boxing.
(5) The consequent inability to open up loop bodies means that few
classic loop optimizations (hoisting etc) that you take for granted
in plain loops can be applied.

Across each of these aspects, there's a "boxing is not so bad" mentality
that justifies lack of attention. But ParallelArray entails a perfect
storm combining them all to lead to serious performance issues.
If we released something that wasted all 16 of your new multicore/MP
CPUs to almost obtain simple sequential performance, there wouldn't
be much reason to use it. But we can, with some loss in uglification,
do a lot better. So we do.

If you or anyone would like to work on language, compiler, and
JVM techniques that improve this state of affairs, the world
will thank you when you make the specialized APIs irrelevant
so we can deprecate them.

-Doug

From osvaldo at visionnaire.com.br  Fri Jan 25 14:44:22 2008
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Fri, 25 Jan 2008 16:44:22 -0300
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>	
	<4799FA9C.1040906@visionnaire.com.br>
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
Message-ID: <479A3C16.6040708@visionnaire.com.br>

jason marshall escreveu:
> On Jan 25, 2008 7:05 AM, Osvaldo Pinali Doederlein 
> <osvaldo at visionnaire.com.br <mailto:osvaldo at visionnaire.com.br>> wrote:
>
>     Having a subpackage of collections would look weird, first because
>     it's different from tradition: today, common collections are in
>     java.util (together with lots of other non-collection stuff), and
>     all concurrent collections are in java.util.concurrent (together
>     with with lots of other non-collection stuff). Not that I think
>     that List and Locale belong in the same package; java.util is a
>     messy bag of unrelated utilites, but that's a design that comes
>     from JDK 1.0 - including the first general collections like
>     Vector. But in a second argument, for more specialized packages
>     like j.u.c and forkjoin, I think it makes sense to co-locate
>     special collections with the APIs that are used together with
>     them. Packages should reflect the tight coupling between these APIs.
>
>
> I'm not sure I can agree with this.  As a counterexample, I would cite 
> more complex APIs, which are split along functional areas.  Swing is 
> perhaps an ad absurdum example of this, but there are more moderate 
> ones, like XML or the cryptography libraries.  My main issue with the 
> API so far, and the reason Joe invited me to comment on it, relates to 
> my strong negative initial impression, which in a nutshell was this:
>
> What the hell are these guys doing?  Specialized primitive 
> implementations?  You've got to be joking.  It's not 1997, you know.
No... when it comes to primitive types versus objects, sometimes we're 
still in the 1950's. ;-) I remember somebody (Doug?) stating that this 
optimized support for primitives make some programs several times faster 
(4x+?). I think the only real solution would be an enhancement of 
generics to support primitives. But for better or worse, Java didn't go 
that way and it's not likely that this can/will be addressed in Java 7, 
or in any future release.
> When I came to look at the ForkJoin code, I didn't expect the surface 
> area of the API to be so large. And when you pull up the Javadoc, the 
> biggest thing I notice is all of the Int-Int, Int-Long, Long-Int etc 
> classes and methods.  It's too much.  No, to be perfectly honest, it's 
> a lttle shocking, actually.  And the only way to solve that problem, 
> short of removing them entirely, is to segregate the core of ForkJoin 
> from the logical next steps (practical and obvious implementations).   
> So that when I look at the API for the first time, I'm willing to give 
> it a chance.
I also have that bad feeling... but it's mostly psychological, because 
lots of types and methods are all the same, they don't require extra 
learning, and they occupy a tiny footprint in the JRE. I wonder if a 
customized composition of the javadocs could alleviate this problem.
> PS:
> Also, as a tangent back to my motivation for subscribing:  I don't 
> agree that a 2x increase in performance (no actual numbers were cited, 
> just 'noticeably faster') is worth all of this extra code.  Haven't we 
> learned by now not to fight the JVM?  Wouldn't a better solution be to 
> figure out how we can -help- the JVM optimize the code instead of 
> trying to do the job for it?  And aren't the Number Objects allocated 
> for the Object array likely to have locality of reference anyway, 
> because they will have temporal locality (be allocated sequentially)?
In most areas, betting against compiler technology proved to be a bad 
bet. But one notable exception is memory-intensive applications, 
remarkably numeric-oriented ones, versus GC and "everything is an 
object" purism. Today we have GCs so sophisticated and full of tricks 
that only Java gurus can tune their JVMs to the max (the ergonomics 
stuff is far from perfect yet), and still, we can observe large 
disadvantage against well tuned C code in the really wicked scenarios. 
Even if the GC behavior is perfect, you still have to face the fact that 
an Integer or Double object is 2-3X bigger than a primitive int or 
double. It sucks up much more space in main RAM and caches, and requires 
much more bandwidth.

The Java platform developed a number of workarounds, like java.nio's 
direct buffers (read: manual memory management that favors manipulation 
of data as raw byte arrays - even worse that primitive arrays of 
primitive types, and RTSJ (more manual memory mgmt). I wonder if 
forkoind could integrate to these things in the future.

A+
Osvaldo

-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo at visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/6876322c/attachment.html 

From dl at cs.oswego.edu  Fri Jan 25 13:52:06 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 25 Jan 2008 13:52:06 -0500
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <4798BADE.1020007@nortel.com>
References: <4798BADE.1020007@nortel.com>
Message-ID: <479A2FD6.8000006@cs.oswego.edu>

Richard Johns wrote:
> I have an application that retransmits messages when they don't get a 
> timely response .  Usually, of course, that's not necessary and their 
> timers are canceled.  This is a traffic generator so message rate is 
> high and we need to remove the canceled timers.
> 
> Is there a timer implementation that efficiently cleans up canceled 
> timers?  DelayQueue uses a binary heap so it's very fast otherwise, but 
> it uses a sequential search for remove().  ScheduledThreadPoolExecutor 
> uses DelayQueue, and Timer also uses a binary heap.
> 

Sorry for not paying attention to this before others replied...

Last september, we put out revised version of ScheduledThreadPoolExecutor
that uses an internal variant of DelayQueue that includes fast eager
cleanup on cancel. This isn't scheduled to get out until Java7 though.
Which looks like it might be a while.
And even then. because of compatibility concerns, fast cleanup won't
be default enabled -- see method setRemoveOnCancelPolicy(boolean).
(Although hopefully this will be reconsidered later.)

But until then you may be able to use or adapt our version in
CVS, that relies also on updated version of ThreadPoolExecutor
that you can also get from CVS.

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ScheduledThreadPoolExecutor.java?view=log

-Doug


From rjohns at nortel.com  Fri Jan 25 14:56:08 2008
From: rjohns at nortel.com (Richard Johns)
Date: Fri, 25 Jan 2008 14:56:08 -0500
Subject: [concurrency-interest] Frequently canceled timers
In-Reply-To: <479A2FD6.8000006@cs.oswego.edu>
References: <4798BADE.1020007@nortel.com> <479A2FD6.8000006@cs.oswego.edu>
Message-ID: <479A3ED8.4020804@nortel.com>

Doug Lea wrote:
> Richard Johns wrote:
>> I have an application that retransmits messages when they don't get a 
>> timely response .  Usually, of course, that's not necessary and their 
>> timers are canceled.  This is a traffic generator so message rate is 
>> high and we need to remove the canceled timers.
>>
>> Is there a timer implementation that efficiently cleans up canceled 
>> timers?  DelayQueue uses a binary heap so it's very fast otherwise, 
>> but it uses a sequential search for remove().  
>> ScheduledThreadPoolExecutor uses DelayQueue, and Timer also uses a 
>> binary heap.
>>
>
> Sorry for not paying attention to this before others replied...
>
> Last september, we put out revised version of ScheduledThreadPoolExecutor
> that uses an internal variant of DelayQueue that includes fast eager
> cleanup on cancel. This isn't scheduled to get out until Java7 though.
> Which looks like it might be a while.
> And even then. because of compatibility concerns, fast cleanup won't
> be default enabled -- see method setRemoveOnCancelPolicy(boolean).
> (Although hopefully this will be reconsidered later.)
>
> But until then you may be able to use or adapt our version in
> CVS, that relies also on updated version of ThreadPoolExecutor
> that you can also get from CVS.
>
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ScheduledThreadPoolExecutor.java?view=log 
>
>
> -Doug
>
Perfect!  (Well, except for the "Java7" part.)  Thanks, I'll use this.

Rick 




From mthornton at optrak.co.uk  Fri Jan 25 15:58:03 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Fri, 25 Jan 2008 20:58:03 +0000
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479A3C16.6040708@visionnaire.com.br>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>		<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>		<4799FA9C.1040906@visionnaire.com.br>	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
	<479A3C16.6040708@visionnaire.com.br>
Message-ID: <479A4D5B.1070802@optrak.co.uk>

Osvaldo Pinali Doederlein wrote:
>> What the hell are these guys doing?  Specialized primitive 
>> implementations?  You've got to be joking.  It's not 1997, you know.
> No... when it comes to primitive types versus objects, sometimes we're 
> still in the 1950's. ;-) I remember somebody (Doug?) stating that this 
> optimized support for primitives make some programs several times 
> faster (4x+?). I think the only real solution would be an enhancement 
> of generics to support primitives. But for better or worse, Java 
> didn't go that way and it's not likely that this can/will be addressed 
> in Java 7, or in any future release.
During the first public review of JSR 14 (Generics) I proposed an 
extension that would have supported primitives. I seem to remember that 
the response was that doing so would be politically impossible as it 
would get unwelcome attention from the anti-primitive brigade. In other 
words this was a battle they didn't want to fight. I think the mechanism 
I proposed then would still be technically feasible today (absent 
curious interactions with auto-boxing). The political issue remains.

Mark Thornton

From neal at gafter.com  Fri Jan 25 17:00:39 2008
From: neal at gafter.com (Neal Gafter)
Date: Fri, 25 Jan 2008 14:00:39 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479A4D5B.1070802@optrak.co.uk>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>
	<4799FA9C.1040906@visionnaire.com.br>
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
	<479A3C16.6040708@visionnaire.com.br> <479A4D5B.1070802@optrak.co.uk>
Message-ID: <15e8b9d20801251400m316d36e5n39107125e58d809e@mail.gmail.com>

On Jan 25, 2008 12:58 PM, Mark Thornton <mthornton at optrak.co.uk> wrote:

> During the first public review of JSR 14 (Generics) I proposed an
> extension that would have supported primitives. ... I think the mechanism
> I proposed then would still be technically feasible today (absent
> curious interactions with auto-boxing)...


I've never heard a proposal that I thought was technically feasible from a
language perspective, other than the obvious performance-problematic scheme
of boxing on the way in and unboxing on the way out.  Do you have a writeup
of your proposed subtyping rules?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/852cce85/attachment.html 

From mthornton at optrak.co.uk  Fri Jan 25 17:13:57 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Fri, 25 Jan 2008 22:13:57 +0000
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479A224D.1050805@cs.oswego.edu>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>		<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>		<4799FA9C.1040906@visionnaire.com.br>	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
	<479A224D.1050805@cs.oswego.edu>
Message-ID: <479A5F25.1070603@optrak.co.uk>

Doug Lea wrote:
> Maybe so, but the only way to put pressure on language and JVM folks
> to take on this unglamorous topic is to actually make something that
> runs well but is awkward to use, and in some ways ugly even to look at
> (but we are trying hard on that front).
>
>   
This is a rather old page (no longer available in its original location):

http://web.archive.org/web/20020202105718/http://java.sun.com/people/jag/FP.html#classes

"/This is an old proposal that was put together way back in 1997. 
Nothing like this has ever moved forward, but there are newer versions 
on the table."

/Even older now. :-(

It seems the Java's object identity (== operator) prevents the creation 
of an efficient unified class system --- you always have either a split 
into 'value' vs 'regular' objects, or you have a significant loss of 
efficiency./
/
Mark Thornton




From mthornton at optrak.co.uk  Fri Jan 25 17:30:09 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Fri, 25 Jan 2008 22:30:09 +0000
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <15e8b9d20801251400m316d36e5n39107125e58d809e@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>	
	<4799FA9C.1040906@visionnaire.com.br>	
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>	
	<479A3C16.6040708@visionnaire.com.br>
	<479A4D5B.1070802@optrak.co.uk>
	<15e8b9d20801251400m316d36e5n39107125e58d809e@mail.gmail.com>
Message-ID: <479A62F1.7040409@optrak.co.uk>

Neal Gafter wrote:
> On Jan 25, 2008 12:58 PM, Mark Thornton <mthornton at optrak.co.uk 
> <mailto:mthornton at optrak.co.uk>> wrote:
>
>     During the first public review of JSR 14 (Generics) I proposed an
>     extension that would have supported primitives. ... I think the
>     mechanism
>     I proposed then would still be technically feasible today (absent
>     curious interactions with auto-boxing)...
>
>
> I've never heard a proposal that I thought was technically feasible 
> from a language perspective, other than the obvious 
> performance-problematic scheme of boxing on the way in and unboxing on 
> the way out.  Do you have a writeup of your proposed subtyping rules?
I'll see what I can dredge up from the archives when I'm at work. It 
never progressed very far as the primary reason for rejection wasn't 
technical. Essentially though a type argument was either a regular one 
(as now) or constrained to be a numeric primitive. A type argument 
couldn't be replaced by both object types and primitives. Then instead 
of having Collections.sort methods for Object[] and every numeric 
primitive, just two methods are required, one for Objects (as now) and 
the other for all the numeric primitives.

Mark Thornton

From jdmarshall at gmail.com  Fri Jan 25 20:04:20 2008
From: jdmarshall at gmail.com (jason marshall)
Date: Fri, 25 Jan 2008 17:04:20 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479A224D.1050805@cs.oswego.edu>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>
	<4799FA9C.1040906@visionnaire.com.br>
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
	<479A224D.1050805@cs.oswego.edu>
Message-ID: <3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>

Now that I've stirred the hornet's nest, let me ask you all a higher level
question:

Do you think the serious design wins for ForkJoin are going to come from
from parallelizing tasks that only take a few instruction cycles, or do you
think ForkJoin's biggest win will be with tasks that take thousands or
millions of cycles?

Most of the posts in this thread are dealing with things that happen near
the noise floor, where the cost of a single address lookup are as big as the
function you plan to execute over the value (ie, basic arithmetic).  If I'm
looking for prime numbers, then building it out of Integers or ints probably
isn't going to matter very much in the overall timeslice.  If I'm looking
for the min element, sure, it'll be faster.  But how often do I really need
to have automated parallelization of min(int[])?


My understanding is that, if you really want to make a function over
primitives go very, very fast, you're going to convert the code to SIMD
instructions on the processor, on in the GPU.  Therefore, the Big Win here
is not in writing an API that tries to make the Java code run as fast as
possible, but instead figuring out how to get Hotspot to turn your code into
SIMD calls for you.

Can you do that with Integer[] or Double[]?  Maybe, maybe not.  But until
Hotspot does that with ints[], and float[], then it hardly matters, does it?

On Jan 25, 2008 9:54 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> jason marshall wrote:
>
> > Also, as a tangent back to my motivation for subscribing:  I don't agree
> > that a 2x increase in performance (no actual numbers were cited, just
> > 'noticeably faster') is worth all of this extra code.
>
> Often 4X and up to 16X in some cases, which is enough to
> outweigh benefits of parallelism on the majority of platforms (i.e.,
> less than 16-ways) it will run on for the next few years at least.
>
> Yes, it is ugly. Please help us find ways to overcome the past
> decade's lack of attention to properly integrating scalars.
>
> > Haven't we
> > learned by now not to fight the JVM?  Wouldn't a better solution be to
> > figure out how we can -help- the JVM optimize the code instead of trying
> > to do the job for it?
>
> Maybe so, but the only way to put pressure on language and JVM folks
> to take on this unglamorous topic is to actually make something that
> runs well but is awkward to use, and in some ways ugly even to look at
> (but we are trying hard on that front).
>
> > And aren't the Number Objects allocated for the
> > Object array likely to have locality of reference anyway, because they
> > will have temporal locality (be allocated sequentially)?
> >
>
> That's only the tip of the iceberg. Other issues include
> (1) It adds significant GC overhead clearing large arrays of refs.
> (2) card-marking GC (google it) creates serious scalability
> issues because of card table write contention (this is often the
> biggest performance issue).  (3) It increases method
> call chain length to access actual values, which interacts poorly
> with JVM inlining rules. (4) When combined with function interfaces (like
> the ones in Ops) it offers few opportunities to bypass boxing.
> (5) The consequent inability to open up loop bodies means that few
> classic loop optimizations (hoisting etc) that you take for granted
> in plain loops can be applied.
>
> Across each of these aspects, there's a "boxing is not so bad" mentality
> that justifies lack of attention. But ParallelArray entails a perfect
> storm combining them all to lead to serious performance issues.
> If we released something that wasted all 16 of your new multicore/MP
> CPUs to almost obtain simple sequential performance, there wouldn't
> be much reason to use it. But we can, with some loss in uglification,
> do a lot better. So we do.
>
> If you or anyone would like to work on language, compiler, and
> JVM techniques that improve this state of affairs, the world
> will thank you when you make the specialized APIs irrelevant
> so we can deprecate them.
>
> -Doug
>



-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/871cd8df/attachment.html 

From dl at cs.oswego.edu  Fri Jan 25 20:21:32 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 25 Jan 2008 20:21:32 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>	<4799FA9C.1040906@visionnaire.com.br>	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>	<479A224D.1050805@cs.oswego.edu>
	<3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>
Message-ID: <479A8B1C.5070900@cs.oswego.edu>

jason marshall wrote:
> Now that I've stirred the hornet's nest, let me ask you all a higher 
> level question:
> 
> Do you think the serious design wins for ForkJoin are going to come from 
> from parallelizing tasks that only take a few instruction cycles, or do 
> you think ForkJoin's biggest win will be with tasks that take thousands 
> or millions of cycles?
> 

That one is easy; the former. We already have j.u.c frameworks in place
(Executors, Futures, etc) for the latter, and they are widely used.

> Most of the posts in this thread are dealing with things that happen 
> near the noise floor, 

How often do you iterate over collections or arrays?
That's basically what ParallelArray et al do for you, for various
kinds of structured traversals.

> My understanding is that, if you really want to make a function over 
> primitives go very, very fast, you're going to convert the code to SIMD 
> instructions on the processor, on in the GPU.  

We've discussed with people looking into SIMD loop optimization.
Surprisingly enough, they require the same sorts of structured
traversals that we arrange. So the leaf computations in a forkjoin
operation may well eventually be SIMD.

> Therefore, the Big Win 
> here is not in writing an API that tries to make the Java code run as 
> fast as possible, but instead figuring out how to get Hotspot to turn 
> your code into SIMD calls for you.

Or both :-)

> 
> Can you do that with Integer[] or Double[]?  Maybe, maybe not.  But 
> until Hotspot does that with ints[], and float[], then it hardly 
> matters, does it?

The SIMD int connection is why ParallelIntArray may possibly be
revived. Floats, not so much.

-Doug


From jdmarshall at gmail.com  Fri Jan 25 20:53:11 2008
From: jdmarshall at gmail.com (jason marshall)
Date: Fri, 25 Jan 2008 17:53:11 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479A8B1C.5070900@cs.oswego.edu>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>
	<47992C6F.6010606@cs.oswego.edu> <4799BBD7.5080709@kav.dk>
	<4799FA9C.1040906@visionnaire.com.br>
	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>
	<479A224D.1050805@cs.oswego.edu>
	<3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>
	<479A8B1C.5070900@cs.oswego.edu>
Message-ID: <3cf41bb90801251753h31e37199xf8452b9d83dd5525@mail.gmail.com>

On Jan 25, 2008 5:21 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> jason marshall wrote:
> > Now that I've stirred the hornet's nest, let me ask you all a higher
> > level question:
> >
> > Do you think the serious design wins for ForkJoin are going to come from
> > from parallelizing tasks that only take a few instruction cycles, or do
> > you think ForkJoin's biggest win will be with tasks that take thousands
> > or millions of cycles?
> >
>
> That one is easy; the former. We already have j.u.c frameworks in place
> (Executors, Futures, etc) for the latter, and they are widely used.
>

> > Most of the posts in this thread are dealing with things that happen
> > near the noise floor,
>
> How often do you iterate over collections or arrays?
> That's basically what ParallelArray et al do for you, for various
> kinds of structured traversals.
>

I would like to do it more often, actually.  And this is where ParallelArray
offers some things that don't quite exist in j.u.c, which is why I'm
interested.  But if jsr166 is predominantly about number crunching in the
small, then maybe I'm not the target audience.

I think my original point stands regardless:  It would be nice if the
high-level concepts were accessible from the Javadoc, and currently they are
not (and now the Ops interfaces are actually worse by far in that respect
than Parallel*Array was when I first looked at the spec).






> > My understanding is that, if you really want to make a function over
> > primitives go very, very fast, you're going to convert the code to SIMD
> > instructions on the processor, on in the GPU.
>
> We've discussed with people looking into SIMD loop optimization.
> Surprisingly enough, they require the same sorts of structured
> traversals that we arrange. So the leaf computations in a forkjoin
> operation may well eventually be SIMD.
>
> > Therefore, the Big Win
> > here is not in writing an API that tries to make the Java code run as
> > fast as possible, but instead figuring out how to get Hotspot to turn
> > your code into SIMD calls for you.
>
> Or both :-)
>
> >
> > Can you do that with Integer[] or Double[]?  Maybe, maybe not.  But
> > until Hotspot does that with ints[], and float[], then it hardly
> > matters, does it?
>
> The SIMD int connection is why ParallelIntArray may possibly be
> revived. Floats, not so much.
>

For floats, the prevailing winds suggest you're going to use GPGPU for
SIMD.  IEEE incompatibilities notwithstanding.




> -Doug
>
>


-- 
- Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080125/7646281c/attachment.html 

From mthornton at optrak.co.uk  Sat Jan 26 05:49:05 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Sat, 26 Jan 2008 10:49:05 +0000
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801251753h31e37199xf8452b9d83dd5525@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>	<4799FA9C.1040906@visionnaire.com.br>	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>	<479A224D.1050805@cs.oswego.edu>	<3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>	<479A8B1C.5070900@cs.oswego.edu>
	<3cf41bb90801251753h31e37199xf8452b9d83dd5525@mail.gmail.com>
Message-ID: <479B1021.2070300@optrak.co.uk>

jason marshall wrote:
>
> For floats, the prevailing winds suggest you're going to use GPGPU for 
> SIMD.  IEEE incompatibilities notwithstanding.
The IEEE incompatibilities may make that a non starter for Java. 
Currently Java can't even use instructions like the fused Multiply 
Accumulate present on some processors. JSR-84 was withdrawn.

Mark Thornton


From dl at cs.oswego.edu  Sat Jan 26 14:23:17 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 26 Jan 2008 14:23:17 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801251753h31e37199xf8452b9d83dd5525@mail.gmail.com>
References: <200801242223.m0OMN5oP012652@cs.oswego.edu>	<47992C6F.6010606@cs.oswego.edu>
	<4799BBD7.5080709@kav.dk>	<4799FA9C.1040906@visionnaire.com.br>	<3cf41bb90801250917ga7b3e01wfe609f93771e3262@mail.gmail.com>	<479A224D.1050805@cs.oswego.edu>	<3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>	<479A8B1C.5070900@cs.oswego.edu>
	<3cf41bb90801251753h31e37199xf8452b9d83dd5525@mail.gmail.com>
Message-ID: <479B88A5.6010400@cs.oswego.edu>

jason marshall wrote:
>  And this is where 
> ParallelArray offers some things that don't quite exist in j.u.c, which 
> is why I'm interested. 

Glad we agree! Most people do seem to like the basic idea here,
which is that:
   1. A lot of everyday code involves traversal
   2. A lot of that traversal takes (or could be easily recast to)
      a parallelizable form (which again overlaps with SIMDable and
      cluster-parallel forms).
   3. A lot of developers would be happy if we put together something
      making it easy and attractive to program in this way to exploit
      increasingly ubiquitous multicores and MPs.

Of course this is not intended to address all possible forms of
concurrency and parallelism; just a common one that is
finally becoming realistically supportable, and is not addressed
by other components and frameworks.

>  But if jsr166 is predominantly about number 
> crunching in the small ...

Not directly, but this emerges as a sort of corollary to (1) and (2):
Most traversals in practice appear to mainly involve, at base,
operations on simple scalar values. So if you ignore this part,
then it hard to make good on the overall goals.

Backing up even further though: Taking all this on encounters
a continuing series of misfits with Java. We could give up
because of them, but we are much too masochistic for that :-).
The highlights so far:

Misfit #1: Java syntax for passing in snippets of code for per-element
operations is awkward and verbose. So we've tried:
   Plan A: Help instigate the "Java closures controversy"
   Plan B: Develop and recommend a usage style that is fairly
     tolerable regardless of syntax support, and likely to be
     much moreso if/when IDEs help out with it.

Misfit #2: Java has no syntax or names or conventions for the
types of these snippets of code needed for apply, reduce,
filter, etc actions. so:
    Plan A: Help intensify language controversies to include
      nominal vs function type disagreements.
    Plan B: Just define all the types the framework will ever need.
      (i..e, all the ones in Ops). It's weird, but people get over
      the weirdness pretty quickly.
      Unexpected consequence: The fact that javadoc thinks you want to
         even see all these boring types is even more offputting.
         We've gotta do something about that.

Misfit #3: Java has at best partial support for allowing checked
exceptions in these snippets of code.
   Plan A: Encourage language folks to fix this.
   Plan B: Just don't allow checked exceptions (which is very
     defensible on other grounds anyway, and likely to continue
     even if better language support emerges).

Misfit #4: Java does not allow you parameterize any of the above
over scalar types, just boxed versions, which as we've been
discussing, are the enemies of efficient parallel processing.
    Plan A: Well, there is no Plan A.
    Plan B: Internally implement all the useful cross products
      of objects vs scalars, limiting API impact to only
      a few essential ones (like the underlying array type).
      Status: Not there yet. There are still too many visible byproducts,
         odd-looking type names, etc. But still enough plausible ideas
         about addressing these to believe this can be made acceptable.

And as a final 30,000ft remark: Even if we cannot achieve usability
goals, we will still have created a useful library that developers
in the future might mainly access from other languages running on JVMs.
In fact, all of the new, evolving JVM-based languages I know that aim to
support fine-grained parallelism already do use some form of
our underlying forkjoin mechanisms, so might be expected to
use the aggregate-operation APIs as well. (Fortress uses jsr166y directly;
last I looked Scala uses FJTask predecessor (which they ought to upgrade!);
and as-yet unreleased X10 runtimes use a continuation-based variant
of jsr166y version.)

(OK, while I'm at it, since people do keep asking me what I
think of these: To me, X10 looks very promising
at least over the medium term for this style of programming while
otherwise maintaining most of the look and feel of Java. Scala
has better integration with programming support unrelated to
parallelism. Fortress is bound to be among the nicest-looking
and most carefully crafted languages ever, but may take a while
to reach the point of everyday usability.)

-Doug

From joe.bowbeer at gmail.com  Sun Jan 27 17:09:52 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sun, 27 Jan 2008 14:09:52 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
Message-ID: <31f2a7bd0801271409l62225635x7a75930dbdb60a14@mail.gmail.com>

On Jan 15, 2008 8:12 AM, Joshua Bloch <josh at bloch.us> wrote:
>
> Hmmm... the onInt and withInt don't really feel right to me.  If people
> don't like intOp (or intFn), then I think we should go with David's
> inclination (intToInt).
>

I'm not sure where the thinking on this is at the moment, but after
finally coding an example(!), I agree with David that intToInt and
LongToLong are better than IntOp and LongOp, respectively.

The Ops table is so big that some consistent convention is better than
a couple shorter names.

1. When searching through the Ops in my IDE, I'd like to remember only
one thing: the naming convention.  That will allow me to start typing
and tabbing and eventually find the Op I'm looking for.

2. When reading my code, the Ops prefix signals me to "load" the
naming convention into my memory so that I can make sense of the type
name that follows.  For this, a consistent convention is better than
one with (even) a couple exceptions.

--Joe

From josh at bloch.us  Sun Jan 27 18:43:34 2008
From: josh at bloch.us (Joshua Bloch)
Date: Sun, 27 Jan 2008 15:43:34 -0800
Subject: [concurrency-interest] Ops type names
In-Reply-To: <31f2a7bd0801271409l62225635x7a75930dbdb60a14@mail.gmail.com>
References: <mailman.7.1200275054.28502.concurrency-interest@altair.cs.oswego.edu>
	<200801142215.m0EMFdED002211@cs.oswego.edu>
	<b097ac510801141653h2d911581r33ab762c1cc50d6a@mail.gmail.com>
	<478CD9F9.8060609@cox.net>
	<b097ac510801150812i2ffb40e7j49f0f025278fb75d@mail.gmail.com>
	<31f2a7bd0801271409l62225635x7a75930dbdb60a14@mail.gmail.com>
Message-ID: <b097ac510801271543t24329a6dw91ea3dcb9b4f15c5@mail.gmail.com>

Works for me.

     Josh

On Jan 27, 2008 2:09 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> On Jan 15, 2008 8:12 AM, Joshua Bloch <josh at bloch.us> wrote:
> >
> > Hmmm... the onInt and withInt don't really feel right to me.  If people
> > don't like intOp (or intFn), then I think we should go with David's
> > inclination (intToInt).
> >
>
> I'm not sure where the thinking on this is at the moment, but after
> finally coding an example(!), I agree with David that intToInt and
> LongToLong are better than IntOp and LongOp, respectively.
>
> The Ops table is so big that some consistent convention is better than
> a couple shorter names.
>
> 1. When searching through the Ops in my IDE, I'd like to remember only
> one thing: the naming convention.  That will allow me to start typing
> and tabbing and eventually find the Op I'm looking for.
>
> 2. When reading my code, the Ops prefix signals me to "load" the
> naming convention into my memory so that I can make sense of the type
> name that follows.  For this, a consistent convention is better than
> one with (even) a couple exceptions.
>
> --Joe
>  _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080127/eaaf4772/attachment.html 

From Darron_Shaffer at stercomm.com  Mon Jan 28 08:54:20 2008
From: Darron_Shaffer at stercomm.com (Shaffer, Darron)
Date: Mon, 28 Jan 2008 08:54:20 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <3cf41bb90801251704o5a9ba50bi870af651229f6463@mail.gmail.com>
Message-ID: <FC30D8A2D3DEE64D93E8DA54A1DB349A01487793@IWDUBCORMSG007.sci.local>


> Do you think the serious design wins for ForkJoin are going to come
from from parallelizing tasks that 
> only take a few instruction cycles, or do you think ForkJoin's biggest
win will be with tasks that take 
> thousands or millions of cycles?


I have a great curiosity about combining NIO with ForkJoin.  When a
selector unblocks with 150 SocketChannels ready for attention, then
ForkJoin could hand the processing off to a pool of threads.  Crypto
probably needs to be moved to a separate stage so it doesn't stall
everything, but otherwise this looks like a natural match.



From David.Biesack at sas.com  Mon Jan 28 15:05:16 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 28 Jan 2008 15:05:16 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <mailman.1.1201453200.25327.concurrency-interest@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <mailman.1.1201453200.25327.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <200801282005.m0SK5G2a016368@cs.oswego.edu>

> From: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] jsr166y.forkjoin API comments
> 
> jason marshall wrote:
> >  And this is where 
> > ParallelArray offers some things that don't quite exist in j.u.c, which 
> > is why I'm interested. 
> 
> Glad we agree! Most people do seem to like the basic idea here,
> which is that:
>    1. A lot of everyday code involves traversal
>    2. A lot of that traversal takes (or could be easily recast to)
>       a parallelizable form (which again overlaps with SIMDable and
>       cluster-parallel forms).
>    3. A lot of developers would be happy if we put together something
>       making it easy and attractive to program in this way to exploit
>       increasingly ubiquitous multicores and MPs.

I just posted a more detailed example to the wiki, comparing
a sequential matrix multiplication algorithm, then the same
algorithm rewritten to run concurrently with an ExecutorService
and then rewritten using ForkJoin

   http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W40

I hope this helps illuminate the programming improvements
that ForkJoin brings. May not be as elegant as with closures, but
it's not bad.

Having written this example, I come away with two (new!) API comments
which I'll post separately.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From David.Biesack at sas.com  Mon Jan 28 15:15:58 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 28 Jan 2008 15:15:58 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
Message-ID: <200801282015.m0SKFwuM017582@cs.oswego.edu>


I wrote:

> Having written this example, I come away with two (new!) API comments
> which I'll post separately.

Here is the first observation.

As can be seen with the Matrix Multiplication example at http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W40 , sometimes you want fork/join but you don't have an array to operate on; you just have a set of indices. In the example, I create a ParallelArray but don't use it; the data already exists in double[][] arrays. Hence the internal allocation of the Object[] array is wasted.

I could have created a ParallelArray<double[]> but this would have been misleading since the algorithm is not structured that way. That is, for the original sequential algorithm,


        for (int j = 0; j < n; j++) {
            for (int i = 0; i < m; i++) {
                final double[] Arowi = a[i];
                double s = 0;
                for (int k = 0; k < n; k++) {
                    s += Arowi[k] * b[k][j]; // A[i][k] * B[k][j]
                }
                c[i][j] = s;
            }
        }

where j is the outer loop index, there is not an array that is referenced via array[j]. Thus, using ForkJoin is slightly more awkward than it needs to be for this pretty basic operation.

I don't know if there is a solution other than adding a new create() method which defers allocating the internal array until and only if it is needed (or maybe not at all, and it's a programming error to use the wrong factory if you really wish to replace/generate values.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From David.Biesack at sas.com  Mon Jan 28 15:35:33 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 28 Jan 2008 15:35:33 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
Message-ID: <0JVD00GREFV9P7A0@fe-prod-02.oswego.edu>


I wrote:

> Having written this example, I come away with two (new!) API comments
> which I'll post separately.

Here is the second observation. A bit long, sorry.

In http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W40 I wanted to operate on the indices only, but not replace the values. Thus, I wanted apply() instead of replaceWithMapping(). But Ops.Procedure was insufficient because it does not pass the index. That is, I wanted a operation interface that has the signature

   void op(int index, A value>);

I ended up using Ops.IntToObject<A> and simply ignoring the result.

Rather than introduce a new interface and new apply() method, I think the ForkJoin API can be lightened by removing the various *Procedure types and replacing them with the existing IntAnd{Type}To{Type} (i.e. IntAndDoubleToDouble, IntAndObjectToObject, etc.) operators and changing apply() to take that same operator type; apply() simply ignores the Op's output (which can be Void typed).

   Ops.DoubleProcedure                use Ops.IntAndDoubleToDouble
   Ops.IntAndDoubleProcedure          use Ops.IntAndDoubleToDouble
   Ops.IntAndObjectProcedure<A>       use Ops.IntAndObjectToObject
   Ops.LongProcedure                  use Ops.IntAndLongToLong
   Ops.Procedure<A>                   use Ops.IntAndObjectToObject

But wait, there's more. The API could be further simplified if some of the methods which do not use the index or the value are consolidated with the indexed variants. For example, in ParallelArray there are three similar methods (generic stripped for simplicity)

 ParallelArray replaceWithMappedIndex(Ops.IntToObject op)
 ParallelArray replaceWithMapping(Ops.Op op)
 ParallelArray replaceWithMappedIndex(Ops.IntAndObjectToObject op)

which can be replaced with a single method:

   ParallelArray mapped(Ops.IntAndObjectToObject op)

as follows:

ParallelArray replaceWithMappedIndex(Ops.IntToObject<Void> op)

    ignore the Void b parameter

ParallelArray replaceWithMapping(Ops.Op op)

    ignore the int a parameter.

ParallelArray replaceWithMappedIndex(Ops.IntAndObjectToObject op)

   this method is renamed to mapped.

Just a thought.

(Sidebar: I don't see uses of many of the Procedure types actually used anywhere in jsr166y.forkjoin. Defined but not used anywhere are:

   Ops.DoubleAndDoubleProcedure     
   Ops.DoubleAndIntProcedure        
   Ops.DoubleAndLongProcedure       
   Ops.DoubleAndObjectProcedure  
   Ops.IntAndIntProcedure           
   Ops.IntAndLongProcedure          
   Ops.IntProcedure                 
   Ops.LongAndDoubleProcedure       
   Ops.LongAndIntProcedure          
   Ops.LongAndLongProcedure         
   Ops.LongAndObjectProcedure    
   Ops.ObjectAndDoubleProcedure  
   Ops.ObjectAndIntProcedure     
   Ops.ObjectAndLongProcedure    
   Ops.ObjectAndObjectProcedure

Perhaps these unused interfaces are designated for an upcoming forkjoin ParallelMap.)

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From David.Biesack at sas.com  Mon Jan 28 15:36:53 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Mon, 28 Jan 2008 15:36:53 -0500 (EST)
Subject: [concurrency-interest] Rename compoundOp -> compositeOp
Message-ID: <200801282036.m0SKarsu019139@cs.oswego.edu>


I did not see any feedback on this earlier suggestion. Perhaps it got lost in the "with"/fluent API discussion:

   Rename CommonOps.compoundOp as CommonOps.compositeOp as per the well-known Composite design pattern.

thanks

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From joe.bowbeer at gmail.com  Mon Jan 28 17:20:10 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 28 Jan 2008 14:20:10 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <200801282015.m0SKFwuM017582@cs.oswego.edu>
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
Message-ID: <31f2a7bd0801281420m15baad0dv28d7ad39dc742159@mail.gmail.com>

On Jan 28, 2008 12:15 PM, David J. Biesack wrote:
>
> As can be seen with the Matrix Multiplication example, sometimes you want fork/join
> but you don't have an array to operate on; you just have a set of indices. In the example,
> I create a ParallelArray but don't use it; the data already exists in double[][] arrays.
> Hence the internal allocation of the Object[] array is wasted.
>
> [ ... ]
>
> I don't know if there is a solution other than adding a new create() method which defers
> allocating the internal array until and only if it is needed (or maybe not at all, and it's a
> programming error to use the wrong factory if you really wish to replace/generate values.
>

There is a createEmpty method.  Does it suffice?

--Joe

From joe.bowbeer at gmail.com  Mon Jan 28 17:31:27 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 28 Jan 2008 14:31:27 -0800
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <31f2a7bd0801281420m15baad0dv28d7ad39dc742159@mail.gmail.com>
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
	<31f2a7bd0801281420m15baad0dv28d7ad39dc742159@mail.gmail.com>
Message-ID: <31f2a7bd0801281431u3ffd275fv2b6f4d5cd13a7b29@mail.gmail.com>

On Jan 28, 2008 2:20 PM, Joe Bowbeer wrote:
> On Jan 28, 2008 12:15 PM, David J. Biesack wrote:
> >
> > As can be seen with the Matrix Multiplication example, sometimes you want fork/join
> > but you don't have an array to operate on; you just have a set of indices. In the example,
> > I create a ParallelArray but don't use it; the data already exists in double[][] arrays.
> > Hence the internal allocation of the Object[] array is wasted.
> >
> > [ ... ]
> >
> > I don't know if there is a solution other than adding a new create() method which defers
> > allocating the internal array until and only if it is needed (or maybe not at all, and it's a
> > programming error to use the wrong factory if you really wish to replace/generate values.
> >
>
> There is a createEmpty method.  Does it suffice?
>
> --Joe
>

On second thought, I'm fairly sure the answer is "no" -- though the
doc is a little fuzzy.  If no, I think a more descriptive name for
createEmpty would result in less confusion.

Rather than create a new create method to enable you to use PA's
control structure without using PA's data, however, I would rather
look for ways to enhance PA in order for it to solve this problem
directly.

--Joe

From dl at cs.oswego.edu  Mon Jan 28 20:36:56 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 28 Jan 2008 20:36:56 -0500
Subject: [concurrency-interest] Rename compoundOp -> compositeOp
In-Reply-To: <200801282036.m0SKarsu019139@cs.oswego.edu>
References: <200801282036.m0SKarsu019139@cs.oswego.edu>
Message-ID: <479E8338.7060809@cs.oswego.edu>

David J. Biesack wrote:
> I did not see any feedback on this earlier suggestion. Perhaps it got lost in
> the "with"/fluent API discussion:
> 
> Rename CommonOps.compoundOp as CommonOps.compositeOp as per the well-known
> Composite design pattern.
> 

Thanks; Sorry not to mention that it still in the set of likely changes.
Rather than commit this or any other renamings or refactorings
as they come in  though, I think I'll give people a chance to keep sending
suggestions for a while (like maybe a week) off current versions
and then see how things settle.

-Doug

From dl at cs.oswego.edu  Mon Jan 28 20:47:02 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 28 Jan 2008 20:47:02 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <0JVD00GREFV9P7A0@fe-prod-02.oswego.edu>
References: <0JVD00GREFV9P7A0@fe-prod-02.oswego.edu>
Message-ID: <479E8596.5080309@cs.oswego.edu>

David J. Biesack wrote:
> 
> 
>  ParallelArray replaceWithMappedIndex(Ops.IntToObject op)
>  ParallelArray replaceWithMapping(Ops.Op op)
>  ParallelArray replaceWithMappedIndex(Ops.IntAndObjectToObject op)
> 
> which can be replaced with a single method:
> 
>    ParallelArray mapped(Ops.IntAndObjectToObject op)
> 

Yes. And it is internally somewhat messy to deal with 3 forms.
But my sense is that many if not most uses are not going to
rely much one the array-ness (i..e, indexing) of ParallelArray,
and it would cause the API to be even more awkward to use if
people has to create little IndexedMapper to Mapper adaptors all
the time. So we might as well accept all forms and cope on their
behalf.

(However, the lack of an indexed-procedure version of apply is
a bug; thanks for pointing it out! This will be added.)


> 
> (Sidebar: I don't see uses of many of the Procedure types actually used anywhere in jsr166y.forkjoin. Defined but not used anywhere are:
> 
> 
> Perhaps these unused interfaces are designated for an upcoming forkjoin ParallelMap.)
> 

Yes, exactly so. The current plan is for something fairly similar to
ParallelArray  -- an array is a "Map" where the keys are indices within
a range. The arbitrary forms of Maps will allow arbitrary keys.

-Doug

From dl at cs.oswego.edu  Tue Jan 29 07:21:52 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 29 Jan 2008 07:21:52 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <200801282015.m0SKFwuM017582@cs.oswego.edu>
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
Message-ID: <479F1A60.6010208@cs.oswego.edu>

David J. Biesack wrote:

> sometimes you want fork/join but you don't have an array to operate on; you
> just have a set of indices. 

This suggests creating something like the following.

class ParallelIntLoop {
     // Constructors, or maybe factories
     ParallelIntLoop(int firstIndex, int upperBound);
     ParallelIntLoop(int firstIndex, int upperBound, int increment);
     ParallelIntLoop(int firstIndex, int upperBound,
                     ForkJoinExecutor ex);
     ParallelIntLoop(int firstIndex, int upperBound, int increment,
                     ForkJoinExecutor ex);
     // Apply to each index
     void apply(IntProcedure p);
     // Map each index and reduce
     <T> T reduce(IntToObject<T> op, Reducer<T> r, T base);
     // Plus scalar specializations, like:
     long reduce(IntToLong op, LongReducer r, long base);
     // Plus basic layered forms, including
     <T> T max(IntToObject<T> op);
}

Plus a version using longs rather than ints.

What do you think?

-Doug


From tim at peierls.net  Tue Jan 29 09:20:38 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 29 Jan 2008 09:20:38 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479F1A60.6010208@cs.oswego.edu>
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
	<479F1A60.6010208@cs.oswego.edu>
Message-ID: <63b4e4050801290620k78e1bd78ga09d1105eced35e4@mail.gmail.com>

On Jan 29, 2008 7:21 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> David J. Biesack wrote:
> > sometimes you want fork/join but you don't have an array to operate on;
> you just have a set of indices.
>
> This suggests creating something like the following.
>
> class ParallelIntLoop { ... }
>

In the absence of ParallelIntLoop, and since in the matrix multiplication
case you *do* have an array to operate on, you can use this:

  ParallelDoubleArray
      .createUsingHandoff(b[0], pool) // b[0].length == # cols in result c
      .withIndexedFilter(new IntAndDoublePredicate()
  {
      public boolean op(int j, double ignored) {
          // use j to compute column j of c
          return false;
      }
  }).apply(new DoubleProcedure() {
      public void op(double ignored) {} // never called
  });

This ignores the values in b[0], just using the array for its length.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080129/828636ac/attachment.html 

From David.Biesack at sas.com  Tue Jan 29 09:50:04 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 29 Jan 2008 09:50:04 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <31f2a7bd0801281431u3ffd275fv2b6f4d5cd13a7b29@mail.gmail.com>
	(joe.bowbeer@gmail.com)
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
	<31f2a7bd0801281420m15baad0dv28d7ad39dc742159@mail.gmail.com>
	<31f2a7bd0801281431u3ffd275fv2b6f4d5cd13a7b29@mail.gmail.com>
Message-ID: <200801291450.m0TEo4TA011230@cs.oswego.edu>

> Date: Mon, 28 Jan 2008 14:31:27 -0800
> From: "Joe Bowbeer" <joe.bowbeer at gmail.com>
> Cc: concurrency-interest at cs.oswego.edu
> 
> On Jan 28, 2008 2:20 PM, Joe Bowbeer wrote:
> > On Jan 28, 2008 12:15 PM, David J. Biesack wrote:
> > >
> > > As can be seen with the Matrix Multiplication example, sometimes you want fork/join
> > > but you don't have an array to operate on; you just have a set of indices. In the example,
> > > I create a ParallelArray but don't use it; the data already exists in double[][] arrays.
> > > Hence the internal allocation of the Object[] array is wasted.
> > >
> > > [ ... ]
> > >
> > > I don't know if there is a solution other than adding a new create() method which defers
> > > allocating the internal array until and only if it is needed (or maybe not at all, and it's a
> > > programming error to use the wrong factory if you really wish to replace/generate values.
> > >
> >
> > There is a createEmpty method.  Does it suffice?
> >
> > --Joe
> >
> 
> On second thought, I'm fairly sure the answer is "no" -- though the
> doc is a little fuzzy.  If no, I think a more descriptive name for
> createEmpty would result in less confusion.

correct, createEmpty is insufficient because it still preallocates
the array space. I think the name "createEmpty" is OK, though; the array is
empty (as per isEmpty); I would suggest renaming the int param 

   int size

to 

   int initialCapacity, 

similar to java.util.ArrayList(int initialCapacity) and others.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From David.Biesack at sas.com  Tue Jan 29 10:14:33 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 29 Jan 2008 10:14:33 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479E8596.5080309@cs.oswego.edu> (message from Doug Lea on Mon,
	28 Jan 2008 20:47:02 -0500)
References: <0JVD00GREFV9P7A0@fe-prod-02.oswego.edu>
	<479E8596.5080309@cs.oswego.edu>
Message-ID: <200801291514.m0TFEXB0012910@cs.oswego.edu>

> Date: Mon, 28 Jan 2008 20:47:02 -0500
> From: Doug Lea <dl at cs.oswego.edu>
> CC: concurrency-interest at cs.oswego.edu
> 
> David J. Biesack wrote:
> > 
> >  ParallelArray replaceWithMappedIndex(Ops.IntToObject op)
> >  ParallelArray replaceWithMapping(Ops.Op op)
> >  ParallelArray replaceWithMappedIndex(Ops.IntAndObjectToObject op)
> > 
> > which can be replaced with a single method:
> > 
> >    ParallelArray mapped(Ops.IntAndObjectToObject op)

I originally suggested naming these map(...)/filter(...)/bound(...) and Doug offered mapped(...)/filtered(...)/bounded(...) to match the suggested class names.

However, I still prefer map(...) and filter(...), which are consistent with Lists in Scala.

The above "mapped(...)" should really be "update(...)"; map() does not alter the source PA; update() does

> -Doug

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From David.Biesack at sas.com  Tue Jan 29 10:23:27 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 29 Jan 2008 10:23:27 -0500 (EST)
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <479F1A60.6010208@cs.oswego.edu> (message from Doug Lea on Tue,
	29 Jan 2008 07:21:52 -0500)
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>
	<479F1A60.6010208@cs.oswego.edu>
Message-ID: <200801291523.m0TFNRMu013406@cs.oswego.edu>

> Date: Tue, 29 Jan 2008 07:21:52 -0500
> From: Doug Lea <dl at cs.oswego.edu>
> CC: concurrency-interest at cs.oswego.edu
> 
> David J. Biesack wrote:
> 
> > sometimes you want fork/join but you don't have an array to operate on; you
> > just have a set of indices. 
> 
> This suggests creating something like the following.
> 
> class ParallelIntLoop {
>      // Constructors, or maybe factories
>      ParallelIntLoop(int firstIndex, int upperBound);
>      ParallelIntLoop(int firstIndex, int upperBound, int increment);
>      ParallelIntLoop(int firstIndex, int upperBound,
>                      ForkJoinExecutor ex);
>      ParallelIntLoop(int firstIndex, int upperBound, int increment,
>                      ForkJoinExecutor ex);
>      // Apply to each index
>      void apply(IntProcedure p);
>      // Map each index and reduce
>      <T> T reduce(IntToObject<T> op, Reducer<T> r, T base);
>      // Plus scalar specializations, like:
>      long reduce(IntToLong op, LongReducer r, long base);
>      // Plus basic layered forms, including
>      <T> T max(IntToObject<T> op);
> }

> Plus a version using longs rather than ints.
> 
> What do you think?

I suggest the name ParallelIntRange -- that is, the class is not a loop, anymore than ParallelArray is.

However, once you add things like filter and map, perhaps this
becomes nothing more than ParallelIntSet (if indeed you have plans
for that), in which case we simply need the appropriate
ParallelIntSet factory method rather than a new ParallelIntLoop class.

class ParallelIntSet {

   ParallelIntSet createRange(int firstIndex, int upperBound, ForkJoinExecutor ex) 
   ParallelIntSet createRange(int firstIndex, int upperBound, int increment, ForkJoinExecutor ex) 
   ...

> -Doug

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From tim at peierls.net  Tue Jan 29 11:11:01 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 29 Jan 2008 11:11:01 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <200801291514.m0TFEXB0012910@cs.oswego.edu>
References: <0JVD00GREFV9P7A0@fe-prod-02.oswego.edu>
	<479E8596.5080309@cs.oswego.edu>
	<200801291514.m0TFEXB0012910@cs.oswego.edu>
Message-ID: <63b4e4050801290811j3d334f6cv7792a34f2ebe065c@mail.gmail.com>

On Jan 29, 2008 10:14 AM, David J. Biesack <David.Biesack at sas.com> wrote:

> I originally suggested naming these map(...)/filter(...)/bound(...) and
> Doug offered mapped(...)/filtered(...)/bounded(...) to match the suggested
> class names.
>

Neither bound nor bounded really work, they need a preposition to make
sense.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080129/674cd637/attachment.html 

From David.Biesack at sas.com  Tue Jan 29 13:51:23 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Tue, 29 Jan 2008 13:51:23 -0500 (EST)
Subject: [concurrency-interest] forkjoin matrix multiply
Message-ID: <200801291851.m0TIpNdh001088@cs.oswego.edu>

 
> I just posted a more detailed example to the wiki, comparing
> a sequential matrix multiplication algorithm, then the same
> algorithm rewritten to run concurrently with an ExecutorService
> and then rewritten using ForkJoin
> 
>    http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W40

Tim Peierls found a concurrency bug in my example that my unit tests missed.
I've corrected that (and my UTs!) and updated the page. Thanks, Tim.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


From u+jsr166 at lysator.liu.se  Tue Jan 29 14:34:48 2008
From: u+jsr166 at lysator.liu.se (Ulrik Svensson)
Date: Tue, 29 Jan 2008 20:34:48 +0100
Subject: [concurrency-interest] Analyzing deadlocks
Message-ID: <1201635288.6284.41.camel@139.211.216.81.static.lk.siw.siwnet.net>

Hi!

As some of you know, I'm developing a new open source tool named
JCarder for finding potential deadlocks in concurrent multi-threaded
Java programs. JCarder does this by instrumenting Java byte code
dynamically in runtime with ASM (i.e., it is not a tool for static
code analysis) and looking for cycles in the graph of acquired locks.
Cycles are visualized graphically with Graphviz.

I would love to get feedback from you on this list, and hear your
thoughts about how tools for analyzing concurrency issues in java
programs can be implemented?

Documentation, source and binaries are available here:
http://www.jcarder.org

/Ulrik Svensson, Sweden


From joe.bowbeer at gmail.com  Tue Jan 29 15:49:27 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 29 Jan 2008 12:49:27 -0800
Subject: [concurrency-interest] forkjoin matrix multiply
In-Reply-To: <200801291851.m0TIpNdh001088@cs.oswego.edu>
References: <200801291851.m0TIpNdh001088@cs.oswego.edu>
Message-ID: <31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>

On Jan 29, 2008 10:51 AM, David J. Biesack wrote:
>
> > I just posted a more detailed example to the wiki, comparing
> > a sequential matrix multiplication algorithm, then the same
> > algorithm rewritten to run concurrently with an ExecutorService
> > and then rewritten using ForkJoin
> >
> >    http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W40
>
> Tim Peierls found a concurrency bug in my example that my unit tests missed.
> I've corrected that (and my UTs!) and updated the page. Thanks, Tim.
>

I see what the PA example is doing now!  It took a moment to sink in...

While there is less code involved when using PA in this way, I'm
put-off by the use of PA in this way -- because I think of PA as an
object with data that operates on that data.

I think that providing a tool class with static methods would be a
better match for this kind of problem.  I'm referring to the
ParallelLoop and ParallelRange ideas.  Though in each case, I don't
understand why these would be objects and not simply tool classes?
The FJexecutor is the only state, right?  But what's the advantage in
creating an object simply to hold an FJexec?  Why not provide static
methods instead?

I'm intrigued by the matrix multiply example.  Should I assume this is
a typical domain for forkoin and friends?

If so, would it be beneficial for us to look inside jama.Matrix, with
the goal of enabling its implementors to parallelize its operations
(using forkjoin tools) in a straightforward manner?

  http://math.nist.gov/javanumerics/jama/doc/

A quick search found another test subject at jmathtools.sourceforge.net :

  org.math.array.DoubleArray
    org.math.array.LinearAlgebra

  http://jmathtools.sourceforge.net/doku.php

These are tool classes with methods that operate on double arrays.
(Variable argument lists... Wow.)

Should we strive to enable their implementors to parallize using forkjoin tools?

--Joe

From mthornton at optrak.co.uk  Tue Jan 29 16:28:22 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 29 Jan 2008 21:28:22 +0000
Subject: [concurrency-interest] forkjoin matrix multiply
In-Reply-To: <31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>
References: <200801291851.m0TIpNdh001088@cs.oswego.edu>
	<31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>
Message-ID: <479F9A76.1090200@optrak.co.uk>

Joe Bowbeer wrote:
> If so, would it be beneficial for us to look inside jama.Matrix, with
> the goal of enabling its implementors to parallelize its operations
> (using forkjoin tools) in a straightforward manner?
>   
I think high performance matrix multiply is usually done with the matrix 
divided into tiles or blocks, such that a couple of tiles fit neatly 
into the processor cache. This technique is applied for each cache level 
(blocks within blocks ...). While the forkJoin tools can help, I'm not 
sure how the parallel array mechanisms help here.

Mark Thornton


From tim at peierls.net  Tue Jan 29 16:43:36 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 29 Jan 2008 16:43:36 -0500
Subject: [concurrency-interest] forkjoin matrix multiply
In-Reply-To: <479F9A76.1090200@optrak.co.uk>
References: <200801291851.m0TIpNdh001088@cs.oswego.edu>
	<31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>
	<479F9A76.1090200@optrak.co.uk>
Message-ID: <63b4e4050801291343j53083358t637cdf42c1b18111@mail.gmail.com>

On Jan 29, 2008 4:28 PM, Mark Thornton <mthornton at optrak.co.uk> wrote:

> Joe Bowbeer wrote:
> > If so, would it be beneficial for us to look inside jama.Matrix, with
> > the goal of enabling its implementors to parallelize its operations
> > (using forkjoin tools) in a straightforward manner?
> >
> I think high performance matrix multiply is usually done with the matrix
> divided into tiles or blocks, such that a couple of tiles fit neatly
> into the processor cache. This technique is applied for each cache level
> (blocks within blocks ...). While the forkJoin tools can help, I'm not
> sure how the parallel array mechanisms help here.
>

Agreed. I think David's example is mainly about comparing a
ThreadPoolExecutor design to a ForkJoin design, not just in performance but
in succinctness. I don't think it was intended as a serious example of doing
high-performance matrix multiplication.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080129/55a70652/attachment.html 

From joe.bowbeer at gmail.com  Tue Jan 29 16:26:11 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 29 Jan 2008 13:26:11 -0800
Subject: [concurrency-interest] ParallelIntLoop (was: jsr166y.forkjoin
	API comments)
Message-ID: <31f2a7bd0801291326o76ced21cwc1442d54ff4520fd@mail.gmail.com>

On Jan 29, 2008 4:21 AM, Doug Lea wrote:
> David J. Biesack wrote:
>
> > sometimes you want fork/join but you don't have an array to operate on; you
> > just have a set of indices.
>
> This suggests creating something like the following.
>
> class ParallelIntLoop {
>      // Constructors, or maybe factories
>      ParallelIntLoop(int firstIndex, int upperBound);
>      ParallelIntLoop(int firstIndex, int upperBound, int increment);
>      ParallelIntLoop(int firstIndex, int upperBound,
>                      ForkJoinExecutor ex);
>      ParallelIntLoop(int firstIndex, int upperBound, int increment,
>                      ForkJoinExecutor ex);
>      // Apply to each index
>      void apply(IntProcedure p);
>      // Map each index and reduce
>      <T> T reduce(IntToObject<T> op, Reducer<T> r, T base);
>      // Plus scalar specializations, like:
>      long reduce(IntToLong op, LongReducer r, long base);
>      // Plus basic layered forms, including
>      <T> T max(IntToObject<T> op);
> }
>

Could a factory create the necessary forkjoin driver task instead?
Alternatively, provide an abstract forkjoin driver task that can be
customized for linear algebra over multidimensional arrays?

Currently there's no middle ground between the few raw ForkJoinTasks
and the freeze-dried PA classes, and I'm thinking there should be.

--Joe

From dl at cs.oswego.edu  Tue Jan 29 18:55:01 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 29 Jan 2008 18:55:01 -0500
Subject: [concurrency-interest] forkjoin matrix multiply
In-Reply-To: <31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>
References: <200801291851.m0TIpNdh001088@cs.oswego.edu>
	<31f2a7bd0801291249q76e6219qc856e94922ff3943@mail.gmail.com>
Message-ID: <479FBCD5.2000707@cs.oswego.edu>

Joe Bowbeer wrote:
> I'm intrigued by the matrix multiply example.  Should I assume this is
> a typical domain for forkoin and friends?
> 

Matrix algebra proper, as opposed to common operations on collections,
seems too far afield for likely JDK components. But it is worth
noting that forkjoin techniques are often the algorithms of
choice these days for matrix operations (multiply, inverse, etc)
on commodity MPs and multicores. My original dl.u.c version FJTask had
some demos of a few of these -- see
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/taskDemo/demos.html
Also, among other places, the chapter by Jack Dongarra in
"Beautiful code" contains brief comparisons of approaches for Gaussian
elimination. (http://www.oreilly.com/catalog/9780596510046/).

-Doug



From dl at cs.oswego.edu  Tue Jan 29 19:10:54 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 29 Jan 2008 19:10:54 -0500
Subject: [concurrency-interest] jsr166y.forkjoin API comments
In-Reply-To: <200801291523.m0TFNRMu013406@cs.oswego.edu>
References: <200801282015.m0SKFwuM017582@cs.oswego.edu>	<479F1A60.6010208@cs.oswego.edu>
	<200801291523.m0TFNRMu013406@cs.oswego.edu>
Message-ID: <479FC08E.80708@cs.oswego.edu>

David J. Biesack wrote:

> I suggest the name ParallelIntRange -- that is, the class is not a loop, anymore than ParallelArray is.
> 

Yes; thanks!

> However, once you add things like filter and map, perhaps this
> becomes nothing more than ParallelIntSet (if indeed you have plans
> for that), 

Not so sure. The nice thing about ParallelIntRange
is that it is very lightweight -- you can afford to make one on the fly just
to hold range/executor params for a single loop. A full ParallelIntSet
would need to, at least sometimes, create an internal bit set array
covering the whole range. And I'm not sure there are enough applications
for this to outweigh the advantages of the simple Range version.

-Doug


From David.Biesack at sas.com  Wed Jan 30 13:35:24 2008
From: David.Biesack at sas.com (David J. Biesack)
Date: Wed, 30 Jan 2008 13:35:24 -0500 (EST)
Subject: [concurrency-interest] forkjoin matrix multiply
In-Reply-To: <mailman.1.1201712401.15480.concurrency-interest@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <mailman.1.1201712401.15480.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <200801301835.m0UIZOAq020689@cs.oswego.edu>


> Date: Tue, 29 Jan 2008 16:43:36 -0500
> From: "Tim Peierls" <tim at peierls.net>
> Subject: Re: [concurrency-interest] forkjoin matrix multiply
> 
> On Jan 29, 2008 4:28 PM, Mark Thornton <mthornton at optrak.co.uk> wrote:
> 
> > Joe Bowbeer wrote:
> > > If so, would it be beneficial for us to look inside jama.Matrix, with
> > > the goal of enabling its implementors to parallelize its operations
> > > (using forkjoin tools) in a straightforward manner?
> > >
> > I think high performance matrix multiply is usually done with the matrix
> > divided into tiles or blocks, such that a couple of tiles fit neatly
> > into the processor cache. This technique is applied for each cache level
> > (blocks within blocks ...). While the forkJoin tools can help, I'm not
> > sure how the parallel array mechanisms help here.
> 
> Agreed. I think David's example is mainly about comparing a
> ThreadPoolExecutor design to a ForkJoin design, not just in performance but
> in succinctness. I don't think it was intended as a serious example of doing
> high-performance matrix multiplication.
> 
> --tim

Most definitely. The examples merely show how to take an existing sequential algorithm and apply ForkJoin to it.

Developing more realistic examples can help refine the API as well; Doug is already considering some additions/enhancements spawned by writing this example (IndexedProcedure; ParallelIntRange). Framework design requires lots of use cases; Matrix Multiply is simply a well understood case. 

Please try more examples and add them to the wiki at http://artisans-serverintellect-com.si-eioswww6.com/default.asp?W32

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513


