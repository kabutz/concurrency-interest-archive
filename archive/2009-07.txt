From alarmnummer at gmail.com  Wed Jul  1 00:37:06 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 1 Jul 2009 06:37:06 +0200
Subject: [concurrency-interest] adaptive spinning/biased lockingand
	java.util.concurrent.lock
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEHFICAA.davidcholmes@aapt.net.au>
References: <4A4A7AEE.90102@cs.oswego.edu>
	<NFBBKALFDCPFIDBNKAPCEEHFICAA.davidcholmes@aapt.net.au>
Message-ID: <1466c1d60906302137k544ceaben3fcbb2ab7e227c46@mail.gmail.com>

Thanks Doug and David for the clarifications.

On Wed, Jul 1, 2009 at 2:18 AM, David Holmes<davidcholmes at aapt.net.au> wrote:
> Can I also clarify something about biased-locking as I recently encountered
> some very mis-guided perceptions of what it is. :)
>
> Biased-locking exists to make un-needed synchronization as cheap as
> possible. It works on the assumption that objects are not shared, so locks
> are not contended and so aren't in fact needed. So when an object acquires a
> monitor lock it simply does a fast-lock by CAS'ing in the owning thread's Id
> into the object header. But the release of the lock is almost a no-op, it
> leaves the object "locked" by that original thread. Subsequent locks by that
> thread then don't need the (expensive) CAS. If another thread tries to lock
> the object we go through an expensive bias-revocation process and revert to
> using normal locking - the fact that contention occurred shows biasedlocking
> is not applicable to this object.
>
> As Doug says you don't tend to use j.u.c Locks in circumstances where
> biased-locking would be beneficial.
>
> Cheers,
> David Holmes
>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
>> Sent: Wednesday, 1 July 2009 6:52 AM
>> To: Peter Veentjer
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] adaptive spinning/biased lockingand
>> java.util.concurrent.lock
>>
>>
>>
>> Peter Veentjer wrote:
>> > Hi Guys,
>> >
>> > do modern jvm's also provide adaptive spinning and biased locking for
>> > the lock implementations (especially the reentrantlock) in the
>> > java.util.concurrent.locks package or is this only provided for the
>> > intrinsic lock?
>> >
>>
>> Only intrinsics. Biased locking does not work well
>> for locks that you expect to contend, which are among
>> the typical cases for using ReentrantLock. We might
>> someday want to automate adaptive spinning in
>> ReentrantLock and other AQS locks. However, this is
>> less pressing an issue than it is for in intrinsic locks,
>> since you can always use tryLock-based constructions
>> to increase spinning.
>>
>> -Doug
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jeremy.manson at gmail.com  Wed Jul  1 00:37:42 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Tue, 30 Jun 2009 21:37:42 -0700
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
Message-ID: <1631da7d0906302137i301748aay60d0a41743912b52@mail.gmail.com>

Sigh.  This is true, but they happen to be unnecessary on x86 +
hotspot.  It's an ongoing discussion.

Jeremy

On Tue, Jun 30, 2009 at 1:32 PM, Peter Veentjer<alarmnummer at gmail.com> wrote:
> On Tue, Jun 30, 2009 at 10:23 PM, Jeremy Manson<jeremy.manson at gmail.com> wrote:
>> On Tue, Jun 30, 2009 at 5:25 AM, Peter Veentjer<alarmnummer at gmail.com> wrote:
>>>> It seems to me that immutability for the sake of propagating constructor
>>>> changes to main memory
>>>> is something of a misnomer - this is more about using the 'final' keyword as
>>>> a coarse grained hook into the
>>>> java memory model. Maybe if we had more direct access to that memory model
>>>> then we could ensure
>>>> that mutable objects could safely be constructed as well, for example:
>>>>
>>>> public class MyMutableClass {
>>>> ? private String myNonFinal;
>>>>
>>>> ? public MyClass() {
>>>> ? ? ?this.myNonFinal = "hello world";
>>>> ? ? ?MemoryModel.flush(); // flush-commit similar to other cache
>>>> technologies
>>>> ? }
>>>> }
>>>
>>> I don't see a happens before relation between the write of the
>>> myNonFinal example and the usage. So I don't think this example is
>>> going to work.
>>
>> I think he was trying to express that the implicit relationship
>> between the write of a final and its reads is enforced by this API.
>> Something like this may be in the Fences API in Java 7.
>>
>> Jeremy
>
> Hi Jeremy,
>
> but you still need a store and load fence to guarantee a happens
> before relation between the write and the read *in nitpicking mode*.
>
> PS: Do you have a reference to the other concurrency features that are
> going to be added (apart from the fences and the fork/join
> functionality) to Java 7?
>


From gkorland at gmail.com  Wed Jul  1 00:52:31 2009
From: gkorland at gmail.com (Guy Korland)
Date: Wed, 1 Jul 2009 07:52:31 +0300
Subject: [concurrency-interest] DeuceSTM 1.0 is ready
Message-ID: <79be5fa30906302152u438c42b7m86d33da68c174fb0@mail.gmail.com>

Hi all,

I just wanted to inform you that DeuceSTM 1.0 was released.
DeuceSTM is a full non-intrusive Java transactional memory.
The API is as simple as adding @Atomic annotation to the targeted method.

For more detail see: http://www.deucestm.org

-- 
Guy Korland
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090701/69c16458/attachment.html>

From ashpublic at mac.com  Wed Jul  1 07:00:59 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Wed, 01 Jul 2009 12:00:59 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <4A4A79AE.7020603@cs.oswego.edu>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
Message-ID: <C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>

Just looked at the Fences API and this is exactly what I was trying to  
allude to.

In fact I would personally prefer to see the explicit use of  
Fences.preStoreFence()
instead of relying on memory model guarantees through the use of  
final. It would
be all too easy for a developer to come along and mistakenly remove  
the multi-purpose
final keyword without appearing to break the code.

Am I right in thinking most jvms would implement this by writing to  
main memory (writes) and
evicting entries from local memory (reads)? Just wondering about any  
performance costs.

So if one were to use both a final field modifier as well as a fence,  
would the jvm be
clever enough not pay the for the happens-before guarantee twice over?

On 30 Jun 2009, at 21:46, Doug Lea wrote:

> Peter Veentjer wrote:
>
>> PS: Do you have a reference to the other concurrency features that  
>> are
>> going to be added (apart from the fences and the fork/join
>> functionality) to Java 7?
>
> Definitely planned classes are in package jsr166y --
> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
>
> Plus Fences, which can't be previewed in jsr166y since
> it relies on JVM support. See
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>
> Plus possibly some sort of customized hash map.
> The main reason for delay on that is algorithmic:
> Efficient support for features like eviction and
> memoization across a large enough range of
> policies to be worth supporting in concurrent maps is not a
> fully solved problem. I want to make sure that
> we offer only that range of them for which we are
> very sure we can support well, but without closing
> the door to future algorithmic overhauls.
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From mads at renxo.com  Thu Jul  2 11:21:06 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Thu, 02 Jul 2009 12:21:06 -0300
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4A2A78.7050705@cs.oswego.edu>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
Message-ID: <4A4CD062.9080206@renxo.com>

Hi Doug,

I recently filed the following bug at Sun's bug database:

http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821

You might want to look into it since this class is used by many 
concurrent classes and you're listed as one of its authors.

I am well aware of the perils of mutable objects, however PriorityQueue 
should account for mutability since priorities might change for a queued 
element at runtime, and it is not always practical to remove and discard 
the previous element and create a new object. This does not only affect 
mutable objects but also those whose priority is somehow based on 
System.currentTimeMillis() or other external data, which is what caused 
us to find this subtle bug.

Best,

Ing. Manuel Dominguez Sarmiento
Director General
Renxo S.A.
e-mail:	mads at renxo.com
Phone:	+54 11 4719 6806, ext. 104



From bronee at gmail.com  Thu Jul  2 11:48:28 2009
From: bronee at gmail.com (Brian S O'Neill)
Date: Thu, 02 Jul 2009 08:48:28 -0700
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CD062.9080206@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com>
Message-ID: <4A4CD6CC.6000606@gmail.com>

I'm not Doug, but personally I would fix the bug by documenting the 
behavior of priority queues. It doesn't make sense to support your use 
case, because it would require that every poll from the queue resort the 
entire heap. This defeats the purpose of using such a structure.

If you have tasks with variable priority, you should use a binary search 
tree instead. Then you can quickly remove and re-insert tasks when its 
priority changes. Call pollFirstEntry to remove the task with highest 
priority.

Manuel Dominguez Sarmiento wrote:
> Hi Doug,
>
> I recently filed the following bug at Sun's bug database:
>
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821
>
> You might want to look into it since this class is used by many 
> concurrent classes and you're listed as one of its authors.
>
> I am well aware of the perils of mutable objects, however 
> PriorityQueue should account for mutability since priorities might 
> change for a queued element at runtime, and it is not always practical 
> to remove and discard the previous element and create a new object. 
> This does not only affect mutable objects but also those whose 
> priority is somehow based on System.currentTimeMillis() or other 
> external data, which is what caused us to find this subtle bug.
>
> Best,
>
> Ing. Manuel Dominguez Sarmiento
> Director General
> Renxo S.A.
> e-mail:    mads at renxo.com
> Phone:    +54 11 4719 6806, ext. 104
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jim.andreou at gmail.com  Thu Jul  2 11:50:23 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Thu, 2 Jul 2009 18:50:23 +0300
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CD062.9080206@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com>
Message-ID: <7d7138c10907020850v680e489eo9e5ba99cac5394a3@mail.gmail.com>

How is this different than mutating keys of a HashMap? There is no way a
structure could find out just when an arbitrary memory update causes side
effects to some of its elements.
Java's PriorityQueue does have some shortcomings (it's very slow to change
an element's priority - i.e. through remove and re-add), but this is most
certainly not one of them.

Regards,
Dimitris

2009/7/2 Manuel Dominguez Sarmiento <mads at renxo.com>

> Hi Doug,
>
> I recently filed the following bug at Sun's bug database:
>
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821
>
> You might want to look into it since this class is used by many concurrent
> classes and you're listed as one of its authors.
>
> I am well aware of the perils of mutable objects, however PriorityQueue
> should account for mutability since priorities might change for a queued
> element at runtime, and it is not always practical to remove and discard the
> previous element and create a new object. This does not only affect mutable
> objects but also those whose priority is somehow based on
> System.currentTimeMillis() or other external data, which is what caused us
> to find this subtle bug.
>
> Best,
>
> Ing. Manuel Dominguez Sarmiento
> Director General
> Renxo S.A.
> e-mail: mads at renxo.com
> Phone:  +54 11 4719 6806, ext. 104
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090702/773d2ceb/attachment.html>

From mthornton at optrak.co.uk  Thu Jul  2 11:50:41 2009
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Thu, 02 Jul 2009 16:50:41 +0100
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CD062.9080206@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com>
Message-ID: <4A4CD751.9000008@optrak.co.uk>

Manuel Dominguez Sarmiento wrote:
> Hi Doug,
>
> I recently filed the following bug at Sun's bug database:
>
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821
>
> You might want to look into it since this class is used by many 
> concurrent classes and you're listed as one of its authors. 
That is not a bug --- the behaviour is as expected. TreeSet likewise 
does not work if the ordering of elements changes after insertion. Nor 
do any of the Map's work if the keys are mutable. Priority queues which 
allow the priority to change have an extra method to perform this 
mutation --- i.e. you have to explicitly inform the queue of each 
element whose priority is changing.

Regards,
Mark Thornton


From holger.hoffstaette at googlemail.com  Thu Jul  2 11:54:11 2009
From: holger.hoffstaette at googlemail.com (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Thu, 02 Jul 2009 17:54:11 +0200
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CD062.9080206@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com>
Message-ID: <4A4CD823.50303@googlemail.com>

Manuel Dominguez Sarmiento wrote:
> I recently filed the following bug at Sun's bug database:
> 
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821

The behaviour is neither subtle nor a bug, and IMHO cannot be changed
because the problem you're trying to fix is inherently unsolvable. Taking
your suggestion to its logical conclusion would mean that an arbitrary
number of mutable objects may never be processed because their aggregate
rate of state (priority) change could be so high that the queue would end
up never dequeing anything, only re-sorting.
Apart from this academic showstopper there's the small issue of state
changes during reordering or comparison. Good luck handling that correctly :)

-h

From mads at renxo.com  Thu Jul  2 12:14:20 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Thu, 02 Jul 2009 13:14:20 -0300
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CD751.9000008@optrak.co.uk>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
Message-ID: <4A4CDCDC.4000308@renxo.com>

I understand this and in fact I was expecting that kind of response from 
Sun. However since they accepted the bug I was lead to believe that it 
might actually be a bug.

However, notice that poll() appears to re-sort the queue every time it 
is invoked. The thing is that it returns the head of the queue before 
re-sorting. Perhaps the re-sorting could be performed before returning 
the head of the queue since it's going to be a performance hit anyway 
(siftDown() is invoked by poll() after obtaining the head of the queue, 
and it is this method that maintains the heap invariant).

Please review the bug report at 
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821 - see how the 
expected result is pretty close to the actual result, except for the 
first poll(). When I tested this I expected mutability to not be taken 
into account at all (as per HashMap, TreeSet, etc.) however the queue is 
in fact re-sorted, except for the head which is always returned before 
re-sorting.

I believe that at least this behaviour should be documented. I'm not for 
implementing nonsense features, however this use case almost seems to 
work but not quite, which is somewhat confusing and it's what prompted 
me to report the "bug" (?) in the first place.

Ing. Manuel Dominguez Sarmiento
Director General
Renxo S.A.
e-mail:	mads at renxo.com
Phone:	+54 11 4719 6806, ext. 104



Mark Thornton wrote:
> Manuel Dominguez Sarmiento wrote:
>> Hi Doug,
>>
>> I recently filed the following bug at Sun's bug database:
>>
>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821
>>
>> You might want to look into it since this class is used by many 
>> concurrent classes and you're listed as one of its authors. 
> That is not a bug --- the behaviour is as expected. TreeSet likewise 
> does not work if the ordering of elements changes after insertion. Nor 
> do any of the Map's work if the keys are mutable. Priority queues 
> which allow the priority to change have an extra method to perform 
> this mutation --- i.e. you have to explicitly inform the queue of each 
> element whose priority is changing.
>
> Regards,
> Mark Thornton
>


From takeshi10 at gmail.com  Thu Jul  2 12:38:09 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Thu, 2 Jul 2009 13:38:09 -0300
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CDCDC.4000308@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
	<4A4CDCDC.4000308@renxo.com>
Message-ID: <7288749d0907020938g6b0f8fa2n671f327f51a86274@mail.gmail.com>

the siftdown and siftup operations don't resort the entire heap, they
just fix the heap invariant

see http://en.wikipedia.org/wiki/Heapsort

On Thu, Jul 2, 2009 at 1:14 PM, Manuel Dominguez
Sarmiento<mads at renxo.com> wrote:
> I understand this and in fact I was expecting that kind of response from
> Sun. However since they accepted the bug I was lead to believe that it might
> actually be a bug.
>
> However, notice that poll() appears to re-sort the queue every time it is
> invoked. The thing is that it returns the head of the queue before
> re-sorting. Perhaps the re-sorting could be performed before returning the
> head of the queue since it's going to be a performance hit anyway
> (siftDown() is invoked by poll() after obtaining the head of the queue, and
> it is this method that maintains the heap invariant).
>
> Please review the bug report at
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821 - see how the
> expected result is pretty close to the actual result, except for the first
> poll(). When I tested this I expected mutability to not be taken into
> account at all (as per HashMap, TreeSet, etc.) however the queue is in fact
> re-sorted, except for the head which is always returned before re-sorting.
>
> I believe that at least this behaviour should be documented. I'm not for
> implementing nonsense features, however this use case almost seems to work
> but not quite, which is somewhat confusing and it's what prompted me to
> report the "bug" (?) in the first place.
>
> Ing. Manuel Dominguez Sarmiento
> Director General
> Renxo S.A.
> e-mail: mads at renxo.com
> Phone: ?+54 11 4719 6806, ext. 104
>
>
>
> Mark Thornton wrote:
>>
>> Manuel Dominguez Sarmiento wrote:
>>>
>>> Hi Doug,
>>>
>>> I recently filed the following bug at Sun's bug database:
>>>
>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6856821
>>>
>>> You might want to look into it since this class is used by many
>>> concurrent classes and you're listed as one of its authors.
>>
>> That is not a bug --- the behaviour is as expected. TreeSet likewise does
>> not work if the ordering of elements changes after insertion. Nor do any of
>> the Map's work if the keys are mutable. Priority queues which allow the
>> priority to change have an extra method to perform this mutation --- i.e.
>> you have to explicitly inform the queue of each element whose priority is
>> changing.
>>
>> Regards,
>> Mark Thornton
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
http://mapsdev.blogspot.com/
Marcelo Takeshi Fukushima


From martinrb at google.com  Thu Jul  2 12:57:46 2009
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 2 Jul 2009 09:57:46 -0700
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CDCDC.4000308@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
	<4A4CDCDC.4000308@renxo.com>
Message-ID: <1ccfd1c10907020957o72a72eb9w55b1847ffbfd72c8@mail.gmail.com>

On Thu, Jul 2, 2009 at 09:14, Manuel Dominguez Sarmiento <mads at renxo.com>wrote:

> I understand this and in fact I was expecting that kind of response from
> Sun. However since they accepted the bug I was lead to believe that it might
> actually be a bug.
>

The bug is in Dispatched state,
which means it's still looking for a Sun engineer to
acknowledge it as a genuine bug,
much less commit to fixing it.

I vaguely recall similar bugs being closed years ago.

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090702/0c088ad5/attachment.html>

From dl at cs.oswego.edu  Sat Jul  4 02:38:46 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 4 Jul 2009 02:38:46 -0400 (EDT)
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <4A4CDCDC.4000308@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
	<4A4CDCDC.4000308@renxo.com>
Message-ID: <58193.89.96.170.50.1246689526.squirrel@altair.cs.oswego.edu>

> I understand this and in fact I was expecting that kind of response from
> Sun. However since they accepted the bug I was lead to believe that it
> might actually be a bug.


As Martin mentioned, this doesn't mean much.

And as others mentioned, this is Not A Bug. But it is
implicitly an RFE. We don't provide a class that permits
re-weightings. Part of the reason is algorithmic. In
all the usual priority queue algorithms, you can't
re-weight unless you can locate, which you don't want
to have to do via sequential search. The usual way out
of this is to embed inverse indices etc inside user
elements, which we also cannot do. However, it would be
possible to create separate indexing structure (maybe
a hash table of some sort) for those usages that can
tolerate extra time/space overhead for sake of extra
functionality. This might be worth exploring someday.

-Doug



From karnok at sztaki.hu  Sat Jul  4 05:00:27 2009
From: karnok at sztaki.hu (karnok at sztaki.hu)
Date: Sat, 04 Jul 2009 11:00:27 +0200
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <58193.89.96.170.50.1246689526.squirrel@altair.cs.oswego.edu>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
	<4A4CDCDC.4000308@renxo.com>
	<58193.89.96.170.50.1246689526.squirrel@altair.cs.oswego.edu>
Message-ID: <20090704110027.19286k6t5kyv2ngo@webmail.sztaki.hu>

Hi,

I think, the resubmission of the prioritized task is a solution to the  
problem, for now. You need to combine the reliable messaging concept  
with the priority queue (and immutability).
Have your object include an 'unique' task id. Keep a reference to the  
task in a separate thread, which should compute the new priorities  
periodically, and resubmit the task *with the same UID* to the  
priority queue. If the original task is already at the head, then the  
poller will get it now and perform the operation. The poller will then  
discard any further same UIDs and let the re-prioritizer thread also  
ignore this task further on.

Quoting Doug Lea <dl at cs.oswego.edu>:

>> I understand this and in fact I was expecting that kind of response from
>> Sun. However since they accepted the bug I was lead to believe that it
>> might actually be a bug.
>
>
> As Martin mentioned, this doesn't mean much.
>
> And as others mentioned, this is Not A Bug. But it is
> implicitly an RFE. We don't provide a class that permits
> re-weightings. Part of the reason is algorithmic. In
> all the usual priority queue algorithms, you can't
> re-weight unless you can locate, which you don't want
> to have to do via sequential search. The usual way out
> of this is to embed inverse indices etc inside user
> elements, which we also cannot do. However, it would be
> possible to create separate indexing structure (maybe
> a hash table of some sort) for those usages that can
> tolerate extra time/space overhead for sake of extra
> functionality. This might be worth exploring someday.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.


From mads at renxo.com  Sat Jul  4 08:22:32 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Sat, 04 Jul 2009 09:22:32 -0300
Subject: [concurrency-interest] PriorityQueue bug with mutable object
In-Reply-To: <58193.89.96.170.50.1246689526.squirrel@altair.cs.oswego.edu>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4CD062.9080206@renxo.com> <4A4CD751.9000008@optrak.co.uk>
	<4A4CDCDC.4000308@renxo.com>
	<58193.89.96.170.50.1246689526.squirrel@altair.cs.oswego.edu>
Message-ID: <4A4F4988.6060508@renxo.com>

Thanks for taking the time to look through this.

- Manuel

Doug Lea wrote:
>> I understand this and in fact I was expecting that kind of response from
>> Sun. However since they accepted the bug I was lead to believe that it
>> might actually be a bug.
>>     
>
>
> As Martin mentioned, this doesn't mean much.
>
> And as others mentioned, this is Not A Bug. But it is
> implicitly an RFE. We don't provide a class that permits
> re-weightings. Part of the reason is algorithmic. In
> all the usual priority queue algorithms, you can't
> re-weight unless you can locate, which you don't want
> to have to do via sequential search. The usual way out
> of this is to embed inverse indices etc inside user
> elements, which we also cannot do. However, it would be
> possible to create separate indexing structure (maybe
> a hash table of some sort) for those usages that can
> tolerate extra time/space overhead for sake of extra
> functionality. This might be worth exploring someday.
>
> -Doug
>
>
>   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090704/e46bf219/attachment.html>

From alexdmiller at yahoo.com  Mon Jul  6 15:13:40 2009
From: alexdmiller at yahoo.com (Alex Miller)
Date: Mon, 6 Jul 2009 12:13:40 -0700 (PDT)
Subject: [concurrency-interest] Java concurrency refcard
In-Reply-To: <mailman.1.1246464001.17134.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1246464001.17134.concurrency-interest@cs.oswego.edu>
Message-ID: <37360.79684.qm@web32205.mail.mud.yahoo.com>


Hey all, I wrote a concurrency refcard for dzone in case anyone here wants to tell me what's wrong on it. :)  

http://refcardz.dzone.com/refcardz/core-java-concurrency

Seriously, I would be interested to know if I screwed something up so please drop me a line either publicly or privately.

Thanks,
Alex

From forax at univ-mlv.fr  Mon Jul  6 20:27:23 2009
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 07 Jul 2009 02:27:23 +0200
Subject: [concurrency-interest] Java concurrency refcard
In-Reply-To: <37360.79684.qm@web32205.mail.mud.yahoo.com>
References: <mailman.1.1246464001.17134.concurrency-interest@cs.oswego.edu>
	<37360.79684.qm@web32205.mail.mud.yahoo.com>
Message-ID: <4A52966B.9000905@univ-mlv.fr>

Alex Miller a ?crit :
> Hey all, I wrote a concurrency refcard for dzone in case anyone here wants to tell me what's wrong on it. :)  
>
> http://refcardz.dzone.com/refcardz/core-java-concurrency
>
> Seriously, I would be interested to know if I screwed something up so please drop me a line either publicly or privately.
>
> Thanks,
> Alex
>   

Hi Alex,
I am not sure a refcard on concurrency is a good idea,
you could split it in two: concurrency low level/
concurrency data structure
I think you can improve, in any order:

- ''might theorically see partial update". In fact, it can be easy to 
observe
  (at least on a 32bits bi-Xeon).
- Differences between notify/notifyAll are not crystal clear.
- how to properly catch InterruptedException,
  interrupt()/interrupted/isInterrupted().
- synchronized is re-entrant
- fainess of Lock
- atomic compareAndSwap is missing.
- concurrent list/set iterator.
- Future.cancel and interrupt()/InteruptedException
- executors shutdown /shutdownNow
- callable must not synchronize/lock
  => deadlock with executor
- scheduled thread pool fixedRate/fixedDelay.
- executor use a BlockingQueue if no worker thread available
- ThreadLocal/InheritedThreadLocal
- I think you can remove all references to Queue
  which is not a concurrent data structure
  and keep focus on BlockingQueue.

cheers,
R?mi

From mthornton at optrak.co.uk  Tue Jul  7 03:31:03 2009
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Tue, 07 Jul 2009 08:31:03 +0100
Subject: [concurrency-interest] Java concurrency refcard
In-Reply-To: <4A52966B.9000905@univ-mlv.fr>
References: <mailman.1.1246464001.17134.concurrency-interest@cs.oswego.edu>	<37360.79684.qm@web32205.mail.mud.yahoo.com>
	<4A52966B.9000905@univ-mlv.fr>
Message-ID: <4A52F9B7.5090903@optrak.co.uk>

R?mi Forax wrote:
> - ''might theorically see partial update". In fact, it can be easy to 
> observe
>  (at least on a 32bits bi-Xeon).
The last time I tested this it took a few milliseconds to observe a 
partial update on a dual core and about 20 minutes on a single core.

Mark Thornton


From hoppithek at uni-muenster.de  Tue Jul  7 14:04:07 2009
From: hoppithek at uni-muenster.de (Armin Hopp)
Date: Tue, 07 Jul 2009 20:04:07 +0200
Subject: [concurrency-interest] Building extra166y with ant
Message-ID: <4A538E17.9020204@uni-muenster.de>

Hi,

I tried buildung the extra166y package using ant and the supplied
build.xml from the lastest cvs (06-07-2009). Anyways it didn't work
until I edited the build.xml's extra166ycompile target. I added
jsr166ycompile to the depends and also inserted
classpath="${build.dir}/jsr166y/" parameter to the javac tag. With these
changes everythings compiles fine. Am I missing something for me to have
to make these changes? Do all of you keep the jsr166y compile path in
you path environment variable?

Just wondering.

cheers,
Armin

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 365 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090707/be269782/attachment.bin>

From joe.bowbeer at gmail.com  Tue Jul  7 14:34:25 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 7 Jul 2009 11:34:25 -0700
Subject: [concurrency-interest] Java concurrency refcard
In-Reply-To: <37360.79684.qm@web32205.mail.mud.yahoo.com>
References: <mailman.1.1246464001.17134.concurrency-interest@cs.oswego.edu>
	<37360.79684.qm@web32205.mail.mud.yahoo.com>
Message-ID: <31f2a7bd0907071134l46e16b0bs5ef85bb2268b783f@mail.gmail.com>

Alex,

Thanks for doing this.

I saw a few things in a quick glance:

1. Can you point out the importance of documentation in one of the hot
tips?  The j.u.c. tools go a long way toward encapsulating useful
mechanisms, and the annotations can be put to good use here as well (see
below), but as a rule, concurrent code usually needs additional explanation.

2. Can you cover the annotations?

3. Please warn against the use of wait-notify.  It's almost always better to
use one of the j.u.c. tools than to write a wait-notify.  In my experience,
wait-notify instances are a reliable source of bugs.

4. Your canonical usage example for wait-notify is completely ignoring the
interrupt!

Joe

On Mon, Jul 6, 2009 at 12:13 PM, Alex Miller wrote:

>
> Hey all, I wrote a concurrency refcard for dzone in case anyone here wants
> to tell me what's wrong on it. :)
>
> http://refcardz.dzone.com/refcardz/core-java-concurrency
>
> Seriously, I would be interested to know if I screwed something up so
> please drop me a line either publicly or privately.
>
> Thanks,
> Alex
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090707/537c6f23/attachment.html>

From ariel at weisberg.ws  Tue Jul  7 18:30:49 2009
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Tue, 07 Jul 2009 18:30:49 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
Message-ID: <1247005849.13302.1323974975@webmail.messagingengine.com>

Hi all,

I did a search on LinkedBlockingDeque and didn't find anything similar
to what I am seeing. Attached is the stack trace from an application
that is deadlocked with three threads waiting for 0x00002aaab3e91080
(threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
Selector"). The execution sites are attempting to offer results to the
deque and the network thread is trying to poll for them using the
non-blocking version of poll. I am seeing the network thread never
return from poll (straight poll()). Do my eyes deceive me?

Thanks,

Ariel Weisberg
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: stack_trace.txt
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090707/296c10a7/attachment.txt>

From davidcholmes at aapt.net.au  Tue Jul  7 19:14:19 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 8 Jul 2009 09:14:19 +1000
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1247005849.13302.1323974975@webmail.messagingengine.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEIDICAA.davidcholmes@aapt.net.au>


Ariel,

The poll()ing thread is blocked waiting for the internal lock, but there's
no indication of any thread owning that lock. You're using an OpenJDK 6
build ... can you try JDK7 ?

I don't recall anything similar to this, but I don't know what version that
OpenJDK6 build relates to.

Make sure you haven't missed any exceptions occurring in other threads.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ariel
> Weisberg
> Sent: Wednesday, 8 July 2009 8:31 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
>
>
> Hi all,
>
> I did a search on LinkedBlockingDeque and didn't find anything similar
> to what I am seeing. Attached is the stack trace from an application
> that is deadlocked with three threads waiting for 0x00002aaab3e91080
> (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
> Selector"). The execution sites are attempting to offer results to the
> deque and the network thread is trying to poll for them using the
> non-blocking version of poll. I am seeing the network thread never
> return from poll (straight poll()). Do my eyes deceive me?
>
> Thanks,
>
> Ariel Weisberg
>


From martinrb at google.com  Tue Jul  7 20:05:44 2009
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 7 Jul 2009 17:05:44 -0700
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1247005849.13302.1323974975@webmail.messagingengine.com>
References: <1247005849.13302.1323974975@webmail.messagingengine.com>
Message-ID: <1ccfd1c10907071705x44599761lb972be4b470628b@mail.gmail.com>

[+core-libs-dev]

Doug Lea and I are (slowly) working on a new version of LinkedBlockingDeque.
I was not aware of a deadlock but can vaguely imagine how it might happen.
A small reproducible test case from you would be useful.

Unfinished work in progress can be found here:
http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQueue/

Martin

On Tue, Jul 7, 2009 at 15:30, Ariel Weisberg <ariel at weisberg.ws> wrote:

> Hi all,
>
> I did a search on LinkedBlockingDeque and didn't find anything similar
> to what I am seeing. Attached is the stack trace from an application
> that is deadlocked with three threads waiting for 0x00002aaab3e91080
> (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
> Selector"). The execution sites are attempting to offer results to the
> deque and the network thread is trying to poll for them using the
> non-blocking version of poll. I am seeing the network thread never
> return from poll (straight poll()). Do my eyes deceive me?
>
> Thanks,
>
> Ariel Weisberg
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090707/5854e79b/attachment.html>

From jeremy.manson at gmail.com  Wed Jul  8 02:13:58 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Tue, 7 Jul 2009 23:13:58 -0700
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
Message-ID: <1631da7d0907072313y34b9f4ebha625823d5723a0f2@mail.gmail.com>

Most VMs would implement this by executing the appropriate fence
instruction (as you describe) and preventing compiler optimizations
that moved accesses around the Fence.  A VM might be clever enough to
combine the fences for this and final fields, but it might not.  I
doubt such an optimization would happen in any timely manner, but who
knows?

I would argue that this method is definitely *not* preferable to use
of the final keyword.  "final" implies something about the semantics
of field access on both the reader and writer side, and the fence
implies something platform-dependent about the store you are putting
it before.  On the off chance that there is ever a platform that
requires the reader to do something to guarantee coherence, all of the
code written using this Fences API will break.

(None of the hardware platforms that Java currently really supports
(i.e., SPARC and x86, plus, to a lesser extent, PPC and ia64) require
reader-side coherence guarantees.  There is always the possibility
that someone will come up with a compiler optimization that breaks
reader-side dependencies in a way that would require additional
guarantees for reading final fields, although such optimizations would
probably be highly suspect.  Anything that used a distributed shared
memory style of programming (or whatever they are calling it these
days) would also possibly break.)

In my opinion, such as it is, replacing something with well-defined
semantics with something that happens to work on the platforms you
know about is something that is highly suspect as a general principle,
and should only be used for very, very particular use cases.

Jeremy

On Wed, Jul 1, 2009 at 4:00 AM, Ashley Williams<ashpublic at mac.com> wrote:
> Just looked at the Fences API and this is exactly what I was trying to
> allude to.
>
> In fact I would personally prefer to see the explicit use of
> Fences.preStoreFence()
> instead of relying on memory model guarantees through the use of final. It
> would
> be all too easy for a developer to come along and mistakenly remove the
> multi-purpose
> final keyword without appearing to break the code.
>
> Am I right in thinking most jvms would implement this by writing to main
> memory (writes) and
> evicting entries from local memory (reads)? Just wondering about any
> performance costs.
>
> So if one were to use both a final field modifier as well as a fence, would
> the jvm be
> clever enough not pay the for the happens-before guarantee twice over?
>
> On 30 Jun 2009, at 21:46, Doug Lea wrote:
>
>> Peter Veentjer wrote:
>>
>>> PS: Do you have a reference to the other concurrency features that are
>>> going to be added (apart from the fences and the fork/join
>>> functionality) to Java 7?
>>
>> Definitely planned classes are in package jsr166y --
>> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
>>
>> Plus Fences, which can't be previewed in jsr166y since
>> it relies on JVM support. See
>>
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>>
>> Plus possibly some sort of customized hash map.
>> The main reason for delay on that is algorithmic:
>> Efficient support for features like eviction and
>> memoization across a large enough range of
>> policies to be worth supporting in concurrent maps is not a
>> fully solved problem. I want to make sure that
>> we offer only that range of them for which we are
>> very sure we can support well, but without closing
>> the door to future algorithmic overhauls.
>>
>> -Doug
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From ashpublic at mac.com  Wed Jul  8 06:14:02 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Wed, 08 Jul 2009 11:14:02 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1631da7d0907072313y34b9f4ebha625823d5723a0f2@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
	<1631da7d0907072313y34b9f4ebha625823d5723a0f2@mail.gmail.com>
Message-ID: <0C9EFA6F-7251-4164-A476-18C49D95EA3B@mac.com>

So I think you are saying that from your knowledge of vm architectures
on various platforms it may not be possible to eliminate redundancy  
under
the covers if you use an explicit fence through the Fences API and an
implicit fence through the final field modifier.

Lets assume then that an explicit fence is used instead of final fields.
I previously understood that the Fences API is supposed to
be platform independent at least w.r.t happens before behavior so that
future re-ordering compiler optimizations would have no adverse effect.
Are you saying that's not true and that there are current and possible
future platforms where the Fences API won't work?

********

As a final thought, I've been developing for many years and whilst I've
always had a fairly sound knowledge of thread fundamentals, I only
came to realize that most of my thread-safe code has only worked through
semi-luck after reading JCiP. In fact I've pinned it down to the  
happens-before rules
that I was inadvertently relying on: "in the same thread",  
"synchronized keyword"
and "transitive". I would further extend this to the majority of  
others that
I have worked with. I dread to think of all the lazy instantiation  
data race
bugs that we must all have produced over the years.

So the reason I'm banging this drum is that I'm starting to think it's
a little dangerous to rely on implicit behavior to control the memory
model. Explicit API calls say "don't touch unless you know what you
are doing" a little louder. However if you say this isn't possible then
I'll add this to my ever growing list of things to think about.

Cheers
- Ashley

On 8 Jul 2009, at 07:13, Jeremy Manson wrote:

> Most VMs would implement this by executing the appropriate fence
> instruction (as you describe) and preventing compiler optimizations
> that moved accesses around the Fence.  A VM might be clever enough to
> combine the fences for this and final fields, but it might not.  I
> doubt such an optimization would happen in any timely manner, but who
> knows?
>
> I would argue that this method is definitely *not* preferable to use
> of the final keyword.  "final" implies something about the semantics
> of field access on both the reader and writer side, and the fence
> implies something platform-dependent about the store you are putting
> it before.  On the off chance that there is ever a platform that
> requires the reader to do something to guarantee coherence, all of the
> code written using this Fences API will break.
>
> (None of the hardware platforms that Java currently really supports
> (i.e., SPARC and x86, plus, to a lesser extent, PPC and ia64) require
> reader-side coherence guarantees.  There is always the possibility
> that someone will come up with a compiler optimization that breaks
> reader-side dependencies in a way that would require additional
> guarantees for reading final fields, although such optimizations would
> probably be highly suspect.  Anything that used a distributed shared
> memory style of programming (or whatever they are calling it these
> days) would also possibly break.)
>
> In my opinion, such as it is, replacing something with well-defined
> semantics with something that happens to work on the platforms you
> know about is something that is highly suspect as a general principle,
> and should only be used for very, very particular use cases.
>
> Jeremy
>
> On Wed, Jul 1, 2009 at 4:00 AM, Ashley Williams<ashpublic at mac.com>  
> wrote:
>> Just looked at the Fences API and this is exactly what I was trying  
>> to
>> allude to.
>>
>> In fact I would personally prefer to see the explicit use of
>> Fences.preStoreFence()
>> instead of relying on memory model guarantees through the use of  
>> final. It
>> would
>> be all too easy for a developer to come along and mistakenly remove  
>> the
>> multi-purpose
>> final keyword without appearing to break the code.
>>
>> Am I right in thinking most jvms would implement this by writing to  
>> main
>> memory (writes) and
>> evicting entries from local memory (reads)? Just wondering about any
>> performance costs.
>>
>> So if one were to use both a final field modifier as well as a  
>> fence, would
>> the jvm be
>> clever enough not pay the for the happens-before guarantee twice  
>> over?
>>
>> On 30 Jun 2009, at 21:46, Doug Lea wrote:
>>
>>> Peter Veentjer wrote:
>>>
>>>> PS: Do you have a reference to the other concurrency features  
>>>> that are
>>>> going to be added (apart from the fences and the fork/join
>>>> functionality) to Java 7?
>>>
>>> Definitely planned classes are in package jsr166y --
>>> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
>>>
>>> Plus Fences, which can't be previewed in jsr166y since
>>> it relies on JVM support. See
>>>
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>>>
>>> Plus possibly some sort of customized hash map.
>>> The main reason for delay on that is algorithmic:
>>> Efficient support for features like eviction and
>>> memoization across a large enough range of
>>> policies to be worth supporting in concurrent maps is not a
>>> fully solved problem. I want to make sure that
>>> we offer only that range of them for which we are
>>> very sure we can support well, but without closing
>>> the door to future algorithmic overhauls.
>>>
>>> -Doug
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>


From davidcholmes at aapt.net.au  Wed Jul  8 07:33:22 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 8 Jul 2009 21:33:22 +1000
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <0C9EFA6F-7251-4164-A476-18C49D95EA3B@mac.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEIEICAA.davidcholmes@aapt.net.au>

Ashley,

I'm confused about what "drum" you are actually beating. I dispute your
premise that "final" is used to any great extent for its JMM semantics. It
has very few JMM semantics and what it does have exist to make immutable
objects easier to share correctly. So I don't understand what implicit
behaviour you think needs to be replaced with an explicit API ???

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ashley
> Williams
> Sent: Wednesday, 8 July 2009 8:14 PM
> To: Jeremy Manson
> Cc: Doug Lea; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Immutable object conundrums
>
>
>
> So I think you are saying that from your knowledge of vm architectures
> on various platforms it may not be possible to eliminate redundancy
> under
> the covers if you use an explicit fence through the Fences API and an
> implicit fence through the final field modifier.
>
> Lets assume then that an explicit fence is used instead of final fields.
> I previously understood that the Fences API is supposed to
> be platform independent at least w.r.t happens before behavior so that
> future re-ordering compiler optimizations would have no adverse effect.
> Are you saying that's not true and that there are current and possible
> future platforms where the Fences API won't work?
>
> ********
>
> As a final thought, I've been developing for many years and whilst I've
> always had a fairly sound knowledge of thread fundamentals, I only
> came to realize that most of my thread-safe code has only worked through
> semi-luck after reading JCiP. In fact I've pinned it down to the
> happens-before rules
> that I was inadvertently relying on: "in the same thread",
> "synchronized keyword"
> and "transitive". I would further extend this to the majority of
> others that
> I have worked with. I dread to think of all the lazy instantiation
> data race
> bugs that we must all have produced over the years.
>
> So the reason I'm banging this drum is that I'm starting to think it's
> a little dangerous to rely on implicit behavior to control the memory
> model. Explicit API calls say "don't touch unless you know what you
> are doing" a little louder. However if you say this isn't possible then
> I'll add this to my ever growing list of things to think about.
>
> Cheers
> - Ashley
>
> On 8 Jul 2009, at 07:13, Jeremy Manson wrote:
>
> > Most VMs would implement this by executing the appropriate fence
> > instruction (as you describe) and preventing compiler optimizations
> > that moved accesses around the Fence.  A VM might be clever enough to
> > combine the fences for this and final fields, but it might not.  I
> > doubt such an optimization would happen in any timely manner, but who
> > knows?
> >
> > I would argue that this method is definitely *not* preferable to use
> > of the final keyword.  "final" implies something about the semantics
> > of field access on both the reader and writer side, and the fence
> > implies something platform-dependent about the store you are putting
> > it before.  On the off chance that there is ever a platform that
> > requires the reader to do something to guarantee coherence, all of the
> > code written using this Fences API will break.
> >
> > (None of the hardware platforms that Java currently really supports
> > (i.e., SPARC and x86, plus, to a lesser extent, PPC and ia64) require
> > reader-side coherence guarantees.  There is always the possibility
> > that someone will come up with a compiler optimization that breaks
> > reader-side dependencies in a way that would require additional
> > guarantees for reading final fields, although such optimizations would
> > probably be highly suspect.  Anything that used a distributed shared
> > memory style of programming (or whatever they are calling it these
> > days) would also possibly break.)
> >
> > In my opinion, such as it is, replacing something with well-defined
> > semantics with something that happens to work on the platforms you
> > know about is something that is highly suspect as a general principle,
> > and should only be used for very, very particular use cases.
> >
> > Jeremy
> >
> > On Wed, Jul 1, 2009 at 4:00 AM, Ashley Williams<ashpublic at mac.com>
> > wrote:
> >> Just looked at the Fences API and this is exactly what I was trying
> >> to
> >> allude to.
> >>
> >> In fact I would personally prefer to see the explicit use of
> >> Fences.preStoreFence()
> >> instead of relying on memory model guarantees through the use of
> >> final. It
> >> would
> >> be all too easy for a developer to come along and mistakenly remove
> >> the
> >> multi-purpose
> >> final keyword without appearing to break the code.
> >>
> >> Am I right in thinking most jvms would implement this by writing to
> >> main
> >> memory (writes) and
> >> evicting entries from local memory (reads)? Just wondering about any
> >> performance costs.
> >>
> >> So if one were to use both a final field modifier as well as a
> >> fence, would
> >> the jvm be
> >> clever enough not pay the for the happens-before guarantee twice
> >> over?
> >>
> >> On 30 Jun 2009, at 21:46, Doug Lea wrote:
> >>
> >>> Peter Veentjer wrote:
> >>>
> >>>> PS: Do you have a reference to the other concurrency features
> >>>> that are
> >>>> going to be added (apart from the fences and the fork/join
> >>>> functionality) to Java 7?
> >>>
> >>> Definitely planned classes are in package jsr166y --
> >>> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
> >>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
> >>>
> >>> Plus Fences, which can't be previewed in jsr166y since
> >>> it relies on JVM support. See
> >>>
> >>>
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/
atomic/Fences.html
>>>
>>> Plus possibly some sort of customized hash map.
>>> The main reason for delay on that is algorithmic:
>>> Efficient support for features like eviction and
>>> memoization across a large enough range of
>>> policies to be worth supporting in concurrent maps is not a
>>> fully solved problem. I want to make sure that
>>> we offer only that range of them for which we are
>>> very sure we can support well, but without closing
>>> the door to future algorithmic overhauls.
>>>
>>> -Doug
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From martinrb at google.com  Wed Jul  8 18:15:44 2009
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 8 Jul 2009 15:15:44 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue changes
Message-ID: <1ccfd1c10907081515p3295bd1bt5da81eb374892033@mail.gmail.com>

The long-awaited changes to ConcurrentLinkedQueue
have come out of vaporware status and are ready for
commit to openjdk7 soon.

When it comes to concurrent lock-free data structures,
even getting singly-linked lists right is really hard!

We do not need additional review according to openjdk rules,
but interested parties are invited to provide some.

http://cr.openjdk.java.net/~martin/webrevs/openjdk7/CLQ/

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090708/667c4347/attachment.html>

From ariel at weisberg.ws  Wed Jul  8 18:57:55 2009
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Wed, 08 Jul 2009 18:57:55 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEIDICAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEIDICAA.davidcholmes@aapt.net.au>
Message-ID: <1247093875.31776.1324114639@webmail.messagingengine.com>

Hi,

> The poll()ing thread is blocked waiting for the internal lock, but
> there's
> no indication of any thread owning that lock. You're using an OpenJDK 6
> build ... can you try JDK7 ?

I got a chance to do that today. I downloaded JDK 7 from
http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
and was able to reproduce the problem. I have attached the stack trace
from running the 1.7 version. It is the same situation as before except
there are 9 execution sites running on each host. There are no threads
that are missing or that have been restarted. Foo Network thread
(selector thread) and Network Thread - 0 are waiting on
0x00002aaab43d3b28. I also ran with JDK 7 and 6 and LinkedBlockingQueue
and was not able to recreate the problem using that structure.

> I don't recall anything similar to this, but I don't know what version
> that
> OpenJDK6 build relates to.

The cluster is running on CentOS 5.3.
>[aweisberg at 3f ~]$ rpm -qi java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
>Name        : java-1.6.0-openjdk           Relocations: (not relocatable)
>Version     : 1.6.0.0                           Vendor: CentOS
>Release     : 0.30.b09.el5                  Build Date: Tue 07 Apr 2009 07:24:52 PM EDT
>Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build Host: builder10.centos.org
>Group       : Development/Languages         Source RPM: java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
>Size        : 76336266                         License: GPLv2 with exceptions
>Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key ID a8a447dce8562897
>URL         : http://icedtea.classpath.org/
>Summary     : OpenJDK Runtime Environment
>Description :
>The OpenJDK runtime environment.

> Make sure you haven't missed any exceptions occurring in other threads.
There are no threads missing in the application (terminated threads are
not replaced) and there is a try catch pair (prints error and rethrows)
around the run loop of each thread. It is possible that an exception may
have been swallowed up somewhere.

>A small reproducible test case from you would be useful.
I am working on that. I wrote a test case that mimics the application's
use of the LBD, but I have not succeeded in reproducing the problem in
the test case. The app has a single thread (network selector) that polls
the LBD and several threads (ExecutionSites, and network threads that
return results from remote ExecutionSites) that offer results into the
queue. About 120k items will go into/out of the deque each second. In
the actual app the problem is reproducible but inconsistent. If I run on
my dual core laptop I can't reproduce it, and it is less likely to occur
with a small cluster, but with 6 nodes (~560k transactions/sec) the
problem will usually appear. Sometimes the cluster will run for several
minutes without issue and other times it will deadlock immediately.

Thanks,

Ariel

On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
<martinrb at google.com> wrote:
>[+core-libs-dev]
>
>Doug Lea and I are (slowly) working on a new version of LinkedBlockingDeque.
>I was not aware of a deadlock but can vaguely imagine how it might happen.
>A small reproducible test case from you would be useful.
>
>Unfinished work in progress can be found here:
>http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQueue/
>
>Martin

On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"
<davidcholmes at aapt.net.au> wrote:
> 
> Ariel,
> 
> The poll()ing thread is blocked waiting for the internal lock, but
> there's
> no indication of any thread owning that lock. You're using an OpenJDK 6
> build ... can you try JDK7 ?
> 
> I don't recall anything similar to this, but I don't know what version
> that
> OpenJDK6 build relates to.
> 
> Make sure you haven't missed any exceptions occurring in other threads.
> 
> David Holmes
> 
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ariel
> > Weisberg
> > Sent: Wednesday, 8 July 2009 8:31 AM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
> >
> >
> > Hi all,
> >
> > I did a search on LinkedBlockingDeque and didn't find anything similar
> > to what I am seeing. Attached is the stack trace from an application
> > that is deadlocked with three threads waiting for 0x00002aaab3e91080
> > (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
> > Selector"). The execution sites are attempting to offer results to the
> > deque and the network thread is trying to poll for them using the
> > non-blocking version of poll. I am seeing the network thread never
> > return from poll (straight poll()). Do my eyes deceive me?
> >
> > Thanks,
> >
> > Ariel Weisberg
> >
> 

From martinrb at google.com  Mon Jul 13 18:37:58 2009
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 13 Jul 2009 15:37:58 -0700
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1247093875.31776.1324114639@webmail.messagingengine.com>
References: <NFBBKALFDCPFIDBNKAPCEEIDICAA.davidcholmes@aapt.net.au>
	<1247093875.31776.1324114639@webmail.messagingengine.com>
Message-ID: <1ccfd1c10907131537x3d566c72se2f2ead08ae06af@mail.gmail.com>

I did some stack trace eyeballing and did a mini-audit of the
LinkedBlockingDeque code, with a view to finding possible bugs,
and came up empty.  Maybe it's a deep bug in hotspot?

Ariel, it would be good if you could get a reproducible test case soonish,
while someone on the planet has the motivation and familiarity to fix it.
In another month I may disavow all knowledge of j.u.c.*Blocking*

Martin


On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg <ariel at weisberg.ws> wrote:

> Hi,
>
> > The poll()ing thread is blocked waiting for the internal lock, but
> > there's
> > no indication of any thread owning that lock. You're using an OpenJDK 6
> > build ... can you try JDK7 ?
>
> I got a chance to do that today. I downloaded JDK 7 from
>
> http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
> and was able to reproduce the problem. I have attached the stack trace
> from running the 1.7 version. It is the same situation as before except
> there are 9 execution sites running on each host. There are no threads
> that are missing or that have been restarted. Foo Network thread
> (selector thread) and Network Thread - 0 are waiting on
> 0x00002aaab43d3b28. I also ran with JDK 7 and 6 and LinkedBlockingQueue
> and was not able to recreate the problem using that structure.
>
> > I don't recall anything similar to this, but I don't know what version
> > that
> > OpenJDK6 build relates to.
>
> The cluster is running on CentOS 5.3.
> >[aweisberg at 3f ~]$ rpm -qi java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
> >Name        : java-1.6.0-openjdk           Relocations: (not relocatable)
> >Version     : 1.6.0.0                           Vendor: CentOS
> >Release     : 0.30.b09.el5                  Build Date: Tue 07 Apr 2009
> 07:24:52 PM EDT
> >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build Host:
> builder10.centos.org
> >Group       : Development/Languages         Source RPM:
> java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
> >Size        : 76336266                         License: GPLv2 with
> exceptions
> >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key ID
> a8a447dce8562897
> >URL         : http://icedtea.classpath.org/
> >Summary     : OpenJDK Runtime Environment
> >Description :
> >The OpenJDK runtime environment.
>
> > Make sure you haven't missed any exceptions occurring in other threads.
> There are no threads missing in the application (terminated threads are
> not replaced) and there is a try catch pair (prints error and rethrows)
> around the run loop of each thread. It is possible that an exception may
> have been swallowed up somewhere.
>
> >A small reproducible test case from you would be useful.
> I am working on that. I wrote a test case that mimics the application's
> use of the LBD, but I have not succeeded in reproducing the problem in
> the test case. The app has a single thread (network selector) that polls
> the LBD and several threads (ExecutionSites, and network threads that
> return results from remote ExecutionSites) that offer results into the
> queue. About 120k items will go into/out of the deque each second. In
> the actual app the problem is reproducible but inconsistent. If I run on
> my dual core laptop I can't reproduce it, and it is less likely to occur
> with a small cluster, but with 6 nodes (~560k transactions/sec) the
> problem will usually appear. Sometimes the cluster will run for several
> minutes without issue and other times it will deadlock immediately.
>
> Thanks,
>
> Ariel
>
> On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
> <martinrb at google.com> wrote:
> >[+core-libs-dev]
> >
> >Doug Lea and I are (slowly) working on a new version of
> LinkedBlockingDeque.
> >I was not aware of a deadlock but can vaguely imagine how it might happen.
> >A small reproducible test case from you would be useful.
> >
> >Unfinished work in progress can be found here:
> >http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQueue/<http://cr.openjdk.java.net/%7Emartin/webrevs/openjdk7/BlockingQueue/>
> >
> >Martin
>
> On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"
> <davidcholmes at aapt.net.au> wrote:
> >
> > Ariel,
> >
> > The poll()ing thread is blocked waiting for the internal lock, but
> > there's
> > no indication of any thread owning that lock. You're using an OpenJDK 6
> > build ... can you try JDK7 ?
> >
> > I don't recall anything similar to this, but I don't know what version
> > that
> > OpenJDK6 build relates to.
> >
> > Make sure you haven't missed any exceptions occurring in other threads.
> >
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ariel
> > > Weisberg
> > > Sent: Wednesday, 8 July 2009 8:31 AM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
> > >
> > >
> > > Hi all,
> > >
> > > I did a search on LinkedBlockingDeque and didn't find anything similar
> > > to what I am seeing. Attached is the stack trace from an application
> > > that is deadlocked with three threads waiting for 0x00002aaab3e91080
> > > (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
> > > Selector"). The execution sites are attempting to offer results to the
> > > deque and the network thread is trying to poll for them using the
> > > non-blocking version of poll. I am seeing the network thread never
> > > return from poll (straight poll()). Do my eyes deceive me?
> > >
> > > Thanks,
> > >
> > > Ariel Weisberg
> > >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090713/7db96631/attachment.html>

From davidcholmes at aapt.net.au  Mon Jul 13 19:00:20 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 14 Jul 2009 09:00:20 +1000
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1ccfd1c10907131537x3d566c72se2f2ead08ae06af@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>

Martin,

I don't think this is due to LBQ/D. This is looking similar to a couple of
other ReentrantLock/AQS "lost wakeup" hangs that I've got on the radar. We
have a reprodeucible test case for one issue but it only fails on one kind
of system - x4450. I'm on vacation most of this week but will try and get
back to this next week.

Ariel: one thing to try please see if -XX:+UseMembar fixes the problem.

Thanks,
David Holmes
  -----Original Message-----
  From: Martin Buchholz [mailto:martinrb at google.com]
  Sent: Tuesday, 14 July 2009 8:38 AM
  To: Ariel Weisberg
  Cc: davidcholmes at aapt.net.au; core-libs-dev;
concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock?


  I did some stack trace eyeballing and did a mini-audit of the
  LinkedBlockingDeque code, with a view to finding possible bugs,
  and came up empty.  Maybe it's a deep bug in hotspot?

  Ariel, it would be good if you could get a reproducible test case soonish,
  while someone on the planet has the motivation and familiarity to fix it.
  In another month I may disavow all knowledge of j.u.c.*Blocking*

  Martin



  On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg <ariel at weisberg.ws> wrote:

    Hi,


    > The poll()ing thread is blocked waiting for the internal lock, but
    > there's
    > no indication of any thread owning that lock. You're using an OpenJDK
6
    > build ... can you try JDK7 ?


    I got a chance to do that today. I downloaded JDK 7 from

http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul
_2009.bin
    and was able to reproduce the problem. I have attached the stack trace
    from running the 1.7 version. It is the same situation as before except
    there are 9 execution sites running on each host. There are no threads
    that are missing or that have been restarted. Foo Network thread
    (selector thread) and Network Thread - 0 are waiting on
    0x00002aaab43d3b28. I also ran with JDK 7 and 6 and LinkedBlockingQueue
    and was not able to recreate the problem using that structure.


    > I don't recall anything similar to this, but I don't know what version
    > that
    > OpenJDK6 build relates to.


    The cluster is running on CentOS 5.3.
    >[aweisberg at 3f ~]$ rpm -qi java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
    >Name        : java-1.6.0-openjdk           Relocations: (not
relocatable)
    >Version     : 1.6.0.0                           Vendor: CentOS
    >Release     : 0.30.b09.el5                  Build Date: Tue 07 Apr 2009
07:24:52 PM EDT
    >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build Host:
builder10.centos.org
    >Group       : Development/Languages         Source RPM:
java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
    >Size        : 76336266                         License: GPLv2 with
exceptions
    >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key ID
a8a447dce8562897
    >URL         : http://icedtea.classpath.org/
    >Summary     : OpenJDK Runtime Environment
    >Description :
    >The OpenJDK runtime environment.


    > Make sure you haven't missed any exceptions occurring in other
threads.

    There are no threads missing in the application (terminated threads are
    not replaced) and there is a try catch pair (prints error and rethrows)
    around the run loop of each thread. It is possible that an exception may
    have been swallowed up somewhere.


    >A small reproducible test case from you would be useful.

    I am working on that. I wrote a test case that mimics the application's
    use of the LBD, but I have not succeeded in reproducing the problem in
    the test case. The app has a single thread (network selector) that polls
    the LBD and several threads (ExecutionSites, and network threads that
    return results from remote ExecutionSites) that offer results into the
    queue. About 120k items will go into/out of the deque each second. In
    the actual app the problem is reproducible but inconsistent. If I run on
    my dual core laptop I can't reproduce it, and it is less likely to occur
    with a small cluster, but with 6 nodes (~560k transactions/sec) the
    problem will usually appear. Sometimes the cluster will run for several
    minutes without issue and other times it will deadlock immediately.

    Thanks,

    Ariel


    On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
    <martinrb at google.com> wrote:
    >[+core-libs-dev]
    >
    >Doug Lea and I are (slowly) working on a new version of
LinkedBlockingDeque.
    >I was not aware of a deadlock but can vaguely imagine how it might
happen.
    >A small reproducible test case from you would be useful.
    >
    >Unfinished work in progress can be found here:
    >http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQueue/
    >
    >Martin


    On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"

    <davidcholmes at aapt.net.au> wrote:
    >

    > Ariel,
    >
    > The poll()ing thread is blocked waiting for the internal lock, but
    > there's
    > no indication of any thread owning that lock. You're using an OpenJDK
6
    > build ... can you try JDK7 ?
    >
    > I don't recall anything similar to this, but I don't know what version
    > that
    > OpenJDK6 build relates to.
    >
    > Make sure you haven't missed any exceptions occurring in other
threads.
    >
    > David Holmes
    >
    > > -----Original Message-----
    > > From: concurrency-interest-bounces at cs.oswego.edu
    > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
Ariel
    > > Weisberg
    > > Sent: Wednesday, 8 July 2009 8:31 AM
    > > To: concurrency-interest at cs.oswego.edu
    > > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
    > >
    > >
    > > Hi all,
    > >
    > > I did a search on LinkedBlockingDeque and didn't find anything
similar
    > > to what I am seeing. Attached is the stack trace from an application
    > > that is deadlocked with three threads waiting for 0x00002aaab3e91080
    > > (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
    > > Selector"). The execution sites are attempting to offer results to
the
    > > deque and the network thread is trying to poll for them using the
    > > non-blocking version of poll. I am seeing the network thread never
    > > return from poll (straight poll()). Do my eyes deceive me?
    > >
    > > Thanks,
    > >
    > > Ariel Weisberg
    > >
    >


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090714/f2f74f69/attachment-0001.html>

From ariel at weisberg.ws  Mon Jul 13 22:59:28 2009
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Mon, 13 Jul 2009 22:59:28 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
Message-ID: <1247540368.18990.1324916035@webmail.messagingengine.com>

Hi all.

Sorry Martin I missed reading your last email. I am not confident
that I will get a small reproducible test case in a reasonable
time frame. Reproducing it with the application is easy and I
will see what I can do about getting the source available.

One interesting thing I can tell you is that if I remove the
LinkedBlockingDeque from the mailbox of the Initiator the system
still deadlocks. The cluster has a TCP mesh topology so any node
can deliver messages to any other node. One of the connections
goes dead and neither side detects that there is a problem. I add
some assertions to the network selection thread to check that all
the connections in the cluster are still healthy and assert that
they have the correct interests set.

Here are the things it checks for  to make sure each connection
is working:
>                             for (ForeignHost.Port port :
foreignHostPorts) {
>
assert(port.m_selectionKey.isValid());
>
assert(port.m_selectionKey.selector() == m_selector);
>                             assert(port.m_channel.isOpen());
>
assert(((SocketChannel)port.m_channel).isConnected());
>
assert(((SocketChannel)port.m_channel).socket().isInputShutdown()
== false);
>
assert(((SocketChannel)port.m_channel).socket().isOutputShutdown(
) == false);
>
assert(((SocketChannel)port.m_channel).isOpen());
>
assert(((SocketChannel)port.m_channel).isRegistered());
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) !=
null);
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) ==
port.m_selectionKey);
>                             if
(m_selector.selectedKeys().contains(port.m_selectionKey)) {
>
assert((port.m_selectionKey.interestOps() & SelectionKey.OP_READ)
!= 0);
>
assert((port.m_selectionKey.interestOps() &
SelectionKey.OP_WRITE) != 0);
>                             } else {
>                                 if (port.isRunning()) {
>
assert(port.m_selectionKey.interestOps() == 0);
>                                 } else {
>
port.m_selectionKey.interestOps(SelectionKey.OP_READ |
SelectionKey.OP_WRITE);
>                                     assert((port.interestOps()
& SelectionKey.OP_READ) != 0);
>                                     assert((port.interestOps()
& SelectionKey.OP_WRITE) != 0);
>                                 }
>                             }
>                             assert(m_selector.isOpen());
>
assert(m_selector.keys().contains(port.m_selectionKey));
OP_READ | OP_WRITE is set as the interest ops every time through,
and there is no other code that changes the interest ops during
execution. The application will run for a while and then one of
the connections will stop being selected on both sides. If I step
in with the debugger on either side everything looks correct. The
keys have the correct interest ops and the selectors have the
keys in their key set.

What I suspect is happening is that a bug on one node stops the
socket from being selected (for both read and write), and
eventually the socket fills up and can't be written to by the
other side.

If I can get my VPN access together tomorrow I will run with
-XX:+UseMembar and also try running on some 8-core AMD machines.
Otherwise I will have to get to it Wednesday.

Thanks,

Ariel Weisberg


On Tue, 14 Jul 2009 05:00 +1000, "David Holmes"
<davidcholmes at aapt.net.au> wrote:

Martin,



I don't think this is due to LBQ/D. This is looking similar to a
couple of other ReentrantLock/AQS "lost wakeup" hangs that I've
got on the radar. We have a reprodeucible test case for one issue
but it only fails on one kind of system - x4450. I'm on vacation
most of this week but will try and get back to this next week.



Ariel: one thing to try please see if -XX:+UseMembar fixes the
problem.



Thanks,

David Holmes

-----Original Message-----
From: Martin Buchholz [mailto:martinrb at google.com]
Sent: Tuesday, 14 July 2009 8:38 AM
To: Ariel Weisberg
Cc: davidcholmes at aapt.net.au; core-libs-dev;
concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock?

  I did some stack trace eyeballing and did a mini-audit of the
  LinkedBlockingDeque code, with a view to finding possible
  bugs,
  and came up empty.  Maybe it's a deep bug in hotspot?
  Ariel, it would be good if you could get a reproducible test
  case soonish,
  while someone on the planet has the motivation and familiarity
  to fix it.
  In another month I may disavow all knowledge of
  j.u.c.*Blocking*
  Martin

On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg
<[1]ariel at weisberg.ws> wrote:

  Hi,

> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?


  I got a chance to do that today. I downloaded JDK 7 from
  [2]http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63
  -linux-x64-02_jul_2009.bin
  and was able to reproduce the problem. I have attached the
  stack trace
  from running the 1.7 version. It is the same situation as
  before except
  there are 9 execution sites running on each host. There are no
  threads
  that are missing or that have been restarted. Foo Network
  thread
  (selector thread) and Network Thread - 0 are waiting on
  0x00002aaab43d3b28. I also ran with JDK 7 and 6 and
  LinkedBlockingQueue
  and was not able to recreate the problem using that structure.

> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.


  The cluster is running on CentOS 5.3.
  >[aweisberg at 3f ~]$ rpm -qi
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
  >Name        : java-1.6.0-openjdk           Relocations: (not
  relocatable)
  >Version     : 1.6.0.0                           Vendor:
  CentOS
  >Release     : 0.30.b09.el5                  Build Date: Tue
  07 Apr 2009 07:24:52 PM EDT
  >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build
  Host: [3]builder10.centos.org
  >Group       : Development/Languages         Source RPM:
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
  >Size        : 76336266                         License: GPLv2
  with exceptions
  >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key
  ID a8a447dce8562897
  >URL         : [4]http://icedtea.classpath.org/
  >Summary     : OpenJDK Runtime Environment
  >Description :
  >The OpenJDK runtime environment.

> Make sure you haven't missed any exceptions occurring in other
threads.

  There are no threads missing in the application (terminated
  threads are
  not replaced) and there is a try catch pair (prints error and
  rethrows)
  around the run loop of each thread. It is possible that an
  exception may
  have been swallowed up somewhere.

>A small reproducible test case from you would be useful.

  I am working on that. I wrote a test case that mimics the
  application's
  use of the LBD, but I have not succeeded in reproducing the
  problem in
  the test case. The app has a single thread (network selector)
  that polls
  the LBD and several threads (ExecutionSites, and network
  threads that
  return results from remote ExecutionSites) that offer results
  into the
  queue. About 120k items will go into/out of the deque each
  second. In
  the actual app the problem is reproducible but inconsistent.
  If I run on
  my dual core laptop I can't reproduce it, and it is less
  likely to occur
  with a small cluster, but with 6 nodes (~560k
  transactions/sec) the
  problem will usually appear. Sometimes the cluster will run
  for several
  minutes without issue and other times it will deadlock
  immediately.
  Thanks,
  Ariel

On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
<[5]martinrb at google.com> wrote:
>[+core-libs-dev]
>
>Doug Lea and I are (slowly) working on a new version of
LinkedBlockingDeque.
>I was not aware of a deadlock but can vaguely imagine how it
might happen.
>A small reproducible test case from you would be useful.
>
>Unfinished work in progress can be found here:
>[6]http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQ
ueue/
>
>Martin


  On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"

<[7]davidcholmes at aapt.net.au> wrote:
>


> Ariel,
>
> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?
>
> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.
>
> Make sure you haven't missed any exceptions occurring in other
threads.
>
> David Holmes
>
> > -----Original Message-----
> > From: [8]concurrency-interest-bounces at cs.oswego.edu
> > [mailto:[9]concurrency-interest-bounces at cs.oswego.edu]On
Behalf Of Ariel
> > Weisberg
> > Sent: Wednesday, 8 July 2009 8:31 AM
> > To: [10]concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
> >
> >
> > Hi all,
> >
> > I did a search on LinkedBlockingDeque and didn't find
anything similar
> > to what I am seeing. Attached is the stack trace from an
application
> > that is deadlocked with three threads waiting for
0x00002aaab3e91080
> > (threads "ExecutionSite: 26", "ExecutionSite:27", and
"Network
> > Selector"). The execution sites are attempting to offer
results to the
> > deque and the network thread is trying to poll for them using
the
> > non-blocking version of poll. I am seeing the network thread
never
> > return from poll (straight poll()). Do my eyes deceive me?
> >
> > Thanks,
> >
> > Ariel Weisberg
> >
>

References

1. mailto:ariel at weisberg.ws
2. http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
3. http://builder10.centos.org/
4. http://icedtea.classpath.org/
5. mailto:martinrb at google.com
6. http://cr.openjdk.java.net/%7Emartin/webrevs/openjdk7/BlockingQueue/
7. mailto:davidcholmes at aapt.net.au
8. mailto:concurrency-interest-bounces at cs.oswego.edu
9. mailto:concurrency-interest-bounces at cs.oswego.edu
  10. mailto:concurrency-interest at cs.oswego.edu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090713/409cbdb2/attachment.html>

From jseigh_cp00 at xemaps.com  Tue Jul 14 19:28:49 2009
From: jseigh_cp00 at xemaps.com (Joseph Seigh)
Date: Tue, 14 Jul 2009 19:28:49 -0400
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <1247540368.18990.1324916035@webmail.messagingengine.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
Message-ID: <4A5D14B1.5040001@xemaps.com>

If you have more than one WeakReference pointing to an object, and the 
object no longer has any normal references, are the references cleared 
atomically?   Or can you bring an object back into play by getting a 
reference to it from a WeakReference that hasn't been cleared after 
seeing a different WeakReference to it get cleared?

Joe Seigh

From crazybob at crazybob.org  Tue Jul 14 19:46:35 2009
From: crazybob at crazybob.org (Bob Lee)
Date: Tue, 14 Jul 2009 16:46:35 -0700
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <4A5D14B1.5040001@xemaps.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<4A5D14B1.5040001@xemaps.com>
Message-ID: <a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>

On Tue, Jul 14, 2009 at 4:28 PM, Joseph Seigh <jseigh_cp00 at xemaps.com>wrote:

> If you have more than one WeakReference pointing to an object, and the
> object no longer has any normal references, are the references cleared
> atomically?   Or can you bring an object back into play by getting a
> reference to it from a WeakReference that hasn't been cleared after seeing a
> different WeakReference to it get cleared?
>

The spec says they are cleared atomically:

"Suppose that the garbage collector determines at a certain point in time
that an object is weakly
reachable<http://java.sun.com/javase/6/docs/api/java/lang/ref/package-summary.html#reachability>.
At that time it will *atomically* clear all weak references to that object
and all weak references to any other weakly-reachable objects from which
that object is reachable through a chain of strong and soft references. At
the same time it will declare all of the formerly weakly-reachable objects
to be finalizable." (
http://java.sun.com/javase/6/docs/api/java/lang/ref/WeakReference.html)

This would be easy to support in a stop-the-world collector, but it seems to
me that it could overly restrict concurrent collectors. Thoughts?

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090714/72600c93/attachment.html>

From dhanji at gmail.com  Tue Jul 14 20:06:20 2009
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 15 Jul 2009 10:06:20 +1000
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<4A5D14B1.5040001@xemaps.com>
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>
Message-ID: <aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>

On Wed, Jul 15, 2009 at 9:46 AM, Bob Lee <crazybob at crazybob.org> wrote:

> On Tue, Jul 14, 2009 at 4:28 PM, Joseph Seigh <jseigh_cp00 at xemaps.com>wrote:
>
>> If you have more than one WeakReference pointing to an object, and the
>> object no longer has any normal references, are the references cleared
>> atomically?   Or can you bring an object back into play by getting a
>> reference to it from a WeakReference that hasn't been cleared after seeing a
>> different WeakReference to it get cleared?
>>
>
> The spec says they are cleared atomically:
>
> "Suppose that the garbage collector determines at a certain point in time
> that an object is weakly reachable<http://java.sun.com/javase/6/docs/api/java/lang/ref/package-summary.html#reachability>.
> At that time it will *atomically* clear all weak references to that object
> and all weak references to any other weakly-reachable objects from which
> that object is reachable through a chain of strong and soft references. At
> the same time it will declare all of the formerly weakly-reachable objects
> to be finalizable." (
> http://java.sun.com/javase/6/docs/api/java/lang/ref/WeakReference.html)
>
> This would be easy to support in a stop-the-world collector, but it seems
> to me that it could overly restrict concurrent collectors. Thoughts?
>

Concurrent collectors also pause all application threads during marking.
They just have shorter pauses as there are more marks done and the sweeping
is concurrent.

So it should not affect atomic clearing?

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/cf4caa74/attachment.html>

From karnok at sztaki.hu  Wed Jul 15 02:14:57 2009
From: karnok at sztaki.hu (=?ISO-8859-1?Q?Karnok_D=E1vid?=)
Date: Wed, 15 Jul 2009 08:14:57 +0200
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>	<1247540368.18990.1324916035@webmail.messagingengine.com>	<4A5D14B1.5040001@xemaps.com>	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>
Message-ID: <001301ca0513$93b683d0$bb238b70$@hu>

I would say, if a weak reference is immutable, then there should be only one
instance around each individual contained object and the JVM should
automagically return that on a new WeakReference(obj) call. I guess a

factory pattern would have helped here more, e.g.
WeakReference.to(myObject). What do you think?

 

-------------------------------- 

Karnok D?vid 

Research Assistant 

Engineering and Management Intelligence laboratory, Computer and Automation
Research Institute, Hungarian Academy of Sciences

 <http://www.sztaki.hu> http://www.sztaki.hu 

 <http://www.emi.sztaki.hu> http://www.emi.sztaki.hu

 

From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Dhanji R.
Prasanna
Sent: Wednesday, July 15, 2009 2:06 AM
To: Bob Lee
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Atomicity of clearing of WeakReferences

 

 

On Wed, Jul 15, 2009 at 9:46 AM, Bob Lee <crazybob at crazybob.org> wrote:

On Tue, Jul 14, 2009 at 4:28 PM, Joseph Seigh <jseigh_cp00 at xemaps.com>
wrote:

If you have more than one WeakReference pointing to an object, and the
object no longer has any normal references, are the references cleared
atomically?   Or can you bring an object back into play by getting a
reference to it from a WeakReference that hasn't been cleared after seeing a
different WeakReference to it get cleared?


The spec says they are cleared atomically:

"Suppose that the garbage collector determines at a certain point in time
that an object is weakly reachable
<http://java.sun.com/javase/6/docs/api/java/lang/ref/package-summary.html#re
achability> . At that time it will atomically clear all weak references to
that object and all weak references to any other weakly-reachable objects
from which that object is reachable through a chain of strong and soft
references. At the same time it will declare all of the formerly
weakly-reachable objects to be finalizable."
(http://java.sun.com/javase/6/docs/api/java/lang/ref/WeakReference.html)

This would be easy to support in a stop-the-world collector, but it seems to
me that it could overly restrict concurrent collectors. Thoughts?

 

Concurrent collectors also pause all application threads during marking.
They just have shorter pauses as there are more marks done and the sweeping
is concurrent.

 

So it should not affect atomic clearing?

 

Dhanji.

 

 

__________ ESET NOD32 Antivirus - V?rusdefin?ci?s adatb?zis: 4238 (20090713)
__________

 

Az ?zenetet az ESET NOD32 Antivirus ellen?rizte.

 

http://www.eset.hu

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/3cb0690b/attachment.html>

From crazybob at crazybob.org  Wed Jul 15 02:24:12 2009
From: crazybob at crazybob.org (Bob Lee)
Date: Wed, 15 Jul 2009 01:24:12 -0500
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <001301ca0513$93b683d0$bb238b70$@hu>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<4A5D14B1.5040001@xemaps.com>
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>
	<001301ca0513$93b683d0$bb238b70$@hu>
Message-ID: <a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>

On Wed, Jul 15, 2009 at 1:14 AM, Karnok D?vid <karnok at sztaki.hu> wrote:

>  I would say, if a weak reference is immutable, then there should be only
> one instance around each individual contained object and the JVM should
> automagically return that on a new WeakReference(obj) call. I guess a
>
> factory pattern would have helped here more, e.g.
> WeakReference.to(myObject). What do you think?
>
You can extend WeakReference, so that won't work.

You could add a level of indirection to the referent, but I don't know of
any impls that do this.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/2c58991b/attachment-0001.html>

From a.shahkar at ieee.org  Wed Jul 15 02:27:44 2009
From: a.shahkar at ieee.org (A Shahkar)
Date: Tue, 14 Jul 2009 23:27:44 -0700 (PDT)
Subject: [concurrency-interest] Problem in customizing the Executor
	framework behaviour
Message-ID: <932330.75771.qm@web54506.mail.re2.yahoo.com>



Dear all,

I'm developing a small framework which is intended to be used to
simulate random requests on custom protocols against server
applications. The following classes and interfaces are used to generate
random requests which probably meet certain requirements enforced by
the protocol.


public interface Randomizer<T> {
public T randomize();
}
 
public class ProtoRequestRandomizer implements Randomizer<ProtoRequest> {
// Generates random requests which meet Proto requirements
}
 
public interface RequestResource {
// Supplies requests to be sent by client simulators.
public Request getRequest();
}
 
public class MyRequestResource implements RequestResource {
public RequestResource(Randomizer<? extends Request> randomizer) {
    // ...
}
     @Override
public synchronized Request getRequest() {
// Generates a request using the supplied randomizer. It may simply call
// randomize() or pick one from a collection of randomized requests.
// If the collection is thread-safe, this method need not to be
 synchronized.
}
}
There will be a Runnable or a Callable, which fetches a request
provided by a RequestResource and sends it to a specified target.
Something like this:


public class BlindRequestTask implements Runnable {
public BlindRequestTask(RequestResource resource, Target target) {
// ...
}
    @Override
public void run() {
// Fetches a request (or a sequence of requests) from the specified RequestResource and sends it to the target, likely on a network.
}
}
I want to use a thread pool created by the executor framework to send a
total number of N requests (or N sequences of requests, whatever the
sending task does) against a target. There is not N different tasks as
you see, there's only one task which should be executed N times by
multiple threads in a thread pool. However every time the task
executes, the request is a different one which is got from the request
resource. N can be a very big number, something around a few ten thousands.

The code should also be able to keep executing the task until
shut down. Also, I want every thread to wait for a fixed delay before
executing the repeated task again. It makes me able to reduce the load
on the target if necessary. How can I achieve this? I'm searching for the most (or a very) efficient solution.

I thought it would be good to supply a customized ArrayBlockingQueue which returns the same task for N times to an executor. But I could not proceed any further because I don't know exactly which methods should be overriden, whether it is an efficient solution, and how can I add the delay feature.

Any other comments are also highly appreciated.

Thanks in advance.


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090714/0693c8e3/attachment.html>

From karnok at sztaki.hu  Wed Jul 15 02:34:25 2009
From: karnok at sztaki.hu (=?iso-8859-2?Q?Karnok_D=E1vid?=)
Date: Wed, 15 Jul 2009 08:34:25 +0200
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>	
	<1247540368.18990.1324916035@webmail.messagingengine.com>	
	<4A5D14B1.5040001@xemaps.com>	
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>	
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>	
	<001301ca0513$93b683d0$bb238b70$@hu>
	<a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>
Message-ID: <002101ca0516$4c090780$e41b1680$@hu>

Is there a reason the Reference sublcasses are not final? I think if there
are only limited number of reference types, why not have them individually
and have Reference<T> as a superinterface?

 

-------------------------------- 

Karnok D?vid 

Research Assistant 

Engineering and Management Intelligence laboratory, Computer and Automation
Research Institute, Hungarian Academy of Sciences

 <http://www.sztaki.hu> http://www.sztaki.hu 

 <http://www.emi.sztaki.hu> http://www.emi.sztaki.hu

 

From: crazyboblee at gmail.com [mailto:crazyboblee at gmail.com] On Behalf Of Bob
Lee
Sent: Wednesday, July 15, 2009 8:24 AM
To: Karnok D?vid
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Atomicity of clearing of WeakReferences

 

On Wed, Jul 15, 2009 at 1:14 AM, Karnok D?vid <karnok at sztaki.hu> wrote:

I would say, if a weak reference is immutable, then there should be only one
instance around each individual contained object and the JVM should
automagically return that on a new WeakReference(obj) call. I guess a

factory pattern would have helped here more, e.g.
WeakReference.to(myObject). What do you think?

You can extend WeakReference, so that won't work.

You could add a level of indirection to the referent, but I don't know of
any impls that do this.

Bob 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/dacd6158/attachment.html>

From crazybob at crazybob.org  Wed Jul 15 02:38:42 2009
From: crazybob at crazybob.org (Bob Lee)
Date: Wed, 15 Jul 2009 01:38:42 -0500
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <002101ca0516$4c090780$e41b1680$@hu>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<4A5D14B1.5040001@xemaps.com>
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>
	<001301ca0513$93b683d0$bb238b70$@hu>
	<a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>
	<002101ca0516$4c090780$e41b1680$@hu>
Message-ID: <a74683f90907142338w5de6c829u4b01e6721c483cdc@mail.gmail.com>

2009/7/15 Karnok D?vid <karnok at sztaki.hu>

>  Is there a reason the Reference sublcasses are not final? I think if
> there are only limited number of reference types, why not have them
> individually and have Reference<T> as a superinterface?
>
If you need to clean up after the referent, you don't have the object around
anymore, so you store any state necessary for the cleanup in the
WeakReference subclass.

Bob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/0b6c1f1b/attachment.html>

From karnok at sztaki.hu  Wed Jul 15 02:48:31 2009
From: karnok at sztaki.hu (=?iso-8859-2?Q?Karnok_D=E1vid?=)
Date: Wed, 15 Jul 2009 08:48:31 +0200
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <a74683f90907142338w5de6c829u4b01e6721c483cdc@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>	
	<1247540368.18990.1324916035@webmail.messagingengine.com>	
	<4A5D14B1.5040001@xemaps.com>	
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>	
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>	
	<001301ca0513$93b683d0$bb238b70$@hu>	
	<a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>	
	<002101ca0516$4c090780$e41b1680$@hu>
	<a74683f90907142338w5de6c829u4b01e6721c483cdc@mail.gmail.com>
Message-ID: <003501ca0518$43efbf60$cbcf3e20$@hu>

Composition over inheritance? Have the WR support for an internal cleanup
context object (maybe in an internal WR too)?

 

David

 

> If you need to clean up after the referent, you don't have the object
around anymore, so you store any state necessary for the cleanup in the
WeakReference subclass.
>
> Bob  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/34f4a672/attachment-0001.html>

From a.shahkar at ieee.org  Wed Jul 15 06:11:26 2009
From: a.shahkar at ieee.org (A Shahkar)
Date: Wed, 15 Jul 2009 03:11:26 -0700 (PDT)
Subject: [concurrency-interest] Problem in customizing the Executor
	framework behaviour
In-Reply-To: <e0563fd80907150201k49527e72l758f96b4beb463cb@mail.gmail.com>
References: <932330.75771.qm@web54506.mail.re2.yahoo.com>
	<e0563fd80907150201k49527e72l758f96b4beb463cb@mail.gmail.com>
Message-ID: <357218.55539.qm@web54502.mail.re2.yahoo.com>

Thanks Erkin.

I was told to take a similar approach when I posted the problem in Sun forums. IMHO, it has a few drawbacks.

Let's suppose N=1,000. We create a fixed thread pool with the size of 10, and instantiate BlindRequest to send 100 requests. We submit the BlindRequestTask 10 times to the thread pool. Now, for any reason, sending the forth request in the second thread takes a long time. Other threads likely finish their work far before the second thread does while it still has a few ten requests to send. Other threads won't help the second one finish its job, and that's not the way thread pool executors are intended to act it. Actually it does not make such difference (specially in performance) if we just run 10 threads instead of a pool, each one executing BlindTaskRequest. Am I right?

Thanks



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/070e77f2/attachment.html>

From joe.bowbeer at gmail.com  Wed Jul 15 07:23:41 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 15 Jul 2009 04:23:41 -0700
Subject: [concurrency-interest] Problem in customizing the Executor
	framework behaviour
In-Reply-To: <357218.55539.qm@web54502.mail.re2.yahoo.com>
References: <932330.75771.qm@web54506.mail.re2.yahoo.com>
	<e0563fd80907150201k49527e72l758f96b4beb463cb@mail.gmail.com>
	<357218.55539.qm@web54502.mail.re2.yahoo.com>
Message-ID: <31f2a7bd0907150423n34b632d9xf97bc1507c0a182a@mail.gmail.com>

A Shahkar wrote:


> Actually it does not make such difference (specially in performance) if we
> just run 10 threads instead of a pool, each one executing BlindTaskRequest.
> Am I right?


Yes, based on my understanding of your description, I think you are right,
and that's the approach I'd recommend.

Joe


On Wed, Jul 15, 2009 at 3:11 AM, A Shahkar wrote:

> Thanks Erkin.
>
> I was told to take a similar approach when I posted the problem in Sun
> forums. IMHO, it has a few drawbacks.
>
> Let's suppose N=1,000. We create a fixed thread pool with the size of 10,
> and instantiate BlindRequest to send 100 requests. We submit the
> BlindRequestTask 10 times to the thread pool. Now, for any reason, sending
> the forth request in the second thread takes a long time. Other threads
> likely finish their work far before the second thread does while it still
> has a few ten requests to send. Other threads won't help the second one
> finish its job, and that's not the way thread pool executors are intended to
> act it. Actually it does not make such difference (specially in performance)
> if we just run 10 threads instead of a pool, each one executing
> BlindTaskRequest. Am I right?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/a8005872/attachment.html>

From a.shahkar at ieee.org  Wed Jul 15 08:25:12 2009
From: a.shahkar at ieee.org (A Shahkar)
Date: Wed, 15 Jul 2009 05:25:12 -0700 (PDT)
Subject: [concurrency-interest] Problem in customizing the Executor
	framework behaviour
In-Reply-To: <e0563fd80907150355xb01c88cre60e3b7c66c85f7f@mail.gmail.com>
References: <932330.75771.qm@web54506.mail.re2.yahoo.com>
	<e0563fd80907150201k49527e72l758f96b4beb463cb@mail.gmail.com>
	<357218.55539.qm@web54502.mail.re2.yahoo.com>
	<e0563fd80907150355xb01c88cre60e3b7c66c85f7f@mail.gmail.com>
Message-ID: <396375.48468.qm@web54504.mail.re2.yahoo.com>

Thanks Erkin. Your idea about supplying the delay to the task's
constructor solved one aspect of the problem. Delays are no more
considered a dark point. Nice idea!


> So you can create your ThreadPoolExecutor first then pause, submit all
> the tasks and unpause the the threadPoolExecutor. So when test starts,
> you will not observe any delay because of request production.

I think actually now you can really understand what I was talking about in my original post.

As I told before, total number of requests (N) can be a very large number. Submitting a few thousand tasks makes the executor create a huge list of identical items. Not only this approach is extremely inefficient, but it also does not allow the application to make N equal to infinity. What is wrong with a user code which wants the framework's library to keep sending requests in a few threads until shut down?

As you might remember, I told about a customized ArrayBlockingQueue given to the executor in my original post. I thought that such a construct could return one task for N times, solving the huge list problem. It can hold an internal parameter which is equal to N and decrement it each time a thread fetches a task to execute. Or it can ignore the parameter if total number of requests is not known. The problem is, I don't know really how I can effectively implement such a construct which does not harm performance. I don't know which methods should be overriden and in what way. This somehow requires a deep understanding of how an executor works with its BlockingQueue.

Can you help me to implement the customized ArrayBlockingQueue?

Again, thank you for your idea on solving the delays problem.



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/c0147556/attachment.html>

From gregg at cytetech.com  Wed Jul 15 12:13:17 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 15 Jul 2009 11:13:17 -0500
Subject: [concurrency-interest] Atomicity of clearing of WeakReferences
In-Reply-To: <003501ca0518$43efbf60$cbcf3e20$@hu>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>	
	<1247540368.18990.1324916035@webmail.messagingengine.com>	
	<4A5D14B1.5040001@xemaps.com>	
	<a74683f90907141646m1b555656ma133dbe112f1a4b7@mail.gmail.com>	
	<aa067ea10907141706u1d4fdfd4j1139558132117dd6@mail.gmail.com>	
	<001301ca0513$93b683d0$bb238b70$@hu>	
	<a74683f90907142324v4faf3ecdpdb84a7ded04eb576@mail.gmail.com>	
	<002101ca0516$4c090780$e41b1680$@hu>
	<a74683f90907142338w5de6c829u4b01e6721c483cdc@mail.gmail.com>
	<003501ca0518$43efbf60$cbcf3e20$@hu>
Message-ID: <4A5E001D.5060109@cytetech.com>

If you need to cleanup after something is unreferenced, PhantomReference may be 
a good choice.  I used it to construct my ReferenceTracker class ( see 
<http://cs.oswego.edu/pipermail/concurrency-interest/2008-December/005724.html>)

The one warning I will give, is that after doing this, I found that I just could 
not use it in all the places I wanted, because of the Sun JVM "bug" that 
nominates objects for finalization, before ALL references are out of scope.

This causes the objects to be posted to the ReferenceQueue before they are 
actually "dead".  This means that any state you change, which is referenced by 
that object, in finalization, can be seen by the object before all references to 
the object have been used and gone out of scope.  Hans went into a lot of detail 
about this issue in many contexts it seems (see 
<http://gceclub.sun.com.cn/java_one_online/2005/TS-3281/ts-3281.pdf>)as follow 
up to the long trail of posts comming from Doug Lea's post at

<http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005743.html>

which is the fences API discussion.  Without Fences, or some other mechanics in 
the JIT to automatically manage this issue, it's not much of a real solution 
because you have to always think about scoping to make sure that refences last 
longer than the JIT currently documents them to exist as visible by the GC.  And 
PhantomReference would really help developers to not have to worry so much about 
scoping...

This is a tricky issue I discovered and I'd say that the way it works now is 
wrong, if not an out right bug.  Finalization should not be invoked (directly or 
indirectly through PhantomReference queues etc) until there are no more 
references to the value in registers, on the stack, or in scoped variables etc.

This misbehavior really makes automated reference tracking for limited resources 
nearly impossible when they are used by short lived bits of code that are prime 
for optimization and registerization that appears to hide references from the GC.

Gregg Wonderly


Karnok D?vid wrote:
> Composition over inheritance? Have the WR support for an internal 
> cleanup context object (maybe in an internal WR too)?
> 
>  
> 
> David
> 
>  
> 
>>  If you need to clean up after the referent, you don't have the object 
> around anymore, so you store any state necessary for the cleanup in the 
> WeakReference subclass.
>>
>>  Bob 
> 
> 
> 
> __________ ESET NOD32 Antivirus - V?rusdefin?ci?s adatb?zis: 4238 
> (20090713) __________
> 
> Az ?zenetet az ESET NOD32 Antivirus elleno~rizte.
> 
> http://www.eset.hu
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ariel at weisberg.ws  Wed Jul 15 15:24:12 2009
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Wed, 15 Jul 2009 15:24:12 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1247540368.18990.1324916035@webmail.messagingengine.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
Message-ID: <1247685852.19957.1325194693@webmail.messagingengine.com>

Hi,

I have found that there are two different failure modes without
involving -XX:+UseMembar. There is the LBD deadlock and then
there is the dead socket in between two nodes. Either failure can
occur with the same code and settings. It appears that the dead
socket problem is more common. The LBD failure is also not
correlated with any specific LBD (originally saw it with only the
LBD for an Initiator's mailbox).

With -XX:+UseMembar the system is noticeably more reliable and
tends to run much longer without failing (although it can still
fail immediately). When it does fail it has been due to a dead
connection. I have not reproduced a deadlock on an LBD with
-XX:+UseMembar.

I also found that the dead socket issue was reproducible twice on
Dell Poweredge 2970s (two socket AMD). It takes an hour or so to
reproduce the dead socket problem on the 2970. I have not
recreated the LBD issue on them although given how difficult the
socket issue is to reproduce it may be that I have not run them
long enough. On the AMD machines I did not use -XX:+UseMembar.

Ariel

On Mon, 13 Jul 2009 18:59 -0400, "Ariel Weisberg"
<ariel at weisberg.ws> wrote:

Hi all.

Sorry Martin I missed reading your last email. I am not confident
that I will get a small reproducible test case in a reasonable
time frame. Reproducing it with the application is easy and I
will see what I can do about getting the source available.

One interesting thing I can tell you is that if I remove the
LinkedBlockingDeque from the mailbox of the Initiator the system
still deadlocks. The cluster has a TCP mesh topology so any node
can deliver messages to any other node. One of the connections
goes dead and neither side detects that there is a problem. I add
some assertions to the network selection thread to check that all
the connections in the cluster are still healthy and assert that
they have the correct interests set.

Here are the things it checks for  to make sure each connection
is working:
>                             for (ForeignHost.Port port :
foreignHostPorts) {
>
assert(port.m_selectionKey.isValid());
>
assert(port.m_selectionKey.selector() == m_selector);
>                             assert(port.m_channel.isOpen());
>
assert(((SocketChannel)port.m_channel).isConnected());
>
assert(((SocketChannel)port.m_channel).socket().isInputShutdown()
== false);
>
assert(((SocketChannel)port.m_channel).socket().isOutputShutdown(
) == false);
>
assert(((SocketChannel)port.m_channel).isOpen());
>
assert(((SocketChannel)port.m_channel).isRegistered());
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) !=
null);
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) ==
port.m_selectionKey);
>                             if
(m_selector.selectedKeys().contains(port.m_selectionKey)) {
>
assert((port.m_selectionKey.interestOps() & SelectionKey.OP_READ)
!= 0);
>
assert((port.m_selectionKey.interestOps() &
SelectionKey.OP_WRITE) != 0);
>                             } else {
>                                 if (port.isRunning()) {
>
assert(port.m_selectionKey.interestOps() == 0);
>                                 } else {
>
port.m_selectionKey.interestOps(SelectionKey.OP_READ |
SelectionKey.OP_WRITE);
>                                     assert((port.interestOps()
& SelectionKey.OP_READ) != 0);
>                                     assert((port.interestOps()
& SelectionKey.OP_WRITE) != 0);
>                                 }
>                             }
>                             assert(m_selector.isOpen());
>
assert(m_selector.keys().contains(port.m_selectionKey));
OP_READ | OP_WRITE is set as the interest ops every time through,
and there is no other code that changes the interest ops during
execution. The application will run for a while and then one of
the connections will stop being selected on both sides. If I step
in with the debugger on either side everything looks correct. The
keys have the correct interest ops and the selectors have the
keys in their key set.

What I suspect is happening is that a bug on one node stops the
socket from being selected (for both read and write), and
eventually the socket fills up and can't be written to by the
other side.

If I can get my VPN access together tomorrow I will run with
-XX:+UseMembar and also try running on some 8-core AMD machines.
Otherwise I will have to get to it Wednesday.

Thanks,

Ariel Weisberg


On Tue, 14 Jul 2009 05:00 +1000, "David Holmes"
<davidcholmes at aapt.net.au> wrote:

Martin,



I don't think this is due to LBQ/D. This is looking similar to a
couple of other ReentrantLock/AQS "lost wakeup" hangs that I've
got on the radar. We have a reprodeucible test case for one issue
but it only fails on one kind of system - x4450. I'm on vacation
most of this week but will try and get back to this next week.



Ariel: one thing to try please see if -XX:+UseMembar fixes the
problem.



Thanks,

David Holmes

-----Original Message-----
From: Martin Buchholz [mailto:martinrb at google.com]
Sent: Tuesday, 14 July 2009 8:38 AM
To: Ariel Weisberg
Cc: davidcholmes at aapt.net.au; core-libs-dev;
concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock?

  I did some stack trace eyeballing and did a mini-audit of the
  LinkedBlockingDeque code, with a view to finding possible
  bugs,
  and came up empty.  Maybe it's a deep bug in hotspot?
  Ariel, it would be good if you could get a reproducible test
  case soonish,
  while someone on the planet has the motivation and familiarity
  to fix it.
  In another month I may disavow all knowledge of
  j.u.c.*Blocking*
  Martin

On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg
<[1]ariel at weisberg.ws> wrote:

  Hi,

> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?


  I got a chance to do that today. I downloaded JDK 7 from
  [2]http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63
  -linux-x64-02_jul_2009.bin
  and was able to reproduce the problem. I have attached the
  stack trace
  from running the 1.7 version. It is the same situation as
  before except
  there are 9 execution sites running on each host. There are no
  threads
  that are missing or that have been restarted. Foo Network
  thread
  (selector thread) and Network Thread - 0 are waiting on
  0x00002aaab43d3b28. I also ran with JDK 7 and 6 and
  LinkedBlockingQueue
  and was not able to recreate the problem using that structure.

> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.


  The cluster is running on CentOS 5.3.
  >[aweisberg at 3f ~]$ rpm -qi
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
  >Name        : java-1.6.0-openjdk           Relocations: (not
  relocatable)
  >Version     : 1.6.0.0                           Vendor:
  CentOS
  >Release     : 0.30.b09.el5                  Build Date: Tue
  07 Apr 2009 07:24:52 PM EDT
  >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build
  Host: [3]builder10.centos.org
  >Group       : Development/Languages         Source RPM:
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
  >Size        : 76336266                         License: GPLv2
  with exceptions
  >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key
  ID a8a447dce8562897
  >URL         : [4]http://icedtea.classpath.org/
  >Summary     : OpenJDK Runtime Environment
  >Description :
  >The OpenJDK runtime environment.

> Make sure you haven't missed any exceptions occurring in other
threads.

  There are no threads missing in the application (terminated
  threads are
  not replaced) and there is a try catch pair (prints error and
  rethrows)
  around the run loop of each thread. It is possible that an
  exception may
  have been swallowed up somewhere.

>A small reproducible test case from you would be useful.

  I am working on that. I wrote a test case that mimics the
  application's
  use of the LBD, but I have not succeeded in reproducing the
  problem in
  the test case. The app has a single thread (network selector)
  that polls
  the LBD and several threads (ExecutionSites, and network
  threads that
  return results from remote ExecutionSites) that offer results
  into the
  queue. About 120k items will go into/out of the deque each
  second. In
  the actual app the problem is reproducible but inconsistent.
  If I run on
  my dual core laptop I can't reproduce it, and it is less
  likely to occur
  with a small cluster, but with 6 nodes (~560k
  transactions/sec) the
  problem will usually appear. Sometimes the cluster will run
  for several
  minutes without issue and other times it will deadlock
  immediately.
  Thanks,
  Ariel

On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
<[5]martinrb at google.com> wrote:
>[+core-libs-dev]
>
>Doug Lea and I are (slowly) working on a new version of
LinkedBlockingDeque.
>I was not aware of a deadlock but can vaguely imagine how it
might happen.
>A small reproducible test case from you would be useful.
>
>Unfinished work in progress can be found here:
>[6]http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQ
ueue/
>
>Martin


  On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"

<[7]davidcholmes at aapt.net.au> wrote:
>


> Ariel,
>
> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?
>
> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.
>
> Make sure you haven't missed any exceptions occurring in other
threads.
>
> David Holmes
>
> > -----Original Message-----
> > From: [8]concurrency-interest-bounces at cs.oswego.edu
> > [mailto:[9]concurrency-interest-bounces at cs.oswego.edu]On
Behalf Of Ariel
> > Weisberg
> > Sent: Wednesday, 8 July 2009 8:31 AM
> > To: [10]concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
> >
> >
> > Hi all,
> >
> > I did a search on LinkedBlockingDeque and didn't find
anything similar
> > to what I am seeing. Attached is the stack trace from an
application
> > that is deadlocked with three threads waiting for
0x00002aaab3e91080
> > (threads "ExecutionSite: 26", "ExecutionSite:27", and
"Network
> > Selector"). The execution sites are attempting to offer
results to the
> > deque and the network thread is trying to poll for them using
the
> > non-blocking version of poll. I am seeing the network thread
never
> > return from poll (straight poll()). Do my eyes deceive me?
> >
> > Thanks,
> >
> > Ariel Weisberg
> >
>

References

1. mailto:ariel at weisberg.ws
2. http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
3. http://builder10.centos.org/
4. http://icedtea.classpath.org/
5. mailto:martinrb at google.com
6. http://cr.openjdk.java.net/%7Emartin/webrevs/openjdk7/BlockingQueue/
7. mailto:davidcholmes at aapt.net.au
8. mailto:concurrency-interest-bounces at cs.oswego.edu
9. mailto:concurrency-interest-bounces at cs.oswego.edu
  10. mailto:concurrency-interest at cs.oswego.edu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/661cfa4c/attachment-0001.html>

From martinrb at google.com  Wed Jul 15 17:24:32 2009
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 15 Jul 2009 14:24:32 -0700
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1247685852.19957.1325194693@webmail.messagingengine.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<1247685852.19957.1325194693@webmail.messagingengine.com>
Message-ID: <1ccfd1c10907151424t2f835a29y80a10228e0bc66c0@mail.gmail.com>

In summary,
there are two different bugs at work here,
and neither of them is in LBD.
The hotspot team is working on the LBD deadlock.
(As always) It would be good to have a good test case for
the dead socket problem.

Martin

On Wed, Jul 15, 2009 at 12:24, Ariel Weisberg <ariel at weisberg.ws> wrote:

> Hi,
>
> I have found that there are two different failure modes without involving
> -XX:+UseMembar. There is the LBD deadlock and then there is the dead socket
> in between two nodes. Either failure can occur with the same code and
> settings. It appears that the dead socket problem is more common. The LBD
> failure is also not correlated with any specific LBD (originally saw it with
> only the LBD for an Initiator's mailbox).
>
> With -XX:+UseMembar the system is noticeably more reliable and tends to run
> much longer without failing (although it can still fail immediately). When
> it does fail it has been due to a dead connection. I have not reproduced a
> deadlock on an LBD with -XX:+UseMembar.
>
> I also found that the dead socket issue was reproducible twice on Dell
> Poweredge 2970s (two socket AMD). It takes an hour or so to reproduce the
> dead socket problem on the 2970. I have not recreated the LBD issue on them
> although given how difficult the socket issue is to reproduce it may be that
> I have not run them long enough. On the AMD machines I did not use
> -XX:+UseMembar.
>
> Ariel
>
> On Mon, 13 Jul 2009 18:59 -0400, "Ariel Weisberg" <ariel at weisberg.ws>
> wrote:
>
>  Hi all.
>
> Sorry Martin I missed reading your last email. I am not confident that I
> will get a small reproducible test case in a reasonable time frame.
> Reproducing it with the application is easy and I will see what I can do
> about getting the source available.
>
> One interesting thing I can tell you is that if I remove the
> LinkedBlockingDeque from the mailbox of the Initiator the system still
> deadlocks. The cluster has a TCP mesh topology so any node can deliver
> messages to any other node. One of the connections goes dead and neither
> side detects that there is a problem. I add some assertions to the network
> selection thread to check that all the connections in the cluster are still
> healthy and assert that they have the correct interests set.
>
> Here are the things it checks for  to make sure each connection is working:
> >                             for (ForeignHost.Port port :
> foreignHostPorts) {
> >                             assert(port.m_selectionKey.isValid());
> >                             assert(port.m_selectionKey.selector() ==
> m_selector);
> >                             assert(port.m_channel.isOpen());
> >
> assert(((SocketChannel)port.m_channel).isConnected());
> >
> assert(((SocketChannel)port.m_channel).socket().isInputShutdown() == false);
> >
> assert(((SocketChannel)port.m_channel).socket().isOutputShutdown() ==
> false);
> >
> assert(((SocketChannel)port.m_channel).isOpen());
> >
> assert(((SocketChannel)port.m_channel).isRegistered());
> >
> assert(((SocketChannel)port.m_channel).keyFor(m_selector) != null);
> >
> assert(((SocketChannel)port.m_channel).keyFor(m_selector) ==
> port.m_selectionKey);
> >                             if
> (m_selector.selectedKeys().contains(port.m_selectionKey)) {
> >                                 assert((port.m_selectionKey.interestOps()
> & SelectionKey.OP_READ) != 0);
> >                                 assert((port.m_selectionKey.interestOps()
> & SelectionKey.OP_WRITE) != 0);
> >                             } else {
> >                                 if (port.isRunning()) {
> >
> assert(port.m_selectionKey.interestOps() == 0);
> >                                 } else {
> >
> port.m_selectionKey.interestOps(SelectionKey.OP_READ |
> SelectionKey.OP_WRITE);
> >                                     assert((port.interestOps() &
> SelectionKey.OP_READ) != 0);
> >                                     assert((port.interestOps() &
> SelectionKey.OP_WRITE) != 0);
> >                                 }
> >                             }
> >                             assert(m_selector.isOpen());
> >
> assert(m_selector.keys().contains(port.m_selectionKey));
> OP_READ | OP_WRITE is set as the interest ops every time through, and there
> is no other code that changes the interest ops during execution. The
> application will run for a while and then one of the connections will stop
> being selected on both sides. If I step in with the debugger on either side
> everything looks correct. The keys have the correct interest ops and the
> selectors have the keys in their key set.
>
> What I suspect is happening is that a bug on one node stops the socket from
> being selected (for both read and write), and eventually the socket fills up
> and can't be written to by the other side.
>
> If I can get my VPN access together tomorrow I will run with -XX:+UseMembar
> and also try running on some 8-core AMD machines. Otherwise I will have to
> get to it Wednesday.
>
> Thanks,
>
> Ariel Weisberg
>
>
> On Tue, 14 Jul 2009 05:00 +1000, "David Holmes" <davidcholmes at aapt.net.au>
> wrote:
>
> Martin,
>
> I don't think this is due to LBQ/D. This is looking similar to a couple of
> other ReentrantLock/AQS "lost wakeup" hangs that I've got on the radar. We
> have a reprodeucible test case for one issue but it only fails on one kind
> of system - x4450. I'm on vacation most of this week but will try and get
> back to this next week.
>
> Ariel: one thing to try please see if -XX:+UseMembar fixes the problem.
>
> Thanks,
> David Holmes
>
> -----Original Message-----
> *From:* Martin Buchholz [mailto:martinrb at google.com]
> *Sent:* Tuesday, 14 July 2009 8:38 AM
> *To:* Ariel Weisberg
> *Cc:* davidcholmes at aapt.net.au; core-libs-dev;
> concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] LinkedBlockingDeque deadlock?
>
>  I did some stack trace eyeballing and did a mini-audit of the
> LinkedBlockingDeque code, with a view to finding possible bugs,
> and came up empty.  Maybe it's a deep bug in hotspot?
>
> Ariel, it would be good if you could get a reproducible test case soonish,
> while someone on the planet has the motivation and familiarity to fix it.
> In another month I may disavow all knowledge of j.u.c.*Blocking*
>
> Martin
>
>
> On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg <ariel at weisberg.ws> wrote:
>
>> Hi,
>>
>> > The poll()ing thread is blocked waiting for the internal lock, but
>> > there's
>> > no indication of any thread owning that lock. You're using an OpenJDK 6
>> > build ... can you try JDK7 ?
>>
>> I got a chance to do that today. I downloaded JDK 7 from
>>
>> http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
>> and was able to reproduce the problem. I have attached the stack trace
>> from running the 1.7 version. It is the same situation as before except
>> there are 9 execution sites running on each host. There are no threads
>> that are missing or that have been restarted. Foo Network thread
>> (selector thread) and Network Thread - 0 are waiting on
>> 0x00002aaab43d3b28. I also ran with JDK 7 and 6 and LinkedBlockingQueue
>> and was not able to recreate the problem using that structure.
>>
>> > I don't recall anything similar to this, but I don't know what version
>> > that
>> > OpenJDK6 build relates to.
>>
>> The cluster is running on CentOS 5.3.
>> >[aweisberg at 3f ~]$ rpm -qi java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
>> >Name        : java-1.6.0-openjdk           Relocations: (not relocatable)
>> >Version     : 1.6.0.0                           Vendor: CentOS
>> >Release     : 0.30.b09.el5                  Build Date: Tue 07 Apr 2009
>> 07:24:52 PM EDT
>> >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build Host:
>> builder10.centos.org
>> >Group       : Development/Languages         Source RPM:
>> java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
>> >Size        : 76336266                         License: GPLv2 with
>> exceptions
>> >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key ID
>> a8a447dce8562897
>> >URL         : http://icedtea.classpath.org/
>> >Summary     : OpenJDK Runtime Environment
>> >Description :
>> >The OpenJDK runtime environment.
>>
>> > Make sure you haven't missed any exceptions occurring in other threads.
>> There are no threads missing in the application (terminated threads are
>> not replaced) and there is a try catch pair (prints error and rethrows)
>> around the run loop of each thread. It is possible that an exception may
>> have been swallowed up somewhere.
>>
>> >A small reproducible test case from you would be useful.
>> I am working on that. I wrote a test case that mimics the application's
>> use of the LBD, but I have not succeeded in reproducing the problem in
>> the test case. The app has a single thread (network selector) that polls
>> the LBD and several threads (ExecutionSites, and network threads that
>> return results from remote ExecutionSites) that offer results into the
>> queue. About 120k items will go into/out of the deque each second. In
>> the actual app the problem is reproducible but inconsistent. If I run on
>> my dual core laptop I can't reproduce it, and it is less likely to occur
>> with a small cluster, but with 6 nodes (~560k transactions/sec) the
>> problem will usually appear. Sometimes the cluster will run for several
>> minutes without issue and other times it will deadlock immediately.
>>
>> Thanks,
>>
>> Ariel
>>
>> On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
>> <martinrb at google.com> wrote:
>> >[+core-libs-dev]
>> >
>> >Doug Lea and I are (slowly) working on a new version of
>> LinkedBlockingDeque.
>> >I was not aware of a deadlock but can vaguely imagine how it might
>> happen.
>> >A small reproducible test case from you would be useful.
>> >
>> >Unfinished work in progress can be found here:
>> >http://cr.openjdk.java.net/~martin/webrevs/openjdk7/BlockingQueue/<http://cr.openjdk.java.net/%7Emartin/webrevs/openjdk7/BlockingQueue/>
>> >
>> >Martin
>>
>> On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"
>> <davidcholmes at aapt.net.au> wrote:
>> >
>>
>> > Ariel,
>> >
>> > The poll()ing thread is blocked waiting for the internal lock, but
>> > there's
>> > no indication of any thread owning that lock. You're using an OpenJDK 6
>> > build ... can you try JDK7 ?
>> >
>> > I don't recall anything similar to this, but I don't know what version
>> > that
>> > OpenJDK6 build relates to.
>> >
>> > Make sure you haven't missed any exceptions occurring in other threads.
>> >
>> > David Holmes
>> >
>> > > -----Original Message-----
>> > > From: concurrency-interest-bounces at cs.oswego.edu
>> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ariel
>> > > Weisberg
>> > > Sent: Wednesday, 8 July 2009 8:31 AM
>> > > To: concurrency-interest at cs.oswego.edu
>> > > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
>> > >
>> > >
>> > > Hi all,
>> > >
>> > > I did a search on LinkedBlockingDeque and didn't find anything similar
>> > > to what I am seeing. Attached is the stack trace from an application
>> > > that is deadlocked with three threads waiting for 0x00002aaab3e91080
>> > > (threads "ExecutionSite: 26", "ExecutionSite:27", and "Network
>> > > Selector"). The execution sites are attempting to offer results to the
>> > > deque and the network thread is trying to poll for them using the
>> > > non-blocking version of poll. I am seeing the network thread never
>> > > return from poll (straight poll()). Do my eyes deceive me?
>> > >
>> > > Thanks,
>> > >
>> > > Ariel Weisberg
>> > >
>> >
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090715/6834e8c9/attachment-0001.html>

From rbetts at gmail.com  Fri Jul 17 12:48:16 2009
From: rbetts at gmail.com (Ryan Betts)
Date: Fri, 17 Jul 2009 12:48:16 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock? (Test case)
In-Reply-To: <1ccfd1c10907151424t2f835a29y80a10228e0bc66c0@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<1247685852.19957.1325194693@webmail.messagingengine.com>
	<1ccfd1c10907151424t2f835a29y80a10228e0bc66c0@mail.gmail.com>
Message-ID: <8F046E81-CBFA-4185-A2A9-5E00D54CAE71@gmail.com>

Hello all,

I've been working with Ariel on the j.u.c.LinkedBlockingDeque deadlock  
we observe. The attached test case reproduces the deadlock  
intermittently, usually requiring several minutes. The test simply  
prints periods until it deadlocks. Attempts to produce a simpler test  
case using only ReentrantLock or without an ExecutorService were  
unsuccessful.

I've attached jstack reports showing the deadlocked case and the dmesg  
output from one of the servers that reproduces the defect. To date,  
this deadlock only occurs on our 2 socket i7s.

We have not filed a defect with Sun for this issue. If that would be  
helpful (or necessary), we would of course happily oblige.

$ java -version
java version "1.6.0"
OpenJDK  Runtime Environment (build 1.6.0-b09)
OpenJDK 64-Bit Server VM (build 1.6.0-b09, mixed mode)

$ uname -a
Linux host3e 2.6.18-128.1.16.el5 #1 SMP Tue Jun 30 06:07:26 EDT 2009  
x86_64 x86_64 x86_64 GNU/Linux

$ javac LBDLockPatternTest.java
$ java LBDLockPatternTest


Thank you,
*--Ryan.


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dmesg.txt
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090717/e80bd33c/attachment-0003.txt>
-------------- next part --------------


-------------- next part --------------
A non-text attachment was scrubbed...
Name: LBDLockPatternTest.java
Type: application/octet-stream
Size: 1703 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090717/e80bd33c/attachment-0001.obj>
-------------- next part --------------



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: jstack-24297.txt
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090717/e80bd33c/attachment-0004.txt>
-------------- next part --------------



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: jstack-25168.txt
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090717/e80bd33c/attachment-0005.txt>
-------------- next part --------------







From ashpublic at mac.com  Fri Jul 17 17:36:15 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Fri, 17 Jul 2009 22:36:15 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
Message-ID: <F4AA57B8-0F9E-4A5B-ABDE-7A6A22D0325C@mac.com>

Thanks to the many responses, just wanted to add a few more thoughts  
to this
thread to help any other concurrency newbies following behind me.

At first I found it difficult to see how to adapt my code to use  
immutable objects.
No matter how I baked it, I found myself removing problematic state  
from my
previously mutable classes, which rendered the code paths that could  
be seen by
different threads as nothing more than functions.

Now in itself this isn't a problem but since I have long ago abandoned  
inheritance
and to some extent "is-a" style interfaces, then this additional  
removal of state
means that the only OO feature I have left is encapsulation, i.e. the  
grouping of
like-minded methods in the same compilation unit. And even OO can't  
claim this
for itself.

Anyway to cut a long story short, if anybody else finds themselves  
with nagging
doubts about their long cherished OO practices, take a look at the  
following
URLs, In particular the superbly eloquent clojure link was a real eye  
opener to me:

http://clojure.org/state
http://www.scala-lang.org/

It almost feels like I'm starting again from scratch.

Cheers
- Ashley

On 1 Jul 2009, at 12:00, Ashley Williams wrote:

> Just looked at the Fences API and this is exactly what I was trying  
> to allude to.
>
> In fact I would personally prefer to see the explicit use of  
> Fences.preStoreFence()
> instead of relying on memory model guarantees through the use of  
> final. It would
> be all too easy for a developer to come along and mistakenly remove  
> the multi-purpose
> final keyword without appearing to break the code.
>
> Am I right in thinking most jvms would implement this by writing to  
> main memory (writes) and
> evicting entries from local memory (reads)? Just wondering about any  
> performance costs.
>
> So if one were to use both a final field modifier as well as a  
> fence, would the jvm be
> clever enough not pay the for the happens-before guarantee twice over?
>
> On 30 Jun 2009, at 21:46, Doug Lea wrote:
>
>> Peter Veentjer wrote:
>>
>>> PS: Do you have a reference to the other concurrency features that  
>>> are
>>> going to be added (apart from the fences and the fork/join
>>> functionality) to Java 7?
>>
>> Definitely planned classes are in package jsr166y --
>> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
>>
>> Plus Fences, which can't be previewed in jsr166y since
>> it relies on JVM support. See
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>>
>> Plus possibly some sort of customized hash map.
>> The main reason for delay on that is algorithmic:
>> Efficient support for features like eviction and
>> memoization across a large enough range of
>> policies to be worth supporting in concurrent maps is not a
>> fully solved problem. I want to make sure that
>> we offer only that range of them for which we are
>> very sure we can support well, but without closing
>> the door to future algorithmic overhauls.
>>
>> -Doug
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Fri Jul 17 22:14:59 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 18 Jul 2009 12:14:59 +1000
Subject: [concurrency-interest] LinkedBlockingDeque deadlock? (Test case)
In-Reply-To: <8F046E81-CBFA-4185-A2A9-5E00D54CAE71@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEKJICAA.davidcholmes@aapt.net.au>


Ryan,

Thanks very much for this.

When this "deadlocks" does top show whether the java process is actually
quiet or is it still consuming CPU? I notice that in the stack dump the main
thread is in the process of unlocking the lock that the other threads are
waiting upon and hence the system is not deadlocked - unless that main
thread is actually "stuck" somewhere. Can you take a series of stackdumps to
see if/how the main thread is executing?

Feel free to just send them to me rather than the mailing lists.

Thanks,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan
> Betts
> Sent: Saturday, 18 July 2009 2:48 AM
> To: concurrency-interest at cs.oswego.edu
> Cc: core-libs-dev
> Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock? (Test
> case)
>
>
> Hello all,
>
> I've been working with Ariel on the j.u.c.LinkedBlockingDeque deadlock
> we observe. The attached test case reproduces the deadlock
> intermittently, usually requiring several minutes. The test simply
> prints periods until it deadlocks. Attempts to produce a simpler test
> case using only ReentrantLock or without an ExecutorService were
> unsuccessful.
>
> I've attached jstack reports showing the deadlocked case and the dmesg
> output from one of the servers that reproduces the defect. To date,
> this deadlock only occurs on our 2 socket i7s.
>
> We have not filed a defect with Sun for this issue. If that would be
> helpful (or necessary), we would of course happily oblige.
>
> $ java -version
> java version "1.6.0"
> OpenJDK  Runtime Environment (build 1.6.0-b09)
> OpenJDK 64-Bit Server VM (build 1.6.0-b09, mixed mode)
>
> $ uname -a
> Linux host3e 2.6.18-128.1.16.el5 #1 SMP Tue Jun 30 06:07:26 EDT 2009
> x86_64 x86_64 x86_64 GNU/Linux
>
> $ javac LBDLockPatternTest.java
> $ java LBDLockPatternTest
>
>
> Thank you,
> *--Ryan.
>
>
>


From davidcholmes at aapt.net.au  Fri Jul 17 22:28:14 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 18 Jul 2009 12:28:14 +1000
Subject: [concurrency-interest] LinkedBlockingDeque deadlock? (Test case)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEKJICAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEKJICAA.davidcholmes@aapt.net.au>


Sorry Ryan, misread the stack trace. The main thread is interacting with the
executors LBQ not the application one.

I'll see if I can use this test to reproduce the issue on Monday.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David
> Holmes
> Sent: Saturday, 18 July 2009 12:15 PM
> To: Ryan Betts; concurrency-interest at cs.oswego.edu
> Cc: core-libs-dev
> Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock? (Test
> case)
>
>
>
>
> Ryan,
>
> Thanks very much for this.
>
> When this "deadlocks" does top show whether the java process is actually
> quiet or is it still consuming CPU? I notice that in the stack
> dump the main
> thread is in the process of unlocking the lock that the other threads are
> waiting upon and hence the system is not deadlocked - unless that main
> thread is actually "stuck" somewhere. Can you take a series of
> stackdumps to
> see if/how the main thread is executing?
>
> Feel free to just send them to me rather than the mailing lists.
>
> Thanks,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ryan
> > Betts
> > Sent: Saturday, 18 July 2009 2:48 AM
> > To: concurrency-interest at cs.oswego.edu
> > Cc: core-libs-dev
> > Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock? (Test
> > case)
> >
> >
> > Hello all,
> >
> > I've been working with Ariel on the j.u.c.LinkedBlockingDeque deadlock
> > we observe. The attached test case reproduces the deadlock
> > intermittently, usually requiring several minutes. The test simply
> > prints periods until it deadlocks. Attempts to produce a simpler test
> > case using only ReentrantLock or without an ExecutorService were
> > unsuccessful.
> >
> > I've attached jstack reports showing the deadlocked case and the dmesg
> > output from one of the servers that reproduces the defect. To date,
> > this deadlock only occurs on our 2 socket i7s.
> >
> > We have not filed a defect with Sun for this issue. If that would be
> > helpful (or necessary), we would of course happily oblige.
> >
> > $ java -version
> > java version "1.6.0"
> > OpenJDK  Runtime Environment (build 1.6.0-b09)
> > OpenJDK 64-Bit Server VM (build 1.6.0-b09, mixed mode)
> >
> > $ uname -a
> > Linux host3e 2.6.18-128.1.16.el5 #1 SMP Tue Jun 30 06:07:26 EDT 2009
> > x86_64 x86_64 x86_64 GNU/Linux
> >
> > $ javac LBDLockPatternTest.java
> > $ java LBDLockPatternTest
> >
> >
> > Thank you,
> > *--Ryan.
> >
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ben_manes at yahoo.com  Mon Jul 20 02:12:45 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Sun, 19 Jul 2009 23:12:45 -0700 (PDT)
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <F4AA57B8-0F9E-4A5B-ABDE-7A6A22D0325C@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
	<F4AA57B8-0F9E-4A5B-ABDE-7A6A22D0325C@mac.com>
Message-ID: <307163.58113.qm@web38805.mail.mud.yahoo.com>

If you design OO based on Alan Kay's definition then there usually isn't an impedance issue:

"I decided to leave out inheritance as a built-in feature until I understood it better... OOP to me means only messaging, local retention 
and protection and hiding of state-process, and extreme late-binding of all things. It can be done in Smalltalk and in LISP. There are
possibly other systems in which this is possible, but I'm not aware of them." -- Alan Kay

You can often mix functional programming ideas with object-oriented ideas and leverage a bottom-up, responsibility-driven approach.  It may only seem incompatible because Java is usually written in  a top-down OO model.




________________________________
From: Ashley Williams <ashpublic at mac.com>
To: concurrency-interest at cs.oswego.edu
Sent: Friday, July 17, 2009 2:36:15 PM
Subject: Re: [concurrency-interest] Immutable object conundrums

Thanks to the many responses, just wanted to add a few more thoughts to this
thread to help any other concurrency newbies following behind me.

At first I found it difficult to see how to adapt my code to use immutable objects.
No matter how I baked it, I found myself removing problematic state from my
previously mutable classes, which rendered the code paths that could be seen by
different threads as nothing more than functions.

Now in itself this isn't a problem but since I have long ago abandoned inheritance
and to some extent "is-a" style interfaces, then this additional removal of state
means that the only OO feature I have left is encapsulation, i.e. the grouping of
like-minded methods in the same compilation unit. And even OO can't claim this
for itself.

Anyway to cut a long story short, if anybody else finds themselves with nagging
doubts about their long cherished OO practices, take a look at the following
URLs, In particular the superbly eloquent clojure link was a real eye opener to me:

http://clojure.org/state
http://www.scala-lang.org/

It almost feels like I'm starting again from scratch.

Cheers
- Ashley

On 1 Jul 2009, at 12:00, Ashley Williams wrote:

> Just looked at the Fences API and this is exactly what I was trying to allude to.
> 
> In fact I would personally prefer to see the explicit use of Fences.preStoreFence()
> instead of relying on memory model guarantees through the use of final. It would
> be all too easy for a developer to come along and mistakenly remove the multi-purpose
> final keyword without appearing to break the code.
> 
> Am I right in thinking most jvms would implement this by writing to main memory (writes) and
> evicting entries from local memory (reads)? Just wondering about any performance costs.
> 
> So if one were to use both a final field modifier as well as a fence, would the jvm be
> clever enough not pay the for the happens-before guarantee twice over?
> 
> On 30 Jun 2009, at 21:46, Doug Lea wrote:
> 
>> Peter Veentjer wrote:
>> 
>>> PS: Do you have a reference to the other concurrency features that are
>>> going to be added (apart from the fences and the fork/join
>>> functionality) to Java 7?
>> 
>> Definitely planned classes are in package jsr166y --
>> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
>> 
>> Plus Fences, which can't be previewed in jsr166y since
>> it relies on JVM support. See
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
>> 
>> Plus possibly some sort of customized hash map.
>> The main reason for delay on that is algorithmic:
>> Efficient support for features like eviction and
>> memoization across a large enough range of
>> policies to be worth supporting in concurrent maps is not a
>> fully solved problem. I want to make sure that
>> we offer only that range of them for which we are
>> very sure we can support well, but without closing
>> the door to future algorithmic overhauls.
>> 
>> -Doug
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090719/ce1984f3/attachment.html>

From ashpublic at mac.com  Mon Jul 20 08:33:44 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Mon, 20 Jul 2009 13:33:44 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <307163.58113.qm@web38805.mail.mud.yahoo.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
	<F4AA57B8-0F9E-4A5B-ABDE-7A6A22D0325C@mac.com>
	<307163.58113.qm@web38805.mail.mud.yahoo.com>
Message-ID: <B90D70DC-425F-4692-B257-1E6FE54760C1@mac.com>

Thanks Ben for the quote, I'll add it to my collection. Or should I  
say create a new
collection based on the old one with one extra element - sorry bad joke!

I also came across a talk by Rich Hickey that I found very instructive  
if like me,
anyone is in the process of picking apart their programming style.
Although he talks about Clojure, the lessons translate very well into  
Java:

http://clojure.blip.tv/file/812787/

------------------------------------------------------------------------------------

It's quite long but you can probably skip the first 21 minutes and  
also stop halfway when he delves
into the Closure code. Oh but pick it up again for the last 15  
minutes. Here are some of the highlights:

* multimethods - like polymophism, but not just based on types, can be  
based on other conditions

* quote: "immutable objects are the new spaghetti code"

* at one point he recommends reading concurrency in practice and that  
it will scare you to death!

* he wrote java classes with static methods and no data, attracting  
looks of horror from colleagues

* whether we like it or not we're all concurrent programmers now since  
clock speeds have leveled off
    and cpu architecture has spread into multiple cores

* CopyOnWrite collections have weakness, still requires locks for  
compound actions and also mutator
    methods take a long time. I don't wish to misrepresent him, he  
admires the collection classes for
    their domain of application.

* Clojure uses immutable persistent data structures that retain read/ 
write access times (Big O) and is
    achieved by structural sharing techniques - nothing like this in  
the java libraries.

* "Secret-sauce" of Clojure is the persistent hashmap and vector  
structures - can never be any concurrent
    modification exceptions thrown from these immutable objects.

* Adding multithreaded behavior to single threaded logic (changing  
requirements) is close to impossible

* Closure has references to immutable targets but those references can  
change in a coordinated fashion

* quote: "Fake in-system threads are over", we now have real threads  
on real cpu cores.

* Refs are STM idiom, can only be reassigned inside a transaction.  
Under  the hood is a complex
    implementation that uses multiversion concurrency control. This  
keeps readers from blocking other
    readers/writers and also writers never block readers.

* Hopes that java language won't change any more, makes maintenance of  
Clojure more difficult

* Can use Clojure libraries from Java, Garbage collector loves Clojure.

This has answered at least one of my questions that immutable objects  
aren't a silver bullet - although
perhaps an alloy of 90% silver. You still have to worry about the  
parent (mutable) references, which in
Clojure is handled by an STM system. This is because with immutable  
objects, the world is a series
of snapshots that eventually have to be reconciled.

In Java it looks like I will have to roll my own reference strategy  
with locks and CAS techniques on top
level aggregate and it's not clear to me how this will work out. This  
task is where I feel there is a
scarcity of examples to follow.

------------------------------------------------------------------------------------

Just one more comment: I also found this paper that's worth a skim:

http://www.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-1.pdf

There is an excellent passage that I've pasted below, the tldr version  
is essentially that todays
multi-threaded programs are broken and we will begin to see this with  
increasing cpu cores:

"I speculate that most multithreaded programs
have such bugs. I speculate further that the bugs have not proved to  
be major handicaps only
because today?s architectures and operating systems deliver modest  
parallelism. The cost of context
switching is high, so only a tiny percentage of the possible  
interleavings of thread instructions
ever occur in practice. I conjecture that most multi-threaded general- 
purpose applications are, in
fact, so full of concurrency bugs that as multi-core architectures  
become commonplace, these bugs
will begin to show up as system failures. This scenario is bleak for  
computer vendors: their next
generation of machines will become widely known as the ones on which  
many programs crash.
These same computer vendors are advocating more multi-threaded  
programming, so that there
is concurrency that can exploit the parallelism they would like to  
sell us. Intel, for example, has
embarked on an active campaign to get leading computer science  
academic programs to put more
emphasis on multi-threaded programming. If they are successful, and  
the next generation of pro-
grammers makes more intensive use of multithreading, then the next  
generation of computers will
become nearly unusable."

On 20 Jul 2009, at 07:12, Ben Manes wrote:

> If you design OO based on Alan Kay's definition then there usually  
> isn't an impedance issue:
>
> "I decided to leave out inheritance as a built-in feature until I  
> understood it better... OOP to me means only messaging, local  
> retention
> and protection and hiding of state-process, and extreme late-binding  
> of all things. It can be done in Smalltalk and in LISP. There are
> possibly other systems in which this is possible, but I'm not aware  
> of them." -- Alan Kay
>
> You can often mix functional programming ideas with object-oriented  
> ideas and leverage a bottom-up, responsibility-driven approach.  It  
> may only seem incompatible because Java is usually written in a top- 
> down OO model.
>
> From: Ashley Williams <ashpublic at mac.com>
> To: concurrency-interest at cs.oswego.edu
> Sent: Friday, July 17, 2009 2:36:15 PM
> Subject: Re: [concurrency-interest] Immutable object conundrums
>
> Thanks to the many responses, just wanted to add a few more thoughts  
> to this
> thread to help any other concurrency newbies following behind me.
>
> At first I found it difficult to see how to adapt my code to use  
> immutable objects.
> No matter how I baked it, I found myself removing problematic state  
> from my
> previously mutable classes, which rendered the code paths that could  
> be seen by
> different threads as nothing more than functions.
>
> Now in itself this isn't a problem but since I have long ago  
> abandoned inheritance
> and to some extent "is-a" style interfaces, then this additional  
> removal of state
> means that the only OO feature I have left is encapsulation, i.e.  
> the grouping of
> like-minded methods in the same compilation unit. And even OO can't  
> claim this
> for itself.
>
> Anyway to cut a long story short, if anybody else finds themselves  
> with nagging
> doubts about their long cherished OO practices, take a look at the  
> following
> URLs, In particular the superbly eloquent clojure link was a real  
> eye opener to me:
>
> http://clojure.org/state
> http://www.scala-lang.org/
>
> It almost feels like I'm starting again from scratch.
>
> Cheers
> - Ashley
>
> On 1 Jul 2009, at 12:00, Ashley Williams wrote:
>
> > Just looked at the Fences API and this is exactly what I was  
> trying to allude to.
> >
> > In fact I would personally prefer to see the explicit use of  
> Fences.preStoreFence()
> > instead of relying on memory model guarantees through the use of  
> final. It would
> > be all too easy for a developer to come along and mistakenly  
> remove the multi-purpose
> > final keyword without appearing to break the code.
> >
> > Am I right in thinking most jvms would implement this by writing  
> to main memory (writes) and
> > evicting entries from local memory (reads)? Just wondering about  
> any performance costs.
> >
> > So if one were to use both a final field modifier as well as a  
> fence, would the jvm be
> > clever enough not pay the for the happens-before guarantee twice  
> over?
> >
> > On 30 Jun 2009, at 21:46, Doug Lea wrote:
> >
> >> Peter Veentjer wrote:
> >>
> >>> PS: Do you have a reference to the other concurrency features  
> that are
> >>> going to be added (apart from the fences and the fork/join
> >>> functionality) to Java 7?
> >>
> >> Definitely planned classes are in package jsr166y --
> >> ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
> >> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
> >>
> >> Plus Fences, which can't be previewed in jsr166y since
> >> it relies on JVM support. See
> >> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html
> >>
> >> Plus possibly some sort of customized hash map.
> >> The main reason for delay on that is algorithmic:
> >> Efficient support for features like eviction and
> >> memoization across a large enough range of
> >> policies to be worth supporting in concurrent maps is not a
> >> fully solved problem. I want to make sure that
> >> we offer only that range of them for which we are
> >> very sure we can support well, but without closing
> >> the door to future algorithmic overhauls.
> >>
> >> -Doug
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090720/998697ac/attachment-0001.html>

From ashpublic at mac.com  Mon Jul 20 09:35:47 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Mon, 20 Jul 2009 14:35:47 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <90622e530907200626s6c62d21cs4ca2a895d2d6ee9c@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
	<4A4A79AE.7020603@cs.oswego.edu>
	<C51BB0DD-8DF2-4460-9BF1-9F276F81171B@mac.com>
	<F4AA57B8-0F9E-4A5B-ABDE-7A6A22D0325C@mac.com>
	<307163.58113.qm@web38805.mail.mud.yahoo.com>
	<B90D70DC-425F-4692-B257-1E6FE54760C1@mac.com>
	<90622e530907200626s6c62d21cs4ca2a895d2d6ee9c@mail.gmail.com>
Message-ID: <7D7ECC9C-D9E4-46FE-A84C-693F73C90D40@mac.com>

On 20 Jul 2009, at 14:26, Christian Vest Hansen wrote:

> On Mon, Jul 20, 2009 at 2:33 PM, Ashley Williams<ashpublic at mac.com>  
> wrote:
>> I also came across a talk by Rich Hickey that I found very  
>> instructive if
>> like me,
>> anyone is in the process of picking apart their programming style.
> (...)
>> * quote: "immutable objects are the new spaghetti code"
>
> I'm not quite sure he said that ;)
>

I was about to correct you but then I saw the typo!
Ahem: "Mutable objects are the new spaghetti code"


From normelton at gmail.com  Mon Jul 20 11:58:06 2009
From: normelton at gmail.com (Norman Elton)
Date: Mon, 20 Jul 2009 11:58:06 -0400
Subject: [concurrency-interest] Serialized ThreadPoolExecutor
Message-ID: <6b3a7f010907200858r20c1488gb6285eca69a31ea9@mail.gmail.com>

I've got a ThreadPoolExecutor that runs tasks. I would like certain
tasks that implement the LockingJob interface to have a "locking key":

public interface LockingJob {
   public Object getLockingKey();
}

In this instance, the queue would serialize any jobs sharing a locking
key. If two jobs come in with key "A", the first must finish executing
before the second begins. Meanwhile, tasks that do not share that key
continue to execute as expected.

I've done this before with a Map<Object,List<Runnable>> that maps a
locking key to a list of jobs queued up. When a job is added to the
queue, the executor first checks to see if a "holding queue" exists.
If so, the job is appended to the list. If not, it is executed
immediately. When a job is completed, another is popped off the
holding queue and executed. Problem is, I have to synchronize around
this holding queue, which seems to introduce a lot of overhead.

Is there a better way to accomplish what I'm after? Am I completely crazy?

Thanks,

Norman

From normelton at gmail.com  Mon Jul 20 13:31:39 2009
From: normelton at gmail.com (Norman Elton)
Date: Mon, 20 Jul 2009 13:31:39 -0400
Subject: [concurrency-interest] Serialized ThreadPoolExecutor
In-Reply-To: <e0563fd80907200935l4dd56a7eh9f4eab21acb8f970@mail.gmail.com>
References: <6b3a7f010907200858r20c1488gb6285eca69a31ea9@mail.gmail.com>
	<e0563fd80907200935l4dd56a7eh9f4eab21acb8f970@mail.gmail.com>
Message-ID: <6b3a7f010907201031h1f345731kccdea5d304763a2e@mail.gmail.com>

Erkin & Jim,

Thanks for your replies. It seems that both your suggestions have a
common downside... If I do the locking inside the job, then a
"waiting" job will occupy one of the threads in my pool. If ten jobs
come in with the same "key", each of which takes one second to
execute, that could impact unrelated jobs. I'd rather other jobs
continue to be scheduled and executed.

Thoughts?

Thanks again,

Norman

From joe.bowbeer at gmail.com  Mon Jul 20 15:14:29 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 20 Jul 2009 12:14:29 -0700
Subject: [concurrency-interest] Serialized ThreadPoolExecutor
In-Reply-To: <6b3a7f010907200858r20c1488gb6285eca69a31ea9@mail.gmail.com>
References: <6b3a7f010907200858r20c1488gb6285eca69a31ea9@mail.gmail.com>
Message-ID: <31f2a7bd0907201214v5f9f511h16ebaa1ea857588@mail.gmail.com>

I'm assuming you've already seen the simple, delegating SerialExecutor
example in the javadoc:

http://java.sun.com/javase/6/docs/api/java/util/concurrent/Executor.html

and that you are looking for an efficient way to map a task to its
serial-executor?

If the total number of locking keys is manageable, I'd recommend using a
ConcurrentMap and putIfAbsent.  There's a small up-front construction cost,
but SerialExecutor is fairly cheap.  The disadvantage is that map entries
will accumulate, but this may not be a problem.

If the total number of locking keys (hence the number serial executors) is
not manageable then I'm currently at a loss.

Joe

On Mon, Jul 20, 2009 at 8:58 AM, Norman Elton wrote:

> I've got a ThreadPoolExecutor that runs tasks. I would like certain
> tasks that implement the LockingJob interface to have a "locking key":
>
> public interface LockingJob {
>   public Object getLockingKey();
> }
>
> In this instance, the queue would serialize any jobs sharing a locking
> key. If two jobs come in with key "A", the first must finish executing
> before the second begins. Meanwhile, tasks that do not share that key
> continue to execute as expected.
>
> I've done this before with a Map<Object,List<Runnable>> that maps a
> locking key to a list of jobs queued up. When a job is added to the
> queue, the executor first checks to see if a "holding queue" exists.
> If so, the job is appended to the list. If not, it is executed
> immediately. When a job is completed, another is popped off the
> holding queue and executed. Problem is, I have to synchronize around
> this holding queue, which seems to introduce a lot of overhead.
>
> Is there a better way to accomplish what I'm after? Am I completely crazy?
>
> Thanks,
>
> Norman
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090720/bf60fc49/attachment.html>

From ariel at weisberg.ws  Tue Jul 21 15:52:33 2009
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Tue, 21 Jul 2009 15:52:33 -0400
Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
In-Reply-To: <1ccfd1c10907151424t2f835a29y80a10228e0bc66c0@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEJGICAA.davidcholmes@aapt.net.au>
	<1247540368.18990.1324916035@webmail.messagingengine.com>
	<1247685852.19957.1325194693@webmail.messagingengine.com>
	<1ccfd1c10907151424t2f835a29y80a10228e0bc66c0@mail.gmail.com>
Message-ID: <1248205953.1518.1326134111@webmail.messagingengine.com>

Hi all,

It tooks a while for me to convince ourselves that this wasn't an
application problem. I am attaching a test case that reliably
reproduces the dead socket problem on some systems. The flow is
essentially the same as the networking code in our messaging
system.

I had the best luck reproducing this on Dell Poweredge 2970s (two
socket AMD) running CentOS 5.3. I dual booted two of them with
Ubuntu server 9.04 and have not succeded in reproducing the
problem with Ubuntu. I was not able to reproduce the problem on
the Dell R610 (2 socket Nehalem) machines running CentOS 5.3 with
the test application although the actual app (messaging system)
does have this issue on the 610s.

I am very interested in hearing about what happens when other
people run it. I am also interested in confirming that this is a
sane use of Selectors, SocketChannels, and SelectionKeys.

Thanks,
Ariel Weisberg

On Wed, 15 Jul 2009 14:24 -0700, "Martin Buchholz"
<martinrb at google.com> wrote:

  In summary,
  there are two different bugs at work here,
  and neither of them is in LBD.
  The hotspot team is working on the LBD deadlock.
  (As always) It would be good to have a good test case for
  the dead socket problem.
  Martin

On Wed, Jul 15, 2009 at 12:24, Ariel Weisberg
<[1]ariel at weisberg.ws> wrote:

Hi,

I have found that there are two different failure modes without
involving -XX:+UseMembar. There is the LBD deadlock and then
there is the dead socket in between two nodes. Either failure can
occur with the same code and settings. It appears that the dead
socket problem is more common. The LBD failure is also not
correlated with any specific LBD (originally saw it with only the
LBD for an Initiator's mailbox).

With -XX:+UseMembar the system is noticeably more reliable and
tends to run much longer without failing (although it can still
fail immediately). When it does fail it has been due to a dead
connection. I have not reproduced a deadlock on an LBD with
-XX:+UseMembar.

I also found that the dead socket issue was reproducible twice on
Dell Poweredge 2970s (two socket AMD). It takes an hour or so to
reproduce the dead socket problem on the 2970. I have not
recreated the LBD issue on them although given how difficult the
socket issue is to reproduce it may be that I have not run them
long enough. On the AMD machines I did not use -XX:+UseMembar.

Ariel


On Mon, 13 Jul 2009 18:59 -0400, "Ariel Weisberg"
<[2]ariel at weisberg.ws> wrote:

Hi all.

Sorry Martin I missed reading your last email. I am not confident
that I will get a small reproducible test case in a reasonable
time frame. Reproducing it with the application is easy and I
will see what I can do about getting the source available.

One interesting thing I can tell you is that if I remove the
LinkedBlockingDeque from the mailbox of the Initiator the system
still deadlocks. The cluster has a TCP mesh topology so any node
can deliver messages to any other node. One of the connections
goes dead and neither side detects that there is a problem. I add
some assertions to the network selection thread to check that all
the connections in the cluster are still healthy and assert that
they have the correct interests set.

Here are the things it checks for  to make sure each connection
is working:
>                             for (ForeignHost.Port port :
foreignHostPorts) {
>
assert(port.m_selectionKey.isValid());
>
assert(port.m_selectionKey.selector() == m_selector);
>                             assert(port.m_channel.isOpen());
>
assert(((SocketChannel)port.m_channel).isConnected());
>
assert(((SocketChannel)port.m_channel).socket().isInputShutdown()
== false);
>
assert(((SocketChannel)port.m_channel).socket().isOutputShutdown(
) == false);
>
assert(((SocketChannel)port.m_channel).isOpen());
>
assert(((SocketChannel)port.m_channel).isRegistered());
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) !=
null);
>
assert(((SocketChannel)port.m_channel).keyFor(m_selector) ==
port.m_selectionKey);
>                             if
(m_selector.selectedKeys().contains(port.m_selectionKey)) {
>
assert((port.m_selectionKey.interestOps() & SelectionKey.OP_READ)
!= 0);
>
assert((port.m_selectionKey.interestOps() &
SelectionKey.OP_WRITE) != 0);
>                             } else {
>                                 if (port.isRunning()) {
>
assert(port.m_selectionKey.interestOps() == 0);
>                                 } else {
>
port.m_selectionKey.interestOps(SelectionKey.OP_READ |
SelectionKey.OP_WRITE);
>                                     assert((port.interestOps()
& SelectionKey.OP_READ) != 0);
>                                     assert((port.interestOps()
& SelectionKey.OP_WRITE) != 0);
>                                 }
>                             }
>                             assert(m_selector.isOpen());
>
assert(m_selector.keys().contains(port.m_selectionKey));
OP_READ | OP_WRITE is set as the interest ops every time through,
and there is no other code that changes the interest ops during
execution. The application will run for a while and then one of
the connections will stop being selected on both sides. If I step
in with the debugger on either side everything looks correct. The
keys have the correct interest ops and the selectors have the
keys in their key set.

What I suspect is happening is that a bug on one node stops the
socket from being selected (for both read and write), and
eventually the socket fills up and can't be written to by the
other side.

If I can get my VPN access together tomorrow I will run with
-XX:+UseMembar and also try running on some 8-core AMD machines.
Otherwise I will have to get to it Wednesday.

Thanks,

Ariel Weisberg


On Tue, 14 Jul 2009 05:00 +1000, "David Holmes"
<[3]davidcholmes at aapt.net.au> wrote:

Martin,



I don't think this is due to LBQ/D. This is looking similar to a
couple of other ReentrantLock/AQS "lost wakeup" hangs that I've
got on the radar. We have a reprodeucible test case for one issue
but it only fails on one kind of system - x4450. I'm on vacation
most of this week but will try and get back to this next week.



Ariel: one thing to try please see if -XX:+UseMembar fixes the
problem.



Thanks,

David Holmes

-----Original Message-----
From: Martin Buchholz [mailto:[4]martinrb at google.com]
Sent: Tuesday, 14 July 2009 8:38 AM
To: Ariel Weisberg
Cc: [5]davidcholmes at aapt.net.au; core-libs-dev;
[6]concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] LinkedBlockingDeque deadlock?

  I did some stack trace eyeballing and did a mini-audit of the
  LinkedBlockingDeque code, with a view to finding possible
  bugs,
  and came up empty.  Maybe it's a deep bug in hotspot?
  Ariel, it would be good if you could get a reproducible test
  case soonish,
  while someone on the planet has the motivation and familiarity
  to fix it.
  In another month I may disavow all knowledge of
  j.u.c.*Blocking*
  Martin

On Wed, Jul 8, 2009 at 15:57, Ariel Weisberg
<[7]ariel at weisberg.ws> wrote:

  Hi,

> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?


  I got a chance to do that today. I downloaded JDK 7 from
  [8]http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63
  -linux-x64-02_jul_2009.bin
  and was able to reproduce the problem. I have attached the
  stack trace
  from running the 1.7 version. It is the same situation as
  before except
  there are 9 execution sites running on each host. There are no
  threads
  that are missing or that have been restarted. Foo Network
  thread
  (selector thread) and Network Thread - 0 are waiting on
  0x00002aaab43d3b28. I also ran with JDK 7 and 6 and
  LinkedBlockingQueue
  and was not able to recreate the problem using that structure.

> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.


  The cluster is running on CentOS 5.3.
  >[aweisberg at 3f ~]$ rpm -qi
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5
  >Name        : java-1.6.0-openjdk           Relocations: (not
  relocatable)
  >Version     : 1.6.0.0                           Vendor:
  CentOS
  >Release     : 0.30.b09.el5                  Build Date: Tue
  07 Apr 2009 07:24:52 PM EDT
  >Install Date: Thu 11 Jun 2009 03:27:46 PM EDT      Build
  Host: [9]builder10.centos.org
  >Group       : Development/Languages         Source RPM:
  java-1.6.0-openjdk-1.6.0.0-0.30.b09.el5.src.rpm
  >Size        : 76336266                         License: GPLv2
  with exceptions
  >Signature   : DSA/SHA1, Wed 08 Apr 2009 07:55:13 AM EDT, Key
  ID a8a447dce8562897
  >URL         : [10]http://icedtea.classpath.org/
  >Summary     : OpenJDK Runtime Environment
  >Description :
  >The OpenJDK runtime environment.

> Make sure you haven't missed any exceptions occurring in other
threads.

  There are no threads missing in the application (terminated
  threads are
  not replaced) and there is a try catch pair (prints error and
  rethrows)
  around the run loop of each thread. It is possible that an
  exception may
  have been swallowed up somewhere.

>A small reproducible test case from you would be useful.

  I am working on that. I wrote a test case that mimics the
  application's
  use of the LBD, but I have not succeeded in reproducing the
  problem in
  the test case. The app has a single thread (network selector)
  that polls
  the LBD and several threads (ExecutionSites, and network
  threads that
  return results from remote ExecutionSites) that offer results
  into the
  queue. About 120k items will go into/out of the deque each
  second. In
  the actual app the problem is reproducible but inconsistent.
  If I run on
  my dual core laptop I can't reproduce it, and it is less
  likely to occur
  with a small cluster, but with 6 nodes (~560k
  transactions/sec) the
  problem will usually appear. Sometimes the cluster will run
  for several
  minutes without issue and other times it will deadlock
  immediately.
  Thanks,
  Ariel

On Wed, 08 Jul 2009 05:14 +1000, "Martin Buchholz"
<[11]martinrb at google.com> wrote:
>[+core-libs-dev]
>
>Doug Lea and I are (slowly) working on a new version of
LinkedBlockingDeque.
>I was not aware of a deadlock but can vaguely imagine how it
might happen.
>A small reproducible test case from you would be useful.
>
>Unfinished work in progress can be found here:
>[12]http://cr.openjdk.java.net/~martin/webrevs/openjdk7/Blocking
Queue/
>
>Martin


  On Wed, 08 Jul 2009 05:14 +1000, "David Holmes"

<[13]davidcholmes at aapt.net.au> wrote:
>


> Ariel,
>
> The poll()ing thread is blocked waiting for the internal lock,
but
> there's
> no indication of any thread owning that lock. You're using an
OpenJDK 6
> build ... can you try JDK7 ?
>
> I don't recall anything similar to this, but I don't know what
version
> that
> OpenJDK6 build relates to.
>
> Make sure you haven't missed any exceptions occurring in other
threads.
>
> David Holmes
>
> > -----Original Message-----
> > From: [14]concurrency-interest-bounces at cs.oswego.edu
> > [mailto:[15]concurrency-interest-bounces at cs.oswego.edu]On
Behalf Of Ariel
> > Weisberg
> > Sent: Wednesday, 8 July 2009 8:31 AM
> > To: [16]concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] LinkedBlockingDeque deadlock?
> >
> >
> > Hi all,
> >
> > I did a search on LinkedBlockingDeque and didn't find
anything similar
> > to what I am seeing. Attached is the stack trace from an
application
> > that is deadlocked with three threads waiting for
0x00002aaab3e91080
> > (threads "ExecutionSite: 26", "ExecutionSite:27", and
"Network
> > Selector"). The execution sites are attempting to offer
results to the
> > deque and the network thread is trying to poll for them using
the
> > non-blocking version of poll. I am seeing the network thread
never
> > return from poll (straight poll()). Do my eyes deceive me?
> >
> > Thanks,
> >
> > Ariel Weisberg
> >
>

  _______________________________________________
  Concurrency-interest mailing list
  [17]Concurrency-interest at cs.oswego.edu
  [18]http://cs.oswego.edu/mailman/listinfo/concurrency-interest

References

1. mailto:ariel at weisberg.ws
2. mailto:ariel at weisberg.ws
3. mailto:davidcholmes at aapt.net.au
4. mailto:martinrb at google.com
5. mailto:davidcholmes at aapt.net.au
6. mailto:concurrency-interest at cs.oswego.edu
7. mailto:ariel at weisberg.ws
8. http://www.java.net/download/jdk7/binaries/jdk-7-ea-bin-b63-linux-x64-02_jul_2009.bin
9. http://builder10.centos.org/
  10. http://icedtea.classpath.org/
  11. mailto:martinrb at google.com
  12. http://cr.openjdk.java.net/%7Emartin/webrevs/openjdk7/BlockingQueue/
  13. mailto:davidcholmes at aapt.net.au
  14. mailto:concurrency-interest-bounces at cs.oswego.edu
  15. mailto:concurrency-interest-bounces at cs.oswego.edu
  16. mailto:concurrency-interest at cs.oswego.edu
  17. mailto:Concurrency-interest at cs.oswego.edu
  18. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090721/c2f53c4a/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: TCPThroughput.java
Type: text/x-java
Size: 15838 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090721/c2f53c4a/attachment-0001.bin>

From richhickey at gmail.com  Wed Jul 22 10:23:34 2009
From: richhickey at gmail.com (Rich Hickey)
Date: Wed, 22 Jul 2009 10:23:34 -0400
Subject: [concurrency-interest] Composing ForkJoin tasks
Message-ID: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>

There are many instances in FJ where it states "This method may be
invoked only from within ForkJoinTask computations." Is
ForkJoinTask.getPool() the correct way to detect when one is within a
ForkJoinTask computation?

It seems desirable if one is in a ForkJoin task and needs to execute
others, it would be preferable to fork/invokeAll them rather than use
a fresh ForkJoinPool.execute, or does it not matter much?

Obviously in a centrally-authored nested computation one knows what's
going on, the situation I'm talking about is arbitrary nested
composition of generic things like parallel map functions.

Is ForkJoinTask.getPool() guaranteed to be safe and valid from any
thread, and a sufficient indicator of running "within a ForkJoinTask
computation"? If so, I think perhaps its doc string could better
indicate that, something like:

"Returns the pool hosting the current task execution, or null if the
current thread is executing outside of any ForkJoin computation."

Rich

From dl at cs.oswego.edu  Wed Jul 22 10:42:22 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 22 Jul 2009 10:42:22 -0400
Subject: [concurrency-interest] Composing ForkJoin tasks
In-Reply-To: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>
References: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>
Message-ID: <4A67254E.10200@cs.oswego.edu>

Rich Hickey wrote:
> There are many instances in FJ where it states "This method may be
> invoked only from within ForkJoinTask computations." Is
> ForkJoinTask.getPool() the correct way to detect when one is within a
> ForkJoinTask computation?

Yes. The reason there is no other method is just that
no name for such a method seems to be better than writing
if (ForkJoinTask.getPool() == null)...

If you can think of one, feel free to suggest it.

> 
> It seems desirable if one is in a ForkJoin task and needs to execute
> others, it would be preferable to fork/invokeAll them rather than use
> a fresh ForkJoinPool.execute, or does it not matter much?

It is definitely faster, although ...

> 
> Obviously in a centrally-authored nested computation one knows what's
> going on, the situation I'm talking about is arbitrary nested
> composition of generic things like parallel map functions.

... in the case of a full nested parallel computation, it is
not as likely to matter as much.

> 
> Is ForkJoinTask.getPool() guaranteed to be safe and valid from any
> thread, and a sufficient indicator of running "within a ForkJoinTask
> computation"? If so, I think perhaps its doc string could better
> indicate that, something like:
> 
> "Returns the pool hosting the current task execution, or null if the
> current thread is executing outside of any ForkJoin computation."
> 

Done; thanks.

-Doug

From gregg at cytetech.com  Wed Jul 22 11:31:28 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 22 Jul 2009 10:31:28 -0500
Subject: [concurrency-interest] Composing ForkJoin tasks
In-Reply-To: <4A67254E.10200@cs.oswego.edu>
References: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>
	<4A67254E.10200@cs.oswego.edu>
Message-ID: <4A6730D0.1020401@cytetech.com>

Doug Lea wrote:
> Rich Hickey wrote:
>> There are many instances in FJ where it states "This method may be
>> invoked only from within ForkJoinTask computations." Is
>> ForkJoinTask.getPool() the correct way to detect when one is within a
>> ForkJoinTask computation?
> 
> Yes. The reason there is no other method is just that
> no name for such a method seems to be better than writing
> if (ForkJoinTask.getPool() == null)...
> 
> If you can think of one, feel free to suggest it.

The only obvious thing to me is to just provide something like the following

public static boolean inForkJoinPool() {
	return getPool() == null;
}

Convenience methods, with useful names, can be helpful in many cases to better 
convey that you are detecting a predictable situation rather than looking for a 
bad situation where null checks generally seem to appear.

Gregg Wonderly

From dl at cs.oswego.edu  Wed Jul 22 14:54:29 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 22 Jul 2009 14:54:29 -0400
Subject: [concurrency-interest] Composing ForkJoin tasks
In-Reply-To: <4A6730D0.1020401@cytetech.com>
References: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>
	<4A67254E.10200@cs.oswego.edu> <4A6730D0.1020401@cytetech.com>
Message-ID: <4A676065.100@cs.oswego.edu>

Gregg Wonderly wrote:
> The only obvious thing to me is to just provide something like the 
> following
> 
> public static boolean inForkJoinPool() {
>     return getPool() == null;
> }
> 

Good idea; thanks; done. This allows adding
"(as may be determined using method {@link #inForkJoinPool})"
to javadocs for FJ-only methods, which should forestall some confusion.

While I'm at it:

We are planning for openjdk integration of jsr166y stuff soon.
So if any members of this list have been wanting to read through
documentation or code and offer suggestions, now (over the next
week) would be a great time to do it -- things are harder to
change once committed into JDK.


-Doug

From dl at cs.oswego.edu  Thu Jul 23 09:08:55 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 23 Jul 2009 09:08:55 -0400
Subject: [concurrency-interest] Building extra166y with ant
In-Reply-To: <4A538E17.9020204@uni-muenster.de>
References: <4A538E17.9020204@uni-muenster.de>
Message-ID: <4A6860E7.8090007@cs.oswego.edu>

Sorry for the long delay on this...

Armin Hopp wrote:
> Hi,
> 
> I tried buildung the extra166y package using ant and the supplied
> build.xml from the lastest cvs (06-07-2009). Anyways it didn't work
> until I edited the build.xml's extra166ycompile target. I added

Sorry for problems; I updated the build file to work when
jsr166y is not already on your path.

-Doug

From gregg at cytetech.com  Thu Jul 23 12:01:50 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 23 Jul 2009 11:01:50 -0500
Subject: [concurrency-interest] Composing ForkJoin tasks
In-Reply-To: <4A676065.100@cs.oswego.edu>
References: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>
	<4A67254E.10200@cs.oswego.edu> <4A6730D0.1020401@cytetech.com>
	<4A676065.100@cs.oswego.edu>
Message-ID: <4A68896E.9060704@cytetech.com>

Doug Lea wrote:
> Gregg Wonderly wrote:
>> The only obvious thing to me is to just provide something like the 
>> following
>>
>> public static boolean inForkJoinPool() {
>>     return getPool() == null;
>> }

And I guess it would help if I actually typed what I meant.  The == should be != 
for correctness :-)

Gregg Wonderly

> 
> Good idea; thanks; done. This allows adding
> "(as may be determined using method {@link #inForkJoinPool})"
> to javadocs for FJ-only methods, which should forestall some confusion.
> 
> While I'm at it:
> 
> We are planning for openjdk integration of jsr166y stuff soon.
> So if any members of this list have been wanting to read through
> documentation or code and offer suggestions, now (over the next
> week) would be a great time to do it -- things are harder to
> change once committed into JDK.
> 
> 
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


From brian at briangoetz.com  Fri Jul 24 23:03:28 2009
From: brian at briangoetz.com (Brian Goetz)
Date: Fri, 24 Jul 2009 23:03:28 -0400
Subject: [concurrency-interest] Composing ForkJoin tasks
In-Reply-To: <4A676065.100@cs.oswego.edu>
References: <f48f022a0907220723rd96979buca4f520a4c74aaf2@mail.gmail.com>	<4A67254E.10200@cs.oswego.edu>
	<4A6730D0.1020401@cytetech.com> <4A676065.100@cs.oswego.edu>
Message-ID: <4A6A7600.3000205@briangoetz.com>

> We are planning for openjdk integration of jsr166y stuff soon.
> So if any members of this list have been wanting to read through
> documentation or code and offer suggestions, now (over the next
> week) would be a great time to do it -- things are harder to
> change once committed into JDK.

It's worth noting that a significant percentage of refereed changes to JUC 
code has been doc changes; in some cases it's been too late to really make the 
spec changes we wanted because we weren't tight enough initially.  So please, 
now is the time to read those over and be as picky as you can.



From R.Spilker at topdesk.com  Tue Jul 28 20:11:14 2009
From: R.Spilker at topdesk.com (=?windows-1252?Q?Roel_Spilker?=)
Date: Wed, 29 Jul 2009 02:11:14 +0200
Subject: [concurrency-interest] Project Lombok: synchronization on private
 field without the boilerplate
Message-ID: <vmime.4a6f93a2.7fd6.6cda890b7f5b312d@mona.topdesk.com>

Hi all,
?
I think you might find this interesting:
?
Project Lombok extends both Eclipse and your javac with a few new language features, and one of them is useful for concurrency: By annotating any method with @Synchronized, the method is synchronized, but not on itself ('this'), but on an automatically created private final field named "$lock".?Also works with static methods (static $LOCK is generated), and you can specify your own lock (though in that case, you'll have to write the field yourself) as well. It's even smart enough to initialize the lock variable with "new Object[0];" instead of the usual "new Object();", because the former serializes just fine whereas the latter won't.
?
Full Disclosure: It's my project (with the help from some friends).
?
?
Project Lombok might be the solution for the ParallelArray issue: Now we no longer need closures to make using parallel array acceptable. Something like this:
?
for (@Parallel String name : names ) {
?? ?System.out.println("Look ma! " + name + " is running in parallel!");
}
?
could be automatically translated to the proper ParallelArray calls and accompanying anonymous inner class literal for the foreach body. 'final' could even be added to any referenced local variables (or, to go even further, wrap them in an AtomicReference!)
?
There's a less than 4 minute video on the front page that demonstrates how it works and walks you through the installation process.
?
Let me know what you think! http://projectlombok.org/ 
?
?

?--Roel Spilker






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090729/2cd79369/attachment.html>

From karmazilla at gmail.com  Fri Jul 31 10:17:18 2009
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Fri, 31 Jul 2009 16:17:18 +0200
Subject: [concurrency-interest] ConcurrentHashSet?
Message-ID: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>

I have on multiple occasions found myself wanting a ConcurrentHashSet
that is to ConcurrentHashMap as HashSet is to HashMap. Yet I find no
such class in java.util.concurrent.

Is this because ConcurrentSkipListSet and CopyOnWriteArraySet in
between them pretty much covers the ground for concurrent sets? I can
sort of intuit the performance pattern I can expect from
CopyOnWriteArraySet, but I an unsure about ConcurrentSkipListSet.
Also, I'm often not terribly interested in the contract that follows
use of a SortedSet.

-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.

From elizarov at devexperts.com  Fri Jul 31 10:40:35 2009
From: elizarov at devexperts.com (Roman Elizarov)
Date: Fri, 31 Jul 2009 18:40:35 +0400
Subject: [concurrency-interest] ConcurrentHashSet?
In-Reply-To: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>
References: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>
Message-ID: <509706833.20090731184035@devexperts.com>

Hello Christian!

You can use Collections.newSetFromMap(new ConcurrentHashMap()).
There is no need to have a separate "ConcurrentHashSet" class, since
sets in java.util (like HashSet) are typically wrappers over
corresponding Map implementations.

Sincerely,
Roman Elizarov

On Friday, July 31, 2009 6:17:18 PM you wrote:

CVH> I have on multiple occasions found myself wanting a ConcurrentHashSet
CVH> that is to ConcurrentHashMap as HashSet is to HashMap. Yet I find no
CVH> such class in java.util.concurrent.

CVH> Is this because ConcurrentSkipListSet and CopyOnWriteArraySet in
CVH> between them pretty much covers the ground for concurrent sets? I can
CVH> sort of intuit the performance pattern I can expect from
CVH> CopyOnWriteArraySet, but I an unsure about ConcurrentSkipListSet.
CVH> Also, I'm often not terribly interested in the contract that follows
CVH> use of a SortedSet.





From david.lloyd at redhat.com  Fri Jul 31 10:58:53 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 31 Jul 2009 09:58:53 -0500
Subject: [concurrency-interest] ConcurrentHashSet?
In-Reply-To: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>
References: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>
Message-ID: <4A7306AD.3050207@redhat.com>

On 07/31/2009 09:17 AM, Christian Vest Hansen wrote:
> I have on multiple occasions found myself wanting a ConcurrentHashSet
> that is to ConcurrentHashMap as HashSet is to HashMap. Yet I find no
> such class in java.util.concurrent.

You could use use Collections.<XX>newSetFromMap(new 
ConcurrentHashMap<XX,Boolean>(...));

- DML

From karmazilla at gmail.com  Fri Jul 31 16:26:43 2009
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Fri, 31 Jul 2009 22:26:43 +0200
Subject: [concurrency-interest] ConcurrentHashSet?
In-Reply-To: <4A7306AD.3050207@redhat.com>
References: <90622e530907310717u1c8411fjb53fa089d100372c@mail.gmail.com>
	<4A7306AD.3050207@redhat.com>
Message-ID: <90622e530907311326v487e190fp71e33a032e2e600@mail.gmail.com>

Ah, nice! Thanks both of you.

On Fri, Jul 31, 2009 at 4:58 PM, David M. Lloyd<david.lloyd at redhat.com> wrote:
> On 07/31/2009 09:17 AM, Christian Vest Hansen wrote:
>>
>> I have on multiple occasions found myself wanting a ConcurrentHashSet
>> that is to ConcurrentHashMap as HashSet is to HashMap. Yet I find no
>> such class in java.util.concurrent.
>
> You could use use Collections.<XX>newSetFromMap(new
> ConcurrentHashMap<XX,Boolean>(...));
>
> - DML
>



-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.

