From peter.kovacs.1.0rc at gmail.com  Thu Jul  3 04:37:25 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Thu, 3 Jul 2008 10:37:25 +0200
Subject: [concurrency-interest] volatile reference vs. AtomicReference
Message-ID: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>

Hi,

I've been wondering whether it makes sense to use AtomicReference
instead of a volatile reference, if I only call the get() and set()
method of AtomicReference. Or is it that reference assignment is not
atomic in 32-bit JVMs?

Thanks
Peter

From matthias at mernst.org  Thu Jul  3 04:51:40 2008
From: matthias at mernst.org (Matthias Ernst)
Date: Thu, 3 Jul 2008 10:51:40 +0200
Subject: [concurrency-interest] volatile reference vs. AtomicReference
In-Reply-To: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
References: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
Message-ID: <22ec15240807030151s3a80f169wc89ff573de04f688@mail.gmail.com>

There's no difference IMHO.

On Thu, Jul 3, 2008 at 10:37 AM, Peter Kovacs
<peter.kovacs.1.0rc at gmail.com> wrote:
> Hi,
>
> I've been wondering whether it makes sense to use AtomicReference
> instead of a volatile reference, if I only call the get() and set()
> method of AtomicReference. Or is it that reference assignment is not
> atomic in 32-bit JVMs?
>
> Thanks
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From mallikap at deshaw.com  Thu Jul  3 05:09:59 2008
From: mallikap at deshaw.com (Mallikarjunaiah, Praveena)
Date: Thu, 3 Jul 2008 14:39:59 +0530
Subject: [concurrency-interest] volatile reference vs. AtomicReference
In-Reply-To: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
References: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
Message-ID: <B911686319FBAC4BA4671AF36F8DC30903C81CCD@mailhyd2.hyd.deshaw.com>

Internally, AtomicReference uses volatile reference itself

Thanks
Praveen

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Peter
Kovacs
Sent: Thursday, July 03, 2008 2:07 PM
To: concurrency-interest
Subject: [concurrency-interest] volatile reference vs. AtomicReference

Hi,

I've been wondering whether it makes sense to use AtomicReference
instead of a volatile reference, if I only call the get() and set()
method of AtomicReference. Or is it that reference assignment is not
atomic in 32-bit JVMs?

Thanks
Peter
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From Thomas.Hawtin at Sun.COM  Thu Jul  3 06:57:05 2008
From: Thomas.Hawtin at Sun.COM (Tom Hawtin)
Date: Thu, 03 Jul 2008 11:57:05 +0100
Subject: [concurrency-interest] volatile reference vs. AtomicReference
In-Reply-To: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
References: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
Message-ID: <486CB081.7080200@sun.com>

Peter Kovacs wrote:
> 
> I've been wondering whether it makes sense to use AtomicReference
> instead of a volatile reference, if I only call the get() and set()
> method of AtomicReference. Or is it that reference assignment is not
> atomic in 32-bit JVMs?

If you use a volatile reference, then it is one less object. OTOH, your 
code might be more consistent if you use always AtomicReference in place 
of volatile, and if you find you need one of the other methods the 
changes is easier. (Although there is AtomicReferenceFieldUpdater.)

Tom

From dcholmes at optusnet.com.au  Thu Jul  3 07:49:42 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 3 Jul 2008 21:49:42 +1000
Subject: [concurrency-interest] volatile reference vs. AtomicReference
In-Reply-To: <b6e8f2e80807030137i33d8a7f6m5513081f97730d99@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEHMHMAA.dcholmes@optusnet.com.au>

Reference assignment is always atomic.

I wouldn't bother with AtomicReference unless I needed the CAS. But it's a
stylistic choice more than anything.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Kovacs
> Sent: Thursday, 3 July 2008 6:37 PM
> To: concurrency-interest
> Subject: [concurrency-interest] volatile reference vs. AtomicReference
>
>
> Hi,
>
> I've been wondering whether it makes sense to use AtomicReference
> instead of a volatile reference, if I only call the get() and set()
> method of AtomicReference. Or is it that reference assignment is not
> atomic in 32-bit JVMs?
>
> Thanks
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From ben_manes at yahoo.com  Thu Jul  3 16:57:04 2008
From: ben_manes at yahoo.com (Ben Manes)
Date: Thu, 3 Jul 2008 13:57:04 -0700 (PDT)
Subject: [concurrency-interest] volatile reference vs. AtomicReference
Message-ID: <873661.33977.qm@web38805.mail.mud.yahoo.com>

I prefer AtomicReference instead of volatile simply because it is more obvious to other developers and they can quickly look at the JavaDoc.  That means that if someone who is looking at my code and does not work regularly with threads, it shouldn't be a surprise.  Most Java developers I've met don't quite understand volatile, so its one less thing to confuse them.  Pretty much stylistic, as David said, since they perform comparably...


----- Original Message ----
From: David Holmes <dcholmes at optusnet.com.au>
To: concurrency-interest <Concurrency-interest at cs.oswego.edu>
Sent: Thursday, July 3, 2008 4:49:42 AM
Subject: Re: [concurrency-interest] volatile reference vs. AtomicReference

Reference assignment is always atomic.

I wouldn't bother with AtomicReference unless I needed the CAS. But it's a
stylistic choice more than anything.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Kovacs
> Sent: Thursday, 3 July 2008 6:37 PM
> To: concurrency-interest
> Subject: [concurrency-interest] volatile reference vs. AtomicReference
>
>
> Hi,
>
> I've been wondering whether it makes sense to use AtomicReference
> instead of a volatile reference, if I only call the get() and set()
> method of AtomicReference. Or is it that reference assignment is not
> atomic in 32-bit JVMs?
>
> Thanks
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080703/401fda8d/attachment.html 

From peter.kovacs.1.0rc at gmail.com  Fri Jul  4 05:15:14 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Fri, 4 Jul 2008 11:15:14 +0200
Subject: [concurrency-interest] volatile reference vs. AtomicReference
In-Reply-To: <873661.33977.qm@web38805.mail.mud.yahoo.com>
References: <873661.33977.qm@web38805.mail.mud.yahoo.com>
Message-ID: <b6e8f2e80807040215l4b28a7bfja4967511114484fd@mail.gmail.com>

An interesting (and useful) consideration. ("Self-documenting code" is
one of my favorite themes, but somehow forgot about it in this case.)

Thank you all for your answers.

Peter

On Thu, Jul 3, 2008 at 10:57 PM, Ben Manes <ben_manes at yahoo.com> wrote:
> I prefer AtomicReference instead of volatile simply because it is more
> obvious to other developers and they can quickly look at the JavaDoc.  That
> means that if someone who is looking at my code and does not work regularly
> with threads, it shouldn't be a surprise.  Most Java developers I've met
> don't quite understand volatile, so its one less thing to confuse them.
> Pretty much stylistic, as David said, since they perform comparably...
>
> ----- Original Message ----
> From: David Holmes <dcholmes at optusnet.com.au>
> To: concurrency-interest <Concurrency-interest at cs.oswego.edu>
> Sent: Thursday, July 3, 2008 4:49:42 AM
> Subject: Re: [concurrency-interest] volatile reference vs. AtomicReference
>
> Reference assignment is always atomic.
>
> I wouldn't bother with AtomicReference unless I needed the CAS. But it's a
> stylistic choice more than anything.
>
> David Holmes
>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
>> Kovacs
>> Sent: Thursday, 3 July 2008 6:37 PM
>> To: concurrency-interest
>> Subject: [concurrency-interest] volatile reference vs. AtomicReference
>>
>>
>> Hi,
>>
>> I've been wondering whether it makes sense to use AtomicReference
>> instead of a volatile reference, if I only call the get() and set()
>> method of AtomicReference. Or is it that reference assignment is not
>> atomic in 32-bit JVMs?
>>
>> Thanks
>> Peter
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at altair.cs.oswego.edu
>> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From dl at cs.oswego.edu  Mon Jul  7 13:19:01 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 07 Jul 2008 13:19:01 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
Message-ID: <48725005.7070806@cs.oswego.edu>


The flexible barrier functionality that was previously restricted
to ForkJoinTasks (in class forkjoin.TaskBarrier) is being
redone as class Phaser (targeted for j.u.c, not j.u.c.forkjoin), that
can be applied in all kinds of tasks. For a snapshot of API, see
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html
Comments and suggestions are very welcome as always. The API is
likely to change a bit as we scope out further uses, and also,
hopefully, stumble upon some better method names.

Among its capabilities is allowing the number of parties in a barrier
to vary dynamically, which CyclicBarrier doesn't and can't support,
but people regularly ask for.

The nice new class name is due to Vivek Sarkar. For a preview of some
likely follow-ons (mainly, new kinds of FJ tasks that can
register in various modes for Phasers, partially in support
of analogous X10 functionality), see the paper by Vivek and others:
http://www.cs.rice.edu/~vsarkar/PDF/SPSS08-phasers.pdf

-Doug



From Ben.Rowlands at morganstanley.com  Mon Jul  7 15:40:10 2008
From: Ben.Rowlands at morganstanley.com (Rowlands, Ben (IT))
Date: Mon, 7 Jul 2008 20:40:10 +0100
Subject: [concurrency-interest] Delayed GC of ResourceBundles
Message-ID: <E295C18F4AD63149810A83F7B7E842B11879624F51@LNWEXMBX0105.msad.ms.com>

Does anyone know why instances of ResourceBundle require a delay of nearly 3 seconds before they can be GC'ed?

I know this is a little off topic but the ResourceBundle internals use a ConcurrentHashMap. It's a long shot, but, I wonder if this may have an impact on the GC behaviour? More likely something to do with the ResourceBundle implementation but I just can't spot it.

Why do I care? I want my library code to work well in multi-classloader environments (OSGi & web containers). To do this I test that my library doesn't keep the enclosing ClassLoader alive longer than necessary so it doesn't caused classloader leaks. Code using ResourceBundles requires ~3 seconds before the ClassLoader is free. While this is probably acceptable (considering how keen other parts of the JDK are to hold static references to ClassLoaders) I just can't spot what is causing the delay.

I've attached an example showing how I check the ClassLoader is free. Running it shows a ~3 second delay (on both JDK 5 & 6). Reducing the poll interval (increasing the frequency of GC's) does not significantly change this delay. I know the test isn't bullet proof given the non-determinism of the collector (it relies on eager release of WeakReferences) however it typically detects release of the ClassLoader after only a few GC iterations.

  public class ResourceBundleTest {

      private static long pollInterval = 500;

      public static void main(String[] args) throws Exception {
          ReferenceQueue<ClassLoader> queue = new ReferenceQueue<ClassLoader>();
          WeakReference<ClassLoader> loaderRef = runInNewClassLoader(UseResourceBundle.class, queue);
          waitUntilReleased(loaderRef, queue);
      }

      private static WeakReference<ClassLoader> runInNewClassLoader(Class<? extends Runnable> runnable,
              ReferenceQueue<ClassLoader> queue) throws Exception {
          ClassLoader loader = newClassLoader();
          ((Runnable) loader.loadClass(runnable.getName()).newInstance()).run();
          return new WeakReference<ClassLoader>(loader, queue);
      }

      // clones current classloader and parents with bootstrap loader
      private static ClassLoader newClassLoader() throws MalformedURLException {
          List<URL> urls = new ArrayList<URL>();
          for (String element : System.getProperty("java.class.path").split(File.pathSeparator)) {
              urls.add(new File(element).toURI().toURL());
          }
          return new URLClassLoader(urls.toArray(new URL[urls.size()]), null);
      }

      public static void waitUntilReleased(WeakReference<ClassLoader> loaderRef,
             ReferenceQueue<ClassLoader> queue) throws InterruptedException {
          long start = System.currentTimeMillis();
          for (int i = 0; queue.remove(pollInterval) != loaderRef; ++i) {
              System.gc();
              System.out.printf("Forced GC #%d (waited %dms)\n", i, System.currentTimeMillis() - start);
          }
          System.out.println("ClassLoader is free!");
      }

      public static class UseResourceBundle implements Runnable {
          public void run() {
              ResourceBundle.getBundle(MyResources.class.getName());
          }
      }

      public static class MyResources extends ListResourceBundle {
          public Object[][] getContents() {
              return new Object[][] { { "foo", "bar" } };
          }
      }
  }

This gives (exact times vary):

  Forced GC #0 (waited 500ms)
  Forced GC #1 (waited 1016ms)
  Forced GC #2 (waited 1516ms)
  Forced GC #3 (waited 2016ms)
  Forced GC #4 (waited 2516ms)
  Forced GC #5 (waited 3016ms)
  Forced GC #6 (waited 3516ms)
  ClassLoader is free!

Thanks,

Ben
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.


From mthornton at optrak.co.uk  Mon Jul  7 15:59:54 2008
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Mon, 07 Jul 2008 20:59:54 +0100
Subject: [concurrency-interest] Delayed GC of ResourceBundles
In-Reply-To: <E295C18F4AD63149810A83F7B7E842B11879624F51@LNWEXMBX0105.msad.ms.com>
References: <E295C18F4AD63149810A83F7B7E842B11879624F51@LNWEXMBX0105.msad.ms.com>
Message-ID: <487275BA.1040105@optrak.co.uk>

Rowlands, Ben (IT) wrote:
> Does anyone know why instances of ResourceBundle require a delay of nearly 3 seconds before they can be GC'ed?
>
> I know this is a little off topic but the ResourceBundle internals use a ConcurrentHashMap. It's a long shot, but, I wonder if this may have an impact on the GC behaviour? More likely something to do with the ResourceBundle implementation but I just can't spot it.
>
> Why do I care? I want my library code to work well in multi-classloader environments (OSGi & web containers). To do this I test that my library doesn't keep the enclosing ClassLoader alive longer than necessary so it doesn't caused classloader leaks. Code using ResourceBundles requires ~3 seconds before the ClassLoader is free. While this is probably acceptable (considering how keen other parts of the JDK are to hold static references to ClassLoaders) I just can't spot what is causing the delay.
>
> I've attached an example showing how I check the ClassLoader is free. Running it shows a ~3 second delay (on both JDK 5 & 6). Reducing the poll interval (increasing the frequency of GC's) does not significantly change this delay. I know the test isn't bullet proof given the non-determinism of the collector (it relies on eager release of WeakReferences) however it typically detects release of the ClassLoader after only a few GC iterations.
>   
This might give some idea:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4405807

The ResourceBundle is held via a SoftReference. There are some VM 
parameters which control how long a SoftReference is held.

Mark Thornton


From Ben.Rowlands at morganstanley.com  Tue Jul  8 05:02:56 2008
From: Ben.Rowlands at morganstanley.com (Rowlands, Ben (IT))
Date: Tue, 8 Jul 2008 10:02:56 +0100
Subject: [concurrency-interest] Delayed GC of ResourceBundles
In-Reply-To: <487275BA.1040105@optrak.co.uk>
References: <E295C18F4AD63149810A83F7B7E842B11879624F51@LNWEXMBX0105.msad.ms.com>
	<487275BA.1040105@optrak.co.uk>
Message-ID: <E295C18F4AD63149810A83F7B7E842B11879624F6F@LNWEXMBX0105.msad.ms.com>

Thanks Mark I didn't spot the softly referenced cache value. Setting '-XX:SoftRefLRUPolicyMSPerMB' to 0 only requires a few iterations before the loader is free.

Thanks again,

Ben

> -----Original Message-----
> From: Mark Thornton [mailto:mthornton at optrak.co.uk]
> Sent: 07 July 2008 21:00
> To: Rowlands, Ben (IT)
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Delayed GC of ResourceBundles
>
> Rowlands, Ben (IT) wrote:
> > Does anyone know why instances of ResourceBundle require a
> delay of nearly 3 seconds before they can be GC'ed?
> >
> > I know this is a little off topic but the ResourceBundle
> internals use a ConcurrentHashMap. It's a long shot, but, I
> wonder if this may have an impact on the GC behaviour? More
> likely something to do with the ResourceBundle implementation
> but I just can't spot it.
> >
> > Why do I care? I want my library code to work well in
> multi-classloader environments (OSGi & web containers). To do
> this I test that my library doesn't keep the enclosing
> ClassLoader alive longer than necessary so it doesn't caused
> classloader leaks. Code using ResourceBundles requires ~3
> seconds before the ClassLoader is free. While this is
> probably acceptable (considering how keen other parts of the
> JDK are to hold static references to ClassLoaders) I just
> can't spot what is causing the delay.
> >
> > I've attached an example showing how I check the
> ClassLoader is free. Running it shows a ~3 second delay (on
> both JDK 5 & 6). Reducing the poll interval (increasing the
> frequency of GC's) does not significantly change this delay.
> I know the test isn't bullet proof given the non-determinism
> of the collector (it relies on eager release of
> WeakReferences) however it typically detects release of the
> ClassLoader after only a few GC iterations.
> >
> This might give some idea:
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4405807
>
> The ResourceBundle is held via a SoftReference. There are some VM
> parameters which control how long a SoftReference is held.
>
> Mark Thornton
--------------------------------------------------------

NOTICE: If received in error, please destroy and notify sender. Sender does not intend to waive confidentiality or privilege. Use of this email is prohibited when received in error.


From alexdmiller at yahoo.com  Tue Jul  8 14:35:45 2008
From: alexdmiller at yahoo.com (Alex Miller)
Date: Tue, 8 Jul 2008 11:35:45 -0700 (PDT)
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
Message-ID: <372185.7378.qm@web32102.mail.mud.yahoo.com>


> The flexible barrier functionality that was previously restricted
> to ForkJoinTasks (in class forkjoin.TaskBarrier) is being
> redone as class Phaser (targeted for j.u.c, not j.u.c.forkjoin), that
> can be applied in all kinds of tasks. For a snapshot of API, see
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html
> Comments and suggestions are very welcome as always. The API is
> likely to change a bit as we scope out further uses, and also,
> hopefully, stumble upon some better method names.

This is great to see!  I could definitely have used a Phaser now and again.  I blogged this note btw:

http://tech.puredanger.com/2008/07/08/java7-phasers/

One thing I mentioned there is that the necessity of subclassing a Phaser to implement a barrier action smells to me.  Why not use an external Runnable/Task action ala CyclicBarrier instead?

Alex Miller
http://tech.puredanger.com

From anjan.dev at gmail.com  Tue Jul  8 14:56:08 2008
From: anjan.dev at gmail.com (Anjan Bacchu)
Date: Tue, 8 Jul 2008 11:56:08 -0700
Subject: [concurrency-interest] archives
Message-ID: <3e0efa20807081156y1c716887wfb333d905cbfa3b1@mail.gmail.com>

Hi There,

  Are there any archives for this list ? It might help to have public
archives available.

Thank you,

BR,
~A
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20080708/67e778f9/attachment.html 

From dl at cs.oswego.edu  Tue Jul  8 20:10:21 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 08 Jul 2008 20:10:21 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <372185.7378.qm@web32102.mail.mud.yahoo.com>
References: <372185.7378.qm@web32102.mail.mud.yahoo.com>
Message-ID: <487401ED.9050802@cs.oswego.edu>

Alex Miller wrote:

 > This is great to see!  I could definitely have used a Phaser now and again. I
 > blogged this note btw:
 >
 > http://tech.puredanger.com/2008/07/08/java7-phasers/
 >

Great; we'd welcome any nice punchy cut-n-paste-n-hack-able
examples you might have for the sample usage section.

 > One thing I mentioned there is that the necessity of subclassing a Phaser to 
implement a barrier action smells to me.  Why not use an external Runnable/Task 
action ala CyclicBarrier instead?
 >

Because onAdvance returns termination indicator, we'd want
a callback with three arguments (phaser, phase, parties)
so callee knows which phaser and what its state is (which
is a momentary state that will change upon return from
onAdvance). It seems a little easier all around to instead
have people do this by subclassing. Not too different in
intent than subclassing ThreadLocal for sake of initialValue.
But alternative suggestions would be welcome.

-Doug


From dl at cs.oswego.edu  Tue Jul  8 20:12:49 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 08 Jul 2008 20:12:49 -0400
Subject: [concurrency-interest] archives
In-Reply-To: <3e0efa20807081156y1c716887wfb333d905cbfa3b1@mail.gmail.com>
References: <3e0efa20807081156y1c716887wfb333d905cbfa3b1@mail.gmail.com>
Message-ID: <48740281.2040206@cs.oswego.edu>

Anjan Bacchu wrote:
> Hi There,
> 
>   Are there any archives for this list ? It might help to have public 
> archives available.
> 

Archive access was switched to members-only a few years ago for
reasons I no longer recall. But because I don't recall,
I just now switched them to public.
See http://altair.cs.oswego.edu/pipermail/concurrency-interest/

-Doug

From jed at atlassian.com  Tue Jul  8 20:32:12 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Wed, 09 Jul 2008 10:32:12 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <48725005.7070806@cs.oswego.edu>
References: <48725005.7070806@cs.oswego.edu>
Message-ID: <4874070C.1000505@atlassian.com>

This is very cool. I have been rolling my own version of with similar 
functionality that is nowhere near as nice or flexible.

Just a quick naming question, as awesome as the name Phaser is, wouldn't 
PhasedBarrier possibly be more accurate?

Doug Lea wrote:
> The flexible barrier functionality that was previously restricted
> to ForkJoinTasks (in class forkjoin.TaskBarrier) is being
> redone as class Phaser (targeted for j.u.c, not j.u.c.forkjoin), that
> can be applied in all kinds of tasks...

cheers,
jed.

From colin.mailinglist at gmail.com  Fri Jul 11 09:22:19 2008
From: colin.mailinglist at gmail.com (Colin Fleming)
Date: Fri, 11 Jul 2008 15:22:19 +0200
Subject: [concurrency-interest] Some advice about implementing Future
Message-ID: <7c6512110807110622m365052fer173816aec2e795dc@mail.gmail.com>

Hi all,

I'm just learning (after far too long) about concurrency, and I'd like some
advice on how to implement a Future. We have a basic Future that we've
implemented using a CountDownLatch. We'd like to make sure that the
contained value is only set once. We have something like the following
(slightly trimmed for brevity):

public final class ResultFutureImpl<T> implements ResultFuture<T>
{
  private final CountDownLatch latch;
  private volatile T result = null;
  private final AtomicBoolean alreadySet = new AtomicBoolean(false);

  public ResultFutureImpl()
  {
    this.latch = new CountDownLatch(1);
  }

  public void set(final T result)
  {
    if (alreadySet.getAndSet(true))
    {
      throw new IllegalStateException("No more than one call to set is
allowed.");
    }
    else
    {
      this.result = result;
      this.latch.countDown();
    }
  }

  public T get() throws InterruptedException, ExecutionException
  {
    latch.await();
    return result;
  }

  public T get(final long timeout, final TimeUnit unit)
      throws InterruptedException, ExecutionException, TimeoutException
  {
    if (!latch.await(timeout, unit))
    {
      throw new TimeoutException();
    }
    return result;
  }

  ... some snippage for brevity ...
}

Is this a safe implementation? My problem is that latch and result clearly
have an invariant, but I don't want to be holding a lock when I call await()
on the latch.

Thanks in advance for any advice!

Cheers,
Colin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080711/0a6b3132/attachment.html>

From tim at peierls.net  Fri Jul 11 10:53:35 2008
From: tim at peierls.net (Tim Peierls)
Date: Fri, 11 Jul 2008 10:53:35 -0400
Subject: [concurrency-interest] Some advice about implementing Future
In-Reply-To: <7c6512110807110622m365052fer173816aec2e795dc@mail.gmail.com>
References: <7c6512110807110622m365052fer173816aec2e795dc@mail.gmail.com>
Message-ID: <63b4e4050807110753h429c0a3bocf575406ba6e1f49@mail.gmail.com>

Looks OK to me. Your ResultFuture extends Future by adding the set method,
right?

I think you can omit ExecutionException in the throws clauses of timed and
untimed get, for this implementation.

If you were willing to forgo null as a possible result value, you could
merge the result and the boolean into a single AtomicReference<T> and use
the value of resultHolder.compareAndSet(null, result) to determine whether
to count down or to throw IllegalStateException. (And I suppose you could
even use AtomicReference<Object> with a distinguished special value to allow
null results, but that starts getting ugly.)

There's a similar example in *Java Concurrency in Practice* (Listing 8.17),
though it isn't expressed as an implementation of Future. It uses plain
synchronization instead of volatile-plus-AtomicBoolean.

--tim

On Fri, Jul 11, 2008 at 9:22 AM, Colin Fleming <colin.mailinglist at gmail.com>
wrote:

> Hi all,
>
> I'm just learning (after far too long) about concurrency, and I'd like some
> advice on how to implement a Future. We have a basic Future that we've
> implemented using a CountDownLatch. We'd like to make sure that the
> contained value is only set once. We have something like the following
> (slightly trimmed for brevity):
>
> public final class ResultFutureImpl<T> implements ResultFuture<T>
> {
>   private final CountDownLatch latch;
>   private volatile T result = null;
>   private final AtomicBoolean alreadySet = new AtomicBoolean(false);
>
>   public ResultFutureImpl()
>   {
>     this.latch = new CountDownLatch(1);
>   }
>
>   public void set(final T result)
>   {
>     if (alreadySet.getAndSet(true))
>     {
>       throw new IllegalStateException("No more than one call to set is
> allowed.");
>     }
>     else
>     {
>       this.result = result;
>       this.latch.countDown();
>     }
>   }
>
>   public T get() throws InterruptedException, ExecutionException
>   {
>     latch.await();
>     return result;
>   }
>
>   public T get(final long timeout, final TimeUnit unit)
>       throws InterruptedException, ExecutionException, TimeoutException
>   {
>     if (!latch.await(timeout, unit))
>     {
>       throw new TimeoutException();
>     }
>     return result;
>   }
>
>   ... some snippage for brevity ...
> }
>
> Is this a safe implementation? My problem is that latch and result clearly
> have an invariant, but I don't want to be holding a lock when I call await()
> on the latch.
>
> Thanks in advance for any advice!
>
> Cheers,
> Colin
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080711/a9a9d106/attachment.html>

From jed at atlassian.com  Fri Jul 11 20:08:27 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Sat, 12 Jul 2008 10:08:27 +1000
Subject: [concurrency-interest] Some advice about implementing Future
In-Reply-To: <63b4e4050807110753h429c0a3bocf575406ba6e1f49@mail.gmail.com>
References: <7c6512110807110622m365052fer173816aec2e795dc@mail.gmail.com>
	<63b4e4050807110753h429c0a3bocf575406ba6e1f49@mail.gmail.com>
Message-ID: <814BBE31-1A27-4814-91C3-827F12624866@atlassian.com>

Even better, use AtomicMarkableReference to support nulls fairly  
easily. It is basically analogous to the volatile/AtomicBoolean pair  
except it offers atomic setting of ref and mark state via:  
compareAndSet(V expectedReference,V newReference, boolean  
expectedMark, boolean newMark).

So you set up the ref as (null, false) then if the above call fails  
with those expected values throw the exception.

cheers,
jed.

On 12/07/2008, at 12:53 AM, Tim Peierls wrote:

> Looks OK to me. Your ResultFuture extends Future by adding the set  
> method, right?
>
> I think you can omit ExecutionException in the throws clauses of  
> timed and untimed get, for this implementation.
>
> If you were willing to forgo null as a possible result value, you  
> could merge the result and the boolean into a single  
> AtomicReference<T> and use the value of  
> resultHolder.compareAndSet(null, result) to determine whether to  
> count down or to throw IllegalStateException. (And I suppose you  
> could even use AtomicReference<Object> with a distinguished special  
> value to allow null results, but that starts getting ugly.)
>
> There's a similar example in Java Concurrency in Practice (Listing  
> 8.17), though it isn't expressed as an implementation of Future. It  
> uses plain synchronization instead of volatile-plus-AtomicBoolean.
>
> --tim
>
> On Fri, Jul 11, 2008 at 9:22 AM, Colin Fleming <colin.mailinglist at gmail.com 
> > wrote:
> Hi all,
>
> I'm just learning (after far too long) about concurrency, and I'd  
> like some advice on how to implement a Future. We have a basic  
> Future that we've implemented using a CountDownLatch. We'd like to  
> make sure that the contained value is only set once. We have  
> something like the following (slightly trimmed for brevity):
>
> public final class ResultFutureImpl<T> implements ResultFuture<T>
> {
>   private final CountDownLatch latch;
>   private volatile T result = null;
>   private final AtomicBoolean alreadySet = new AtomicBoolean(false);
>
>   public ResultFutureImpl()
>   {
>     this.latch = new CountDownLatch(1);
>   }
>
>   public void set(final T result)
>   {
>     if (alreadySet.getAndSet(true))
>     {
>       throw new IllegalStateException("No more than one call to set  
> is allowed.");
>     }
>     else
>     {
>       this.result = result;
>       this.latch.countDown();
>     }
>   }
>
>   public T get() throws InterruptedException, ExecutionException
>   {
>     latch.await();
>     return result;
>   }
>
>   public T get(final long timeout, final TimeUnit unit)
>       throws InterruptedException, ExecutionException,  
> TimeoutException
>   {
>     if (!latch.await(timeout, unit))
>     {
>       throw new TimeoutException();
>     }
>     return result;
>   }
>
>   ... some snippage for brevity ...
> }
>
> Is this a safe implementation? My problem is that latch and result  
> clearly have an invariant, but I don't want to be holding a lock  
> when I call await() on the latch.
>
> Thanks in advance for any advice!
>
> Cheers,
> Colin
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gkorland at gmail.com  Mon Jul 14 10:51:05 2008
From: gkorland at gmail.com (Guy Korland)
Date: Mon, 14 Jul 2008 17:51:05 +0300
Subject: [concurrency-interest] LinkedBlockingQueue - ReentrantLock vs
	Synchronized
Message-ID: <79be5fa30807140751n1993033et1d58b5188608ee14@mail.gmail.com>

Hi,

I guess this question was asked many times so I'm sorry for wasting your
time.

But, form a quick glance at the LinkedBlockingQueue implementation it seems
like the use of the locks (takeLock & putLock), is really fits more to
synchronized.
In fact it seems like the "lock based" implementation is even performing
worse since the jvm optimizes the synchronized overhead.

-- 
Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080714/0805b9bb/attachment.html>

From dcholmes at optusnet.com.au  Mon Jul 14 17:29:36 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 15 Jul 2008 07:29:36 +1000
Subject: [concurrency-interest] LinkedBlockingQueue - ReentrantLock
	vsSynchronized
In-Reply-To: <79be5fa30807140751n1993033et1d58b5188608ee14@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEJIHMAA.dcholmes@optusnet.com.au>

Hi Guy,

LinkedBlockingQueue also takes advantage of the features of Conditions
(better timed-wait support) and interruptible-locking.

On the performance side ... When JDK 5 came out synchronized was still
primarily optimized for uncontended locking, and performance with contention
was really poor. On the other hand ReentrantLock performs well under
contention. Since JDK 5 synchronized performance under contention has
improved.  If you turn the contention knob from zero to full I expect you
will still find that there is a point where ReentrantLock outperforms
synchronized - though that point will have moved since JDK 5 days.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Guy Korland
  Sent: Tuesday, 15 July 2008 12:51 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] LinkedBlockingQueue - ReentrantLock
vsSynchronized


  Hi,

  I guess this question was asked many times so I'm sorry for wasting your
time.

  But, form a quick glance at the LinkedBlockingQueue implementation it
seems like the use of the locks (takeLock & putLock), is really fits more to
synchronized.
  In fact it seems like the "lock based" implementation is even performing
worse since the jvm optimizes the synchronized overhead.

  --
  Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080715/0d319d66/attachment.html>

From dawid.kurzyniec at gmail.com  Tue Jul 15 06:23:14 2008
From: dawid.kurzyniec at gmail.com (Dawid Kurzyniec)
Date: Tue, 15 Jul 2008 12:23:14 +0200
Subject: [concurrency-interest] ReentrantReadWriteLock fair lock
In-Reply-To: <79be5fa30806260648h6b2a0e16t9895bf0f6e16ac9d@mail.gmail.com>
References: <79be5fa30806260648h6b2a0e16t9895bf0f6e16ac9d@mail.gmail.com>
Message-ID: <3cbaca580807150323n9d7809w8e274da6c7c17b96@mail.gmail.com>

On Thu, Jun 26, 2008 at 3:48 PM, Guy Korland <gkorland at gmail.com> wrote:
> Hi,
>
> Is there a good reason why
> edu.emory.mathcs.backport.java.util.concurrent.ReentrantReadWriteLock
> doesn't include a fair constructor?

It would be very work-intensive to implement, and there isn't high
demand for it. The code of this class is based on dl.u.c.
writer-preference lock, which has slightly different semantics that
fair RRWL in 5.0, although it passes just fine as a nonfair lock.

--
Regards,
Dawid

From ashwin.jayaprakash at gmail.com  Tue Jul 15 13:23:43 2008
From: ashwin.jayaprakash at gmail.com (Ashwin Jayaprakash)
Date: Tue, 15 Jul 2008 10:23:43 -0700
Subject: [concurrency-interest] LinkedBlockingQueue and ConcurrentLinkedQueue
Message-ID: <837c23d40807151023y6ecf399fm25f1c8c6d7dfa1d5@mail.gmail.com>

Hello,
I've observed something similar when comparing LinkedBlockingQueue and
ConcurrentLinkedQueue. On Intel platforms, repeated CAS operations hurt
performance -
http://forum.java.sun.com/thread.jspa?threadID=5312465&messageID=10331596#10331596

Ashwin.




On Tue, Jul 15, 2008 at 9:00 AM, <concurrency-interest-request at cs.oswego.edu>
wrote:

> Send Concurrency-interest mailing list submissions to
>        concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
>        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
>        concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
>        concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
> Today's Topics:
>
>   1. Re: LinkedBlockingQueue - ReentrantLock   vsSynchronized
>      (David Holmes)
>   2. Re: ReentrantReadWriteLock fair lock (Dawid Kurzyniec)
>
>
> ---------- Forwarded message ----------
> From: "David Holmes" <dcholmes at optusnet.com.au>
> To: "Guy Korland" <gkorland at gmail.com>, <
> concurrency-interest at cs.oswego.edu>
> Date: Tue, 15 Jul 2008 07:29:36 +1000
> Subject: Re: [concurrency-interest] LinkedBlockingQueue - ReentrantLock
> vsSynchronized
>  Hi Guy,
>
> LinkedBlockingQueue also takes advantage of the features of Conditions
> (better timed-wait support) and interruptible-locking.
>
> On the performance side ... When JDK 5 came out synchronized was still
> primarily optimized for uncontended locking, and performance with contention
> was really poor. On the other hand ReentrantLock performs well under
> contention. Since JDK 5 synchronized performance under contention has
> improved.  If you turn the contention knob from zero to full I expect you
> will still find that there is a point where ReentrantLock outperforms
> synchronized - though that point will have moved since JDK 5 days.
>
> Cheers,
> David Holmes
>
> -----Original Message-----
> **
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080715/00541eee/attachment.html>

From ben_manes at yahoo.com  Tue Jul 15 17:48:35 2008
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 15 Jul 2008 14:48:35 -0700 (PDT)
Subject: [concurrency-interest] LinkedBlockingQueue and
	ConcurrentLinkedQueue
Message-ID: <795668.43822.qm@web38801.mail.mud.yahoo.com>

After every operation, you should perform a Thread.yield() to ensure that there is contention against the locks.  Otherwise, you might observe that a thread executes its full time slice and may be switched out while holding the lock.  Thus, all the other threads will yield and the original thread will be allowed to perform work again.  When I perform tests like this, I usually allow a flag to observe the behavior between forced and non-forced contention.  You should see that CAS based operations often perform better than a lock under high contention.  Under low contention, it may very depending on the algorithm.

I am starting to put together a test since ehcache is starting to get high in our list of lock contentions, so you can see how much this can yeilding will cause:
  - SYNC_FIFO: LinkedHashMap guarded by Collections.synchronized()
  - RW_FIFO: LinkedHashMap guarded by ReentrantReadWriteLock
  - FAST_FIFO: Second-chance FIFO using a ConcurrentHashMap as the store, a ConcurrentLinkedQueue for eviction.

______READ CENTRIC________
-- 80% read / 20% write --
== not forcing contention ==
SYNC_FIFO: 3,012 ms
RW_FIFO:   1,772 ms
FAST_FIFO:   968 ms

== forcing contention ==
SYNC_FIFO: 7,576 ms
RW_FIFO:   6,780 ms
FAST_FIFO:   975 ms

______WRITE CENTRIC________
-- 20% read / 80% write --
== not forcing contention ==
SYNC_FIFO: 5,566 ms
RW_FIFO:   2,235 ms
FAST_FIFO:   980 ms

== forcing contention ==
SYNC_FIFO: 12,963 ms
RW_FIFO:   10,273 ms
FAST_FIFO:    985 ms


----- Original Message ----
From: Ashwin Jayaprakash <ashwin.jayaprakash at gmail.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tuesday, July 15, 2008 10:23:43 AM
Subject: [concurrency-interest] LinkedBlockingQueue and ConcurrentLinkedQueue


Hello,
I've observed something similar when comparing LinkedBlockingQueue and ConcurrentLinkedQueue. On Intel platforms, repeated CAS operations hurt performance - http://forum.java.sun.com/thread.jspa?threadID=5312465&messageID=10331596#10331596

Ashwin.





On Tue, Jul 15, 2008 at 9:00 AM,  <concurrency-interest-request at cs.oswego.edu> wrote:

Send Concurrency-interest mailing list submissions to
       concurrency-interest at cs.oswego.edu

To subscribe or unsubscribe via the World Wide Web, visit
       http://cs.oswego.edu/mailman/listinfo/concurrency-interest
or, via email, send a message with subject or body 'help' to
       concurrency-interest-request at cs.oswego.edu

You can reach the person managing the list at
       concurrency-interest-owner at cs.oswego.edu

When replying, please edit your Subject line so it is more specific
than "Re: Contents of Concurrency-interest digest..."

Today's Topics:

  1. Re: LinkedBlockingQueue - ReentrantLock   vsSynchronized
     (David Holmes)
  2. Re: ReentrantReadWriteLock fair lock (Dawid Kurzyniec)


---------- Forwarded message ----------
From: "David Holmes" <dcholmes at optusnet.com.au>
To: "Guy Korland" <gkorland at gmail.com>, <concurrency-interest at cs.oswego.edu>
Date: Tue, 15 Jul 2008 07:29:36 +1000
Subject: Re: [concurrency-interest] LinkedBlockingQueue - ReentrantLock vsSynchronized

Hi Guy,
 
LinkedBlockingQueue also takes advantage of the features of Conditions 
(better timed-wait support) and interruptible-locking. 
 
On the performance side ... When JDK 5 came out synchronized was still 
primarily optimized for uncontended locking, and performance with contention was 
really poor. On the other hand ReentrantLock performs well under contention. 
Since JDK 5 synchronized performance under contention has improved.  If you 
turn the contention knob from zero to full I expect you will still find that 
there is a point where ReentrantLock outperforms synchronized - though that 
point will have moved since JDK 5 days.
 
Cheers,
David Holmes
-----Original Message-----


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080715/bbe6ec0c/attachment.html>

From dl at cs.oswego.edu  Wed Jul 16 07:49:47 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 16 Jul 2008 07:49:47 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <4874070C.1000505@atlassian.com>
References: <48725005.7070806@cs.oswego.edu> <4874070C.1000505@atlassian.com>
Message-ID: <487DE05B.3050501@cs.oswego.edu>

Jed Wesley-Smith wrote:
> This is very cool. I have been rolling my own version of with similar 
> functionality that is nowhere near as nice or flexible.
> 
> Just a quick naming question, as awesome as the name Phaser is, wouldn't 
> PhasedBarrier possibly be more accurate?
> 

I let this sit a few days in case anyone else complained about
name, but I think the consensus might be that the awesomeness
of "Phaser" outweighs having the name carry the fact that it
is a kind of barrier. (As Josh Bloch has said a few times,
one minor failure of java.util.concurrent is that some of
the class names look too imposing. For the main
example, some people still use java.util.Timer just because
java.util.concurrent.ScheduledThreadPoolExecutor seems
so much more complicated.)

I still don't love some of the method names though. Right
now, names like "arriveAndAwaitAdvance()" are unambiguously
descriptive. Because there are more methods
you can use/call than in other kinds of barriers, we
want them to be less confusing. But they get a bit clunky and
verbose when you use them all the time. Suggestions welcome.

A minor update of javadoc is at:
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html

-Doug



From dl at cs.oswego.edu  Wed Jul 16 08:05:32 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 16 Jul 2008 08:05:32 -0400
Subject: [concurrency-interest] LinkedBlockingQueue and
	ConcurrentLinkedQueue
In-Reply-To: <837c23d40807151023y6ecf399fm25f1c8c6d7dfa1d5@mail.gmail.com>
References: <837c23d40807151023y6ecf399fm25f1c8c6d7dfa1d5@mail.gmail.com>
Message-ID: <487DE40C.8040508@cs.oswego.edu>

Ashwin Jayaprakash wrote:
> Hello,
> I've observed something similar when comparing LinkedBlockingQueue and 
> ConcurrentLinkedQueue. On Intel platforms, repeated CAS operations hurt 
> performance - 
> http://forum.java.sun.com/thread.jspa?threadID=5312465&messageID=10331596#10331596 

ConcurrentLinkedQueue does have more overhead than we'd like.
(A long story, but in part because the cost of the rarely-used
Collections.remove(element) method is spread out to the
more commonly used methods like put and poll.)
The upcoming (CAS-based) LinkedTransferQueue has less overhead,
and  can replace it in most usages. In fact, it is possible that
when we get around to thinking about JDK release, we might just
have CLQ delegate to LTQ.

See:
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/LinkedTransferQueue.html

(More generally, note that locks ultimately rely on CASes and
memory fences as well -- it is not the CASes but how they used
that matters here.)


-Doug


From dl at cs.oswego.edu  Wed Jul 16 08:27:43 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 16 Jul 2008 08:27:43 -0400
Subject: [concurrency-interest] LinkedBlockingQueue
	and	ConcurrentLinkedQueue
In-Reply-To: <795668.43822.qm@web38801.mail.mud.yahoo.com>
References: <795668.43822.qm@web38801.mail.mud.yahoo.com>
Message-ID: <487DE93F.9020500@cs.oswego.edu>

Ben Manes wrote:
> After every operation, you should perform a Thread.yield() 

Benchmarking unbounded queue performance is indeed tricky because
measured performance is so sensitive to producer/consumer
rates. For the main problem,  if producers are too fast then
you will mostly just be measuring the memory/gc effects of unbounded
growth in queue size. One way to deal with this is to invoke
a barrier every N iterations (for N perhaps around 1000) to
force threads to not get too far ahead/behind. This is a much
better technique than using Thread.yield, since yield has
different effects (including NO effect) on different platforms.

While I'm at it: Different queues also have different
typical performance profiles across one-to-one, many-to-one,
one-to-many, and many-to-many producer/consumer configurations.
There are a couple of good queue implementations out there
that are great for one-to-one but terrible (or even incorrect)
otherwise, so we don't include them in j.u.c.

-Doug



From joe.bowbeer at gmail.com  Wed Jul 16 12:25:26 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 16 Jul 2008 09:25:26 -0700
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <487DE05B.3050501@cs.oswego.edu>
References: <48725005.7070806@cs.oswego.edu> <4874070C.1000505@atlassian.com>
	<487DE05B.3050501@cs.oswego.edu>
Message-ID: <31f2a7bd0807160925j2f2c8ac4pc13b2da1e9d75af1@mail.gmail.com>

I would support PhasedBarrier.

It's descriptive, consistent, short enough, and is related to the given name
of its ancestor (Phaser).

For an even more awesome descriptive name, I suggest: BarrierOMatic

(For those too young to appreciate this, check out SNL, episode 17. Comes
with 10 rotary attachments. My that's some tasty Barrier!)

--Joe

On Wed, Jul 16, 2008 at 4:49 AM, Doug Lea wrote:

> Jed Wesley-Smith wrote:
>
>> This is very cool. I have been rolling my own version of with similar
>> functionality that is nowhere near as nice or flexible.
>>
>> Just a quick naming question, as awesome as the name Phaser is, wouldn't
>> PhasedBarrier possibly be more accurate?
>>
>>
> I let this sit a few days in case anyone else complained about
> name, but I think the consensus might be that the awesomeness
> of "Phaser" outweighs having the name carry the fact that it
> is a kind of barrier. (As Josh Bloch has said a few times,
> one minor failure of java.util.concurrent is that some of
> the class names look too imposing. For the main
> example, some people still use java.util.Timer just because
> java.util.concurrent.ScheduledThreadPoolExecutor seems
> so much more complicated.)
>
> I still don't love some of the method names though. Right
> now, names like "arriveAndAwaitAdvance()" are unambiguously
> descriptive. Because there are more methods
> you can use/call than in other kinds of barriers, we
> want them to be less confusing. But they get a bit clunky and
> verbose when you use them all the time. Suggestions welcome.
>
> A minor update of javadoc is at:
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html
>
> -Doug
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080716/1f7fef43/attachment.html>

From hallorant at gmail.com  Wed Jul 16 14:52:31 2008
From: hallorant at gmail.com (Tim Halloran)
Date: Wed, 16 Jul 2008 14:52:31 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <487DE05B.3050501@cs.oswego.edu>
References: <48725005.7070806@cs.oswego.edu> <4874070C.1000505@atlassian.com>
	<487DE05B.3050501@cs.oswego.edu>
Message-ID: <a36ab4bc0807161152l37cf3349lf55644c973c600be@mail.gmail.com>

I'm in support of just Phaser.

The method names are quite clear except it took me a bit to figure out how
to do, in CyclicBarrier terms, a barrier action.  When using CyclicBarrier I
can pass a Runnable into the constructor. Using a Phaser I need to subclass
and override the onAdvance method.  I pondered this a bit when I tried to
replace a CyclicBarrier with this class.  Hence, I'd suggest a bit more in
the class Javadoc bullet:

Barrier actions, performed by the task triggering a phase advance while
others may be waiting, are arranged by overriding method onAdvance, that
also controls termination. (Overriding onAdvance is similar to providing a
barrier action to a CyclicBarrier.)

Or some such -- to better highlight the tie to this capability.

Regards,
Tim

On Wed, Jul 16, 2008 at 7:49 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> Jed Wesley-Smith wrote:
>
>> This is very cool. I have been rolling my own version of with similar
>> functionality that is nowhere near as nice or flexible.
>>
>> Just a quick naming question, as awesome as the name Phaser is, wouldn't
>> PhasedBarrier possibly be more accurate?
>>
>>
> I let this sit a few days in case anyone else complained about
> name, but I think the consensus might be that the awesomeness
> of "Phaser" outweighs having the name carry the fact that it
> is a kind of barrier. (As Josh Bloch has said a few times,
> one minor failure of java.util.concurrent is that some of
> the class names look too imposing. For the main
> example, some people still use java.util.Timer just because
> java.util.concurrent.ScheduledThreadPoolExecutor seems
> so much more complicated.)
>
> I still don't love some of the method names though. Right
> now, names like "arriveAndAwaitAdvance()" are unambiguously
> descriptive. Because there are more methods
> you can use/call than in other kinds of barriers, we
> want them to be less confusing. But they get a bit clunky and
> verbose when you use them all the time. Suggestions welcome.
>
> A minor update of javadoc is at:
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080716/e7cf5ebd/attachment.html>

From jed at atlassian.com  Wed Jul 16 19:35:41 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 17 Jul 2008 09:35:41 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <487DE05B.3050501@cs.oswego.edu>
References: <48725005.7070806@cs.oswego.edu> <4874070C.1000505@atlassian.com>
	<487DE05B.3050501@cs.oswego.edu>
Message-ID: <5AD5927A-97C6-4DD5-9304-87D38DEA3E79@atlassian.com>

I must admit I don't have a strong opinion on the Phaser/PhasedBarrier  
- but mostly as I now understand what it is. The javadoc updates do  
improve the situation somewhat though for newcomers.

On the method naming, for a CyclicBarrier you await() to arrive and  
the advance but for a Phaser you arriveAndAwaitAdvance(). Now while  
they are conceptually analagous they do have quite different semantics  
(different exception signature for one). While I understand the  
separation of arrival and waiting for advance properties, I don't  
understand the need to change the semantics of the call or how  
breaking is supported (at least in the way CyclicBarrier supports it).  
It would be easier to grok if the CyclicBarrier interface was  
supported - ie. rename arriveAndAwaitAdvance() to await() or add  
await() that supports interruption. My initial thought was that you  
could do away with _advance_ in most of the method names but the  
difference in the interruption policy makes that problematic. I guess  
it'd be interesting to know why awaitAdvance()/arriveAndAwaitAdvance()  
doesn't throw InterruptedException/BrokenBarrierException.

Also, I don't understand how an arriveAndAwaitAdvance() can throw an  
IllegalStateException if the number of waiting parties becomes  
negative. Shouldn't it advance and return once the waiting parties  
reaches zero?

Anyway, I am looking forward to using it in anger.

cheers,
jed.

On 16/07/2008, at 9:49 PM, Doug Lea wrote:

> Jed Wesley-Smith wrote:
>> This is very cool. I have been rolling my own version of with  
>> similar functionality that is nowhere near as nice or flexible.
>> Just a quick naming question, as awesome as the name Phaser is,  
>> wouldn't PhasedBarrier possibly be more accurate?
>
> I let this sit a few days in case anyone else complained about
> name, but I think the consensus might be that the awesomeness
> of "Phaser" outweighs having the name carry the fact that it
> is a kind of barrier. (As Josh Bloch has said a few times,
> one minor failure of java.util.concurrent is that some of
> the class names look too imposing. For the main
> example, some people still use java.util.Timer just because
> java.util.concurrent.ScheduledThreadPoolExecutor seems
> so much more complicated.)
>
> I still don't love some of the method names though. Right
> now, names like "arriveAndAwaitAdvance()" are unambiguously
> descriptive. Because there are more methods
> you can use/call than in other kinds of barriers, we
> want them to be less confusing. But they get a bit clunky and
> verbose when you use them all the time. Suggestions welcome.
>
> A minor update of javadoc is at:
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/ 
> Phaser.html
>
> -Doug
>
>


From karnok at sztaki.hu  Thu Jul 17 08:56:26 2008
From: karnok at sztaki.hu (=?iso-8859-2?Q?Karnok_D=E1vid?=)
Date: Thu, 17 Jul 2008 14:56:26 +0200
Subject: [concurrency-interest] jsr166y on JDK 5?
Message-ID: <009401c8e80c$860d4f90$6e026fc3@workforce>

Hello,

 

I would like to use Doug Lea's jsr166y implementation in my project but I am
not allowed to use JDK 6. I downloaded the source code but can't compile it
using JDK 5 because a missing method Unsafe.putOrderedLong() call within
ForkJoinWorkerThread. Is there a backported version of this library or is
the current JDK 6 version correct under JDK 5 too?

 

--------------------------------

Karnok D?vid

PhD Student

 

Engineering and Management Intelligence laboratory, Computer and Automation
Research Institute, Hungarian Academy of Sciences

http://www.sztaki.hu

http://www.emi.sztaki.hu 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080717/596b7853/attachment.html>

From dl at cs.oswego.edu  Thu Jul 17 09:18:02 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 17 Jul 2008 09:18:02 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <5AD5927A-97C6-4DD5-9304-87D38DEA3E79@atlassian.com>
References: <48725005.7070806@cs.oswego.edu> <4874070C.1000505@atlassian.com>
	<487DE05B.3050501@cs.oswego.edu>
	<5AD5927A-97C6-4DD5-9304-87D38DEA3E79@atlassian.com>
Message-ID: <487F468A.7060306@cs.oswego.edu>

Jed Wesley-Smith wrote:
>  I guess it'd be interesting 
> to know why awaitAdvance()/arriveAndAwaitAdvance() doesn't throw 
> InterruptedException/BrokenBarrierException.

This is mainly experience driven. Causing BrokenBarrierExceptions
when a party hits interrupt or timeout, but not if it encounters
some other exception while executing usually forces people to set up
two kinds of recovery -- one dealing with the barrier and the other for
all other exceptions. Normally, across these, all you want to do is
cause all other parties to wake up and take some evasive action.
This is one use of the forceTermination method.

Note that we do support awaitAdvanceInterruptibly, so
you can still abort the wait on interrupt, but unlike
CyclicBarrier, this doesn't itself change barrier state.
Among other alternatives, you might do something like:
   try { p.awaitAdvanceInterruptibly(lastPhase);
   catch (InterruptedException ex) {
     record(ex); p.forceTermination();
   }

And/Or other actions like arriveAndDeregister or even reset.

> 
> Also, I don't understand how an arriveAndAwaitAdvance() can throw an 
> IllegalStateException if the number of waiting parties becomes negative. 
> Shouldn't it advance and return once the waiting parties reaches zero?
> 

It can happen if you forget to register. As in:
   Phaser p = new Phaser(0);
   p.arrive()

I just realized though that this exception should be
suppressed if isTerminated, since throwing it in this
case just makes users life more difficult without adding
any safety.


Thanks for the questions! I added a few clarifications to
javadoc. Also including Tim Halloran's suggestions, plus
an example.  (Thanks Tim!)

http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html

-Doug


From dl at cs.oswego.edu  Thu Jul 17 09:29:04 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 17 Jul 2008 09:29:04 -0400
Subject: [concurrency-interest] jsr166y on JDK 5?
In-Reply-To: <009401c8e80c$860d4f90$6e026fc3@workforce>
References: <009401c8e80c$860d4f90$6e026fc3@workforce>
Message-ID: <487F4920.8040907@cs.oswego.edu>

Karnok D?vid wrote:
> Hello,
> I would like to use Doug Lea?s jsr166y implementation in my project but 
> I am not allowed to use JDK 6. I downloaded the source code but can?t 
> compile it using JDK 5 because a missing method Unsafe.putOrderedLong() 
> call within ForkJoinWorkerThread. Is there a backported version of this 
> library or is the current JDK 6 version correct under JDK 5 too?
> 

You can cause this to be compilable in Java5 by looking
for the instances of lines like:
        _unsafe.putOrderedLong(this, spOffset, s + 1); // only need store fence
         //        sp = s + 1;
And swapping the uncommenting:
        // _unsafe.putOrderedLong(this, spOffset, s + 1); // only need store fence
           sp = s + 1;

(The Java6 version is a small but noticeable optimization.)

I'll insert some better instructions in next check-in.

For things like this I wish Java had #ifdefs,
(Yes, I know I could use m4 or ant preprocessing or
even reflection here, but it is not worth doing this
just for the sake of putting out prereleases.)

-Doug





From dcholmes at optusnet.com.au  Sun Jul 20 23:37:48 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 21 Jul 2008 13:37:48 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <48725005.7070806@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCCELIHMAA.dcholmes@optusnet.com.au>

So ... Phaser seems to be to barriers what AQS is to synchronizers. It's
powerful and flexible but adds an additional burden on the user to get the
semantics right. I wouldn't push this as a replacment for CyclicBarrier or
CountdownLatch as they have simpler semantics - particularly with respect to
error conditions like broken barriers.

In the sense that Phaser is at the same conceptual level as AQS then I find
the method names appropriate.

In the example usage:

  void runTasks(List<Runnable> list) {
    final Phaser phaser = new Phaser(1); // "1" to register self
    for (Runnable r : list) {
      phaser.register();
      new Thread() {
        public void run() { r.run(); phaser.arrive(); }
      }.start();
   }
   int p = phaser.arriveAndDeregister(); // deregister self
   otherActions(); // do other things while tasks execute
   phaser.awaitAdvance(p); // wait for all tasks to arrive
 }

I don't see how the self-registration serves any purpose. Was this example
trimmed down from one in which the tasks originally waited for a "start"
signal?

I don't understand the operation of the arriveAndDeregister method.
Conceptually the phaser has two pieces of states:
 - number of registered parties: registered
 - number of parties arrived: arrivals
and the phaser advances when these two become equal. So "arrive" would
increment "arrivals"; and "deregister" would decrement "registered"; which
implies that arriveAndDeregister() would do both!  - which has to be wrong,
unless de-registration only affects future phases ??? And even then I wonder
why you wouldn't simply deregister() ?

Cheers,
David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> Sent: Tuesday, 8 July 2008 3:19 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Phasers (were: TaskBarriers)
>
>
>
> The flexible barrier functionality that was previously restricted
> to ForkJoinTasks (in class forkjoin.TaskBarrier) is being
> redone as class Phaser (targeted for j.u.c, not j.u.c.forkjoin), that
> can be applied in all kinds of tasks. For a snapshot of API, see
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/jsr166y/Phaser.html
> Comments and suggestions are very welcome as always. The API is
> likely to change a bit as we scope out further uses, and also,
> hopefully, stumble upon some better method names.
>
> Among its capabilities is allowing the number of parties in a barrier
> to vary dynamically, which CyclicBarrier doesn't and can't support,
> but people regularly ask for.
>
> The nice new class name is due to Vivek Sarkar. For a preview of some
> likely follow-ons (mainly, new kinds of FJ tasks that can
> register in various modes for Phasers, partially in support
> of analogous X10 functionality), see the paper by Vivek and others:
> http://www.cs.rice.edu/~vsarkar/PDF/SPSS08-phasers.pdf
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From jed at atlassian.com  Mon Jul 21 03:47:11 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Mon, 21 Jul 2008 17:47:11 +1000
Subject: [concurrency-interest] Single Consumer Single Producer single
	element queue
Message-ID: <48843EFF.7030108@atlassian.com>

all,

Just asking for a bit of advice as to an implementation of a SRSW queue 
which has a t most one element. In this queue any write that encounters 
an already full queue simply replaces the current element with the new 
one. Additionally I need the reader to block until an element becomes 
available, but the writer should complete immediately.

I have rolled an implementation that uses a Semaphore for allowing a 
reader to block, and the writer first drains all permits, writes its 
value then releases a permit. It works OK, but I was just wondering if 
anyone has any other ideas for implementation that may be better tuned 
for SRSW and/or more elegant.

cheers,
jed.

From jed at atlassian.com  Mon Jul 21 05:00:32 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Mon, 21 Jul 2008 19:00:32 +1000
Subject: [concurrency-interest] Single Consumer Single Producer single
	element queue
In-Reply-To: <48843EFF.7030108@atlassian.com>
References: <48843EFF.7030108@atlassian.com>
Message-ID: <6340000A-E155-48B7-B5D3-90A1677CC39C@atlassian.com>

I should have been a bit more explicit, the Queue interface is not  
required. Only get/put or equivalent. Interruption policy is not  
relevant to the basics either.

cheers,
Jed

On 21/07/2008, at 5:47 PM, Jed Wesley-Smith <jed at atlassian.com> wrote:

> all,
>
> Just asking for a bit of advice as to an implementation of a SRSW  
> queue which has a t most one element. In this queue any write that  
> encounters an already full queue simply replaces the current element  
> with the new one. Additionally I need the reader to block until an  
> element becomes available, but the writer should complete immediately.
>
> I have rolled an implementation that uses a Semaphore for allowing a  
> reader to block, and the writer first drains all permits, writes its  
> value then releases a permit. It works OK, but I was just wondering  
> if anyone has any other ideas for implementation that may be better  
> tuned for SRSW and/or more elegant.
>
> cheers,
> jed.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Mon Jul 21 08:22:27 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 21 Jul 2008 08:22:27 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCELIHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCCELIHMAA.dcholmes@optusnet.com.au>
Message-ID: <48847F83.6040404@cs.oswego.edu>

David Holmes wrote:
> 
> In the example usage:
> ...
> 
> I don't see how the self-registration serves any purpose. Was this example
> trimmed down from one in which the tasks originally waited for a "start"
> signal? 

Yes; thanks! Fixed to be more informative.

> 
> I don't understand the operation of the arriveAndDeregister method.
> Conceptually the phaser has two pieces of states:
>  - number of registered parties: registered
>  - number of parties arrived: arrivals
> and the phaser advances when these two become equal. So "arrive" would
> increment "arrivals"; and "deregister" would decrement "registered"; which
> implies that arriveAndDeregister() would do both!  - which has to be wrong,
> unless de-registration only affects future phases ??? And even then I wonder
> why you wouldn't simply deregister() ?
> 

It is because of the intersection of two rules
   You can arrive only if registered
   You can deregister only if registered.
So you can only deregister upon arrival, as a single atomic action.
(Hence the name :-)

Deregistration does indeed only impact future phases. If you don't
care about future phases, you might as well just arrive().

I'll try to clarify this in javadocs.

-Doug


From dcholmes at optusnet.com.au  Mon Jul 21 19:42:09 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 22 Jul 2008 09:42:09 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <48847F83.6040404@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEMAHMAA.dcholmes@optusnet.com.au>

Doug writes:
> David Holmes wrote:
> > I don't understand the operation of the arriveAndDeregister method.
> > Conceptually the phaser has two pieces of states:
> >  - number of registered parties: registered
> >  - number of parties arrived: arrivals
> > and the phaser advances when these two become equal. So "arrive" would
> > increment "arrivals"; and "deregister" would decrement "registered";
which
> > implies that arriveAndDeregister() would do both!  - which has to be
wrong,
> > unless de-registration only affects future phases ??? And even then I
wonder
> > why you wouldn't simply deregister() ?
> >
>
> It is because of the intersection of two rules
>    You can arrive only if registered
>    You can deregister only if registered.
> So you can only deregister upon arrival, as a single atomic action.
> (Hence the name :-)
>
> Deregistration does indeed only impact future phases. If you don't
> care about future phases, you might as well just arrive().

I just realized that there is no deregister() method, so arriveAndDeregister
would be the normal usage for deregistration. That said, shouldn't there
then also be arriveAndAwaitAdvanceAndDeregister ? I can see that being used
for a start-latch that transforms into a stop-latch:

    phaser.register();
    for (Runnable r : list) {
      phaser.register();
      new Thread() {
        public void run() {
             phaser.arriveAndAwaitAdvance(); // wait for start signal
             r.run();
             phaser.arrive(); // signal completion
        }
      }.start();
   }
   phaser.arriveAndAwaitAdvanceAndDeregister(); // wait for everyone to be
ready then start them
   // do other stuff
   phase.awaitAdvance(); // wait for everyone to complete


BTW should all the methods that return the current phase number say:

"@returns the current barrier phase number XXXXX, or a negative value if
terminated"

It seems to me we should either always says this or never - leaving the
general docs to explain that a negative phase number means that the phaser
has terminated. ("termination" strikes me as the wrong word here ... but I
can't think of anything better right now).

Cheers,
David


From dl at cs.oswego.edu  Tue Jul 22 07:13:24 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 22 Jul 2008 07:13:24 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEMAHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCEEMAHMAA.dcholmes@optusnet.com.au>
Message-ID: <4885C0D4.3070405@cs.oswego.edu>

David Holmes wrote:
> I just realized that there is no deregister() method, so arriveAndDeregister
> would be the normal usage for deregistration. That said, shouldn't there
> then also be arriveAndAwaitAdvanceAndDeregister ? I can see that being used
> for a start-latch that transforms into a stop-latch:
> 

You can get this sort of effect via
int p = phaser.arriveAndDeregister();
phaser.awaitCycleAdvance(p);

There is a small difference though. In the
non-deregistration case, arriveAndAwaitAdvance()
returns your arrival index, while
awaitAdvance(arrive()) returns phase.
There are use cases for both forms.
We don't have an arrival index form for deregistration
version though. Maybe there should be one, although
I can't offhand think of a usage.

An alternative I considered but at first rejected
was to have arrive() and arriveAndDeregister() return
a long holding both index and phase, with utilities
that could decode return value for you. This would be efficient
but a little icky wrt programmer usability. But maybe worth
supporting these in addition to the others though, which
would avoid needing arriveAndDeregisterAndAwaitAdvance().


Relatedly, maybe we should add
   awaitTermination();
(plus interrupt and timed versions)
that is behaviorally equivalent to
   while (awaitAdvance(arrive()) >= 0) {}
but can be a little more efficiently implemented internally.
This might be handy in variations of your example.
Note that it would require that you be registered
in order to call it, which might be a source of
errors that would only sometimes be trapped, other
times only leading to unexpected behavior.

-Doug

From forax at univ-mlv.fr  Tue Jul 22 08:29:52 2008
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 22 Jul 2008 14:29:52 +0200
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <4885C0D4.3070405@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCEEMAHMAA.dcholmes@optusnet.com.au>
	<4885C0D4.3070405@cs.oswego.edu>
Message-ID: <4885D2C0.4080907@univ-mlv.fr>

Doug Lea a ?crit :
> David Holmes wrote:
>> I just realized that there is no deregister() method, so 
>> arriveAndDeregister
>> would be the normal usage for deregistration. That said, shouldn't there
>> then also be arriveAndAwaitAdvanceAndDeregister ? I can see that 
>> being used
>> for a start-latch that transforms into a stop-latch:
>>
>
> You can get this sort of effect via
> int p = phaser.arriveAndDeregister();
> phaser.awaitCycleAdvance(p);
>
> There is a small difference though. In the
> non-deregistration case, arriveAndAwaitAdvance()
> returns your arrival index, while
> awaitAdvance(arrive()) returns phase.
> There are use cases for both forms.
> We don't have an arrival index form for deregistration
> version though. Maybe there should be one, although
> I can't offhand think of a usage.
>
> An alternative I considered but at first rejected
> was to have arrive() and arriveAndDeregister() return
> a long holding both index and phase, with utilities
> that could decode return value for you. This would be efficient
> but a little icky wrt programmer usability. But maybe worth
> supporting these in addition to the others though, which
> would avoid needing arriveAndDeregisterAndAwaitAdvance().
In my opinion, we could use a boolean deregister as parameter of arrive.
arrive() -> arrive(false)
arriveAndDeregister() -> arrive(true)

and to the similar trick to arriveAndAdvance.
arriveAndAdvance() -> arriveAndAdvance(false)
arriveAndDeregisterAndAwaitAdvance() -> arriveAndAdvance(true)

my two cents,
R?mi
> ...
>
> -Doug


From dcholmes at optusnet.com.au  Tue Jul 22 18:07:50 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jul 2008 08:07:50 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <4885D2C0.4080907@univ-mlv.fr>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEMIHMAA.dcholmes@optusnet.com.au>

I like Remi's idea. Seems an easy way to get the "expected" symmetry.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of R?mi
> Forax
> Sent: Tuesday, 22 July 2008 10:30 PM
> To: Doug Lea
> Cc: concurrency-interest at cs.oswego.edu; dholmes at ieee.org
> Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)
>
>
> Doug Lea a ?crit :
> > David Holmes wrote:
> >> I just realized that there is no deregister() method, so
> >> arriveAndDeregister
> >> would be the normal usage for deregistration. That said,
> shouldn't there
> >> then also be arriveAndAwaitAdvanceAndDeregister ? I can see that
> >> being used
> >> for a start-latch that transforms into a stop-latch:
> >>
> >
> > You can get this sort of effect via
> > int p = phaser.arriveAndDeregister();
> > phaser.awaitCycleAdvance(p);
> >
> > There is a small difference though. In the
> > non-deregistration case, arriveAndAwaitAdvance()
> > returns your arrival index, while
> > awaitAdvance(arrive()) returns phase.
> > There are use cases for both forms.
> > We don't have an arrival index form for deregistration
> > version though. Maybe there should be one, although
> > I can't offhand think of a usage.
> >
> > An alternative I considered but at first rejected
> > was to have arrive() and arriveAndDeregister() return
> > a long holding both index and phase, with utilities
> > that could decode return value for you. This would be efficient
> > but a little icky wrt programmer usability. But maybe worth
> > supporting these in addition to the others though, which
> > would avoid needing arriveAndDeregisterAndAwaitAdvance().
> In my opinion, we could use a boolean deregister as parameter of arrive.
> arrive() -> arrive(false)
> arriveAndDeregister() -> arrive(true)
>
> and to the similar trick to arriveAndAdvance.
> arriveAndAdvance() -> arriveAndAdvance(false)
> arriveAndDeregisterAndAwaitAdvance() -> arriveAndAdvance(true)
>
> my two cents,
> R?mi
> > ...
> >
> > -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dl at cs.oswego.edu  Tue Jul 22 19:18:31 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 22 Jul 2008 19:18:31 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEMIHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCAEMIHMAA.dcholmes@optusnet.com.au>
Message-ID: <48866AC7.5030008@cs.oswego.edu>

David Holmes wrote:
> I like Remi's idea. Seems an easy way to get the "expected" symmetry.
> 

Not so sure. Seems a bit error seeking. Looking at or writing:
   phaser.arrive(true).
doesn't plainly indicate whether you mean to deregister
or stay registered (or become registered?) And using
an enum instead seems ugly enough to annoy people.
   phaser.arrive(Phaser.STAY_REGISTERED);
Probably better would be to add a few more methods
to fill out the possibilities. Even though their names would
be uglier, they cover cases people will rarely if ever
use anyway.

-Doug



From dcholmes at optusnet.com.au  Tue Jul 22 19:37:44 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jul 2008 09:37:44 +1000
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <48866AC7.5030008@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEMJHMAA.dcholmes@optusnet.com.au>

Doug,

I was going to disagree with you but after writing that email I changed my
mind. :)

There are seven combinations to cover here (even if not all are obviously
useful), covering arrival, waiting and deregistration - combined with
interruptible/timed versions of the blocking ones. That's either a lot of
long method names, or a combination of naming and "flag" arguments. Neither
is particularly aesthetically pleasing, but long names are clearer than
parameters that you always have to look up the docs to remeber what they
mean.

arrive()
arriveAndDeregister()
arriveAndAwaitAdvance()
arriveAndAwaitAdvanceAndDeregister()
awaitAdvance()
awaitAdvanceAndDeregister()
deregister()

Cheers,
David

> -----Original Message-----
> From: Doug Lea [mailto:dl at cs.oswego.edu]
> Sent: Wednesday, 23 July 2008 9:19 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)
>
>
> David Holmes wrote:
> > I like Remi's idea. Seems an easy way to get the "expected" symmetry.
> >
>
> Not so sure. Seems a bit error seeking. Looking at or writing:
>    phaser.arrive(true).
> doesn't plainly indicate whether you mean to deregister
> or stay registered (or become registered?) And using
> an enum instead seems ugly enough to annoy people.
>    phaser.arrive(Phaser.STAY_REGISTERED);
> Probably better would be to add a few more methods
> to fill out the possibilities. Even though their names would
> be uglier, they cover cases people will rarely if ever
> use anyway.
>
> -Doug
>
>


From peter.kovacs.1.0rc at gmail.com  Tue Jul 22 23:29:04 2008
From: peter.kovacs.1.0rc at gmail.com (Peter Kovacs)
Date: Wed, 23 Jul 2008 05:29:04 +0200
Subject: [concurrency-interest] archives
In-Reply-To: <48740281.2040206@cs.oswego.edu>
References: <3e0efa20807081156y1c716887wfb333d905cbfa3b1@mail.gmail.com>
	<48740281.2040206@cs.oswego.edu>
Message-ID: <b6e8f2e80807222029p53239a36p28f4f4badd930b1a@mail.gmail.com>

Is there a way to search in them (apart from downloading and unzipping
them on my machine)?

Thanks
Peter

On Wed, Jul 9, 2008 at 2:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> Anjan Bacchu wrote:
>>
>> Hi There,
>>
>>  Are there any archives for this list ? It might help to have public
>> archives available.
>>
>
> Archive access was switched to members-only a few years ago for
> reasons I no longer recall. But because I don't recall,
> I just now switched them to public.
> See http://altair.cs.oswego.edu/pipermail/concurrency-interest/
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dcholmes at optusnet.com.au  Tue Jul 22 23:59:44 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Wed, 23 Jul 2008 13:59:44 +1000
Subject: [concurrency-interest] archives
In-Reply-To: <b6e8f2e80807222029p53239a36p28f4f4badd930b1a@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEMLHMAA.dcholmes@optusnet.com.au>

Peter,

There's a searchable archive on Nabble:

http://www.nabble.com/JSR166-Concurrency-f2681.html

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Kovacs
> Sent: Wednesday, 23 July 2008 1:29 PM
> To: Doug Lea
> Cc: Anjan Bacchu; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] archives
> 
> 
> Is there a way to search in them (apart from downloading and unzipping
> them on my machine)?
> 
> Thanks
> Peter
> 
> On Wed, Jul 9, 2008 at 2:12 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> > Anjan Bacchu wrote:
> >>
> >> Hi There,
> >>
> >>  Are there any archives for this list ? It might help to have public
> >> archives available.
> >>
> >
> > Archive access was switched to members-only a few years ago for
> > reasons I no longer recall. But because I don't recall,
> > I just now switched them to public.
> > See http://altair.cs.oswego.edu/pipermail/concurrency-interest/
> >
> > -Doug
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From Darron_Shaffer at stercomm.com  Wed Jul 23 09:27:03 2008
From: Darron_Shaffer at stercomm.com (Shaffer, Darron)
Date: Wed, 23 Jul 2008 09:27:03 -0400
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEMJHMAA.dcholmes@optusnet.com.au>
Message-ID: <FC30D8A2D3DEE64D93E8DA54A1DB349A038CB858@IWDUBCORMSG007.sci.local>

Should some of those be in the form of: awaitAdvanceThenDeregister()?

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David
Holmes
Sent: Tuesday, July 22, 2008 6:38 PM
To: Doug Lea
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)

Doug,

I was going to disagree with you but after writing that email I changed
my
mind. :)

There are seven combinations to cover here (even if not all are
obviously
useful), covering arrival, waiting and deregistration - combined with
interruptible/timed versions of the blocking ones. That's either a lot
of
long method names, or a combination of naming and "flag" arguments.
Neither
is particularly aesthetically pleasing, but long names are clearer than
parameters that you always have to look up the docs to remeber what they
mean.

arrive()
arriveAndDeregister()
arriveAndAwaitAdvance()
arriveAndAwaitAdvanceAndDeregister()
awaitAdvance()
awaitAdvanceAndDeregister()
deregister()

Cheers,
David

> -----Original Message-----
> From: Doug Lea [mailto:dl at cs.oswego.edu]
> Sent: Wednesday, 23 July 2008 9:19 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)
>
>
> David Holmes wrote:
> > I like Remi's idea. Seems an easy way to get the "expected"
symmetry.
> >
>
> Not so sure. Seems a bit error seeking. Looking at or writing:
>    phaser.arrive(true).
> doesn't plainly indicate whether you mean to deregister
> or stay registered (or become registered?) And using
> an enum instead seems ugly enough to annoy people.
>    phaser.arrive(Phaser.STAY_REGISTERED);
> Probably better would be to add a few more methods
> to fill out the possibilities. Even though their names would
> be uglier, they cover cases people will rarely if ever
> use anyway.
>
> -Doug
>
>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Wed Jul 23 10:23:18 2008
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Wed, 23 Jul 2008 16:23:18 +0200
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <FC30D8A2D3DEE64D93E8DA54A1DB349A038CB858@IWDUBCORMSG007.sci.local>
References: <FC30D8A2D3DEE64D93E8DA54A1DB349A038CB858@IWDUBCORMSG007.sci.local>
Message-ID: <48873ED6.1040901@univ-mlv.fr>

Shaffer, Darron a ?crit :
> Should some of those be in the form of: awaitAdvanceThenDeregister()?
>   
+1,
ThenDeregister is better than AndDeregister and avoid symetry with 
AndAwaitAdvance.

R?mi
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David
> Holmes
> Sent: Tuesday, July 22, 2008 6:38 PM
> To: Doug Lea
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)
>
> Doug,
>
> I was going to disagree with you but after writing that email I changed
> my
> mind. :)
>
> There are seven combinations to cover here (even if not all are
> obviously
> useful), covering arrival, waiting and deregistration - combined with
> interruptible/timed versions of the blocking ones. That's either a lot
> of
> long method names, or a combination of naming and "flag" arguments.
> Neither
> is particularly aesthetically pleasing, but long names are clearer than
> parameters that you always have to look up the docs to remeber what they
> mean.
>
> arrive()
> arriveAndDeregister()
> arriveAndAwaitAdvance()
> arriveAndAwaitAdvanceAndDeregister()
> awaitAdvance()
> awaitAdvanceAndDeregister()
> deregister()
>
> Cheers,
> David
>
>   
>> -----Original Message-----
>> From: Doug Lea [mailto:dl at cs.oswego.edu]
>> Sent: Wednesday, 23 July 2008 9:19 AM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Phasers (were: TaskBarriers)
>>
>>
>> David Holmes wrote:
>>     
>>> I like Remi's idea. Seems an easy way to get the "expected"
>>>       
> symmetry.
>   
>> Not so sure. Seems a bit error seeking. Looking at or writing:
>>    phaser.arrive(true).
>> doesn't plainly indicate whether you mean to deregister
>> or stay registered (or become registered?) And using
>> an enum instead seems ugly enough to annoy people.
>>    phaser.arrive(Phaser.STAY_REGISTERED);
>> Probably better would be to add a few more methods
>> to fill out the possibilities. Even though their names would
>> be uglier, they cover cases people will rarely if ever
>> use anyway.
>>
>> -Doug
>>
>>
>>     
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>   


From gregg at cytetech.com  Wed Jul 23 10:58:45 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 23 Jul 2008 09:58:45 -0500
Subject: [concurrency-interest] Phasers (were: TaskBarriers)
In-Reply-To: <48866AC7.5030008@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCAEMIHMAA.dcholmes@optusnet.com.au>
	<48866AC7.5030008@cs.oswego.edu>
Message-ID: <48874725.2050800@cytetech.com>

Doug Lea wrote:
> David Holmes wrote:
>> I like Remi's idea. Seems an easy way to get the "expected" symmetry.
>>
> 
> Not so sure. Seems a bit error seeking. Looking at or writing:
>   phaser.arrive(true).
> doesn't plainly indicate whether you mean to deregister
> or stay registered (or become registered?) And using
> an enum instead seems ugly enough to annoy people.
>   phaser.arrive(Phaser.STAY_REGISTERED);
> Probably better would be to add a few more methods
> to fill out the possibilities. Even though their names would
> be uglier, they cover cases people will rarely if ever
> use anyway.

The use of the connecting word "and" in the methods names might be better 
represented with "then" as an indication of the phase transitions happening in a 
time order, as in

	arriveThenAwaitAdvanceThenDeregister()
and
	arriveThenDeregister()

indicate, to me, a flow that is easy to understand, rather than a bunch of 
things, all of which get done, but which 'and' doesn't really help me know when.

Gregg Wonderly

From jed at atlassian.com  Wed Jul 23 18:31:27 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 24 Jul 2008 08:31:27 +1000
Subject: [concurrency-interest] Single Consumer Single Producer single
	element queue
In-Reply-To: <6340000A-E155-48B7-B5D3-90A1677CC39C@atlassian.com>
References: <48843EFF.7030108@atlassian.com>
	<6340000A-E155-48B7-B5D3-90A1677CC39C@atlassian.com>
Message-ID: <FA4BEF41-F7BE-411F-AEF3-8982066CC728@atlassian.com>

ok,

seems probably code is required.

In order to create a single element blocking queue (where older  
elements are discarded rather than newer elements being rejected) I  
needed a way to signal to a waiting thread that an element has become  
available. This needs to be reused for multiple add/take pairs.

I came up with a couple of different Latch implementations, one that  
has a boolean released condition suitable for SRSW, and also one that  
is more useful in MRMW. It is a inspired by the Phaser although very  
simplified. I wanted to get the lists once-over to see if there is  
something stupid I am doing.

All comments and suggestions welcomed. Method javadoc removed for  
brevity:

/**
  * Copyright 2008 Atlassian Pty Ltd
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
  * You may obtain a copy of the License at
  *
  *     http://www.apache.org/licenses/LICENSE-2.0
  *
  * Unless required by applicable law or agreed to in writing, software
  * distributed under the License is distributed on an "AS IS" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  
implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */

package com.atlassian.util.concurrent;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;

/**
  * A {@link PhasedLatch} is a latch that resets after it is released  
and can be
  * reused. A potentially waiting thread can test the current phase  
before
  * performing an action. The action is then guarded by that phase and  
can await
  * that phase.
  * <p>
  * Implementation note: currently only {@link Integer#MIN_VALUE} to
  * {@link Integer#MAX_VALUE} phases are currently supported.
  */
public class PhasedLatch
{
     private final Sync sync = new Sync();

     public void release()
     {
         sync.releaseShared(1);
     }

     public void await() throws InterruptedException
     {
         sync.await(getPhase());
     }

     public boolean await(final long timeout, final TimeUnit unit)  
throws InterruptedException
     {
         return sync.await(getPhase(), timeout, unit);
     }

     public void awaitPhase(final int phase) throws InterruptedException
     {
         sync.await(phase);
     }

     public boolean awaitPhase(final int phase, final long timeout,  
final TimeUnit unit) throws InterruptedException
     {
         return sync.await(phase, timeout, unit);
     }

     public int getPhase()
     {
         return sync.getCurrentPhase();
     }

     /**
      * This sync implements Phasing. The state represents the current  
phase as
      * an integer that continually increases. Will fail once
      * {@link Integer#MAX_VALUE} is reached.
      */
     private class Sync extends AbstractQueuedSynchronizer
     {
         private static final long serialVersionUID =  
-7753362916930221487L;

         private final ThreadLocal<Integer> waitingPhase = new  
ThreadLocal<Integer>();

         Sync()
         {
             setState(Integer.MIN_VALUE);
         }

         public int getCurrentPhase()
         {
             return getState();
         }

         void await(final int phase) throws InterruptedException
         {
             waitingPhase.set(phase);
             acquireSharedInterruptibly(1);
             waitingPhase.set(null);
         }

         boolean await(final int phase, final long timeout, final  
TimeUnit unit) throws InterruptedException
         {
             waitingPhase.set(getState());
             final boolean result = tryAcquireSharedNanos(1,  
unit.toNanos(timeout));
             if (result)
             {
                 waitingPhase.set(null);
             }
             return result;
         }

         @Override
         protected int tryAcquireShared(final int ignore)
         {
             return (getState() > waitingPhase.get()) ? 0 : -1;
         }

         @Override
         protected boolean tryReleaseShared(final int ignore)
         {
             while (true)
             {
                 int state = getState();
                 if (compareAndSetState(state, state++))
                 {
                     return true;
                 }
             }
         }
     }
}

From alarmnummer at gmail.com  Thu Jul 24 08:16:10 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 24 Jul 2008 14:16:10 +0200
Subject: [concurrency-interest] Single Consumer Single Producer single
	element queue
In-Reply-To: <FA4BEF41-F7BE-411F-AEF3-8982066CC728@atlassian.com>
References: <48843EFF.7030108@atlassian.com>
	<6340000A-E155-48B7-B5D3-90A1677CC39C@atlassian.com>
	<FA4BEF41-F7BE-411F-AEF3-8982066CC728@atlassian.com>
Message-ID: <1466c1d60807240516u3f991d44q8ba5623cf99e2166@mail.gmail.com>

What about the following?

class ItemContainer<E>{
	private final Lock lock = new ReentrantLock();
	private final Condition itemAvailableCondition = lock.newCondition();
	private E item;

	public void place(E item){
		if(item == null)throw new NullPointerException();
		lock.acquire();
		try{
			this.item = item;
			itemAvailableCondition.signal();				
		}finally{
			lock.release();
		}
	}

	public E take()throws InterruptedException{
		lock.acquire();
		try{	
			while(item==null)
				lock.await();

			E result = item;
			item = null;
			return result;
		}finally{
			lock.release();		
		}
	}
}

On Thu, Jul 24, 2008 at 12:31 AM, Jed Wesley-Smith <jed at atlassian.com> wrote:
> ok,
>
> seems probably code is required.
>
> In order to create a single element blocking queue (where older elements are
> discarded rather than newer elements being rejected) I needed a way to
> signal to a waiting thread that an element has become available. This needs
> to be reused for multiple add/take pairs.
>
> I came up with a couple of different Latch implementations, one that has a
> boolean released condition suitable for SRSW, and also one that is more
> useful in MRMW. It is a inspired by the Phaser although very simplified. I
> wanted to get the lists once-over to see if there is something stupid I am
> doing.
>
> All comments and suggestions welcomed. Method javadoc removed for brevity:
>
> /**
>  * Copyright 2008 Atlassian Pty Ltd
>  *
>  * Licensed under the Apache License, Version 2.0 (the "License");
>  * you may not use this file except in compliance with the License.
>  * You may obtain a copy of the License at
>  *
>  *     http://www.apache.org/licenses/LICENSE-2.0
>  *
>  * Unless required by applicable law or agreed to in writing, software
>  * distributed under the License is distributed on an "AS IS" BASIS,
>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
>  * See the License for the specific language governing permissions and
>  * limitations under the License.
>  */
>
> package com.atlassian.util.concurrent;
>
> import java.util.concurrent.TimeUnit;
> import java.util.concurrent.locks.AbstractQueuedSynchronizer;
>
> /**
>  * A {@link PhasedLatch} is a latch that resets after it is released and can
> be
>  * reused. A potentially waiting thread can test the current phase before
>  * performing an action. The action is then guarded by that phase and can
> await
>  * that phase.
>  * <p>
>  * Implementation note: currently only {@link Integer#MIN_VALUE} to
>  * {@link Integer#MAX_VALUE} phases are currently supported.
>  */
> public class PhasedLatch
> {
>    private final Sync sync = new Sync();
>
>    public void release()
>    {
>        sync.releaseShared(1);
>    }
>
>    public void await() throws InterruptedException
>    {
>        sync.await(getPhase());
>    }
>
>    public boolean await(final long timeout, final TimeUnit unit) throws
> InterruptedException
>    {
>        return sync.await(getPhase(), timeout, unit);
>    }
>
>    public void awaitPhase(final int phase) throws InterruptedException
>    {
>        sync.await(phase);
>    }
>
>    public boolean awaitPhase(final int phase, final long timeout, final
> TimeUnit unit) throws InterruptedException
>    {
>        return sync.await(phase, timeout, unit);
>    }
>
>    public int getPhase()
>    {
>        return sync.getCurrentPhase();
>    }
>
>    /**
>     * This sync implements Phasing. The state represents the current phase
> as
>     * an integer that continually increases. Will fail once
>     * {@link Integer#MAX_VALUE} is reached.
>     */
>    private class Sync extends AbstractQueuedSynchronizer
>    {
>        private static final long serialVersionUID = -7753362916930221487L;
>
>        private final ThreadLocal<Integer> waitingPhase = new
> ThreadLocal<Integer>();
>
>        Sync()
>        {
>            setState(Integer.MIN_VALUE);
>        }
>
>        public int getCurrentPhase()
>        {
>            return getState();
>        }
>
>        void await(final int phase) throws InterruptedException
>        {
>            waitingPhase.set(phase);
>            acquireSharedInterruptibly(1);
>            waitingPhase.set(null);
>        }
>
>        boolean await(final int phase, final long timeout, final TimeUnit
> unit) throws InterruptedException
>        {
>            waitingPhase.set(getState());
>            final boolean result = tryAcquireSharedNanos(1,
> unit.toNanos(timeout));
>            if (result)
>            {
>                waitingPhase.set(null);
>            }
>            return result;
>        }
>
>        @Override
>        protected int tryAcquireShared(final int ignore)
>        {
>            return (getState() > waitingPhase.get()) ? 0 : -1;
>        }
>
>        @Override
>        protected boolean tryReleaseShared(final int ignore)
>        {
>            while (true)
>            {
>                int state = getState();
>                if (compareAndSetState(state, state++))
>                {
>                    return true;
>                }
>            }
>        }
>    }
> }
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jed at atlassian.com  Thu Jul 24 22:03:53 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Fri, 25 Jul 2008 12:03:53 +1000
Subject: [concurrency-interest] Single Consumer Single Producer single
	element queue
In-Reply-To: <1466c1d60807240516u3f991d44q8ba5623cf99e2166@mail.gmail.com>
References: <48843EFF.7030108@atlassian.com>
	<6340000A-E155-48B7-B5D3-90A1677CC39C@atlassian.com>
	<FA4BEF41-F7BE-411F-AEF3-8982066CC728@atlassian.com>
	<1466c1d60807240516u3f991d44q8ba5623cf99e2166@mail.gmail.com>
Message-ID: <0779B2C5-3FDD-45B5-831B-9CF05FF5A03F@atlassian.com>

Well, I wanted the writer thread to be lock-free if possible (and it  
was my first chance to play with AQS!). For my SRSW case I actually  
came up with a simpler latch implementation that I believe is lock- 
free (please advise if I am wrong) as far as the writer/releaser  
thread is concerned. It approximates the usage of a Condition without  
requiring a Lock. This requires a little more care in its use as you  
can't use the lock to ensure atomicity, but works well for my use  
(where I have a single writer thread and multiple reader threads each  
with its own queue.

Following is the BooleanLatch and then it's usage.

/**
  * Copyright 2008 Atlassian Pty Ltd
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
  * You may obtain a copy of the License at
  *
  *     http://www.apache.org/licenses/LICENSE-2.0
  *
  * Unless required by applicable law or agreed to in writing, software
  * distributed under the License is distributed on an "AS IS" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  
implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */

package com.atlassian.util.concurrent;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;

/**
  * A {@link BooleanLatch} is a reusable latch that resets after it is  
released
  * and waited on. It depends on a boolean condition of being released  
or not and
  * becomes unreleased when one thread successfully awaits it. It is  
useful for
  * rally like release-wait-release coordination, and as a replacement  
to waiting
  * on a {@link Condition} (it should be faster as the write thread  
does not need
  * to acquire a lock in order to signal.
  * <p>
  * This latch is suitable for SRSW coordination. MRSW is supported  
but has the
  * same semantics as {@link Condition#signal()}, that is to say that
  * {@link Condition#signalAll()} is not supported and if there are  
multiple
  * waiters then the thread that is released is arbitrary.
  */
public class BooleanLatch {
     private final Sync sync = new Sync();

     public void release() {
         sync.release(0);
     }

     public void await() throws InterruptedException {
         sync.acquireInterruptibly(0);
     }

     public boolean await(final long timeout, final TimeUnit unit)  
throws InterruptedException {
         return sync.tryAcquireNanos(1, unit.toNanos(timeout));
     }

     /**
      * Synchronization control For BooleanLatch. Uses AQS state to  
represent
      * released state.
      */
     private class Sync extends AbstractQueuedSynchronizer {
         private static final long serialVersionUID =  
-3475411235403448115L;

         private static final int RELEASED = 0;
         private static final int UNAVAILABLE = -1;

         private Sync() {
             setState(UNAVAILABLE);
         }

         @Override
         protected boolean tryAcquire(final int ignore) {
             final boolean released = (getState() == RELEASED);
             if (released) {
                 compareAndSetState(RELEASED, UNAVAILABLE);
             }
             return released;
         }

         @Override
         protected boolean tryRelease(final int ignore) {
             final int state = getState();
             if (state == UNAVAILABLE) {
                 setState(RELEASED);
             }
             return true;
         }
     }
}

usage:

/**
  * Copyright 2008 Atlassian Pty Ltd
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
  * You may obtain a copy of the License at
  *
  *     http://www.apache.org/licenses/LICENSE-2.0
  *
  * Unless required by applicable law or agreed to in writing, software
  * distributed under the License is distributed on an "AS IS" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  
implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */

package com.atlassian.util.concurrent;

import static com.atlassian.util.concurrent.Assertions.notNull;

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicReference;

/**
  * A Reference with queue semantics where rather than getting the  
current
  * reference it is taken instead. Analagous to a single element
  * {@link BlockingQueue} but does not support that whole interface.
  *
  * @param <T>
  */
public class BlockingReference<T> {
     private final AtomicReference<T> ref = new AtomicReference<T>();
     private final BooleanLatch latch = new BooleanLatch();

     public T take() throws InterruptedException {
         latch.await();
         return ref.getAndSet(null);
     }

     public T take(final long timeout, final TimeUnit unit) throws  
TimeoutException, InterruptedException {
         if (!latch.await(timeout, unit)) {
             throw new TimeoutException();
         }
         return ref.getAndSet(null);
     }

     public void set(final T value) {
         notNull("value", value);
         ref.set(value);
         latch.release();
     }

     public boolean isNull() {
         return ref.get() == null;
     }
}

This implementation is SRSW safe, to make it MRSW safe you just need  
to spin and check the result to make sure it is not null before  
returning it. eg.

     public T take() throws InterruptedException {
         while (true) {
             latch.await();
             final T result = ref.getAndSet(null);
             if (result != null) {
                 return result;
             }
         }
     }


On 24/07/2008, at 10:16 PM, Peter Veentjer wrote:

> What about the following?
>
> class ItemContainer<E>{
> 	private final Lock lock = new ReentrantLock();
> 	private final Condition itemAvailableCondition = lock.newCondition();
> 	private E item;
>
> 	public void place(E item){
> 		if(item == null)throw new NullPointerException();
> 		lock.acquire();
> 		try{
> 			this.item = item;
> 			itemAvailableCondition.signal();				
> 		}finally{
> 			lock.release();
> 		}
> 	}
>
> 	public E take()throws InterruptedException{
> 		lock.acquire();
> 		try{	
> 			while(item==null)
> 				lock.await();
>
> 			E result = item;
> 			item = null;
> 			return result;
> 		}finally{
> 			lock.release();		
> 		}
> 	}
> }
>>

From charlesforgy at hotmail.com  Sun Jul 27 15:23:40 2008
From: charlesforgy at hotmail.com (Charles Forgy)
Date: Sun, 27 Jul 2008 15:23:40 -0400
Subject: [concurrency-interest] Use of park/unpark in forkjoin framework
Message-ID: <BLU108-W483580C6C6183ECE8379ABC8800@phx.gbl>


I apologize if this has been asked before, but I could not find this information.  Is there a way to tell the forkjoin framework to delay parking a thread--e.g., to spin for a specified time before parking? I have an application where the lengths of the tasks can vary, and I believe this ability would be helpful there.  -- Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080727/89cedb37/attachment.html>

From lnezda at gmail.com  Sun Jul 27 23:36:03 2008
From: lnezda at gmail.com (Luke Nezda)
Date: Sun, 27 Jul 2008 22:36:03 -0500
Subject: [concurrency-interest] jsr166y.forkjoin.ForkJoinWorkerThread on
	Java5
Message-ID: <b205e9650807272036kb3c4d5n655e71f2f979d2a6@mail.gmail.com>

Hello All-
I am interested in using forkjoin on Java5 JVMs (Linux, Windows, *Mac
OS X).  I downloaded the jsr166 CVS head today and it fails to build
with Java5 JDK because of recent changes to ForkJoinWorker introduced
at Revision 1.19 July 7th.  Specifically 2 calls to
sun.misc.Unsafe.putOrderedLong().  This seems to be a Java6 change to
sun.misc.Unsafe as it compiles fine & runs demos with the Mac OS X
Java6 JDK (didn't have other platforms to check with today), but fails
to build with Mac OS X Java5 JDK -- have to guess since these classes
aren't quite official.  I replaced these
putOrderedLong(Object,long,long) calls with putLong(Object,long,long)
calls and then build and demos run on Java5.  This is clearly an
unprincipaled change on my part.  I don't know the relationship
between putLong() and putOrderedLong() -- is this change correct?
Alternatively, was the previous revision (1.18) correct? Could I
revert to that to have forkjoin working on Java5?
Thanks in advance,
-Luke

From dl at cs.oswego.edu  Mon Jul 28 11:39:08 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 28 Jul 2008 11:39:08 -0400
Subject: [concurrency-interest] jsr166y.forkjoin.ForkJoinWorkerThread
 on	Java5
In-Reply-To: <b205e9650807272036kb3c4d5n655e71f2f979d2a6@mail.gmail.com>
References: <b205e9650807272036kb3c4d5n655e71f2f979d2a6@mail.gmail.com>
Message-ID: <488DE81C.3070802@cs.oswego.edu>

Luke Nezda wrote:
> Hello All-
> I am interested in using forkjoin on Java5 JVMs (Linux, Windows, *Mac
> OS X).  I downloaded the jsr166 CVS head today and it fails to build
> with Java5 

Recycling an answer from last week...

> 
> You can cause this to be compilable in Java5 by looking
> for the instances of lines like:
>        _unsafe.putOrderedLong(this, spOffset, s + 1); // only need store fence
>         //        sp = s + 1;
> And swapping the uncommenting:
>        // _unsafe.putOrderedLong(this, spOffset, s + 1); // only need store fence
>           sp = s + 1;
> 
> (The Java6 version is a small but noticeable optimization.)

Given the set of complaints, I suppose I should go back to
checking in Java5 compatible only and provide instructions
for those who want to get 5% or so performance improvements
using Java6 or early Java7 builds.

-Doug

From dl at cs.oswego.edu  Mon Jul 28 11:53:40 2008
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 28 Jul 2008 11:53:40 -0400
Subject: [concurrency-interest] Use of park/unpark in forkjoin framework
In-Reply-To: <BLU108-W483580C6C6183ECE8379ABC8800@phx.gbl>
References: <BLU108-W483580C6C6183ECE8379ABC8800@phx.gbl>
Message-ID: <488DEB84.30404@cs.oswego.edu>

Charles Forgy wrote:
>   Is there a way to tell the forkjoin framework to delay 
> parking a thread--e.g., to spin for a specified time before parking? I 
> have an application where the lengths of the tasks can vary, and I 
> believe this ability would be helpful there.  -- Thanks.
> 


The FJ steal/spin/block control is in the process of being
improved (mainly for better support for constructions
using phasers) so you might not see this issue in
upcoming updates. But we must internally handle these to
balance responsiveness with resource consumption and contention.

However, there are a slowly increasing bunch of methods hiding in
ForkJoinWorkerThread that you can use for more fine-grained
control. See for example executeTask (javadoc pasted below)
that you can call in a method that is "sure" that others it
is waiting for will finish sooner than would be worth blocking for.

In general though, in the majority of cases where you think
you want this kind of functionality, a better answer is to
further subdivide processing, to avoid these kinds of imbalances.
You can subdivide surprisingly finely in this framework
and still get good performance. As a very rough rule of thumb,
tasks with more than around 1000 CPU instructions are usually
worth subdividing.

-Doug


public static boolean executeTask()

     Helps this program complete by processing a local, stolen or submitted 
task, if one is available. This method may be useful when several tasks are 
forked, and only one of them must be joined, as in:

        while (!t1.isDone() && !t2.isDone())
          ForkJoinWorkerThread.executeTask();


     Returns:
         true if a task was run; a false return indicates that no task was 
available.





From nielspeter at npstrandberg.com  Tue Jul 29 09:33:36 2008
From: nielspeter at npstrandberg.com (nielspeter at npstrandberg.com)
Date: Tue, 29 Jul 2008 15:33:36 +0200 (CEST)
Subject: [concurrency-interest] Consumers working on a queue of primary key's
Message-ID: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>

It must be better to create a limited number of consumer runnable's taking
db primary keys from a BlockingQueue to work on instead of creating a lot
of heavy Runnable objects.

My question: Is there a "better" or more "correct" way to do this?


Here is what I do:

1) Add a lot of primary keys to a BlockingQueue.

2) Create a newFixedThreadPool ExecutorService, with
 let's say, max 5
threads.

3) Create the 5 new Runnable?s. Each given a reference to a db service
class and the BlockingQueue that contains the primary id's.

4) Start each Runnable.

5) Each Runnable takes a primary key from the queue and start to work.
That includes som db manipulation and some http calls.

The ExecutorService is terminating when the queue is empty.

The CountDownLatch is used to eleminate "busy-waiting". Instead of writing:

while(!keyQueue.isEmpty()) {
// do nothing
}

Poison added to stop each consumer and not have to wait for an
InterruptedException to be thrown by each consumer.

Here is the code:

package com.npstrandberg.concurrency;

import java.util.List;
import java.util.ArrayList;
import java.util.concurrent.*;


public class Test {

    static long poison = -1L;

    public static void main(String[] args) {

        // create some bogus primary keys
        List<Long> keys = new ArrayList<Long>();
        for (long i = 0; i < 10; i++) {
            keys.add(i);
        }

        new Test().doWork(keys);

    }

    public void doWork(List<Long> ids) {

        BlockingQueue<Long> keyQueue = new LinkedBlockingQueue<Long>(ids);
        CountDownLatch latch = new CountDownLatch(keyQueue.size());

        int threads = 5;
        ExecutorService es = Executors.newFixedThreadPool(threads);

        for (int i = 0; i < threads; i++) {
            es.execute(new Consumer(keyQueue, latch)); // and the db
service class
            keyQueue.add(poison); // add poison for each consumer at the
back of the queue.
        }



        // wait until the queue is empty
        try {
            latch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // shutdown ExecutorService
        shutdownAndAwaitTermination(es);

        System.out.println("All Done!");

        System.out.println("CountDownLatch: " + latch.getCount());
        System.out.println("Queue empty? " + keyQueue.size());

    }

    /*
    From
http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html
     */
    void shutdownAndAwaitTermination(ExecutorService pool) {
        pool.shutdown(); // Disable new tasks from being submitted
        try {
            // Wait a while for existing tasks to terminate
            if (!pool.awaitTermination(10, TimeUnit.SECONDS)) {
                pool.shutdownNow(); // Cancel currently executing tasks
                // Wait a while for tasks to respond to being cancelled
                if (!pool.awaitTermination(10, TimeUnit.SECONDS))
                    System.err.println("Pool did not terminate");
            }
        } catch (InterruptedException ie) {
            // (Re-)Cancel if current thread also interrupted
            pool.shutdownNow();
            // Preserve interrupt status
            Thread.currentThread().interrupt();
        }
    }


    class Consumer implements Runnable {


        private BlockingQueue<Long> keyQueue;
        private CountDownLatch latch;

        Consumer(BlockingQueue<Long> keyQueue, CountDownLatch latch) {
            this.keyQueue = keyQueue;
            this.latch = latch;
        }

        public void run() {
            while (true) {
                try {
                    long key = keyQueue.take();

                    // poison?
                    if (key == poison) {
                        System.out.println(this + " done!");
                        break;
                    }

                    latch.countDown();

                    // fetch som db data

                    // do some http fetching

                    // do some parsing

                    // som som db data

                    System.out.println(this + " work on '" + key + "'
done!");

                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}


/ Niels Peter


From tim at peierls.net  Tue Jul 29 10:20:21 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 29 Jul 2008 10:20:21 -0400
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
Message-ID: <63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>

You're essentially re-implementing a limited form of ThreadPoolExecutor (on
top of ThreadPoolExecutor!) to avoid "creating a lot of heavy Runnable
objects". But your Consumer inner loop is doing database and HTTP fetching,
parsing, and other stuff ... what sounds like quite a lot of work. The cost
of creating a Runnable to perform that work is probably quite small compared
to the work itself.

So you can just use the ExecutorService interface directly and simplify the
code:

public void doWork(List<Long> keys) {
  int threads = 5;
  ExecutorService es = Executors.newFixedThreadPool(threads);
  for (final Long key : keys) {
    es.execute(new Runnable() {
      public void run() {
        // fetch som db data, do some http fetching, do some parsing, som
som db data
        System.out.println(this + " work on '" + key + "' done!");
      }
    });
  }

  shutdownAndAwaitTermination(es);

  System.out.println("All Done!");
}

This way you don't have to collect all the keys at once. You could change
doWork(List<Long>) to doWork(Iterable<Long>) without changing the body of
the code, and then supply an Iterable that retrieves the keys incrementally.

A variant would be to use an ArrayBlockingQueue instead of the
LinkedBlockingQueue that newFixedThreadPool uses. Bounding the queue would
throttle submission to the executor service rather than face the risk of
resource exhaustion the way unbounded queues do.

--tim



On Tue, Jul 29, 2008 at 9:33 AM, <nielspeter at npstrandberg.com> wrote:

> It must be better to create a limited number of consumer runnable's taking
> db primary keys from a BlockingQueue to work on instead of creating a lot
> of heavy Runnable objects.
>
> My question: Is there a "better" or more "correct" way to do this?
>
>
> Here is what I do:
>
> 1) Add a lot of primary keys to a BlockingQueue.
>
> 2) Create a newFixedThreadPool ExecutorService, with? let's say, max 5
> threads.
>
> 3) Create the 5 new Runnable's. Each given a reference to a db service
> class and the BlockingQueue that contains the primary id's.
>
> 4) Start each Runnable.
>
> 5) Each Runnable takes a primary key from the queue and start to work.
> That includes som db manipulation and some http calls.
>
> The ExecutorService is terminating when the queue is empty.
>
> The CountDownLatch is used to eleminate "busy-waiting". Instead of writing:
>
> while(!keyQueue.isEmpty()) {
> // do nothing
> }
>
> Poison added to stop each consumer and not have to wait for an
> InterruptedException to be thrown by each consumer.
>
> Here is the code:
>
> package com.npstrandberg.concurrency;
>
> import java.util.List;
> import java.util.ArrayList;
> import java.util.concurrent.*;
>
>
> public class Test {
>
>    static long poison = -1L;
>
>    public static void main(String[] args) {
>
>        // create some bogus primary keys
>        List<Long> keys = new ArrayList<Long>();
>        for (long i = 0; i < 10; i++) {
>            keys.add(i);
>        }
>
>        new Test().doWork(keys);
>
>    }
>
>    public void doWork(List<Long> ids) {
>
>        BlockingQueue<Long> keyQueue = new LinkedBlockingQueue<Long>(ids);
>        CountDownLatch latch = new CountDownLatch(keyQueue.size());
>
>        int threads = 5;
>        ExecutorService es = Executors.newFixedThreadPool(threads);
>
>        for (int i = 0; i < threads; i++) {
>            es.execute(new Consumer(keyQueue, latch)); // and the db
> service class
>            keyQueue.add(poison); // add poison for each consumer at the
> back of the queue.
>        }
>
>
>
>        // wait until the queue is empty
>        try {
>            latch.await();
>        } catch (InterruptedException e) {
>            e.printStackTrace();
>        }
>
>        // shutdown ExecutorService
>        shutdownAndAwaitTermination(es);
>
>        System.out.println("All Done!");
>
>        System.out.println("CountDownLatch: " + latch.getCount());
>        System.out.println("Queue empty? " + keyQueue.size());
>
>    }
>
>    /*
>    From
>
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html
>     */
>    void shutdownAndAwaitTermination(ExecutorService pool) {
>        pool.shutdown(); // Disable new tasks from being submitted
>        try {
>            // Wait a while for existing tasks to terminate
>            if (!pool.awaitTermination(10, TimeUnit.SECONDS)) {
>                pool.shutdownNow(); // Cancel currently executing tasks
>                // Wait a while for tasks to respond to being cancelled
>                if (!pool.awaitTermination(10, TimeUnit.SECONDS))
>                    System.err.println("Pool did not terminate");
>            }
>        } catch (InterruptedException ie) {
>            // (Re-)Cancel if current thread also interrupted
>            pool.shutdownNow();
>            // Preserve interrupt status
>            Thread.currentThread().interrupt();
>        }
>    }
>
>
>    class Consumer implements Runnable {
>
>
>        private BlockingQueue<Long> keyQueue;
>        private CountDownLatch latch;
>
>        Consumer(BlockingQueue<Long> keyQueue, CountDownLatch latch) {
>            this.keyQueue = keyQueue;
>            this.latch = latch;
>        }
>
>        public void run() {
>            while (true) {
>                try {
>                    long key = keyQueue.take();
>
>                    // poison?
>                    if (key == poison) {
>                        System.out.println(this + " done!");
>                        break;
>                    }
>
>                    latch.countDown();
>
>                    // fetch som db data
>
>                    // do some http fetching
>
>                    // do some parsing
>
>                    // som som db data
>
>                    System.out.println(this + " work on '" + key + "'
> done!");
>
>                } catch (InterruptedException e) {
>                    e.printStackTrace();
>                }
>            }
>        }
>    }
> }
>
>
> / Niels Peter
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080729/92969f77/attachment.html>

From alarmnummer at gmail.com  Tue Jul 29 10:41:32 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 29 Jul 2008 16:41:32 +0200
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
Message-ID: <1466c1d60807290741y534460c2r3e9fc2b4a41aaca8@mail.gmail.com>

On Tue, Jul 29, 2008 at 3:33 PM,  <nielspeter at npstrandberg.com> wrote:
> It must be better to create a limited number of consumer runnable's taking
> db primary keys from a BlockingQueue to work on instead of creating a lot
> of heavy Runnable objects.
>
> My question: Is there a "better" or more "correct" way to do this?

I had the problem for some time ago and that is why I decided to
create the Repeater:

http://prometheus.codehaus.org/guide-repeater.html

But a runnable is not a heavy object (unlike a thread). So if you wrap
the key in a Runnable, you can use the Executor without any custom
code. And in most cases this would be the best solution (executors are
well tested and part of the standard jre).

I have not looked at your code, I don't have the time at the moment.

>
>
> Here is what I do:
>
> 1) Add a lot of primary keys to a BlockingQueue.
>
> 2) Create a newFixedThreadPool ExecutorService, with? let's say, max 5
> threads.
>
> 3) Create the 5 new Runnable's. Each given a reference to a db service
> class and the BlockingQueue that contains the primary id's.
>
> 4) Start each Runnable.
>
> 5) Each Runnable takes a primary key from the queue and start to work.
> That includes som db manipulation and some http calls.
>
> The ExecutorService is terminating when the queue is empty.
>
> The CountDownLatch is used to eleminate "busy-waiting". Instead of writing:
>
> while(!keyQueue.isEmpty()) {
> // do nothing
> }
>
> Poison added to stop each consumer and not have to wait for an
> InterruptedException to be thrown by each consumer.
>
> Here is the code:
>
> package com.npstrandberg.concurrency;
>
> import java.util.List;
> import java.util.ArrayList;
> import java.util.concurrent.*;
>
>
> public class Test {
>
>    static long poison = -1L;
>
>    public static void main(String[] args) {
>
>        // create some bogus primary keys
>        List<Long> keys = new ArrayList<Long>();
>        for (long i = 0; i < 10; i++) {
>            keys.add(i);
>        }
>
>        new Test().doWork(keys);
>
>    }
>
>    public void doWork(List<Long> ids) {
>
>        BlockingQueue<Long> keyQueue = new LinkedBlockingQueue<Long>(ids);
>        CountDownLatch latch = new CountDownLatch(keyQueue.size());
>
>        int threads = 5;
>        ExecutorService es = Executors.newFixedThreadPool(threads);
>
>        for (int i = 0; i < threads; i++) {
>            es.execute(new Consumer(keyQueue, latch)); // and the db
> service class
>            keyQueue.add(poison); // add poison for each consumer at the
> back of the queue.
>        }
>
>
>
>        // wait until the queue is empty
>        try {
>            latch.await();
>        } catch (InterruptedException e) {
>            e.printStackTrace();
>        }
>
>        // shutdown ExecutorService
>        shutdownAndAwaitTermination(es);
>
>        System.out.println("All Done!");
>
>        System.out.println("CountDownLatch: " + latch.getCount());
>        System.out.println("Queue empty? " + keyQueue.size());
>
>    }
>
>    /*
>    From
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html
>     */
>    void shutdownAndAwaitTermination(ExecutorService pool) {
>        pool.shutdown(); // Disable new tasks from being submitted
>        try {
>            // Wait a while for existing tasks to terminate
>            if (!pool.awaitTermination(10, TimeUnit.SECONDS)) {
>                pool.shutdownNow(); // Cancel currently executing tasks
>                // Wait a while for tasks to respond to being cancelled
>                if (!pool.awaitTermination(10, TimeUnit.SECONDS))
>                    System.err.println("Pool did not terminate");
>            }
>        } catch (InterruptedException ie) {
>            // (Re-)Cancel if current thread also interrupted
>            pool.shutdownNow();
>            // Preserve interrupt status
>            Thread.currentThread().interrupt();
>        }
>    }
>
>
>    class Consumer implements Runnable {
>
>
>        private BlockingQueue<Long> keyQueue;
>        private CountDownLatch latch;
>
>        Consumer(BlockingQueue<Long> keyQueue, CountDownLatch latch) {
>            this.keyQueue = keyQueue;
>            this.latch = latch;
>        }
>
>        public void run() {
>            while (true) {
>                try {
>                    long key = keyQueue.take();
>
>                    // poison?
>                    if (key == poison) {
>                        System.out.println(this + " done!");
>                        break;
>                    }
>
>                    latch.countDown();
>
>                    // fetch som db data
>
>                    // do some http fetching
>
>                    // do some parsing
>
>                    // som som db data
>
>                    System.out.println(this + " work on '" + key + "'
> done!");
>
>                } catch (InterruptedException e) {
>                    e.printStackTrace();
>                }
>            }
>        }
>    }
> }
>
>
> / Niels Peter
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From matthias at mernst.org  Tue Jul 29 11:49:46 2008
From: matthias at mernst.org (Matthias Ernst)
Date: Tue, 29 Jul 2008 17:49:46 +0200
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
Message-ID: <22ec15240807290849w53d765c6ye62eb9a47396ddaf@mail.gmail.com>

On Tue, Jul 29, 2008 at 3:33 PM,  <nielspeter at npstrandberg.com> wrote:
> It must be better to create a limited number of consumer runnable's taking
> db primary keys from a BlockingQueue to work on instead of creating a lot
> of heavy Runnable objects.

...
> 5) Each Runnable takes a primary key from the queue and start to work.
> That includes som db manipulation and some http calls.

Wrong construction-site as we say in German.

Your runnables need not be heavier than 16 bytes (8 bytes object
header, 4 bytes outer context, 4 bytes reference to primary key
object). The client libraries to the db and http will already create
orders of magnitude more garbage than those runnables and they involve
network io. You could create thousands of runnables before your HTTP
server has even parsed the protocol version.

Matthias

From takeshi10 at gmail.com  Tue Jul 29 13:34:24 2008
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Tue, 29 Jul 2008 14:34:24 -0300
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
Message-ID: <7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>

correct me if im wrong, but using an ArrayBlockingQueue instead of the
LinkedBlockingQueue on an ExecutorService will cause it to reject (by
throwing exceptions) work instead of trotle the producer

using Iterable might turn a bit complicated for the client, but have
the advantage of working with prefetched keys - in other words, you'd
only have to implement the more clever version if its needed

On 7/29/08, Tim Peierls <tim at peierls.net> wrote:
> You're essentially re-implementing a limited form of ThreadPoolExecutor (on
> top of ThreadPoolExecutor!) to avoid "creating a lot of heavy Runnable
> objects". But your Consumer inner loop is doing database and HTTP fetching,
> parsing, and other stuff ... what sounds like quite a lot of work. The cost
> of creating a Runnable to perform that work is probably quite small compared
> to the work itself.
>
> So you can just use the ExecutorService interface directly and simplify the
> code:
>
> public void doWork(List<Long> keys) {
>   int threads = 5;
>   ExecutorService es =
> Executors.newFixedThreadPool(threads);
>    for (final Long key : keys) {
>     es.execute(new Runnable() {
>       public void run() {
>         // fetch som db data, do some http fetching, do some parsing, som
> som db data
>         System.out.println(this + " work on '" + key + "' done!");
>        }
>     });
>   }
>
>   shutdownAndAwaitTermination(es);
>
>   System.out.println("All Done!");
> }
>
>  This way you don't have to collect all the keys at once. You could change
> doWork(List<Long>) to doWork(Iterable<Long>) without changing the body of
> the code, and then supply an Iterable that retrieves the keys incrementally.
>
> A variant would be to use an ArrayBlockingQueue instead of the
> LinkedBlockingQueue that newFixedThreadPool uses. Bounding the queue would
> throttle submission to the executor service rather than face the risk of
> resource exhaustion the way unbounded queues do.
>
> --tim
>
>
>
>
> On Tue, Jul 29, 2008 at 9:33 AM, <nielspeter at npstrandberg.com> wrote:
> > It must be better to create a limited number of consumer runnable's taking
> > db primary keys from a BlockingQueue to work on instead of creating a lot
> > of heavy Runnable objects.
> >
> > My question: Is there a "better" or more "correct" way to do this?
> >
> >
> > Here is what I do:
> >
> > 1) Add a lot of primary keys to a BlockingQueue.
> >
> > 2) Create a newFixedThreadPool ExecutorService, with? let's say, max 5
> > threads.
> >
> > 3) Create the 5 new Runnable's. Each given a reference to a db service
> > class and the BlockingQueue that contains the primary id's.
> >
> > 4) Start each Runnable.
> >
> > 5) Each Runnable takes a primary key from the queue and start to work.
> > That includes som db manipulation and some http calls.
> >
> > The ExecutorService is terminating when the queue is empty.
> >
> > The CountDownLatch is used to eleminate "busy-waiting". Instead of
> writing:
> >
> > while(!keyQueue.isEmpty()) {
> > // do nothing
> > }
> >
> > Poison added to stop each consumer and not have to wait for an
> > InterruptedException to be thrown by each consumer.
> >
> > Here is the code:
> >
> > package com.npstrandberg.concurrency;
> >
> > import java.util.List;
> > import java.util.ArrayList;
> > import java.util.concurrent.*;
> >
> >
> > public class Test {
> >
> >    static long poison = -1L;
> >
> >    public static void main(String[] args) {
> >
> >        // create some bogus primary keys
> >        List<Long> keys = new ArrayList<Long>();
> >        for (long i = 0; i < 10; i++) {
> >            keys.add(i);
> >        }
> >
> >        new Test().doWork(keys);
> >
> >    }
> >
> >    public void doWork(List<Long> ids) {
> >
> >        BlockingQueue<Long> keyQueue = new
> LinkedBlockingQueue<Long>(ids);
> >        CountDownLatch latch = new
> CountDownLatch(keyQueue.size());
> >
> >        int threads = 5;
> >        ExecutorService es =
> Executors.newFixedThreadPool(threads);
> >
> >        for (int i = 0; i < threads; i++) {
> >            es.execute(new Consumer(keyQueue, latch)); // and the db
> > service class
> >            keyQueue.add(poison); // add poison for each consumer at the
> > back of the queue.
> >        }
> >
> >
> >
> >        // wait until the queue is empty
> >        try {
> >            latch.await();
> >        } catch (InterruptedException e) {
> >            e.printStackTrace();
> >        }
> >
> >        // shutdown ExecutorService
> >        shutdownAndAwaitTermination(es);
> >
> >        System.out.println("All Done!");
> >
> >        System.out.println("CountDownLatch: " +
> latch.getCount());
> >        System.out.println("Queue empty? " + keyQueue.size());
> >
> >    }
> >
> >    /*
> >    From
> >
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html
> >     */
> >    void shutdownAndAwaitTermination(ExecutorService pool)
> {
> >        pool.shutdown(); // Disable new tasks from being submitted
> >        try {
> >            // Wait a while for existing tasks to terminate
> >            if (!pool.awaitTermination(10, TimeUnit.SECONDS)) {
> >                pool.shutdownNow(); // Cancel currently executing tasks
> >                // Wait a while for tasks to respond to being cancelled
> >                if (!pool.awaitTermination(10, TimeUnit.SECONDS))
> >                    System.err.println("Pool did not terminate");
> >            }
> >        } catch (InterruptedException ie) {
> >            // (Re-)Cancel if current thread also interrupted
> >            pool.shutdownNow();
> >            // Preserve interrupt status
> >            Thread.currentThread().interrupt();
> >        }
> >    }
> >
> >
> >    class Consumer implements Runnable {
> >
> >
> >        private BlockingQueue<Long> keyQueue;
> >        private CountDownLatch latch;
> >
> >        Consumer(BlockingQueue<Long> keyQueue, CountDownLatch latch) {
> >            this.keyQueue = keyQueue;
> >            this.latch = latch;
> >        }
> >
> >        public void run() {
> >            while (true) {
> >                try {
> >                    long key = keyQueue.take();
> >
> >                    // poison?
> >                    if (key == poison) {
> >                        System.out.println(this + " done!");
> >                        break;
> >                    }
> >
> >                    latch.countDown();
> >
> >                    // fetch som db data
> >
> >                    // do some http fetching
> >
> >                    // do some parsing
> >
> >                    // som som db data
> >
> >                    System.out.println(this + " work on '" + key + "'
> > done!");
> >
> >                } catch (InterruptedException e) {
> >                    e.printStackTrace();
> >                }
> >            }
> >        }
> >    }
> > }
> >
> >
> > / Niels Peter
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> >
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> _______________________________________________
>  Concurrency-interest mailing list
>  Concurrency-interest at cs.oswego.edu
>  http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
[]'s
Marcelo Takeshi Fukushima


From tim at peierls.net  Tue Jul 29 13:57:50 2008
From: tim at peierls.net (Tim Peierls)
Date: Tue, 29 Jul 2008 13:57:50 -0400
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
Message-ID: <63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>

On Tue, Jul 29, 2008 at 1:34 PM, Marcelo Fukushima <takeshi10 at gmail.com>wrote:

> correct me if im wrong, but using an ArrayBlockingQueue instead of the
> LinkedBlockingQueue on an ExecutorService will cause it to reject (by
> throwing exceptions) work instead of trotle the producer


Right, to get the throttling you would additionally need a
RejectedExecutionHandler like CallerRunsPolicy.



> using Iterable might turn a bit complicated for the client, but have
> the advantage of working with prefetched keys - in other words, you'd
> only have to implement the more clever version if its needed
>

Yes, relaxing the signature to use Iterable would allow clients to pass List
still, but also permit incremental implementations.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080729/c96af68f/attachment.html>

From alarmnummer at gmail.com  Tue Jul 29 14:39:31 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 29 Jul 2008 20:39:31 +0200
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
Message-ID: <1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>

> Right, to get the throttling you would additionally need a
> RejectedExecutionHandler like CallerRunsPolicy.

The CallerRunsPolicy is dangerous and imho should only be used with
much care (I have not seen a good application of it so far)

For example:
you have no idea what the priority of the thread is that calls the
execute method. If the priority is high it could cause serious
problems.

It is a shame that the Executor has lost the ability to block. In the
original executor of doug lea this was possible.

It is possible to make the call blocking by creating a custom
rejectedexecutionhandler that directly accesses the workqueue and does
a put instead of an offer.

>
>
>>
>> using Iterable might turn a bit complicated for the client, but have
>> the advantage of working with prefetched keys - in other words, you'd
>> only have to implement the more clever version if its needed
>
> Yes, relaxing the signature to use Iterable would allow clients to pass List
> still, but also permit incremental implementations.
>
> --tim
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From joe.bowbeer at gmail.com  Tue Jul 29 19:05:39 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 29 Jul 2008 16:05:39 -0700
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
Message-ID: <31f2a7bd0807291605l51078f9eifcbc3a48f6fd0f26@mail.gmail.com>

On Tue, Jul 29, 2008 at 10:57 AM, Tim Peierls  wrote:

> On Tue, Jul 29, 2008 at 1:34 PM, Marcelo Fukushima wrote:
>
>> correct me if im wrong, but using an ArrayBlockingQueue instead of the
>> LinkedBlockingQueue on an ExecutorService will cause it to reject (by
>> throwing exceptions) work instead of trotle the producer
>
>
> Right, to get the throttling you would additionally need a
> RejectedExecutionHandler like CallerRunsPolicy.
>
>
>
>> using Iterable might turn a bit complicated for the client, but have
>> the advantage of working with prefetched keys - in other words, you'd
>> only have to implement the more clever version if its needed
>>
>
> Yes, relaxing the signature to use Iterable would allow clients to pass
> List still, but also permit incremental implementations.
>
> --tim
>
>
Another way to achieve throttling is with an ExecutorCompletionService.

See submitWork method below.

public class Test {

    private static final int THREADS = 5;
    private static final int MAX_PENDING = 10;

    public void submitWork(Iterable<Long> keys, CompletionService<?> cs)
            throws InterruptedException {
        int pending = 0;
        for (Long key : keys) {
            if (pending == MAX_PENDING) {
                cs.take();
                pending--;
            }
            cs.submit(makeRunnable(key), null);
            pending++;
        }
    }

    private Runnable makeRunnable(final Long key) {
        return new Runnable() {
            public void run() {
                // TODO
                System.out.println("Work on '" + key + "' done!");
            }
        };
    }

    public static void main(String[] args) throws InterruptedException {

        // create some bogus primary keys
        List<Long> keys = new ArrayList<Long>();
        for (long i = 0; i < 20; i++) {
            keys.add(i);
        }

        ExecutorService es = Executors.newFixedThreadPool(THREADS);
        CompletionService<?> ecs = new
ExecutorCompletionService<Object>(es);

        new Test().submitWork(keys, ecs);

        es.shutdown();
        es.awaitTermination(10, TimeUnit.SECONDS);
        System.out.println("All Done!");
    }
}

--Joe
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080729/226c0e12/attachment.html>

From joe.bowbeer at gmail.com  Tue Jul 29 20:32:06 2008
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 29 Jul 2008 17:32:06 -0700
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <31f2a7bd0807291605l51078f9eifcbc3a48f6fd0f26@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
	<31f2a7bd0807291605l51078f9eifcbc3a48f6fd0f26@mail.gmail.com>
Message-ID: <31f2a7bd0807291732u344b8d7sd17204a2b0a34332@mail.gmail.com>

PS -

Using a CompletionService avoids the possibility that one slowpoke task
could hold up the producer thread indefinitely -- which is something that
could happen when using CallerRuns with a single producer thread.


On Tue, Jul 29, 2008 at 4:05 PM, wrote:

> On Tue, Jul 29, 2008 at 10:57 AM, Tim Peierls  wrote:
>
> On Tue, Jul 29, 2008 at 1:34 PM, Marcelo Fukushima wrote:
>>
>>> correct me if im wrong, but using an ArrayBlockingQueue instead of the
>>> LinkedBlockingQueue on an ExecutorService will cause it to reject (by
>>> throwing exceptions) work instead of trotle the producer
>>
>>
>> Right, to get the throttling you would additionally need a
>> RejectedExecutionHandler like CallerRunsPolicy.
>>
>>
>>
>>> using Iterable might turn a bit complicated for the client, but have
>>> the advantage of working with prefetched keys - in other words, you'd
>>> only have to implement the more clever version if its needed
>>>
>>
>> Yes, relaxing the signature to use Iterable would allow clients to pass
>> List still, but also permit incremental implementations.
>>
>> --tim
>>
>>
> Another way to achieve throttling is with an ExecutorCompletionService.
>
> See submitWork method below.
>
> public class Test {
>
>     private static final int THREADS = 5;
>     private static final int MAX_PENDING = 10;
>
>     public void submitWork(Iterable<Long> keys, CompletionService<?> cs)
>             throws InterruptedException {
>         int pending = 0;
>         for (Long key : keys) {
>             if (pending == MAX_PENDING) {
>                 cs.take();
>                 pending--;
>             }
>             cs.submit(makeRunnable(key), null);
>             pending++;
>         }
>     }
>
>     private Runnable makeRunnable(final Long key) {
>         return new Runnable() {
>             public void run() {
>                 // TODO
>                 System.out.println("Work on '" + key + "' done!");
>             }
>         };
>     }
>
>     public static void main(String[] args) throws InterruptedException {
>
>         // create some bogus primary keys
>         List<Long> keys = new ArrayList<Long>();
>         for (long i = 0; i < 20; i++) {
>             keys.add(i);
>         }
>
>         ExecutorService es = Executors.newFixedThreadPool(THREADS);
>         CompletionService<?> ecs = new
> ExecutorCompletionService<Object>(es);
>
>         new Test().submitWork(keys, ecs);
>
>         es.shutdown();
>         es.awaitTermination(10, TimeUnit.SECONDS);
>         System.out.println("All Done!");
>     }
> }
>
> --Joe
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20080729/a9580d94/attachment-0001.html>

From ziba at summa-tech.com  Wed Jul 30 06:58:04 2008
From: ziba at summa-tech.com (Eduardo Ito)
Date: Wed, 30 Jul 2008 07:58:04 -0300
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
	<1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>
Message-ID: <d72ed5e90807300358y43854fdbk24c9a495d42a5609@mail.gmail.com>

There is an implementation of "CallerBlocksPolicy" instead of CallerRunsPolicy?
I need something like this.


On Tue, Jul 29, 2008 at 3:39 PM, Peter Veentjer <alarmnummer at gmail.com> wrote:
>> Right, to get the throttling you would additionally need a
>> RejectedExecutionHandler like CallerRunsPolicy.
>
> The CallerRunsPolicy is dangerous and imho should only be used with
> much care (I have not seen a good application of it so far)
>
> For example:
> you have no idea what the priority of the thread is that calls the
> execute method. If the priority is high it could cause serious
> problems.
>
> It is a shame that the Executor has lost the ability to block. In the
> original executor of doug lea this was possible.
>
> It is possible to make the call blocking by creating a custom
> rejectedexecutionhandler that directly accesses the workqueue and does
> a put instead of an offer.
>
>>
>>
>>>
>>> using Iterable might turn a bit complicated for the client, but have
>>> the advantage of working with prefetched keys - in other words, you'd
>>> only have to implement the more clever version if its needed
>>
>> Yes, relaxing the signature to use Iterable would allow clients to pass List
>> still, but also permit incremental implementations.
>>
>> --tim
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Eduardo Issao Ito
Summa Technologies

"The structure of a system tends to mirror the structure of the group
producing it."
[Mel Conway - April, 1968 Datamation]

From alarmnummer at gmail.com  Wed Jul 30 07:09:49 2008
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Wed, 30 Jul 2008 13:09:49 +0200
Subject: [concurrency-interest] Consumers working on a queue of primary
	key's
In-Reply-To: <d72ed5e90807300358y43854fdbk24c9a495d42a5609@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
	<1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>
	<d72ed5e90807300358y43854fdbk24c9a495d42a5609@mail.gmail.com>
Message-ID: <1466c1d60807300409i68d72ee4r2fbd7e1d6318df9b@mail.gmail.com>

It is quite easy to implement yourself.

example:

class CallerBlocksPolicy extends RejectedExecutionHandler{
   void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
        try{
             executor.workQueue.put(r);
       }catch(InterruptedException ex){
              Thread.interrupt();//restore flag
              ... and now you need to figure out what to do with the
task (probably just drop it).
       }
   }
}

I wrote this code in notepad, so don't shoot me if it contains bugs.
But I hope you get the picture.

On Wed, Jul 30, 2008 at 12:58 PM, Eduardo Ito <ziba at summa-tech.com> wrote:
> There is an implementation of "CallerBlocksPolicy" instead of CallerRunsPolicy?
> I need something like this.
>
>
> On Tue, Jul 29, 2008 at 3:39 PM, Peter Veentjer <alarmnummer at gmail.com> wrote:
>>> Right, to get the throttling you would additionally need a
>>> RejectedExecutionHandler like CallerRunsPolicy.
>>
>> The CallerRunsPolicy is dangerous and imho should only be used with
>> much care (I have not seen a good application of it so far)
>>
>> For example:
>> you have no idea what the priority of the thread is that calls the
>> execute method. If the priority is high it could cause serious
>> problems.
>>
>> It is a shame that the Executor has lost the ability to block. In the
>> original executor of doug lea this was possible.
>>
>> It is possible to make the call blocking by creating a custom
>> rejectedexecutionhandler that directly accesses the workqueue and does
>> a put instead of an offer.
>>
>>>
>>>
>>>>
>>>> using Iterable might turn a bit complicated for the client, but have
>>>> the advantage of working with prefetched keys - in other words, you'd
>>>> only have to implement the more clever version if its needed
>>>
>>> Yes, relaxing the signature to use Iterable would allow clients to pass List
>>> still, but also permit incremental implementations.
>>>
>>> --tim
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Eduardo Issao Ito
> Summa Technologies
>
> "The structure of a system tends to mirror the structure of the group
> producing it."
> [Mel Conway - April, 1968 Datamation]
>

From gregg at cytetech.com  Wed Jul 30 12:14:33 2008
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 30 Jul 2008 11:14:33 -0500
Subject: [concurrency-interest] Consumers working on a queue of primary
 key's
In-Reply-To: <1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>
References: <53101.195.249.127.231.1217338416.squirrel@webmail01.one.com>
	<63b4e4050807290720y406036b1xee5d678164617cad@mail.gmail.com>
	<7288749d0807291034j72f4c46bwaae57ef415eeffd3@mail.gmail.com>
	<63b4e4050807291057lb3dd9d1s58a2342bd5adf481@mail.gmail.com>
	<1466c1d60807291139o714bb4e7w1a284330bdd4b45@mail.gmail.com>
Message-ID: <48909369.50809@cytetech.com>

Peter Veentjer wrote:
>> Right, to get the throttling you would additionally need a
>> RejectedExecutionHandler like CallerRunsPolicy.
> 
> The CallerRunsPolicy is dangerous and imho should only be used with
> much care (I have not seen a good application of it so far)
> 
> For example:
> you have no idea what the priority of the thread is that calls the
> execute method. If the priority is high it could cause serious
> problems.
> 
> It is a shame that the Executor has lost the ability to block. In the
> original executor of doug lea this was possible.

Yes, I too wish that there was an available CallerBlocksPolicy, but that too is 
not always the perfect solution, given the expectation of most callers, that 
they are starting an asynchronous activity.  In the end, it's probably best to 
really pay attention to where you can best throttle things, and make that happen 
well before you are ready to put work into a queue.

Gregg Wonderly

From dcholmes at optusnet.com.au  Wed Jul 30 18:37:55 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 31 Jul 2008 08:37:55 +1000
Subject: [concurrency-interest] Consumers working on a queue of
	primarykey's
In-Reply-To: <1466c1d60807300409i68d72ee4r2fbd7e1d6318df9b@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEPIHMAA.dcholmes@optusnet.com.au>

As I recall it isn't quite this straight-forward. While the put() will block
the caller if the queue is full, there's no guarantee that a direct put()
into the queue will cause the work to be processed. In theory (unless I
remebering an older version - there have been so many :) ) the queue could
be full but then be emptied and all worker threads idle-timeout before the
put() actually completes. In that case there won't be any workers to do a
take(). It's unlikely, and can only happen if the TPE is configured in a
particular way, but as I said no guarantee.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Veentjer
> Sent: Wednesday, 30 July 2008 9:10 PM
> To: Eduardo Ito
> Cc: concurrency-interest at cs.oswego.edu; Tim Peierls;
> nielspeter at npstrandberg.com
> Subject: Re: [concurrency-interest] Consumers working on a queue of
> primarykey's
>
>
> It is quite easy to implement yourself.
>
> example:
>
> class CallerBlocksPolicy extends RejectedExecutionHandler{
>    void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
>         try{
>              executor.workQueue.put(r);
>        }catch(InterruptedException ex){
>               Thread.interrupt();//restore flag
>               ... and now you need to figure out what to do with the
> task (probably just drop it).
>        }
>    }
> }
>
> I wrote this code in notepad, so don't shoot me if it contains bugs.
> But I hope you get the picture.
>
> On Wed, Jul 30, 2008 at 12:58 PM, Eduardo Ito <ziba at summa-tech.com> wrote:
> > There is an implementation of "CallerBlocksPolicy" instead of
> CallerRunsPolicy?
> > I need something like this.
> >
> >
> > On Tue, Jul 29, 2008 at 3:39 PM, Peter Veentjer
> <alarmnummer at gmail.com> wrote:
> >>> Right, to get the throttling you would additionally need a
> >>> RejectedExecutionHandler like CallerRunsPolicy.
> >>
> >> The CallerRunsPolicy is dangerous and imho should only be used with
> >> much care (I have not seen a good application of it so far)
> >>
> >> For example:
> >> you have no idea what the priority of the thread is that calls the
> >> execute method. If the priority is high it could cause serious
> >> problems.
> >>
> >> It is a shame that the Executor has lost the ability to block. In the
> >> original executor of doug lea this was possible.
> >>
> >> It is possible to make the call blocking by creating a custom
> >> rejectedexecutionhandler that directly accesses the workqueue and does
> >> a put instead of an offer.
> >>
> >>>
> >>>
> >>>>
> >>>> using Iterable might turn a bit complicated for the client, but have
> >>>> the advantage of working with prefetched keys - in other words, you'd
> >>>> only have to implement the more clever version if its needed
> >>>
> >>> Yes, relaxing the signature to use Iterable would allow
> clients to pass List
> >>> still, but also permit incremental implementations.
> >>>
> >>> --tim
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
> >
> > --
> > Eduardo Issao Ito
> > Summa Technologies
> >
> > "The structure of a system tends to mirror the structure of the group
> > producing it."
> > [Mel Conway - April, 1968 Datamation]
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jed at atlassian.com  Wed Jul 30 20:34:40 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 31 Jul 2008 10:34:40 +1000
Subject: [concurrency-interest] Consumers working on a queue
	of	primarykey's
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEPIHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCCEPIHMAA.dcholmes@optusnet.com.au>
Message-ID: <489108A0.8090405@atlassian.com>

David Holmes wrote:
> As I recall it isn't quite this straight-forward. While the put() will block
> the caller if the queue is full, there's no guarantee that a direct put()
> into the queue will cause the work to be processed. In theory (unless I
> remebering an older version - there have been so many :) ) the queue could
> be full but then be emptied and all worker threads idle-timeout before the
> put() actually completes. In that case there won't be any workers to do a
> take(). It's unlikely, and can only happen if the TPE is configured in a
> particular way, but as I said no guarantee.
>   

We have a BoundedExecutor class that wraps an ExecutorService with a 
Semaphore. For instance:

public class BoundedExecutor {
    private final ExecutorService executor;
    private final Semaphore semaphore;

    public BoundedExecutor(final ExecutorService executor, final int 
permits) {
        this.executor = executor;
        semaphore = new Semaphore(permits);
    }

    public void execute(final Runnable command) {
        try {
            semaphore.acquire();
        }
        catch (final InterruptedException e) {
            throw new RejectedExecutionException(e);
        }
        try {
            executor.execute(new Runnable() {
                public void run() {
                    try {
                        command.run();
                    }
                    finally {
                        semaphore.release();
                    }
                }
            });
        }
        catch (final RejectedExecutionException rej) {
            semaphore.release();
            throw rej;
        }
    }
    ...
}


cheers,
jed.

From dcholmes at optusnet.com.au  Wed Jul 30 20:45:02 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 31 Jul 2008 10:45:02 +1000
Subject: [concurrency-interest] Consumers working on a queue of
	primarykey's
In-Reply-To: <489108A0.8090405@atlassian.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEPMHMAA.dcholmes@optusnet.com.au>

Hi Jed,

I'm not quite clear on the intended semantics here. How many permits do you
initialize to? If you release a permit after completion then this controls
the number of queued+active submissions. And you still expect rejected
executions here to throw an exception not to block until submission is
possible.

Cheers,
David Holmes

> -----Original Message-----
> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
> Sent: Thursday, 31 July 2008 10:35 AM
> To: dholmes at ieee.org
> Cc: Peter Veentjer; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Consumers working on a queue of
> primarykey's
>
>
> David Holmes wrote:
> > As I recall it isn't quite this straight-forward. While the
> put() will block
> > the caller if the queue is full, there's no guarantee that a
> direct put()
> > into the queue will cause the work to be processed. In theory (unless I
> > remebering an older version - there have been so many :) ) the
> queue could
> > be full but then be emptied and all worker threads idle-timeout
> before the
> > put() actually completes. In that case there won't be any
> workers to do a
> > take(). It's unlikely, and can only happen if the TPE is configured in a
> > particular way, but as I said no guarantee.
> >
>
> We have a BoundedExecutor class that wraps an ExecutorService with a
> Semaphore. For instance:
>
> public class BoundedExecutor {
>     private final ExecutorService executor;
>     private final Semaphore semaphore;
>
>     public BoundedExecutor(final ExecutorService executor, final int
> permits) {
>         this.executor = executor;
>         semaphore = new Semaphore(permits);
>     }
>
>     public void execute(final Runnable command) {
>         try {
>             semaphore.acquire();
>         }
>         catch (final InterruptedException e) {
>             throw new RejectedExecutionException(e);
>         }
>         try {
>             executor.execute(new Runnable() {
>                 public void run() {
>                     try {
>                         command.run();
>                     }
>                     finally {
>                         semaphore.release();
>                     }
>                 }
>             });
>         }
>         catch (final RejectedExecutionException rej) {
>             semaphore.release();
>             throw rej;
>         }
>     }
>     ...
> }
>
>
> cheers,
> jed.


From jed at atlassian.com  Wed Jul 30 22:16:14 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 31 Jul 2008 12:16:14 +1000
Subject: [concurrency-interest] Consumers working on a queue of
	primarykey's
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEPMHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCCEPMHMAA.dcholmes@optusnet.com.au>
Message-ID: <4891206E.5070609@atlassian.com>

Hi, David.

Basically this only allows a bound of N actively running or queued tasks 
and blocks on submit if N tasks are currently queued/running.

The number of permits is up to the client. If the queue size is < the 
(bound - pool size) then it doesn't really do anything apart from 
maintain a Semaphore that is always positive (basically this is a 
config/programming failure, albeit a relatively benign one).

If the queue size > than (bound - pool size) then tasks should never get 
rejected by the underlying Executor and will only throw RejectedEE if 
interrupted.

In cleaning this code for the list I forgot to add that it implements 
Executor. Making it implement ExecutorService complicates life a bit 
mostly due to what to do if invokeAny is called with a collection of 
tasks that is larger than the total number of permits.

In truth the RejectedExecutionException catch block should probably be 
expanded to be a bit smarter and more defensive. It doesn't currently 
handle RuntimeExceptions and Errors thrown during the queuing phase for 
instance. In practice this isn't a great concern as we only use the 
Executors (which we have never seen throw anything on submission), but 
it should be handled if the class was to be added to a library for instance.

cheers,
jed.

David Holmes wrote:
> Hi Jed,
>
> I'm not quite clear on the intended semantics here. How many permits do you
> initialize to? If you release a permit after completion then this controls
> the number of queued+active submissions. And you still expect rejected
> executions here to throw an exception not to block until submission is
> possible.
>   
>> -----Original Message-----
>> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
>> Sent: Thursday, 31 July 2008 10:35 AM
>> To: dholmes at ieee.org
>> Cc: Peter Veentjer; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Consumers working on a queue of
>> primarykey's
>>
>>
>> David Holmes wrote:
>>     
>>> As I recall it isn't quite this straight-forward. While the
>>>       
>> put() will block
>>     
>>> the caller if the queue is full, there's no guarantee that a
>>>       
>> direct put()
>>     
>>> into the queue will cause the work to be processed. In theory (unless I
>>> remebering an older version - there have been so many :) ) the
>>>       
>> queue could
>>     
>>> be full but then be emptied and all worker threads idle-timeout
>>>       
>> before the
>>     
>>> put() actually completes. In that case there won't be any
>>>       
>> workers to do a
>>     
>>> take(). It's unlikely, and can only happen if the TPE is configured in a
>>> particular way, but as I said no guarantee.
>>>
>>>       
>> We have a BoundedExecutor class that wraps an ExecutorService with a
>> Semaphore. For instance:
>>
>> public class BoundedExecutor {
>>     private final ExecutorService executor;
>>     private final Semaphore semaphore;
>>
>>     public BoundedExecutor(final ExecutorService executor, final int
>> permits) {
>>         this.executor = executor;
>>         semaphore = new Semaphore(permits);
>>     }
>>
>>     public void execute(final Runnable command) {
>>         try {
>>             semaphore.acquire();
>>         }
>>         catch (final InterruptedException e) {
>>             throw new RejectedExecutionException(e);
>>         }
>>         try {
>>             executor.execute(new Runnable() {
>>                 public void run() {
>>                     try {
>>                         command.run();
>>                     }
>>                     finally {
>>                         semaphore.release();
>>                     }
>>                 }
>>             });
>>         }
>>         catch (final RejectedExecutionException rej) {
>>             semaphore.release();
>>             throw rej;
>>         }
>>     }
>>     ...
>> }
>>
>>
>> cheers,
>> jed.
>>     
>
>   


From dcholmes at optusnet.com.au  Wed Jul 30 22:31:44 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 31 Jul 2008 12:31:44 +1000
Subject: [concurrency-interest] Consumers working on a queue
	ofprimarykey's
In-Reply-To: <4891206E.5070609@atlassian.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEPNHMAA.dcholmes@optusnet.com.au>

I see. So to operate this in the classic way you'd set the number of permits
equal to the queue capacity plus the max number of pool threads. That way a
permit would only be denied if the execute() would be rejected. Though
there's a race condition with the worker releasing the permit and getting
the next task from the queue, which could allow a new submission to acquire
the semaphore but still get rejected because the queue is still full.

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jed
> Wesley-Smith
> Sent: Thursday, 31 July 2008 12:16 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Consumers working on a queue
> ofprimarykey's
>
>
> Hi, David.
>
> Basically this only allows a bound of N actively running or queued tasks
> and blocks on submit if N tasks are currently queued/running.
>
> The number of permits is up to the client. If the queue size is < the
> (bound - pool size) then it doesn't really do anything apart from
> maintain a Semaphore that is always positive (basically this is a
> config/programming failure, albeit a relatively benign one).
>
> If the queue size > than (bound - pool size) then tasks should never get
> rejected by the underlying Executor and will only throw RejectedEE if
> interrupted.
>
> In cleaning this code for the list I forgot to add that it implements
> Executor. Making it implement ExecutorService complicates life a bit
> mostly due to what to do if invokeAny is called with a collection of
> tasks that is larger than the total number of permits.
>
> In truth the RejectedExecutionException catch block should probably be
> expanded to be a bit smarter and more defensive. It doesn't currently
> handle RuntimeExceptions and Errors thrown during the queuing phase for
> instance. In practice this isn't a great concern as we only use the
> Executors (which we have never seen throw anything on submission), but
> it should be handled if the class was to be added to a library
> for instance.
>
> cheers,
> jed.
>
> David Holmes wrote:
> > Hi Jed,
> >
> > I'm not quite clear on the intended semantics here. How many
> permits do you
> > initialize to? If you release a permit after completion then
> this controls
> > the number of queued+active submissions. And you still expect rejected
> > executions here to throw an exception not to block until submission is
> > possible.
> >
> >> -----Original Message-----
> >> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
> >> Sent: Thursday, 31 July 2008 10:35 AM
> >> To: dholmes at ieee.org
> >> Cc: Peter Veentjer; concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] Consumers working on a queue of
> >> primarykey's
> >>
> >>
> >> David Holmes wrote:
> >>
> >>> As I recall it isn't quite this straight-forward. While the
> >>>
> >> put() will block
> >>
> >>> the caller if the queue is full, there's no guarantee that a
> >>>
> >> direct put()
> >>
> >>> into the queue will cause the work to be processed. In theory
> (unless I
> >>> remebering an older version - there have been so many :) ) the
> >>>
> >> queue could
> >>
> >>> be full but then be emptied and all worker threads idle-timeout
> >>>
> >> before the
> >>
> >>> put() actually completes. In that case there won't be any
> >>>
> >> workers to do a
> >>
> >>> take(). It's unlikely, and can only happen if the TPE is
> configured in a
> >>> particular way, but as I said no guarantee.
> >>>
> >>>
> >> We have a BoundedExecutor class that wraps an ExecutorService with a
> >> Semaphore. For instance:
> >>
> >> public class BoundedExecutor {
> >>     private final ExecutorService executor;
> >>     private final Semaphore semaphore;
> >>
> >>     public BoundedExecutor(final ExecutorService executor, final int
> >> permits) {
> >>         this.executor = executor;
> >>         semaphore = new Semaphore(permits);
> >>     }
> >>
> >>     public void execute(final Runnable command) {
> >>         try {
> >>             semaphore.acquire();
> >>         }
> >>         catch (final InterruptedException e) {
> >>             throw new RejectedExecutionException(e);
> >>         }
> >>         try {
> >>             executor.execute(new Runnable() {
> >>                 public void run() {
> >>                     try {
> >>                         command.run();
> >>                     }
> >>                     finally {
> >>                         semaphore.release();
> >>                     }
> >>                 }
> >>             });
> >>         }
> >>         catch (final RejectedExecutionException rej) {
> >>             semaphore.release();
> >>             throw rej;
> >>         }
> >>     }
> >>     ...
> >> }
> >>
> >>
> >> cheers,
> >> jed.
> >>
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jed at atlassian.com  Wed Jul 30 22:39:27 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 31 Jul 2008 12:39:27 +1000
Subject: [concurrency-interest] Consumers working on a queue
	ofprimarykey's
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEPNHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCKEPNHMAA.dcholmes@optusnet.com.au>
Message-ID: <489125DF.8090905@atlassian.com>

Right, except that to set the queue size at all would be to basically 
invite the race condition to hurt you :-)

Normally you'd probably use something like one of the Executors fixed 
thread pools as the delegate and therefore have a practically unbounded 
queue (unless you are setting your permit bound up near Integer.MAX_VALUE).

cheers,
jed.

David Holmes wrote:
> I see. So to operate this in the classic way you'd set the number of permits
> equal to the queue capacity plus the max number of pool threads. That way a
> permit would only be denied if the execute() would be rejected. Though
> there's a race condition with the worker releasing the permit and getting
> the next task from the queue, which could allow a new submission to acquire
> the semaphore but still get rejected because the queue is still full.
>
> David
>
>   
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jed
>> Wesley-Smith
>> Sent: Thursday, 31 July 2008 12:16 PM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Consumers working on a queue
>> ofprimarykey's
>>
>>
>> Hi, David.
>>
>> Basically this only allows a bound of N actively running or queued tasks
>> and blocks on submit if N tasks are currently queued/running.
>>
>> The number of permits is up to the client. If the queue size is < the
>> (bound - pool size) then it doesn't really do anything apart from
>> maintain a Semaphore that is always positive (basically this is a
>> config/programming failure, albeit a relatively benign one).
>>
>> If the queue size > than (bound - pool size) then tasks should never get
>> rejected by the underlying Executor and will only throw RejectedEE if
>> interrupted.
>>
>> In cleaning this code for the list I forgot to add that it implements
>> Executor. Making it implement ExecutorService complicates life a bit
>> mostly due to what to do if invokeAny is called with a collection of
>> tasks that is larger than the total number of permits.
>>
>> In truth the RejectedExecutionException catch block should probably be
>> expanded to be a bit smarter and more defensive. It doesn't currently
>> handle RuntimeExceptions and Errors thrown during the queuing phase for
>> instance. In practice this isn't a great concern as we only use the
>> Executors (which we have never seen throw anything on submission), but
>> it should be handled if the class was to be added to a library
>> for instance.
>>
>> cheers,
>> jed.
>>
>> David Holmes wrote:
>>     
>>> Hi Jed,
>>>
>>> I'm not quite clear on the intended semantics here. How many
>>>       
>> permits do you
>>     
>>> initialize to? If you release a permit after completion then
>>>       
>> this controls
>>     
>>> the number of queued+active submissions. And you still expect rejected
>>> executions here to throw an exception not to block until submission is
>>> possible.
>>>
>>>       
>>>> -----Original Message-----
>>>> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
>>>> Sent: Thursday, 31 July 2008 10:35 AM
>>>> To: dholmes at ieee.org
>>>> Cc: Peter Veentjer; concurrency-interest at cs.oswego.edu
>>>> Subject: Re: [concurrency-interest] Consumers working on a queue of
>>>> primarykey's
>>>>
>>>>
>>>> David Holmes wrote:
>>>>
>>>>         
>>>>> As I recall it isn't quite this straight-forward. While the
>>>>>
>>>>>           
>>>> put() will block
>>>>
>>>>         
>>>>> the caller if the queue is full, there's no guarantee that a
>>>>>
>>>>>           
>>>> direct put()
>>>>
>>>>         
>>>>> into the queue will cause the work to be processed. In theory
>>>>>           
>> (unless I
>>     
>>>>> remebering an older version - there have been so many :) ) the
>>>>>
>>>>>           
>>>> queue could
>>>>
>>>>         
>>>>> be full but then be emptied and all worker threads idle-timeout
>>>>>
>>>>>           
>>>> before the
>>>>
>>>>         
>>>>> put() actually completes. In that case there won't be any
>>>>>
>>>>>           
>>>> workers to do a
>>>>
>>>>         
>>>>> take(). It's unlikely, and can only happen if the TPE is
>>>>>           
>> configured in a
>>     
>>>>> particular way, but as I said no guarantee.
>>>>>
>>>>>
>>>>>           
>>>> We have a BoundedExecutor class that wraps an ExecutorService with a
>>>> Semaphore. For instance:
>>>>
>>>> public class BoundedExecutor {
>>>>     private final ExecutorService executor;
>>>>     private final Semaphore semaphore;
>>>>
>>>>     public BoundedExecutor(final ExecutorService executor, final int
>>>> permits) {
>>>>         this.executor = executor;
>>>>         semaphore = new Semaphore(permits);
>>>>     }
>>>>
>>>>     public void execute(final Runnable command) {
>>>>         try {
>>>>             semaphore.acquire();
>>>>         }
>>>>         catch (final InterruptedException e) {
>>>>             throw new RejectedExecutionException(e);
>>>>         }
>>>>         try {
>>>>             executor.execute(new Runnable() {
>>>>                 public void run() {
>>>>                     try {
>>>>                         command.run();
>>>>                     }
>>>>                     finally {
>>>>                         semaphore.release();
>>>>                     }
>>>>                 }
>>>>             });
>>>>         }
>>>>         catch (final RejectedExecutionException rej) {
>>>>             semaphore.release();
>>>>             throw rej;
>>>>         }
>>>>     }
>>>>     ...
>>>> }
>>>>
>>>>         


From dcholmes at optusnet.com.au  Wed Jul 30 22:44:16 2008
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 31 Jul 2008 12:44:16 +1000
Subject: [concurrency-interest] Consumers working on a queue
	ofprimarykey's
In-Reply-To: <489125DF.8090905@atlassian.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEPOHMAA.dcholmes@optusnet.com.au>

Ok. So the expected usage here is unbounded queue and
core-thread==max-threads ? This can never reject anything, but the semaphore
provides the bounded-blocking behaviour. So this isn't a general approach to
dealing with the classic: create core threads, fill queue, create to max
threads, then reject; where you want a blocking RejectedExecutionHandler.

David

> -----Original Message-----
> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
> Sent: Thursday, 31 July 2008 12:39 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Consumers working on a queue
> ofprimarykey's
>
>
> Right, except that to set the queue size at all would be to basically
> invite the race condition to hurt you :-)
>
> Normally you'd probably use something like one of the Executors fixed
> thread pools as the delegate and therefore have a practically unbounded
> queue (unless you are setting your permit bound up near
> Integer.MAX_VALUE).
>
> cheers,
> jed.
>
> David Holmes wrote:
> > I see. So to operate this in the classic way you'd set the
> number of permits
> > equal to the queue capacity plus the max number of pool
> threads. That way a
> > permit would only be denied if the execute() would be rejected. Though
> > there's a race condition with the worker releasing the permit
> and getting
> > the next task from the queue, which could allow a new
> submission to acquire
> > the semaphore but still get rejected because the queue is still full.
> >
> > David
> >
> >
> >> -----Original Message-----
> >> From: concurrency-interest-bounces at cs.oswego.edu
> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jed
> >> Wesley-Smith
> >> Sent: Thursday, 31 July 2008 12:16 PM
> >> To: dholmes at ieee.org
> >> Cc: concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] Consumers working on a queue
> >> ofprimarykey's
> >>
> >>
> >> Hi, David.
> >>
> >> Basically this only allows a bound of N actively running or
> queued tasks
> >> and blocks on submit if N tasks are currently queued/running.
> >>
> >> The number of permits is up to the client. If the queue size is < the
> >> (bound - pool size) then it doesn't really do anything apart from
> >> maintain a Semaphore that is always positive (basically this is a
> >> config/programming failure, albeit a relatively benign one).
> >>
> >> If the queue size > than (bound - pool size) then tasks should
> never get
> >> rejected by the underlying Executor and will only throw RejectedEE if
> >> interrupted.
> >>
> >> In cleaning this code for the list I forgot to add that it implements
> >> Executor. Making it implement ExecutorService complicates life a bit
> >> mostly due to what to do if invokeAny is called with a collection of
> >> tasks that is larger than the total number of permits.
> >>
> >> In truth the RejectedExecutionException catch block should probably be
> >> expanded to be a bit smarter and more defensive. It doesn't currently
> >> handle RuntimeExceptions and Errors thrown during the queuing phase for
> >> instance. In practice this isn't a great concern as we only use the
> >> Executors (which we have never seen throw anything on submission), but
> >> it should be handled if the class was to be added to a library
> >> for instance.
> >>
> >> cheers,
> >> jed.
> >>
> >> David Holmes wrote:
> >>
> >>> Hi Jed,
> >>>
> >>> I'm not quite clear on the intended semantics here. How many
> >>>
> >> permits do you
> >>
> >>> initialize to? If you release a permit after completion then
> >>>
> >> this controls
> >>
> >>> the number of queued+active submissions. And you still expect rejected
> >>> executions here to throw an exception not to block until submission is
> >>> possible.
> >>>
> >>>
> >>>> -----Original Message-----
> >>>> From: Jed Wesley-Smith [mailto:jed at atlassian.com]
> >>>> Sent: Thursday, 31 July 2008 10:35 AM
> >>>> To: dholmes at ieee.org
> >>>> Cc: Peter Veentjer; concurrency-interest at cs.oswego.edu
> >>>> Subject: Re: [concurrency-interest] Consumers working on a queue of
> >>>> primarykey's
> >>>>
> >>>>
> >>>> David Holmes wrote:
> >>>>
> >>>>
> >>>>> As I recall it isn't quite this straight-forward. While the
> >>>>>
> >>>>>
> >>>> put() will block
> >>>>
> >>>>
> >>>>> the caller if the queue is full, there's no guarantee that a
> >>>>>
> >>>>>
> >>>> direct put()
> >>>>
> >>>>
> >>>>> into the queue will cause the work to be processed. In theory
> >>>>>
> >> (unless I
> >>
> >>>>> remebering an older version - there have been so many :) ) the
> >>>>>
> >>>>>
> >>>> queue could
> >>>>
> >>>>
> >>>>> be full but then be emptied and all worker threads idle-timeout
> >>>>>
> >>>>>
> >>>> before the
> >>>>
> >>>>
> >>>>> put() actually completes. In that case there won't be any
> >>>>>
> >>>>>
> >>>> workers to do a
> >>>>
> >>>>
> >>>>> take(). It's unlikely, and can only happen if the TPE is
> >>>>>
> >> configured in a
> >>
> >>>>> particular way, but as I said no guarantee.
> >>>>>
> >>>>>
> >>>>>
> >>>> We have a BoundedExecutor class that wraps an ExecutorService with a
> >>>> Semaphore. For instance:
> >>>>
> >>>> public class BoundedExecutor {
> >>>>     private final ExecutorService executor;
> >>>>     private final Semaphore semaphore;
> >>>>
> >>>>     public BoundedExecutor(final ExecutorService executor, final int
> >>>> permits) {
> >>>>         this.executor = executor;
> >>>>         semaphore = new Semaphore(permits);
> >>>>     }
> >>>>
> >>>>     public void execute(final Runnable command) {
> >>>>         try {
> >>>>             semaphore.acquire();
> >>>>         }
> >>>>         catch (final InterruptedException e) {
> >>>>             throw new RejectedExecutionException(e);
> >>>>         }
> >>>>         try {
> >>>>             executor.execute(new Runnable() {
> >>>>                 public void run() {
> >>>>                     try {
> >>>>                         command.run();
> >>>>                     }
> >>>>                     finally {
> >>>>                         semaphore.release();
> >>>>                     }
> >>>>                 }
> >>>>             });
> >>>>         }
> >>>>         catch (final RejectedExecutionException rej) {
> >>>>             semaphore.release();
> >>>>             throw rej;
> >>>>         }
> >>>>     }
> >>>>     ...
> >>>> }
> >>>>
> >>>>
>


From jed at atlassian.com  Thu Jul 31 00:24:14 2008
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 31 Jul 2008 14:24:14 +1000
Subject: [concurrency-interest] Consumers working on a queue
	ofprimarykey's
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEPOHMAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCEEPOHMAA.dcholmes@optusnet.com.au>
Message-ID: <48913E6E.50008@atlassian.com>

Correct, the TPE would never grow beyond core pool size. Thanks for 
pointing this out.

cheers,
jed.

David Holmes wrote:
> Ok. So the expected usage here is unbounded queue and
> core-thread==max-threads ? This can never reject anything, but the semaphore
> provides the bounded-blocking behaviour. So this isn't a general approach to
> dealing with the classic: create core threads, fill queue, create to max
> threads, then reject; where you want a blocking RejectedExecutionHandler.
>
> David
>
>   


