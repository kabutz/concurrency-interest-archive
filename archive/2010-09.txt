From paulo.silveira at gmail.com  Wed Sep  1 01:03:36 2010
From: paulo.silveira at gmail.com (Paulo Silveira)
Date: Wed, 1 Sep 2010 02:03:36 -0300
Subject: [concurrency-interest] retrofitted wait/notify?
In-Reply-To: <AANLkTinBshaanwrn36NjoEOnTW92Q8bxPNytKWuokzP6@mail.gmail.com>
References: <AANLkTik6DVifaWWD-Z5TYJ6G9c_Nn7F88PO5LYYtA0Bx@mail.gmail.com>
	<AANLkTinBshaanwrn36NjoEOnTW92Q8bxPNytKWuokzP6@mail.gmail.com>
Message-ID: <AANLkTi=BnKRMdmKDPQwdCGP1OF3y9o0_TJKVbFjTAP3B@mail.gmail.com>

Thanks Bob

David also told me that in a separated thread. So the question is: why
not implement the BlockingQueues with the old fashioned wait/notify?

Paulo

--
Paulo Silveira
Caelum | Ensino e Inova??o
www.caelum.com.br
www.arquiteturajava.com.br



On Tue, Aug 31, 2010 at 11:34 PM, Bob Lee <crazybob at crazybob.org> wrote:
> On Tue, Aug 31, 2010 at 11:14 AM, Paulo Silveira <paulo.silveira at gmail.com>
> wrote:
>>
>> why
>> not using AbstractQueuedSynchronizer /UnfairSyncs to implement
>> wait/notify instead of its native implementations? There is probably
>> an obvious answer, but I cant figuer it out.
>
> wait() and notify() are typically highly optimized for memory and
> performance. For example, the lock state bits are typically encoded in the
> object header.
> Bob


From davidcholmes at aapt.net.au  Wed Sep  1 01:12:32 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 1 Sep 2010 15:12:32 +1000
Subject: [concurrency-interest] retrofitted wait/notify?
In-Reply-To: <AANLkTi=BnKRMdmKDPQwdCGP1OF3y9o0_TJKVbFjTAP3B@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEAOIIAA.davidcholmes@aapt.net.au>

Paulo,

> David also told me that in a separated thread. So the question is: why
> not implement the BlockingQueues with the old fashioned wait/notify?

As I also said (via email) Locks+Conditions have some advantages over
sync+wait/notify. One of those is multiple Conditions per lock, which is one
thing LinkedBlockingQueue takes advantage of. The others are better timeout
support - also reflected in the timed-blocking-queue operations - and better
performance under contention.

David

> Paulo
>
> --
> Paulo Silveira
> Caelum | Ensino e Inova??o
> www.caelum.com.br
> www.arquiteturajava.com.br
>
>
>
> On Tue, Aug 31, 2010 at 11:34 PM, Bob Lee <crazybob at crazybob.org> wrote:
> > On Tue, Aug 31, 2010 at 11:14 AM, Paulo Silveira
> <paulo.silveira at gmail.com>
> > wrote:
> >>
> >> why
> >> not using AbstractQueuedSynchronizer /UnfairSyncs to implement
> >> wait/notify instead of its native implementations? There is probably
> >> an obvious answer, but I cant figuer it out.
> >
> > wait() and notify() are typically highly optimized for memory and
> > performance. For example, the lock state bits are typically
> encoded in the
> > object header.
> > Bob
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From vgrazi at gmail.com  Wed Sep  1 05:55:56 2010
From: vgrazi at gmail.com (Victor Grazi)
Date: Wed, 1 Sep 2010 05:55:56 -0400
Subject: [concurrency-interest] Java Concurrent Animated latest release
Message-ID: <AANLkTik_1+i-KPozVvaJ0aDjaTdPN=pxqEK8EXAaxPtn@mail.gmail.com>

I am pleased to announce the latest version of Java Concurrent Animated on
Source Forge.

This app contains a series of interactive animations that illustrate the
functionality of the components comprising the java.util.concurrent package.

I will be presenting this next month at JavaOne along with Kirk Pepperdine
(of Java Performance Tuning fame) and Heinz Kabutz (of Java Specialist
Newsletter fame).

Please download the self executing Jar and let me hear your comments for
better or for worse.

Also, if you like the app, please add a recommendation on Source Forge
https://sourceforge.net/projects/javaconcurrenta/

Many thanks,
Victor Grazi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100901/9025fa34/attachment.html>

From jason_mehrens at hotmail.com  Wed Sep  1 13:47:10 2010
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Wed, 1 Sep 2010 12:47:10 -0500
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
Message-ID: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>


Since the topic came up, I drafted a patch for BUGID 6213323.  Since 'state' is read and written to, it can be used as the happens-before edge.  It seems so simple I surely have missed something that will cause it to break or deliver poor performance.
 
Regards,
 
Jason 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100901/f1c61ef4/attachment.html>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: FutureTask.patch
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100901/f1c61ef4/attachment.ksh>

From dl at cs.oswego.edu  Fri Sep  3 19:57:55 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 03 Sep 2010 19:57:55 -0400
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
In-Reply-To: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>
References: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>
Message-ID: <4C818B83.90500@cs.oswego.edu>

On 09/01/10 13:47, Jason Mehrens wrote:
> Since the topic came up, I drafted a patch for BUGID 6213323.  Since 'state' is
> read and written to, it can be used as the happens-before edge. It seems so
> simple I surely have missed something that will cause it to break or deliver
> poor performance.
>

Thanks. This would be a bit slower than now because of the
volatile write introduced in the constructor.
We could instead insert a cheaper final-field-style
store-fence in the constructor. Too bad we don't have a Fence API :-)
We can work around this internally within jdk code via Unsafe.
I'll contemplate doing this.

-Doug

From reachbach at gmail.com  Sun Sep  5 03:25:53 2010
From: reachbach at gmail.com (Bharath Ravi Kumar)
Date: Sun, 5 Sep 2010 12:55:53 +0530
Subject: [concurrency-interest] CAS with write contention expensive?
Message-ID: <AANLkTik36Pa4ergUhNq=8Lix+bdWnCuJ2=8=CJYpB_Ss@mail.gmail.com>

Hi,

I'm looking to maintain a count (a monotonically increasing value) across
threads for a specific purpose. This count may obviously be incremented
simultaneously by multiple threads, and losing a count is not permissible
(though temporary staleness of the value is fine). The initial proposal was
to use an atomic integer for this purpose.But, after reading numerous
writeups on the CAS implementation in hotspot on x86 (including this one -
http://blogs.sun.com/dave/entry/biased_locking_in_hotspot), it appears that
a CAS in the presence of contention is expensive on multiprocessors (be it
SMP's or NUMA systems). Is that a correct assumption? Does CAS on a "hot"
location indeed lead to bus contention, and hence increased latency on x86
systems? If that is so, the only alternative appears to be reducing write
contention through other means.

-Bharath
P.S: For reasons of latency, locking is not an option in our case.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100905/3eca12da/attachment.html>

From Online at Stolsvik.com  Sun Sep  5 05:30:03 2010
From: Online at Stolsvik.com (=?UTF-8?Q?Endre_St=C3=B8lsvik?=)
Date: Sun, 5 Sep 2010 11:30:03 +0200
Subject: [concurrency-interest] CAS with write contention expensive?
In-Reply-To: <AANLkTik36Pa4ergUhNq=8Lix+bdWnCuJ2=8=CJYpB_Ss@mail.gmail.com>
References: <AANLkTik36Pa4ergUhNq=8Lix+bdWnCuJ2=8=CJYpB_Ss@mail.gmail.com>
Message-ID: <AANLkTimVoy8cE_myhK17SfHNvBRA1e-NhXdx3itFw2FG@mail.gmail.com>

Each thread holds a local count. To get the total count, iterate through all
the threads in question. Or have the thread update some global counter every
1000 increases, or every second, whatever comes first. Or something.

Also, you should probably just test it and check how it pans out - maybe it
is plenty fast enough for your scenario.

Endre.

On Sun, Sep 5, 2010 at 09:25, Bharath Ravi Kumar <reachbach at gmail.com>wrote:

> Hi,
>
> I'm looking to maintain a count (a monotonically increasing value) across
> threads for a specific purpose. This count may obviously be incremented
> simultaneously by multiple threads, and losing a count is not permissible
> (though temporary staleness of the value is fine). The initial proposal was
> to use an atomic integer for this purpose.But, after reading numerous
> writeups on the CAS implementation in hotspot on x86 (including this one -
> http://blogs.sun.com/dave/entry/biased_locking_in_hotspot), it appears
> that a CAS in the presence of contention is expensive on multiprocessors (be
> it SMP's or NUMA systems). Is that a correct assumption? Does CAS on a "hot"
> location indeed lead to bus contention, and hence increased latency on x86
> systems? If that is so, the only alternative appears to be reducing write
> contention through other means.
>
> -Bharath
> P.S: For reasons of latency, locking is not an option in our case.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100905/c9953df4/attachment.html>

From davidcholmes at aapt.net.au  Sun Sep  5 05:37:31 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 5 Sep 2010 19:37:31 +1000
Subject: [concurrency-interest] CAS with write contention expensive?
In-Reply-To: <AANLkTimVoy8cE_myhK17SfHNvBRA1e-NhXdx3itFw2FG@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEBNIIAA.davidcholmes@aapt.net.au>

Endre beat me to it. :) Yes first see if you have a problem with the simplest solution - AtomicInteger. Else you have to reduce the contention by some means - which typically means splitting the count. Or you revisit your application logic and see just how critical that count value really is.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Endre St?lsvik
  Sent: Sunday, 5 September 2010 7:30 PM
  To: Bharath Ravi Kumar
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] CAS with write contention expensive?


  Each thread holds a local count. To get the total count, iterate through all the threads in question. Or have the thread update some global counter every 1000 increases, or every second, whatever comes first. Or something.


  Also, you should probably just test it and check how it pans out - maybe it is plenty fast enough for your scenario.


  Endre.


  On Sun, Sep 5, 2010 at 09:25, Bharath Ravi Kumar <reachbach at gmail.com> wrote:

    Hi,

    I'm looking to maintain a count (a monotonically increasing value) across threads for a specific purpose. This count may obviously be incremented simultaneously by multiple threads, and losing a count is not permissible (though temporary staleness of the value is fine). The initial proposal was to use an atomic integer for this purpose.But, after reading numerous writeups on the CAS implementation in hotspot on x86 (including this one - http://blogs.sun.com/dave/entry/biased_locking_in_hotspot), it appears that a CAS in the presence of contention is expensive on multiprocessors (be it SMP's or NUMA systems). Is that a correct assumption? Does CAS on a "hot" location indeed lead to bus contention, and hence increased latency on x86 systems? If that is so, the only alternative appears to be reducing write contention through other means. 

    -Bharath
    P.S: For reasons of latency, locking is not an option in our case.

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100905/aa1994a3/attachment.html>

From reachbach at gmail.com  Sun Sep  5 08:09:30 2010
From: reachbach at gmail.com (Bharath Ravi Kumar)
Date: Sun, 5 Sep 2010 17:39:30 +0530
Subject: [concurrency-interest] CAS with write contention expensive?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEBNIIAA.davidcholmes@aapt.net.au>
References: <AANLkTimVoy8cE_myhK17SfHNvBRA1e-NhXdx3itFw2FG@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEBNIIAA.davidcholmes@aapt.net.au>
Message-ID: <AANLkTi=9WF6k83dKR1-yDch+jxNpN-pWNLnPrcLc=rQX@mail.gmail.com>

Thanks David, Endre. Keeping count with ThreadLocal would mean detecting
thread exit/death, which would get unnecessarily complicated. Due to the
nature of the thread pool we use, threads can get destroyed and re-created
routinely (and losing counts is not an option). As it appears, due to the
expected write contention, using AtomicInt's as is can be ruled out. So,
splitting the count and consolidating subsequently seems the simplest
alternative.

-Bharath

On Sun, Sep 5, 2010 at 3:07 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>  Endre beat me to it. :) Yes first see if you have a problem with the
> simplest solution - AtomicInteger. Else you have to reduce the contention by
> some means - which typically means splitting the count. Or you revisit your
> application logic and see just how critical that count value really is.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Endre St?lsvik
> *Sent:* Sunday, 5 September 2010 7:30 PM
> *To:* Bharath Ravi Kumar
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] CAS with write contention expensive?
>
> Each thread holds a local count. To get the total count, iterate through
> all the threads in question. Or have the thread update some global counter
> every 1000 increases, or every second, whatever comes first. Or something.
>
> Also, you should probably just test it and check how it pans out - maybe it
> is plenty fast enough for your scenario.
>
> Endre.
>
> On Sun, Sep 5, 2010 at 09:25, Bharath Ravi Kumar <reachbach at gmail.com>wrote:
>
>> Hi,
>>
>> I'm looking to maintain a count (a monotonically increasing value) across
>> threads for a specific purpose. This count may obviously be incremented
>> simultaneously by multiple threads, and losing a count is not permissible
>> (though temporary staleness of the value is fine). The initial proposal was
>> to use an atomic integer for this purpose.But, after reading numerous
>> writeups on the CAS implementation in hotspot on x86 (including this one -
>> http://blogs.sun.com/dave/entry/biased_locking_in_hotspot), it appears
>> that a CAS in the presence of contention is expensive on multiprocessors (be
>> it SMP's or NUMA systems). Is that a correct assumption? Does CAS on a "hot"
>> location indeed lead to bus contention, and hence increased latency on x86
>> systems? If that is so, the only alternative appears to be reducing write
>> contention through other means.
>>
>> -Bharath
>> P.S: For reasons of latency, locking is not an option in our case.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100905/c858de77/attachment-0001.html>

From alarmnummer at gmail.com  Mon Sep  6 09:19:12 2010
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 6 Sep 2010 15:19:12 +0200
Subject: [concurrency-interest] High performance 'profiling' counter
Message-ID: <AANLkTikRzxyoEuE8ZV59MhdKW54N-EDMa7H0X9fh-pSL@mail.gmail.com>

Hi Guys,

I'm currently playing with different designs of a high performance profiling
counter (so I'm only interested in the total from time to time and it isn't
used for unique id generation). An AtomicLong isn't going to cut it because
there is way too much contention and therefor doesn't scale.

I started out with a design based on the internals of the AtomicLongArray so
you effectively have a stripe of longs (since the design is based on an
array of longs). The first approach wasn't very scalable because of (I
guess) false sharing on the cache line; so different longs being stored in
the same cache line and shared between caches.

The next approach is that a thread writes at a specific element in the array
(just for experimentation purposes) and have a lot of unused room in the
array in between. I played with all kinds of settings, and even with a 64k
array and each thread (8 in total since I have 8 real cores) write at an
interval of 8192 elements (so there is 65 kbyte of room between used
elements) and still there is contention somehow. So I guess the problem is
not only related to false sharing on the cache line.

The strange thing is, when I give each thread his personal counter with only
1 long in the array, the system does scale linearly.

So is there some optimization going on that no expensive cas is done when
the jvm is able to recognize that an object will only be touched by a single
thread (except for creation and after completion)?

I also looked at the high performance counter of Cliff Click and apart from
a lot of magic, it also uses a long array combined with an
Unsafe.compareAndSwapLong as with my design. So that can't be the cause of
the problem.

Could someone help me to understand what is going on?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100906/f580eb07/attachment.html>

From viktor.klang at gmail.com  Mon Sep  6 12:33:45 2010
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 6 Sep 2010 18:33:45 +0200
Subject: [concurrency-interest] High performance 'profiling' counter
In-Reply-To: <AANLkTikRzxyoEuE8ZV59MhdKW54N-EDMa7H0X9fh-pSL@mail.gmail.com>
References: <AANLkTikRzxyoEuE8ZV59MhdKW54N-EDMa7H0X9fh-pSL@mail.gmail.com>
Message-ID: <AANLkTim+-nD+b=+odvKRaXks=-iev=2hD=yJz9MrQyX6@mail.gmail.com>

What if you use a pinned Thread and do the counting asynch from a
TransferQueue of Longs, do a timeout-ed take and every N takes check reader
queue to see if someone's interested in reading the counters current value?
(I'm guessing reads will be less than 1% compared to writes)

         Not using caller-runs semantics
         No volatile reads or writes
         No CAS

Would be interesting to see how it performs.

On Mon, Sep 6, 2010 at 3:19 PM, Peter Veentjer <alarmnummer at gmail.com>wrote:

> Hi Guys,
>
> I'm currently playing with different designs of a high performance
> profiling counter (so I'm only interested in the total from time to time and
> it isn't used for unique id generation). An AtomicLong isn't going to cut it
> because there is way too much contention and therefor doesn't scale.
>
> I started out with a design based on the internals of the AtomicLongArray
> so you effectively have a stripe of longs (since the design is based on an
> array of longs). The first approach wasn't very scalable because of (I
> guess) false sharing on the cache line; so different longs being stored in
> the same cache line and shared between caches.
>
> The next approach is that a thread writes at a specific element in the
> array (just for experimentation purposes) and have a lot of unused room in
> the array in between. I played with all kinds of settings, and even with a
> 64k array and each thread (8 in total since I have 8 real cores) write at an
> interval of 8192 elements (so there is 65 kbyte of room between used
> elements) and still there is contention somehow. So I guess the problem is
> not only related to false sharing on the cache line.
>
> The strange thing is, when I give each thread his personal counter with
> only 1 long in the array, the system does scale linearly.
>
> So is there some optimization going on that no expensive cas is done when
> the jvm is able to recognize that an object will only be touched by a single
> thread (except for creation and after completion)?
>
> I also looked at the high performance counter of Cliff Click and apart from
> a lot of magic, it also uses a long array combined with an
> Unsafe.compareAndSwapLong as with my design. So that can't be the cause of
> the problem.
>
> Could someone help me to understand what is going on?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang,
Code Connoisseur
Work:   www.akkasource.com
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100906/ded0dfd6/attachment.html>

From alarmnummer at gmail.com  Mon Sep  6 16:46:50 2010
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 6 Sep 2010 22:46:50 +0200
Subject: [concurrency-interest] High performance 'profiling' counter
In-Reply-To: <AANLkTim+-nD+b=+odvKRaXks=-iev=2hD=yJz9MrQyX6@mail.gmail.com>
References: <AANLkTikRzxyoEuE8ZV59MhdKW54N-EDMa7H0X9fh-pSL@mail.gmail.com>
	<AANLkTim+-nD+b=+odvKRaXks=-iev=2hD=yJz9MrQyX6@mail.gmail.com>
Message-ID: <AANLkTi=o8iT==y56ArK9wtcsdz-JvfSLpyzrmeaHsbpz@mail.gmail.com>

Sounds like a lot of contention to me ;)

The queue is going to need to use a lock or cas to provide concurrency
control. So my guess would be that I'm worse of.  And another problem is
that the queue could produce a lot of object litter, which limits
scalability even more.

On Mon, Sep 6, 2010 at 6:33 PM, Viktor Klang <viktor.klang at gmail.com> wrote:

> What if you use a pinned Thread and do the counting asynch from a
> TransferQueue of Longs, do a timeout-ed take and every N takes check reader
> queue to see if someone's interested in reading the counters current value?
> (I'm guessing reads will be less than 1% compared to writes)
>
>          Not using caller-runs semantics
>          No volatile reads or writes
>          No CAS
>
> Would be interesting to see how it performs.
>
> On Mon, Sep 6, 2010 at 3:19 PM, Peter Veentjer <alarmnummer at gmail.com>wrote:
>
>> Hi Guys,
>>
>> I'm currently playing with different designs of a high performance
>> profiling counter (so I'm only interested in the total from time to time and
>> it isn't used for unique id generation). An AtomicLong isn't going to cut it
>> because there is way too much contention and therefor doesn't scale.
>>
>> I started out with a design based on the internals of the AtomicLongArray
>> so you effectively have a stripe of longs (since the design is based on an
>> array of longs). The first approach wasn't very scalable because of (I
>> guess) false sharing on the cache line; so different longs being stored in
>> the same cache line and shared between caches.
>>
>> The next approach is that a thread writes at a specific element in the
>> array (just for experimentation purposes) and have a lot of unused room in
>> the array in between. I played with all kinds of settings, and even with a
>> 64k array and each thread (8 in total since I have 8 real cores) write at an
>> interval of 8192 elements (so there is 65 kbyte of room between used
>> elements) and still there is contention somehow. So I guess the problem is
>> not only related to false sharing on the cache line.
>>
>> The strange thing is, when I give each thread his personal counter with
>> only 1 long in the array, the system does scale linearly.
>>
>> So is there some optimization going on that no expensive cas is done when
>> the jvm is able to recognize that an object will only be touched by a single
>> thread (except for creation and after completion)?
>>
>> I also looked at the high performance counter of Cliff Click and apart
>> from a lot of magic, it also uses a long array combined with an
>> Unsafe.compareAndSwapLong as with my design. So that can't be the cause of
>> the problem.
>>
>> Could someone help me to understand what is going on?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work:   www.akkasource.com
> Code:   github.com/viktorklang
> Follow: twitter.com/viktorklang
> Read:   klangism.tumblr.com
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100906/1140808a/attachment.html>

From unmesh_joshi at hotmail.com  Tue Sep  7 06:11:15 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue, 7 Sep 2010 10:11:15 +0000
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>


Hi,
We are implementing synchronization for our caching system. Current implementation is like this
class CachingGateway  {    public synchronized <T> T getContent(String key) {           T content = this.cache.get(key);           if (content == null) {               content = loadContent(key); //make network call and lot of processing to load content               this.cache.put(key, content);
           }          return content;    }
}

Putting 'synchronized' on getContent method is too much, because it unnecessarily blocks calls for keys for which have cached content. (This happens when other thread is loading content for some different key).We were thinking of improving this by using a lock per key. Because our key is string, we thought of using String.intern.


class CachingGateway  {    public <T> T getContent(String key) {          synchronized(key.intern()) {                T content = this.cache.get(key);                if (content == null) {                       content = loadContent(key); //make network call and lot of processing to load content                        this.cache.put(key, content);                 }                  return content;             }     }}

We know that there are not more than 100 keys in our system.  Is string.intern a recommended way for implementing per key lock?
Thanks,Unmesh
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/2b808fad/attachment.html>

From viktor.klang at gmail.com  Tue Sep  7 06:32:29 2010
From: viktor.klang at gmail.com (Viktor Klang)
Date: Tue, 7 Sep 2010 12:32:29 +0200
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
Message-ID: <AANLkTikpoTnKc7MJsffVOf-X9ThPAKe4wYqZ_Jwzjz2W@mail.gmail.com>

I wouldn't do that...

http://stackoverflow.com/questions/461896/what-is-the-most-frequent-concurrency-problem-youve-encountered-in-java/463437#463437

On Tue, Sep 7, 2010 at 12:11 PM, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:

>  Hi,
>
> We are implementing synchronization for our caching system. Current
> implementation is like this
>
> class CachingGateway  {
>     public synchronized <T> T getContent(String key) {
>            T content = this.cache.get(key);
>            if (content == null) {
>                content = loadContent(key); //make network call and lot of
> processing to load content
>                this.cache.put(key, content);
>            }
>           return content;
>     }
>
> }
>
>
> Putting 'synchronized' on getContent method is too much, because it
> unnecessarily blocks calls for keys for which have cached content. (This
> happens when other thread is loading content for some different key).
> We were thinking of improving this by using a lock per key. Because our key
> is string, we thought of using String.intern.
>
>
>
> class CachingGateway  {
>     public <T> T getContent(String key) {
>           synchronized(key.intern()) {
>                 T content = this.cache.get(key);
>                 if (content == null) {
>                        content = loadContent(key); //make network call and
> lot of processing to load content
>                         this.cache.put(key, content);
>                  }
>                   return content;
>              }
>      }
>
> }
>
>
> We know that there are not more than 100 keys in our system.  Is
> string.intern a recommended way for implementing per key lock?
>
> Thanks,
> Unmesh
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang,
Code Connoisseur
Work:   www.akkasource.com
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/66b16651/attachment-0001.html>

From unmesh_joshi at hotmail.com  Tue Sep  7 06:44:30 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue, 7 Sep 2010 10:44:30 +0000
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <AANLkTikpoTnKc7MJsffVOf-X9ThPAKe4wYqZ_Jwzjz2W@mail.gmail.com>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>,
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>,
	<AANLkTikpoTnKc7MJsffVOf-X9ThPAKe4wYqZ_Jwzjz2W@mail.gmail.com>
Message-ID: <BAY140-W34FE7EAE7A7F0E74CAD4BEF710@phx.gbl>


Whats the problem if the key is going to be one of the 100 unique urls in our system? Are they any alternate implementations for implementing per key locking?

Date: Tue, 7 Sep 2010 12:32:29 +0200
Subject: Re: [concurrency-interest] Locking on String.intern
From: viktor.klang at gmail.com
To: unmesh_joshi at hotmail.com
CC: concurrency-interest at cs.oswego.edu

I wouldn't do that...

http://stackoverflow.com/questions/461896/what-is-the-most-frequent-concurrency-problem-youve-encountered-in-java/463437#463437


On Tue, Sep 7, 2010 at 12:11 PM, Unmesh joshi <unmesh_joshi at hotmail.com> wrote:






Hi,
We are implementing synchronization for our caching system. Current implementation is like this
class CachingGateway  {    public synchronized <T> T getContent(String key) {
           T content = this.cache.get(key);           if (content == null) {               content = loadContent(key); //make network call and lot of processing to load content               this.cache.put(key, content);

           }          return content;    }
}

Putting 'synchronized' on getContent method is too much, because it unnecessarily blocks calls for keys for which have cached content. (This happens when other thread is loading content for some different key).
We were thinking of improving this by using a lock per key. Because our key is string, we thought of using String.intern.



class CachingGateway  {    public <T> T getContent(String key) {          synchronized(key.intern()) {
                T content = this.cache.get(key);                if (content == null) {                       content = loadContent(key); //make network call and lot of processing to load content
                        this.cache.put(key, content);                 }                  return content;
             }     }
}

We know that there are not more than 100 keys in our system.  Is string.intern a recommended way for implementing per key lock?

Thanks,Unmesh
 		 	   		  

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu

http://cs.oswego.edu/mailman/listinfo/concurrency-interest




-- 
Viktor Klang,
Code Connoisseur
Work:   www.akkasource.com
Code:   github.com/viktorklang

Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com

 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/f5a98a16/attachment.html>

From viktor.klang at gmail.com  Tue Sep  7 06:47:37 2010
From: viktor.klang at gmail.com (Viktor Klang)
Date: Tue, 7 Sep 2010 12:47:37 +0200
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <BAY140-W34FE7EAE7A7F0E74CAD4BEF710@phx.gbl>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
	<AANLkTikpoTnKc7MJsffVOf-X9ThPAKe4wYqZ_Jwzjz2W@mail.gmail.com>
	<BAY140-W34FE7EAE7A7F0E74CAD4BEF710@phx.gbl>
Message-ID: <AANLkTinhshzat2LOZ8HJ+1-Mg6MCMmbYTToeKHYhRJhb@mail.gmail.com>

Also, something worth thinking about is to avoid the dog-pile-effect:

http://hype-free.blogspot.com/2008/05/avoiding-dogpile-effect.html

On Tue, Sep 7, 2010 at 12:44 PM, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:

>  Whats the problem if the key is going to be one of the 100 unique urls in
> our system? Are they any alternate implementations for implementing per key
> locking?
>
> ------------------------------
> Date: Tue, 7 Sep 2010 12:32:29 +0200
> Subject: Re: [concurrency-interest] Locking on String.intern
> From: viktor.klang at gmail.com
> To: unmesh_joshi at hotmail.com
> CC: concurrency-interest at cs.oswego.edu
>
>
> I wouldn't do that...
>
>
> http://stackoverflow.com/questions/461896/what-is-the-most-frequent-concurrency-problem-youve-encountered-in-java/463437#463437
>
> On Tue, Sep 7, 2010 at 12:11 PM, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:
>
>  Hi,
>
> We are implementing synchronization for our caching system. Current
> implementation is like this
>
> class CachingGateway  {
>     public synchronized <T> T getContent(String key) {
>            T content = this.cache.get(key);
>            if (content == null) {
>                content = loadContent(key); //make network call and lot of
> processing to load content
>                this.cache.put(key, content);
>            }
>           return content;
>     }
>
> }
>
>
> Putting 'synchronized' on getContent method is too much, because it
> unnecessarily blocks calls for keys for which have cached content. (This
> happens when other thread is loading content for some different key).
> We were thinking of improving this by using a lock per key. Because our key
> is string, we thought of using String.intern.
>
>
>
> class CachingGateway  {
>     public <T> T getContent(String key) {
>           synchronized(key.intern()) {
>                 T content = this.cache.get(key);
>                 if (content == null) {
>                        content = loadContent(key); //make network call and
> lot of processing to load content
>                         this.cache.put(key, content);
>                  }
>                   return content;
>              }
>      }
>
> }
>
>
> We know that there are not more than 100 keys in our system.  Is
> string.intern a recommended way for implementing per key lock?
>
> Thanks,
> Unmesh
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work:   www.akkasource.com
> Code:   github.com/viktorklang
> Follow: twitter.com/viktorklang
> Read:   klangism.tumblr.com
>
>


-- 
Viktor Klang,
Code Connoisseur
Work:   www.akkasource.com
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/43784c7a/attachment.html>

From lists at laerad.com  Tue Sep  7 07:14:41 2010
From: lists at laerad.com (Benedict Elliott Smith)
Date: Tue, 7 Sep 2010 12:14:41 +0100
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <BAY140-W34FE7EAE7A7F0E74CAD4BEF710@phx.gbl>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
	<AANLkTikpoTnKc7MJsffVOf-X9ThPAKe4wYqZ_Jwzjz2W@mail.gmail.com>
	<BAY140-W34FE7EAE7A7F0E74CAD4BEF710@phx.gbl>
Message-ID: <AANLkTim35gOs7_XpmHJStTZLXPO4TSF_1d3r_7bQ9n9=@mail.gmail.com>

If you want to lock in this way but would like to avoid the prospect of
another section of code synchronizing on the same object, you could simply
have a ConcurrentHashMap, and atomically place an object against each key if
there isn't already one, synchronizing on your new object if you inserted,
or the existing one if not.

par example:

class CachingGateway  {
    private final ConcurrentHashMap<String, Object> locks =
ConcurrentHashMap<String, Object>() ;
    private Object getLock(String key) {
        final Object lock, lockalt ;
        lockalt = locks.putIfAbsent(lock = new Object()) ;
        if (lockalt != null) {
           return lockalt ;
        }
        return lock ;
    }
    public <T> T getContent(String key) {
          synchronized(getLock(key)) {
                T content = this.cache.get(key);
                if (content == null) {
                       content = loadContent(key); //make network call and
lot of processing to load content
                        this.cache.put(key, content);
                 }
                  return content;
             }
     }
}

However, given that the thread that succeeds at putIfAbsent can simply
update the cache immediately if everyone else knows to wait, I would
probably suggest you use a CountDownLatch instead of synchronizing on an
object, and do something vaguely along the lines of:

class CachingGateway  {
    private final ConcurrentHashMap<String, CountDownLatch> caching =
ConcurrentHashMap<String, CountDownLatch>() ;
    public <T> T getContent(String key) {
          T content = this.cache.get(key) ;
           if (content == null) {
               final CountDownLatch latch = caching.putIfAbsent(key, new
CountDownLatch(1)) ;
               if (latch != null) {
                   latch.await() ;
                   content = this.cache.get(key) ;
               } else {
                   content = loadContent(key); //make network call and lot
of processing to load content
                   this.cache.put(key, content);
                   caching.get(key).countDown() ;
               }
           }
           return content ;
     }
}

Obviously cache itself needs to be a ConcurrentHashMap or any of this to be
remotely safe, and I am assuming that null is in invalid value to be
associated with a populated key.

This is just a skeleton though - if your loadContent() call fails with a
RuntimeException here, anybody else attempting to access that cache entry
will block indefinitely.



On 7 September 2010 11:44, Unmesh joshi <unmesh_joshi at hotmail.com> wrote:

>  Whats the problem if the key is going to be one of the 100 unique urls in
> our system? Are they any alternate implementations for implementing per key
> locking?
>
> ------------------------------
> Date: Tue, 7 Sep 2010 12:32:29 +0200
> Subject: Re: [concurrency-interest] Locking on String.intern
> From: viktor.klang at gmail.com
> To: unmesh_joshi at hotmail.com
> CC: concurrency-interest at cs.oswego.edu
>
>
> I wouldn't do that...
>
>
> http://stackoverflow.com/questions/461896/what-is-the-most-frequent-concurrency-problem-youve-encountered-in-java/463437#463437
>
> On Tue, Sep 7, 2010 at 12:11 PM, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:
>
>  Hi,
>
> We are implementing synchronization for our caching system. Current
> implementation is like this
>
> class CachingGateway  {
>     public synchronized <T> T getContent(String key) {
>            T content = this.cache.get(key);
>            if (content == null) {
>                content = loadContent(key); //make network call and lot of
> processing to load content
>                this.cache.put(key, content);
>            }
>           return content;
>     }
>
> }
>
>
> Putting 'synchronized' on getContent method is too much, because it
> unnecessarily blocks calls for keys for which have cached content. (This
> happens when other thread is loading content for some different key).
> We were thinking of improving this by using a lock per key. Because our key
> is string, we thought of using String.intern.
>
>
>
> class CachingGateway  {
>     public <T> T getContent(String key) {
>           synchronized(key.intern()) {
>                 T content = this.cache.get(key);
>                 if (content == null) {
>                        content = loadContent(key); //make network call and
> lot of processing to load content
>                         this.cache.put(key, content);
>                  }
>                   return content;
>              }
>      }
>
> }
>
>
> We know that there are not more than 100 keys in our system.  Is
> string.intern a recommended way for implementing per key lock?
>
> Thanks,
> Unmesh
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Viktor Klang,
> Code Connoisseur
> Work:   www.akkasource.com
> Code:   github.com/viktorklang
> Follow: twitter.com/viktorklang
> Read:   klangism.tumblr.com
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/f80a56b9/attachment-0001.html>

From szegedia at gmail.com  Tue Sep  7 07:25:17 2010
From: szegedia at gmail.com (Attila Szegedi)
Date: Tue, 7 Sep 2010 13:25:17 +0200
Subject: [concurrency-interest] LockSupport.park() still broken in Java 6u21?
Message-ID: <92C029EA-03F9-45FA-ADFC-55411A07A738@gmail.com>

Hi folks,

at Twitter, we recently swapped out the Scala actor library's usage of private copies of JUC LinkedBlockingQueue from our Kestrel message-queueing system with proper JUC LinkedBlockingQueue[1]. This solved our immediate problem, but now we seem to be experiencing what eerily resembles <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6822370> "ReentrantReadWriteLock: threads hung when there are no threads holding onto the lock". That is, our JVMs sometime hang, and we have all of our threads in:

  java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00002aaaeca02e20> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
	?

The bug 6822370 is claimed to have been fixed for Java 6u18; we're running 6u21 and still see this. The amount of traffic whizzing through these systems is, as you can imagine, quite staggering, so we're bound to trigger some very low probability race condition sooner or later.

I was wondering - before I dig in deeper - if anyone else had a similar problem on a JVM that has the 6822370 fixed (6u18 or later). We'll probably proceed with trying running with -XX:+UseMembar to see if it takes the problem away, but are worried about the throughput decrease it might incur.

Thanks in advance for any information,
  Attila.

[1] We did this 'cause the private copy in Scala 2.7.x was so old it still had the <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6805775> bug, "LinkedBlockingQueue Nodes should unlink themselves before becoming garbage" and it was killing GC performance in our VMs.

--
twitter: http://twitter.com/szegedi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/89de6036/attachment.html>

From alexdmiller at yahoo.com  Tue Sep  7 07:35:22 2010
From: alexdmiller at yahoo.com (Alex Miller)
Date: Tue, 7 Sep 2010 04:35:22 -0700 (PDT)
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <mailman.3.1283855556.3265.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1283855556.3265.concurrency-interest@cs.oswego.edu>
Message-ID: <459159.80624.qm@web32501.mail.mud.yahoo.com>

I'd second that NON-recommendation of synchronizing on interned strings.  If 
you're interested in a high-performance in-memory cache with good concurrency, I 
would recommend checking out Ehcache.  In particular, I would also look at the 
SelfPopulatingCache wrapper that can provide this kind of cache loading behavior 
(and safely handle common cases like the lazy load below).

Alex

On Tue, 7 Sep 2010 12:32:29, Viktor Klang <viktor.klang at gmail.com> wrote: 

> I wouldn't do that...
> 
>http://stackoverflow.com/questions/461896/what-is-the-most-frequent-concurrency-problem-youve-encountered-in-java/463437#463437
>7
> 
> On Tue, Sep 7, 2010 at 12:11 PM, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:
> 
> >  Hi,
> >
> > We are implementing synchronization for our caching system. Current
> > implementation is like this
> >
> > class CachingGateway  {
> >     public synchronized <T> T getContent(String key) {
> >            T content = this.cache.get(key);
> >            if (content == null) {
> >                content = loadContent(key); //make network call and lot of
> > processing to load content
> >                this.cache.put(key, content);
> >            }
> >           return content;
> >     }
> >
> > }
> >
> >
> > Putting 'synchronized' on getContent method is too much, because it
> > unnecessarily blocks calls for keys for which have cached content. (This
> > happens when other thread is loading content for some different key).
> > We were thinking of improving this by using a lock per key. Because our key
> > is string, we thought of using String.intern.
> >
> >
> >
> > class CachingGateway  {
> >     public <T> T getContent(String key) {
> >           synchronized(key.intern()) {
> >                 T content = this.cache.get(key);
> >                 if (content == null) {
> >                        content = loadContent(key); //make network call and
> > lot of processing to load content
> >                         this.cache.put(key, content);
> >                  }
> >                   return content;
> >              }
> >      }
> >
> > }
> >
> >
> > We know that there are not more than 100 keys in our system.  Is
> > string.intern a recommended way for implementing per key lock?
> >
> > Thanks,
> > Unmesh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/9a734c5d/attachment.html>

From davidcholmes at aapt.net.au  Tue Sep  7 07:47:47 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 7 Sep 2010 21:47:47 +1000
Subject: [concurrency-interest] LockSupport.park() still broken in Java
	6u21?
In-Reply-To: <92C029EA-03F9-45FA-ADFC-55411A07A738@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMECJIIAA.davidcholmes@aapt.net.au>

Having threads pile up in await() is not the typical symptom of 6822370 -
which is certainly fixed in 6u18 and 6u21.

What we need to establish in this case is whether the blocking queue is
actually empty or not. Can you (relatively) easily reproduce this? On what
kind of system (CPU arch, number of CPUs, OS). Can you add a thread that
polls the queue size and so would report the queue's state when the other
threads have hung?

+UseMembar might help but won't in itself help identify the root cause.

David Holmes
Oracle
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Attila
Szegedi
  Sent: Tuesday, 7 September 2010 9:25 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] LockSupport.park() still broken in Java
6u21?


  Hi folks,


  at Twitter, we recently swapped out the Scala actor library's usage of
private copies of JUC LinkedBlockingQueue from our Kestrel message-queueing
system with proper JUC LinkedBlockingQueue[1]. This solved our immediate
problem, but now we seem to be experiencing what eerily resembles
<http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6822370>
"ReentrantReadWriteLock: threads hung when there are no threads holding onto
the lock". That is, our JVMs sometime hang, and we have all of our threads
in:


    java.lang.Thread.State: WAITING (parking)
  at sun.misc.Unsafe.park(Native Method)
  - parking to wait for  <0x00002aaaeca02e20> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
  at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
  at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(
AbstractQueuedSynchronizer.java:1987)
  at
java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
  ?



  The bug 6822370 is claimed to have been fixed for Java 6u18; we're running
6u21 and still see this. The amount of traffic whizzing through these
systems is, as you can imagine, quite staggering, so we're bound to trigger
some very low probability race condition sooner or later.


  I was wondering - before I dig in deeper - if anyone else had a similar
problem on a JVM that has the 6822370 fixed (6u18 or later). We'll probably
proceed with trying running with -XX:+UseMembar to see if it takes the
problem away, but are worried about the throughput decrease it might incur.


  Thanks in advance for any information,

    Attila.


  [1] We did this 'cause the private copy in Scala 2.7.x was so old it still
had the <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6805775> bug,
"LinkedBlockingQueue Nodes should unlink themselves before becoming garbage"
and it was killing GC performance in our VMs.


  --
  twitter: http://twitter.com/szegedi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/30f8e87a/attachment-0001.html>

From unmesh_joshi at hotmail.com  Tue Sep  7 09:36:15 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue, 7 Sep 2010 13:36:15 +0000
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <mailman.7.1283860075.3265.concurrency-interest@cs.oswego.edu>
References: <mailman.7.1283860075.3265.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W17D00903231A7E27F395F0EF710@phx.gbl>


I understand that String.intern is bad because there might be some other library doing similar stuff and the locks will be shared. Other than this, is there any technical flaw in this?

>>From: Alex Miller <alexdmiller at yahoo.com>>>Subject: Re: [concurrency-interest] Locking on String.internTo: concurrency-interest at cs.oswego.eduMessage-ID: <459159.80624.qm at web32501.mail.mud.yahoo.com>Content-Type: text/plain; charset="us-ascii"I'd second that NON-recommendation of synchronizing on interned strings. If you're interested in a high-performance in-memory cache with good concurrency, I would recommend checking out Ehcache. In particular, I would also look at the SelfPopulatingCache wrapper that can provide this kind of cache loading behavior (and safely handle common cases like the lazy load below).Alex 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/5d6f1d9a/attachment.html>

From joe.bowbeer at gmail.com  Tue Sep  7 11:29:51 2010
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 7 Sep 2010 08:29:51 -0700
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
Message-ID: <AANLkTimKPTCtDTWgBi59_1VEm440z5eTeL3FfJqFGy_X@mail.gmail.com>

String.intern is fine for interning a String, but then, as others have
pointed out, the questions remain:

1. What happens when several threads lookup the same key at about the same
time? (dogpile)
2. What else is using these unique Strings as locks? (public lock)
3. What happens if/when a value can't be generated? (failure)
4. What happens when cache entries are no longer used? (garbage)

The first two problems are adequately resolved by the Memoizer sample from
Java Concurrency in Practice:

http://javaconcurrencyinpractice.com/listings/Memoizer.java

The last two problems have been discussed on this list.  Their solutions
tend to be domain-specific.  I would expect a production-ready
implementation (EHCache) to be configurable for most scenarios.

Joe

On Tue, Sep 7, 2010 at 3:11 AM, Unmesh joshi wrote:

>  Hi,
>
> We are implementing synchronization for our caching system. Current
> implementation is like this
>
> class CachingGateway  {
>     public synchronized <T> T getContent(String key) {
>            T content = this.cache.get(key);
>            if (content == null) {
>                content = loadContent(key); //make network call and lot of
> processing to load content
>                this.cache.put(key, content);
>            }
>           return content;
>     }
>
> }
>
>
> Putting 'synchronized' on getContent method is too much, because it
> unnecessarily blocks calls for keys for which have cached content. (This
> happens when other thread is loading content for some different key).
> We were thinking of improving this by using a lock per key. Because our key
> is string, we thought of using String.intern.
>
>
>
> class CachingGateway  {
>     public <T> T getContent(String key) {
>           synchronized(key.intern()) {
>                 T content = this.cache.get(key);
>                 if (content == null) {
>                        content = loadContent(key); //make network call and
> lot of processing to load content
>                         this.cache.put(key, content);
>                  }
>                   return content;
>              }
>      }
>
> }
>
>
> We know that there are not more than 100 keys in our system.  Is
> string.intern a recommended way for implementing per key lock?
>
> Thanks,
> Unmesh
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/4cc9f6fa/attachment.html>

From jason_mehrens at hotmail.com  Tue Sep  7 11:38:56 2010
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Tue, 7 Sep 2010 10:38:56 -0500
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
In-Reply-To: <4C818B83.90500@cs.oswego.edu>
References: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>,
	<4C818B83.90500@cs.oswego.edu>
Message-ID: <SNT114-W3688B3F7764078DE69B89F83710@phx.gbl>


Working on this patch made me think of one more thing that should considered and that is BUG 6464365: FutureTask.{set,setException} not called by run().  A subclass of FutureTask (that overrides the set method) might be surprised by a null value during a cancel race if the original target callable never returns null.  Here is an alternate patch.  If we can't get the original performance it might not be worth it.
 
Thanks,
 
Jason
 
> Date: Fri, 3 Sep 2010 19:57:55 -0400
> From: dl at cs.oswego.edu
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Suggested patch for BUGID 6213323
> 
> On 09/01/10 13:47, Jason Mehrens wrote:
> > Since the topic came up, I drafted a patch for BUGID 6213323. Since 'state' is
> > read and written to, it can be used as the happens-before edge. It seems so
> > simple I surely have missed something that will cause it to break or deliver
> > poor performance.
> >
> 
> Thanks. This would be a bit slower than now because of the
> volatile write introduced in the constructor.
> We could instead insert a cheaper final-field-style
> store-fence in the constructor. Too bad we don't have a Fence API :-)
> We can work around this internally within jdk code via Unsafe.
> I'll contemplate doing this.
> 
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/a452e640/attachment.html>

From jason_mehrens at hotmail.com  Tue Sep  7 11:55:37 2010
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Tue, 7 Sep 2010 10:55:37 -0500
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
In-Reply-To: <SNT114-W3688B3F7764078DE69B89F83710@phx.gbl>
References: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>, ,
	<4C818B83.90500@cs.oswego.edu>,
	<SNT114-W3688B3F7764078DE69B89F83710@phx.gbl>
Message-ID: <SNT114-W107D1087FF331A7E01F13E83710@phx.gbl>


Works better if I attach the patch.
 
Jason
 


From: jason_mehrens at hotmail.com
To: dl at cs.oswego.edu; concurrency-interest at cs.oswego.edu
Date: Tue, 7 Sep 2010 10:38:56 -0500
Subject: Re: [concurrency-interest] Suggested patch for BUGID 6213323




Working on this patch made me think of one more thing that should considered and that is BUG 6464365: FutureTask.{set,setException} not called by run().  A subclass of FutureTask (that overrides the set method) might be surprised by a null value during a cancel race if the original target callable never returns null.  Here is an alternate patch.  If we can't get the original performance it might not be worth it.
 
Thanks,
 
Jason
 
> Date: Fri, 3 Sep 2010 19:57:55 -0400
> From: dl at cs.oswego.edu
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Suggested patch for BUGID 6213323
> 
> On 09/01/10 13:47, Jason Mehrens wrote:
> > Since the topic came up, I drafted a patch for BUGID 6213323. Since 'state' is
> > read and written to, it can be used as the happens-before edge. It seems so
> > simple I surely have missed something that will cause it to break or deliver
> > poor performance.
> >
> 
> Thanks. This would be a bit slower than now because of the
> volatile write introduced in the constructor.
> We could instead insert a cheaper final-field-style
> store-fence in the constructor. Too bad we don't have a Fence API :-)
> We can work around this internally within jdk code via Unsafe.
> I'll contemplate doing this.
> 
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________ Concurrency-interest mailing list Concurrency-interest at cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/7e34a83b/attachment.html>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: FutureTask.patch
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100907/7e34a83b/attachment.ksh>

From blair at orcaware.com  Tue Sep  7 14:57:42 2010
From: blair at orcaware.com (Blair Zajac)
Date: Tue, 07 Sep 2010 11:57:42 -0700
Subject: [concurrency-interest] Locking on String.intern
In-Reply-To: <BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
References: <mailman.1.1283788800.7276.concurrency-interest@cs.oswego.edu>
	<BAY140-W1811BB62FD5ECB5D32687BEF710@phx.gbl>
Message-ID: <4C868B26.3050309@orcaware.com>

On 09/07/2010 03:11 AM, Unmesh joshi wrote:
> Hi,
>
> We are implementing synchronization for our caching system. Current
> implementation is like this

In addition to all the other replies you got, another possibility it to 
use Google Guava's MapMaker to make a computing map.  It will guarantee 
that only one thread is invoking loadContent() for a specific key:

http://guava-libraries.googlecode.com/svn/trunk/javadoc/index.html

Regards,
Blair


From unmesh_joshi at hotmail.com  Wed Sep  8 13:25:31 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed, 8 Sep 2010 17:25:31 +0000
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 68,
	Issue 9
In-Reply-To: <mailman.1.1283875200.1680.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1283875200.1680.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W16EC778CBD2170AFA3C885EF720@phx.gbl>


I think dogpile problem should not happen with string.intern. But looking at all the replies I am convinced that String.intern is a clever hack, which will work, but its definitely bad, as string.intern is not intended for such usage. So its better to use something like EhCache or other libraries which are designed for such scenarios. 
Curiously, String.intern's internal implementation in openjdk acquires a lock on whole StringTable, so lot of threads calling String.intern, might be unnecessarily blocking anyway, though for small duration.
oop StringTable::basic_add(int index, Handle string_or_null, jchar* name,                           int len, unsigned int hashValue, TRAPS) {  debug_only(StableMemoryChecker smc(name, len * sizeof(name[0])));  assert(!Universe::heap()->is_in_reserved(name) || GC_locker::is_active(),         "proposed name of symbol must be stable");
  Handle string;  // try to reuse the string if possible  if (!string_or_null.is_null() && string_or_null()->is_perm()) {    string = string_or_null;  } else {    string = java_lang_String::create_tenured_from_unicode(name, len, CHECK_NULL);  }
  // Allocation must be done before grapping the SymbolTable_lock lock  MutexLocker ml(StringTable_lock, THREAD);
  assert(java_lang_String::equals(string(), name, len),         "string must be properly initialized");
  // Since look-up was done lock-free, we need to check if another  // thread beat us in the race to insert the symbol.
  oop test = lookup(index, name, len, hashValue); // calls lookup(u1*, int)  if (test != NULL) {    // Entry already added    return test;  }
  HashtableEntry* entry = new_entry(hashValue, string());  add_entry(index, entry);  return string();} >>From: Joe Bowbeer <joe.bowbeer at gmail.com>>>Subject: Re: [concurrency-interest] Locking on String.intern>>>To: concurrency-interest at cs.oswego.edu>>>Message-ID:>>><AANLkTimKPTCtDTWgBi59_1VEm440z5eTeL3FfJqFGy_X at mail.gmail.com>>>>Content-Type: text/plain; charset="iso-8859-1">>>>String.intern is fine for interning a String, but then, as others have>>pointed out, the questions remain:>>1. What happens when several threads lookup the same key at about the same>>time? (dogpile)>>>2. What else is using these unique Strings as locks? (public lock)>>>>3. What happens if/when a value can't be generated? (failure) 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100908/543b813e/attachment.html>

From dl at cs.oswego.edu  Thu Sep  9 07:34:17 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 09 Sep 2010 07:34:17 -0400
Subject: [concurrency-interest] Openjdk/jsr166y sync
Message-ID: <4C88C639.5030000@cs.oswego.edu>


Coincident with updated JDK plans (see
http://blogs.sun.com/mr/entry/rethinking_jdk7) we are
about to resync jsr166y classes (ForkJoin, TransferQueue, Phaser)
with openjdk versions). We will also finally release into jdk
ConcurrentLinkedDeque that had been triaged out jsr166x
vs JDK6 four years ago for algorithmic/performance reasons
which we (mainly Martin) have since addressed.

These incorporate the simplifications we did for
jsr66y versions of APIs in June (for example, dropping helpJoin()).
Also, Martin Buchholz, David Holmes, and Chris Hegarty
helped review and fix/improve things for this integration.

The versions in jsr166y, those in our JDK-ready j.u.c CVS,
those in openjdk j.u.c, and those in Oracle jdk7 binary
snapshots should soon (probably within a few weeks?) all
be in sync. Any of you re-distributing jsr166y versions
in other languages/packages might also want to sync up now.

As always, you can get to our versions via
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html

In particular, the jsr166y versions:
# API specs:  http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
# jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar (compiled using 
Java6 javac).
# Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

From viktor.klang at gmail.com  Thu Sep  9 07:38:03 2010
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 9 Sep 2010 13:38:03 +0200
Subject: [concurrency-interest] A bit of feedback needed
Message-ID: <AANLkTi=JWVfnE4WDCZTTKofJexf4nGcK42+opZFUzJ1m@mail.gmail.com>

Hi guys,

I just thought I'd have some expert feedback on this,

this is the version that performs best of 3 different version I made (1 who
did the garbage-collection amortized and one implemented on immutable sets
inside and CAS operations=

It's written in Scala but it should be fairly easy to read,
it doesn't support any collection interface since it's rather specialized.

import scala.reflect.Manifest

import java.util.concurrent.{ConcurrentSkipListSet, ConcurrentHashMap}
import java.util.{Set => JSet}

import annotation.tailrec

class Index[K <: AnyRef,V <: AnyRef : Manifest] {
  import scala.collection.JavaConversions._

  private val Naught = Array[V]() //Nil for Arrays
  private val container = new ConcurrentHashMap[K, JSet[V]]
  private val emptySet = new ConcurrentSkipListSet[V]

  def put(key: K, value: V) {

    //Returns whether it needs to be retried or not
    def tryPut(set: JSet[V], v: V): Boolean = {
      set.synchronized {
          if (set.isEmpty) true //IF the set is empty then it has been
removed, so signal retry
          else { //Else add the value to the set and signal that retry is
not needed
            set add v
            false
          }
      }
    }

    @tailrec def syncPut(k: K, v: V): Boolean = {
      var retry = false
      val set = container get k
      if (set ne null) retry = tryPut(set,v)
      else {
        val newSet = new ConcurrentSkipListSet[V]
        newSet add v

        // Parry for two simultaneous putIfAbsent(id,newSet)
        val oldSet = container.putIfAbsent(k,newSet)
        if (oldSet ne null)
          retry = tryPut(oldSet,v)
      }

      if (retry) syncPut(k,v)
      else true
    }

    syncPut(key,value)
  }

  def values(key: K) = {
    val set: JSet[V] = container get key
    if (set ne null) set toArray Naught
    else Naught
  }

  def foreach(key: K)(fun: (V) => Unit) {
    val set = container get key
    if (set ne null)
     set foreach fun
  }

  def foreach(fun: (K,V) => Unit) {
    container.entrySet foreach {
      (e) => e.getValue.foreach(fun(e.getKey,_))
    }
  }

  def remove(key: K, value: V) {
    val set = container get key
    if (set ne null) {
      set.synchronized {
        if (set.remove(value)) { //If we can remove the value
          if (set.isEmpty)       //and the set becomes empty
            container.remove(key,emptySet) //We try to remove the key if
it's mapped to an empty set
        }
      }
    }
  }

  def clear = { foreach(remove) }
}


Engage! :-)

-- 
Viktor Klang,
Code Connoisseur
Work:   www.akkasource.com
Code:   github.com/viktorklang
Follow: twitter.com/viktorklang
Read:   klangism.tumblr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100909/256788ae/attachment.html>

From jason_mehrens at hotmail.com  Fri Sep 10 11:50:22 2010
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 10 Sep 2010 10:50:22 -0500
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
In-Reply-To: <4C818B83.90500@cs.oswego.edu>
References: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>,
	<4C818B83.90500@cs.oswego.edu>
Message-ID: <SNT114-W19E0827AA0457079B14D0683740@phx.gbl>


Hi Doug,

> Thanks. This would be a bit slower than now because of the
> volatile write introduced in the constructor.
> We could instead insert a cheaper final-field-style
> store-fence in the constructor. Too bad we don't have a Fence API :-)
 
Just out of curiosity, can the store-fence (created by final) be piggybacked when used with inner or nested classes?  Since FutureTask$Sync is stored in a final field of the FutureTask class, is that outside store-fence enough to safely omit the volatile write in Sync class constructor (which does not leak)?
 
Thanks,
 
Jason 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100910/19fcb760/attachment.html>

From dl at cs.oswego.edu  Fri Sep 10 19:25:19 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 10 Sep 2010 19:25:19 -0400
Subject: [concurrency-interest] Suggested patch for BUGID 6213323
In-Reply-To: <SNT114-W19E0827AA0457079B14D0683740@phx.gbl>
References: <SNT114-W116808BC977B4F81075C02838B0@phx.gbl>,
	<4C818B83.90500@cs.oswego.edu>
	<SNT114-W19E0827AA0457079B14D0683740@phx.gbl>
Message-ID: <4C8ABE5F.7070706@cs.oswego.edu>

On 09/10/10 11:50, Jason Mehrens wrote:
> Hi Doug,
>
>  > Thanks. This would be a bit slower than now because of the
>  > volatile write introduced in the constructor.
>  > We could instead insert a cheaper final-field-style
>  > store-fence in the constructor. Too bad we don't have a Fence API :-)
>
> Just out of curiosity, can the store-fence (created by final) be piggybacked
> when used with inner or nested classes? Since FutureTask$Sync is stored in a
> final field of the FutureTask class, is that outside store-fence enough to
> safely omit the volatile write in Sync class constructor (which does not leak)?
>

You can't ask the question in quite this way because the JLS
final-field specs do not *require* a store-fence and further the
JLS doesn't require any particular representation at all
for outer-this's. In practice, most if not all use a final
outer-this field and use a store-fence. but you can't
micro-optimize based on these possibly transient facts.
Well, at least we can't in supplying sources for core
libraries that we believe work on all possible JVMs.

-Doug




From dl at cs.oswego.edu  Sat Sep 11 12:31:45 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Sep 2010 12:31:45 -0400
Subject: [concurrency-interest] Reminder: CAP10 -- Splash Workshop on
 Concurrency for the Application Programmer
Message-ID: <4C8BAEF1.9040101@cs.oswego.edu>

Here's a reminder that the workshop submission deadline is monday.


                         Call For Participation
                        SPLASH 2010 Workshop on
               Concurrency for the Application Programmer
                        Monday, October 18, 2010
                          Splash, Reno Nevada

For more information and discussion about this workshop,
see the CFP at http://gee.cs.oswego.edu/dl/html/CAP2010.html
and join the CAP Facebook group at
http://www.facebook.com/group.php?gid=129568167064179

Forced by architectural and commercial considerations, programmers now
have to confront multi-core systems, heterogeneity, clusters, clouds.

What does this revolution mean for the application programmer,
typically removed from the hardware through many layers of middle-ware
(often on top of managed run-time environments)? How should the
capabilities of heterogeneous processors (including GPUs, FPGAs,
streaming processors) and heterogeneous memory (including non-coherent
memory) be made available to the application programmer? Should
abstractions for the application programmer focus primarily on
application-level concurrency rather than implementation-level
concurrency? Should application-level concurrency abstractions be
fundamentally determinate? Fundamentally declarative? Resilient in the
face of node- and network- failure? How can high-performance
concurrent programs be written in garbage-collected languages? How can
they not be written in garbage-collected languages?

This workshop aims to bring together practitioners and thinkers to
address all topics around concurrency for the application
programmer. We intend to try to keep the workshop small (ideally,
between 20 - 40 participants). Participants are expected to have
significant experience developing either applications, or concurrent
application frameworks (e.g. Hadoop, data-streaming languages) or
domain-specific languages, or tooling for application programmers.

Potential participants are requested to submit either 10-page
technical papers or 3-page position papers, using 10-point ACM SIGPLAN
templates to http://www.easychair.org/conferences/?conf=cap100. The
Program Committee will choose from the selected
submissions. Participation in the workshop will be through invitations
and on the basis of submissions.

Accepted papers will be posted in advance of the meeting, thereby
offering a chance for participants to read each others' papers and be
prepared for a more meaningful discussion.

Program Committee
     * Bob Blainey (IBM)
     * Joshua Bloch (Google)
     * Ras Bodik (UC Berkeley/Par Lab)
     * Amol Ghoting (IBM)
     * Kevlin Henney (Curbrain Ltd)
     * David Holmes (Oracle)
     * Jim Larus (Microsoft)
     * Doug Lea (SUNY Oswego) -- Co-chair
     * Martin Odersky (EPFL)
     * Bill Pugh (U Maryland)
     * Vijay Saraswat (IBM) -- Co-chair
     * Adam Welc

Dates

     * Submission deadline: September 13, 2010
       Note that the Splash early registration deadline is September 16
     * Acceptance notification: September 20, 2010
     * Final copy deadline: October 4, 2010
     * Workshop: October 18, 2010


From unmesh_joshi at hotmail.com  Mon Sep 13 10:12:34 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Mon, 13 Sep 2010 14:12:34 +0000
Subject: [concurrency-interest] ReentrantReadWriteLock starvation
Message-ID: <BAY140-W8FD702CC7638C5BEFB0D2EF770@phx.gbl>


Hi,
I was reading http://www.javaspecialists.eu/archive/Issue165.html. And the tests mentioned there, show that lock starvation happens for write lock, when using ReadWriteLock under high concurrency. ReadWriteLocks are used in high performance caches like EHCache. Is there any tests which show lock starvation trends in ReadWriteLock in JDK 6? What are the recommended alternatives?
Thanks,Unmesh
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/f4bfd063/attachment.html>

From chris_overseas at hotmail.com  Mon Sep 13 10:30:09 2010
From: chris_overseas at hotmail.com (Chris Miller)
Date: Mon, 13 Sep 2010 14:30:09 +0000
Subject: [concurrency-interest] Waking up periodic tasks
Message-ID: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>


Hello All,



I have some jobs that I schedule to run periodically using 
ScheduledExecutorService.scheduledWithFixedDelay(). This of course all works 
fine, however when a certain event happens I'd also like to be able to wake up 
one of the jobs immediately (assuming it's not running already). I don't seem to be 
able to figure out an easy way to do this.



Here's some example code:

  List<Worker> workers = 
...;
  ScheduledExecutorService scheduler = 
Executors.newScheduledThreadPool(workers.size());
  Map<Worker, 
RunnableScheduledFuture<?>> futures = new HashMap<Worker, 
RunnableScheduledFuture<?>>();

  for (final Worker worker : 
workers) {
    Runnable runnable = new Runnable() {
      public void run() 
{
        worker.doStuff();
      }
    };
    RunnableScheduledFuture<?> future = 
(RunnableScheduledFuture<?>) scheduler.scheduleWithFixedDelay(runnable, 
0L, 60L, TimeUnit.SECONDS);
    futures.put(worker, future);
  }



How do I then wakeup a particular worker? I'm guessing that overriding 
ScheduledThreadPoolExecutor.decorateTask() might hold the key to what I want. 
I've considered wrapping the ScheduledFutureTask with one that has custom 
Delayed.getDelay() and compareTo() implementations, but altering the behaviour of 
compareTo() on the fly sounds like a pretty bad idea. Should I maintain an "isRunning()" flag on the runnable and just be rescheduling it via scheduler.schedule() method? Or is there a better way that I'm overlooking?



Regards,
Chris 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/c6b42ad1/attachment.html>

From tim at peierls.net  Mon Sep 13 10:42:34 2010
From: tim at peierls.net (Tim Peierls)
Date: Mon, 13 Sep 2010 10:42:34 -0400
Subject: [concurrency-interest] Waking up periodic tasks
In-Reply-To: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>
References: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>
Message-ID: <AANLkTi=0gYjjHPe+R+KcPc+D8w1hBpPO3513-qhNvW=q@mail.gmail.com>

How about just calling worker.doStuff() for the appropriate worker outside
of the scheduled calls?

Or, if you need to reset so that the fixed delay is calculated from the
point of the "wake up", how about canceling and rescheduling?

--tim

On Mon, Sep 13, 2010 at 10:30 AM, Chris Miller
<chris_overseas at hotmail.com>wrote:

>  Hello All,
>
>
> I have some jobs that I schedule to run periodically using
> ScheduledExecutorService.scheduledWithFixedDelay(). This of course all works
> fine, however when a certain event happens I'd also like to be able to wake
> up one of the jobs immediately (assuming it's not running already). I don't
> seem to be able to figure out an easy way to do this.
>
>
> Here's some example code:
>
>   List<Worker> workers = ...;
>   ScheduledExecutorService scheduler =
> Executors.newScheduledThreadPool(workers.size());
>   Map<Worker, RunnableScheduledFuture<?>> futures = new HashMap<Worker,
> RunnableScheduledFuture<?>>();
>
>   for (final Worker worker : workers) {
>     Runnable runnable = new Runnable() {
>       public void run() {
>         worker.doStuff();
>       }
>     };
>     RunnableScheduledFuture<?> future = (RunnableScheduledFuture<?>)
> scheduler.scheduleWithFixedDelay(runnable, 0L, 60L, TimeUnit.SECONDS);
>     futures.put(worker, future);
>   }
>
>
> How do I then wakeup a particular worker? I'm guessing that overriding
> ScheduledThreadPoolExecutor.decorateTask() might hold the key to what I
> want. I've considered wrapping the ScheduledFutureTask with one that has
> custom Delayed.getDelay() and compareTo() implementations, but altering the
> behaviour of compareTo() on the fly sounds like a pretty bad idea. Should I
> maintain an "isRunning()" flag on the runnable and just be rescheduling it
> via scheduler.schedule() method? Or is there a better way that I'm
> overlooking?
>
>
>
> Regards,
> Chris
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/68093992/attachment.html>

From chris_overseas at hotmail.com  Mon Sep 13 11:31:59 2010
From: chris_overseas at hotmail.com (Chris Miller)
Date: Mon, 13 Sep 2010 15:31:59 +0000
Subject: [concurrency-interest] Waking up periodic tasks
In-Reply-To: <AANLkTi=0gYjjHPe+R+KcPc+D8w1hBpPO3513-qhNvW=q@mail.gmail.com>
References: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>,
	<AANLkTi=0gYjjHPe+R+KcPc+D8w1hBpPO3513-qhNvW=q@mail.gmail.com>
Message-ID: <SNT139-w31C450915F8829612A7D35F9770@phx.gbl>


Hi Tim,

> How about just calling worker.doStuff() for the appropriate worker outside of the scheduled calls? 
Sorry I wasn't very clear about that. The thread doing the waking must not block, and the worker itself isn't threadsafe. I only want the worker to run on one of the pooled scheduler threads, not from the thread that's waking it up or any other thread I'm managing externally.

> Or, if you need to reset so that the fixed delay is calculated from the point of the "wake up", how about canceling and rescheduling?

For some reason cancelling and rescheduling hadn't occurred to me. I don't mind resetting the fixed delay at this point so this sounds like reasonable a possibility. Thanks for the idea.

Given that Future.cancel(false) will block if the worker is currently running, I'll need to put that plus the rescheduling into a new thread (since the thread doing the waking must not block). I'll also need to ensure that only one cancel()/reschedule can happen at a time for a particular worker, otherwise I risk ending up with the same worker being rescheduled twice should the thread doing the waking trigger two wakeups in quick succession (that would be bad since the worker isn't threadsafe). A bit messy but I think it'll solve my problem.

Thanks for your help!

Chris
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/0917f46f/attachment.html>

From tim at peierls.net  Mon Sep 13 14:02:12 2010
From: tim at peierls.net (Tim Peierls)
Date: Mon, 13 Sep 2010 14:02:12 -0400
Subject: [concurrency-interest] Waking up periodic tasks
In-Reply-To: <SNT139-w31C450915F8829612A7D35F9770@phx.gbl>
References: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>
	<AANLkTi=0gYjjHPe+R+KcPc+D8w1hBpPO3513-qhNvW=q@mail.gmail.com>
	<SNT139-w31C450915F8829612A7D35F9770@phx.gbl>
Message-ID: <AANLkTikGVDLugxHmq02z+yyv_FPhMxZRhAv+wTk1vs1H@mail.gmail.com>

I'm confused by the claim that Future.cancel(false) will block if the worker
is currently running. Are you already using a custom ScheduledFuture? The
standard implementation might spin a few times, but I don't think it can
block.

If you aren't using a custom ScheduledFuture, then I think you can cancel
and reschedule in the thread doing the "waking". If cancel returns true,
reschedule with initial delay 0, otherwise reschedule with initial delay
equal to the period (plus possibly some buffer to allow time for the running
task to complete). To avoid problems when the running task takes longer to
complete than the initial delay, you can do something like synchronize on
the worker object when calling doStuff:

    synchronized (worker) {
        worker.doStuff();
    }

--tim


On Mon, Sep 13, 2010 at 11:31 AM, Chris Miller
<chris_overseas at hotmail.com>wrote:

>  Hi Tim,
>
>
> > How about just calling worker.doStuff() for the appropriate worker
> outside of the scheduled calls?
>
> Sorry I wasn't very clear about that. The thread doing the waking must not
> block, and the worker itself isn't threadsafe. I only want the worker to run
> on one of the pooled scheduler threads, not from the thread that's waking it
> up or any other thread I'm managing externally.
>
> > Or, if you need to reset so that the fixed delay is calculated from the
> point of the "wake up", how about canceling and rescheduling?
>
> For some reason cancelling and rescheduling hadn't occurred to me. I don't
> mind resetting the fixed delay at this point so this sounds like reasonable
> a possibility. Thanks for the idea.
>
> Given that Future.cancel(false) will block if the worker is currently
> running, I'll need to put that plus the rescheduling into a new thread
> (since the thread doing the waking must not block). I'll also need to ensure
> that only one cancel()/reschedule can happen at a time for a particular
> worker, otherwise I risk ending up with the same worker being rescheduled
> twice should the thread doing the waking trigger two wakeups in quick
> succession (that would be bad since the worker isn't threadsafe). A bit
> messy but I think it'll solve my problem.
>
> Thanks for your help!
>
> Chris
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/530d23cc/attachment.html>

From martinrb at google.com  Mon Sep 13 14:07:03 2010
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 13 Sep 2010 11:07:03 -0700
Subject: [concurrency-interest] ReentrantReadWriteLock starvation
In-Reply-To: <BAY140-W8FD702CC7638C5BEFB0D2EF770@phx.gbl>
References: <BAY140-W8FD702CC7638C5BEFB0D2EF770@phx.gbl>
Message-ID: <AANLkTin+Eo6L-uqSPV6i0b7Lbu=DpgU5dyzT8yHdwGkb@mail.gmail.com>

There is no lock starvation in JDK 6, but on the other hand it is possible
for a reader to get the read lock ahead of a waiting writer, if there are
also waiting readers that haven't woken yet  One could design a RWL with
stronger writer preference, but I don't know of any implementation in java.
Fair RRWLs do what you want by disabling barging completely, but at a very
high performance cost.

Martin

On Mon, Sep 13, 2010 at 07:12, Unmesh joshi <unmesh_joshi at hotmail.com>wrote:

>  Hi,
>
> I was reading http://www.javaspecialists.eu/archive/Issue165.html. And the
> tests mentioned there, show that lock starvation happens for write lock,
> when using ReadWriteLock under high concurrency. ReadWriteLocks are used in
> high performance caches like EHCache. Is there any tests which show lock
> starvation trends in ReadWriteLock in JDK 6? What are the recommended
> alternatives?
>
> Thanks,
> Unmesh
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/e1b40ed1/attachment.html>

From martinrb at google.com  Mon Sep 13 14:24:08 2010
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 13 Sep 2010 11:24:08 -0700
Subject: [concurrency-interest] Waking up periodic tasks
In-Reply-To: <SNT139-w31C450915F8829612A7D35F9770@phx.gbl>
References: <SNT139-w503B06F0E23F5AA1EB8304F9770@phx.gbl>
	<AANLkTi=0gYjjHPe+R+KcPc+D8w1hBpPO3513-qhNvW=q@mail.gmail.com>
	<SNT139-w31C450915F8829612A7D35F9770@phx.gbl>
Message-ID: <AANLkTiko4R=u-dDG6Xpz+r9rmt3kdqEn8sp_hZMutVZ4@mail.gmail.com>

On Mon, Sep 13, 2010 at 08:31, Chris Miller <chris_overseas at hotmail.com>wrote:

>  Hi Tim,
>
>
> For some reason cancelling and rescheduling hadn't occurred to me. I don't
> mind resetting the fixed delay at this point so this sounds like reasonable
> a possibility. Thanks for the idea.
>
>
cancelling and rescheduling is a natural way to do things, especially since
STPE is implemented by simply adding a new task to the work queue at the end
of execution of any periodic task.


> Given that Future.cancel(false) will block if the worker is currently
> running,
>

Future.cancel does not block.  You can think of it as mostly setting a state
variable (atomically).


> I'll need to put that plus the rescheduling into a new thread (since the
> thread doing the waking must not block). I'll also need to ensure that only
> one cancel()/reschedule can happen at a time for a particular worker,
> otherwise I risk ending up with the same worker being rescheduled twice
> should the thread doing the waking trigger two wakeups in quick succession
> (that would be bad since the worker isn't threadsafe). A bit messy but I
> think it'll solve my problem.
>
>
You can avoid overlapping executions by having each task execution acquire a
shared lock.


> Thanks for your help!
>
> Chris
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100913/9d1d2f00/attachment.html>

From davidcholmes at aapt.net.au  Mon Sep 13 19:44:04 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 14 Sep 2010 09:44:04 +1000
Subject: [concurrency-interest] ReentrantReadWriteLock starvation
In-Reply-To: <BAY140-W8FD702CC7638C5BEFB0D2EF770@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEELIIAA.davidcholmes@aapt.net.au>

I thought there had been past discussion on the article in this list but now
I can't find anything.

When considering the policies you might use for determining which thread
(reader or writer) should get the RWL next, there is a broad spectrum of
possibilities. The normal basis for deciding is simply on whether we have a
reader or writer: At one end we have writer preference and at the other
reader preference. Reader preference actually makes little sense so we tend
to stay at the writer end of the spectrum. Writer preference often sounds
the "best" as it ensures writers are considered the most important, but
funnily enough people who advocate that will then complain that readers can
wait too long - so it is a difficult balance. In j.u.c it was decided to
take a step away from writer preference in the "fair" RWL mode. This mode
tries to ensure that the time taken to get the lock, whether reader or
writer is mostly a function of the number of concurrent readers and writers
at the time you try to acquire it (as opposed to writer preference where for
a reader it is a function of the number of writers during the timeframe in
which you are waiting). So there is no starvation possible in this mode.
Unfortunately throughput can be terrible because you force many unnecessary
context switches by making threads explicitly queue. Unfair (or normal) mode
addresses this by allowing barging (with barging the lock is not handed to a
waiter but the waiter is simply woken and must contend with others threads
trying to acquire the lock at the same time). Barging greatly improves
throughput but now the time it takes to acquire the lock is in general
indeterminate.

With "reasonable" numbers of readers and writers unfair mode strikes a good
balance of throughput and delay. But naturally there is a point where things
go awry and delays can become undesirably and unpredictably long.

The are many possible approaches between the current fair and unfair modes
but they could not all be implemented in j.u.c. But it is not hard for
people to roll their own custom RRWL to support a more suitable policy for
their application.

However the onus is on framework providers, that use RRWL, to expose the
ability to "customize" the RRWL used. At a minimum by allowing fair or
unfair to be selected, and ideally by allowing a custom lock implementation.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
  Sent: Tuesday, 14 September 2010 12:13 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] ReentrantReadWriteLock starvation


  Hi,


  I was reading http://www.javaspecialists.eu/archive/Issue165.html. And the
tests mentioned there, show that lock starvation happens for write lock,
when using ReadWriteLock under high concurrency. ReadWriteLocks are used in
high performance caches like EHCache. Is there any tests which show lock
starvation trends in ReadWriteLock in JDK 6? What are the recommended
alternatives?


  Thanks,
  Unmesh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100914/4309ed39/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Sep 13 20:01:17 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 14 Sep 2010 10:01:17 +1000
Subject: [concurrency-interest] ReentrantReadWriteLock starvation
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEELIIAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEEMIIAA.davidcholmes@aapt.net.au>

One additional caveat that always slips my mind when discussing RRWL. If you
use the non-blocking tryLock() methods then barging can occur in both fair
and non-fair mode.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Holmes
  Sent: Tuesday, 14 September 2010 9:44 AM
  To: Unmesh joshi; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ReentrantReadWriteLock starvation


  I thought there had been past discussion on the article in this list but
now I can't find anything.

  When considering the policies you might use for determining which thread
(reader or writer) should get the RWL next, there is a broad spectrum of
possibilities. The normal basis for deciding is simply on whether we have a
reader or writer: At one end we have writer preference and at the other
reader preference. Reader preference actually makes little sense so we tend
to stay at the writer end of the spectrum. Writer preference often sounds
the "best" as it ensures writers are considered the most important, but
funnily enough people who advocate that will then complain that readers can
wait too long - so it is a difficult balance. In j.u.c it was decided to
take a step away from writer preference in the "fair" RWL mode. This mode
tries to ensure that the time taken to get the lock, whether reader or
writer is mostly a function of the number of concurrent readers and writers
at the time you try to acquire it (as opposed to writer preference where for
a reader it is a function of the number of writers during the timeframe in
which you are waiting). So there is no starvation possible in this mode.
Unfortunately throughput can be terrible because you force many unnecessary
context switches by making threads explicitly queue. Unfair (or normal) mode
addresses this by allowing barging (with barging the lock is not handed to a
waiter but the waiter is simply woken and must contend with others threads
trying to acquire the lock at the same time). Barging greatly improves
throughput but now the time it takes to acquire the lock is in general
indeterminate.

  With "reasonable" numbers of readers and writers unfair mode strikes a
good balance of throughput and delay. But naturally there is a point where
things go awry and delays can become undesirably and unpredictably long.

  The are many possible approaches between the current fair and unfair modes
but they could not all be implemented in j.u.c. But it is not hard for
people to roll their own custom RRWL to support a more suitable policy for
their application.

  However the onus is on framework providers, that use RRWL, to expose the
ability to "customize" the RRWL used. At a minimum by allowing fair or
unfair to be selected, and ideally by allowing a custom lock implementation.

  David Holmes
    -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
    Sent: Tuesday, 14 September 2010 12:13 AM
    To: concurrency-interest at cs.oswego.edu
    Subject: [concurrency-interest] ReentrantReadWriteLock starvation


    Hi,


    I was reading http://www.javaspecialists.eu/archive/Issue165.html. And
the tests mentioned there, show that lock starvation happens for write lock,
when using ReadWriteLock under high concurrency. ReadWriteLocks are used in
high performance caches like EHCache. Is there any tests which show lock
starvation trends in ReadWriteLock in JDK 6? What are the recommended
alternatives?


    Thanks,
    Unmesh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100914/2e823554/attachment.html>

From unmesh_joshi at hotmail.com  Mon Sep 20 10:49:06 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Mon, 20 Sep 2010 14:49:06 +0000
Subject: [concurrency-interest] Lock striping utilities
In-Reply-To: <mailman.1.1284480000.1160.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1284480000.1160.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W116ED95A2DF67B4431E25CEF7E0@phx.gbl>


Hi,
I was looking at lock striping implementation in various frameworks and see that its almost same implementation in JBoss Cache, ConcurrentHashMap in Java utils, MakerMaker ( Google Guava) and BlockingCache in EHCache. It keeps a array of locks based on concurrencylevel and use  single-word Wang/Jenkins hash (or something similar as in EHCache) to make sure we dont get too many collisions.Does it make sense to have a common lock striping utility which maintains pool of locks and returns lock based on hashcode of the object?
Thanks,Unmesh 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100920/e7d95529/attachment.html>

From dl at cs.oswego.edu  Fri Sep 24 08:05:57 2010
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 24 Sep 2010 08:05:57 -0400
Subject: [concurrency-interest] Upcoming j.u.c resyncs
Message-ID: <4C9C9425.3070006@cs.oswego.edu>


The jsr166y/openjdk resyncs mentioned a few weeks ago
appear to be complete for openjdk proper, and I think
will start appearing in jdk7 binary snapshots soon.
For those of you tracking or syncing into other
repositories, you might also want to grab updates
of tests etc (see the usual links at
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html)

Sometime soon, we will also check for and resync
other j.u.c. updates we have made over the
past few years that don't appear in openjdk.
Most of these are just small doc clarifications
made in response to suggestions on this list,
as well as a few performance improvements.
But there are also a couple listed below that we'd
like reactions about before committing. Plus, now
would be a good time to suggest any other minor
updates.

* PriorityBlockingQueue (which is basically a heap-based
priority queue managed under a single lock) employs that
lock in "fair" mode, to minimize surprise. However, as
most members of this list know, fair-mode locks can be very
slow under contention. Even though the specs for the class
do not promise fairness, we probably cannot just change
this to use non-fair locks without breaking some user
code out there that unknowingly relies on it.
But we could add new constructors that enable users
of this class to decide to use non-fair
mode if they encounter performance problems. Since this is
an API change, it could only go into Java7 versions.
(Aside: A "ConcurrentPriorityQueue", that does not
implement BlockingQueue but uses more scalable nonblocking
synchronization has been a low-priority candidate for
addition for a while. One reason for not adding one
sooner is that just using a ConcurrentSkipListSet for
such purposes already works pretty well, although has
a bigger footprint than a custom priority queue would.

* I'm still not very excited about suggested modifications
to FutureTask that drop inner Callables/Runnables (to enable
prompter GC) upon completion, at the cost of a very small
performance hit. The main impetus for this is the
lack of efficient cleanup upon cancellation in Java6
ScheduledThreadPoolExecutor. Our current
version of ScheduledThreadPoolExecutor does include
(optional) faster cleanup, which is a preferable solution
because (1) it enables GC of the entire FutureTask object,
not just the inner Callable and (2) it has no impact outside
of this use case. But unfortunately this required another small
API change (adding setRemoveOnCancelPolicy) so wasn't incorporated
into Java6 versions. But it is in Java7 versions, and is
available for use by others encountering garbage retention
problems by getting standalone copies of the class (that will
work fine in Java6 VMs).

-Doug





From jason_mehrens at hotmail.com  Fri Sep 24 10:04:11 2010
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 24 Sep 2010 09:04:11 -0500
Subject: [concurrency-interest] Upcoming j.u.c resyncs
In-Reply-To: <4C9C9425.3070006@cs.oswego.edu>
References: <4C9C9425.3070006@cs.oswego.edu>
Message-ID: <SNT114-W283F3CBC651C32469CF08D83620@phx.gbl>


> * I'm still not very excited about suggested modifications
> to FutureTask that drop inner Callables/Runnables (to enable
> prompter GC) upon completion, at the cost of a very small
> performance hit. 
 
Agreed.
 
>The main impetus for this is the
> lack of efficient cleanup upon cancellation in Java6
> ScheduledThreadPoolExecutor.
 
The other reasons are:
1. Clean up when FutureTask is 'done' and not just during cancellation.
2. ExecutorCompletionService won't queue extra garbage.
 
 
Jason 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100924/d713accc/attachment.html>

From unmesh_joshi at hotmail.com  Mon Sep 27 04:11:59 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Mon, 27 Sep 2010 08:11:59 +0000
Subject: [concurrency-interest] Understanding Thread dump.
In-Reply-To: <mailman.3.1284048000.15931.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1284048000.15931.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W203D390052A98505332D28EF650@phx.gbl>


Hi,I was looking at the following thread dumpFull thread dump Java HotSpot(TM) Server VM (11.0-b16 mixed mode):"pool-3-thread-1428" prio=10 tid=0x72b83800 nid=0x60ef waiting on condition [0x73318000..0x73318fb0]java.lang.Thread.State: TIMED_WAITING (parking)at sun.misc.Unsafe.park(Native Method)- parking to wait for <0x98983260> (a java.util.concurrent.SynchronousQueue$TransferStack)at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:945)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)at java.lang.Thread.run(Thread.java:619)"MergeTask" daemon prio=10 tid=0x09454c00 nid=0x60e7 waiting for monitor entry [0x65106000..0x65106f30]java.lang.Thread.State: BLOCKED (on object monitor)at org.apache.log4j.Category.callAppenders(Category.java:201)- waiting to lock <0x96d90bb8> (a org.apache.log4j.spi.RootLogger)at org.apache.log4j.Category.forcedLog(Category.java:388)at org.apache.log4j.Category.log(Category.java:853)at sun.reflect.GeneratedMethodAccessor55.invoke(Unknown Source)

I can see that 0x98983260 and 0x96d90bb8 are memory addresses of condition object and lock object respectively.But I was puzzled with [0x73318000..0x73318fb0] and [0x65106000..0x65106f30].
What do these memory ranges indicate? Is there any documentation related to thread dump?
In OpenJDK source code I can see following comment. But I did not understand what it means.// print guess for valid stack memory region (assume 4K pages); helps lock debuggingst->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() & ~right_n_bits(12));How does this help in lock debugging?Thanks,Unmesh 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/9b85915b/attachment.html>

From forax at univ-mlv.fr  Mon Sep 27 06:50:28 2010
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 27 Sep 2010 12:50:28 +0200
Subject: [concurrency-interest] Understanding Thread dump.
In-Reply-To: <BAY140-W203D390052A98505332D28EF650@phx.gbl>
References: <mailman.3.1284048000.15931.concurrency-interest@cs.oswego.edu>
	<BAY140-W203D390052A98505332D28EF650@phx.gbl>
Message-ID: <4CA076F4.1010201@univ-mlv.fr>

  Le 27/09/2010 10:11, Unmesh joshi a ?crit :
> Hi,
>
> I was looking at the following thread dump
>
> Full thread dump Java HotSpot(TM) Server VM (11.0-b16 mixed mode):
>
> "pool-3-thread-1428" prio=10 tid=0x72b83800 nid=0x60ef waiting on 
> condition [0x73318000..0x73318fb0]
> java.lang.Thread.State: TIMED_WAITING (parking)
> at sun.misc.Unsafe.park(Native Method)
> - parking to wait for <0x98983260> (a 
> java.util.concurrent.SynchronousQueue$TransferStack)
> at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
> at 
> java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
> at 
> java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
> at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
> at 
> java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:945)
> at 
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
> at java.lang.Thread.run(Thread.java:619)
>
> "MergeTask" daemon prio=10 tid=0x09454c00 nid=0x60e7 waiting for 
> monitor entry [0x65106000..0x65106f30]
> java.lang.Thread.State: BLOCKED (on object monitor)
> at org.apache.log4j.Category.callAppenders(Category.java:201)
> - waiting to lock <0x96d90bb8> (a org.apache.log4j.spi.RootLogger)
> at org.apache.log4j.Category.forcedLog(Category.java:388)
> at org.apache.log4j.Category.log(Category.java:853)
> at sun.reflect.GeneratedMethodAccessor55.invoke(Unknown Source)
>
>
> I can see that 0x98983260 and 0x96d90bb8 are memory addresses of 
> condition object and lock object respectively.But I was puzzled with 
> [0x73318000..0x73318fb0] and [0x65106000..0x65106f30].
>
> What do these memory ranges indicate? Is there any documentation 
> related to thread dump?

The memory range is last stack frame.

>
> In OpenJDK source code I can see following comment. But I did not 
> understand what it means.
>
> // print guess for valid stack memory region (assume 4K pages); helps 
> lock debugging
> st->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() & 
> ~right_n_bits(12));
>
> How does this help in lock debugging?

The VM can store thread inflated structure on stack
see http://blogs.sun.com/dave/entry/lets_say_you_re_interested

>
> Thanks,
> Unmesh

R?mi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/20a54f34/attachment.html>

From david.dice at gmail.com  Mon Sep 27 14:08:16 2010
From: david.dice at gmail.com (David Dice)
Date: Mon, 27 Sep 2010 14:08:16 -0400
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 68,
	Issue 20
In-Reply-To: <mailman.3.1285603200.15169.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1285603200.15169.concurrency-interest@cs.oswego.edu>
Message-ID: <AANLkTi=bZ6yb+Ckn115wKVqjW-cP3A6yGfupBA6KrtLn@mail.gmail.com>

On Mon, Sep 27, 2010 at 12:00 PM, <
concurrency-interest-request at cs.oswego.edu> wrote:

>
> > In OpenJDK source code I can see following comment. But I did not
> > understand what it means.
> >
> > // print guess for valid stack memory region (assume 4K pages); helps
> > lock debugging
> > st->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &
> > ~right_n_bits(12));
> >
> > How does this help in lock debugging?
>
> The VM can store thread inflated structure on stack
> see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
>
>
I could be misinterpreting the sentence above, but HotSpot never stores
objectmonitors on the stack.   Given JNI monitor access and the possibility
of imbalanced access in bytecode (code that was emitted by something other
than javac, for instance) there's no guaranteed of stack-like lifetimes for
monitors.

Regarding the "4K" comment in the source code,  first, 4KB has nothing to do
with the system page size, but instead relates to SP values being used to
uniquely identify threads.   Hotspot assumes, for instance, that two
different threads that exist at the same time will never have SP values that
reside in the same 4KB logical page, and as such, such SP "pages" can safely
serve as thread identity for the purpose of stack-locking.   Put another
way, the value in mark word of a stack locked object both (a) identifies the
thread holding the lock, and (b) gives us a way to find the displaced mark
word, which resides on the stack at the address found in the mark word in
the object.  4KB was picked long ago (I believe before anamorphic sold
hotspot to Sun) but seems reasonable.   In particular, the "within the same
4KB page" test is useful to detect recursive stack locking.  (The test  is
emitted directly by the JIT into the synchronization site, so it's prudent
to have a dense idiom that occasionally deflects control into the slow path
when, technically, it didn't need to).

Regards
Dave Dice
Scalable Synchronization Research Group - Sun Labs at Oracle
http://blogs.sun.com/dave
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/c8f4fb86/attachment.html>

From forax at univ-mlv.fr  Mon Sep 27 14:41:52 2010
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 27 Sep 2010 20:41:52 +0200
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 68,
 Issue 20
In-Reply-To: <AANLkTi=bZ6yb+Ckn115wKVqjW-cP3A6yGfupBA6KrtLn@mail.gmail.com>
References: <mailman.3.1285603200.15169.concurrency-interest@cs.oswego.edu>
	<AANLkTi=bZ6yb+Ckn115wKVqjW-cP3A6yGfupBA6KrtLn@mail.gmail.com>
Message-ID: <4CA0E570.2080009@univ-mlv.fr>

Le 27/09/2010 20:08, David Dice a ?crit :
>
>
> On Mon, Sep 27, 2010 at 12:00 PM, 
> <concurrency-interest-request at cs.oswego.edu 
> <mailto:concurrency-interest-request at cs.oswego.edu>> wrote:
>
>
>     > In OpenJDK source code I can see following comment. But I did not
>     > understand what it means.
>     >
>     > // print guess for valid stack memory region (assume 4K pages);
>     helps
>     > lock debugging
>     > st->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &
>     > ~right_n_bits(12));
>     >
>     > How does this help in lock debugging?
>
>     The VM can store thread inflated structure on stack
>     see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
>
>
> I could be misinterpreting the sentence above, but HotSpot never 
> stores objectmonitors on the stack.   Given JNI monitor access and the 
> possibility of imbalanced access in bytecode (code that was emitted by 
> something other than javac, for instance) there's no guaranteed of 
> stack-like lifetimes for monitors.
>
> Regarding the "4K" comment in the source code,  first, 4KB has nothing 
> to do with the system page size, but instead relates to SP values 
> being used to uniquely identify threads.   Hotspot assumes, for 
> instance, that two different threads that exist at the same time will 
> never have SP values that reside in the same 4KB logical page, and as 
> such, such SP "pages" can safely serve as thread identity for the 
> purpose of stack-locking.   Put another way, the value in mark word of 
> a stack locked object both (a) identifies the thread holding the lock, 
> and (b) gives us a way to find the displaced mark word, which resides 
> on the stack at the address found in the mark word in the object.  4KB 
> was picked long ago (I believe before anamorphic sold hotspot to Sun) 
> but seems reasonable.   In particular, the "within the same 4KB page" 
> test is useful to detect recursive stack locking.  (The test  is 
> emitted directly by the JIT into the synchronization site, so it's 
> prudent to have a dense idiom that occasionally deflects control into 
> the slow path when, technically, it didn't need to).
>
> Regards
> Dave Dice
> Scalable Synchronization Research Group - Sun Labs at Oracle
> http://blogs.sun.com/dave

My bad.
I was thinking about the displaced mark word but don't name it correctly.

R?mi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/23435c1c/attachment.html>

From unmesh_joshi at hotmail.com  Tue Sep 28 00:13:02 2010
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue, 28 Sep 2010 04:13:02 +0000
Subject: [concurrency-interest] Understanding Thread dump.
In-Reply-To: <mailman.3.1285603200.15169.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1285603200.15169.concurrency-interest@cs.oswego.edu>
Message-ID: <BAY140-W27C0858D807D9877178777EF660@phx.gbl>



> 
> The memory range is last stack frame.
\> The VM can store thread inflated structure on stack
> see http://blogs.sun.com/dave/entry/lets_say_you_re_interested

Anyone knows of any article/blog explaining how knowing last stack frame's memory range helps debugging locking issues in JVM?    		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100928/7d2521e5/attachment.html>

From davidcholmes at aapt.net.au  Tue Sep 28 00:46:49 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 28 Sep 2010 14:46:49 +1000
Subject: [concurrency-interest] Understanding Thread dump.
In-Reply-To: <BAY140-W27C0858D807D9877178777EF660@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEHHIIAA.davidcholmes@aapt.net.au>

No blogs or articles.

In that address range the end value was that of the highest lock record that
existed for the thread. So by knowing that you could identify if other
addresses are potentially lock records, or validate whether a recorded
lock-record in a mark-word was valid. This is useful for debugging the
implementation of locking in the VM, not debugging locking issues in an
application.

Note that the highest-lock-record was removed earlier in the JDK7 lifecycle.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh joshi
  Sent: Tuesday, 28 September 2010 2:13 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Understanding Thread dump.



  >
  > The memory range is last stack frame.
  \> The VM can store thread inflated structure on stack
  > see http://blogs.sun.com/dave/entry/lets_say_you_re_interested


  Anyone knows of any article/blog explaining how knowing last stack frame's
memory range helps debugging locking issues in JVM?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100928/d97cde2c/attachment.html>

From sandepgarg at gmail.com  Tue Sep 28 12:07:05 2010
From: sandepgarg at gmail.com (sandeep garg)
Date: Tue, 28 Sep 2010 21:37:05 +0530
Subject: [concurrency-interest] help
Message-ID: <AANLkTikEfYEKuGi6JK8fEVVjNqKs2JsULhnrzQsNWxh6@mail.gmail.com>

On Tue, Sep 28, 2010 at 9:30 PM, <concurrency-interest-request at cs.oswego.edu
> wrote:

> Send Concurrency-interest mailing list submissions to
>        concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
>        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
>        concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
>        concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
>   1. Re: Concurrency-interest Digest, Vol 68,  Issue 20 (David Dice)
>   2. Re: Concurrency-interest Digest, Vol 68, Issue 20 (R?mi Forax)
>   3. Re: Understanding Thread dump. (Unmesh joshi)
>   4. Re: Understanding Thread dump. (David Holmes)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 27 Sep 2010 14:08:16 -0400
> From: David Dice <david.dice at gmail.com>
> Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
>        68,     Issue 20
> To: concurrency-interest at cs.oswego.edu
> Message-ID:
>        <AANLkTi=bZ6yb+Ckn115wKVqjW-cP3A6yGfupBA6KrtLn at mail.gmail.com<bZ6yb%2BCkn115wKVqjW-cP3A6yGfupBA6KrtLn at mail.gmail.com>
> >
> Content-Type: text/plain; charset="iso-8859-1"
>
> On Mon, Sep 27, 2010 at 12:00 PM, <
> concurrency-interest-request at cs.oswego.edu> wrote:
>
> >
> > > In OpenJDK source code I can see following comment. But I did not
> > > understand what it means.
> > >
> > > // print guess for valid stack memory region (assume 4K pages); helps
> > > lock debugging
> > > st->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &
> > > ~right_n_bits(12));
> > >
> > > How does this help in lock debugging?
> >
> > The VM can store thread inflated structure on stack
> > see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
> >
> >
> I could be misinterpreting the sentence above, but HotSpot never stores
> objectmonitors on the stack.   Given JNI monitor access and the possibility
> of imbalanced access in bytecode (code that was emitted by something other
> than javac, for instance) there's no guaranteed of stack-like lifetimes for
> monitors.
>
> Regarding the "4K" comment in the source code,  first, 4KB has nothing to
> do
> with the system page size, but instead relates to SP values being used to
> uniquely identify threads.   Hotspot assumes, for instance, that two
> different threads that exist at the same time will never have SP values
> that
> reside in the same 4KB logical page, and as such, such SP "pages" can
> safely
> serve as thread identity for the purpose of stack-locking.   Put another
> way, the value in mark word of a stack locked object both (a) identifies
> the
> thread holding the lock, and (b) gives us a way to find the displaced mark
> word, which resides on the stack at the address found in the mark word in
> the object.  4KB was picked long ago (I believe before anamorphic sold
> hotspot to Sun) but seems reasonable.   In particular, the "within the same
> 4KB page" test is useful to detect recursive stack locking.  (The test  is
> emitted directly by the JIT into the synchronization site, so it's prudent
> to have a dense idiom that occasionally deflects control into the slow path
> when, technically, it didn't need to).
>
> Regards
> Dave Dice
> Scalable Synchronization Research Group - Sun Labs at Oracle
> http://blogs.sun.com/dave
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/c8f4fb86/attachment-0001.html
> >
>
> ------------------------------
>
> Message: 2
> Date: Mon, 27 Sep 2010 20:41:52 +0200
> From: R?mi Forax <forax at univ-mlv.fr>
> Subject: Re: [concurrency-interest] Concurrency-interest Digest, Vol
>        68, Issue 20
> To: concurrency-interest at cs.oswego.edu
> Message-ID: <4CA0E570.2080009 at univ-mlv.fr>
> Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"
>
> Le 27/09/2010 20:08, David Dice a ?crit :
> >
> >
> > On Mon, Sep 27, 2010 at 12:00 PM,
> > <concurrency-interest-request at cs.oswego.edu
> > <mailto:concurrency-interest-request at cs.oswego.edu>> wrote:
> >
> >
> >     > In OpenJDK source code I can see following comment. But I did not
> >     > understand what it means.
> >     >
> >     > // print guess for valid stack memory region (assume 4K pages);
> >     helps
> >     > lock debugging
> >     > st->print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &
> >     > ~right_n_bits(12));
> >     >
> >     > How does this help in lock debugging?
> >
> >     The VM can store thread inflated structure on stack
> >     see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
> >
> >
> > I could be misinterpreting the sentence above, but HotSpot never
> > stores objectmonitors on the stack.   Given JNI monitor access and the
> > possibility of imbalanced access in bytecode (code that was emitted by
> > something other than javac, for instance) there's no guaranteed of
> > stack-like lifetimes for monitors.
> >
> > Regarding the "4K" comment in the source code,  first, 4KB has nothing
> > to do with the system page size, but instead relates to SP values
> > being used to uniquely identify threads.   Hotspot assumes, for
> > instance, that two different threads that exist at the same time will
> > never have SP values that reside in the same 4KB logical page, and as
> > such, such SP "pages" can safely serve as thread identity for the
> > purpose of stack-locking.   Put another way, the value in mark word of
> > a stack locked object both (a) identifies the thread holding the lock,
> > and (b) gives us a way to find the displaced mark word, which resides
> > on the stack at the address found in the mark word in the object.  4KB
> > was picked long ago (I believe before anamorphic sold hotspot to Sun)
> > but seems reasonable.   In particular, the "within the same 4KB page"
> > test is useful to detect recursive stack locking.  (The test  is
> > emitted directly by the JIT into the synchronization site, so it's
> > prudent to have a dense idiom that occasionally deflects control into
> > the slow path when, technically, it didn't need to).
> >
> > Regards
> > Dave Dice
> > Scalable Synchronization Research Group - Sun Labs at Oracle
> > http://blogs.sun.com/dave
>
> My bad.
> I was thinking about the displaced mark word but don't name it correctly.
>
> R?mi
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100927/23435c1c/attachment-0001.html
> >
>
> ------------------------------
>
> Message: 3
> Date: Tue, 28 Sep 2010 04:13:02 +0000
> From: Unmesh joshi <unmesh_joshi at hotmail.com>
> Subject: Re: [concurrency-interest] Understanding Thread dump.
> To: <concurrency-interest at cs.oswego.edu>
> Message-ID: <BAY140-W27C0858D807D9877178777EF660 at phx.gbl>
> Content-Type: text/plain; charset="iso-8859-1"
>
>
>
> >
> > The memory range is last stack frame.
> \> The VM can store thread inflated structure on stack
> > see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
>
> Anyone knows of any article/blog explaining how knowing last stack frame's
> memory range helps debugging locking issues in JVM?
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100928/7d2521e5/attachment-0001.html
> >
>
> ------------------------------
>
> Message: 4
> Date: Tue, 28 Sep 2010 14:46:49 +1000
> From: "David Holmes" <davidcholmes at aapt.net.au>
> Subject: Re: [concurrency-interest] Understanding Thread dump.
> To: "Unmesh joshi" <unmesh_joshi at hotmail.com>,
>        <concurrency-interest at cs.oswego.edu>
> Message-ID: <NFBBKALFDCPFIDBNKAPCEEHHIIAA.davidcholmes at aapt.net.au>
> Content-Type: text/plain; charset="iso-8859-1"
>
> No blogs or articles.
>
> In that address range the end value was that of the highest lock record
> that
> existed for the thread. So by knowing that you could identify if other
> addresses are potentially lock records, or validate whether a recorded
> lock-record in a mark-word was valid. This is useful for debugging the
> implementation of locking in the VM, not debugging locking issues in an
> application.
>
> Note that the highest-lock-record was removed earlier in the JDK7
> lifecycle.
>
> David Holmes
>  -----Original Message-----
>  From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Unmesh
> joshi
>  Sent: Tuesday, 28 September 2010 2:13 PM
>  To: concurrency-interest at cs.oswego.edu
>  Subject: Re: [concurrency-interest] Understanding Thread dump.
>
>
>
>  >
>  > The memory range is last stack frame.
>  \> The VM can store thread inflated structure on stack
>  > see http://blogs.sun.com/dave/entry/lets_say_you_re_interested
>
>
>  Anyone knows of any article/blog explaining how knowing last stack frame's
> memory range helps debugging locking issues in JVM?
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100928/d97cde2c/attachment-0001.html
> >
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> End of Concurrency-interest Digest, Vol 68, Issue 21
> ****************************************************
>



-- 
Sandeep Garg
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100928/a1a94d0d/attachment.html>

From sandeep.bansal85 at gmail.com  Thu Sep 30 09:58:11 2010
From: sandeep.bansal85 at gmail.com (sandeep bansal)
Date: Thu, 30 Sep 2010 19:28:11 +0530
Subject: [concurrency-interest] Final field set null on thread termination
Message-ID: <AANLkTi=a6zMkA4uVH47VFqkf6-trG0iNB=POmZasNbpY@mail.gmail.com>

Hi Everyone,

I have a thread which is something like this:

public class LogThread extends Thread {
        ...
    private static volatile boolean stopped;
    private final StatisticsLogger statsLogger;
    ...
    public LogThread(String loggerName, Config config) {
        statsLogger = new FileLogger(loggerName, config);
    }

    public void run() {
        if (statsLogger == null) {
            return;
        }
        while(!LogThread.stopped) {
            try {
                            ...
                            statsLogger.log(logData);
                            ...
            } catch (Exception ex) {
                logger.error("Exception when logging data", ex);
            }
        }
        statsLogger.shutdown();
    }

    public static final void shutdown() {
        stopped = true;
    }
}

http://pastie.org/1191267

The problem is that whenever i shutdown the thread statsLogger.shutdown()
throws a null pointer exception. I have no idea why this is happening. My
java version is 1.6.0.18. Can anyone please give me a clue.

-- 
Regards,
Sandeep
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20100930/a0d21474/attachment.html>

From davidcholmes at aapt.net.au  Thu Sep 30 18:06:14 2010
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 1 Oct 2010 08:06:14 +1000
Subject: [concurrency-interest] Final field set null on thread
	termination
In-Reply-To: <AANLkTi=a6zMkA4uVH47VFqkf6-trG0iNB=POmZasNbpY@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEIBIIAA.davidcholmes@aapt.net.au>

Can you show us the actual stacktrace for the NullPointerException? I just
want to verify it is coming from where you think.

Can you try this on a version of JDK7?

Note that the null check in run() is superfluous as statsLogger can never be
null.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of sandeep
bansal
  Sent: Thursday, 30 September 2010 11:58 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Final field set null on thread termination


  Hi Everyone,

  I have a thread which is something like this:

  public class LogThread extends Thread {
          ...
      private static volatile boolean stopped;
      private final StatisticsLogger statsLogger;
      ...
      public LogThread(String loggerName, Config config) {
          statsLogger = new FileLogger(loggerName, config);
      }

      public void run() {
          if (statsLogger == null) {
              return;
          }
          while(!LogThread.stopped) {
              try {
                              ...
                              statsLogger.log(logData);
                              ...
              } catch (Exception ex) {
                  logger.error("Exception when logging data", ex);
              }
          }
          statsLogger.shutdown();
      }

      public static final void shutdown() {
          stopped = true;
      }
  }

  http://pastie.org/1191267

  The problem is that whenever i shutdown the thread statsLogger.shutdown()
throws a null pointer exception. I have no idea why this is happening. My
java version is 1.6.0.18. Can anyone please give me a clue.

  --
  Regards,
  Sandeep
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20101001/2c478cd4/attachment.html>

