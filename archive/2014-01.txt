From nathan.reynolds at oracle.com  Wed Jan  1 23:26:25 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 01 Jan 2014 21:26:25 -0700
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
Message-ID: <52C4EA71.5000407@oracle.com>

Fascinating!  It kind of reminds me of the following algorithms that 
guarantee exclusivity without atomic operations.

http://en.wikipedia.org/wiki/Bakery_algorithm
http://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm
http://en.wikipedia.org/wiki/Peterson%27s_algorithm
http://en.wikipedia.org/wiki/Szymanski%27s_Algorithm
http://en.wikipedia.org/wiki/Dekker%27s_algorithm

readersVersion has 2 sub-arrays (i.e. one for each versionIndex). 
Couldn't we only have 1 array?  Instead of having NOT_READING and 
READING flags.  Have 0 or 1 for reading a particular version and -1 for 
not reading.  This would cut the memory usage in half.

It seems that readersVersion has to be instantiated for every instance.  
Couldn't we only have 1 array for the entire process? Combining the 
previous paragraph's idea with this one... readIndicator.arrive() would 
set the versionIndex first, store-store fence and then set the 
pointer/reference.  This ensures that the writer won't see the 
versionIndex change after the pointer/reference has been set.  
readIndicator.depart() would set the pointer/reference to NULL.  The 
writer has to check the pointer and then versionIndex.

In Java-land, one could create a delegate wrapper for any interface with 
Proxy.newProxyInstance 
(http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Proxy.html). 
When the InvocationHandler is executed, it determines if the method is a 
read or write method and then executes the appropriate left-right 
logic.  This would allow for writing the left-right logic only in the 
InvocationHandler and then be re-used for all sorts of interfaces.  In 
other words, left-right wouldn't have to be built into every data 
structure.  Write Once Use Everywhere.

-Nathan

On 12/25/2013 5:44 AM, Pedro Ramalhete wrote:
> Hello,
>
> We are pleased to announce a new concurrency control technique which 
> we named "Left-Right" and that allows Wait-Free Populations Oblivious 
> read operations. The easiest way to explain what it is, is to say that 
> it's a "kind of" Reader-Writer Lock that doesn't block for Readers, 
> which makes it ideal for low-latency and real-time deployment scenarios:
> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>
> In case you missed it above, this means that you can have one Writer 
> and multiple Readers executing simultaneously, and unlike optimistic 
> read locks, you don't have to worry about atomicity, or memory 
> management, or invariants.
>
> Similarly to a Reader-Writer lock, it can be applied to any 
> (non-thread-safe) data structure and enable it to be used in a 
> multi-threaded application, where it will be Blocking for Writers, and 
> Wait-Free for Readers. It can be implemented in Java, Scala, C11, or 
> C++1x.
> Sample source code can be seen here:
> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/LRScalableTreeSet.java
> http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/leftright/LRScalableGuard.java
>
> Its two main innovations are, the usage of two instances, and the new 
> concurrency control algorithm whose novel state machine gives 
> wait-free guarantees for read operations.
>
>
> There is another technique which also uses two instances but requires 
> 3 locks, which perhaps has already been discovered, that we named 
> "Double Instance Locking" and it is much easier to understand and 
> implement, but it is only Lock-Free for read operations:
> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLocking.pptx
> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLockGuard.java
> http://concurrencyfreaks.com/2013/11/double-instance-locking.html
>
> We would like to hear expert's comments on it   ;)
>
> Merry Christmas,
> Pedro & Andreia
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140101/ea732a55/attachment.html>

From peter.levart at gmail.com  Thu Jan  2 04:23:29 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 02 Jan 2014 10:23:29 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <52C4EA71.5000407@oracle.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52C4EA71.5000407@oracle.com>
Message-ID: <52C53011.9030809@gmail.com>

On 01/02/2014 05:26 AM, Nathan Reynolds wrote:
> In Java-land, one could create a delegate wrapper for any interface 
> with Proxy.newProxyInstance 
> (http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Proxy.html). 
> When the InvocationHandler is executed, it determines if the method is 
> a read or write method and then executes the appropriate left-right 
> logic.  This would allow for writing the left-right logic only in the 
> InvocationHandler and then be re-used for all sorts of interfaces.  In 
> other words, left-right wouldn't have to be built into every data 
> structure.  Write Once Use Everywhere.

Good idea. This would only work for simple "snapshot" and modification 
methods though. Something that returns a "view" over internal state 
(like Map.entrySet() for example), won't work unless the returned object 
is also wrapped with a similar Proxy... Now that we have lambdas, a 
generic solution could be modelled with them:

http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java

This can be used like that:

LeftRight<Set<Integer>> lrSet = new LeftRight<>(new HashSet<>(), new 
HashSet<>());

// reading
boolean contains = lrSet.read(12, (key, set) -> set.contains(key));

// modifying
lrSet.modify(12, (key, set) -> set.add(key));


This is particularly well suited for modifying since the same lambda 
logic is executed twice for every external invocation and must apply the 
same modifications to each mirror of the data structure.

Regards, Peter


From peter.levart at gmail.com  Thu Jan  2 07:11:09 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 02 Jan 2014 13:11:09 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>	<52BF6CB6.3040103@gmail.com>
	<CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>
Message-ID: <52C5575D.5060700@gmail.com>

(resend - this one is for the list - previous had wrong From: address 
and was not accepted)

On 12/31/2013 10:15 PM, Pedro Ramalhete wrote:
> Hi Peter,
>
> We were unable to compile your code, even using the latest stable
> netbeans-lambda, so we couldn't test it or benchmark it.

I'm sorry, I published the wrong version that doesn't compiIle. 
Inference in JDK 8 and covariant function return types don't play well 
together. Here's the version that compiles - just removed the wildcards 
from return type parameters of Function and BiFunction interfaces in 
read() methods:

http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java


>
> Yes, you are right, the usage of LongAdders is a valid implementation 
> of the
> readIndicator. The ingress/egress pattern is described in the paper
> "NUMA Aware Reader-Writer Locks" and we implemented it using LongAdders
> on our own rwlock LongAdderRWLock.
> To avoid using 4 LongAdder instances, Andreia suggests using the same 
> trick
> she discovered for LongAdderExtRWLock, that uses 2 instances instead of 4:
> http://concurrencyfreaks.blogspot.fr/2013/09/scalable-rw-lock-with-single-longadder.html
> Notice that LongAdder.increment() is not wait-free, (I would say it is
> lock-free but I'm not completely sure), and by using LongAdder you are
> losing the wait-free progress guarantee provided by the Left-Right 
> technique.

Do you mean the possibility of a delay caused by LongAdder.increment() 
re-trying the cas and resizing the cells array as a consequence of 
increasing load on the LongAdder instance?

For that matter, even ThreadLocal.get() is not entirely wait-free, since 
it can stray into expunging stale entries and moving following entries 
into vacant slots, although the pauses caused by that might not be long 
or frequent.

>
>
> Performance wise, Andreia has done a (non-functional) implementation of
> the Left-Right with a single LongAdder per counter, and on our benchmark
> it has similar performance, except for 0.1% writes, where it is surpassed
> by the Left-Right with the "scalable readindicator" that is shown in the
> paper, which uses a CLQ and an array.

I also experimented with an alternative readindicator implementation, 
very similar to your CLQ/array. For comparison with two-long-adders 
approach, I created this interface, and two implementations:

http://cr.openjdk.java.net/~plevart/misc/LeftRight/EnterExitWait.java
http://cr.openjdk.java.net/~plevart/misc/LeftRight/LongAdderEEW.java
http://cr.openjdk.java.net/~plevart/misc/LeftRight/TLChainEEW.java

The following benchmark, run on a 4 core Intel i7 PC shows TLChainEEW to 
be slightly better than LongAdderEEW:

http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java

I used Unsafe.putOrderedInt() in TLChainEEW to publish from reader 
threads. I think this is enough for sequential consistency. Do you agree?

>
>
> Besides the compilation failure, there is one issue in your 
> implementation.
> The order of calling exists.sum() and enters.sum() must always be 
> "exists"
> first (egress counter) and then "enters" (ingress counter).
> In EnterExistCounter, on the function isEmtpty(), the implementation is
> "exits.sum() == enters.sum()" and although I'm not sure of Java's 
> expression
> evaluation rules for this case, I would assume that there is no guarantee
> on which one will be evaluated first, thus causing a bug if enters.sum()
> happens to be executed before exists.sum().

Java does guarantee that binary operators 1st evaluate left operand and 
then right:

http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.7


Regards, Peter

>
>
> Thanks,
> Pedro
>
>
> On Sun, Dec 29, 2013 at 1:28 AM, Peter Levart <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>> wrote:
>
>     Hello Pedro,
>
>     This is a very interesting article. I immediately jumped into
>     implementing the basic algorithm myself, but using a slightly
>     different coding approach, and, since these are the days of JDK 8,
>     using functional interfaces which play nicely with lambdas:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/LeftRight.java>
>
>     I tried to leverage j.u.c.LongAdder here to implement
>     "readIndaicator" - the alternative for "Algorithms 2, 3 and 5"
>     described in paper. But as you've written in paper, using a
>     counter for that purpose, it has to be sequentially consistent,
>     which you've showed, is not the case for LongAdder:
>
>     http://concurrencyfreaks.blogspot.com/2013/09/longadder-is-not-sequentially-consistent.html
>
>     LongAdder is not sequentially consistent if used with different
>     modification operations - for example using LongAdder.increment()
>     for "arrive" and LongAdder.decrement() for "depart" operations,
>     combined with LongAdder.sum() == 0L to implement "isEmpty". But
>     you also showed that LongAdder is sequentialy consistent if only a
>     single kind of modifications are applied to it. For example, only
>     using inclrement() to modify, and sum() to read. So I thought
>     using two LongAdders - one for ingress, the other for egress, and
>     reading their sum()s in correct order (first egress sum, then
>     ingress sum) and comparing them for equality would do the job. Am
>     I right?
>
>     Regards, Peter
>
>
>     On 12/25/2013 01:44 PM, Pedro Ramalhete wrote:
>>     Hello,
>>
>>     We are pleased to announce a new concurrency control technique
>>     which we named "Left-Right" and that allows Wait-Free Populations
>>     Oblivious read operations. The easiest way to explain what it is,
>>     is to say that it's a "kind of" Reader-Writer Lock that doesn't
>>     block for Readers, which makes it ideal for low-latency and
>>     real-time deployment scenarios:
>>     http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>>
>>     In case you missed it above, this means that you can have one
>>     Writer and multiple Readers executing simultaneously, and unlike
>>     optimistic read locks, you don't have to worry about atomicity,
>>     or memory management, or invariants.
>>
>>     Similarly to a Reader-Writer lock, it can be applied to any
>>     (non-thread-safe) data structure and enable it to be used in a
>>     multi-threaded application, where it will be Blocking for
>>     Writers, and Wait-Free for Readers. It can be implemented in
>>     Java, Scala, C11, or C++1x.
>>     Sample source code can be seen here:
>>     http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/LRScalableTreeSet.java
>>     http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/leftright/LRScalableGuard.java
>>
>>     Its two main innovations are, the usage of two instances, and the
>>     new concurrency control algorithm whose novel state machine gives
>>     wait-free guarantees for read operations.
>>
>>
>>     There is another technique which also uses two instances but
>>     requires 3 locks, which perhaps has already been discovered, that
>>     we named "Double Instance Locking" and it is much easier to
>>     understand and implement, but it is only Lock-Free for read
>>     operations:
>>     http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLocking.pptx
>>     http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLockGuard.java
>>     http://concurrencyfreaks.com/2013/11/double-instance-locking.html
>>
>>     We would like to hear expert's comments on it   ;)
>>
>>     Merry Christmas,
>>     Pedro & Andreia
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/543594ef/attachment-0001.html>

From mr.chrisvest at gmail.com  Thu Jan  2 08:32:18 2014
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Thu, 2 Jan 2014 14:32:18 +0100
Subject: [concurrency-interest] ThreadFactory implementation recommendations
Message-ID: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>

Hi,

I?m maintaining a library that does background work using an Executor. I allow people to configure their own Executor if they want, but I also want to provide a reasonable default if they don?t.

Looking at the Executors.defaultThreadFactory and privilegedThreadFactory implementations, and considering the many deployment options available to Java developers today, I wonder if you have any advice for what ThreadFactory implementation I should use?

The only thing I want to do out of the ordinary is setting my own prefix for the Thread names. Apart from that, I want to just ?do the right thing? in as many contexts as possible.

Cheers,
Chris

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/69cfebac/attachment.html>

From vitalyd at gmail.com  Thu Jan  2 08:51:42 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 2 Jan 2014 08:51:42 -0500
Subject: [concurrency-interest] ThreadFactory implementation
	recommendations
In-Reply-To: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>
References: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>
Message-ID: <CAHjP37E_b2a5RGRkvvg73NCd=ZVg+53sqLqcU59L+VRRU12F-A@mail.gmail.com>

Chris,

I think I would do the following:
1) Allow user to provide their own threadfactory
2) use defaultThreadFactory for when they don't provide a custom one

In both cases, internally I'd wrap it in your own threadfactory that
manipulates the name of the thread returned by 1 or 2 above.

I think this is fine from usability as you cater to default easily and for
cases where something custom is needed, you allow the hook to do that.

Sent from my phone
On Jan 2, 2014 8:42 AM, "Chris Vest" <mr.chrisvest at gmail.com> wrote:

> Hi,
>
> I?m maintaining a library that does background work using an Executor. I
> allow people to configure their own Executor if they want, but I also want
> to provide a reasonable default if they don?t.
>
> Looking at the Executors.defaultThreadFactory and privilegedThreadFactory
> implementations, and considering the many deployment options available to
> Java developers today, I wonder if you have any advice for what
> ThreadFactory implementation I should use?
>
> The only thing I want to do out of the ordinary is setting my own prefix
> for the Thread names. Apart from that, I want to just ?do the right thing?
> in as many contexts as possible.
>
> Cheers,
> Chris
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/361040c7/attachment.html>

From martinrb at google.com  Thu Jan  2 10:16:20 2014
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 2 Jan 2014 07:16:20 -0800
Subject: [concurrency-interest] ThreadFactory implementation
	recommendations
In-Reply-To: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>
References: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>
Message-ID: <CA+kOe09etma+LLeysEQZShLH3EsJOWOk1Dw=sfD9EzgO=DN_QQ@mail.gmail.com>

http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/util/concurrent/ThreadFactoryBuilder.html


On Thu, Jan 2, 2014 at 5:32 AM, Chris Vest <mr.chrisvest at gmail.com> wrote:

> Hi,
>
> I?m maintaining a library that does background work using an Executor. I
> allow people to configure their own Executor if they want, but I also want
> to provide a reasonable default if they don?t.
>
> Looking at the Executors.defaultThreadFactory and privilegedThreadFactory
> implementations, and considering the many deployment options available to
> Java developers today, I wonder if you have any advice for what
> ThreadFactory implementation I should use?
>
> The only thing I want to do out of the ordinary is setting my own prefix
> for the Thread names. Apart from that, I want to just ?do the right thing?
> in as many contexts as possible.
>
> Cheers,
> Chris
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/79c5b9d7/attachment.html>

From pramalhe at gmail.com  Thu Jan  2 11:27:33 2014
From: pramalhe at gmail.com (Pedro Ramalhete)
Date: Thu, 2 Jan 2014 17:27:33 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
	technique
Message-ID: <CAAApjO2KbVK70J9=ZsVJaN_N7YXccU2_Mq85jSSO2o9XtihNHA@mail.gmail.com>

>Fascinating!  It kind of reminds me of the following algorithms that
>guarantee exclusivity without atomic operations.
>
>http://en.wikipedia.org/wiki/Bakery_algorithm<http://en.wikipedia.org/wiki/Bakery_algorithm>
>http://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm<http://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm>
>http://en.wikipedia.org/wiki/Peterson%27s_algorithm<http://en.wikipedia.org/wiki/Peterson%27s_algorithm>
>http://en.wikipedia.org/wiki/Szymanski%27s_Algorithm<http://en.wikipedia.org/wiki/Szymanski%27s_Algorithm>
>http://en.wikipedia.org/wiki/Dekker%27s_algorithm<http://en.wikipedia.org/wiki/Dekker%27s_algorithm>
>

Thanks, yes you got it right Nathan, it is a concurrency control algorithm
:)


>readersVersion has 2 sub-arrays (i.e. one for each versionIndex).
>Couldn't we only have 1 array?  Instead of having NOT_READING and
>READING flags.  Have 0 or 1 for reading a particular version and -1 for
>not reading.  This would cut the memory usage in half.

Yes, it is possible to implement it using a single array in readersVersion
with three-states as you describe. There are some things to keep in mind
with that approach:
- It can't be used with "couter-based" readIndicators;
- We still have to scan the array twice, once before, and once after
toggling the versionIndex variable;
- Slightly worse performance for the Writer due to (slightly) higher number
of cache-misses when scanning the array of readersVersion;
If the goal is to have reduced memory usage, then I would recommend using a
readIndicator with LongAdderExt, which has O(N_cores) instead
of the CLQ+array techniques which have a memory usage of O(N_Readers).

The main purpose of having a versionIndex with only two states (0 or 1) is
to be able to use counter-based readIndicators, and for that, we need two
arrays. If you have only one array where the Reader publishes the version,
that version doesn't need to be "re-used" and can be increased indefinitely
(or until LONG_MAX).
In the extreme, the readIndicator that uses less memory is a single
AtomicLong, one per readersVersion, but this isn't very good for
contention, as you can imagine ;)


>It seems that readersVersion has to be instantiated for every instance.
>Couldn't we only have 1 array for the entire process?

You're assuming that there are no nested calls, with read operations on one
LR calling read (or write) operations on another one. If that is the case,
then yes the optimization you describe can be done, with one single
readIndicator instance shared among all LR instances of the process. This
is an interesting idea which we hadn't thought of.
There are a couple things to keep in mind when using such an approach:
- You need an extra mechanism to identify each of the LR instances and
their respective versionIndex. Notice that you need to encode: the
versionIndex, a unique identifier of the LR instance, and the state
NOT_READING;
- It can happen that not all threads will access all LR instances as
Readers, yet the array will have to have an entry for each thread that ever
accessed one of the LR instances at least once and the entry will only be
removed when the thread stops running. This means that the Writers will
always have a very large array to scan (about the size N_Threads);
- Will cause more cache-misses for the Writers;

>Combining the
>previous paragraph's idea with this one... readIndicator.arrive() would
>set the versionIndex first, store-store fence and then set the
>pointer/reference.  This ensures that the writer won't see the
>versionIndex change after the pointer/reference has been set.
>readIndicator.depart() would set the pointer/reference to NULL.  The
>writer has to check the pointer and then versionIndex.

Regarding the algorithm you described, it is correct as far as we could
see, although there is a missing piece.
Suppose that a Writer is scanning the array searching for reference X with
version 0, and sees a reference that matches X, but then the Writer goes to
sleep. In the meantime, the Reader corresponding to that particular entry
finishes its operation, changing X to null, and a bit later can start a new
read operation on another LR instance Y, which
happens to be at version 0.
If the Writer thread then wakes up and looks at the Reader's version it
will see 0 and it will spin/yield waiting... forever?
One way to overcome this is that the Writer must always: read the
reference, read the version, confirm that the reference hasn't change, if
it didn't change then spin/yield and re-read reference and version.

Some care is required in the implementation and algorithm, but I believe
that your idea of having a single array for multiple LR instances can be
usefull in many practical situations.


Pedro
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/406590e6/attachment-0001.html>

From nathan.reynolds at oracle.com  Thu Jan  2 15:12:07 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 02 Jan 2014 13:12:07 -0700
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <CAAApjO2KbVK70J9=ZsVJaN_N7YXccU2_Mq85jSSO2o9XtihNHA@mail.gmail.com>
References: <CAAApjO2KbVK70J9=ZsVJaN_N7YXccU2_Mq85jSSO2o9XtihNHA@mail.gmail.com>
Message-ID: <52C5C817.2090207@oracle.com>

On 1/2/2014 9:27 AM, Pedro Ramalhete wrote:
> >Fascinating!  It kind of reminds me of the following algorithms that
> >guarantee exclusivity without atomic operations.
> >
> >http://en.wikipedia.org/wiki/Bakery_algorithm 
> <http://en.wikipedia.org/wiki/Bakery_algorithm>
> >http://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm 
> <http://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm>
> >http://en.wikipedia.org/wiki/Peterson%27s_algorithm 
> <http://en.wikipedia.org/wiki/Peterson%27s_algorithm>
> >http://en.wikipedia.org/wiki/Szymanski%27s_Algorithm 
> <http://en.wikipedia.org/wiki/Szymanski%27s_Algorithm>
> >http://en.wikipedia.org/wiki/Dekker%27s_algorithm 
> <http://en.wikipedia.org/wiki/Dekker%27s_algorithm>
> >
>
> Thanks, yes you got it right Nathan, it is a concurrency control 
> algorithm  :)
>
>
> >readersVersion has 2 sub-arrays (i.e. one for each versionIndex).
> >Couldn't we only have 1 array?  Instead of having NOT_READING and
> >READING flags.  Have 0 or 1 for reading a particular version and -1 for
> >not reading.  This would cut the memory usage in half.
>
> Yes, it is possible to implement it using a single array in 
> readersVersion with three-states as you describe. There are some 
> things to keep in mind with that approach:
> - It can't be used with "couter-based" readIndicators;
> - We still have to scan the array twice, once before, and once after 
> toggling the versionIndex variable;
> - Slightly worse performance for the Writer due to (slightly) higher 
> number of cache-misses when scanning the array of readersVersion;
> If the goal is to have reduced memory usage, then I would recommend 
> using a readIndicator with LongAdderExt, which has O(N_cores) instead
> of the CLQ+array techniques which have a memory usage of O(N_Readers).
>
> The main purpose of having a versionIndex with only two states (0 or 
> 1) is to be able to use counter-based readIndicators, and for that, we 
> need two arrays. If you have only one array where the Reader publishes 
> the version, that version doesn't need to be "re-used" and can be 
> increased indefinitely (or until LONG_MAX).
> In the extreme, the readIndicator that uses less memory is a single 
> AtomicLong, one per readersVersion, but this isn't very good for 
> contention, as you can imagine ;)
>
>
> >It seems that readersVersion has to be instantiated for every instance.
> >Couldn't we only have 1 array for the entire process?
>
> You're assuming that there are no nested calls, with read operations 
> on one LR calling read (or write) operations on another one.

I hadn't thought about that but you are right.  The constraint is worse 
the non-recursive lock.  The thread can't be doing a read/write 
operation on 2 different instances at the same time.

This scenario does occur in practice.  One of the ideas to avoid 
deadlocks is to always acquire locks in the same order.  Because the 
rule exists, it would suggest that we would have to deal with nested LR 
operations.

This stirs a question.  Does the LR algorithm require that the lock not 
be used recursively?  If so, the code should defend against this and 
throw an exception if that is attempted.  Or perhaps, the thread could 
increment a recursion counter.

> If that is the case, then yes the optimization you describe can be 
> done, with one single readIndicator instance shared among all LR 
> instances of the process. This is an interesting idea which we hadn't 
> thought of.
> There are a couple things to keep in mind when using such an approach:
> - You need an extra mechanism to identify each of the LR instances and 
> their respective versionIndex. Notice that you need to encode: the 
> versionIndex, a unique identifier of the LR instance, and the state 
> NOT_READING;
> - It can happen that not all threads will access all LR instances as 
> Readers, yet the array will have to have an entry for each thread that 
> ever accessed one of the LR instances at least once and the entry will 
> only be removed when the thread stops running. This means that the 
> Writers will always have a very large array to scan (about the size 
> N_Threads);
> - Will cause more cache-misses for the Writers;
>
> >Combining the
> >previous paragraph's idea with this one... readIndicator.arrive() would
> >set the versionIndex first, store-store fence and then set the
> >pointer/reference.  This ensures that the writer won't see the
> >versionIndex change after the pointer/reference has been set.
> >readIndicator.depart() would set the pointer/reference to NULL.  The
> >writer has to check the pointer and then versionIndex.
>
> Regarding the algorithm you described, it is correct as far as we 
> could see, although there is a missing piece.
> Suppose that a Writer is scanning the array searching for reference X 
> with version 0, and sees a reference that matches X, but then the 
> Writer goes to sleep. In the meantime, the Reader corresponding to 
> that particular entry finishes its operation, changing X to null, and 
> a bit later can start a new read operation on another LR instance Y, which
> happens to be at version 0.
> If the Writer thread then wakes up and looks at the Reader's version 
> it will see 0 and it will spin/yield waiting... forever?
> One way to overcome this is that the Writer must always: read the 
> reference, read the version, confirm that the reference hasn't change, 
> if it didn't change then spin/yield and re-read reference and version.
>
> Some care is required in the implementation and algorithm, but I 
> believe that your idea of having a single array for multiple LR 
> instances can be usefull in many practical situations.
We could assign a unique number to each LR instance.  Then combine the 
unique number with 1 bit for the versionIndex.  For example, the 
versionIndex could be put in the sign bit and the remaining 31 bits 
(assuming int) can be used for the LR instance unique number.  Thus, the 
reader sets both in the same store operation.  The value 0 would be 
reserved to mean NOT_READING which means 0 can't be used for an LR 
instance unique number.

Then again, this idea isn't worth much since it requires no nesting of LR.
>
>
> Pedro


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140102/e8ba78b4/attachment.html>

From pramalhe at gmail.com  Fri Jan  3 14:18:55 2014
From: pramalhe at gmail.com (Pedro Ramalhete)
Date: Fri, 3 Jan 2014 20:18:55 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
	technique
In-Reply-To: <52C53F75.2070803@marand.si>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52BF6CB6.3040103@gmail.com>
	<CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>
	<52C53F75.2070803@marand.si>
Message-ID: <CAAApjO3BbAEXFH4Juu42TJAU-W9ynsG5mMecfqu-TcJ=Kx0B7g@mail.gmail.com>

On Thu, Jan 2, 2014 at 11:29 AM, Peter Levart <peter.levart at marand.si>wrote:

>
> On 12/31/2013 10:15 PM, Pedro Ramalhete wrote:
>
> Hi Peter,
>
> We were unable to compile your code, even using the latest stable
> netbeans-lambda, so we couldn't test it or benchmark it.
>
>
> I'm sorry, I published the wrong version that doesn't compiIle. Inference
> in JDK 8 and covariant function return types don't play well together.
> Here's the version that compiles - just removed the wildcards from return
> type parameters of Function and BiFunction interfaces in read() methods:
>
> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>
>
Thanks Peter, it compiles now.
I see you even added the possibility to specify different "readIndicator"
mechanisms, which is cool!


>
> Do you mean the possibility of a delay caused by LongAdder.increment()
> re-trying the cas and resizing the cells array as a consequence of
> increasing load on the LongAdder instance?
>

Yes, LongAdder.increment() is (at best) lock-free because of
longAccumulate() which contains a "for(;;)" loop, in which one of the "else
if" statements does something like "a.cas(v, v+x)" which may fail, and will
then cause an "h = advanceProbe(h)" which will result in a new "a" cell
(hopefully) but even then, there is no guarantee that some other thread
isn't doing a cas() on that particular cell as well, and the cas() will
fail again. This kind of behavior is lock-free.


> For that matter, even ThreadLocal.get() is not entirely wait-free, since
> it can stray into expunging stale entries and moving following entries into
> vacant slots, although the pauses caused by that might not be long or
> frequent.
>
>
 Hummm I don't understand why you say that ThreadLocal.get() is not
wait-free. There is no sharing of state between threads in this class,
apart from "nextHashCode" which is only read/written on the constructor.
Each thread will expunge its own stale entries, so there is no possibility
of blocking or retry caused by other threads. To me,
ThreadLocal.get()/set() both seem Wait-Free Population Oblivious:
http://concurrencyfreaks.com/2013/05/lock-free-and-wait-free-definition-and.html


>
>
> I also experimented with an alternative readindicator implementation, very
> similar to your CLQ/array. For comparison with two-long-adders approach, I
> created this interface, and two implementations:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/EnterExitWait.java
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LongAdderEEW.java
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/TLChainEEW.java
>
> The following benchmark, run on a 4 core Intel i7 PC shows TLChainEEW to
> be slightly better than LongAdderEEW:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java
>

Yesterday, Andreia added your implementation with (LongAdders) to our
benchmark suite, and ran it on a 32-core opteron. You can check the results
here if you're interested:
http://concurrencyfreaks.com/2014/01/lambdas-and-left-right-technique.html



>
> I used Unsafe.putOrderedInt() in TLChainEEW to publish from reader
> threads. I think this is enough for sequential consistency. Do you agree?
>

According to the documentation on putOrderedInt(), it is a "version of
putIntVolatile() that does not guarantee immediate visibility of the store
to other threads",
which means that using it in TLChainEEW.enter()/exit() may result in
waitEmpty() not seeing the new value of Entry.in, and thus cause
enter()/exit() to _not_ be
sequentially consistent with waitEmpty().
http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/sun/misc/Unsafe.java#Unsafe.putOrderedInt%28java.lang.Object%2Clong%2Cint%29


>
>
>
> Besides the compilation failure, there is one issue in your
> implementation.
> The order of calling exists.sum() and enters.sum() must always be
> "exists"
> first (egress counter) and then "enters" (ingress counter).
> In EnterExistCounter, on the function isEmtpty(), the implementation is
> "exits.sum() == enters.sum()" and although I'm not sure of Java's
> expression
> evaluation rules for this case, I would assume that there is no guarantee
> on which one will be evaluated first, thus causing a bug if enters.sum()
> happens to be executed before exists.sum().
>
>
> Java does guarantee that binary operators 1st evaluate left operand and
> then right:
>
> http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.7
>
>
Ahhh I didn't know that Java gave that guarantee... I'm always learning
something new  ;)
In that case, your implementation of waitEmpty() with LongAdders is
absolutely correct.
Thanks for the link!


Thanks,
Pedro

>
>
> On Sun, Dec 29, 2013 at 1:28 AM, Peter Levart <peter.levart at gmail.com>wrote:
>
>>  Hello Pedro,
>>
>> This is a very interesting article. I immediately jumped into
>> implementing the basic algorithm myself, but using a slightly different
>> coding approach, and, since these are the days of JDK 8, using functional
>> interfaces which play nicely with lambdas:
>>
>> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>
>> I tried to leverage j.u.c.LongAdder here to implement "readIndaicator" -
>> the alternative for "Algorithms 2, 3 and 5" described in paper. But as
>> you've written in paper, using a counter for that purpose, it has to be
>> sequentially consistent, which you've showed, is not the case for LongAdder:
>>
>>
>> http://concurrencyfreaks.blogspot.com/2013/09/longadder-is-not-sequentially-consistent.html
>>
>> LongAdder is not sequentially consistent if used with different
>> modification operations - for example using LongAdder.increment() for
>> "arrive" and LongAdder.decrement() for "depart" operations, combined with
>> LongAdder.sum() == 0L to implement "isEmpty". But you also showed that
>> LongAdder is sequentialy consistent if only a single kind of modifications
>> are applied to it. For example, only using inclrement() to modify, and
>> sum() to read. So I thought using two LongAdders - one for ingress, the
>> other for egress, and reading their sum()s in correct order (first egress
>> sum, then ingress sum) and comparing them for equality would do the job. Am
>> I right?
>>
>> Regards, Peter
>>
>>
>> On 12/25/2013 01:44 PM, Pedro Ramalhete wrote:
>>
>>  Hello,
>>
>> We are pleased to announce a new concurrency control technique which we
>> named "Left-Right" and that allows Wait-Free Populations Oblivious read
>> operations. The easiest way to explain what it is, is to say that it's a
>> "kind of" Reader-Writer Lock that doesn't block for Readers, which makes it
>> ideal for low-latency and real-time deployment scenarios:
>>
>> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>>
>> In case you missed it above, this means that you can have one Writer and
>> multiple Readers executing simultaneously, and unlike optimistic read
>> locks, you don't have to worry about atomicity, or memory management, or
>> invariants.
>>
>> Similarly to a Reader-Writer lock, it can be applied to any
>> (non-thread-safe) data structure and enable it to be used in a
>> multi-threaded application, where it will be Blocking for Writers, and
>> Wait-Free for Readers. It can be implemented in Java, Scala, C11, or C++1x.
>> Sample source code can be seen here:
>>
>> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/LRScalableTreeSet.java
>>
>> http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/leftright/LRScalableGuard.java
>>
>> Its two main innovations are, the usage of two instances, and the new
>> concurrency control algorithm whose novel state machine gives wait-free
>> guarantees for read operations.
>>
>>
>> There is another technique which also uses two instances but requires 3
>> locks, which perhaps has already been discovered, that we named "Double
>> Instance Locking" and it is much easier to understand and implement, but it
>> is only Lock-Free for read operations:
>>
>> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLocking.pptx
>>
>> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLockGuard.java
>> http://concurrencyfreaks.com/2013/11/double-instance-locking.html
>>
>> We would like to hear expert's comments on it   ;)
>>
>> Merry Christmas,
>> Pedro & Andreia
>>
>>
>>   _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140103/2862e166/attachment.html>

From mr.chrisvest at gmail.com  Fri Jan  3 18:49:11 2014
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Sat, 4 Jan 2014 00:49:11 +0100
Subject: [concurrency-interest] ThreadFactory implementation
	recommendations
In-Reply-To: <CAHjP37E_b2a5RGRkvvg73NCd=ZVg+53sqLqcU59L+VRRU12F-A@mail.gmail.com>
References: <C9947E3B-F0F8-4123-8354-F370990E4D3B@gmail.com>
	<CAHjP37E_b2a5RGRkvvg73NCd=ZVg+53sqLqcU59L+VRRU12F-A@mail.gmail.com>
Message-ID: <D7E8A94A-AF23-40DF-85A9-6145DD4F9472@gmail.com>

Thanks for the replies.

I only want to set the thread names to aid debugging, so I?m going to just wrap the defaultThreadFactory with that additional bit of logic. Since I can?t set the ThreadFactory on arbitrary Executors, I don?t see much point in allowing users to set both, so I?m going to stick with just allowing them to set the Executor. Then they can configure it however they like, if they want to.

Cheers,
Chris

On 02 Jan 2014, at 14:51, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Chris,
> 
> I think I would do the following:
> 1) Allow user to provide their own threadfactory
> 2) use defaultThreadFactory for when they don't provide a custom one
> 
> In both cases, internally I'd wrap it in your own threadfactory that manipulates the name of the thread returned by 1 or 2 above.
> 
> I think this is fine from usability as you cater to default easily and for cases where something custom is needed, you allow the hook to do that.
> 
> Sent from my phone
> 
> On Jan 2, 2014 8:42 AM, "Chris Vest" <mr.chrisvest at gmail.com> wrote:
> Hi,
> 
> I?m maintaining a library that does background work using an Executor. I allow people to configure their own Executor if they want, but I also want to provide a reasonable default if they don?t.
> 
> Looking at the Executors.defaultThreadFactory and privilegedThreadFactory implementations, and considering the many deployment options available to Java developers today, I wonder if you have any advice for what ThreadFactory implementation I should use?
> 
> The only thing I want to do out of the ordinary is setting my own prefix for the Thread names. Apart from that, I want to just ?do the right thing? in as many contexts as possible.
> 
> Cheers,
> Chris
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140104/5e430db1/attachment-0001.html>

From nathan.reynolds at oracle.com  Sat Jan  4 19:50:33 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Sat, 04 Jan 2014 17:50:33 -0700
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <52C53011.9030809@gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52C4EA71.5000407@oracle.com> <52C53011.9030809@gmail.com>
Message-ID: <52C8AC59.7090507@oracle.com>

Consider the following code.  It seems to be a bit simpler.  It uses 
Function instead of BiFunction. Also, if someone wants to use a 
valueSet() they have to do so inside the lambda.  This is no different 
than having to do everything inside the critical section of a lock.

LeftRight<Map<String, Integer>> lrMap = new LeftRight<>(new HashMap<>(), 
new HashMap<>());

//reading
String key = "Hello";
boolean contains = lrMap.read(map ? map.containsKey(key));
int count = lrMap.read(map ?
{
    for (Map.Entry<String, Integer> entry : map.valueSet())
       result += entry.getValue();

    return(result);
}

//modifying
Integer value = 5;
Integer result = lrMap.modify(map ? map.put(key, value));

Note: Some modifying operations return a value so LeftRight.modify() 
should also be allowed to return a value.

-Nathan

On 1/2/2014 2:23 AM, Peter Levart wrote:
> On 01/02/2014 05:26 AM, Nathan Reynolds wrote:
>> In Java-land, one could create a delegate wrapper for any interface 
>> with Proxy.newProxyInstance 
>> (http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Proxy.html). 
>> When the InvocationHandler is executed, it determines if the method 
>> is a read or write method and then executes the appropriate 
>> left-right logic.  This would allow for writing the left-right logic 
>> only in the InvocationHandler and then be re-used for all sorts of 
>> interfaces.  In other words, left-right wouldn't have to be built 
>> into every data structure.  Write Once Use Everywhere.
>
> Good idea. This would only work for simple "snapshot" and modification 
> methods though. Something that returns a "view" over internal state 
> (like Map.entrySet() for example), won't work unless the returned 
> object is also wrapped with a similar Proxy... Now that we have 
> lambdas, a generic solution could be modelled with them:
>
> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>
> This can be used like that:
>
> LeftRight<Set<Integer>> lrSet = new LeftRight<>(new HashSet<>(), new 
> HashSet<>());
>
> // reading
> boolean contains = lrSet.read(12, (key, set) -> set.contains(key));
>
> // modifying
> lrSet.modify(12, (key, set) -> set.add(key));
>
>
> This is particularly well suited for modifying since the same lambda 
> logic is executed twice for every external invocation and must apply 
> the same modifications to each mirror of the data structure.
>
> Regards, Peter
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140104/213778a4/attachment.html>

From nathan.reynolds at oracle.com  Sat Jan  4 20:14:01 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Sat, 04 Jan 2014 18:14:01 -0700
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <52C8AC59.7090507@oracle.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52C4EA71.5000407@oracle.com> <52C53011.9030809@gmail.com>
	<52C8AC59.7090507@oracle.com>
Message-ID: <52C8B1D9.5050205@oracle.com>

Let me try again with the code.  It wouldn't have compiled.

       LeftRightLock<HashMap<String, Integer>> lock;
       String key;
       Integer val;
       Integer out;
       int count;
       boolean contains;

       lock     = new LeftRightLock<>(new HashMap<String, Integer>(), 
new HashMap<String, Integer>());

       // Reading
       key      = "Hello";
       contains = lock.read(map -> map.containsKey(key));
       count    = lock.read(map ->
       {
          int result;

          result = 0;

          for (Integer value : map.values())
             result += value;

          return(result);
       });

       // Writing
       val = 5;
       out = lock.modify(map -> map.put(key, val));

-Nathan

On 1/4/2014 5:50 PM, Nathan Reynolds wrote:
> Consider the following code.  It seems to be a bit simpler.  It uses 
> Function instead of BiFunction.  Also, if someone wants to use a 
> valueSet() they have to do so inside the lambda.  This is no different 
> than having to do everything inside the critical section of a lock.
>
> LeftRight<Map<String, Integer>> lrMap = new LeftRight<>(new 
> HashMap<>(), new HashMap<>());
>
> //reading
> String key = "Hello";
> boolean contains = lrMap.read(map ? map.containsKey(key));
> int count = lrMap.read(map ?
> {
>    for (Map.Entry<String, Integer> entry : map.valueSet())
>       result += entry.getValue();
>
>    return(result);
> }
>
> //modifying
> Integer value = 5;
> Integer result = lrMap.modify(map ? map.put(key, value));
>
> Note: Some modifying operations return a value so LeftRight.modify() 
> should also be allowed to return a value.
> -Nathan
> On 1/2/2014 2:23 AM, Peter Levart wrote:
>> On 01/02/2014 05:26 AM, Nathan Reynolds wrote:
>>> In Java-land, one could create a delegate wrapper for any interface 
>>> with Proxy.newProxyInstance 
>>> (http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Proxy.html). 
>>> When the InvocationHandler is executed, it determines if the method 
>>> is a read or write method and then executes the appropriate 
>>> left-right logic.  This would allow for writing the left-right logic 
>>> only in the InvocationHandler and then be re-used for all sorts of 
>>> interfaces.  In other words, left-right wouldn't have to be built 
>>> into every data structure.  Write Once Use Everywhere.
>>
>> Good idea. This would only work for simple "snapshot" and 
>> modification methods though. Something that returns a "view" over 
>> internal state (like Map.entrySet() for example), won't work unless 
>> the returned object is also wrapped with a similar Proxy... Now that 
>> we have lambdas, a generic solution could be modelled with them:
>>
>> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>
>> This can be used like that:
>>
>> LeftRight<Set<Integer>> lrSet = new LeftRight<>(new HashSet<>(), new 
>> HashSet<>());
>>
>> // reading
>> boolean contains = lrSet.read(12, (key, set) -> set.contains(key));
>>
>> // modifying
>> lrSet.modify(12, (key, set) -> set.add(key));
>>
>>
>> This is particularly well suited for modifying since the same lambda 
>> logic is executed twice for every external invocation and must apply 
>> the same modifications to each mirror of the data structure.
>>
>> Regards, Peter
>>
>>
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140104/28b530fc/attachment.html>

From peter.levart at gmail.com  Sun Jan  5 07:07:53 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 05 Jan 2014 13:07:53 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <52C8B1D9.5050205@oracle.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52C4EA71.5000407@oracle.com> <52C53011.9030809@gmail.com>
	<52C8AC59.7090507@oracle.com> <52C8B1D9.5050205@oracle.com>
Message-ID: <52C94B19.5030802@gmail.com>


On 01/05/2014 02:14 AM, Nathan Reynolds wrote:
> Let me try again with the code.  It wouldn't have compiled.
>
>       LeftRightLock<HashMap<String, Integer>> lock;
>       String key;
>       Integer val;
>       Integer out;
>       int count;
>       boolean contains;
>
>       lock     = new LeftRightLock<>(new HashMap<String, Integer>(), 
> new HashMap<String, Integer>());
>
>       // Reading
>       key      = "Hello";
>       contains = lock.read(map -> map.containsKey(key));
>       count    = lock.read(map ->
>       {
>          int result;
>
>          result = 0;
>
>          for (Integer value : map.values())
>             result += value;
>
>          return(result);
>       });
>
>       // Writing
>       val = 5;
>       out = lock.modify(map -> map.put(key, val));

Hi Nathan,

Yes, the above is an example of a clean functional approach. Using 
closures to pass parameters to the read/modify operation. If you look at 
the source of LeftRight.java, you can see I allowed for such usage with 
overloaded read method (using Function instead of BiFunction). I also 
give overloaded modify method (using Consumer instead of BiConsumer). 
The reason for Bi* variants (Tri*, Quad*, etc. would also be needed 
sometimes) is preserving the progress properties of LeftRight algorithm.

Current lambda implementation creates an instance of a lambda function 
object for each lambda expression evaluation if this expression captures 
any state (if it doesn't, the lambda expression evaluates into a 
constant singleton object). I have doubts that JVM will always be able 
to eliminate this allocation, which it theoretically could, since 
captured state does not escape if it is used only for reading. But in 
practice it can be passed deep down into implementation methods of the 
data-structure lookup operation, so any allocation elimination algorithm 
would have a difficult time proving that captured state does not escape.

LeftRight read operations are declared to be Wait-free Population 
Oblivious and allocating objects has it's own progress guarantees which 
can be weaker. So methods that take closures over captured state are a 
welcome addition, but should only be used when original LeftRight.read 
operation progress properties are not strictly needed.

Your example also shows how a Function could be used for modify 
operation (instead of Consumer), which effectively turns it into 
readModify operation. The hypothetical dilemma with this is what to do 
with the return value. The function is called twice (each time with a 
distinct mirror of the data structure) and if data-structure read/modify 
operation is deterministic, it should return the same/equal/equivalent 
value in both invocations, so the read operation could return the result 
of 1st (or 2nd) invocation and still be useful.

Regards, Peter

>
> -Nathan
> On 1/4/2014 5:50 PM, Nathan Reynolds wrote:
>> Consider the following code.  It seems to be a bit simpler.  It uses 
>> Function instead of BiFunction.  Also, if someone wants to use a 
>> valueSet() they have to do so inside the lambda.  This is no 
>> different than having to do everything inside the critical section of 
>> a lock.
>>
>> LeftRight<Map<String, Integer>> lrMap = new LeftRight<>(new 
>> HashMap<>(), new HashMap<>());
>>
>> //reading
>> String key = "Hello";
>> boolean contains = lrMap.read(map ? map.containsKey(key));
>> int count = lrMap.read(map ?
>> {
>>    for (Map.Entry<String, Integer> entry : map.valueSet())
>>       result += entry.getValue();
>>
>>    return(result);
>> }
>>
>> //modifying
>> Integer value = 5;
>> Integer result = lrMap.modify(map ? map.put(key, value));
>>
>> Note: Some modifying operations return a value so LeftRight.modify() 
>> should also be allowed to return a value.
>> -Nathan
>> On 1/2/2014 2:23 AM, Peter Levart wrote:
>>> On 01/02/2014 05:26 AM, Nathan Reynolds wrote:
>>>> In Java-land, one could create a delegate wrapper for any interface 
>>>> with Proxy.newProxyInstance 
>>>> (http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Proxy.html). 
>>>> When the InvocationHandler is executed, it determines if the method 
>>>> is a read or write method and then executes the appropriate 
>>>> left-right logic.  This would allow for writing the left-right 
>>>> logic only in the InvocationHandler and then be re-used for all 
>>>> sorts of interfaces.  In other words, left-right wouldn't have to 
>>>> be built into every data structure.  Write Once Use Everywhere.
>>>
>>> Good idea. This would only work for simple "snapshot" and 
>>> modification methods though. Something that returns a "view" over 
>>> internal state (like Map.entrySet() for example), won't work unless 
>>> the returned object is also wrapped with a similar Proxy... Now that 
>>> we have lambdas, a generic solution could be modelled with them:
>>>
>>> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>>
>>> This can be used like that:
>>>
>>> LeftRight<Set<Integer>> lrSet = new LeftRight<>(new HashSet<>(), new 
>>> HashSet<>());
>>>
>>> // reading
>>> boolean contains = lrSet.read(12, (key, set) -> set.contains(key));
>>>
>>> // modifying
>>> lrSet.modify(12, (key, set) -> set.add(key));
>>>
>>>
>>> This is particularly well suited for modifying since the same lambda 
>>> logic is executed twice for every external invocation and must apply 
>>> the same modifications to each mirror of the data structure.
>>>
>>> Regards, Peter
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140105/5b08b462/attachment-0001.html>

From peter.levart at gmail.com  Sun Jan  5 09:05:20 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 05 Jan 2014 15:05:20 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <CAAApjO3BbAEXFH4Juu42TJAU-W9ynsG5mMecfqu-TcJ=Kx0B7g@mail.gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>	<52BF6CB6.3040103@gmail.com>	<CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>	<52C53F75.2070803@marand.si>
	<CAAApjO3BbAEXFH4Juu42TJAU-W9ynsG5mMecfqu-TcJ=Kx0B7g@mail.gmail.com>
Message-ID: <52C966A0.7080304@gmail.com>


On 01/03/2014 08:18 PM, Pedro Ramalhete wrote:
>
>
> On Thu, Jan 2, 2014 at 11:29 AM, Peter Levart <peter.levart at marand.si 
> <mailto:peter.levart at marand.si>> wrote:
>
>
>     On 12/31/2013 10:15 PM, Pedro Ramalhete wrote:
>>     Hi Peter,
>>
>>     We were unable to compile your code, even using the latest stable
>>     netbeans-lambda, so we couldn't test it or benchmark it.
>
>     I'm sorry, I published the wrong version that doesn't compiIle.
>     Inference in JDK 8 and covariant function return types don't play
>     well together. Here's the version that compiles - just removed the
>     wildcards from return type parameters of Function and BiFunction
>     interfaces in read() methods:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/LeftRight.java>
>
>
> Thanks Peter, it compiles now.
> I see you even added the possibility to specify different 
> "readIndicator" mechanisms, which is cool!
>
>
>
>     Do you mean the possibility of a delay caused by
>     LongAdder.increment() re-trying the cas and resizing the cells
>     array as a consequence of increasing load on the LongAdder instance?
>
>
> Yes, LongAdder.increment() is (at best) lock-free because of 
> longAccumulate() which contains a "for(;;)" loop, in which one of the 
> "else if" statements does something like "a.cas(v, v+x)" which may 
> fail, and will then cause an "h = advanceProbe(h)" which will result 
> in a new "a" cell (hopefully) but even then, there is no guarantee 
> that some other thread isn't doing a cas() on that particular cell as 
> well, and the cas() will fail again. This kind of behavior is lock-free.
>
>     For that matter, even ThreadLocal.get() is not entirely wait-free,
>     since it can stray into expunging stale entries and moving
>     following entries into vacant slots, although the pauses caused by
>     that might not be long or frequent.
>
>  Hummm I don't understand why you say that ThreadLocal.get() is not 
> wait-free. There is no sharing of state between threads in this class, 
> apart from "nextHashCode" which is only read/written on the 
> constructor. Each thread will expunge its own stale entries, so there 
> is no possibility of blocking or retry caused by other threads. To me, 
> ThreadLocal.get()/set() both seem Wait-Free Population Oblivious:
> http://concurrencyfreaks.com/2013/05/lock-free-and-wait-free-definition-and.html

You're right. ThreadLocal operations access thread-local state only (a 
ThreadLocalMap assigned to 'threadLocals' field in 
Thread.currentThread() object). So there can not be any interaction with 
other threads (besides false-sharing cache interactions).

>
>
>     I also experimented with an alternative readindicator
>     implementation, very similar to your CLQ/array. For comparison
>     with two-long-adders approach, I created this interface, and two
>     implementations:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/EnterExitWait.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/EnterExitWait.java>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LongAdderEEW.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/LongAdderEEW.java>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/TLChainEEW.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/TLChainEEW.java>
>
>     The following benchmark, run on a 4 core Intel i7 PC shows
>     TLChainEEW to be slightly better than LongAdderEEW:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java
>     <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/LRTest.java>
>
> Yesterday, Andreia added your implementation with (LongAdders) to our 
> benchmark suite, and ran it on a 32-core opteron. You can check the 
> results here if you're interested:
> http://concurrencyfreaks.com/2014/01/lambdas-and-left-right-technique.html
>

Interesting. So why is the performance of the generic lambda approach so 
low on your benchmarks, compared to other approaches? Can you share the 
source of the benchmark (or the fragment where LeftRight class is used)? 
Did Andreia use the 'read' method with Function or BiFunction parameter? 
What does "Total ops / s" represent on the diagrams? The mix or read and 
modify operations? Only read operations? How do you achieve "0.1%, 1%, 
10% or 30%" writes, since writes are inherently single-threaded in Left 
Right algorithm?

I noticed the LRLongAdderExtCollection and LRLongAdderExtMap classes here:

http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/collections/

... I would just like to note that method references have common 
implementation with lambdas in JDK 8. What that means is that a "bound" 
method reference:

     anInstance::method

allocates a function object at each evaluation of method reference (not 
invocation of the resulting function object), because the function 
object effectively "captures" the "anInstance" reference. To avoid 
object allocation and still use method references and lambdas, they 
should be non-capturing. Such method references are the un-bound kind:

     SomeType::method

and for lambdas, they should not reference any non-static state besides 
it's own parameters. Non-capturing method references and lambdas 
translate into a very fast constant load.

>
>     I used Unsafe.putOrderedInt() in TLChainEEW to publish from reader
>     threads. I think this is enough for sequential consistency. Do you
>     agree?
>
>
> According to the documentation on putOrderedInt(), it is a "version of 
> putIntVolatile() that does not guarantee immediate visibility of the 
> store to other threads",
> which means that using it in TLChainEEW.enter()/exit() may result in 
> waitEmpty() not seeing the new value of Entry.in, and thus cause 
> enter()/exit() to _not_ be
> sequentially consistent with waitEmpty().
> http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/sun/misc/Unsafe.java#Unsafe.putOrderedInt%28java.lang.Object%2Clong%2Cint%29
>

Right. enter() then must use volatile write. But exit() could use "lazy" 
write and still be sequentially consistent with waitEmpty(), right? 
Using "lazy" write for exit() still has performance advantage that is 
measurable. I have modified the test to compare LeftRight technique 
using the readIndicator variants with volatile exit() and lazy exit() 
and lazy variant shows up to 10% faster read of a 1024 element TreeSet 
than volatile variant while not noticeably influencing write throughput:

     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java

Regards, Peter

>
>>
>>
>>     Besides the compilation failure, there is one issue in your
>>     implementation.
>>     The order of calling exists.sum() and enters.sum() must always be
>>     "exists"
>>     first (egress counter) and then "enters" (ingress counter).
>>     In EnterExistCounter, on the function isEmtpty(), the
>>     implementation is
>>     "exits.sum() == enters.sum()" and although I'm not sure of Java's
>>     expression
>>     evaluation rules for this case, I would assume that there is no
>>     guarantee
>>     on which one will be evaluated first, thus causing a bug if
>>     enters.sum()
>>     happens to be executed before exists.sum().
>
>     Java does guarantee that binary operators 1st evaluate left
>     operand and then right:
>
>     http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.7
>
> Ahhh I didn't know that Java gave that guarantee... I'm always 
> learning something new  ;)
> In that case, your implementation of waitEmpty() with LongAdders is 
> absolutely correct.
> Thanks for the link!
>
>
> Thanks,
> Pedro
>
>>
>>
>>     On Sun, Dec 29, 2013 at 1:28 AM, Peter Levart
>>     <peter.levart at gmail.com <mailto:peter.levart at gmail.com>> wrote:
>>
>>         Hello Pedro,
>>
>>         This is a very interesting article. I immediately jumped into
>>         implementing the basic algorithm myself, but using a slightly
>>         different coding approach, and, since these are the days of
>>         JDK 8, using functional interfaces which play nicely with
>>         lambdas:
>>
>>         http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>         <http://cr.openjdk.java.net/%7Eplevart/misc/LeftRight/LeftRight.java>
>>
>>         I tried to leverage j.u.c.LongAdder here to implement
>>         "readIndaicator" - the alternative for "Algorithms 2, 3 and
>>         5" described in paper. But as you've written in paper, using
>>         a counter for that purpose, it has to be sequentially
>>         consistent, which you've showed, is not the case for LongAdder:
>>
>>         http://concurrencyfreaks.blogspot.com/2013/09/longadder-is-not-sequentially-consistent.html
>>
>>         LongAdder is not sequentially consistent if used with
>>         different modification operations - for example using
>>         LongAdder.increment() for "arrive" and LongAdder.decrement()
>>         for "depart" operations, combined with LongAdder.sum() == 0L
>>         to implement "isEmpty". But you also showed that LongAdder is
>>         sequentialy consistent if only a single kind of modifications
>>         are applied to it. For example, only using inclrement() to
>>         modify, and sum() to read. So I thought using two LongAdders
>>         - one for ingress, the other for egress, and reading their
>>         sum()s in correct order (first egress sum, then ingress sum)
>>         and comparing them for equality would do the job. Am I right?
>>
>>         Regards, Peter
>>
>>
>>         On 12/25/2013 01:44 PM, Pedro Ramalhete wrote:
>>>         Hello,
>>>
>>>         We are pleased to announce a new concurrency control
>>>         technique which we named "Left-Right" and that allows
>>>         Wait-Free Populations Oblivious read operations. The easiest
>>>         way to explain what it is, is to say that it's a "kind of"
>>>         Reader-Writer Lock that doesn't block for Readers, which
>>>         makes it ideal for low-latency and real-time deployment
>>>         scenarios:
>>>         http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>>>
>>>         In case you missed it above, this means that you can have
>>>         one Writer and multiple Readers executing simultaneously,
>>>         and unlike optimistic read locks, you don't have to worry
>>>         about atomicity, or memory management, or invariants.
>>>
>>>         Similarly to a Reader-Writer lock, it can be applied to any
>>>         (non-thread-safe) data structure and enable it to be used in
>>>         a multi-threaded application, where it will be Blocking for
>>>         Writers, and Wait-Free for Readers. It can be implemented in
>>>         Java, Scala, C11, or C++1x.
>>>         Sample source code can be seen here:
>>>         http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/LRScalableTreeSet.java
>>>         http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/leftright/LRScalableGuard.java
>>>
>>>         Its two main innovations are, the usage of two instances,
>>>         and the new concurrency control algorithm whose novel state
>>>         machine gives wait-free guarantees for read operations.
>>>
>>>
>>>         There is another technique which also uses two instances but
>>>         requires 3 locks, which perhaps has already been discovered,
>>>         that we named "Double Instance Locking" and it is much
>>>         easier to understand and implement, but it is only Lock-Free
>>>         for read operations:
>>>         http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLocking.pptx
>>>         http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLockGuard.java
>>>         http://concurrencyfreaks.com/2013/11/double-instance-locking.html
>>>
>>>         We would like to hear expert's comments on it   ;)
>>>
>>>         Merry Christmas,
>>>         Pedro & Andreia
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140105/0d36daf9/attachment-0001.html>

From andreiacraveiroramalhete at gmail.com  Sun Jan  5 16:40:44 2014
From: andreiacraveiroramalhete at gmail.com (Andreia Craveiro Ramalhete)
Date: Sun, 5 Jan 2014 22:40:44 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
	technique
In-Reply-To: <52C966A0.7080304@gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>
	<52BF6CB6.3040103@gmail.com>
	<CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>
	<52C53F75.2070803@marand.si>
	<CAAApjO3BbAEXFH4Juu42TJAU-W9ynsG5mMecfqu-TcJ=Kx0B7g@mail.gmail.com>
	<52C966A0.7080304@gmail.com>
Message-ID: <CAE7WXf69+L_u5aN+u0V-yGTGtXN0_MoQ_QiEQEyrJrrJ0F3NPA@mail.gmail.com>

Hello Peter,

I had a look to the test and found a copy/paste mistake, basically I was
calling the modify function, instead of the read. Sorry, I have re-runned
the test and results are now at the same range as the other LeftRight
implementations. We have updated with the correct results
http://concurrencyfreaks.blogspot.fr/2014/01/lambdas-and-left-right-technique.html,
and the test
https://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/tests/TestTreeSetFullRebalanceLambda.java.
I made a small change to your LeftRight on modify() so it has a return
value (it was necessary for our validation tests).

About the use of Unsafe.putOrderedInt() on exit(), we believe that it is
correct, the worse it can happen is that the write may not see that a read
already departed and wait unnecessarily.

Thank you for your functional version of the LeftRight, it is really useful
to test with different data structures.

regards,
Andreia


On Sun, Jan 5, 2014 at 3:05 PM, Peter Levart <peter.levart at gmail.com> wrote:

>
> On 01/03/2014 08:18 PM, Pedro Ramalhete wrote:
>
>
>
> On Thu, Jan 2, 2014 at 11:29 AM, Peter Levart <peter.levart at marand.si>wrote:
>
>>
>> On 12/31/2013 10:15 PM, Pedro Ramalhete wrote:
>>
>> Hi Peter,
>>
>> We were unable to compile your code, even using the latest stable
>> netbeans-lambda, so we couldn't test it or benchmark it.
>>
>>
>>  I'm sorry, I published the wrong version that doesn't compiIle.
>> Inference in JDK 8 and covariant function return types don't play well
>> together. Here's the version that compiles - just removed the wildcards
>> from return type parameters of Function and BiFunction interfaces in read()
>> methods:
>>
>> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>
>>
> Thanks Peter, it compiles now.
> I see you even added the possibility to specify different "readIndicator"
> mechanisms, which is cool!
>
>
>>
>>  Do you mean the possibility of a delay caused by LongAdder.increment()
>> re-trying the cas and resizing the cells array as a consequence of
>> increasing load on the LongAdder instance?
>>
>
> Yes, LongAdder.increment() is (at best) lock-free because of
> longAccumulate() which contains a "for(;;)" loop, in which one of the "else
> if" statements does something like "a.cas(v, v+x)" which may fail, and will
> then cause an "h = advanceProbe(h)" which will result in a new "a" cell
> (hopefully) but even then, there is no guarantee that some other thread
> isn't doing a cas() on that particular cell as well, and the cas() will
> fail again. This kind of behavior is lock-free.
>
>
>>  For that matter, even ThreadLocal.get() is not entirely wait-free, since
>> it can stray into expunging stale entries and moving following entries into
>> vacant slots, although the pauses caused by that might not be long or
>> frequent.
>>
>>
>  Hummm I don't understand why you say that ThreadLocal.get() is not
> wait-free. There is no sharing of state between threads in this class,
> apart from "nextHashCode" which is only read/written on the constructor.
> Each thread will expunge its own stale entries, so there is no possibility
> of blocking or retry caused by other threads. To me,
> ThreadLocal.get()/set() both seem Wait-Free Population Oblivious:
>
> http://concurrencyfreaks.com/2013/05/lock-free-and-wait-free-definition-and.html
>
>
> You're right. ThreadLocal operations access thread-local state only (a
> ThreadLocalMap assigned to 'threadLocals' field in Thread.currentThread()
> object). So there can not be any interaction with other threads (besides
> false-sharing cache interactions).
>
>
>
>
>>
>>
>>  I also experimented with an alternative readindicator implementation,
>> very similar to your CLQ/array. For comparison with two-long-adders
>> approach, I created this interface, and two implementations:
>>
>>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/EnterExitWait.java
>>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LongAdderEEW.java
>>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/TLChainEEW.java
>>
>> The following benchmark, run on a 4 core Intel i7 PC shows TLChainEEW to
>> be slightly better than LongAdderEEW:
>>
>>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java
>>
>
> Yesterday, Andreia added your implementation with (LongAdders) to our
> benchmark suite, and ran it on a 32-core opteron. You can check the results
> here if you're interested:
> http://concurrencyfreaks.com/2014/01/lambdas-and-left-right-technique.html
>
>
> Interesting. So why is the performance of the generic lambda approach so
> low on your benchmarks, compared to other approaches? Can you share the
> source of the benchmark (or the fragment where LeftRight class is used)?
> Did Andreia use the 'read' method with Function or BiFunction parameter?
> What does "Total ops / s" represent on the diagrams? The mix or read and
> modify operations? Only read operations? How do you achieve "0.1%, 1%, 10%
> or 30%" writes, since writes are inherently single-threaded in Left Right
> algorithm?
>
> I noticed the LRLongAdderExtCollection and LRLongAdderExtMap classes here:
>
>
> http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/collections/
>
> ... I would just like to note that method references have common
> implementation with lambdas in JDK 8. What that means is that a "bound"
> method reference:
>
>     anInstance::method
>
> allocates a function object at each evaluation of method reference (not
> invocation of the resulting function object), because the function object
> effectively "captures" the "anInstance" reference. To avoid object
> allocation and still use method references and lambdas, they should be
> non-capturing. Such method references are the un-bound kind:
>
>     SomeType::method
>
> and for lambdas, they should not reference any non-static state besides
> it's own parameters. Non-capturing method references and lambdas translate
> into a very fast constant load.
>
>
>
>
>>
>> I used Unsafe.putOrderedInt() in TLChainEEW to publish from reader
>> threads. I think this is enough for sequential consistency. Do you agree?
>>
>
> According to the documentation on putOrderedInt(), it is a "version of
> putIntVolatile() that does not guarantee immediate visibility of the store
> to other threads",
> which means that using it in TLChainEEW.enter()/exit() may result in
> waitEmpty() not seeing the new value of Entry.in, and thus cause
> enter()/exit() to _not_ be
> sequentially consistent with waitEmpty().
>
> http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/sun/misc/Unsafe.java#Unsafe.putOrderedInt%28java.lang.Object%2Clong%2Cint%29
>
>
>
> Right. enter() then must use volatile write. But exit() could use "lazy"
> write and still be sequentially consistent with waitEmpty(), right? Using
> "lazy" write for exit() still has performance advantage that is measurable.
> I have modified the test to compare LeftRight technique using the
> readIndicator variants with volatile exit() and lazy exit() and lazy
> variant shows up to 10% faster read of a 1024 element TreeSet than volatile
> variant while not noticeably influencing write throughput:
>
>     http://cr.openjdk.java.net/~plevart/misc/LeftRight/LRTest.java
>
> Regards, Peter
>
>
>
>>
>>
>> Besides the compilation failure, there is one issue in your
>> implementation.
>> The order of calling exists.sum() and enters.sum() must always be
>> "exists"
>> first (egress counter) and then "enters" (ingress counter).
>> In EnterExistCounter, on the function isEmtpty(), the implementation is
>> "exits.sum() == enters.sum()" and although I'm not sure of Java's
>> expression
>> evaluation rules for this case, I would assume that there is no guarantee
>> on which one will be evaluated first, thus causing a bug if enters.sum()
>> happens to be executed before exists.sum().
>>
>>
>>  Java does guarantee that binary operators 1st evaluate left operand and
>> then right:
>>
>> http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.7
>>
>>
> Ahhh I didn't know that Java gave that guarantee... I'm always learning
> something new  ;)
> In that case, your implementation of waitEmpty() with LongAdders is
> absolutely correct.
> Thanks for the link!
>
>
> Thanks,
> Pedro
>
>>
>>
>> On Sun, Dec 29, 2013 at 1:28 AM, Peter Levart <peter.levart at gmail.com>wrote:
>>
>>>  Hello Pedro,
>>>
>>> This is a very interesting article. I immediately jumped into
>>> implementing the basic algorithm myself, but using a slightly different
>>> coding approach, and, since these are the days of JDK 8, using functional
>>> interfaces which play nicely with lambdas:
>>>
>>> http://cr.openjdk.java.net/~plevart/misc/LeftRight/LeftRight.java
>>>
>>> I tried to leverage j.u.c.LongAdder here to implement "readIndaicator" -
>>> the alternative for "Algorithms 2, 3 and 5" described in paper. But as
>>> you've written in paper, using a counter for that purpose, it has to be
>>> sequentially consistent, which you've showed, is not the case for LongAdder:
>>>
>>>
>>> http://concurrencyfreaks.blogspot.com/2013/09/longadder-is-not-sequentially-consistent.html
>>>
>>> LongAdder is not sequentially consistent if used with different
>>> modification operations - for example using LongAdder.increment() for
>>> "arrive" and LongAdder.decrement() for "depart" operations, combined with
>>> LongAdder.sum() == 0L to implement "isEmpty". But you also showed that
>>> LongAdder is sequentialy consistent if only a single kind of modifications
>>> are applied to it. For example, only using inclrement() to modify, and
>>> sum() to read. So I thought using two LongAdders - one for ingress, the
>>> other for egress, and reading their sum()s in correct order (first egress
>>> sum, then ingress sum) and comparing them for equality would do the job. Am
>>> I right?
>>>
>>> Regards, Peter
>>>
>>>
>>> On 12/25/2013 01:44 PM, Pedro Ramalhete wrote:
>>>
>>>  Hello,
>>>
>>> We are pleased to announce a new concurrency control technique which we
>>> named "Left-Right" and that allows Wait-Free Populations Oblivious read
>>> operations. The easiest way to explain what it is, is to say that it's a
>>> "kind of" Reader-Writer Lock that doesn't block for Readers, which makes it
>>> ideal for low-latency and real-time deployment scenarios:
>>>
>>> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/leftright-extended.pdf
>>>
>>> In case you missed it above, this means that you can have one Writer and
>>> multiple Readers executing simultaneously, and unlike optimistic read
>>> locks, you don't have to worry about atomicity, or memory management, or
>>> invariants.
>>>
>>> Similarly to a Reader-Writer lock, it can be applied to any
>>> (non-thread-safe) data structure and enable it to be used in a
>>> multi-threaded application, where it will be Blocking for Writers, and
>>> Wait-Free for Readers. It can be implemented in Java, Scala, C11, or C++1x.
>>> Sample source code can be seen here:
>>>
>>> http://sourceforge.net/projects/ccfreaks/files/papers/LeftRight/LRScalableTreeSet.java
>>>
>>> http://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/leftright/LRScalableGuard.java
>>>
>>> Its two main innovations are, the usage of two instances, and the new
>>> concurrency control algorithm whose novel state machine gives wait-free
>>> guarantees for read operations.
>>>
>>>
>>> There is another technique which also uses two instances but requires 3
>>> locks, which perhaps has already been discovered, that we named "Double
>>> Instance Locking" and it is much easier to understand and implement, but it
>>> is only Lock-Free for read operations:
>>>
>>> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLocking.pptx
>>>
>>> http://sourceforge.net/projects/ccfreaks/files/papers/DoubleInstance/DoubleInstanceLockGuard.java
>>> http://concurrencyfreaks.com/2013/11/double-instance-locking.html
>>>
>>> We would like to hear expert's comments on it   ;)
>>>
>>> Merry Christmas,
>>> Pedro & Andreia
>>>
>>>
>>>   _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140105/8ec88fd3/attachment-0001.html>

From aaron.grunthal at infinite-source.de  Mon Jan  6 08:36:09 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Mon, 06 Jan 2014 14:36:09 +0100
Subject: [concurrency-interest] Left-Right - A new concurrency control
 technique
In-Reply-To: <CAE7WXf69+L_u5aN+u0V-yGTGtXN0_MoQ_QiEQEyrJrrJ0F3NPA@mail.gmail.com>
References: <CAAApjO21nDTbVJhmjU0F+dTgjn5NuQeq3qC1w=hXRJZLZ0idyA@mail.gmail.com>	<52BF6CB6.3040103@gmail.com>	<CAAApjO3JzZV46BDp1cL5ZoDZH8PXt7VOXHZW3dxSB=f-jOeQdw@mail.gmail.com>	<52C53F75.2070803@marand.si>	<CAAApjO3BbAEXFH4Juu42TJAU-W9ynsG5mMecfqu-TcJ=Kx0B7g@mail.gmail.com>	<52C966A0.7080304@gmail.com>
	<CAE7WXf69+L_u5aN+u0V-yGTGtXN0_MoQ_QiEQEyrJrrJ0F3NPA@mail.gmail.com>
Message-ID: <52CAB149.9080608@infinite-source.de>

Looking at the charts in the blog post you linked:

Since you're using a fixed *ratio* of reads to writes and ramp up the # 
of threads that means the number of writes and reads goes up simultaneously.

If I understood correctly the writers in Left-Right are blocking and 
thus will reach saturation at some point. Scaling up something against a 
saturation point is non-linear. And since writer throughput depends on 
the # of readers that exacerbates the issue further.

Having different charts with non-linear behavior based on different 
ratios makes them very difficult to compare.

I think that plotting writes and reads per second separately and using a 
fixed rate of writes instead of a fixed ratio would make those charts 
more comparable.

- Aaron


On 05.01.2014 22:40, Andreia Craveiro Ramalhete wrote:
> Hello Peter,
>
> I had a look to the test and found a copy/paste mistake, basically I was
> calling the modify function, instead of the read. Sorry, I have
> re-runned the test and results are now at the same range as the other
> LeftRight implementations. We have updated with the correct results
> http://concurrencyfreaks.blogspot.fr/2014/01/lambdas-and-left-right-technique.html,
> and the test
> https://sourceforge.net/projects/ccfreaks/files/java/src/com/concurrencyfreaks/tests/TestTreeSetFullRebalanceLambda.java.
> I made a small change to your LeftRight on modify() so it has a return
> value (it was necessary for our validation tests).
>
> About the use of Unsafe.putOrderedInt() on exit(), we believe that it is
> correct, the worse it can happen is that the write may not see that a
> read already departed and wait unnecessarily.
>
> Thank you for your functional version of the LeftRight, it is really
> useful to test with different data structures.
>
> regards,
> Andreia


From evgeny.a.morozov at gmail.com  Tue Jan  7 03:08:24 2014
From: evgeny.a.morozov at gmail.com (Eugene Morozov)
Date: Tue, 7 Jan 2014 00:08:24 -0800
Subject: [concurrency-interest] ThreadSafe static analysis tool for Java
 concurrency: free trials available
In-Reply-To: <52B85014.60809@contemplateltd.com>
References: <52B85014.60809@contemplateltd.com>
Message-ID: <CAGu0ZE1cBcn+KH0Ax3k9qWbZ4v9AjgDKy_phPArCqkJKONd6RQ@mail.gmail.com>

Don,

I've requested trial version and I've got link to Eclipse plugin. I don't
use Eclipse. And I don't want to.
Anything you may suggest?

--
Be well!
Jean Morozov


On Mon, Dec 23, 2013 at 7:00 AM, Don Sannella <d.sannella at contemplateltd.com
> wrote:

> Contemplate, an Edinburgh University spin-out company, has developed an
> advanced static analysis tool, ThreadSafe, that specifically targets Java
> concurrency defects and includes some dedicated treatment for
> java.util.concurrent.  It handles enterprise-scale Java codebases and
> includes integration with Eclipse and SonarQube.
>
> I wrote to the list in April to look for people who would be willing to
> try out ThreadSafe and give feedback.  Thanks to everybody who participated!
>
> We have moved on and are now offering ThreadSafe 1.2 for sale in
> single-user and enterprise versions.  You can get a free trial by filling
> out a simple webform at:
>
> http://www.contemplateltd.com/try-buy/request-a-trial
>
> I encourage you to give it a spin.  I'm still very interested in any
> feedback.  Even more: if you like it, please spread the word!
>
> More information on Contemplate's website: www.contemplateltd.com
>
> Regards,
>
> Don Sannella
>
> ----------------------------------------------------------------------
> Prof. Donald Sannella, Laboratory for Foundations of Computer Science,
> School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK
> http://homepages.inf.ed.ac.uk/dts  dts at inf.ed.ac.uk  +44 131 650 5184
>
> and
>
> ---------------------------------------------------------
> Don Sannella                d.sannella at contemplateltd.com
> Contemplate Ltd                    www.contemplateltd.com
> Appleton Tower, 11 Crichton Street, Edinburgh EH8 9LE, UK
> tel +44 7939 132117  fax +44 131 6503474  skype dsannella
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140107/4f6f3db8/attachment.html>

From d.sannella at contemplateltd.com  Tue Jan  7 11:25:04 2014
From: d.sannella at contemplateltd.com (Don Sannella)
Date: Tue, 07 Jan 2014 16:25:04 +0000
Subject: [concurrency-interest] ThreadSafe static analysis tool for Java
 concurrency: free trials available
In-Reply-To: <CAGu0ZE1cBcn+KH0Ax3k9qWbZ4v9AjgDKy_phPArCqkJKONd6RQ@mail.gmail.com>
References: <52B85014.60809@contemplateltd.com>
	<CAGu0ZE1cBcn+KH0Ax3k9qWbZ4v9AjgDKy_phPArCqkJKONd6RQ@mail.gmail.com>
Message-ID: <52CC2A60.4090307@contemplateltd.com>

On 07/01/2014 08:08, Eugene Morozov wrote:
> Don,
>
> I've requested trial version and I've got link to Eclipse plugin. I
> don't use Eclipse. And I don't want to.
> Anything you may suggest?

Hi Jean,

Thanks for the question!

Currently, there are two ways of using ThreadSafe:

- Eclipse plugin: This is ThreadSafe Solo, and it's what you get when
   you request a free trial on
   http://www.contemplateltd.com/try-buy/request-a-trial
- SonarQube (formerly Sonar) plugin: included in ThreadSafe Enterprise.
   If you want a free trial of this, please contact me.

An IDE, like Eclipse, provides the best interface for investigating
ThreadSafe results, because they typically include multiple locations,
sometimes even relevant locations in multiple classes.

We are developing a command line program that will run the ThreadSafe
analyses and generate an HTML report. However, this isn't ready for
general use yet. Please contact me if you want to try it out; we may
offer a beta version before it is product-ready.

Unfortunately, there's no IntelliJ plugin yet. We've focused on Eclipse
support, just because it has a larger market share. We've seen interest
in an IntelliJ plugin too, but as a small start-up, we don't yet have
the resources to build and maintain an IntelliJ plugin as well.

Best regards, Don

----------------------------------------------------------------------
Prof. Donald Sannella, Laboratory for Foundations of Computer Science,
School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK
http://homepages.inf.ed.ac.uk/dts  dts at inf.ed.ac.uk  +44 131 650 5184

and

---------------------------------------------------------
Don Sannella                d.sannella at contemplateltd.com
Contemplate Ltd                    www.contemplateltd.com
Appleton Tower, 11 Crichton Street, Edinburgh EH8 9LE, UK
tel +44 7939 132117  fax +44 131 6503474  skype dsannella

From dl at cs.oswego.edu  Wed Jan  8 15:25:00 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 08 Jan 2014 15:25:00 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
Message-ID: <52CDB41C.70601@cs.oswego.edu>


It's time for tentatively proposing plans for JDK9. Here's a summary
of concurrency-related ones, some of which are already in their
earliest stages. All so far are preliminaries for anything
interestingly impacting java.util.concurrent, so are in the form of
OpenJDK "Java Enhancement Proposals" (JEP) that should soon emerge on
openjdk lists.

1. JMM Revisions

I submitted a JEP for updating and extending the JMM. The goals are to
update/fix formalisms and also extend coverage so that we can rigorously
spec things we've been adding.  We have an impressive set of
academics, researchers, and engineers tentatively signed up to
contribute.

2. JVM support

A second JEP covers per-release JVM support that j.u.c components can
use to improve performance and functionality: NUMA utilities, more
efficient memory polling, and two-variable compareAndSet (2CAS) --
directly implemented on some platforms, and efficiently emulated on
others.

3. Language support

A third JEP will cover a way to get rid of the need for Unsafe for
CASing fields, ordered/fenced access, etc. The time seems right to get
just enough syntax support to solve problems that we've never
otherwise found a good solution for over the years. At the moment, I
think the most likely possibility will allow access to operations
using ".volatile". for example:

     class Usage {
         volatile int count;
         int incrementCount() {
             return count.volatile.incrementAndGet();
         }
     }

There's more from there. A proposal (by others) for some sort of Value
Types seems to be a sure thing.  This will be a big help in dealing
with locality in parallel code (among other things).

And soon enough (but not all that soon), new java.util.concurrent
stuff. No firm plans yet, but providing more consistent support
for Async programming is near the top of the list.


-Doug

From aaron.grunthal at infinite-source.de  Wed Jan  8 16:20:27 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Wed, 08 Jan 2014 22:20:27 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52CDB41C.70601@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>
Message-ID: <52CDC11B.7070206@infinite-source.de>

On 08.01.2014 21:25, Doug Lea wrote:
> There's more from there. A proposal (by others) for some sort of Value
> Types seems to be a sure thing.  This will be a big help in dealing
> with locality in parallel code (among other things).


Ah, that won't give us flat arrays of struct-like composite values, will 
it? Because that what would make shared memory IPC much easier.

- Aaron

From mikeb01 at gmail.com  Wed Jan  8 17:05:02 2014
From: mikeb01 at gmail.com (Michael Barker)
Date: Thu, 9 Jan 2014 11:05:02 +1300
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52CDB41C.70601@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>
Message-ID: <CALwNKeQ=j0N9AcG70-Yve2-FY2Qj_Qb6-YFB15qu9rFm3GqRPA@mail.gmail.com>

>
> 3. Language support
>
> A third JEP will cover a way to get rid of the need for Unsafe for
> CASing fields, ordered/fenced access, etc. The time seems right to get
> just enough syntax support to solve problems that we've never
> otherwise found a good solution for over the years. At the moment, I
> think the most likely possibility will allow access to operations
> using ".volatile". for example:
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>

+1, I'm quite excited about by the proposal.  It has the added advantage
making code easier to read/understand as the fence is explicit when at
point of use, rather than requiring a developer to trace back to the
variable definition to determine if an assignment operation will trigger
the appropriate memory fence.

Could this pave the way to a richer atomic operations (like C++)?  E.g.

count.volatile.setVolatile(...); // Load/Store
count.volatile.setOrdered(...); // Store/Store
count.volatile.setAtomic(...) // No fence, just atomicity guaranteed.

Mike.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140109/35c5f29c/attachment.html>

From dl at cs.oswego.edu  Wed Jan  8 18:53:51 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 08 Jan 2014 18:53:51 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52CDC11B.7070206@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>
	<52CDC11B.7070206@infinite-source.de>
Message-ID: <52CDE50F.2030308@cs.oswego.edu>

On 01/08/2014 04:20 PM, Aaron Grunthal wrote:
> On 08.01.2014 21:25, Doug Lea wrote:
>> There's more from there. A proposal (by others) for some sort of Value
>> Types seems to be a sure thing.  This will be a big help in dealing
>> with locality in parallel code (among other things).
>
>
> Ah, that won't give us flat arrays of struct-like composite values, will it?
> Because that what would make shared memory IPC much easier.
>

I'll refrain from replying on behalf of Brian Goetz and others
working on this proposal, but yes, I would expect some form of
support for something along those lines.

-Doug



From dl at cs.oswego.edu  Wed Jan  8 18:59:53 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 08 Jan 2014 18:59:53 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CALwNKeQ=j0N9AcG70-Yve2-FY2Qj_Qb6-YFB15qu9rFm3GqRPA@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>
	<CALwNKeQ=j0N9AcG70-Yve2-FY2Qj_Qb6-YFB15qu9rFm3GqRPA@mail.gmail.com>
Message-ID: <52CDE679.5030806@cs.oswego.edu>

On 01/08/2014 05:05 PM, Michael Barker wrote:

>     A third JEP will cover a way to get rid of the need for Unsafe for
>     CASing fields, ordered/fenced access, etc.
>
> Could this pave the way to a richer atomic operations (like C++)?  E.g.

Yes, one goal is to be memory-model-compatible with C11/C++11.
The details are subject to JMM9, which is why these three JEPs are
intertwined. But yes, expect something like your...

> count.volatile.setVolatile(...); // Load/Store
> count.volatile.setOrdered(...); // Store/Store

-Doug


From aaron.grunthal at infinite-source.de  Wed Jan  8 20:18:15 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Thu, 09 Jan 2014 02:18:15 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CALwNKeQ=j0N9AcG70-Yve2-FY2Qj_Qb6-YFB15qu9rFm3GqRPA@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>
	<CALwNKeQ=j0N9AcG70-Yve2-FY2Qj_Qb6-YFB15qu9rFm3GqRPA@mail.gmail.com>
Message-ID: <52CDF8D7.3020802@infinite-source.de>

This only looks usable for for hand-crafted atomic accesses and not for 
building an atomic-toolbox for people who might prefer slightly slower 
but lock-free code over reasoning about ordering for every single field 
access.

I don't see how a developer could put things like 
read-calculate-cas/redo + appropriate barriers etc. into a utility 
library and somehow still access the fields of different classes 
dynamically.

So for anything but core libraries extending AtomicXXXFieldUpdaters 
/wrapping them in a few lambdas would still be the way to go. They 
basically act as a sort of heavy-weight FieldHandle anyway.

- Aaron

On 08.01.2014 23:05, Michael Barker wrote:
>     3. Language support
>
>     A third JEP will cover a way to get rid of the need for Unsafe for
>     CASing fields, ordered/fenced access, etc. The time seems right to get
>     just enough syntax support to solve problems that we've never
>     otherwise found a good solution for over the years. At the moment, I
>     think the most likely possibility will allow access to operations
>     using ".volatile". for example:
>
>          class Usage {
>              volatile int count;
>              int incrementCount() {
>                  return count.volatile.__incrementAndGet();
>              }
>          }
>
>
> +1, I'm quite excited about by the proposal.  It has the added advantage
> making code easier to read/understand as the fence is explicit when at
> point of use, rather than requiring a developer to trace back to the
> variable definition to determine if an assignment operation will trigger
> the appropriate memory fence.
>
> Could this pave the way to a richer atomic operations (like C++)?  E.g.
>
> count.volatile.setVolatile(...); // Load/Store
> count.volatile.setOrdered(...); // Store/Store
> count.volatile.setAtomic(...) // No fence, just atomicity guaranteed.
>
> Mike.
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From nathan.reynolds at oracle.com  Fri Jan 10 12:29:16 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 10 Jan 2014 10:29:16 -0700
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
	Normal Loads and Stores
Message-ID: <52D02DEC.1030507@oracle.com>

When writing concurrent code, I use the first table in 
http://g.oswego.edu/dl/jmm/cookbook.html to reason about how the various 
lines of code can be reordered and if that is going to cause a problem.

Then, I read through the Java Memory Model (JMM) in 
http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4. I 
suppose I understand the happens-before and everything being said 
there.  But, I don't get how one goes from the JMM to the cookbook's 
table.  In particular, why according to the JMM can't normal 
loads/stores be reordered with respect to volatile loads/stores.  Is 
there some line or paragraph in the JMM that I am not understanding?

-- 
-Nathan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/e1e86d69/attachment.html>

From kasperni at gmail.com  Fri Jan 10 12:57:29 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Fri, 10 Jan 2014 18:57:29 +0100
Subject: [concurrency-interest] CompletableFuture.getExceptionallyCause()
Message-ID: <CAPs6150WkPwnmaM17iCgz8i5T-Ni1yUu+CCtPQgmsG0vTq4+pg@mail.gmail.com>

Hi,

I'm trying to retrieve the cause of a failure from a CompletableFuture.

Any easier way than this?



if (isCompletedExceptionally()) {

    try {

        super.getNow(null);

    } catch (CancellationException e) {

        return e;

    } catch (CompletionException e) {

        return e.getCause();

    }

}

return null;


Cheers

  Kasper
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/bbdbd149/attachment.html>

From aleksey.shipilev at oracle.com  Fri Jan 10 13:04:47 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 10 Jan 2014 22:04:47 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D02DEC.1030507@oracle.com>
References: <52D02DEC.1030507@oracle.com>
Message-ID: <52D0363F.7030906@oracle.com>

On 01/10/2014 09:29 PM, Nathan Reynolds wrote:
> When writing concurrent code, I use the first table in
> http://g.oswego.edu/dl/jmm/cookbook.html to reason about how the various
> lines of code can be reordered and if that is going to cause a problem.
> 
> Then, I read through the Java Memory Model (JMM) in
> http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4. 
> I suppose I understand the happens-before and everything being said
> there.  But, I don't get how one goes from the JMM to the cookbook's
> table.  In particular, why according to the JMM can't normal
> loads/stores be reordered with respect to volatile loads/stores.  Is
> there some line or paragraph in the JMM that I am not understanding?

I recently gave a JMM talk (in Russian, sorry), and was having the same
question. Below is what I had finally arrived to. I'm sure you can
explain that more rigorously.

JSR 133 Cookbook explains the *conservative* implementation which still
fits JMM rules. Now, there is a confusion between JMM and JSR 133
Cookbook. Cookbook is *NOT* the Java Memory Model, Cookbook is a
conservative interpretation for runtime implementors.

The table you are referring to provides the guidance for conservative
implementations: notably, allowing moving in the normal load/stores
before the volatile store (release), and moving in the normal
load/stores after the volatile load (acquire). That is infamous "roach
motel".

The beauty of "roach motel" is that it allows local decisions, and you
can arrive to that model by simply observing that moving the operations
into the hb order does not violate correctness (since operations you are
about to move are racy anyway). I.e.:

   int a;
   volatile int b;

    Thread 1  |  Thread 2
 -------------|--------------
     b = 1    |   r1 = b
     a = 1    |   r2 = a

It does not really matter if we move (a=1) up the volatile store, since
adding this op into the induced happens-before does not yield new
behaviors. We were reading $a through the race anyway, so we anyway were
allowed to see both {0, 1}. Now we constrain myself to see only {1}. No
new behaviors => we're fine.

The converse is "disallowed" (note the asymmetry in the table), but that
is only the conservative guidance. In fact, smart JMM-conforming
implementations *can* reorder normal load/stores with volatile
load/stores, if that does not violate the provisions of JMM. For example:

   int a;
   volatile int b;

    Thread 1  |  Thread 2
 -------------|--------------
     a = 1    |
     b = 1    |   r1 = b
              |    ...
              |  (a is not used)

Assume $b is only accessed by threads 1 and 2, while $a is only accessed
by thread 1.

Magic Global Analyzer can figure out that thread 2 will never ever
access $a through any hb chains containing (b=1)--sw-->(r1=b{1}), and
then it does not matter if we move/hide the (a=1) past (b=1),
effectively pushing it out from the induced happens-before order. (I'm
sure I'm missing some other transitive effects).

Conservative implementations do not have the luxury of global analysis,
so what happens in other threads is opaque to them. They have to assume
the effects of move like that are observable (= yield new behaviors =
violate JMM), and should in turn block that kind of reordering.

-Aleksey.

From nathan.reynolds at oracle.com  Fri Jan 10 13:30:46 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 10 Jan 2014 11:30:46 -0700
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D0363F.7030906@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
Message-ID: <52D03C56.5040209@oracle.com>

 > JSR 133 Cookbook explains the *conservative* implementation which 
still fits JMM rules.

So, really I should fully understand the JMM and code to that because 
then I would be able to write more aggressive code.

Assuming the first piece of code...  So, storing into b and then loading 
from b creates a happens-before relationship.  Why are operations on 'a' 
constrained by that relationship?  Is it because of program order?

-Nathan

On 1/10/2014 11:04 AM, Aleksey Shipilev wrote:
> On 01/10/2014 09:29 PM, Nathan Reynolds wrote:
>> When writing concurrent code, I use the first table in
>> http://g.oswego.edu/dl/jmm/cookbook.html to reason about how the various
>> lines of code can be reordered and if that is going to cause a problem.
>>
>> Then, I read through the Java Memory Model (JMM) in
>> http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.
>> I suppose I understand the happens-before and everything being said
>> there.  But, I don't get how one goes from the JMM to the cookbook's
>> table.  In particular, why according to the JMM can't normal
>> loads/stores be reordered with respect to volatile loads/stores.  Is
>> there some line or paragraph in the JMM that I am not understanding?
> I recently gave a JMM talk (in Russian, sorry), and was having the same
> question. Below is what I had finally arrived to. I'm sure you can
> explain that more rigorously.
>
> JSR 133 Cookbook explains the *conservative* implementation which still
> fits JMM rules. Now, there is a confusion between JMM and JSR 133
> Cookbook. Cookbook is *NOT* the Java Memory Model, Cookbook is a
> conservative interpretation for runtime implementors.
>
> The table you are referring to provides the guidance for conservative
> implementations: notably, allowing moving in the normal load/stores
> before the volatile store (release), and moving in the normal
> load/stores after the volatile load (acquire). That is infamous "roach
> motel".
>
> The beauty of "roach motel" is that it allows local decisions, and you
> can arrive to that model by simply observing that moving the operations
> into the hb order does not violate correctness (since operations you are
> about to move are racy anyway). I.e.:
>
>     int a;
>     volatile int b;
>
>      Thread 1  |  Thread 2
>   -------------|--------------
>       b = 1    |   r1 = b
>       a = 1    |   r2 = a
>
> It does not really matter if we move (a=1) up the volatile store, since
> adding this op into the induced happens-before does not yield new
> behaviors. We were reading $a through the race anyway, so we anyway were
> allowed to see both {0, 1}. Now we constrain myself to see only {1}. No
> new behaviors => we're fine.
>
> The converse is "disallowed" (note the asymmetry in the table), but that
> is only the conservative guidance. In fact, smart JMM-conforming
> implementations *can* reorder normal load/stores with volatile
> load/stores, if that does not violate the provisions of JMM. For example:
>
>     int a;
>     volatile int b;
>
>      Thread 1  |  Thread 2
>   -------------|--------------
>       a = 1    |
>       b = 1    |   r1 = b
>                |    ...
>                |  (a is not used)
>
> Assume $b is only accessed by threads 1 and 2, while $a is only accessed
> by thread 1.
>
> Magic Global Analyzer can figure out that thread 2 will never ever
> access $a through any hb chains containing (b=1)--sw-->(r1=b{1}), and
> then it does not matter if we move/hide the (a=1) past (b=1),
> effectively pushing it out from the induced happens-before order. (I'm
> sure I'm missing some other transitive effects).
>
> Conservative implementations do not have the luxury of global analysis,
> so what happens in other threads is opaque to them. They have to assume
> the effects of move like that are observable (= yield new behaviors =
> violate JMM), and should in turn block that kind of reordering.
>
> -Aleksey.
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/04e6d9b6/attachment.html>

From forax at univ-mlv.fr  Fri Jan 10 13:32:22 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Fri, 10 Jan 2014 19:32:22 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52CDB41C.70601@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>
Message-ID: <52D03CB6.8000307@univ-mlv.fr>

On 01/08/2014 09:25 PM, Doug Lea wrote:

[...]
>
> 3. Language support
>
> A third JEP will cover a way to get rid of the need for Unsafe for
> CASing fields, ordered/fenced access, etc. The time seems right to get
> just enough syntax support to solve problems that we've never
> otherwise found a good solution for over the years. At the moment, I
> think the most likely possibility will allow access to operations
> using ".volatile". for example:
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>
> There's more from there. A proposal (by others) for some sort of Value
> Types seems to be a sure thing.  This will be a big help in dealing
> with locality in parallel code (among other things).

I don't like the idea to have a specific DSL for concurrency,
moreover I don't think you need one :)

what about ?
class Usage {
   volatile int count;

   int incrementCount() {
       return PublicUnsafe.incrementAndGet(Usage::count);
   }
}

obviously you need some magic, 'field reference' for Usage::count
and a way to tell the compiler to transform incrementAndGet to
an invokedynamic that will be set to used method of
sun.misc.Unsafe.

Transforming incrementAndGet to an invokedynamic is the same
transformation as the one done when creating a lambda,
we need a way to be able to specify that transformation as
an API developer. I want to submit a JEP about that
(we also need this transformation to modernize Java EE
by removing the use of proxies wich are the primary reason to
have gigantic stacktraces).

The idea is that if you use invokedynamic, you know the caller
context, so you don't need to implement a generic path
but you can specialize the code to the caller context,
by example you can get ride of the cast when you do a CAS.

class Usage {
   volatile int count;

   int incrementCount() {
       for(;;) {
         int count = this.count;
         int newCount = count + 1;
         if (PublicUnsafe.compareAndSet(Usage::count, count, newCount)) {
           return newCount;
         }
       }
   }
}

here compareAndSet will be typed by the compiler compareAndSet(FieldRef, 
int, int),
even if you can declare compareAndSet like this:

package java.lang.invoke;
public class PublicUnsafe {
   interceptable  // new keyword saying that an invokedynamic should be 
generated
   public <T> boolean compareAndSet(FieldRef, T expected, T newValue) {
     ...
   }

   // + the bootstrap method that will be called to resolve invokedynamic.
}

This is basically the same transformation as the one done when one call
MethodHandle.invokeExact or MH.invoke, the compiler doesn't perform
any boxing, generate an invokedynamic with the signature of the value at 
callsite.
When the VM calls the bootstrap method it will send the signature adapted to
the caller types, so the linker code can call the right Unsafe.get*, 
Unsafe.put*
and combine them. The linker will also check that the field reference is 
constant,
obviously the JIT will remove that check if the field reference is 
really constant
so the generated code will be exactly the same as the one write when using
Unsafe directly.

>
> And soon enough (but not all that soon), new java.util.concurrent
> stuff. No firm plans yet, but providing more consistent support
> for Async programming is near the top of the list.
>
>
> -Doug

R?mi


From oleksandr.otenko at oracle.com  Fri Jan 10 13:54:08 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 10 Jan 2014 18:54:08 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D03C56.5040209@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com>
Message-ID: <52D041D0.2080004@oracle.com>

Yes, because of program order.

17.4.3. Programs and Program Order says that intra-thread actions 
(everything non-volatile) are in program order. This means the thread is 
free to reorder the a=1 any way it likes, as long as the thread that 
does it will observe a=1 in actions that use value a after the line a=1.

I suppose, the reasoning then goes like this:

Thread 1:
a=1
b=1

Thread 2:
rb=b
ra=a

Since ra=a appears in program order after rb=b, then it should observe 
a=1, if it observes b=1, because a=1 appears in program order before b=1.

It is more interesting which bit of JMM says that /even intra-thread/ 
actions should respect the ordering reasoning above, because (I think) 
at some point it mentions "we only concern ourselves with hb of volatile 
accesses".

Which bit of JMM says that program order of intra-thread actions with 
respect to inter-thrtead actions should be observable by other threads 
that observe inter-thread actions of that thread?



Alex


On 10/01/2014 18:30, Nathan Reynolds wrote:
> > JSR 133 Cookbook explains the *conservative* implementation which 
> still fits JMM rules.
>
> So, really I should fully understand the JMM and code to that because 
> then I would be able to write more aggressive code.
>
> Assuming the first piece of code...  So, storing into b and then 
> loading from b creates a happens-before relationship.  Why are 
> operations on 'a' constrained by that relationship?  Is it because of 
> program order?
> -Nathan
> On 1/10/2014 11:04 AM, Aleksey Shipilev wrote:
>> On 01/10/2014 09:29 PM, Nathan Reynolds wrote:
>>> When writing concurrent code, I use the first table in
>>> http://g.oswego.edu/dl/jmm/cookbook.html  to reason about how the various
>>> lines of code can be reordered and if that is going to cause a problem.
>>>
>>> Then, I read through the Java Memory Model (JMM) in
>>> http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.
>>> I suppose I understand the happens-before and everything being said
>>> there.  But, I don't get how one goes from the JMM to the cookbook's
>>> table.  In particular, why according to the JMM can't normal
>>> loads/stores be reordered with respect to volatile loads/stores.  Is
>>> there some line or paragraph in the JMM that I am not understanding?
>> I recently gave a JMM talk (in Russian, sorry), and was having the same
>> question. Below is what I had finally arrived to. I'm sure you can
>> explain that more rigorously.
>>
>> JSR 133 Cookbook explains the *conservative* implementation which still
>> fits JMM rules. Now, there is a confusion between JMM and JSR 133
>> Cookbook. Cookbook is *NOT* the Java Memory Model, Cookbook is a
>> conservative interpretation for runtime implementors.
>>
>> The table you are referring to provides the guidance for conservative
>> implementations: notably, allowing moving in the normal load/stores
>> before the volatile store (release), and moving in the normal
>> load/stores after the volatile load (acquire). That is infamous "roach
>> motel".
>>
>> The beauty of "roach motel" is that it allows local decisions, and you
>> can arrive to that model by simply observing that moving the operations
>> into the hb order does not violate correctness (since operations you are
>> about to move are racy anyway). I.e.:
>>
>>     int a;
>>     volatile int b;
>>
>>      Thread 1  |  Thread 2
>>   -------------|--------------
>>       b = 1    |   r1 = b
>>       a = 1    |   r2 = a
>>
>> It does not really matter if we move (a=1) up the volatile store, since
>> adding this op into the induced happens-before does not yield new
>> behaviors. We were reading $a through the race anyway, so we anyway were
>> allowed to see both {0, 1}. Now we constrain myself to see only {1}. No
>> new behaviors => we're fine.
>>
>> The converse is "disallowed" (note the asymmetry in the table), but that
>> is only the conservative guidance. In fact, smart JMM-conforming
>> implementations *can* reorder normal load/stores with volatile
>> load/stores, if that does not violate the provisions of JMM. For example:
>>
>>     int a;
>>     volatile int b;
>>
>>      Thread 1  |  Thread 2
>>   -------------|--------------
>>       a = 1    |
>>       b = 1    |   r1 = b
>>                |    ...
>>                |  (a is not used)
>>
>> Assume $b is only accessed by threads 1 and 2, while $a is only accessed
>> by thread 1.
>>
>> Magic Global Analyzer can figure out that thread 2 will never ever
>> access $a through any hb chains containing (b=1)--sw-->(r1=b{1}), and
>> then it does not matter if we move/hide the (a=1) past (b=1),
>> effectively pushing it out from the induced happens-before order. (I'm
>> sure I'm missing some other transitive effects).
>>
>> Conservative implementations do not have the luxury of global analysis,
>> so what happens in other threads is opaque to them. They have to assume
>> the effects of move like that are observable (= yield new behaviors =
>> violate JMM), and should in turn block that kind of reordering.
>>
>> -Aleksey.
>>
>>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/e990ef06/attachment.html>

From aleksey.shipilev at oracle.com  Fri Jan 10 13:55:24 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 10 Jan 2014 22:55:24 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D03C56.5040209@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com>
Message-ID: <52D0421C.8010506@oracle.com>

On 01/10/2014 10:30 PM, Nathan Reynolds wrote:
>> JSR 133 Cookbook explains the *conservative* implementation which
> still fits JMM rules.
> 
> So, really I should fully understand the JMM and code to that because
> then I would be able to write more aggressive code.

I'm not sure it will help with more aggressive code, since the limiting
factor would be quality-of-implementation (QoI) issues. Although most
people (Doug included) sometimes use the insights from the
implementation here and there. It is however important to draw the line
between what is mandated by spec, and what is the QoI issue when you
reason about the correctness and performance.

> Assuming the first piece of code...  So, storing into b and then loading
> from b creates a happens-before relationship.  Why are operations on 'a'
> constrained by that relationship?  Is it because of program order?

As per JLS 17.4.4, (b=1) and (r1=b)=1 are ordered by synchronizes-with
(sw) order. Synchronizes-with order transitively closes with program
order to induce happens-before. You can think about synchronizes-with
order as the pitch-point edges which connect the program orders in
different threads.

In more detail:

    int a;
    volatile int b;

     Thread 1  |  Thread 2
  -------------|--------------
      b = 1    |   r1 = b
      a = 1    |   r2 = a


The orders are:
  ... ---po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...
                \--po--> a=1

...which transitively closes into:
  ... ---hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...

There is no hb between (a=1) and (r2=a), hence r2 could be anything
written anywhere (in our example, the set of written values is {0, 1})
even if we observe (r1=1).

"Roach motel" (and JMM) allows this reordering:

     Thread 1  |  Thread 2
  -------------|--------------
      a = 1    |
      b = 1    |   r1 = b
               |   r2 = a

...which yields these orders:
  ... --po--> a=1 --po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...

...which close into:
  ... --hb--> a=1 --hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...

Under hb properties, if we observed (r1=b)=1, then (r2=a) can now only
observe (r2=a)=1. This *shrinks* the observable values for $a to just
{1}, but this is legal, since we only need to keep out new behaviors,
and we can remove the otherwise legal behaviors during the transformations.

-Aleksey.

From aleksey.shipilev at oracle.com  Fri Jan 10 14:06:06 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 10 Jan 2014 23:06:06 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D041D0.2080004@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com> <52D041D0.2080004@oracle.com>
Message-ID: <52D0449E.1020609@oracle.com>

On 01/10/2014 10:54 PM, Oleksandr Otenko wrote:
> Which bit of JMM says that program order of intra-thread actions with
> respect to inter-thrtead actions should be observable by other threads
> that observe inter-thread actions of that thread?

Spec says that the read to variable X can observe either of two things:
 a) the *last* write to X in happens-before order
 b) *any* write to X not in the happens-before order (race)

Since hb includes po, we are conservatively required to observe
everything before the "release" write in the program order of other
thread, in the thread which "acquired" the value observed through
synchronizes-with.

If there are no reads in acquiring thread which can observe the writes
in the releasing thread, we are actually free to mess with the program
order of releasing thread as much as we want. That's the point of my
original note: it is possible, but requires global analysis to prove the
correctness.

-Aleksey.


From oleksandr.otenko at oracle.com  Fri Jan 10 14:08:05 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 10 Jan 2014 19:08:05 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D041D0.2080004@oracle.com>
References: <52D02DEC.1030507@oracle.com>
	<52D0363F.7030906@oracle.com>	<52D03C56.5040209@oracle.com>
	<52D041D0.2080004@oracle.com>
Message-ID: <52D04515.8090405@oracle.com>

ugh, it is 17.4.5, where on the first line hb is defined as program 
order of all actions in the same thread. So inside the same thread two 
actions have hb order equal to program order. But across threads the two 
program orders become linked by observing the order of inter-thread actions.

Alex

On 10/01/2014 18:54, Oleksandr Otenko wrote:
> Yes, because of program order.
>
> 17.4.3. Programs and Program Order says that intra-thread actions 
> (everything non-volatile) are in program order. This means the thread 
> is free to reorder the a=1 any way it likes, as long as the thread 
> that does it will observe a=1 in actions that use value a after the 
> line a=1.
>
> I suppose, the reasoning then goes like this:
>
> Thread 1:
> a=1
> b=1
>
> Thread 2:
> rb=b
> ra=a
>
> Since ra=a appears in program order after rb=b, then it should observe 
> a=1, if it observes b=1, because a=1 appears in program order before b=1.
>
> It is more interesting which bit of JMM says that /even intra-thread/ 
> actions should respect the ordering reasoning above, because (I think) 
> at some point it mentions "we only concern ourselves with hb of 
> volatile accesses".
>
> Which bit of JMM says that program order of intra-thread actions with 
> respect to inter-thrtead actions should be observable by other threads 
> that observe inter-thread actions of that thread?
>
>
>
> Alex
>
>
> On 10/01/2014 18:30, Nathan Reynolds wrote:
>> > JSR 133 Cookbook explains the *conservative* implementation which 
>> still fits JMM rules.
>>
>> So, really I should fully understand the JMM and code to that because 
>> then I would be able to write more aggressive code.
>>
>> Assuming the first piece of code...  So, storing into b and then 
>> loading from b creates a happens-before relationship. Why are 
>> operations on 'a' constrained by that relationship? Is it because of 
>> program order?
>> -Nathan
>> On 1/10/2014 11:04 AM, Aleksey Shipilev wrote:
>>> On 01/10/2014 09:29 PM, Nathan Reynolds wrote:
>>>> When writing concurrent code, I use the first table in
>>>> http://g.oswego.edu/dl/jmm/cookbook.html  to reason about how the various
>>>> lines of code can be reordered and if that is going to cause a problem.
>>>>
>>>> Then, I read through the Java Memory Model (JMM) in
>>>> http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.
>>>> I suppose I understand the happens-before and everything being said
>>>> there.  But, I don't get how one goes from the JMM to the cookbook's
>>>> table.  In particular, why according to the JMM can't normal
>>>> loads/stores be reordered with respect to volatile loads/stores.  Is
>>>> there some line or paragraph in the JMM that I am not understanding?
>>> I recently gave a JMM talk (in Russian, sorry), and was having the same
>>> question. Below is what I had finally arrived to. I'm sure you can
>>> explain that more rigorously.
>>>
>>> JSR 133 Cookbook explains the *conservative* implementation which still
>>> fits JMM rules. Now, there is a confusion between JMM and JSR 133
>>> Cookbook. Cookbook is *NOT* the Java Memory Model, Cookbook is a
>>> conservative interpretation for runtime implementors.
>>>
>>> The table you are referring to provides the guidance for conservative
>>> implementations: notably, allowing moving in the normal load/stores
>>> before the volatile store (release), and moving in the normal
>>> load/stores after the volatile load (acquire). That is infamous "roach
>>> motel".
>>>
>>> The beauty of "roach motel" is that it allows local decisions, and you
>>> can arrive to that model by simply observing that moving the operations
>>> into the hb order does not violate correctness (since operations you are
>>> about to move are racy anyway). I.e.:
>>>
>>>     int a;
>>>     volatile int b;
>>>
>>>      Thread 1  |  Thread 2
>>>   -------------|--------------
>>>       b = 1    |   r1 = b
>>>       a = 1    |   r2 = a
>>>
>>> It does not really matter if we move (a=1) up the volatile store, since
>>> adding this op into the induced happens-before does not yield new
>>> behaviors. We were reading $a through the race anyway, so we anyway were
>>> allowed to see both {0, 1}. Now we constrain myself to see only {1}. No
>>> new behaviors => we're fine.
>>>
>>> The converse is "disallowed" (note the asymmetry in the table), but that
>>> is only the conservative guidance. In fact, smart JMM-conforming
>>> implementations *can* reorder normal load/stores with volatile
>>> load/stores, if that does not violate the provisions of JMM. For example:
>>>
>>>     int a;
>>>     volatile int b;
>>>
>>>      Thread 1  |  Thread 2
>>>   -------------|--------------
>>>       a = 1    |
>>>       b = 1    |   r1 = b
>>>                |    ...
>>>                |  (a is not used)
>>>
>>> Assume $b is only accessed by threads 1 and 2, while $a is only accessed
>>> by thread 1.
>>>
>>> Magic Global Analyzer can figure out that thread 2 will never ever
>>> access $a through any hb chains containing (b=1)--sw-->(r1=b{1}), and
>>> then it does not matter if we move/hide the (a=1) past (b=1),
>>> effectively pushing it out from the induced happens-before order. (I'm
>>> sure I'm missing some other transitive effects).
>>>
>>> Conservative implementations do not have the luxury of global analysis,
>>> so what happens in other threads is opaque to them. They have to assume
>>> the effects of move like that are observable (= yield new behaviors =
>>> violate JMM), and should in turn block that kind of reordering.
>>>
>>> -Aleksey.
>>>
>>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/aecad491/attachment-0001.html>

From oleksandr.otenko at oracle.com  Fri Jan 10 14:11:18 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 10 Jan 2014 19:11:18 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D0449E.1020609@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com> <52D041D0.2080004@oracle.com>
	<52D0449E.1020609@oracle.com>
Message-ID: <52D045D6.4000106@oracle.com>

Yes, thanks. This was a clear consequence from the cookbook. I was 
wondering which JMM part says this. Found it now.

Alex

On 10/01/2014 19:06, Aleksey Shipilev wrote:
> On 01/10/2014 10:54 PM, Oleksandr Otenko wrote:
>> Which bit of JMM says that program order of intra-thread actions with
>> respect to inter-thrtead actions should be observable by other threads
>> that observe inter-thread actions of that thread?
> Spec says that the read to variable X can observe either of two things:
>   a) the *last* write to X in happens-before order
>   b) *any* write to X not in the happens-before order (race)
>
> Since hb includes po, we are conservatively required to observe
> everything before the "release" write in the program order of other
> thread, in the thread which "acquired" the value observed through
> synchronizes-with.
>
> If there are no reads in acquiring thread which can observe the writes
> in the releasing thread, we are actually free to mess with the program
> order of releasing thread as much as we want. That's the point of my
> original note: it is possible, but requires global analysis to prove the
> correctness.
>
> -Aleksey.
>


From nathan.reynolds at oracle.com  Fri Jan 10 16:42:16 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 10 Jan 2014 14:42:16 -0700
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D0421C.8010506@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com> <52D0421C.8010506@oracle.com>
Message-ID: <52D06938.9000200@oracle.com>

Okay.  I think I understand.  Now a test for me.  :)

Let's change the situation a bit.  Let's introduce a branch. Initially, 
both start as 0.

int c;

while (true)    |  b = 1;
{                    |
    if (a == 0)   |
       a = b;      |
                      |
    r1 = a;        |
}                    |

If I understand correctly, it seems to me that as long as 'a' == 0, then 
'a' has to be reloaded every iteration.  This is because loading 'b' is 
part of a happens-before operation and program order ties 'a' into that 
happens-before.  Then, once 'a' is non-zero, then the loop could be 
optimized into "while (true) {}".

Please grade my answer.  :)

-Nathan

On 1/10/2014 11:55 AM, Aleksey Shipilev wrote:
> On 01/10/2014 10:30 PM, Nathan Reynolds wrote:
>>> JSR 133 Cookbook explains the *conservative* implementation which
>> still fits JMM rules.
>>
>> So, really I should fully understand the JMM and code to that because
>> then I would be able to write more aggressive code.
> I'm not sure it will help with more aggressive code, since the limiting
> factor would be quality-of-implementation (QoI) issues. Although most
> people (Doug included) sometimes use the insights from the
> implementation here and there. It is however important to draw the line
> between what is mandated by spec, and what is the QoI issue when you
> reason about the correctness and performance.
>
>> Assuming the first piece of code...  So, storing into b and then loading
>> from b creates a happens-before relationship.  Why are operations on 'a'
>> constrained by that relationship?  Is it because of program order?
> As per JLS 17.4.4, (b=1) and (r1=b)=1 are ordered by synchronizes-with
> (sw) order. Synchronizes-with order transitively closes with program
> order to induce happens-before. You can think about synchronizes-with
> order as the pitch-point edges which connect the program orders in
> different threads.
>
> In more detail:
>
>      int a;
>      volatile int b;
>
>       Thread 1  |  Thread 2
>    -------------|--------------
>        b = 1    |   r1 = b
>        a = 1    |   r2 = a
>
>
> The orders are:
>    ... ---po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...
>                  \--po--> a=1
>
> ...which transitively closes into:
>    ... ---hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...
>
> There is no hb between (a=1) and (r2=a), hence r2 could be anything
> written anywhere (in our example, the set of written values is {0, 1})
> even if we observe (r1=1).
>
> "Roach motel" (and JMM) allows this reordering:
>
>       Thread 1  |  Thread 2
>    -------------|--------------
>        a = 1    |
>        b = 1    |   r1 = b
>                 |   r2 = a
>
> ...which yields these orders:
>    ... --po--> a=1 --po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...
>
> ...which close into:
>    ... --hb--> a=1 --hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...
>
> Under hb properties, if we observed (r1=b)=1, then (r2=a) can now only
> observe (r2=a)=1. This *shrinks* the observable values for $a to just
> {1}, but this is legal, since we only need to keep out new behaviors,
> and we can remove the otherwise legal behaviors during the transformations.
>
> -Aleksey.
>
>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/21bd001a/attachment.html>

From oleksandr.otenko at oracle.com  Fri Jan 10 17:45:57 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 10 Jan 2014 22:45:57 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D06938.9000200@oracle.com>
References: <52D02DEC.1030507@oracle.com>
	<52D0363F.7030906@oracle.com>	<52D03C56.5040209@oracle.com>
	<52D0421C.8010506@oracle.com> <52D06938.9000200@oracle.com>
Message-ID: <52D07825.8090704@oracle.com>

Because the loop is infinite, and contains no observable side-effects 
(there is nothing the other threads are bound to observe by JMM ever), 
it is optimizable into while(true); even without reading a or b.


Alex

On 10/01/2014 21:42, Nathan Reynolds wrote:
> Okay.  I think I understand.  Now a test for me.  :)
>
> Let's change the situation a bit.  Let's introduce a branch. 
> Initially, both start as 0.
>
> int c;
>
> while (true)    |  b = 1;
> {                    |
>    if (a == 0)   |
>       a = b;      |
>                      |
>    r1 = a;        |
> }                    |
>
> If I understand correctly, it seems to me that as long as 'a' == 0, 
> then 'a' has to be reloaded every iteration.  This is because loading 
> 'b' is part of a happens-before operation and program order ties 'a' 
> into that happens-before.  Then, once 'a' is non-zero, then the loop 
> could be optimized into "while (true) {}".
>
> Please grade my answer.  :)
> -Nathan
> On 1/10/2014 11:55 AM, Aleksey Shipilev wrote:
>> On 01/10/2014 10:30 PM, Nathan Reynolds wrote:
>>>> JSR 133 Cookbook explains the *conservative* implementation which
>>> still fits JMM rules.
>>>
>>> So, really I should fully understand the JMM and code to that because
>>> then I would be able to write more aggressive code.
>> I'm not sure it will help with more aggressive code, since the limiting
>> factor would be quality-of-implementation (QoI) issues. Although most
>> people (Doug included) sometimes use the insights from the
>> implementation here and there. It is however important to draw the line
>> between what is mandated by spec, and what is the QoI issue when you
>> reason about the correctness and performance.
>>
>>> Assuming the first piece of code...  So, storing into b and then loading
>>> from b creates a happens-before relationship.  Why are operations on 'a'
>>> constrained by that relationship?  Is it because of program order?
>> As per JLS 17.4.4, (b=1) and (r1=b)=1 are ordered by synchronizes-with
>> (sw) order. Synchronizes-with order transitively closes with program
>> order to induce happens-before. You can think about synchronizes-with
>> order as the pitch-point edges which connect the program orders in
>> different threads.
>>
>> In more detail:
>>
>>      int a;
>>      volatile int b;
>>
>>       Thread 1  |  Thread 2
>>    -------------|--------------
>>        b = 1    |   r1 = b
>>        a = 1    |   r2 = a
>>
>>
>> The orders are:
>>    ... ---po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...
>>                  \--po--> a=1
>>
>> ...which transitively closes into:
>>    ... ---hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...
>>
>> There is no hb between (a=1) and (r2=a), hence r2 could be anything
>> written anywhere (in our example, the set of written values is {0, 1})
>> even if we observe (r1=1).
>>
>> "Roach motel" (and JMM) allows this reordering:
>>
>>       Thread 1  |  Thread 2
>>    -------------|--------------
>>        a = 1    |
>>        b = 1    |   r1 = b
>>                 |   r2 = a
>>
>> ...which yields these orders:
>>    ... --po--> a=1 --po--> b=1 --sw--> (r1=b)=1 --po--> r2=a --po--> ...
>>
>> ...which close into:
>>    ... --hb--> a=1 --hb--> b=1 --hb--> (r1=b)=1 --hb--> r2=a --hb--> ...
>>
>> Under hb properties, if we observed (r1=b)=1, then (r2=a) can now only
>> observe (r2=a)=1. This *shrinks* the observable values for $a to just
>> {1}, but this is legal, since we only need to keep out new behaviors,
>> and we can remove the otherwise legal behaviors during the transformations.
>>
>> -Aleksey.
>>
>>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140110/ccaa4746/attachment.html>

From radhakrishnan.mohan at gmail.com  Sat Jan 11 00:22:42 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Sat, 11 Jan 2014 10:52:42 +0530
Subject: [concurrency-interest] JEP 171: Fence Intrinsics(Basic question)
Message-ID: <CAOoXFP8f6O8ZemFkMXhciKBd+8=jGUkv9E_UG5ZXLUDy67_2Qw@mail.gmail.com>

Hi,

"According to the current JMM, some language-level uses of volatile may be
reordered with some uses of non-volatile variables. But this would not be
allowed here. (It is not allowed in the current intrinsics either, but this
is an undocumented difference between intrinsics-based vs language-based
volatile access.)

Is there a simpler explanation for this for developers ? Can I use a test
with b120 to try this like it is mentioned in
http://openjdk.java.net/jeps/171?

Thanks,
Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140111/dcd07fa8/attachment-0001.html>

From davidcholmes at aapt.net.au  Sat Jan 11 05:57:50 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 11 Jan 2014 20:57:50 +1000
Subject: [concurrency-interest] JEP 171: Fence Intrinsics(Basic question)
In-Reply-To: <CAOoXFP8f6O8ZemFkMXhciKBd+8=jGUkv9E_UG5ZXLUDy67_2Qw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEJNKDAA.davidcholmes@aapt.net.au>

This JEP did not proceed in JDK 8 so there is nothing for you to test.

These fence methods, like the Unsafe related volatile methods have stronger
reordering constraints that exists for language-level volatile accesses with
respect to non-volatile accesses.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mohan
Radhakrishnan
  Sent: Saturday, 11 January 2014 3:23 PM
  To: Concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] JEP 171: Fence Intrinsics(Basic question)


  Hi,


  "According to the current JMM, some language-level uses of volatile may be
reordered with some uses of non-volatile variables. But this would not be
allowed here. (It is not allowed in the current intrinsics either, but this
is an undocumented difference between intrinsics-based vs language-based
volatile access.)


  Is there a simpler explanation for this for developers ? Can I use a test
with b120 to try this like it is mentioned in
http://openjdk.java.net/jeps/171?


  Thanks,
  Mohan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140111/77e4c79a/attachment.html>

From dl at cs.oswego.edu  Sat Jan 11 07:16:51 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 07:16:51 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D03CB6.8000307@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
Message-ID: <52D13633.5000706@cs.oswego.edu>

On 01/10/2014 01:32 PM, Remi Forax wrote:
> I don't like the idea to have a specific DSL for concurrency,
> moreover I don't think you need one :)

It's not a DSL,  ".volatile" is a form of cast that allows
a field to be used as if it were a stand-alone AtomicX.
In terms of JLS specs, it can be viewed as actually generating
one. Here's a draft of current scheme:

...

The target solution requires a syntax enhancement, a few
library enhancements, and compiler support.

We model the extended operations on volatile integers via an interface
VolatileInt, that also captures the functionality of AtomicInteger
(which will also be updated to reflect Java Memory Model revisions as
part of this JEP). A tentative version is below. Similar interfaces
are needed for other primitive and reference types.

We then enable access to corresponding methods for volatile fields
using the ".volatile" prefix. For example:

     class Usage {
         volatile int count;
         int incrementCount() {
             return count.volatile.incrementAndGet();
         }
     }

This syntax is required to avoid ambiguities with existing usages,
especially for volatile references for which invocations of methods on
the reference versus the referent would be indistinguishable.  The
".volatile" syntax is slightly unusual, but we are confident that it
is syntactically unambiguous and semantically specifiable in a JLS
update. Note in particular that just "count.volatile" without any
method invocation would not be a legal expression. We also expect to
develop a means of supporting volatile operations on array elements in
addition to fields.

The main task is to translate these calls into corresponding JVM
intrinsics. The most likely option is for the source compiler to use
method handles. This and other techniques are known to suffice, but
are subject to further exploration.

Here is a tentative VolatileInt interface.  Those for other types are
similar.  The final released versions will surely differ in small
ways.

     interface VolatileInt {
         int get();
         int getRelaxed();
         int getAcquire();
         int getSequential();

         void set(int x);
         void setRelaxed(int x);
         void setRelease(int x);
         void setSequential(int x);

         int getAndSet(int x);
         boolean compareAndSet(int e, int x);
         boolean compareAndSetAcquire(int e, int x);
         boolean compareAndSetRelease(int e, int x);
         boolean weakCompareAndSet(int e, int x);
         boolean weakCompareAndSetAcquire(int e, int x);
         boolean weakCompareAndSetRelease(int e, int x);

         int getAndAdd(int x);
         int addAndGet(int x);
         int getAndIncrement();
         int incrementAndGet();
         int getAndDecrement();
         int decrementAndGet();
     }




From dl at cs.oswego.edu  Sat Jan 11 07:32:43 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 07:32:43 -0500
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 Normal Loads and Stores
In-Reply-To: <52D03C56.5040209@oracle.com>
References: <52D02DEC.1030507@oracle.com> <52D0363F.7030906@oracle.com>
	<52D03C56.5040209@oracle.com>
Message-ID: <52D139EB.7050300@cs.oswego.edu>

On 01/10/2014 01:30 PM, Nathan Reynolds wrote:
>  > JSR 133 Cookbook explains the *conservative* implementation which still fits
> JMM rules.
>
> So, really I should fully understand the JMM and code to that because then I
> would be able to write more aggressive code.

This is unlikely to be true:

* The current JMM is very complex, in part to deal with oddities like
causal loops. (We hope to significantly simplify in JMM9.) The chance
that you get a proof right without (non-existent) proof tools is low.
Further, the formal model contains some problems that make the wrong
legality claim about a few corner-cases, for example
disallowing optimizations known to be sound and known to be performed.

* JVMs also for the most part use the conservative approximations,
so even if some further relaxation were legal, it is unlikely to matter.

-Doug



From dl at cs.oswego.edu  Sat Jan 11 07:53:13 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 07:53:13 -0500
Subject: [concurrency-interest] JEP 171: Fence Intrinsics(Basic question)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEJNKDAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEJNKDAA.davidcholmes@aapt.net.au>
Message-ID: <52D13EB9.3@cs.oswego.edu>

On 01/11/2014 05:57 AM, David Holmes wrote:
> This JEP did not proceed in JDK 8 so there is nothing for you to test.

To clarify, JEP171 did result in JVM-level support, but not user-level.
The intrinsics solve some pointwise internal implementation problems
in JDK8 while also setting the stage for the new JDK9 efforts I've mentioned.

-Doug


> These fence methods, like the Unsafe related volatile methods have stronger
> reordering constraints that exists for language-level volatile accesses with
> respect to non-volatile accesses.
> David Holmes
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Mohan
>     Radhakrishnan
>     *Sent:* Saturday, 11 January 2014 3:23 PM
>     *To:* Concurrency-interest at cs.oswego.edu
>     *Subject:* [concurrency-interest] JEP 171: Fence Intrinsics(Basic question)
>
>     Hi,
>
>     "According to the current JMM, some language-level uses of |volatile| may be
>     reordered with some uses of non-volatile variables. But this would not be
>     allowed here. (It is not allowed in the current intrinsics either, but this
>     is an undocumented difference between intrinsics-based vs language-based
>     volatile access.)
>
>     Is there a simpler explanation for this for developers ? Can I use a test
>     with b120 to try this like it is mentioned in http://openjdk.java.net/jeps/171?
>
>     Thanks,
>     Mohan
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From viktor.klang at gmail.com  Sat Jan 11 08:09:48 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 11 Jan 2014 14:09:48 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D13633.5000706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
Message-ID: <CANPzfU8PkxbjpNFaiHMX6_V4tBj=h7k2bZ=uNv0o-iWnMxRJLg@mail.gmail.com>

Idea:

((AtomicInteger)count).incrementAndGet()

i.e. let the compiler allow casting volatile members to their Atomics, and
have it as an optimization to delegate to Unsafe?

Cheers,
?


On Sat, Jan 11, 2014 at 1:16 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 01/10/2014 01:32 PM, Remi Forax wrote:
>
>> I don't like the idea to have a specific DSL for concurrency,
>> moreover I don't think you need one :)
>>
>
> It's not a DSL,  ".volatile" is a form of cast that allows
> a field to be used as if it were a stand-alone AtomicX.
> In terms of JLS specs, it can be viewed as actually generating
> one. Here's a draft of current scheme:
>
> ...
>
> The target solution requires a syntax enhancement, a few
> library enhancements, and compiler support.
>
> We model the extended operations on volatile integers via an interface
> VolatileInt, that also captures the functionality of AtomicInteger
> (which will also be updated to reflect Java Memory Model revisions as
> part of this JEP). A tentative version is below. Similar interfaces
> are needed for other primitive and reference types.
>
> We then enable access to corresponding methods for volatile fields
> using the ".volatile" prefix. For example:
>
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>
> This syntax is required to avoid ambiguities with existing usages,
> especially for volatile references for which invocations of methods on
> the reference versus the referent would be indistinguishable.  The
> ".volatile" syntax is slightly unusual, but we are confident that it
> is syntactically unambiguous and semantically specifiable in a JLS
> update. Note in particular that just "count.volatile" without any
> method invocation would not be a legal expression. We also expect to
> develop a means of supporting volatile operations on array elements in
> addition to fields.
>
> The main task is to translate these calls into corresponding JVM
> intrinsics. The most likely option is for the source compiler to use
> method handles. This and other techniques are known to suffice, but
> are subject to further exploration.
>
> Here is a tentative VolatileInt interface.  Those for other types are
> similar.  The final released versions will surely differ in small
> ways.
>
>     interface VolatileInt {
>         int get();
>         int getRelaxed();
>         int getAcquire();
>         int getSequential();
>
>         void set(int x);
>         void setRelaxed(int x);
>         void setRelease(int x);
>         void setSequential(int x);
>
>         int getAndSet(int x);
>         boolean compareAndSet(int e, int x);
>         boolean compareAndSetAcquire(int e, int x);
>         boolean compareAndSetRelease(int e, int x);
>         boolean weakCompareAndSet(int e, int x);
>         boolean weakCompareAndSetAcquire(int e, int x);
>         boolean weakCompareAndSetRelease(int e, int x);
>
>         int getAndAdd(int x);
>         int addAndGet(int x);
>         int getAndIncrement();
>         int incrementAndGet();
>         int getAndDecrement();
>         int decrementAndGet();
>
>     }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?

*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140111/69abc24b/attachment-0001.html>

From dl at cs.oswego.edu  Sat Jan 11 08:37:36 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 08:37:36 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CANPzfU8PkxbjpNFaiHMX6_V4tBj=h7k2bZ=uNv0o-iWnMxRJLg@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<CANPzfU8PkxbjpNFaiHMX6_V4tBj=h7k2bZ=uNv0o-iWnMxRJLg@mail.gmail.com>
Message-ID: <52D14920.9050208@cs.oswego.edu>

On 01/11/2014 08:09 AM, ?iktor ?lang wrote:
> Idea:
>
> ((AtomicInteger)count).incrementAndGet()
>
> i.e. let the compiler allow casting volatile members to their Atomics, and have
> it as an optimization to delegate to Unsafe?
>

Right. I considered a few options along these lines. One problem
is that officially spec'ing them infiltrates other JLS specs.
This form of cast is different than others so complicates
the already complicated specs on casting. Plus it is uglier.

So far the reaction to .volatile has been about as good as
I can imagine any such change to be: It's just barely jarring
enough to tell you that something unusual is going on, but
the meaning is obvious enough that most people will not have
to look it up in the JLS.

-Doug




> Cheers,
> ?
>
>
> On Sat, Jan 11, 2014 at 1:16 PM, Doug Lea <dl at cs.oswego.edu
> <mailto:dl at cs.oswego.edu>> wrote:
>
>     On 01/10/2014 01:32 PM, Remi Forax wrote:
>
>         I don't like the idea to have a specific DSL for concurrency,
>         moreover I don't think you need one :)
>
>
>     It's not a DSL,  ".volatile" is a form of cast that allows
>     a field to be used as if it were a stand-alone AtomicX.
>     In terms of JLS specs, it can be viewed as actually generating
>     one. Here's a draft of current scheme:
>
>     ...
>
>     The target solution requires a syntax enhancement, a few
>     library enhancements, and compiler support.
>
>     We model the extended operations on volatile integers via an interface
>     VolatileInt, that also captures the functionality of AtomicInteger
>     (which will also be updated to reflect Java Memory Model revisions as
>     part of this JEP). A tentative version is below. Similar interfaces
>     are needed for other primitive and reference types.
>
>     We then enable access to corresponding methods for volatile fields
>     using the ".volatile" prefix. For example:
>
>
>          class Usage {
>              volatile int count;
>              int incrementCount() {
>                  return count.volatile.__incrementAndGet();
>              }
>          }
>
>     This syntax is required to avoid ambiguities with existing usages,
>     especially for volatile references for which invocations of methods on
>     the reference versus the referent would be indistinguishable.  The
>     ".volatile" syntax is slightly unusual, but we are confident that it
>     is syntactically unambiguous and semantically specifiable in a JLS
>     update. Note in particular that just "count.volatile" without any
>     method invocation would not be a legal expression. We also expect to
>     develop a means of supporting volatile operations on array elements in
>     addition to fields.
>
>     The main task is to translate these calls into corresponding JVM
>     intrinsics. The most likely option is for the source compiler to use
>     method handles. This and other techniques are known to suffice, but
>     are subject to further exploration.
>
>     Here is a tentative VolatileInt interface.  Those for other types are
>     similar.  The final released versions will surely differ in small
>     ways.
>
>          interface VolatileInt {
>              int get();
>              int getRelaxed();
>              int getAcquire();
>              int getSequential();
>
>              void set(int x);
>              void setRelaxed(int x);
>              void setRelease(int x);
>              void setSequential(int x);
>
>              int getAndSet(int x);
>              boolean compareAndSet(int e, int x);
>              boolean compareAndSetAcquire(int e, int x);
>              boolean compareAndSetRelease(int e, int x);
>              boolean weakCompareAndSet(int e, int x);
>              boolean weakCompareAndSetAcquire(int e, int x);
>              boolean weakCompareAndSetRelease(int e, int x);
>
>              int getAndAdd(int x);
>              int addAndGet(int x);
>              int getAndIncrement();
>              int incrementAndGet();
>              int getAndDecrement();
>              int decrementAndGet();
>
>          }
>
>
>
>     _________________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.__oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> --
> Cheers,
> ?
> *
> *
> *
> Viktor Klang*
> /Director of Engineering/
> Typesafe <http://www.typesafe.com/>
>
> Twitter: @viktorklang




From viktor.klang at gmail.com  Sat Jan 11 10:01:05 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sat, 11 Jan 2014 16:01:05 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D14920.9050208@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
	<CANPzfU8PkxbjpNFaiHMX6_V4tBj=h7k2bZ=uNv0o-iWnMxRJLg@mail.gmail.com>
	<52D14920.9050208@cs.oswego.edu>
Message-ID: <CANPzfU-CKzg4sansNRzG==3urccXan1fm_XOX+qDh2GkQ0Hu0w@mail.gmail.com>

On Sat, Jan 11, 2014 at 2:37 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 01/11/2014 08:09 AM, ?iktor ?lang wrote:
>
>> Idea:
>>
>> ((AtomicInteger)count).incrementAndGet()
>>
>> i.e. let the compiler allow casting volatile members to their Atomics,
>> and have
>> it as an optimization to delegate to Unsafe?
>>
>>
> Right. I considered a few options along these lines. One problem
> is that officially spec'ing them infiltrates other JLS specs.
> This form of cast is different than others so complicates
> the already complicated specs on casting. Plus it is uglier.
>
> So far the reaction to .volatile has been about as good as
> I can imagine any such change to be: It's just barely jarring
> enough to tell you that something unusual is going on, but
> the meaning is obvious enough that most people will not have
> to look it up in the JLS.
>

True, also using "volatile" which is already reserved means that it should
be safe.

Cheers,
?


>
> -Doug
>
>
>
>
>  Cheers,
>> ?
>>
>>
>> On Sat, Jan 11, 2014 at 1:16 PM, Doug Lea <dl at cs.oswego.edu
>> <mailto:dl at cs.oswego.edu>> wrote:
>>
>>     On 01/10/2014 01:32 PM, Remi Forax wrote:
>>
>>         I don't like the idea to have a specific DSL for concurrency,
>>         moreover I don't think you need one :)
>>
>>
>>     It's not a DSL,  ".volatile" is a form of cast that allows
>>     a field to be used as if it were a stand-alone AtomicX.
>>     In terms of JLS specs, it can be viewed as actually generating
>>     one. Here's a draft of current scheme:
>>
>>     ...
>>
>>     The target solution requires a syntax enhancement, a few
>>     library enhancements, and compiler support.
>>
>>     We model the extended operations on volatile integers via an interface
>>     VolatileInt, that also captures the functionality of AtomicInteger
>>     (which will also be updated to reflect Java Memory Model revisions as
>>     part of this JEP). A tentative version is below. Similar interfaces
>>     are needed for other primitive and reference types.
>>
>>     We then enable access to corresponding methods for volatile fields
>>     using the ".volatile" prefix. For example:
>>
>>
>>          class Usage {
>>              volatile int count;
>>              int incrementCount() {
>>                  return count.volatile.__incrementAndGet();
>>
>>              }
>>          }
>>
>>     This syntax is required to avoid ambiguities with existing usages,
>>     especially for volatile references for which invocations of methods on
>>     the reference versus the referent would be indistinguishable.  The
>>     ".volatile" syntax is slightly unusual, but we are confident that it
>>     is syntactically unambiguous and semantically specifiable in a JLS
>>     update. Note in particular that just "count.volatile" without any
>>     method invocation would not be a legal expression. We also expect to
>>     develop a means of supporting volatile operations on array elements in
>>     addition to fields.
>>
>>     The main task is to translate these calls into corresponding JVM
>>     intrinsics. The most likely option is for the source compiler to use
>>     method handles. This and other techniques are known to suffice, but
>>     are subject to further exploration.
>>
>>     Here is a tentative VolatileInt interface.  Those for other types are
>>     similar.  The final released versions will surely differ in small
>>     ways.
>>
>>          interface VolatileInt {
>>              int get();
>>              int getRelaxed();
>>              int getAcquire();
>>              int getSequential();
>>
>>              void set(int x);
>>              void setRelaxed(int x);
>>              void setRelease(int x);
>>              void setSequential(int x);
>>
>>              int getAndSet(int x);
>>              boolean compareAndSet(int e, int x);
>>              boolean compareAndSetAcquire(int e, int x);
>>              boolean compareAndSetRelease(int e, int x);
>>              boolean weakCompareAndSet(int e, int x);
>>              boolean weakCompareAndSetAcquire(int e, int x);
>>              boolean weakCompareAndSetRelease(int e, int x);
>>
>>              int getAndAdd(int x);
>>              int addAndGet(int x);
>>              int getAndIncrement();
>>              int incrementAndGet();
>>              int getAndDecrement();
>>              int decrementAndGet();
>>
>>          }
>>
>>
>>
>>     _________________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.__oswego.edu <mailto:Concurrency-interest@
>> cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>> *
>> *
>> *
>> Viktor Klang*
>> /Director of Engineering/
>> Typesafe <http://www.typesafe.com/>
>>
>> Twitter: @viktorklang
>>
>
>
>


-- 
Cheers,
?

*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140111/ddec670e/attachment.html>

From aaron.grunthal at infinite-source.de  Sat Jan 11 11:40:54 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Sat, 11 Jan 2014 17:40:54 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D13633.5000706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
Message-ID: <52D17416.30506@infinite-source.de>

On 11.01.2014 13:16, Doug Lea wrote:
> Note in particular that just "count.volatile" without any
> method invocation would not be a legal expression.

Which means it can't be passed around, which in turn means you have to 
write all the usual atomic algorithms for every call site and every 
field again and again.
Which is why Remi's proposed FieldRef would be more useful.

Those would also cover other use-cases. E.g. passing field-access to 
some utility class without having to implement some public interface 
with specific getters and setters.

- Aaron

From dl at cs.oswego.edu  Sat Jan 11 12:17:13 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 12:17:13 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D17416.30506@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>
	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<52D17416.30506@infinite-source.de>
Message-ID: <52D17C99.2040706@cs.oswego.edu>

On 01/11/2014 11:40 AM, Aaron Grunthal wrote:
> On 11.01.2014 13:16, Doug Lea wrote:
>> Note in particular that just "count.volatile" without any
>> method invocation would not be a legal expression.
>
> Which means it can't be passed around, which in turn means you have to write all
> the usual atomic algorithms for every call site and every field again and again.

JVMs do not support internal pointers. There are a lot of good reasons
they don't, and a lot of JVM internals would be impacted if they did.
And anything short of that is either special-casing (as here) or
reflection in disguise (with java.lang.reflect.Field etc), or, as
you pointed out in previous mail, using methods with lambda arguments.
Which I think you made a good argument for: Lambda-based works best
in cases where semantics matter but performance doesn't.
We'd like to get past the decade-long discussions that amount to
whining about this state of affairs and implement an effective
efficient solution.

-Doug



From zhong.j.yu at gmail.com  Sat Jan 11 15:43:05 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sat, 11 Jan 2014 14:43:05 -0600
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D17C99.2040706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
	<52D17416.30506@infinite-source.de>
	<52D17C99.2040706@cs.oswego.edu>
Message-ID: <CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>

What if the standalone `count.volatile` expression does evaluates to
an object, that can be passed around? In the case of
`count.volatile.incrementAndGet()`, the object is created and
immediately becomes garbage, so the runtime cost can be zero.

Another question, will `count.volatile::incrementAndGet()` be supported?

Zhong Yu



On Sat, Jan 11, 2014 at 11:17 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> On 01/11/2014 11:40 AM, Aaron Grunthal wrote:
>>
>> On 11.01.2014 13:16, Doug Lea wrote:
>>>
>>> Note in particular that just "count.volatile" without any
>>> method invocation would not be a legal expression.
>>
>>
>> Which means it can't be passed around, which in turn means you have to
>> write all
>> the usual atomic algorithms for every call site and every field again and
>> again.
>
>
> JVMs do not support internal pointers. There are a lot of good reasons
> they don't, and a lot of JVM internals would be impacted if they did.
> And anything short of that is either special-casing (as here) or
> reflection in disguise (with java.lang.reflect.Field etc), or, as
> you pointed out in previous mail, using methods with lambda arguments.
> Which I think you made a good argument for: Lambda-based works best
> in cases where semantics matter but performance doesn't.
> We'd like to get past the decade-long discussions that amount to
> whining about this state of affairs and implement an effective
> efficient solution.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From zhong.j.yu at gmail.com  Sat Jan 11 15:45:42 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sat, 11 Jan 2014 14:45:42 -0600
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
	<52D17416.30506@infinite-source.de>
	<52D17C99.2040706@cs.oswego.edu>
	<CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>
Message-ID: <CACuKZqE-W+=XKGGZ-tUA2MX2mFxZdwY87wzxvspes=NKMxx=Bg@mail.gmail.com>

On Sat, Jan 11, 2014 at 2:43 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> What if the standalone `count.volatile` expression does evaluates to
> an object, that can be passed around? In the case of
> `count.volatile.incrementAndGet()`, the object is created and
> immediately becomes garbage, so the runtime cost can be zero.
>
> Another question, will `count.volatile::incrementAndGet()` be supported?

sorry, should be `count.volatile::incrementAndGet`. The question is
whether `count.volatile` appears to be an ordinary object to other
parts of JLS.

>
> Zhong Yu
>
>
>
> On Sat, Jan 11, 2014 at 11:17 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>> On 01/11/2014 11:40 AM, Aaron Grunthal wrote:
>>>
>>> On 11.01.2014 13:16, Doug Lea wrote:
>>>>
>>>> Note in particular that just "count.volatile" without any
>>>> method invocation would not be a legal expression.
>>>
>>>
>>> Which means it can't be passed around, which in turn means you have to
>>> write all
>>> the usual atomic algorithms for every call site and every field again and
>>> again.
>>
>>
>> JVMs do not support internal pointers. There are a lot of good reasons
>> they don't, and a lot of JVM internals would be impacted if they did.
>> And anything short of that is either special-casing (as here) or
>> reflection in disguise (with java.lang.reflect.Field etc), or, as
>> you pointed out in previous mail, using methods with lambda arguments.
>> Which I think you made a good argument for: Lambda-based works best
>> in cases where semantics matter but performance doesn't.
>> We'd like to get past the decade-long discussions that amount to
>> whining about this state of affairs and implement an effective
>> efficient solution.
>>
>> -Doug
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Sat Jan 11 15:53:18 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 11 Jan 2014 15:53:18 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D17416.30506@infinite-source.de>	<52D17C99.2040706@cs.oswego.edu>
	<CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>
Message-ID: <52D1AF3E.8020604@cs.oswego.edu>

On 01/11/2014 03:43 PM, Zhong Yu wrote:
> What if the standalone `count.volatile` expression does evaluates to an
> object, that can be passed around?

Not needing to answer that question is the reason not to allow it.
If someday someone does later decide to make this legal, they will
get a shot at ascribing it sensible non-error-seeking semantics.
Good luck with that.

> Another question, will `count.volatile::incrementAndGet()` be supported?
> sorry, should be `count.volatile::incrementAndGet`.

Same answer :-)

-Doug



From gergg at cox.net  Sat Jan 11 16:30:06 2014
From: gergg at cox.net (Gregg Wonderly)
Date: Sat, 11 Jan 2014 15:30:06 -0600
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CkuZ1n00R02hR0p01kudQk>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
	<52D17416.30506@infinite-source.de>
	<52D17C99.2040706@cs.oswego.edu>
	<CACuKZqFwmEJQq-E4K--T+KqRYUjZqk5LTZ1MBXN-eiBWycZO2g@mail.gmail.com>
	<CkuZ1n00R02hR0p01kudQk>
Message-ID: <CC32B84C-B1FA-4451-AC92-85AA8BF4172E@cox.net>

Why would this not resolve to a Java.lang.Proxy which wrapped all method invocations on the original object with a fence?  Field references might also be proxied as a new JIT generated class which would be a one time event which put fences  before reads and after writes to the fields.

Adding the keyword volatile to a class declaration might make it possible to generate such a "safe" class always.

Gregg

Sent from my iPhone

> On Jan 11, 2014, at 2:53 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> 
>> On 01/11/2014 03:43 PM, Zhong Yu wrote:
>> What if the standalone `count.volatile` expression does evaluates to an
>> object, that can be passed around?
> 
> Not needing to answer that question is the reason not to allow it.
> If someday someone does later decide to make this legal, they will
> get a shot at ascribing it sensible non-error-seeking semantics.
> Good luck with that.
> 
>> Another question, will `count.volatile::incrementAndGet()` be supported?
>> sorry, should be `count.volatile::incrementAndGet`.
> 
> Same answer :-)
> 
> -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hjohn at xs4all.nl  Sun Jan 12 05:03:41 2014
From: hjohn at xs4all.nl (John Hendrikx)
Date: Sun, 12 Jan 2014 11:03:41 +0100
Subject: [concurrency-interest] Converting to CompletableFuture
Message-ID: <52D2687D.9030409@xs4all.nl>

Hi List,

I'm trying to rewrite some of my older code for which I wrote my own 
little custom CompletableFuture (before realizing something like it 
existed) to use a CompletableFuture instead.  From what I understand it 
seems like a perfect match for tasks that need to be executed in the 
background, allows steps to be executed on different Executors and 
allows simple steps to be executed directly on whatever thread the 
previous stage ran on.

However, I'm unsure how to transform some of it to CompletableFuture -- 
I have two major uses for it in my code, the simplest one I've detailed 
below:

Basically, I have a task that I want to execute asynchronously:

1) Do a database query to see if some object is stored in the database 
(takes several ms)
2) Based on query above, run a 2nd task on either Executor 1 or Executor 
2 -- the idea here being that things that are in the database can be 
queried fast and should be prioritized over slower tasks, which fetch 
data over HTTP.  Specifically, I donot want type 2 tasks to be able to 
fill up an Executor's threads/queue and prevent the fast type 1 tasks 
from executing as soon as possible, and vice versa.

So in my own custom solution, this is handled as follows:

         Task task = new Task(p -> {
           // p = a Task instance, representing the "parent" Task (in 
this case the one created one line above).
           Executor chosenExecutor = imageHandle.isFastSource() ? 
FAST_EXECUTOR : SLOW_EXECUTOR;  // isFastSource is a database query 
taking several ms

           p.addStep(chosenExecutor, new BackgroundLoader(this, 
imageHandle));  // Add a step to the parent Task
         });

         FAST_EXECUTOR.execute(task);  // Execute main task on 
FAST_EXECUTOR as the first step is always a step that completes fast.

Note that BackgroundLoader is an implementation of TaskRunnable (a Task 
step) that gives access to the parent Task that triggered it, and allows 
further steps to be added as more information becomes available on how 
to proceed further with this background task:

   public interface TaskRunnable {
     void run(Task currentTask);
   }

How can this be done with a CompletableFuture?

I tried:

     CompletableFuture<Image> futureImage = CompletableFuture
              .supplyAsync(() -> imageHandle.isFastSource() ? 
FAST_EXECUTOR : SLOW_EXECUTOR)
              .thenApplyAsync(executor -> { 
loadInBackground(imageHandle) }, executor??);

But I donot see how I can use thenApplyAsync to add a step to the Future 
using the Executor that the previous step determined.  I have this 
feeling it may not be possible at all as CompletableFuture seems to be a 
static chain of events that cannot be modified while it is running, 
unlike the Task system I constructed.

--John



From viktor.klang at gmail.com  Sun Jan 12 07:22:43 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 12 Jan 2014 13:22:43 +0100
Subject: [concurrency-interest] Converting to CompletableFuture
In-Reply-To: <52D2687D.9030409@xs4all.nl>
References: <52D2687D.9030409@xs4all.nl>
Message-ID: <CANPzfU_yWWoYYn57K66aoMyBTDRcAKjpr96snAH8zM5sS1UovQ@mail.gmail.com>

On Sun, Jan 12, 2014 at 11:03 AM, John Hendrikx <hjohn at xs4all.nl> wrote:

> Hi List,
>
> I'm trying to rewrite some of my older code for which I wrote my own
> little custom CompletableFuture (before realizing something like it
> existed) to use a CompletableFuture instead.  From what I understand it
> seems like a perfect match for tasks that need to be executed in the
> background, allows steps to be executed on different Executors and allows
> simple steps to be executed directly on whatever thread the previous stage
> ran on.
>
> However, I'm unsure how to transform some of it to CompletableFuture -- I
> have two major uses for it in my code, the simplest one I've detailed below:
>
> Basically, I have a task that I want to execute asynchronously:
>
> 1) Do a database query to see if some object is stored in the database
> (takes several ms)
> 2) Based on query above, run a 2nd task on either Executor 1 or Executor 2
> -- the idea here being that things that are in the database can be queried
> fast and should be prioritized over slower tasks, which fetch data over
> HTTP.  Specifically, I donot want type 2 tasks to be able to fill up an
> Executor's threads/queue and prevent the fast type 1 tasks from executing
> as soon as possible, and vice versa.
>
> So in my own custom solution, this is handled as follows:
>
>         Task task = new Task(p -> {
>           // p = a Task instance, representing the "parent" Task (in this
> case the one created one line above).
>           Executor chosenExecutor = imageHandle.isFastSource() ?
> FAST_EXECUTOR : SLOW_EXECUTOR;  // isFastSource is a database query taking
> several ms
>
>           p.addStep(chosenExecutor, new BackgroundLoader(this,
> imageHandle));  // Add a step to the parent Task
>         });
>
>         FAST_EXECUTOR.execute(task);  // Execute main task on
> FAST_EXECUTOR as the first step is always a step that completes fast.
>
> Note that BackgroundLoader is an implementation of TaskRunnable (a Task
> step) that gives access to the parent Task that triggered it, and allows
> further steps to be added as more information becomes available on how to
> proceed further with this background task:
>
>   public interface TaskRunnable {
>     void run(Task currentTask);
>   }
>
> How can this be done with a CompletableFuture?
>
> I tried:
>
>     CompletableFuture<Image> futureImage = CompletableFuture
>              .supplyAsync(() -> imageHandle.isFastSource() ? FAST_EXECUTOR
> : SLOW_EXECUTOR)
>              .thenApplyAsync(executor -> { loadInBackground(imageHandle)
> }, executor??);
>

Don't have access to a compiler atm so YMMV:

supplyAsync(() -> imageHandle.isFastSource() ? FAST_EXECUTOR :
SLOW_EXECUTOR).thenCompose(executor -> supplyAsync(() ->
loadInBackground(imageHandle), executor))

Cheers,
?


>
> But I donot see how I can use thenApplyAsync to add a step to the Future
> using the Executor that the previous step determined.  I have this feeling
> it may not be possible at all as CompletableFuture seems to be a static
> chain of events that cannot be modified while it is running, unlike the
> Task system I constructed.
>
> --John
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?

*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140112/d8f1fa1c/attachment-0001.html>

From aph at redhat.com  Sun Jan 12 11:36:32 2014
From: aph at redhat.com (Andrew Haley)
Date: Sun, 12 Jan 2014 16:36:32 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D13633.5000706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
Message-ID: <52D2C490.6000603@redhat.com>

On 01/11/2014 12:16 PM, Doug Lea wrote:
>          int getAndAdd(int x);
>          int addAndGet(int x);
>          int getAndIncrement();
>          int incrementAndGet();
>          int getAndDecrement();
>          int decrementAndGet();

It would be nice to be able to set and clear and flip bits with
getAndOr() etc.  I don't quite understand why these aren't already part
of AtomicInteger.

Andrew.

From vitalyd at gmail.com  Sun Jan 12 13:28:53 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 12 Jan 2014 13:28:53 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D2C490.6000603@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu> <52D2C490.6000603@redhat.com>
Message-ID: <CAHjP37FKq+zZ9RbfgMFD5YtEZC-mHDqNO+MR1FXoZJKct1XJMQ@mail.gmail.com>

Does any hardware support atomic fetch-and-AND/OR operations? As far as I
know, x86/64 doesn't have it (you can do each atomically but not the load
and the operation together).  You're looking at a manual CAS loop at this
point, so may as well not include that in AtomicInteger since this can be
done by user code using the AI primitives.

The fetch-and-add methods are special because they have hardware support,
at least on x86 (LOCK xadd), and can thus be intrinsified by JIT.

Sent from my phone
On Jan 12, 2014 11:40 AM, "Andrew Haley" <aph at redhat.com> wrote:

> On 01/11/2014 12:16 PM, Doug Lea wrote:
> >          int getAndAdd(int x);
> >          int addAndGet(int x);
> >          int getAndIncrement();
> >          int incrementAndGet();
> >          int getAndDecrement();
> >          int decrementAndGet();
>
> It would be nice to be able to set and clear and flip bits with
> getAndOr() etc.  I don't quite understand why these aren't already part
> of AtomicInteger.
>
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140112/62858382/attachment.html>

From hjohn at xs4all.nl  Mon Jan 13 04:05:40 2014
From: hjohn at xs4all.nl (John Hendrikx)
Date: Mon, 13 Jan 2014 10:05:40 +0100
Subject: [concurrency-interest] Converting to CompletableFuture
In-Reply-To: <CANPzfU_yWWoYYn57K66aoMyBTDRcAKjpr96snAH8zM5sS1UovQ@mail.gmail.com>
References: <52D2687D.9030409@xs4all.nl>
	<CANPzfU_yWWoYYn57K66aoMyBTDRcAKjpr96snAH8zM5sS1UovQ@mail.gmail.com>
Message-ID: <52D3AC64.8030803@xs4all.nl>

Thank you, this put me on the right path!

On 12/01/2014 13:22, ?iktor ?lang wrote:
>
> On Sun, Jan 12, 2014 at 11:03 AM, John Hendrikx <hjohn at xs4all.nl 
> <mailto:hjohn at xs4all.nl>> wrote:
>
>
>         CompletableFuture<Image> futureImage = CompletableFuture
>                  .supplyAsync(() -> imageHandle.isFastSource() ?
>     FAST_EXECUTOR : SLOW_EXECUTOR)
>                  .thenApplyAsync(executor -> {
>     loadInBackground(imageHandle) }, executor??);
>
>
> Don't have access to a compiler atm so YMMV:
>
> supplyAsync(() -> imageHandle.isFastSource() ? FAST_EXECUTOR : 
> SLOW_EXECUTOR).thenCompose(executor -> supplyAsync(() -> 
> loadInBackground(imageHandle), executor))
>
> Cheers,
> ?
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140113/24c61f1b/attachment.html>

From hjohn at xs4all.nl  Mon Jan 13 06:33:31 2014
From: hjohn at xs4all.nl (John Hendrikx)
Date: Mon, 13 Jan 2014 12:33:31 +0100
Subject: [concurrency-interest] CompletableFuture questions
Message-ID: <52D3CF0B.5080507@xs4all.nl>

Hi List,

I'm having some trouble using my usual path to get answers (Google) when 
it comes to CompletableFuture issues, so I hope people won't mind me 
asking here.

1) The cancel() method's behavior is odd.   If (in this case) not all 
Stages are async, it does not check the next Stage to see if the Future 
was cancelled.

     CompletableFuture<Integer> f1 = CompletableFuture.supplyAsync(() -> 2);
     CompletableFuture<Integer> f2 = f1.thenApply(d -> {
       try {
         Thread.sleep(1000);  // Give the system plenty of time to 
receive the cancel
       }
       catch(Exception e){
       }
       return 2 / d;
     });
     CompletableFuture<Void> f3 = f2.thenAccept(d -> { 
System.out.println("Why was I not cancelled?  Result = " + d); });
     f3.cancel(true);

The System.out will still happen... only by changing both thenApply and 
thenAccept to their Async versions does the cancellation actually occur.

2) How do I combine a "settle" delay with a CompletableFuture?  My 
current code will do something in the background based on some 
property's value, but only if that property has been stable for say 500 
ms.  The original code uses a ScheduledExecutorService for this, which 
can handle a ton of tasks with only a single thread.  The Future 
returned from the schedule() method can be cancelled and it can be 
replaced with a new Future that again waits for 500 ms if the property 
was changed in the mean time.

With CompletableFuture this would seem even easier.  I just need to 
create a CompletableFuture chain that:
   - waits 500 ms (cancellable at any time)
   - does some heavy lifting (could be more than one step), if not cancelled
   - does an update on a UI thread (JavaFX UI thread, Swing Event 
Thread) using a custom Executor, if not cancelled

However, I donot seem to be able to create a CompletableFuture with any 
kind of delay without it eating up a valuable Thread.   Furthermore, the 
delay would only "start" when the Future gets run (not when it gets 
queued), although that can be worked around.  If I do it seperately (a 
ScheduledFuture, which triggers a CompletableFuture), I don't have a 
single point any more on which to call the cancel() method, unless I can 
combine a ScheduledFuture with a CompletableFuture somehow.

3) In the Javadocs is says that calling cancel() will not interrupt 
running async parts of my CompletableFuture, not even simple steps that 
are sleeping... and there doesn't seem to be any way to know which 
Thread(s) is/are currently involved in the computation.

Is there any way to achieve a system that sets up some heavy multi-step 
task, but can cancel it at any time when it is determined that the 
result will no longer be needed?  This kind of thing happens a lot in 
UI's where Images are loaded in the background and where user 
interaction quickly changes what is actually relevant to still fully load.

In other words, I don't want the system grinding to a halt when the user 
simply holds down "cursor down" because of hundreds of background loads 
occuring of which only the last few ones will be relevant when the key 
gets released.  The "settle" delay helps with this, but it is not 
optimal (forced delay is not optimal when there is only one background 
task started; it only makes the problem slightly harder to reproduce, it 
is still there if you time it right).

I think the optimal situation for dealing with this is to use an 
Executor with a small pool (like 5), that can thefore load 5 Images in 
the background simultaneously.  They start instantly and can be 
cancelled quickly.  The rest of the background tasks get queued up and 
can be cancelled before they even get to run.  This ensures that:

- I never use resources for more than 5 images at a time (memory 
constraints)
- Images get loaded as fast as possible (no settle delay)
- When many background loads get triggered, most of them will be 
cancelled before even running
- Running tasks that get cancelled instantly free up a Thread for 
something that IS relevant

--John





From viktor.klang at gmail.com  Mon Jan 13 06:59:02 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 13 Jan 2014 12:59:02 +0100
Subject: [concurrency-interest] CompletableFuture questions
In-Reply-To: <52D3CF0B.5080507@xs4all.nl>
References: <52D3CF0B.5080507@xs4all.nl>
Message-ID: <CANPzfU9MsELPXPDvBROaOQvZED8wYcMQY7ufHBtXCirCm7PFdQ@mail.gmail.com>

You can implement your own cancellation-wrapper.
This is a gist for how I did it for Scala Futures:

https://gist.github.com/viktorklang/5409467

Cheers,
?


On Mon, Jan 13, 2014 at 12:33 PM, John Hendrikx <hjohn at xs4all.nl> wrote:

> Hi List,
>
> I'm having some trouble using my usual path to get answers (Google) when
> it comes to CompletableFuture issues, so I hope people won't mind me asking
> here.
>
> 1) The cancel() method's behavior is odd.   If (in this case) not all
> Stages are async, it does not check the next Stage to see if the Future was
> cancelled.
>
>     CompletableFuture<Integer> f1 = CompletableFuture.supplyAsync(() ->
> 2);
>     CompletableFuture<Integer> f2 = f1.thenApply(d -> {
>       try {
>         Thread.sleep(1000);  // Give the system plenty of time to receive
> the cancel
>       }
>       catch(Exception e){
>       }
>       return 2 / d;
>     });
>     CompletableFuture<Void> f3 = f2.thenAccept(d -> {
> System.out.println("Why was I not cancelled?  Result = " + d); });
>     f3.cancel(true);
>
> The System.out will still happen... only by changing both thenApply and
> thenAccept to their Async versions does the cancellation actually occur.
>
> 2) How do I combine a "settle" delay with a CompletableFuture?  My current
> code will do something in the background based on some property's value,
> but only if that property has been stable for say 500 ms.  The original
> code uses a ScheduledExecutorService for this, which can handle a ton of
> tasks with only a single thread.  The Future returned from the schedule()
> method can be cancelled and it can be replaced with a new Future that again
> waits for 500 ms if the property was changed in the mean time.
>
> With CompletableFuture this would seem even easier.  I just need to create
> a CompletableFuture chain that:
>   - waits 500 ms (cancellable at any time)
>   - does some heavy lifting (could be more than one step), if not cancelled
>   - does an update on a UI thread (JavaFX UI thread, Swing Event Thread)
> using a custom Executor, if not cancelled
>
> However, I donot seem to be able to create a CompletableFuture with any
> kind of delay without it eating up a valuable Thread.   Furthermore, the
> delay would only "start" when the Future gets run (not when it gets
> queued), although that can be worked around.  If I do it seperately (a
> ScheduledFuture, which triggers a CompletableFuture), I don't have a single
> point any more on which to call the cancel() method, unless I can combine a
> ScheduledFuture with a CompletableFuture somehow.
>
> 3) In the Javadocs is says that calling cancel() will not interrupt
> running async parts of my CompletableFuture, not even simple steps that are
> sleeping... and there doesn't seem to be any way to know which Thread(s)
> is/are currently involved in the computation.
>
> Is there any way to achieve a system that sets up some heavy multi-step
> task, but can cancel it at any time when it is determined that the result
> will no longer be needed?  This kind of thing happens a lot in UI's where
> Images are loaded in the background and where user interaction quickly
> changes what is actually relevant to still fully load.
>
> In other words, I don't want the system grinding to a halt when the user
> simply holds down "cursor down" because of hundreds of background loads
> occuring of which only the last few ones will be relevant when the key gets
> released.  The "settle" delay helps with this, but it is not optimal
> (forced delay is not optimal when there is only one background task
> started; it only makes the problem slightly harder to reproduce, it is
> still there if you time it right).
>
> I think the optimal situation for dealing with this is to use an Executor
> with a small pool (like 5), that can thefore load 5 Images in the
> background simultaneously.  They start instantly and can be cancelled
> quickly.  The rest of the background tasks get queued up and can be
> cancelled before they even get to run.  This ensures that:
>
> - I never use resources for more than 5 images at a time (memory
> constraints)
> - Images get loaded as fast as possible (no settle delay)
> - When many background loads get triggered, most of them will be cancelled
> before even running
> - Running tasks that get cancelled instantly free up a Thread for
> something that IS relevant
>
> --John
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?

*Viktor Klang*
*Director of Engineering*
Typesafe <http://www.typesafe.com/>

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140113/bb2f322c/attachment-0001.html>

From dl at cs.oswego.edu  Mon Jan 13 07:13:08 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 13 Jan 2014 07:13:08 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D2C490.6000603@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu> <52D2C490.6000603@redhat.com>
Message-ID: <52D3D854.70909@cs.oswego.edu>

On 01/12/2014 11:36 AM, Andrew Haley wrote:
> On 01/11/2014 12:16 PM, Doug Lea wrote:
>>           int getAndAdd(int x);
>>           int addAndGet(int x);
>>           int getAndIncrement();
>>           int incrementAndGet();
>>           int getAndDecrement();
>>           int decrementAndGet();
>
> It would be nice to be able to set and clear and flip bits with
> getAndOr() etc.  I don't quite understand why these aren't already part
> of AtomicInteger.
>

We generalized this for AtomicInteger in JDK8 by adding:

int getAndUpdate(IntUnaryOperator updateFunction)
int getAndAccumulate(int x, IntBinaryOperator accumulatorFunction)

I can't think of a reason not to do the same at interface
level (VolatileX) as well. Thanks for the reminder.

As Vitaly mentioned, one motivation for the explicit ones
for adding is allow mapping to special instructions on some
platforms. Also, they are by far most common, so it is
nice to make them convenient to use.

-Doug



From peter.firmstone at zeus.net.au  Sun Jan 12 13:22:54 2014
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Mon, 13 Jan 2014 04:22:54 +1000
Subject: [concurrency-interest] JDK9 Concurrency Preliminaries
Message-ID: <1389550974.9194.15.camel@Nokia-N900>

The ability to freeze an object to make it immutable prior to sharing with other threads.

Example: an immutable array.

Regards,

Peter.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140113/28ca34ce/attachment.html>

From nathan.reynolds at oracle.com  Mon Jan 13 12:28:12 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Mon, 13 Jan 2014 10:28:12 -0700
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D13633.5000706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
Message-ID: <52D4222C.6050404@oracle.com>

I don't remember if this has been covered already...  One problem with 
the Atomic___FieldUpdater classes is that there are a bunch of branches 
that have to be executed.  For example, compareAndSet has 6 
comparisons.  For this reason, many will resort to using Unsafe 
directly.  Will this change remove the need for the comparisons?  I 
think I already know the answer but just wanted to make sure.

-Nathan

On 1/11/2014 5:16 AM, Doug Lea wrote:
> On 01/10/2014 01:32 PM, Remi Forax wrote:
>> I don't like the idea to have a specific DSL for concurrency,
>> moreover I don't think you need one :)
>
> It's not a DSL,  ".volatile" is a form of cast that allows
> a field to be used as if it were a stand-alone AtomicX.
> In terms of JLS specs, it can be viewed as actually generating
> one. Here's a draft of current scheme:
>
> ...
>
> The target solution requires a syntax enhancement, a few
> library enhancements, and compiler support.
>
> We model the extended operations on volatile integers via an interface
> VolatileInt, that also captures the functionality of AtomicInteger
> (which will also be updated to reflect Java Memory Model revisions as
> part of this JEP). A tentative version is below. Similar interfaces
> are needed for other primitive and reference types.
>
> We then enable access to corresponding methods for volatile fields
> using the ".volatile" prefix. For example:
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>
> This syntax is required to avoid ambiguities with existing usages,
> especially for volatile references for which invocations of methods on
> the reference versus the referent would be indistinguishable.  The
> ".volatile" syntax is slightly unusual, but we are confident that it
> is syntactically unambiguous and semantically specifiable in a JLS
> update. Note in particular that just "count.volatile" without any
> method invocation would not be a legal expression. We also expect to
> develop a means of supporting volatile operations on array elements in
> addition to fields.
>
> The main task is to translate these calls into corresponding JVM
> intrinsics. The most likely option is for the source compiler to use
> method handles. This and other techniques are known to suffice, but
> are subject to further exploration.
>
> Here is a tentative VolatileInt interface.  Those for other types are
> similar.  The final released versions will surely differ in small
> ways.
>
>     interface VolatileInt {
>         int get();
>         int getRelaxed();
>         int getAcquire();
>         int getSequential();
>
>         void set(int x);
>         void setRelaxed(int x);
>         void setRelease(int x);
>         void setSequential(int x);
>
>         int getAndSet(int x);
>         boolean compareAndSet(int e, int x);
>         boolean compareAndSetAcquire(int e, int x);
>         boolean compareAndSetRelease(int e, int x);
>         boolean weakCompareAndSet(int e, int x);
>         boolean weakCompareAndSetAcquire(int e, int x);
>         boolean weakCompareAndSetRelease(int e, int x);
>
>         int getAndAdd(int x);
>         int addAndGet(int x);
>         int getAndIncrement();
>         int incrementAndGet();
>         int getAndDecrement();
>         int decrementAndGet();
>     }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140113/cdade9e6/attachment.html>

From aph at redhat.com  Mon Jan 13 12:44:47 2014
From: aph at redhat.com (Andrew Haley)
Date: Mon, 13 Jan 2014 17:44:47 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D3D854.70909@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu> <52D2C490.6000603@redhat.com>
	<52D3D854.70909@cs.oswego.edu>
Message-ID: <52D4260F.7080008@redhat.com>

On 01/13/2014 12:13 PM, Doug Lea wrote:
> As Vitaly mentioned, one motivation for the explicit ones
> for adding is allow mapping to special instructions on some
> platforms.

I see.  I'm wondering how easy it would be to recognize getAndOr()
from getAndUpdate(IntUnaryOperator).  On platforms with ldrex/strex
it makes precious little sense to do ld;op;cas.

Andrew.


From aaron.grunthal at infinite-source.de  Mon Jan 13 13:52:41 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Mon, 13 Jan 2014 19:52:41 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D4222C.6050404@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>
	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<52D4222C.6050404@oracle.com>
Message-ID: <52D435F9.409@infinite-source.de>

On 13.01.2014 18:28, Nathan Reynolds wrote:
> I don't remember if this has been covered already...  One problem with
> the Atomic___FieldUpdater classes is that there are a bunch of branches
> that have to be executed.  For example, compareAndSet has 6
> comparisons.  For this reason, many will resort to using Unsafe
> directly.  Will this change remove the need for the comparisons?  I
> think I already know the answer but just wanted to make sure.
>
> -Nathan

With ReferenceFieldUpdaters it seems even more than 6 comparisons, at 
least in the presence of polymorphism it checks the value and target 
types. And instanceof checks loops + indirection through the class 
hierarchy.
The question is how many of those checks the JVM can eliminate or would 
be necessary anyway at those callsites.

- Aaron

From dl at cs.oswego.edu  Mon Jan 13 15:16:35 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 13 Jan 2014 15:16:35 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D435F9.409@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>
	<52D435F9.409@infinite-source.de>
Message-ID: <52D449A3.9010907@cs.oswego.edu>

On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
> On 13.01.2014 18:28, Nathan Reynolds wrote:
>> I don't remember if this has been covered already...  One problem with
>> the Atomic___FieldUpdater classes is that there are a bunch of branches
>> that have to be executed.  For example, compareAndSet has 6
>> comparisons.  For this reason, many will resort to using Unsafe
>> directly.

Yes, this is the main problem we are trying to solve.

> The question is how many of those checks the JVM can eliminate or would be necessary anyway at those callsites.

Nothing less than eliminating all of them will be acceptable for target users.
The FieldUpdater approach falls into the reflection-in-disguise
category, which hasn't been amenable to this.
The .volatile solution can in principle generate overhead-less
optimal code. It will take some hard work to make this happen though.


-Doug



From peter.levart at gmail.com  Thu Jan 16 11:26:13 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 16 Jan 2014 17:26:13 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D449A3.9010907@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>
	<52D449A3.9010907@cs.oswego.edu>
Message-ID: <52D80825.9070403@gmail.com>

On 01/13/2014 09:16 PM, Doug Lea wrote:
> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>> I don't remember if this has been covered already...  One problem with
>>> the Atomic___FieldUpdater classes is that there are a bunch of branches
>>> that have to be executed.  For example, compareAndSet has 6
>>> comparisons.  For this reason, many will resort to using Unsafe
>>> directly.
>
> Yes, this is the main problem we are trying to solve.
>
>> The question is how many of those checks the JVM can eliminate or 
>> would be necessary anyway at those callsites.
>
> Nothing less than eliminating all of them will be acceptable for 
> target users.
> The FieldUpdater approach falls into the reflection-in-disguise
> category, which hasn't been amenable to this.
> The .volatile solution can in principle generate overhead-less
> optimal code. It will take some hard work to make this happen though.
>
>
> -Doug
>

Hi,

I did an experiment using MethodHandles in recent JDK 8, investigating 
their ability to avoid and/or optimize-away those checks. Here's an 
simple utility that merges together Unsafe methods with constant method 
handles:

https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/jdk/src/share/classes/java/lang/invoke/IntFieldHandles.java

(this should be appended to JDK boot classpath in order to work, if 
someone wants to experiment with it)

The following microbenchmark compares performance of direct Unsafe usage 
with MethodHandles wrapped Unsafe usage, which is safe, so a MH based 
utility could be used as an alternative to Unsafe and be exposed to user 
code even in security constrained environments:

https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/IntFieldHandlesTest.java

The test creates an instance of IntFieldHandles object and assigns it to 
a static final field. IntFieldHandles contains final instance 
MethodHandle fields that reference MHs which implement various atomic 
operations. I suspect that results show that JIT is able to:
- detect that MHs referenced of final instance fields in object 
referenced from static final field are constant inside tight loop, so it 
inlines them into call-sites
- optimize the non-null check out of a tight loop

These are results I get on my PC for 1 billion operations:

volatile get...
                Java bytecode:    254529453 ns (  0.25 ns/op)
                       Unsafe:    282554699 ns (  0.28 ns/op)
              IntFieldHandles:    283295007 ns (  0.28 ns/op)
  AtomicIntegerFieldUpdaterMH:    283064319 ns (  0.28 ns/op)
    AtomicIntegerFieldUpdater:    791010695 ns (  0.79 ns/op)

volatile set...
                Java bytecode:    875844892 ns (  0.88 ns/op)
                       Unsafe:   1694360893 ns (  1.69 ns/op)
              IntFieldHandles:   1694270390 ns (  1.69 ns/op)
  AtomicIntegerFieldUpdaterMH:   1694504218 ns (  1.69 ns/op)
    AtomicIntegerFieldUpdater:   5198716697 ns (  5.20 ns/op)

volatile set followed by volatile get...
                Java bytecode:   5197015493 ns (  5.20 ns/op)
                       Unsafe:   5214028002 ns (  5.21 ns/op)
              IntFieldHandles:   5197769609 ns (  5.20 ns/op)
  AtomicIntegerFieldUpdaterMH:   5198323773 ns (  5.20 ns/op)
    AtomicIntegerFieldUpdater:   6779080084 ns (  6.78 ns/op)

Java bytecode volatile get followed by compare-and-set loop...
                       Unsafe:   7909649848 ns (  7.91 ns/op)
              IntFieldHandles:   7909497393 ns (  7.91 ns/op)
  AtomicIntegerFieldUpdaterMH:   7921124292 ns (  7.92 ns/op)
    AtomicIntegerFieldUpdater:   8134981470 ns (  8.13 ns/op)


It is interesting to note that even classic AtomicIntegerFieldUpdater is 
not so bad compared to direct Unsafe usage when combining more that one 
atomic operation in a sequence on the same field. I don't know why 
normal bytecode volatile put is 2x faster than Unsafe volatile put. I 
also include comparison with special implementation of 
AtomicIntegerFieldUpdater based on constant MHs:

https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/AtomicIntegerFieldUpdaterMH.java

It shows that even generic MHs (with receiver of type Object) can 
optimize the cast out of tight loop ('this' in our example test)...

The problem with MHs in Java is that their invokeXXX() methods declare 
throws Throwable, so their direct usage in Java is clumsy. We need a 
language feature to overcome that.


Regards, Peter


From nathan.reynolds at oracle.com  Thu Jan 16 12:59:22 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 16 Jan 2014 10:59:22 -0700
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D80825.9070403@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D80825.9070403@gmail.com>
Message-ID: <52D81DFA.6080103@oracle.com>

 > I don't know why normal bytecode volatile put is 2x faster than 
Unsafe volatile put.

Consider disassembling the normal bytecode and the Unsafe volatile put.  
The disassembly should help give ideas why there is a difference.

This page describes how to print the assembly code of JITed methods.

http://wikis.sun.com/pages/viewpage.action?pageId=212340194
http://classparser.blogspot.com/2010/03/hsdis-i386dll.html

1) Copy hsdis-i386.dll to the following locations...  (it should be in 
the same directory as jvm.dll)
       C:\Program Files (x86)\Java\jdk1.6.0_25\jre\bin\client\hsdis-i386.dll
       C:\Program Files (x86)\Java\jdk1.6.0_25\jre\bin\server\hsdis-i386.dll
       C:\Program Files (x86)\Java\jre6\bin\client\hsdis-i386.dll

2) Use these command line options:
       Print all methods
          -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly

       Print specific method
          -XX:+UnlockDiagnosticVMOptions 
-XX:CompileCommand=print,*IntFieldHandlesTest./method/
          Can put multiple -XX:CompileCommand arguments to filter 
several methods

         Print Intel syntax add:
             -XX:PrintAssemblyOptions=intel

-Nathan

On 1/16/2014 9:26 AM, Peter Levart wrote:
> On 01/13/2014 09:16 PM, Doug Lea wrote:
>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>> I don't remember if this has been covered already...  One problem with
>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>> branches
>>>> that have to be executed.  For example, compareAndSet has 6
>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>> directly.
>>
>> Yes, this is the main problem we are trying to solve.
>>
>>> The question is how many of those checks the JVM can eliminate or 
>>> would be necessary anyway at those callsites.
>>
>> Nothing less than eliminating all of them will be acceptable for 
>> target users.
>> The FieldUpdater approach falls into the reflection-in-disguise
>> category, which hasn't been amenable to this.
>> The .volatile solution can in principle generate overhead-less
>> optimal code. It will take some hard work to make this happen though.
>>
>>
>> -Doug
>>
>
> Hi,
>
> I did an experiment using MethodHandles in recent JDK 8, investigating 
> their ability to avoid and/or optimize-away those checks. Here's an 
> simple utility that merges together Unsafe methods with constant 
> method handles:
>
> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/jdk/src/share/classes/java/lang/invoke/IntFieldHandles.java 
>
>
> (this should be appended to JDK boot classpath in order to work, if 
> someone wants to experiment with it)
>
> The following microbenchmark compares performance of direct Unsafe 
> usage with MethodHandles wrapped Unsafe usage, which is safe, so a MH 
> based utility could be used as an alternative to Unsafe and be exposed 
> to user code even in security constrained environments:
>
> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/IntFieldHandlesTest.java 
>
>
> The test creates an instance of IntFieldHandles object and assigns it 
> to a static final field. IntFieldHandles contains final instance 
> MethodHandle fields that reference MHs which implement various atomic 
> operations. I suspect that results show that JIT is able to:
> - detect that MHs referenced of final instance fields in object 
> referenced from static final field are constant inside tight loop, so 
> it inlines them into call-sites
> - optimize the non-null check out of a tight loop
>
> These are results I get on my PC for 1 billion operations:
>
> volatile get...
>                Java bytecode:    254529453 ns (  0.25 ns/op)
>                       Unsafe:    282554699 ns (  0.28 ns/op)
>              IntFieldHandles:    283295007 ns (  0.28 ns/op)
>  AtomicIntegerFieldUpdaterMH:    283064319 ns (  0.28 ns/op)
>    AtomicIntegerFieldUpdater:    791010695 ns (  0.79 ns/op)
>
> volatile set...
>                Java bytecode:    875844892 ns (  0.88 ns/op)
>                       Unsafe:   1694360893 ns (  1.69 ns/op)
>              IntFieldHandles:   1694270390 ns (  1.69 ns/op)
>  AtomicIntegerFieldUpdaterMH:   1694504218 ns (  1.69 ns/op)
>    AtomicIntegerFieldUpdater:   5198716697 ns (  5.20 ns/op)
>
> volatile set followed by volatile get...
>                Java bytecode:   5197015493 ns (  5.20 ns/op)
>                       Unsafe:   5214028002 ns (  5.21 ns/op)
>              IntFieldHandles:   5197769609 ns (  5.20 ns/op)
>  AtomicIntegerFieldUpdaterMH:   5198323773 ns (  5.20 ns/op)
>    AtomicIntegerFieldUpdater:   6779080084 ns (  6.78 ns/op)
>
> Java bytecode volatile get followed by compare-and-set loop...
>                       Unsafe:   7909649848 ns (  7.91 ns/op)
>              IntFieldHandles:   7909497393 ns (  7.91 ns/op)
>  AtomicIntegerFieldUpdaterMH:   7921124292 ns (  7.92 ns/op)
>    AtomicIntegerFieldUpdater:   8134981470 ns (  8.13 ns/op)
>
>
> It is interesting to note that even classic AtomicIntegerFieldUpdater 
> is not so bad compared to direct Unsafe usage when combining more that 
> one atomic operation in a sequence on the same field. I don't know why 
> normal bytecode volatile put is 2x faster than Unsafe volatile put. I 
> also include comparison with special implementation of 
> AtomicIntegerFieldUpdater based on constant MHs:
>
> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/AtomicIntegerFieldUpdaterMH.java 
>
>
> It shows that even generic MHs (with receiver of type Object) can 
> optimize the cast out of tight loop ('this' in our example test)...
>
> The problem with MHs in Java is that their invokeXXX() methods declare 
> throws Throwable, so their direct usage in Java is clumsy. We need a 
> language feature to overcome that.
>
>
> Regards, Peter
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140116/fd760fa0/attachment.html>

From dl at cs.oswego.edu  Thu Jan 16 13:14:26 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 16 Jan 2014 13:14:26 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D80825.9070403@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>
	<52D449A3.9010907@cs.oswego.edu> <52D80825.9070403@gmail.com>
Message-ID: <52D82182.3090104@cs.oswego.edu>

On 01/16/2014 11:26 AM, Peter Levart wrote:
>
> I did an experiment using MethodHandles in recent JDK 8, investigating their
> ability to avoid and/or optimize-away those checks.

Thanks! I should have mentioned that Paul Sandoz had also experimented
with this enough to know that in principle, MH-based compilation of
the proposed .volatile could work well. Thanks for helping to confirm this.

> operation in a sequence on the same field. I don't know why normal bytecode
> volatile put is 2x faster than Unsafe volatile put.

My guess is that you are seeing the effects of hotspot being
a little smarter about optimizing around bytecode volatile ops
than the instrinsified versions, not the generated code for
the actual operations. The impact is likely context dependent,
and probably not noticeable on most non-microbenchmarks.

-Doug








From forax at univ-mlv.fr  Fri Jan 17 04:37:27 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Fri, 17 Jan 2014 10:37:27 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D449A3.9010907@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>
	<52D449A3.9010907@cs.oswego.edu>
Message-ID: <52D8F9D7.3050100@univ-mlv.fr>

On 01/13/2014 09:16 PM, Doug Lea wrote:
> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>> I don't remember if this has been covered already...  One problem with
>>> the Atomic___FieldUpdater classes is that there are a bunch of branches
>>> that have to be executed.  For example, compareAndSet has 6
>>> comparisons.  For this reason, many will resort to using Unsafe
>>> directly.
>
> Yes, this is the main problem we are trying to solve.
>
>> The question is how many of those checks the JVM can eliminate or 
>> would be necessary anyway at those callsites.
>
> Nothing less than eliminating all of them will be acceptable for 
> target users.
> The FieldUpdater approach falls into the reflection-in-disguise
> category, which hasn't been amenable to this.
> The .volatile solution can in principle generate overhead-less
> optimal code. It will take some hard work to make this happen though.

I've written a small proof of concept of how this can work and there are 
so good news and some things that must be improved.

First, you can separate the problem in two independant questions, one is 
the .volatile syntax and the other is how to talk to the JIT to avoid 
those stupid runtime checks.

For the former question, I see several good reasons to not use the 
.volatile syntax.
The first one is that the syntax doesn't cover all use cases, you can 
not do a double CAS with the .volatile syntax by example, because the 
syntax consider only one field.
The second one, is a problem that I have discovered only when coding a 
solution, the world that the VM see and the world that Java proposes to 
an user are not perfectly aligned. In Java, you can access to a private 
field of an inner class from the enclosing class (and vice versa). The 
VM can not do that. The compiler bridge that gap by generating getter 
and setter (the access$xxx method). Obviously, the .volatile syntax can 
not use the same trick and will have at runtime to do some check and 
bypass the security model. While it's not a dig deal because the check 
can be done once for all, it means that you offer a possible angle of 
attack from the security perspective because the code has to elevate its 
privilege.
The third one is more conceptual, if Java offers a specific syntax for 
concurrency, uses will want a specific syntax for any other fields like 
by example a specific syntax for HPC.

Basically, what we want is to have an intrinsic, like a C++ instrinsic 
provided by the C++ compiler, also like a VM instrinsic that transform a 
method like unsafe.compareAndSwapObject to assembly code.
That's why I think it's better to provide an instrinsic-like mechanism 
that will replace a call to a Java method to a specific sequence of 
bytecodes. We have the tool for specifying the sequence of bytecode it's 
the method handle combiners of the package java.lang.invoke. All we need 
is something in the Java compiler that says, the call to this method is 
not a classical Java code but a call to something that will be turned to 
a method handle tree, i.e. a call through invokedynamic.

Using invokedynamic and the method handles are the answer to the 
question 2, the .volatile syntax will use invokedynamic, the 
instrinsic-like mecanism I propose will use invokedynamic. That's why I 
think it's important so separate the discussion about the syntax from 
the discussion about how to about the class check at runtime.

So let me explain how to code a Java instrinsic in Java.
You need two parts, the first one is the declaration of methods that 
will be turned to an intrinsic.
This can be done by writing a classical method that throw an error. The 
method body will be never called, the method is just here for the 
typechecking.
The second part is that javac has to know that this method is an 
intrinsic, using a keyword by example,
and generate an invokedynamic instead of the callsicall invoke* bytecode.
And at runtime, the first time that a method tagged intrinsic will be 
called for a callsite,
the VM will call the bootstrap method.

Here is an example for compareAndSet:
public class Volatiles {
   public static intrinsic boolean compareAndSet(String fieldName, 
Object current, int expected, int newValue) {
     throw new InternalError();
   }

   public static intrinsic <T> boolean compareAndSet(String fieldName, 
Object current, T expected, T newValue) {
     throw new InternalError();
   }

   public static CallSite bootstrap(Lookup lookup, String name, 
MethodType type, MethodHandle impl) {
     ...
   }
}

and it will be used that way:
public class Linked {
   private volatile Node head;

   private boolean compareAndSet(Node expected, Node newValue) {
     return Volatiles.compareAndSet("head", this, expected, newValue);
   }
...

Here I know what you think, it uses a String, it will do reflection, it 
will be slow,
obviously the answer is no.
Let me detail how it works, first you can notice that you don't have to 
specify the class,
when the bootstrap method is called, the Lookup parameter contains the 
class that call
the method so it's not needed and it's even better, it restrict the API 
because it
can only be used to access to a member that is declared in the class to call
"Volatiles.compareAndSet" so there is no security privilege enhancement,
it fully relies on the Lookup object for doing the security check so no 
potential new security hole.

Now the string parameter, Java has no way to reference a field so you 
need to send the name
of the field, but there is a trick here. The implementation use the 
method handle guardWithTest
(a glorified 'if') to check that the String will never changed (doing a 
pointer check),
The things is that if the API is used correctly, the string will be 
always a string literal so
the JIT will prove easily that the String never changed so will just 
remove the pointer check.
The else branch throws an exception to inform the user of the API that 
the String must be a constant.
This trick allows to specify the field to be updated in a nice way (just 
a string) without any performance penalty.

Now, how to get ride of the value check that check dynamically that you 
can not use Volatiles.compareAndSet to set a String inside the field 'head'.
The trick here is to ask the compiler to do a little more work that 
usual when computing the signature of the invokedynamic call. Instead of 
using the signature of Volatiles.compareAndSet which is (String, Object, 
Object, Object)boolean due to the erasure, javac will use the type of 
the expression found during the typechecking phase (this is something 
javac already does for signature polymorphic method like 
MethodHandle.invokeExact, so no big deal). Here in the example, the 
signature of invokedynamic will be (String, Linked, Node, Node)boolean. 
That the the signature convey the real type information, the boostrap 
method can check once that the type of newValue is correct with respect 
to the type of the field. Note: technically it can not be done in the 
bootstrap method because to get the field you need the field name and 
the bootstrap method doesn't have the argument. But the usual trick, is 
to register a method that will be called the first time in the boostrap 
method and in the method, the code have access to the value of the first 
call. At the end of the method, the method will relink the call site 
with the method handle tree that call unsafe.compareAndSwapObject. 
Basically, it just an extra level of indirection for the first call. Not 
something that the JIT will see because when the JIT will be triggered 
there will be no reference to that intermediary method anymore.

The signature trick allows also to get ride of the check that verifie 
that the second parameter is an object of the current class ('this' in 
the example).

Now, I've done some simple test to check that the JIT was really able to 
not insert check and correctly generate the same code as calling 
directly Unsafe.compareAndSwapObject.
It mostly work, the JIT correctly remove the String pointer check, but 
it insert two null supplementary checks that verifies that expected and 
newValue are not null when I compare with a code that use 
Unsafe.compareAndSwapObject directly.

I believe (I may be wrong, hence John and Christian in CC) that, these 
checks are artifacts that comes from the way the method handle tree is 
transformed to assembly code, the lambda form.
Lambda forms internally erases the types to Object and use a Class.cast 
to ensure safety, Class.cast is transformed to an instanceof. The part 
that check the class hierarchy of instanceof is removed because 
Unsafe.compareAndSwapObject use Object as parameter but the null check 
still float around.

I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
removed now.

In conclusion, we are close enough (far more close that I was thinking 
initially) to provide a solution that allow people to have the 
performance of unsafe.compareAndSwapObject without the unsafe bits
I believe it's better to come with a general solution that allow 
developers to trap method calls and replace them by tree of method 
handles that to have a specific syntax just for concurrency.

regards,
R?mi

Here is the full code of the bootstrap method:
public static CallSite bootstrap(Lookup lookup, String name, MethodType 
type, MethodHandle impls) {
     if (type.parameterType(1) != lookup.lookupClass()) {
       throw new LinkageError("the second parameter of compareAndSet 
must be this");
     }

     // also check that the parameter(2) and parameter(3) have the same type
     if (type.parameterType(2) != type.parameterType(3)) {
       throw new LinkageError("expected value and new value should have 
the same type");
     }

     MethodHandle fallback;
     if (type.parameterType(2) == int.class) {
       throw new AssertionError("NIY");
     } else {
       fallback = CASCallSite.FALLBACK_OBJECT;
     }

     return new CASCallSite(lookup, type, fallback);
   }

   static final Unsafe UNSAFE;
   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
   static {
     Unsafe unsafe;
     try {
       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
       theUnsafe.setAccessible(true);
       unsafe = (Unsafe)theUnsafe.get(null);
     } catch (NoSuchFieldException | IllegalAccessException e) {
       throw new AssertionError(e);
     }
     UNSAFE = unsafe;

     MethodHandle unsafeMH;
     Lookup lookup = MethodHandles.lookup();
     try {
       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class, 
"checkFieldName",
           MethodType.methodType(boolean.class, String.class, 
String.class));
       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
           MethodType.methodType(boolean.class));
       unsafeMH = lookup.findVirtual(Unsafe.class, "compareAndSwapObject",
           MethodType.methodType(boolean.class, Object.class, 
long.class, Object.class, Object.class));
     } catch (NoSuchMethodException | IllegalAccessException e) {
       throw new AssertionError(e);
     }
     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
   }

   @SuppressWarnings("unused")  // used by a method handle
   private static boolean checkFieldName(String expected, String value) {
     return expected == value;
   }

   @SuppressWarnings("unused")  // used by a method handle
   private static boolean throwError() {
     throw new IllegalStateException("the field name must be constant");
   }

   static class CASCallSite extends MutableCallSite {
     static MethodHandle FALLBACK_OBJECT;
     static {
       try {
         FALLBACK_OBJECT = 
MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
             MethodType.methodType(boolean.class, String.class, 
Object.class, Object.class, Object.class));
       } catch (NoSuchMethodException | IllegalAccessException e) {
         throw new AssertionError(e);
       }
     }

     private final Lookup lookup;

     CASCallSite(Lookup lookup, MethodType type, MethodHandle fallback) {
       super(type);
       this.lookup = lookup;
       setTarget(fallback.bindTo(this).asType(type));
     }

     boolean fallback(String name, Object self, Object expected, Object 
newValue) throws Throwable {
       MethodHandle getter;
       try {
         getter = lookup.findGetter(lookup.lookupClass(), name, 
type().parameterType(2));
         // use a horrible workaround
         //getter = lookup.findGetter(lookup.lookupClass(), name, 
newValue.getClass());
       } catch (NoSuchFieldException | IllegalAccessException e) {
         throw new IllegalStateException(e);
       }
       Field field = MethodHandles.reflectAs(Field.class, getter);
       long offset = UNSAFE.objectFieldOffset(field);
       MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS, 
1, offset);
       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 0, 
String.class);
       MethodHandle throwError = 
MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
       MethodHandle guard = 
MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name), 
unsafeCas.asType(type()), throwError);
       setTarget(guard);
       return (boolean)target.invokeExact(self, expected, newValue);
     }
   }

>
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From elizarov at devexperts.com  Fri Jan 17 05:09:39 2014
From: elizarov at devexperts.com (Roman Elizarov)
Date: Fri, 17 Jan 2014 10:09:39 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D8F9D7.3050100@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>
	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr>
Message-ID: <187ecc99bba94e39bfc5de7b7fd8ffae@exchmb01.office.devexperts.com>

Syntax is as important as implementation and its performance. The problem with "String fieldName" is that it looks like a string in a source code and even if javac knows that the method is intrinsic and does the actual compile-time checking that the string is constant and refers to the actual field, it still looks scripty, hacky, and ugly in the source code. It is an improvement upon AtomicFieldUpdater classes in terms of performance, but it offers no improvement in terms of syntax. I write a lot of code with volatiles/Unsafe and I don't want it to look ugly. It becomes hard to maintain and buggy, because of bad syntax of both Unsafe and AFU ways. 

I will **very much*** prefer this:

	head.volatile.compareAndSet(expected, newValue)

to this:

	Volatiles.compareAndSet("head", this, expected, newValue)

The concern of "specific syntax for concurrency" is legit, but moot, because Java _already_ has a lot of specific syntax for concurrency (but no specific syntax for HPC, for example) and extending Java's concurrency syntax does not break the spirit of Java, but enhances it. 

Actually, I would consider the second syntax to be a total failure to give Java a good concurrency library, regardless of its performance. If giving Java a specific syntax for concurrency is indeed a concern, then consider supporting field handles in Java instead. I can live with something like this:

	Volatiles.compareAndSet(this::head, expected, newValue)

Sincerely,
Roman Elizarov

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Remi Forax
Sent: Friday, January 17, 2014 1:37 PM
To: concurrency-interest at cs.oswego.edu
Cc: Christian Thalinger; John Rose
Subject: Re: [concurrency-interest] JDK9 concurrency preliminaries

On 01/13/2014 09:16 PM, Doug Lea wrote:
> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>> I don't remember if this has been covered already...  One problem 
>>> with the Atomic___FieldUpdater classes is that there are a bunch of 
>>> branches that have to be executed.  For example, compareAndSet has 6 
>>> comparisons.  For this reason, many will resort to using Unsafe 
>>> directly.
>
> Yes, this is the main problem we are trying to solve.
>
>> The question is how many of those checks the JVM can eliminate or 
>> would be necessary anyway at those callsites.
>
> Nothing less than eliminating all of them will be acceptable for 
> target users.
> The FieldUpdater approach falls into the reflection-in-disguise 
> category, which hasn't been amenable to this.
> The .volatile solution can in principle generate overhead-less optimal 
> code. It will take some hard work to make this happen though.

I've written a small proof of concept of how this can work and there are so good news and some things that must be improved.

First, you can separate the problem in two independant questions, one is the .volatile syntax and the other is how to talk to the JIT to avoid those stupid runtime checks.

For the former question, I see several good reasons to not use the .volatile syntax.
The first one is that the syntax doesn't cover all use cases, you can not do a double CAS with the .volatile syntax by example, because the syntax consider only one field.
The second one, is a problem that I have discovered only when coding a solution, the world that the VM see and the world that Java proposes to an user are not perfectly aligned. In Java, you can access to a private field of an inner class from the enclosing class (and vice versa). The VM can not do that. The compiler bridge that gap by generating getter and setter (the access$xxx method). Obviously, the .volatile syntax can not use the same trick and will have at runtime to do some check and bypass the security model. While it's not a dig deal because the check can be done once for all, it means that you offer a possible angle of attack from the security perspective because the code has to elevate its privilege.
The third one is more conceptual, if Java offers a specific syntax for concurrency, uses will want a specific syntax for any other fields like by example a specific syntax for HPC.

Basically, what we want is to have an intrinsic, like a C++ instrinsic provided by the C++ compiler, also like a VM instrinsic that transform a method like unsafe.compareAndSwapObject to assembly code.
That's why I think it's better to provide an instrinsic-like mechanism that will replace a call to a Java method to a specific sequence of bytecodes. We have the tool for specifying the sequence of bytecode it's the method handle combiners of the package java.lang.invoke. All we need is something in the Java compiler that says, the call to this method is not a classical Java code but a call to something that will be turned to a method handle tree, i.e. a call through invokedynamic.

Using invokedynamic and the method handles are the answer to the question 2, the .volatile syntax will use invokedynamic, the instrinsic-like mecanism I propose will use invokedynamic. That's why I think it's important so separate the discussion about the syntax from the discussion about how to about the class check at runtime.

So let me explain how to code a Java instrinsic in Java.
You need two parts, the first one is the declaration of methods that will be turned to an intrinsic.
This can be done by writing a classical method that throw an error. The method body will be never called, the method is just here for the typechecking.
The second part is that javac has to know that this method is an intrinsic, using a keyword by example, and generate an invokedynamic instead of the callsicall invoke* bytecode.
And at runtime, the first time that a method tagged intrinsic will be called for a callsite, the VM will call the bootstrap method.

Here is an example for compareAndSet:
public class Volatiles {
   public static intrinsic boolean compareAndSet(String fieldName, Object current, int expected, int newValue) {
     throw new InternalError();
   }

   public static intrinsic <T> boolean compareAndSet(String fieldName, Object current, T expected, T newValue) {
     throw new InternalError();
   }

   public static CallSite bootstrap(Lookup lookup, String name, MethodType type, MethodHandle impl) {
     ...
   }
}

and it will be used that way:
public class Linked {
   private volatile Node head;

   private boolean compareAndSet(Node expected, Node newValue) {
     return Volatiles.compareAndSet("head", this, expected, newValue);
   }
...

Here I know what you think, it uses a String, it will do reflection, it will be slow, obviously the answer is no.
Let me detail how it works, first you can notice that you don't have to specify the class, when the bootstrap method is called, the Lookup parameter contains the class that call the method so it's not needed and it's even better, it restrict the API because it can only be used to access to a member that is declared in the class to call "Volatiles.compareAndSet" so there is no security privilege enhancement, it fully relies on the Lookup object for doing the security check so no potential new security hole.

Now the string parameter, Java has no way to reference a field so you need to send the name of the field, but there is a trick here. The implementation use the method handle guardWithTest (a glorified 'if') to check that the String will never changed (doing a pointer check), The things is that if the API is used correctly, the string will be always a string literal so the JIT will prove easily that the String never changed so will just remove the pointer check.
The else branch throws an exception to inform the user of the API that the String must be a constant.
This trick allows to specify the field to be updated in a nice way (just a string) without any performance penalty.

Now, how to get ride of the value check that check dynamically that you can not use Volatiles.compareAndSet to set a String inside the field 'head'.
The trick here is to ask the compiler to do a little more work that usual when computing the signature of the invokedynamic call. Instead of using the signature of Volatiles.compareAndSet which is (String, Object, Object, Object)boolean due to the erasure, javac will use the type of the expression found during the typechecking phase (this is something javac already does for signature polymorphic method like MethodHandle.invokeExact, so no big deal). Here in the example, the signature of invokedynamic will be (String, Linked, Node, Node)boolean. 
That the the signature convey the real type information, the boostrap method can check once that the type of newValue is correct with respect to the type of the field. Note: technically it can not be done in the bootstrap method because to get the field you need the field name and the bootstrap method doesn't have the argument. But the usual trick, is to register a method that will be called the first time in the boostrap method and in the method, the code have access to the value of the first call. At the end of the method, the method will relink the call site with the method handle tree that call unsafe.compareAndSwapObject. 
Basically, it just an extra level of indirection for the first call. Not something that the JIT will see because when the JIT will be triggered there will be no reference to that intermediary method anymore.

The signature trick allows also to get ride of the check that verifie that the second parameter is an object of the current class ('this' in the example).

Now, I've done some simple test to check that the JIT was really able to not insert check and correctly generate the same code as calling directly Unsafe.compareAndSwapObject.
It mostly work, the JIT correctly remove the String pointer check, but it insert two null supplementary checks that verifies that expected and newValue are not null when I compare with a code that use Unsafe.compareAndSwapObject directly.

I believe (I may be wrong, hence John and Christian in CC) that, these checks are artifacts that comes from the way the method handle tree is transformed to assembly code, the lambda form.
Lambda forms internally erases the types to Object and use a Class.cast to ensure safety, Class.cast is transformed to an instanceof. The part that check the class hierarchy of instanceof is removed because Unsafe.compareAndSwapObject use Object as parameter but the null check still float around.

I use a fairly old build (jdk8b155) so perhaps, these artifacts are removed now.

In conclusion, we are close enough (far more close that I was thinking
initially) to provide a solution that allow people to have the performance of unsafe.compareAndSwapObject without the unsafe bits I believe it's better to come with a general solution that allow developers to trap method calls and replace them by tree of method handles that to have a specific syntax just for concurrency.

regards,
R?mi

Here is the full code of the bootstrap method:
public static CallSite bootstrap(Lookup lookup, String name, MethodType type, MethodHandle impls) {
     if (type.parameterType(1) != lookup.lookupClass()) {
       throw new LinkageError("the second parameter of compareAndSet must be this");
     }

     // also check that the parameter(2) and parameter(3) have the same type
     if (type.parameterType(2) != type.parameterType(3)) {
       throw new LinkageError("expected value and new value should have the same type");
     }

     MethodHandle fallback;
     if (type.parameterType(2) == int.class) {
       throw new AssertionError("NIY");
     } else {
       fallback = CASCallSite.FALLBACK_OBJECT;
     }

     return new CASCallSite(lookup, type, fallback);
   }

   static final Unsafe UNSAFE;
   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
   static {
     Unsafe unsafe;
     try {
       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
       theUnsafe.setAccessible(true);
       unsafe = (Unsafe)theUnsafe.get(null);
     } catch (NoSuchFieldException | IllegalAccessException e) {
       throw new AssertionError(e);
     }
     UNSAFE = unsafe;

     MethodHandle unsafeMH;
     Lookup lookup = MethodHandles.lookup();
     try {
       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class,
"checkFieldName",
           MethodType.methodType(boolean.class, String.class, String.class));
       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
           MethodType.methodType(boolean.class));
       unsafeMH = lookup.findVirtual(Unsafe.class, "compareAndSwapObject",
           MethodType.methodType(boolean.class, Object.class, long.class, Object.class, Object.class));
     } catch (NoSuchMethodException | IllegalAccessException e) {
       throw new AssertionError(e);
     }
     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
   }

   @SuppressWarnings("unused")  // used by a method handle
   private static boolean checkFieldName(String expected, String value) {
     return expected == value;
   }

   @SuppressWarnings("unused")  // used by a method handle
   private static boolean throwError() {
     throw new IllegalStateException("the field name must be constant");
   }

   static class CASCallSite extends MutableCallSite {
     static MethodHandle FALLBACK_OBJECT;
     static {
       try {
         FALLBACK_OBJECT =
MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
             MethodType.methodType(boolean.class, String.class, Object.class, Object.class, Object.class));
       } catch (NoSuchMethodException | IllegalAccessException e) {
         throw new AssertionError(e);
       }
     }

     private final Lookup lookup;

     CASCallSite(Lookup lookup, MethodType type, MethodHandle fallback) {
       super(type);
       this.lookup = lookup;
       setTarget(fallback.bindTo(this).asType(type));
     }

     boolean fallback(String name, Object self, Object expected, Object
newValue) throws Throwable {
       MethodHandle getter;
       try {
         getter = lookup.findGetter(lookup.lookupClass(), name, type().parameterType(2));
         // use a horrible workaround
         //getter = lookup.findGetter(lookup.lookupClass(), name, newValue.getClass());
       } catch (NoSuchFieldException | IllegalAccessException e) {
         throw new IllegalStateException(e);
       }
       Field field = MethodHandles.reflectAs(Field.class, getter);
       long offset = UNSAFE.objectFieldOffset(field);
       MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS,
1, offset);
       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 0, String.class);
       MethodHandle throwError =
MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
       MethodHandle guard =
MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name),
unsafeCas.asType(type()), throwError);
       setTarget(guard);
       return (boolean)target.invokeExact(self, expected, newValue);
     }
   }

>
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From cbergstrom at pathscale.com  Fri Jan 17 08:02:35 2014
From: cbergstrom at pathscale.com (=?ISO-8859-1?Q?=22C=2E_Bergstr=F6m=22?=)
Date: Fri, 17 Jan 2014 20:02:35 +0700
Subject: [concurrency-interest] [OT] Deadlock detection project
Message-ID: <52D929EB.1010204@pathscale.com>

Hi

A friend referred me to this list since I've struck out getting help 
other places. I'm interested to hire someone for a small project to work 
on some static analysis for deadlock detection (java) and other 
concurrency issues. The infrastructure of choice is open, but I have a 
preference for something more "research friendly". It's a personal 
project of mine and not related to my official work. Anyone interested 
in helping (for profit) please ping me off list so we can discuss it 
further.

Thanks

(Happy New Year)

Christopher

From oleksandr.otenko at oracle.com  Fri Jan 17 08:41:28 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 17 Jan 2014 13:41:28 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D8F9D7.3050100@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr>
Message-ID: <52D93308.7060103@oracle.com>

Sounds like Java macros.


Alex


On 17/01/2014 09:37, Remi Forax wrote:
> On 01/13/2014 09:16 PM, Doug Lea wrote:
>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>> I don't remember if this has been covered already...  One problem with
>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>> branches
>>>> that have to be executed.  For example, compareAndSet has 6
>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>> directly.
>>
>> Yes, this is the main problem we are trying to solve.
>>
>>> The question is how many of those checks the JVM can eliminate or 
>>> would be necessary anyway at those callsites.
>>
>> Nothing less than eliminating all of them will be acceptable for 
>> target users.
>> The FieldUpdater approach falls into the reflection-in-disguise
>> category, which hasn't been amenable to this.
>> The .volatile solution can in principle generate overhead-less
>> optimal code. It will take some hard work to make this happen though.
>
> I've written a small proof of concept of how this can work and there 
> are so good news and some things that must be improved.
>
> First, you can separate the problem in two independant questions, one 
> is the .volatile syntax and the other is how to talk to the JIT to 
> avoid those stupid runtime checks.
>
> For the former question, I see several good reasons to not use the 
> .volatile syntax.
> The first one is that the syntax doesn't cover all use cases, you can 
> not do a double CAS with the .volatile syntax by example, because the 
> syntax consider only one field.
> The second one, is a problem that I have discovered only when coding a 
> solution, the world that the VM see and the world that Java proposes 
> to an user are not perfectly aligned. In Java, you can access to a 
> private field of an inner class from the enclosing class (and vice 
> versa). The VM can not do that. The compiler bridge that gap by 
> generating getter and setter (the access$xxx method). Obviously, the 
> .volatile syntax can not use the same trick and will have at runtime 
> to do some check and bypass the security model. While it's not a dig 
> deal because the check can be done once for all, it means that you 
> offer a possible angle of attack from the security perspective because 
> the code has to elevate its privilege.
> The third one is more conceptual, if Java offers a specific syntax for 
> concurrency, uses will want a specific syntax for any other fields 
> like by example a specific syntax for HPC.
>
> Basically, what we want is to have an intrinsic, like a C++ instrinsic 
> provided by the C++ compiler, also like a VM instrinsic that transform 
> a method like unsafe.compareAndSwapObject to assembly code.
> That's why I think it's better to provide an instrinsic-like mechanism 
> that will replace a call to a Java method to a specific sequence of 
> bytecodes. We have the tool for specifying the sequence of bytecode 
> it's the method handle combiners of the package java.lang.invoke. All 
> we need is something in the Java compiler that says, the call to this 
> method is not a classical Java code but a call to something that will 
> be turned to a method handle tree, i.e. a call through invokedynamic.
>
> Using invokedynamic and the method handles are the answer to the 
> question 2, the .volatile syntax will use invokedynamic, the 
> instrinsic-like mecanism I propose will use invokedynamic. That's why 
> I think it's important so separate the discussion about the syntax 
> from the discussion about how to about the class check at runtime.
>
> So let me explain how to code a Java instrinsic in Java.
> You need two parts, the first one is the declaration of methods that 
> will be turned to an intrinsic.
> This can be done by writing a classical method that throw an error. 
> The method body will be never called, the method is just here for the 
> typechecking.
> The second part is that javac has to know that this method is an 
> intrinsic, using a keyword by example,
> and generate an invokedynamic instead of the callsicall invoke* bytecode.
> And at runtime, the first time that a method tagged intrinsic will be 
> called for a callsite,
> the VM will call the bootstrap method.
>
> Here is an example for compareAndSet:
> public class Volatiles {
>   public static intrinsic boolean compareAndSet(String fieldName, 
> Object current, int expected, int newValue) {
>     throw new InternalError();
>   }
>
>   public static intrinsic <T> boolean compareAndSet(String fieldName, 
> Object current, T expected, T newValue) {
>     throw new InternalError();
>   }
>
>   public static CallSite bootstrap(Lookup lookup, String name, 
> MethodType type, MethodHandle impl) {
>     ...
>   }
> }
>
> and it will be used that way:
> public class Linked {
>   private volatile Node head;
>
>   private boolean compareAndSet(Node expected, Node newValue) {
>     return Volatiles.compareAndSet("head", this, expected, newValue);
>   }
> ...
>
> Here I know what you think, it uses a String, it will do reflection, 
> it will be slow,
> obviously the answer is no.
> Let me detail how it works, first you can notice that you don't have 
> to specify the class,
> when the bootstrap method is called, the Lookup parameter contains the 
> class that call
> the method so it's not needed and it's even better, it restrict the 
> API because it
> can only be used to access to a member that is declared in the class 
> to call
> "Volatiles.compareAndSet" so there is no security privilege enhancement,
> it fully relies on the Lookup object for doing the security check so 
> no potential new security hole.
>
> Now the string parameter, Java has no way to reference a field so you 
> need to send the name
> of the field, but there is a trick here. The implementation use the 
> method handle guardWithTest
> (a glorified 'if') to check that the String will never changed (doing 
> a pointer check),
> The things is that if the API is used correctly, the string will be 
> always a string literal so
> the JIT will prove easily that the String never changed so will just 
> remove the pointer check.
> The else branch throws an exception to inform the user of the API that 
> the String must be a constant.
> This trick allows to specify the field to be updated in a nice way 
> (just a string) without any performance penalty.
>
> Now, how to get ride of the value check that check dynamically that 
> you can not use Volatiles.compareAndSet to set a String inside the 
> field 'head'.
> The trick here is to ask the compiler to do a little more work that 
> usual when computing the signature of the invokedynamic call. Instead 
> of using the signature of Volatiles.compareAndSet which is (String, 
> Object, Object, Object)boolean due to the erasure, javac will use the 
> type of the expression found during the typechecking phase (this is 
> something javac already does for signature polymorphic method like 
> MethodHandle.invokeExact, so no big deal). Here in the example, the 
> signature of invokedynamic will be (String, Linked, Node, 
> Node)boolean. That the the signature convey the real type information, 
> the boostrap method can check once that the type of newValue is 
> correct with respect to the type of the field. Note: technically it 
> can not be done in the bootstrap method because to get the field you 
> need the field name and the bootstrap method doesn't have the 
> argument. But the usual trick, is to register a method that will be 
> called the first time in the boostrap method and in the method, the 
> code have access to the value of the first call. At the end of the 
> method, the method will relink the call site with the method handle 
> tree that call unsafe.compareAndSwapObject. Basically, it just an 
> extra level of indirection for the first call. Not something that the 
> JIT will see because when the JIT will be triggered there will be no 
> reference to that intermediary method anymore.
>
> The signature trick allows also to get ride of the check that verifie 
> that the second parameter is an object of the current class ('this' in 
> the example).
>
> Now, I've done some simple test to check that the JIT was really able 
> to not insert check and correctly generate the same code as calling 
> directly Unsafe.compareAndSwapObject.
> It mostly work, the JIT correctly remove the String pointer check, but 
> it insert two null supplementary checks that verifies that expected 
> and newValue are not null when I compare with a code that use 
> Unsafe.compareAndSwapObject directly.
>
> I believe (I may be wrong, hence John and Christian in CC) that, these 
> checks are artifacts that comes from the way the method handle tree is 
> transformed to assembly code, the lambda form.
> Lambda forms internally erases the types to Object and use a 
> Class.cast to ensure safety, Class.cast is transformed to an 
> instanceof. The part that check the class hierarchy of instanceof is 
> removed because Unsafe.compareAndSwapObject use Object as parameter 
> but the null check still float around.
>
> I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
> removed now.
>
> In conclusion, we are close enough (far more close that I was thinking 
> initially) to provide a solution that allow people to have the 
> performance of unsafe.compareAndSwapObject without the unsafe bits
> I believe it's better to come with a general solution that allow 
> developers to trap method calls and replace them by tree of method 
> handles that to have a specific syntax just for concurrency.
>
> regards,
> R?mi
>
> Here is the full code of the bootstrap method:
> public static CallSite bootstrap(Lookup lookup, String name, 
> MethodType type, MethodHandle impls) {
>     if (type.parameterType(1) != lookup.lookupClass()) {
>       throw new LinkageError("the second parameter of compareAndSet 
> must be this");
>     }
>
>     // also check that the parameter(2) and parameter(3) have the same 
> type
>     if (type.parameterType(2) != type.parameterType(3)) {
>       throw new LinkageError("expected value and new value should have 
> the same type");
>     }
>
>     MethodHandle fallback;
>     if (type.parameterType(2) == int.class) {
>       throw new AssertionError("NIY");
>     } else {
>       fallback = CASCallSite.FALLBACK_OBJECT;
>     }
>
>     return new CASCallSite(lookup, type, fallback);
>   }
>
>   static final Unsafe UNSAFE;
>   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>   static {
>     Unsafe unsafe;
>     try {
>       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>       theUnsafe.setAccessible(true);
>       unsafe = (Unsafe)theUnsafe.get(null);
>     } catch (NoSuchFieldException | IllegalAccessException e) {
>       throw new AssertionError(e);
>     }
>     UNSAFE = unsafe;
>
>     MethodHandle unsafeMH;
>     Lookup lookup = MethodHandles.lookup();
>     try {
>       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class, 
> "checkFieldName",
>           MethodType.methodType(boolean.class, String.class, 
> String.class));
>       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>           MethodType.methodType(boolean.class));
>       unsafeMH = lookup.findVirtual(Unsafe.class, "compareAndSwapObject",
>           MethodType.methodType(boolean.class, Object.class, 
> long.class, Object.class, Object.class));
>     } catch (NoSuchMethodException | IllegalAccessException e) {
>       throw new AssertionError(e);
>     }
>     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>   }
>
>   @SuppressWarnings("unused")  // used by a method handle
>   private static boolean checkFieldName(String expected, String value) {
>     return expected == value;
>   }
>
>   @SuppressWarnings("unused")  // used by a method handle
>   private static boolean throwError() {
>     throw new IllegalStateException("the field name must be constant");
>   }
>
>   static class CASCallSite extends MutableCallSite {
>     static MethodHandle FALLBACK_OBJECT;
>     static {
>       try {
>         FALLBACK_OBJECT = 
> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>             MethodType.methodType(boolean.class, String.class, 
> Object.class, Object.class, Object.class));
>       } catch (NoSuchMethodException | IllegalAccessException e) {
>         throw new AssertionError(e);
>       }
>     }
>
>     private final Lookup lookup;
>
>     CASCallSite(Lookup lookup, MethodType type, MethodHandle fallback) {
>       super(type);
>       this.lookup = lookup;
>       setTarget(fallback.bindTo(this).asType(type));
>     }
>
>     boolean fallback(String name, Object self, Object expected, Object 
> newValue) throws Throwable {
>       MethodHandle getter;
>       try {
>         getter = lookup.findGetter(lookup.lookupClass(), name, 
> type().parameterType(2));
>         // use a horrible workaround
>         //getter = lookup.findGetter(lookup.lookupClass(), name, 
> newValue.getClass());
>       } catch (NoSuchFieldException | IllegalAccessException e) {
>         throw new IllegalStateException(e);
>       }
>       Field field = MethodHandles.reflectAs(Field.class, getter);
>       long offset = UNSAFE.objectFieldOffset(field);
>       MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS, 
> 1, offset);
>       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 0, 
> String.class);
>       MethodHandle throwError = 
> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>       MethodHandle guard = 
> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name), 
> unsafeCas.asType(type()), throwError);
>       setTarget(guard);
>       return (boolean)target.invokeExact(self, expected, newValue);
>     }
>   }
>
>>
>>
>> -Doug
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Fri Jan 17 08:49:25 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 17 Jan 2014 13:49:25 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D93308.7060103@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr> <52D93308.7060103@oracle.com>
Message-ID: <52D934E5.4020101@oracle.com>

In the sense that I like it.

I wonder if it would be possible to use a similar technique to write 
parameterized code, prove it is safe, once, and then reuse by plugging 
it as "a method handle tree" that you are talking about, providing 
parameters at call sites.

(compare:

queue.poll()
queue.poll(timeout)
queue.take()

- that's 3x the concurrent methods that do essentially the same thing;


queue.offer(a)
queue.offer(a,timeout)
queue.put(a)

that's another 3x the concurrent methods that do essentially the same thing.

Now technically need to test all permutations of all methods executing 
concurrently, whereas it would suffice to test one pair (the others 
being parameterized by non-essential stuff, plugged as lambdas).

Alex



On 17/01/2014 13:41, Oleksandr Otenko wrote:
> Sounds like Java macros.
>
>
> Alex
>
>
> On 17/01/2014 09:37, Remi Forax wrote:
>> On 01/13/2014 09:16 PM, Doug Lea wrote:
>>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>>> I don't remember if this has been covered already...  One problem 
>>>>> with
>>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>>> branches
>>>>> that have to be executed.  For example, compareAndSet has 6
>>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>>> directly.
>>>
>>> Yes, this is the main problem we are trying to solve.
>>>
>>>> The question is how many of those checks the JVM can eliminate or 
>>>> would be necessary anyway at those callsites.
>>>
>>> Nothing less than eliminating all of them will be acceptable for 
>>> target users.
>>> The FieldUpdater approach falls into the reflection-in-disguise
>>> category, which hasn't been amenable to this.
>>> The .volatile solution can in principle generate overhead-less
>>> optimal code. It will take some hard work to make this happen though.
>>
>> I've written a small proof of concept of how this can work and there 
>> are so good news and some things that must be improved.
>>
>> First, you can separate the problem in two independant questions, one 
>> is the .volatile syntax and the other is how to talk to the JIT to 
>> avoid those stupid runtime checks.
>>
>> For the former question, I see several good reasons to not use the 
>> .volatile syntax.
>> The first one is that the syntax doesn't cover all use cases, you can 
>> not do a double CAS with the .volatile syntax by example, because the 
>> syntax consider only one field.
>> The second one, is a problem that I have discovered only when coding 
>> a solution, the world that the VM see and the world that Java 
>> proposes to an user are not perfectly aligned. In Java, you can 
>> access to a private field of an inner class from the enclosing class 
>> (and vice versa). The VM can not do that. The compiler bridge that 
>> gap by generating getter and setter (the access$xxx method). 
>> Obviously, the .volatile syntax can not use the same trick and will 
>> have at runtime to do some check and bypass the security model. While 
>> it's not a dig deal because the check can be done once for all, it 
>> means that you offer a possible angle of attack from the security 
>> perspective because the code has to elevate its privilege.
>> The third one is more conceptual, if Java offers a specific syntax 
>> for concurrency, uses will want a specific syntax for any other 
>> fields like by example a specific syntax for HPC.
>>
>> Basically, what we want is to have an intrinsic, like a C++ 
>> instrinsic provided by the C++ compiler, also like a VM instrinsic 
>> that transform a method like unsafe.compareAndSwapObject to assembly 
>> code.
>> That's why I think it's better to provide an instrinsic-like 
>> mechanism that will replace a call to a Java method to a specific 
>> sequence of bytecodes. We have the tool for specifying the sequence 
>> of bytecode it's the method handle combiners of the package 
>> java.lang.invoke. All we need is something in the Java compiler that 
>> says, the call to this method is not a classical Java code but a call 
>> to something that will be turned to a method handle tree, i.e. a call 
>> through invokedynamic.
>>
>> Using invokedynamic and the method handles are the answer to the 
>> question 2, the .volatile syntax will use invokedynamic, the 
>> instrinsic-like mecanism I propose will use invokedynamic. That's why 
>> I think it's important so separate the discussion about the syntax 
>> from the discussion about how to about the class check at runtime.
>>
>> So let me explain how to code a Java instrinsic in Java.
>> You need two parts, the first one is the declaration of methods that 
>> will be turned to an intrinsic.
>> This can be done by writing a classical method that throw an error. 
>> The method body will be never called, the method is just here for the 
>> typechecking.
>> The second part is that javac has to know that this method is an 
>> intrinsic, using a keyword by example,
>> and generate an invokedynamic instead of the callsicall invoke* 
>> bytecode.
>> And at runtime, the first time that a method tagged intrinsic will be 
>> called for a callsite,
>> the VM will call the bootstrap method.
>>
>> Here is an example for compareAndSet:
>> public class Volatiles {
>>   public static intrinsic boolean compareAndSet(String fieldName, 
>> Object current, int expected, int newValue) {
>>     throw new InternalError();
>>   }
>>
>>   public static intrinsic <T> boolean compareAndSet(String fieldName, 
>> Object current, T expected, T newValue) {
>>     throw new InternalError();
>>   }
>>
>>   public static CallSite bootstrap(Lookup lookup, String name, 
>> MethodType type, MethodHandle impl) {
>>     ...
>>   }
>> }
>>
>> and it will be used that way:
>> public class Linked {
>>   private volatile Node head;
>>
>>   private boolean compareAndSet(Node expected, Node newValue) {
>>     return Volatiles.compareAndSet("head", this, expected, newValue);
>>   }
>> ...
>>
>> Here I know what you think, it uses a String, it will do reflection, 
>> it will be slow,
>> obviously the answer is no.
>> Let me detail how it works, first you can notice that you don't have 
>> to specify the class,
>> when the bootstrap method is called, the Lookup parameter contains 
>> the class that call
>> the method so it's not needed and it's even better, it restrict the 
>> API because it
>> can only be used to access to a member that is declared in the class 
>> to call
>> "Volatiles.compareAndSet" so there is no security privilege enhancement,
>> it fully relies on the Lookup object for doing the security check so 
>> no potential new security hole.
>>
>> Now the string parameter, Java has no way to reference a field so you 
>> need to send the name
>> of the field, but there is a trick here. The implementation use the 
>> method handle guardWithTest
>> (a glorified 'if') to check that the String will never changed (doing 
>> a pointer check),
>> The things is that if the API is used correctly, the string will be 
>> always a string literal so
>> the JIT will prove easily that the String never changed so will just 
>> remove the pointer check.
>> The else branch throws an exception to inform the user of the API 
>> that the String must be a constant.
>> This trick allows to specify the field to be updated in a nice way 
>> (just a string) without any performance penalty.
>>
>> Now, how to get ride of the value check that check dynamically that 
>> you can not use Volatiles.compareAndSet to set a String inside the 
>> field 'head'.
>> The trick here is to ask the compiler to do a little more work that 
>> usual when computing the signature of the invokedynamic call. Instead 
>> of using the signature of Volatiles.compareAndSet which is (String, 
>> Object, Object, Object)boolean due to the erasure, javac will use the 
>> type of the expression found during the typechecking phase (this is 
>> something javac already does for signature polymorphic method like 
>> MethodHandle.invokeExact, so no big deal). Here in the example, the 
>> signature of invokedynamic will be (String, Linked, Node, 
>> Node)boolean. That the the signature convey the real type 
>> information, the boostrap method can check once that the type of 
>> newValue is correct with respect to the type of the field. Note: 
>> technically it can not be done in the bootstrap method because to get 
>> the field you need the field name and the bootstrap method doesn't 
>> have the argument. But the usual trick, is to register a method that 
>> will be called the first time in the boostrap method and in the 
>> method, the code have access to the value of the first call. At the 
>> end of the method, the method will relink the call site with the 
>> method handle tree that call unsafe.compareAndSwapObject. Basically, 
>> it just an extra level of indirection for the first call. Not 
>> something that the JIT will see because when the JIT will be 
>> triggered there will be no reference to that intermediary method 
>> anymore.
>>
>> The signature trick allows also to get ride of the check that verifie 
>> that the second parameter is an object of the current class ('this' 
>> in the example).
>>
>> Now, I've done some simple test to check that the JIT was really able 
>> to not insert check and correctly generate the same code as calling 
>> directly Unsafe.compareAndSwapObject.
>> It mostly work, the JIT correctly remove the String pointer check, 
>> but it insert two null supplementary checks that verifies that 
>> expected and newValue are not null when I compare with a code that 
>> use Unsafe.compareAndSwapObject directly.
>>
>> I believe (I may be wrong, hence John and Christian in CC) that, 
>> these checks are artifacts that comes from the way the method handle 
>> tree is transformed to assembly code, the lambda form.
>> Lambda forms internally erases the types to Object and use a 
>> Class.cast to ensure safety, Class.cast is transformed to an 
>> instanceof. The part that check the class hierarchy of instanceof is 
>> removed because Unsafe.compareAndSwapObject use Object as parameter 
>> but the null check still float around.
>>
>> I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
>> removed now.
>>
>> In conclusion, we are close enough (far more close that I was 
>> thinking initially) to provide a solution that allow people to have 
>> the performance of unsafe.compareAndSwapObject without the unsafe bits
>> I believe it's better to come with a general solution that allow 
>> developers to trap method calls and replace them by tree of method 
>> handles that to have a specific syntax just for concurrency.
>>
>> regards,
>> R?mi
>>
>> Here is the full code of the bootstrap method:
>> public static CallSite bootstrap(Lookup lookup, String name, 
>> MethodType type, MethodHandle impls) {
>>     if (type.parameterType(1) != lookup.lookupClass()) {
>>       throw new LinkageError("the second parameter of compareAndSet 
>> must be this");
>>     }
>>
>>     // also check that the parameter(2) and parameter(3) have the 
>> same type
>>     if (type.parameterType(2) != type.parameterType(3)) {
>>       throw new LinkageError("expected value and new value should 
>> have the same type");
>>     }
>>
>>     MethodHandle fallback;
>>     if (type.parameterType(2) == int.class) {
>>       throw new AssertionError("NIY");
>>     } else {
>>       fallback = CASCallSite.FALLBACK_OBJECT;
>>     }
>>
>>     return new CASCallSite(lookup, type, fallback);
>>   }
>>
>>   static final Unsafe UNSAFE;
>>   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>>   static {
>>     Unsafe unsafe;
>>     try {
>>       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>>       theUnsafe.setAccessible(true);
>>       unsafe = (Unsafe)theUnsafe.get(null);
>>     } catch (NoSuchFieldException | IllegalAccessException e) {
>>       throw new AssertionError(e);
>>     }
>>     UNSAFE = unsafe;
>>
>>     MethodHandle unsafeMH;
>>     Lookup lookup = MethodHandles.lookup();
>>     try {
>>       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class, 
>> "checkFieldName",
>>           MethodType.methodType(boolean.class, String.class, 
>> String.class));
>>       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>>           MethodType.methodType(boolean.class));
>>       unsafeMH = lookup.findVirtual(Unsafe.class, 
>> "compareAndSwapObject",
>>           MethodType.methodType(boolean.class, Object.class, 
>> long.class, Object.class, Object.class));
>>     } catch (NoSuchMethodException | IllegalAccessException e) {
>>       throw new AssertionError(e);
>>     }
>>     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>>   }
>>
>>   @SuppressWarnings("unused")  // used by a method handle
>>   private static boolean checkFieldName(String expected, String value) {
>>     return expected == value;
>>   }
>>
>>   @SuppressWarnings("unused")  // used by a method handle
>>   private static boolean throwError() {
>>     throw new IllegalStateException("the field name must be constant");
>>   }
>>
>>   static class CASCallSite extends MutableCallSite {
>>     static MethodHandle FALLBACK_OBJECT;
>>     static {
>>       try {
>>         FALLBACK_OBJECT = 
>> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>>             MethodType.methodType(boolean.class, String.class, 
>> Object.class, Object.class, Object.class));
>>       } catch (NoSuchMethodException | IllegalAccessException e) {
>>         throw new AssertionError(e);
>>       }
>>     }
>>
>>     private final Lookup lookup;
>>
>>     CASCallSite(Lookup lookup, MethodType type, MethodHandle fallback) {
>>       super(type);
>>       this.lookup = lookup;
>>       setTarget(fallback.bindTo(this).asType(type));
>>     }
>>
>>     boolean fallback(String name, Object self, Object expected, 
>> Object newValue) throws Throwable {
>>       MethodHandle getter;
>>       try {
>>         getter = lookup.findGetter(lookup.lookupClass(), name, 
>> type().parameterType(2));
>>         // use a horrible workaround
>>         //getter = lookup.findGetter(lookup.lookupClass(), name, 
>> newValue.getClass());
>>       } catch (NoSuchFieldException | IllegalAccessException e) {
>>         throw new IllegalStateException(e);
>>       }
>>       Field field = MethodHandles.reflectAs(Field.class, getter);
>>       long offset = UNSAFE.objectFieldOffset(field);
>>       MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS, 
>> 1, offset);
>>       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 0, 
>> String.class);
>>       MethodHandle throwError = 
>> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>>       MethodHandle guard = 
>> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name), 
>> unsafeCas.asType(type()), throwError);
>>       setTarget(guard);
>>       return (boolean)target.invokeExact(self, expected, newValue);
>>     }
>>   }
>>
>>>
>>>
>>> -Doug
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dl at cs.oswego.edu  Fri Jan 17 09:37:38 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 17 Jan 2014 09:37:38 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D8F9D7.3050100@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr>
Message-ID: <52D94032.5060905@cs.oswego.edu>

On 01/17/2014 04:37 AM, Remi Forax wrote:

> I believe it's better to come with a general solution that allow developers to
> trap method calls and replace them by tree of method handles that to have a
> specific syntax just for concurrency.

I downplayed in posted JEP draft that we must also support a
way to operate on array elements, as in:
   int[] a = ...
   a[7].volatile.setRelease(17);

I don't see a path to this without the .volatile syntax support
or something essentially equivalent.

The reason arrays were not otherwise covered is that it is
still a TBD issue whether to allow access to elements in this way
for any array, without any type or annotation. Most likely the
answer will be yes; anything else hits some language, type,
or usability snag.

-Doug



From forax at univ-mlv.fr  Fri Jan 17 12:14:12 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Fri, 17 Jan 2014 18:14:12 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D94032.5060905@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D8F9D7.3050100@univ-mlv.fr>
	<52D94032.5060905@cs.oswego.edu>
Message-ID: <52D964E4.6020506@univ-mlv.fr>

On 01/17/2014 03:37 PM, Doug Lea wrote:
> On 01/17/2014 04:37 AM, Remi Forax wrote:
>
>> I believe it's better to come with a general solution that allow 
>> developers to
>> trap method calls and replace them by tree of method handles that to 
>> have a
>> specific syntax just for concurrency.
>
> I downplayed in posted JEP draft that we must also support a
> way to operate on array elements, as in:
>   int[] a = ...
>   a[7].volatile.setRelease(17);
>
> I don't see a path to this without the .volatile syntax support
> or something essentially equivalent.

I fail to see the issue here, perhaps it's because the semantics of 
setRelease is very special ?
Why a method that takes an array an int and a new value is not enough

public class Volatiles {
   public void setRelease(int[] array, int index, int newValue) {
      ...
   }
}


>
> The reason arrays were not otherwise covered is that it is
> still a TBD issue whether to allow access to elements in this way
> for any array, without any type or annotation. Most likely the
> answer will be yes; anything else hits some language, type,
> or usability snag.

You don't have a similar issue with a field ?

>
> -Doug

R?mi

From forax at univ-mlv.fr  Fri Jan 17 12:23:30 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Fri, 17 Jan 2014 18:23:30 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D934E5.4020101@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr> <52D93308.7060103@oracle.com>
	<52D934E5.4020101@oracle.com>
Message-ID: <52D96712.50507@univ-mlv.fr>

On 01/17/2014 02:49 PM, Oleksandr Otenko wrote:
> In the sense that I like it.

Yes, it's like C macro. But the macro expansion is done by the JIT and 
it's typesafe.

>
> I wonder if it would be possible to use a similar technique to write 
> parameterized code, prove it is safe, once, and then reuse by plugging 
> it as "a method handle tree" that you are talking about, providing 
> parameters at call sites.
>
> (compare:
>
> queue.poll()
> queue.poll(timeout)
> queue.take()
>
> - that's 3x the concurrent methods that do essentially the same thing;

more or less, poll() can be lock free while take() can't.

>
>
> queue.offer(a)
> queue.offer(a,timeout)
> queue.put(a)
>
> that's another 3x the concurrent methods that do essentially the same 
> thing.
>
> Now technically need to test all permutations of all methods executing 
> concurrently, whereas it would suffice to test one pair (the others 
> being parameterized by non-essential stuff, plugged as lambdas).

No, because the code inside the method handle tree can do side effect so 
a code with a method handle or without it doesn't exhibit the same 
property from a concurrency point of view.

>
> Alex

R?mi

>
>
>
> On 17/01/2014 13:41, Oleksandr Otenko wrote:
>> Sounds like Java macros.
>>
>>
>> Alex
>>
>>
>> On 17/01/2014 09:37, Remi Forax wrote:
>>> On 01/13/2014 09:16 PM, Doug Lea wrote:
>>>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>>>> I don't remember if this has been covered already...  One problem 
>>>>>> with
>>>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>>>> branches
>>>>>> that have to be executed.  For example, compareAndSet has 6
>>>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>>>> directly.
>>>>
>>>> Yes, this is the main problem we are trying to solve.
>>>>
>>>>> The question is how many of those checks the JVM can eliminate or 
>>>>> would be necessary anyway at those callsites.
>>>>
>>>> Nothing less than eliminating all of them will be acceptable for 
>>>> target users.
>>>> The FieldUpdater approach falls into the reflection-in-disguise
>>>> category, which hasn't been amenable to this.
>>>> The .volatile solution can in principle generate overhead-less
>>>> optimal code. It will take some hard work to make this happen though.
>>>
>>> I've written a small proof of concept of how this can work and there 
>>> are so good news and some things that must be improved.
>>>
>>> First, you can separate the problem in two independant questions, 
>>> one is the .volatile syntax and the other is how to talk to the JIT 
>>> to avoid those stupid runtime checks.
>>>
>>> For the former question, I see several good reasons to not use the 
>>> .volatile syntax.
>>> The first one is that the syntax doesn't cover all use cases, you 
>>> can not do a double CAS with the .volatile syntax by example, 
>>> because the syntax consider only one field.
>>> The second one, is a problem that I have discovered only when coding 
>>> a solution, the world that the VM see and the world that Java 
>>> proposes to an user are not perfectly aligned. In Java, you can 
>>> access to a private field of an inner class from the enclosing class 
>>> (and vice versa). The VM can not do that. The compiler bridge that 
>>> gap by generating getter and setter (the access$xxx method). 
>>> Obviously, the .volatile syntax can not use the same trick and will 
>>> have at runtime to do some check and bypass the security model. 
>>> While it's not a dig deal because the check can be done once for 
>>> all, it means that you offer a possible angle of attack from the 
>>> security perspective because the code has to elevate its privilege.
>>> The third one is more conceptual, if Java offers a specific syntax 
>>> for concurrency, uses will want a specific syntax for any other 
>>> fields like by example a specific syntax for HPC.
>>>
>>> Basically, what we want is to have an intrinsic, like a C++ 
>>> instrinsic provided by the C++ compiler, also like a VM instrinsic 
>>> that transform a method like unsafe.compareAndSwapObject to assembly 
>>> code.
>>> That's why I think it's better to provide an instrinsic-like 
>>> mechanism that will replace a call to a Java method to a specific 
>>> sequence of bytecodes. We have the tool for specifying the sequence 
>>> of bytecode it's the method handle combiners of the package 
>>> java.lang.invoke. All we need is something in the Java compiler that 
>>> says, the call to this method is not a classical Java code but a 
>>> call to something that will be turned to a method handle tree, i.e. 
>>> a call through invokedynamic.
>>>
>>> Using invokedynamic and the method handles are the answer to the 
>>> question 2, the .volatile syntax will use invokedynamic, the 
>>> instrinsic-like mecanism I propose will use invokedynamic. That's 
>>> why I think it's important so separate the discussion about the 
>>> syntax from the discussion about how to about the class check at 
>>> runtime.
>>>
>>> So let me explain how to code a Java instrinsic in Java.
>>> You need two parts, the first one is the declaration of methods that 
>>> will be turned to an intrinsic.
>>> This can be done by writing a classical method that throw an error. 
>>> The method body will be never called, the method is just here for 
>>> the typechecking.
>>> The second part is that javac has to know that this method is an 
>>> intrinsic, using a keyword by example,
>>> and generate an invokedynamic instead of the callsicall invoke* 
>>> bytecode.
>>> And at runtime, the first time that a method tagged intrinsic will 
>>> be called for a callsite,
>>> the VM will call the bootstrap method.
>>>
>>> Here is an example for compareAndSet:
>>> public class Volatiles {
>>>   public static intrinsic boolean compareAndSet(String fieldName, 
>>> Object current, int expected, int newValue) {
>>>     throw new InternalError();
>>>   }
>>>
>>>   public static intrinsic <T> boolean compareAndSet(String 
>>> fieldName, Object current, T expected, T newValue) {
>>>     throw new InternalError();
>>>   }
>>>
>>>   public static CallSite bootstrap(Lookup lookup, String name, 
>>> MethodType type, MethodHandle impl) {
>>>     ...
>>>   }
>>> }
>>>
>>> and it will be used that way:
>>> public class Linked {
>>>   private volatile Node head;
>>>
>>>   private boolean compareAndSet(Node expected, Node newValue) {
>>>     return Volatiles.compareAndSet("head", this, expected, newValue);
>>>   }
>>> ...
>>>
>>> Here I know what you think, it uses a String, it will do reflection, 
>>> it will be slow,
>>> obviously the answer is no.
>>> Let me detail how it works, first you can notice that you don't have 
>>> to specify the class,
>>> when the bootstrap method is called, the Lookup parameter contains 
>>> the class that call
>>> the method so it's not needed and it's even better, it restrict the 
>>> API because it
>>> can only be used to access to a member that is declared in the class 
>>> to call
>>> "Volatiles.compareAndSet" so there is no security privilege 
>>> enhancement,
>>> it fully relies on the Lookup object for doing the security check so 
>>> no potential new security hole.
>>>
>>> Now the string parameter, Java has no way to reference a field so 
>>> you need to send the name
>>> of the field, but there is a trick here. The implementation use the 
>>> method handle guardWithTest
>>> (a glorified 'if') to check that the String will never changed 
>>> (doing a pointer check),
>>> The things is that if the API is used correctly, the string will be 
>>> always a string literal so
>>> the JIT will prove easily that the String never changed so will just 
>>> remove the pointer check.
>>> The else branch throws an exception to inform the user of the API 
>>> that the String must be a constant.
>>> This trick allows to specify the field to be updated in a nice way 
>>> (just a string) without any performance penalty.
>>>
>>> Now, how to get ride of the value check that check dynamically that 
>>> you can not use Volatiles.compareAndSet to set a String inside the 
>>> field 'head'.
>>> The trick here is to ask the compiler to do a little more work that 
>>> usual when computing the signature of the invokedynamic call. 
>>> Instead of using the signature of Volatiles.compareAndSet which is 
>>> (String, Object, Object, Object)boolean due to the erasure, javac 
>>> will use the type of the expression found during the typechecking 
>>> phase (this is something javac already does for signature 
>>> polymorphic method like MethodHandle.invokeExact, so no big deal). 
>>> Here in the example, the signature of invokedynamic will be (String, 
>>> Linked, Node, Node)boolean. That the the signature convey the real 
>>> type information, the boostrap method can check once that the type 
>>> of newValue is correct with respect to the type of the field. Note: 
>>> technically it can not be done in the bootstrap method because to 
>>> get the field you need the field name and the bootstrap method 
>>> doesn't have the argument. But the usual trick, is to register a 
>>> method that will be called the first time in the boostrap method and 
>>> in the method, the code have access to the value of the first call. 
>>> At the end of the method, the method will relink the call site with 
>>> the method handle tree that call unsafe.compareAndSwapObject. 
>>> Basically, it just an extra level of indirection for the first call. 
>>> Not something that the JIT will see because when the JIT will be 
>>> triggered there will be no reference to that intermediary method 
>>> anymore.
>>>
>>> The signature trick allows also to get ride of the check that 
>>> verifie that the second parameter is an object of the current class 
>>> ('this' in the example).
>>>
>>> Now, I've done some simple test to check that the JIT was really 
>>> able to not insert check and correctly generate the same code as 
>>> calling directly Unsafe.compareAndSwapObject.
>>> It mostly work, the JIT correctly remove the String pointer check, 
>>> but it insert two null supplementary checks that verifies that 
>>> expected and newValue are not null when I compare with a code that 
>>> use Unsafe.compareAndSwapObject directly.
>>>
>>> I believe (I may be wrong, hence John and Christian in CC) that, 
>>> these checks are artifacts that comes from the way the method handle 
>>> tree is transformed to assembly code, the lambda form.
>>> Lambda forms internally erases the types to Object and use a 
>>> Class.cast to ensure safety, Class.cast is transformed to an 
>>> instanceof. The part that check the class hierarchy of instanceof is 
>>> removed because Unsafe.compareAndSwapObject use Object as parameter 
>>> but the null check still float around.
>>>
>>> I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
>>> removed now.
>>>
>>> In conclusion, we are close enough (far more close that I was 
>>> thinking initially) to provide a solution that allow people to have 
>>> the performance of unsafe.compareAndSwapObject without the unsafe bits
>>> I believe it's better to come with a general solution that allow 
>>> developers to trap method calls and replace them by tree of method 
>>> handles that to have a specific syntax just for concurrency.
>>>
>>> regards,
>>> R?mi
>>>
>>> Here is the full code of the bootstrap method:
>>> public static CallSite bootstrap(Lookup lookup, String name, 
>>> MethodType type, MethodHandle impls) {
>>>     if (type.parameterType(1) != lookup.lookupClass()) {
>>>       throw new LinkageError("the second parameter of compareAndSet 
>>> must be this");
>>>     }
>>>
>>>     // also check that the parameter(2) and parameter(3) have the 
>>> same type
>>>     if (type.parameterType(2) != type.parameterType(3)) {
>>>       throw new LinkageError("expected value and new value should 
>>> have the same type");
>>>     }
>>>
>>>     MethodHandle fallback;
>>>     if (type.parameterType(2) == int.class) {
>>>       throw new AssertionError("NIY");
>>>     } else {
>>>       fallback = CASCallSite.FALLBACK_OBJECT;
>>>     }
>>>
>>>     return new CASCallSite(lookup, type, fallback);
>>>   }
>>>
>>>   static final Unsafe UNSAFE;
>>>   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>>>   static {
>>>     Unsafe unsafe;
>>>     try {
>>>       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>>>       theUnsafe.setAccessible(true);
>>>       unsafe = (Unsafe)theUnsafe.get(null);
>>>     } catch (NoSuchFieldException | IllegalAccessException e) {
>>>       throw new AssertionError(e);
>>>     }
>>>     UNSAFE = unsafe;
>>>
>>>     MethodHandle unsafeMH;
>>>     Lookup lookup = MethodHandles.lookup();
>>>     try {
>>>       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class, 
>>> "checkFieldName",
>>>           MethodType.methodType(boolean.class, String.class, 
>>> String.class));
>>>       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>>>           MethodType.methodType(boolean.class));
>>>       unsafeMH = lookup.findVirtual(Unsafe.class, 
>>> "compareAndSwapObject",
>>>           MethodType.methodType(boolean.class, Object.class, 
>>> long.class, Object.class, Object.class));
>>>     } catch (NoSuchMethodException | IllegalAccessException e) {
>>>       throw new AssertionError(e);
>>>     }
>>>     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>>>   }
>>>
>>>   @SuppressWarnings("unused")  // used by a method handle
>>>   private static boolean checkFieldName(String expected, String 
>>> value) {
>>>     return expected == value;
>>>   }
>>>
>>>   @SuppressWarnings("unused")  // used by a method handle
>>>   private static boolean throwError() {
>>>     throw new IllegalStateException("the field name must be constant");
>>>   }
>>>
>>>   static class CASCallSite extends MutableCallSite {
>>>     static MethodHandle FALLBACK_OBJECT;
>>>     static {
>>>       try {
>>>         FALLBACK_OBJECT = 
>>> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>>>             MethodType.methodType(boolean.class, String.class, 
>>> Object.class, Object.class, Object.class));
>>>       } catch (NoSuchMethodException | IllegalAccessException e) {
>>>         throw new AssertionError(e);
>>>       }
>>>     }
>>>
>>>     private final Lookup lookup;
>>>
>>>     CASCallSite(Lookup lookup, MethodType type, MethodHandle 
>>> fallback) {
>>>       super(type);
>>>       this.lookup = lookup;
>>>       setTarget(fallback.bindTo(this).asType(type));
>>>     }
>>>
>>>     boolean fallback(String name, Object self, Object expected, 
>>> Object newValue) throws Throwable {
>>>       MethodHandle getter;
>>>       try {
>>>         getter = lookup.findGetter(lookup.lookupClass(), name, 
>>> type().parameterType(2));
>>>         // use a horrible workaround
>>>         //getter = lookup.findGetter(lookup.lookupClass(), name, 
>>> newValue.getClass());
>>>       } catch (NoSuchFieldException | IllegalAccessException e) {
>>>         throw new IllegalStateException(e);
>>>       }
>>>       Field field = MethodHandles.reflectAs(Field.class, getter);
>>>       long offset = UNSAFE.objectFieldOffset(field);
>>>       MethodHandle target = 
>>> MethodHandles.insertArguments(UNSAFE_CAS, 1, offset);
>>>       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 
>>> 0, String.class);
>>>       MethodHandle throwError = 
>>> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>>>       MethodHandle guard = 
>>> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name), 
>>> unsafeCas.asType(type()), throwError);
>>>       setTarget(guard);
>>>       return (boolean)target.invokeExact(self, expected, newValue);
>>>     }
>>>   }
>>>
>>>>
>>>>
>>>> -Doug
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From peter.levart at gmail.com  Fri Jan 17 13:09:39 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Fri, 17 Jan 2014 19:09:39 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D13633.5000706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu>
Message-ID: <52D971E3.80903@gmail.com>

On 01/11/2014 01:16 PM, Doug Lea wrote:
> On 01/10/2014 01:32 PM, Remi Forax wrote:
>> I don't like the idea to have a specific DSL for concurrency,
>> moreover I don't think you need one :)
>
> It's not a DSL,  ".volatile" is a form of cast that allows
> a field to be used as if it were a stand-alone AtomicX.
> In terms of JLS specs, it can be viewed as actually generating
> one. Here's a draft of current scheme:
>
> ...
>
> The target solution requires a syntax enhancement, a few
> library enhancements, and compiler support.
>
> We model the extended operations on volatile integers via an interface
> VolatileInt, that also captures the functionality of AtomicInteger
> (which will also be updated to reflect Java Memory Model revisions as
> part of this JEP). A tentative version is below. Similar interfaces
> are needed for other primitive and reference types.
>
> We then enable access to corresponding methods for volatile fields
> using the ".volatile" prefix. For example:
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>
> This syntax is required to avoid ambiguities with existing usages,
> especially for volatile references for which invocations of methods on
> the reference versus the referent would be indistinguishable.  The
> ".volatile" syntax is slightly unusual, but we are confident that it
> is syntactically unambiguous and semantically specifiable in a JLS
> update. Note in particular that just "count.volatile" without any
> method invocation would not be a legal expression. We also expect to
> develop a means of supporting volatile operations on array elements in
> addition to fields.

Hi,

The ".volatile" syntax is not really unusual. It looks familiar. It 
looks like an expression producing an object, but it isn't. In that 
respect it is not "orthogonal" to other language features. It feels like 
a language hack. I was thinking of an alternative (really rather 
unusual) syntax which would be a combination of "marks" for fields 
requesting particular memory ordering and additional syntax for some 
operations. Since lambdas and method references didn't "burn" the famous 
hash character '#', what about the following syntax:

class C {
   int x;

...

   // atomic reads/writes

   int r = x#volatile // volatile read

   x#volatile = 10; // volatile write

   int r = x#acquire; // read acquire

   x#release = 10; // write release

   int r = x#relaxed; // relaxed read (only atomicity guaranteed)

   x#relaxed = 10; // relaxed write


   // CAS

   boolean r = x#volatile === expect : new; // volatile compare-and-set

   boolean r = x#acquire === expect : new; // compare-and-set acquire

   boolean r = x#release === expect : new; // compare-and-set release

   boolean r = x#relaxed === expect : new; // relaxed (weak?) 
compare-and-set

   boolean r = x === expect : new; // 
non-atomic-neither-guaranteeing-any-visibility conditional set (for 
locals too)

   // why '===' ? It is a combination of '==' (compare) and '=' (set) ...

   // atomic operations

   int r = ++x#volatile; // volatile increment-and-get

   int r = x#volatile++; // volatile get-and-increment

   int r = x#volatile += 3 // volatile add-and-get

   int r = x#volatile ?+= 3 // volatile get-and-add

   int r = x#volatile ?= 10; // volatile get-and-set

   // #acquire, #release, #relaxed variants sensible?

   int r = x ?+= 3; // non-atomic-neither-guaranteeing-any-visibility 
"post add" (for locals too)

   int r = x ?= 10; // non-atomic-neither-guaranteeing-any-visibility 
"post set" (for locals too)

   // other in-place atomic operations implemented as 
read-operation-cas-loop like:

   int r = x#volatile *= 2; // volatile multiply-and-get


Memory ordering marks could be applied to array elements too, of course:

     array[i]#volatile = 10;


Instead of using '#' character to mark fields, I thought about using a 
dot '.' followed by a reserved word:

     x.volatile  instead of  x#volatile
     x.try       instead of  x#acquire
     x.finally   instead of  x#release

... but I didn't know what to use for relaxed

     x.do        instead of  x#relaxed  ?


Regards, Peter


>
> The main task is to translate these calls into corresponding JVM
> intrinsics. The most likely option is for the source compiler to use
> method handles. This and other techniques are known to suffice, but
> are subject to further exploration.
>
> Here is a tentative VolatileInt interface.  Those for other types are
> similar.  The final released versions will surely differ in small
> ways.
>
>     interface VolatileInt {
>         int get();
>         int getRelaxed();
>         int getAcquire();
>         int getSequential();
>
>         void set(int x);
>         void setRelaxed(int x);
>         void setRelease(int x);
>         void setSequential(int x);
>
>         int getAndSet(int x);
>         boolean compareAndSet(int e, int x);
>         boolean compareAndSetAcquire(int e, int x);
>         boolean compareAndSetRelease(int e, int x);
>         boolean weakCompareAndSet(int e, int x);
>         boolean weakCompareAndSetAcquire(int e, int x);
>         boolean weakCompareAndSetRelease(int e, int x);
>
>         int getAndAdd(int x);
>         int addAndGet(int x);
>         int getAndIncrement();
>         int incrementAndGet();
>         int getAndDecrement();
>         int decrementAndGet();
>     }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Fri Jan 17 13:56:14 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Fri, 17 Jan 2014 19:56:14 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D971E3.80903@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>
	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<52D971E3.80903@gmail.com>
Message-ID: <52D97CCE.9050005@univ-mlv.fr>

On 01/17/2014 07:09 PM, Peter Levart wrote:

[...]

>
> Hi,
>
> The ".volatile" syntax is not really unusual. It looks familiar. It 
> looks like an expression producing an object, but it isn't. In that 
> respect it is not "orthogonal" to other language features. It feels 
> like a language hack. I was thinking of an alternative (really rather 
> unusual) syntax which would be a combination of "marks" for fields 
> requesting particular memory ordering and additional syntax for some 
> operations. Since lambdas and method references didn't "burn" the 
> famous hash character '#', what about the following syntax:
>
> class C {
>   int x;
>
> ...
>
>   // atomic reads/writes
>
>   int r = x#volatile // volatile read
>
>   x#volatile = 10; // volatile write
>
>   int r = x#acquire; // read acquire
>
>   x#release = 10; // write release
>
>   int r = x#relaxed; // relaxed read (only atomicity guaranteed)
>
>   x#relaxed = 10; // relaxed write
>
>
>   // CAS
>
>   boolean r = x#volatile === expect : new; // volatile compare-and-set
>
>   boolean r = x#acquire === expect : new; // compare-and-set acquire
>
>   boolean r = x#release === expect : new; // compare-and-set release
>
>   boolean r = x#relaxed === expect : new; // relaxed (weak?) 
> compare-and-set
>
>   boolean r = x === expect : new; // 
> non-atomic-neither-guaranteeing-any-visibility conditional set (for 
> locals too)
>
>   // why '===' ? It is a combination of '==' (compare) and '=' (set) ...
>
>   // atomic operations
>
>   int r = ++x#volatile; // volatile increment-and-get
>
>   int r = x#volatile++; // volatile get-and-increment
>
>   int r = x#volatile += 3 // volatile add-and-get
>
>   int r = x#volatile ?+= 3 // volatile get-and-add
>
>   int r = x#volatile ?= 10; // volatile get-and-set
>
>   // #acquire, #release, #relaxed variants sensible?
>
>   int r = x ?+= 3; // non-atomic-neither-guaranteeing-any-visibility 
> "post add" (for locals too)
>
>   int r = x ?= 10; // non-atomic-neither-guaranteeing-any-visibility 
> "post set" (for locals too)
>
>   // other in-place atomic operations implemented as 
> read-operation-cas-loop like:
>
>   int r = x#volatile *= 2; // volatile multiply-and-get
>
>
> Memory ordering marks could be applied to array elements too, of course:
>
>     array[i]#volatile = 10;
>
>
> Instead of using '#' character to mark fields, I thought about using a 
> dot '.' followed by a reserved word:
>
>     x.volatile  instead of  x#volatile
>     x.try       instead of  x#acquire
>     x.finally   instead of  x#release
>
> ... but I didn't know what to use for relaxed
>
>     x.do        instead of  x#relaxed  ?
>
>
> Regards, Peter

I've forgotten to mention that we had already been bitten by choosing a 
syntax instead of an API.
'synchronized' can be seen as a nice syntax, but if you take a look to 
sun.misc.Unsafe you will see a monitorEnter(), monitorExit() and even a 
tryMonitorEnter() (tryLock on a monitor) because the semantics of a 
synchronized block was not enough.

An API is versatile, a syntax is not.

R?mi

>
>
>>
>> The main task is to translate these calls into corresponding JVM
>> intrinsics. The most likely option is for the source compiler to use
>> method handles. This and other techniques are known to suffice, but
>> are subject to further exploration.
>>
>> Here is a tentative VolatileInt interface.  Those for other types are
>> similar.  The final released versions will surely differ in small
>> ways.
>>
>>     interface VolatileInt {
>>         int get();
>>         int getRelaxed();
>>         int getAcquire();
>>         int getSequential();
>>
>>         void set(int x);
>>         void setRelaxed(int x);
>>         void setRelease(int x);
>>         void setSequential(int x);
>>
>>         int getAndSet(int x);
>>         boolean compareAndSet(int e, int x);
>>         boolean compareAndSetAcquire(int e, int x);
>>         boolean compareAndSetRelease(int e, int x);
>>         boolean weakCompareAndSet(int e, int x);
>>         boolean weakCompareAndSetAcquire(int e, int x);
>>         boolean weakCompareAndSetRelease(int e, int x);
>>
>>         int getAndAdd(int x);
>>         int addAndGet(int x);
>>         int getAndIncrement();
>>         int incrementAndGet();
>>         int getAndDecrement();
>>         int decrementAndGet();
>>     }
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Fri Jan 17 14:19:27 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 17 Jan 2014 14:19:27 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D971E3.80903@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu> <52D971E3.80903@gmail.com>
Message-ID: <52D9823F.6000702@cs.oswego.edu>

On 01/17/2014 01:09 PM, Peter Levart wrote:
> On 01/11/2014 01:16 PM, Doug Lea wrote:
>>             return count.volatile.incrementAndGet();
>
> The ".volatile" syntax is not really unusual. It looks familiar. It looks like
> an expression producing an object, but it isn't.

The slightly jarring effect  is because dot is overloaded in Java to mean
either dereference (as in field access) or scope (as in package imports
and inner-class "Outer.this"), or both. Here, we need the scope
sense, to distinguish the set of VolatileX ops from any others.
The reason for needing it is to avoid possible ambiguity for
example if you had an volatile reference to an AtomicReference.

If the two senses had different symbols in Java, I suspect that this
would be completely uncontroversial. As it stands, it is just imperfect
enough for people to offer alternatives. Fine. Please do. Maybe there
is a better option, but I'm getting to think not.

A few people over the years have tried to think up more purely
syntactic solutions like your ...

>    int r = x#acquire; // read acquire
>    x#release = 10; // write release
>    boolean r = x#volatile === expect : new; // volatile compare-and-set

The main argument against them is that we now know that the
set of operations is likely to grow over time, so any solution
should make reference to an API.

-Doug


From aaron.grunthal at infinite-source.de  Fri Jan 17 14:32:34 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Fri, 17 Jan 2014 20:32:34 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D964E4.6020506@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D8F9D7.3050100@univ-mlv.fr>	<52D94032.5060905@cs.oswego.edu>
	<52D964E4.6020506@univ-mlv.fr>
Message-ID: <52D98552.2000703@infinite-source.de>

I imagine type safety for Reference-Arrays that are not Object[] would 
be an issue. How can we reduce that to compile-time checks?

Expand it to something like

   public void <T> setRelease(Class<T> actualType, T[] array, int index, 
T newValue) {
      ...
   }

and then hope that the compiler can optimize away actualType.cast(newValue)?

- Aaron


On 17.01.2014 18:14, Remi Forax wrote:
> On 01/17/2014 03:37 PM, Doug Lea wrote:
>> On 01/17/2014 04:37 AM, Remi Forax wrote:
>>
>>> I believe it's better to come with a general solution that allow
>>> developers to
>>> trap method calls and replace them by tree of method handles that to
>>> have a
>>> specific syntax just for concurrency.
>>
>> I downplayed in posted JEP draft that we must also support a
>> way to operate on array elements, as in:
>>   int[] a = ...
>>   a[7].volatile.setRelease(17);
>>
>> I don't see a path to this without the .volatile syntax support
>> or something essentially equivalent.
>
> I fail to see the issue here, perhaps it's because the semantics of
> setRelease is very special ?
> Why a method that takes an array an int and a new value is not enough
>
> public class Volatiles {
>    public void setRelease(int[] array, int index, int newValue) {
>       ...
>    }
> }
>
>
>>
>> The reason arrays were not otherwise covered is that it is
>> still a TBD issue whether to allow access to elements in this way
>> for any array, without any type or annotation. Most likely the
>> answer will be yes; anything else hits some language, type,
>> or usability snag.
>
> You don't have a similar issue with a field ?
>
>>
>> -Doug
>
> R?mi
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From mikeb01 at gmail.com  Fri Jan 17 14:44:38 2014
From: mikeb01 at gmail.com (Michael Barker)
Date: Sat, 18 Jan 2014 08:44:38 +1300
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52CDB41C.70601@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>
Message-ID: <CALwNKeSzZ_bi34ihasQCmSeePCXL6fF1e3jWhJkyxoUHGTRgLQ@mail.gmail.com>

>
>
>     class Usage {
>         volatile int count;
>         int incrementCount() {
>             return count.volatile.incrementAndGet();
>         }
>     }
>

Would fields require the volatile modifier or could this be applied to any
field?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140118/69afd422/attachment.html>

From oleksandr.otenko at oracle.com  Fri Jan 17 14:49:38 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 17 Jan 2014 19:49:38 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D96712.50507@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr> <52D93308.7060103@oracle.com>
	<52D934E5.4020101@oracle.com> <52D96712.50507@univ-mlv.fr>
Message-ID: <52D98952.2080209@oracle.com>

On 17/01/2014 17:23, Remi Forax wrote:
> On 01/17/2014 02:49 PM, Oleksandr Otenko wrote:
>> In the sense that I like it.
>
> Yes, it's like C macro. But the macro expansion is done by the JIT and 
> it's typesafe.
I am thinking it is more like a Lisp macro, though.


>>
>> I wonder if it would be possible to use a similar technique to write 
>> parameterized code, prove it is safe, once, and then reuse by 
>> plugging it as "a method handle tree" that you are talking about, 
>> providing parameters at call sites.
>>
>> (compare:
>>
>> queue.poll()
>> queue.poll(timeout)
>> queue.take()
>>
>> - that's 3x the concurrent methods that do essentially the same thing;
>
> more or less, poll() can be lock free while take() can't.

They have more in common than different. They assume the same things 
about the concurrent communication about contenders. So the best way to 
ensure the contenders follow the same protocol is to actually use the 
same steps.


>>
>>
>> queue.offer(a)
>> queue.offer(a,timeout)
>> queue.put(a)
>>
>> that's another 3x the concurrent methods that do essentially the same 
>> thing.
>>
>> Now technically need to test all permutations of all methods 
>> executing concurrently, whereas it would suffice to test one pair 
>> (the others being parameterized by non-essential stuff, plugged as 
>> lambdas).
>
> No, because the code inside the method handle tree can do side effect 
> so a code with a method handle or without it doesn't exhibit the same 
> property from a concurrency point of view.

Well, I've seen several places where I could get immense help from macros.


Alex


>>
>> Alex
>
> R?mi
>
>>
>>
>>
>> On 17/01/2014 13:41, Oleksandr Otenko wrote:
>>> Sounds like Java macros.
>>>
>>>
>>> Alex
>>>
>>>
>>> On 17/01/2014 09:37, Remi Forax wrote:
>>>> On 01/13/2014 09:16 PM, Doug Lea wrote:
>>>>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>>>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>>>>> I don't remember if this has been covered already...  One 
>>>>>>> problem with
>>>>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>>>>> branches
>>>>>>> that have to be executed.  For example, compareAndSet has 6
>>>>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>>>>> directly.
>>>>>
>>>>> Yes, this is the main problem we are trying to solve.
>>>>>
>>>>>> The question is how many of those checks the JVM can eliminate or 
>>>>>> would be necessary anyway at those callsites.
>>>>>
>>>>> Nothing less than eliminating all of them will be acceptable for 
>>>>> target users.
>>>>> The FieldUpdater approach falls into the reflection-in-disguise
>>>>> category, which hasn't been amenable to this.
>>>>> The .volatile solution can in principle generate overhead-less
>>>>> optimal code. It will take some hard work to make this happen though.
>>>>
>>>> I've written a small proof of concept of how this can work and 
>>>> there are so good news and some things that must be improved.
>>>>
>>>> First, you can separate the problem in two independant questions, 
>>>> one is the .volatile syntax and the other is how to talk to the JIT 
>>>> to avoid those stupid runtime checks.
>>>>
>>>> For the former question, I see several good reasons to not use the 
>>>> .volatile syntax.
>>>> The first one is that the syntax doesn't cover all use cases, you 
>>>> can not do a double CAS with the .volatile syntax by example, 
>>>> because the syntax consider only one field.
>>>> The second one, is a problem that I have discovered only when 
>>>> coding a solution, the world that the VM see and the world that 
>>>> Java proposes to an user are not perfectly aligned. In Java, you 
>>>> can access to a private field of an inner class from the enclosing 
>>>> class (and vice versa). The VM can not do that. The compiler bridge 
>>>> that gap by generating getter and setter (the access$xxx method). 
>>>> Obviously, the .volatile syntax can not use the same trick and will 
>>>> have at runtime to do some check and bypass the security model. 
>>>> While it's not a dig deal because the check can be done once for 
>>>> all, it means that you offer a possible angle of attack from the 
>>>> security perspective because the code has to elevate its privilege.
>>>> The third one is more conceptual, if Java offers a specific syntax 
>>>> for concurrency, uses will want a specific syntax for any other 
>>>> fields like by example a specific syntax for HPC.
>>>>
>>>> Basically, what we want is to have an intrinsic, like a C++ 
>>>> instrinsic provided by the C++ compiler, also like a VM instrinsic 
>>>> that transform a method like unsafe.compareAndSwapObject to 
>>>> assembly code.
>>>> That's why I think it's better to provide an instrinsic-like 
>>>> mechanism that will replace a call to a Java method to a specific 
>>>> sequence of bytecodes. We have the tool for specifying the sequence 
>>>> of bytecode it's the method handle combiners of the package 
>>>> java.lang.invoke. All we need is something in the Java compiler 
>>>> that says, the call to this method is not a classical Java code but 
>>>> a call to something that will be turned to a method handle tree, 
>>>> i.e. a call through invokedynamic.
>>>>
>>>> Using invokedynamic and the method handles are the answer to the 
>>>> question 2, the .volatile syntax will use invokedynamic, the 
>>>> instrinsic-like mecanism I propose will use invokedynamic. That's 
>>>> why I think it's important so separate the discussion about the 
>>>> syntax from the discussion about how to about the class check at 
>>>> runtime.
>>>>
>>>> So let me explain how to code a Java instrinsic in Java.
>>>> You need two parts, the first one is the declaration of methods 
>>>> that will be turned to an intrinsic.
>>>> This can be done by writing a classical method that throw an error. 
>>>> The method body will be never called, the method is just here for 
>>>> the typechecking.
>>>> The second part is that javac has to know that this method is an 
>>>> intrinsic, using a keyword by example,
>>>> and generate an invokedynamic instead of the callsicall invoke* 
>>>> bytecode.
>>>> And at runtime, the first time that a method tagged intrinsic will 
>>>> be called for a callsite,
>>>> the VM will call the bootstrap method.
>>>>
>>>> Here is an example for compareAndSet:
>>>> public class Volatiles {
>>>>   public static intrinsic boolean compareAndSet(String fieldName, 
>>>> Object current, int expected, int newValue) {
>>>>     throw new InternalError();
>>>>   }
>>>>
>>>>   public static intrinsic <T> boolean compareAndSet(String 
>>>> fieldName, Object current, T expected, T newValue) {
>>>>     throw new InternalError();
>>>>   }
>>>>
>>>>   public static CallSite bootstrap(Lookup lookup, String name, 
>>>> MethodType type, MethodHandle impl) {
>>>>     ...
>>>>   }
>>>> }
>>>>
>>>> and it will be used that way:
>>>> public class Linked {
>>>>   private volatile Node head;
>>>>
>>>>   private boolean compareAndSet(Node expected, Node newValue) {
>>>>     return Volatiles.compareAndSet("head", this, expected, newValue);
>>>>   }
>>>> ...
>>>>
>>>> Here I know what you think, it uses a String, it will do 
>>>> reflection, it will be slow,
>>>> obviously the answer is no.
>>>> Let me detail how it works, first you can notice that you don't 
>>>> have to specify the class,
>>>> when the bootstrap method is called, the Lookup parameter contains 
>>>> the class that call
>>>> the method so it's not needed and it's even better, it restrict the 
>>>> API because it
>>>> can only be used to access to a member that is declared in the 
>>>> class to call
>>>> "Volatiles.compareAndSet" so there is no security privilege 
>>>> enhancement,
>>>> it fully relies on the Lookup object for doing the security check 
>>>> so no potential new security hole.
>>>>
>>>> Now the string parameter, Java has no way to reference a field so 
>>>> you need to send the name
>>>> of the field, but there is a trick here. The implementation use the 
>>>> method handle guardWithTest
>>>> (a glorified 'if') to check that the String will never changed 
>>>> (doing a pointer check),
>>>> The things is that if the API is used correctly, the string will be 
>>>> always a string literal so
>>>> the JIT will prove easily that the String never changed so will 
>>>> just remove the pointer check.
>>>> The else branch throws an exception to inform the user of the API 
>>>> that the String must be a constant.
>>>> This trick allows to specify the field to be updated in a nice way 
>>>> (just a string) without any performance penalty.
>>>>
>>>> Now, how to get ride of the value check that check dynamically that 
>>>> you can not use Volatiles.compareAndSet to set a String inside the 
>>>> field 'head'.
>>>> The trick here is to ask the compiler to do a little more work that 
>>>> usual when computing the signature of the invokedynamic call. 
>>>> Instead of using the signature of Volatiles.compareAndSet which is 
>>>> (String, Object, Object, Object)boolean due to the erasure, javac 
>>>> will use the type of the expression found during the typechecking 
>>>> phase (this is something javac already does for signature 
>>>> polymorphic method like MethodHandle.invokeExact, so no big deal). 
>>>> Here in the example, the signature of invokedynamic will be 
>>>> (String, Linked, Node, Node)boolean. That the the signature convey 
>>>> the real type information, the boostrap method can check once that 
>>>> the type of newValue is correct with respect to the type of the 
>>>> field. Note: technically it can not be done in the bootstrap method 
>>>> because to get the field you need the field name and the bootstrap 
>>>> method doesn't have the argument. But the usual trick, is to 
>>>> register a method that will be called the first time in the 
>>>> boostrap method and in the method, the code have access to the 
>>>> value of the first call. At the end of the method, the method will 
>>>> relink the call site with the method handle tree that call 
>>>> unsafe.compareAndSwapObject. Basically, it just an extra level of 
>>>> indirection for the first call. Not something that the JIT will see 
>>>> because when the JIT will be triggered there will be no reference 
>>>> to that intermediary method anymore.
>>>>
>>>> The signature trick allows also to get ride of the check that 
>>>> verifie that the second parameter is an object of the current class 
>>>> ('this' in the example).
>>>>
>>>> Now, I've done some simple test to check that the JIT was really 
>>>> able to not insert check and correctly generate the same code as 
>>>> calling directly Unsafe.compareAndSwapObject.
>>>> It mostly work, the JIT correctly remove the String pointer check, 
>>>> but it insert two null supplementary checks that verifies that 
>>>> expected and newValue are not null when I compare with a code that 
>>>> use Unsafe.compareAndSwapObject directly.
>>>>
>>>> I believe (I may be wrong, hence John and Christian in CC) that, 
>>>> these checks are artifacts that comes from the way the method 
>>>> handle tree is transformed to assembly code, the lambda form.
>>>> Lambda forms internally erases the types to Object and use a 
>>>> Class.cast to ensure safety, Class.cast is transformed to an 
>>>> instanceof. The part that check the class hierarchy of instanceof 
>>>> is removed because Unsafe.compareAndSwapObject use Object as 
>>>> parameter but the null check still float around.
>>>>
>>>> I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
>>>> removed now.
>>>>
>>>> In conclusion, we are close enough (far more close that I was 
>>>> thinking initially) to provide a solution that allow people to have 
>>>> the performance of unsafe.compareAndSwapObject without the unsafe bits
>>>> I believe it's better to come with a general solution that allow 
>>>> developers to trap method calls and replace them by tree of method 
>>>> handles that to have a specific syntax just for concurrency.
>>>>
>>>> regards,
>>>> R?mi
>>>>
>>>> Here is the full code of the bootstrap method:
>>>> public static CallSite bootstrap(Lookup lookup, String name, 
>>>> MethodType type, MethodHandle impls) {
>>>>     if (type.parameterType(1) != lookup.lookupClass()) {
>>>>       throw new LinkageError("the second parameter of compareAndSet 
>>>> must be this");
>>>>     }
>>>>
>>>>     // also check that the parameter(2) and parameter(3) have the 
>>>> same type
>>>>     if (type.parameterType(2) != type.parameterType(3)) {
>>>>       throw new LinkageError("expected value and new value should 
>>>> have the same type");
>>>>     }
>>>>
>>>>     MethodHandle fallback;
>>>>     if (type.parameterType(2) == int.class) {
>>>>       throw new AssertionError("NIY");
>>>>     } else {
>>>>       fallback = CASCallSite.FALLBACK_OBJECT;
>>>>     }
>>>>
>>>>     return new CASCallSite(lookup, type, fallback);
>>>>   }
>>>>
>>>>   static final Unsafe UNSAFE;
>>>>   static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>>>>   static {
>>>>     Unsafe unsafe;
>>>>     try {
>>>>       Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>>>>       theUnsafe.setAccessible(true);
>>>>       unsafe = (Unsafe)theUnsafe.get(null);
>>>>     } catch (NoSuchFieldException | IllegalAccessException e) {
>>>>       throw new AssertionError(e);
>>>>     }
>>>>     UNSAFE = unsafe;
>>>>
>>>>     MethodHandle unsafeMH;
>>>>     Lookup lookup = MethodHandles.lookup();
>>>>     try {
>>>>       CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class, 
>>>> "checkFieldName",
>>>>           MethodType.methodType(boolean.class, String.class, 
>>>> String.class));
>>>>       THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>>>>           MethodType.methodType(boolean.class));
>>>>       unsafeMH = lookup.findVirtual(Unsafe.class, 
>>>> "compareAndSwapObject",
>>>>           MethodType.methodType(boolean.class, Object.class, 
>>>> long.class, Object.class, Object.class));
>>>>     } catch (NoSuchMethodException | IllegalAccessException e) {
>>>>       throw new AssertionError(e);
>>>>     }
>>>>     UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>>>>   }
>>>>
>>>>   @SuppressWarnings("unused")  // used by a method handle
>>>>   private static boolean checkFieldName(String expected, String 
>>>> value) {
>>>>     return expected == value;
>>>>   }
>>>>
>>>>   @SuppressWarnings("unused")  // used by a method handle
>>>>   private static boolean throwError() {
>>>>     throw new IllegalStateException("the field name must be 
>>>> constant");
>>>>   }
>>>>
>>>>   static class CASCallSite extends MutableCallSite {
>>>>     static MethodHandle FALLBACK_OBJECT;
>>>>     static {
>>>>       try {
>>>>         FALLBACK_OBJECT = 
>>>> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>>>>             MethodType.methodType(boolean.class, String.class, 
>>>> Object.class, Object.class, Object.class));
>>>>       } catch (NoSuchMethodException | IllegalAccessException e) {
>>>>         throw new AssertionError(e);
>>>>       }
>>>>     }
>>>>
>>>>     private final Lookup lookup;
>>>>
>>>>     CASCallSite(Lookup lookup, MethodType type, MethodHandle 
>>>> fallback) {
>>>>       super(type);
>>>>       this.lookup = lookup;
>>>>       setTarget(fallback.bindTo(this).asType(type));
>>>>     }
>>>>
>>>>     boolean fallback(String name, Object self, Object expected, 
>>>> Object newValue) throws Throwable {
>>>>       MethodHandle getter;
>>>>       try {
>>>>         getter = lookup.findGetter(lookup.lookupClass(), name, 
>>>> type().parameterType(2));
>>>>         // use a horrible workaround
>>>>         //getter = lookup.findGetter(lookup.lookupClass(), name, 
>>>> newValue.getClass());
>>>>       } catch (NoSuchFieldException | IllegalAccessException e) {
>>>>         throw new IllegalStateException(e);
>>>>       }
>>>>       Field field = MethodHandles.reflectAs(Field.class, getter);
>>>>       long offset = UNSAFE.objectFieldOffset(field);
>>>>       MethodHandle target = 
>>>> MethodHandles.insertArguments(UNSAFE_CAS, 1, offset);
>>>>       MethodHandle unsafeCas = MethodHandles.dropArguments(target, 
>>>> 0, String.class);
>>>>       MethodHandle throwError = 
>>>> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>>>>       MethodHandle guard = 
>>>> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name), 
>>>> unsafeCas.asType(type()), throwError);
>>>>       setTarget(guard);
>>>>       return (boolean)target.invokeExact(self, expected, newValue);
>>>>     }
>>>>   }
>>>>
>>>>>
>>>>>
>>>>> -Doug
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>


From aaron.grunthal at infinite-source.de  Fri Jan 17 15:24:39 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Fri, 17 Jan 2014 21:24:39 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D9823F.6000702@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>
	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<52D971E3.80903@gmail.com> <52D9823F.6000702@cs.oswego.edu>
Message-ID: <52D99187.6010803@infinite-source.de>

On 17.01.2014 20:19, Doug Lea wrote:
>
> If the two senses had different symbols in Java, I suspect that this
> would be completely uncontroversial. As it stands, it is just imperfect
> enough for people to offer alternatives. Fine. Please do. Maybe there
> is a better option, but I'm getting to think not.

Ok, since Peter's benchmarks seem to suggest that an alternative 
implementation for FieldUpdaters would work after all I would suggest 
less sugar that does more:


public class MyClass {

   private Object foo;


   public static RefFieldHandle<MyClass, Object> getFooFieldHandle() {
     return this#foo
   }

   public static BiConsumer<MyClass, Object> getUnboundFooSetter() {
     return this#foo::set;
   }

   public Consumer<Object> getBoundVolatileFooSetter() {
     return x -> this#foo.setVolatile(this, x)
   }

   // or even simpler, make the internal handle public
   // of course this completely bypasses the private field
   // but so do regular setters
   public static final RefFieldHandle<MyClass, Object> FOO = this#foo;
}


this#foo would be syntactic sugar for having the compiler add an 
Unsafe/MethodHandle based field updater to the constant pool of the 
class and return that constant.

this#foo::set then gives you a method reference to the setter of the 
field updater. I.e. it's bound to the FieldHandle instance in the 
constant pool but not bound to an instance of MyClass. Its signature is 
equivalent to (Myclass, Object)void.

As far as I understand all this can be optimized to 1 instance of the 
FieldUpdater and 1 instance of MethodHandle.

Only the getBoundFooSetter() method would create new MH Objects at 
runtime (i.e. more garbage), and even those might get optimized away in 
some cases.

We could also disambiguate different field types:

static#foo for static fields
this#foo for instance fields
MyClass#foo for cla... oh wait, we don't have those. :P


For arrays we also have to create an appropriate ArrayUpdater in the 
constant pool of the arrays's class.

MyClass[]#atomic would get you the Updater
MyClass[]#atomic::set gives you a method reference equivalent to 
(MyClass[], MyClass)void

or if the "atomic" seems superfluous:

MyClass[]# for the updater
MyClass[]#::set for the method reference



- Aaron

From aaron.grunthal at infinite-source.de  Fri Jan 17 16:12:19 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Fri, 17 Jan 2014 22:12:19 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D17C99.2040706@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D17416.30506@infinite-source.de>
	<52D17C99.2040706@cs.oswego.edu>
Message-ID: <52D99CB3.20605@infinite-source.de>

Can I assume adding new bytecodes for atomic ops has been ruled a larger 
evil than intrinsics and monkeying with invokedynamic due to reasons I 
am not aware of?

- Aaron

On 11.01.2014 18:17, Doug Lea wrote:
>
> JVMs do not support internal pointers. There are a lot of good reasons
> they don't, and a lot of JVM internals would be impacted if they did.
> And anything short of that is either special-casing (as here) or
> reflection in disguise (with java.lang.reflect.Field etc), or, as
> you pointed out in previous mail, using methods with lambda arguments.
> Which I think you made a good argument for: Lambda-based works best
> in cases where semantics matter but performance doesn't.
> We'd like to get past the decade-long discussions that amount to
> whining about this state of affairs and implement an effective
> efficient solution.


From dl at cs.oswego.edu  Fri Jan 17 20:10:55 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 17 Jan 2014 20:10:55 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <CALwNKeSzZ_bi34ihasQCmSeePCXL6fF1e3jWhJkyxoUHGTRgLQ@mail.gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>
	<CALwNKeSzZ_bi34ihasQCmSeePCXL6fF1e3jWhJkyxoUHGTRgLQ@mail.gmail.com>
Message-ID: <52D9D49F.1000900@cs.oswego.edu>

On 01/17/2014 02:44 PM, Michael Barker wrote:
>
>          class Usage {
>              volatile int count;
>              int incrementCount() {
>                  return count.volatile.__incrementAndGet();
>              }
>          }
>
>
> Would fields require the volatile modifier or could this be applied to any field?

Sorry to be evasive for now, but I'll defer answering until there
is some progress on JMM revisions that might provide semantics for
mixed-mode fields.

-Doug


From dl at cs.oswego.edu  Fri Jan 17 20:16:07 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 17 Jan 2014 20:16:07 -0500
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D99CB3.20605@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D17416.30506@infinite-source.de>
	<52D17C99.2040706@cs.oswego.edu>
	<52D99CB3.20605@infinite-source.de>
Message-ID: <52D9D5D7.5020400@cs.oswego.edu>

On 01/17/2014 04:12 PM, Aaron Grunthal wrote:
> Can I assume adding new bytecodes for atomic ops has been ruled a larger evil
> than intrinsics and monkeying with invokedynamic due to reasons I am not aware of?
>

I'm not in charge of such things, but adding bytecodes is traumatic
enough to be done only rarely, but multicores etc evolve fast
enough that revisiting intrinsics every 2 years or so for major
releases is just barely often enough.

-Doug



From aaron.grunthal at infinite-source.de  Fri Jan 17 21:59:29 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Sat, 18 Jan 2014 03:59:29 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D99187.6010803@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D971E3.80903@gmail.com>
	<52D9823F.6000702@cs.oswego.edu>
	<52D99187.6010803@infinite-source.de>
Message-ID: <52D9EE11.4070904@infinite-source.de>

On 17.01.2014 21:24, Aaron Grunthal wrote:
> MyClass[]#atomic::set gives you a method reference equivalent to
> (MyClass[], MyClass)void

That was meant to be (MyClass[], int, MyClass)void

From forax at univ-mlv.fr  Sat Jan 18 04:48:36 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Sat, 18 Jan 2014 10:48:36 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <187ecc99bba94e39bfc5de7b7fd8ffae@exchmb01.office.devexperts.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>
	<52D8F9D7.3050100@univ-mlv.fr>
	<187ecc99bba94e39bfc5de7b7fd8ffae@exchmb01.office.devexperts.com>
Message-ID: <52DA4DF4.5000908@univ-mlv.fr>

On 01/17/2014 11:09 AM, Roman Elizarov wrote:
> Syntax is as important as implementation and its performance. The problem with "String fieldName" is that it looks like a string in a source code and even if javac knows that the method is intrinsic and does the actual compile-time checking that the string is constant and refers to the actual field, it still looks scripty, hacky, and ugly in the source code. It is an improvement upon AtomicFieldUpdater classes in terms of performance, but it offers no improvement in terms of syntax. I write a lot of code with volatiles/Unsafe and I don't want it to look ugly. It becomes hard to maintain and buggy, because of bad syntax of both Unsafe and AFU ways.
>
> I will **very much*** prefer this:
>
> 	head.volatile.compareAndSet(expected, newValue)
>
> to this:
>
> 	Volatiles.compareAndSet("head", this, expected, newValue)
>
> The concern of "specific syntax for concurrency" is legit, but moot, because Java _already_ has a lot of specific syntax for concurrency (but no specific syntax for HPC, for example) and extending Java's concurrency syntax does not break the spirit of Java, but enhances it.
>
> Actually, I would consider the second syntax to be a total failure to give Java a good concurrency library, regardless of its performance. If giving Java a specific syntax for concurrency is indeed a concern, then consider supporting field handles in Java instead. I can live with something like this:
>
> 	Volatiles.compareAndSet(this::head, expected, newValue)
>
> Sincerely,
> Roman Elizarov

yes,
a String is less typesafe than a dedicated syntax but it's because we 
don't have a field reference syntax in Java. The 'right' API should be

   Volatiles.compareAndSet(Linked::head, this, expected, newValue)


regards,
R?mi

>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Remi Forax
> Sent: Friday, January 17, 2014 1:37 PM
> To: concurrency-interest at cs.oswego.edu
> Cc: Christian Thalinger; John Rose
> Subject: Re: [concurrency-interest] JDK9 concurrency preliminaries
>
> On 01/13/2014 09:16 PM, Doug Lea wrote:
>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>> I don't remember if this has been covered already...  One problem
>>>> with the Atomic___FieldUpdater classes is that there are a bunch of
>>>> branches that have to be executed.  For example, compareAndSet has 6
>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>> directly.
>> Yes, this is the main problem we are trying to solve.
>>
>>> The question is how many of those checks the JVM can eliminate or
>>> would be necessary anyway at those callsites.
>> Nothing less than eliminating all of them will be acceptable for
>> target users.
>> The FieldUpdater approach falls into the reflection-in-disguise
>> category, which hasn't been amenable to this.
>> The .volatile solution can in principle generate overhead-less optimal
>> code. It will take some hard work to make this happen though.
> I've written a small proof of concept of how this can work and there are so good news and some things that must be improved.
>
> First, you can separate the problem in two independant questions, one is the .volatile syntax and the other is how to talk to the JIT to avoid those stupid runtime checks.
>
> For the former question, I see several good reasons to not use the .volatile syntax.
> The first one is that the syntax doesn't cover all use cases, you can not do a double CAS with the .volatile syntax by example, because the syntax consider only one field.
> The second one, is a problem that I have discovered only when coding a solution, the world that the VM see and the world that Java proposes to an user are not perfectly aligned. In Java, you can access to a private field of an inner class from the enclosing class (and vice versa). The VM can not do that. The compiler bridge that gap by generating getter and setter (the access$xxx method). Obviously, the .volatile syntax can not use the same trick and will have at runtime to do some check and bypass the security model. While it's not a dig deal because the check can be done once for all, it means that you offer a possible angle of attack from the security perspective because the code has to elevate its privilege.
> The third one is more conceptual, if Java offers a specific syntax for concurrency, uses will want a specific syntax for any other fields like by example a specific syntax for HPC.
>
> Basically, what we want is to have an intrinsic, like a C++ instrinsic provided by the C++ compiler, also like a VM instrinsic that transform a method like unsafe.compareAndSwapObject to assembly code.
> That's why I think it's better to provide an instrinsic-like mechanism that will replace a call to a Java method to a specific sequence of bytecodes. We have the tool for specifying the sequence of bytecode it's the method handle combiners of the package java.lang.invoke. All we need is something in the Java compiler that says, the call to this method is not a classical Java code but a call to something that will be turned to a method handle tree, i.e. a call through invokedynamic.
>
> Using invokedynamic and the method handles are the answer to the question 2, the .volatile syntax will use invokedynamic, the instrinsic-like mecanism I propose will use invokedynamic. That's why I think it's important so separate the discussion about the syntax from the discussion about how to about the class check at runtime.
>
> So let me explain how to code a Java instrinsic in Java.
> You need two parts, the first one is the declaration of methods that will be turned to an intrinsic.
> This can be done by writing a classical method that throw an error. The method body will be never called, the method is just here for the typechecking.
> The second part is that javac has to know that this method is an intrinsic, using a keyword by example, and generate an invokedynamic instead of the callsicall invoke* bytecode.
> And at runtime, the first time that a method tagged intrinsic will be called for a callsite, the VM will call the bootstrap method.
>
> Here is an example for compareAndSet:
> public class Volatiles {
>     public static intrinsic boolean compareAndSet(String fieldName, Object current, int expected, int newValue) {
>       throw new InternalError();
>     }
>
>     public static intrinsic <T> boolean compareAndSet(String fieldName, Object current, T expected, T newValue) {
>       throw new InternalError();
>     }
>
>     public static CallSite bootstrap(Lookup lookup, String name, MethodType type, MethodHandle impl) {
>       ...
>     }
> }
>
> and it will be used that way:
> public class Linked {
>     private volatile Node head;
>
>     private boolean compareAndSet(Node expected, Node newValue) {
>       return Volatiles.compareAndSet("head", this, expected, newValue);
>     }
> ...
>
> Here I know what you think, it uses a String, it will do reflection, it will be slow, obviously the answer is no.
> Let me detail how it works, first you can notice that you don't have to specify the class, when the bootstrap method is called, the Lookup parameter contains the class that call the method so it's not needed and it's even better, it restrict the API because it can only be used to access to a member that is declared in the class to call "Volatiles.compareAndSet" so there is no security privilege enhancement, it fully relies on the Lookup object for doing the security check so no potential new security hole.
>
> Now the string parameter, Java has no way to reference a field so you need to send the name of the field, but there is a trick here. The implementation use the method handle guardWithTest (a glorified 'if') to check that the String will never changed (doing a pointer check), The things is that if the API is used correctly, the string will be always a string literal so the JIT will prove easily that the String never changed so will just remove the pointer check.
> The else branch throws an exception to inform the user of the API that the String must be a constant.
> This trick allows to specify the field to be updated in a nice way (just a string) without any performance penalty.
>
> Now, how to get ride of the value check that check dynamically that you can not use Volatiles.compareAndSet to set a String inside the field 'head'.
> The trick here is to ask the compiler to do a little more work that usual when computing the signature of the invokedynamic call. Instead of using the signature of Volatiles.compareAndSet which is (String, Object, Object, Object)boolean due to the erasure, javac will use the type of the expression found during the typechecking phase (this is something javac already does for signature polymorphic method like MethodHandle.invokeExact, so no big deal). Here in the example, the signature of invokedynamic will be (String, Linked, Node, Node)boolean.
> That the the signature convey the real type information, the boostrap method can check once that the type of newValue is correct with respect to the type of the field. Note: technically it can not be done in the bootstrap method because to get the field you need the field name and the bootstrap method doesn't have the argument. But the usual trick, is to register a method that will be called the first time in the boostrap method and in the method, the code have access to the value of the first call. At the end of the method, the method will relink the call site with the method handle tree that call unsafe.compareAndSwapObject.
> Basically, it just an extra level of indirection for the first call. Not something that the JIT will see because when the JIT will be triggered there will be no reference to that intermediary method anymore.
>
> The signature trick allows also to get ride of the check that verifie that the second parameter is an object of the current class ('this' in the example).
>
> Now, I've done some simple test to check that the JIT was really able to not insert check and correctly generate the same code as calling directly Unsafe.compareAndSwapObject.
> It mostly work, the JIT correctly remove the String pointer check, but it insert two null supplementary checks that verifies that expected and newValue are not null when I compare with a code that use Unsafe.compareAndSwapObject directly.
>
> I believe (I may be wrong, hence John and Christian in CC) that, these checks are artifacts that comes from the way the method handle tree is transformed to assembly code, the lambda form.
> Lambda forms internally erases the types to Object and use a Class.cast to ensure safety, Class.cast is transformed to an instanceof. The part that check the class hierarchy of instanceof is removed because Unsafe.compareAndSwapObject use Object as parameter but the null check still float around.
>
> I use a fairly old build (jdk8b155) so perhaps, these artifacts are removed now.
>
> In conclusion, we are close enough (far more close that I was thinking
> initially) to provide a solution that allow people to have the performance of unsafe.compareAndSwapObject without the unsafe bits I believe it's better to come with a general solution that allow developers to trap method calls and replace them by tree of method handles that to have a specific syntax just for concurrency.
>
> regards,
> R?mi
>
> Here is the full code of the bootstrap method:
> public static CallSite bootstrap(Lookup lookup, String name, MethodType type, MethodHandle impls) {
>       if (type.parameterType(1) != lookup.lookupClass()) {
>         throw new LinkageError("the second parameter of compareAndSet must be this");
>       }
>
>       // also check that the parameter(2) and parameter(3) have the same type
>       if (type.parameterType(2) != type.parameterType(3)) {
>         throw new LinkageError("expected value and new value should have the same type");
>       }
>
>       MethodHandle fallback;
>       if (type.parameterType(2) == int.class) {
>         throw new AssertionError("NIY");
>       } else {
>         fallback = CASCallSite.FALLBACK_OBJECT;
>       }
>
>       return new CASCallSite(lookup, type, fallback);
>     }
>
>     static final Unsafe UNSAFE;
>     static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>     static {
>       Unsafe unsafe;
>       try {
>         Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>         theUnsafe.setAccessible(true);
>         unsafe = (Unsafe)theUnsafe.get(null);
>       } catch (NoSuchFieldException | IllegalAccessException e) {
>         throw new AssertionError(e);
>       }
>       UNSAFE = unsafe;
>
>       MethodHandle unsafeMH;
>       Lookup lookup = MethodHandles.lookup();
>       try {
>         CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class,
> "checkFieldName",
>             MethodType.methodType(boolean.class, String.class, String.class));
>         THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>             MethodType.methodType(boolean.class));
>         unsafeMH = lookup.findVirtual(Unsafe.class, "compareAndSwapObject",
>             MethodType.methodType(boolean.class, Object.class, long.class, Object.class, Object.class));
>       } catch (NoSuchMethodException | IllegalAccessException e) {
>         throw new AssertionError(e);
>       }
>       UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>     }
>
>     @SuppressWarnings("unused")  // used by a method handle
>     private static boolean checkFieldName(String expected, String value) {
>       return expected == value;
>     }
>
>     @SuppressWarnings("unused")  // used by a method handle
>     private static boolean throwError() {
>       throw new IllegalStateException("the field name must be constant");
>     }
>
>     static class CASCallSite extends MutableCallSite {
>       static MethodHandle FALLBACK_OBJECT;
>       static {
>         try {
>           FALLBACK_OBJECT =
> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>               MethodType.methodType(boolean.class, String.class, Object.class, Object.class, Object.class));
>         } catch (NoSuchMethodException | IllegalAccessException e) {
>           throw new AssertionError(e);
>         }
>       }
>
>       private final Lookup lookup;
>
>       CASCallSite(Lookup lookup, MethodType type, MethodHandle fallback) {
>         super(type);
>         this.lookup = lookup;
>         setTarget(fallback.bindTo(this).asType(type));
>       }
>
>       boolean fallback(String name, Object self, Object expected, Object
> newValue) throws Throwable {
>         MethodHandle getter;
>         try {
>           getter = lookup.findGetter(lookup.lookupClass(), name, type().parameterType(2));
>           // use a horrible workaround
>           //getter = lookup.findGetter(lookup.lookupClass(), name, newValue.getClass());
>         } catch (NoSuchFieldException | IllegalAccessException e) {
>           throw new IllegalStateException(e);
>         }
>         Field field = MethodHandles.reflectAs(Field.class, getter);
>         long offset = UNSAFE.objectFieldOffset(field);
>         MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS,
> 1, offset);
>         MethodHandle unsafeCas = MethodHandles.dropArguments(target, 0, String.class);
>         MethodHandle throwError =
> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>         MethodHandle guard =
> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name),
> unsafeCas.asType(type()), throwError);
>         setTarget(guard);
>         return (boolean)target.invokeExact(self, expected, newValue);
>       }
>     }
>
>>
>> -Doug
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Sat Jan 18 04:54:06 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Sat, 18 Jan 2014 10:54:06 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu> <52D03CB6.8000307@univ-mlv.fr>
	<52D13633.5000706@cs.oswego.edu> <52D971E3.80903@gmail.com>
	<52D97CCE.9050005@univ-mlv.fr>
	<1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>
Message-ID: <52DA4F3E.30301@univ-mlv.fr>

On 01/18/2014 03:19 AM, David Lloyd wrote:
> Nah that syntax kinda sucks - it's obviously just a hack.  What about being a bit more bold and adding an actual "in vs inout" method parameter mechanism to JVM and JLS?  Then the method could just be a plain intrinsic.
>
> --
> - DML

Hi David,
It will never happen,
inout => pointer aliasing => rewrite all interpreters and JITs => not 
Java anymore.

cheers,
R?mi

>
>
>> On Jan 17, 2014, at 1:07 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>
>> On 01/17/2014 07:09 PM, Peter Levart wrote:
>>
>> [...]
>>
>>> Hi,
>>>
>>> The ".volatile" syntax is not really unusual. It looks familiar. It looks like an expression producing an object, but it isn't. In that respect it is not "orthogonal" to other language features. It feels like a language hack. I was thinking of an alternative (really rather unusual) syntax which would be a combination of "marks" for fields requesting particular memory ordering and additional syntax for some operations. Since lambdas and method references didn't "burn" the famous hash character '#', what about the following syntax:
>>>
>>> class C {
>>>   int x;
>>>
>>> ...
>>>
>>>   // atomic reads/writes
>>>
>>>   int r = x#volatile // volatile read
>>>
>>>   x#volatile = 10; // volatile write
>>>
>>>   int r = x#acquire; // read acquire
>>>
>>>   x#release = 10; // write release
>>>
>>>   int r = x#relaxed; // relaxed read (only atomicity guaranteed)
>>>
>>>   x#relaxed = 10; // relaxed write
>>>
>>>
>>>   // CAS
>>>
>>>   boolean r = x#volatile === expect : new; // volatile compare-and-set
>>>
>>>   boolean r = x#acquire === expect : new; // compare-and-set acquire
>>>
>>>   boolean r = x#release === expect : new; // compare-and-set release
>>>
>>>   boolean r = x#relaxed === expect : new; // relaxed (weak?) compare-and-set
>>>
>>>   boolean r = x === expect : new; // non-atomic-neither-guaranteeing-any-visibility conditional set (for locals too)
>>>
>>>   // why '===' ? It is a combination of '==' (compare) and '=' (set) ...
>>>
>>>   // atomic operations
>>>
>>>   int r = ++x#volatile; // volatile increment-and-get
>>>
>>>   int r = x#volatile++; // volatile get-and-increment
>>>
>>>   int r = x#volatile += 3 // volatile add-and-get
>>>
>>>   int r = x#volatile ?+= 3 // volatile get-and-add
>>>
>>>   int r = x#volatile ?= 10; // volatile get-and-set
>>>
>>>   // #acquire, #release, #relaxed variants sensible?
>>>
>>>   int r = x ?+= 3; // non-atomic-neither-guaranteeing-any-visibility "post add" (for locals too)
>>>
>>>   int r = x ?= 10; // non-atomic-neither-guaranteeing-any-visibility "post set" (for locals too)
>>>
>>>   // other in-place atomic operations implemented as read-operation-cas-loop like:
>>>
>>>   int r = x#volatile *= 2; // volatile multiply-and-get
>>>
>>>
>>> Memory ordering marks could be applied to array elements too, of course:
>>>
>>>     array[i]#volatile = 10;
>>>
>>>
>>> Instead of using '#' character to mark fields, I thought about using a dot '.' followed by a reserved word:
>>>
>>>     x.volatile  instead of  x#volatile
>>>     x.try       instead of  x#acquire
>>>     x.finally   instead of  x#release
>>>
>>> ... but I didn't know what to use for relaxed
>>>
>>>     x.do        instead of  x#relaxed  ?
>>>
>>>
>>> Regards, Peter
>> I've forgotten to mention that we had already been bitten by choosing a syntax instead of an API.
>> 'synchronized' can be seen as a nice syntax, but if you take a look to sun.misc.Unsafe you will see a monitorEnter(), monitorExit() and even a tryMonitorEnter() (tryLock on a monitor) because the semantics of a synchronized block was not enough.
>>
>> An API is versatile, a syntax is not.
>>
>> R?mi
>>
>>>
>>>> The main task is to translate these calls into corresponding JVM
>>>> intrinsics. The most likely option is for the source compiler to use
>>>> method handles. This and other techniques are known to suffice, but
>>>> are subject to further exploration.
>>>>
>>>> Here is a tentative VolatileInt interface.  Those for other types are
>>>> similar.  The final released versions will surely differ in small
>>>> ways.
>>>>
>>>>     interface VolatileInt {
>>>>         int get();
>>>>         int getRelaxed();
>>>>         int getAcquire();
>>>>         int getSequential();
>>>>
>>>>         void set(int x);
>>>>         void setRelaxed(int x);
>>>>         void setRelease(int x);
>>>>         void setSequential(int x);
>>>>
>>>>         int getAndSet(int x);
>>>>         boolean compareAndSet(int e, int x);
>>>>         boolean compareAndSetAcquire(int e, int x);
>>>>         boolean compareAndSetRelease(int e, int x);
>>>>         boolean weakCompareAndSet(int e, int x);
>>>>         boolean weakCompareAndSetAcquire(int e, int x);
>>>>         boolean weakCompareAndSetRelease(int e, int x);
>>>>
>>>>         int getAndAdd(int x);
>>>>         int addAndGet(int x);
>>>>         int getAndIncrement();
>>>>         int incrementAndGet();
>>>>         int getAndDecrement();
>>>>         int decrementAndGet();
>>>>     }
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Sat Jan 18 05:21:53 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Sat, 18 Jan 2014 11:21:53 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D9D5D7.5020400@cs.oswego.edu>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D17416.30506@infinite-source.de>	<52D17C99.2040706@cs.oswego.edu>	<52D99CB3.20605@infinite-source.de>
	<52D9D5D7.5020400@cs.oswego.edu>
Message-ID: <52DA55C1.6080608@univ-mlv.fr>

On 01/18/2014 02:16 AM, Doug Lea wrote:
> On 01/17/2014 04:12 PM, Aaron Grunthal wrote:
>> Can I assume adding new bytecodes for atomic ops has been ruled a 
>> larger evil
>> than intrinsics and monkeying with invokedynamic due to reasons I am 
>> not aware of?
>>
>
> I'm not in charge of such things, but adding bytecodes is traumatic
> enough to be done only rarely, but multicores etc evolve fast
> enough that revisiting intrinsics every 2 years or so for major
> releases is just barely often enough.
>
> -Doug

as an anecdote, at some point during the development of the JSR 292,
we realized that instead of 1 new bytecode, we need 5, but because we 
were mandated to add only one new bytecode we overload the meaning of 
two existing bytecodes (ldc and invokevirtual).

R?mi


From peter.levart at gmail.com  Sun Jan 19 09:51:16 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 19 Jan 2014 15:51:16 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D81DFA.6080103@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>
	<52D81DFA.6080103@oracle.com>
Message-ID: <52DBE664.6010409@gmail.com>


On 01/16/2014 06:59 PM, Nathan Reynolds wrote:
> > I don't know why normal bytecode volatile put is 2x faster than 
> Unsafe volatile put.
>
> Consider disassembling the normal bytecode and the Unsafe volatile 
> put.  The disassembly should help give ideas why there is a difference.
>
> This page describes how to print the assembly code of JITed methods.
>
> http://wikis.sun.com/pages/viewpage.action?pageId=212340194
> http://classparser.blogspot.com/2010/03/hsdis-i386dll.html
>
> 1) Copy hsdis-i386.dll to the following locations...  (it should be in 
> the same directory as jvm.dll)
>       C:\Program Files 
> (x86)\Java\jdk1.6.0_25\jre\bin\client\hsdis-i386.dll
>       C:\Program Files 
> (x86)\Java\jdk1.6.0_25\jre\bin\server\hsdis-i386.dll
>       C:\Program Files (x86)\Java\jre6\bin\client\hsdis-i386.dll
>
> 2) Use these command line options:
>       Print all methods
>          -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly
>
>       Print specific method
>          -XX:+UnlockDiagnosticVMOptions 
> -XX:CompileCommand=print,*IntFieldHandlesTest./method/
>          Can put multiple -XX:CompileCommand arguments to filter 
> several methods
>
>         Print Intel syntax add:
>             -XX:PrintAssemblyOptions=intel
>
> -Nathan

Thanks for pointers. Here are the results:

The following method:

     void javaSet(int n) {
         for (int i = 0; i < n; i++) {
             this.x = 0x4321;
         }
     }

...gets compiled several times, but finally with C2 to the following 
amd64 code:

Code:
[Entry Point]
[Constants]
   # {method} {0x00007f339846d700} 'javaSet' '(I)V' in 'IntFieldHandlesTest'
   # this:     rsi:rsi   = 'IntFieldHandlesTest'
   # parm0:    rdx       = int
   #           [sp+0x20]  (sp of caller)
   0x00007f338519d3c0: cmp    0x8(%rsi),%rax
   0x00007f338519d3c4: jne    0x00007f3385045b60  ; {runtime_call}
   0x00007f338519d3ca: xchg   %ax,%ax
   0x00007f338519d3cc: nopl   0x0(%rax)
[Verified Entry Point]
   0x00007f338519d3d0: sub    $0x18,%rsp
   0x00007f338519d3d7: mov    %rbp,0x10(%rsp) ;*synchronization entry
                                                 ; - 
IntFieldHandlesTest::javaSet at -1 (line 107)

   0x00007f338519d3dc: test   %edx,%edx
   0x00007f338519d3de: jle    0x00007f338519d480 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::javaSet at 4 (line 107)

   0x00007f338519d3e4: xor    %r11d,%r11d
   0x00007f338519d3e7: movl   $0x4321,0x10(%rsi)
   0x00007f338519d3ee: lock addl $0x0,(%rsp)     ;*putfield x
                                                 ; - 
IntFieldHandlesTest::javaSet at 11 (line 108)

   0x00007f338519d3f3: inc    %r11d              ;*iinc
                                                 ; - 
IntFieldHandlesTest::javaSet at 14 (line 107)

   0x00007f338519d3f6: cmp    $0x1,%r11d
   0x00007f338519d3fa: jl     0x00007f338519d3e7 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::javaSet at 4 (line 107)

   0x00007f338519d3fc: mov    %edx,%r10d
   0x00007f338519d3ff: add    $0xfffffffffffffff9,%r10d
   0x00007f338519d403: mov    $0x80000000,%r8d
   0x00007f338519d409: cmp    %r10d,%edx
   0x00007f338519d40c: cmovl  %r8d,%r10d
   0x00007f338519d410: cmp    %r10d,%r11d
   0x00007f338519d413: jge    0x00007f338519d466
   0x00007f338519d415: nopw   0x0(%rax,%rax,1)
   0x00007f338519d420: movl   $0x4321,0x10(%rsi)
   0x00007f338519d427: movl   $0x4321,0x10(%rsi)
   0x00007f338519d42e: movl   $0x4321,0x10(%rsi)
   0x00007f338519d435: movl   $0x4321,0x10(%rsi)
   0x00007f338519d43c: movl   $0x4321,0x10(%rsi)
   0x00007f338519d443: movl   $0x4321,0x10(%rsi)
   0x00007f338519d44a: movl   $0x4321,0x10(%rsi)
   0x00007f338519d451: movl   $0x4321,0x10(%rsi)
   0x00007f338519d458: lock addl $0x0,(%rsp)     ;*putfield x
                                                 ; - 
IntFieldHandlesTest::javaSet at 11 (line 108)

   0x00007f338519d45d: add    $0x8,%r11d         ;*iinc
                                                 ; - 
IntFieldHandlesTest::javaSet at 14 (line 107)

   0x00007f338519d461: cmp    %r10d,%r11d
   0x00007f338519d464: jl     0x00007f338519d420 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::javaSet at 4 (line 107)

   0x00007f338519d466: cmp    %edx,%r11d
   0x00007f338519d469: jge    0x00007f338519d480
   0x00007f338519d46b: nop
   0x00007f338519d46c: movl   $0x4321,0x10(%rsi)
   0x00007f338519d473: lock addl $0x0,(%rsp)     ;*putfield x
                                                 ; - 
IntFieldHandlesTest::javaSet at 11 (line 108)

   0x00007f338519d478: inc    %r11d              ;*iinc
                                                 ; - 
IntFieldHandlesTest::javaSet at 14 (line 107)

   0x00007f338519d47b: cmp    %edx,%r11d
   0x00007f338519d47e: jl     0x00007f338519d46c ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::javaSet at 4 (line 107)

   0x00007f338519d480: add    $0x10,%rsp
   0x00007f338519d484: pop    %rbp
   0x00007f338519d485: test   %eax,0x1723fb75(%rip)        # 
0x00007f339c3dd000
                                                 ; {poll_return}
   0x00007f338519d48b: retq                      ;*putfield x
                                                 ; - 
IntFieldHandlesTest::javaSet at 11 (line 108)

   0x00007f338519d48c: hlt
   0x00007f338519d48d: hlt
   0x00007f338519d48e: hlt
   0x00007f338519d48f: hlt
   0x00007f338519d490: hlt
   0x00007f338519d491: hlt
   0x00007f338519d492: hlt
   0x00007f338519d493: hlt
   0x00007f338519d494: hlt
   0x00007f338519d495: hlt
   0x00007f338519d496: hlt
   0x00007f338519d497: hlt
   0x00007f338519d498: hlt
   0x00007f338519d499: hlt
   0x00007f338519d49a: hlt
   0x00007f338519d49b: hlt
   0x00007f338519d49c: hlt
   0x00007f338519d49d: hlt
   0x00007f338519d49e: hlt
   0x00007f338519d49f: hlt
[Exception Handler]
[Stub Code]
   0x00007f338519d4a0: jmpq   0x00007f338506c120  ; {no_reloc}
[Deopt Handler Code]
   0x00007f338519d4a5: callq  0x00007f338519d4aa
   0x00007f338519d4aa: subq   $0x5,(%rsp)
   0x00007f338519d4af: jmpq   0x00007f3385047100  ; {runtime_call}
   0x00007f338519d4b4: hlt
   0x00007f338519d4b5: hlt
   0x00007f338519d4b6: hlt
   0x00007f338519d4b7: hlt
OopMapSet contains 0 OopMaps


while the unsafe variant:

     void unsafeSet(int n) {
         for (int i = 0; i < n; i++) {
             U.putIntVolatile(this, X_offset, 0x4321);
         }
     }

...gets compiled to the following last C2 version:

Code:
[Entry Point]
[Constants]
   # {method} {0x00007f2e15327ac8} 'unsafeSet' '(I)V' in 
'IntFieldHandlesTest'
   # this:     rsi:rsi   = 'IntFieldHandlesTest'
   # parm0:    rdx       = int
   #           [sp+0x20]  (sp of caller)
   0x00007f2f0d19f3c0: cmp    0x8(%rsi),%rax
   0x00007f2f0d19f3c4: jne    0x00007f2f0d045b60  ; {runtime_call}
   0x00007f2f0d19f3ca: xchg   %ax,%ax
   0x00007f2f0d19f3cc: nopl   0x0(%rax)
[Verified Entry Point]
   0x00007f2f0d19f3d0: sub    $0x18,%rsp
   0x00007f2f0d19f3d7: mov    %rbp,0x10(%rsp) ;*synchronization entry
                                                 ; - 
IntFieldHandlesTest::unsafeSet at -1 (line 133)

   0x00007f2f0d19f3dc: test   %edx,%edx
   0x00007f2f0d19f3de: jle    0x00007f2f0d19f464 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 4 (line 133)

   0x00007f2f0d19f3e4: xor    %r11d,%r11d
   0x00007f2f0d19f3e7: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f3ee: lock addl $0x0,(%rsp) ;*invokevirtual putIntVolatile
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 17 (line 134)

   0x00007f2f0d19f3f3: inc    %r11d              ;*iinc
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 20 (line 133)

   0x00007f2f0d19f3f6: cmp    $0x1,%r11d
   0x00007f2f0d19f3fa: jl     0x00007f2f0d19f3e7 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 4 (line 133)

   0x00007f2f0d19f3fc: mov    %edx,%r10d
   0x00007f2f0d19f3ff: add    $0xfffffffffffffffd,%r10d
   0x00007f2f0d19f403: mov    $0x80000000,%r8d
   0x00007f2f0d19f409: cmp    %r10d,%edx
   0x00007f2f0d19f40c: cmovl  %r8d,%r10d
   0x00007f2f0d19f410: cmp    %r10d,%r11d
   0x00007f2f0d19f413: jge    0x00007f2f0d19f44a
   0x00007f2f0d19f415: nopw   0x0(%rax,%rax,1)
   0x00007f2f0d19f420: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f427: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f42e: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f435: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f43c: lock addl $0x0,(%rsp) ;*invokevirtual putIntVolatile
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 17 (line 134)

   0x00007f2f0d19f441: add    $0x4,%r11d         ;*iinc
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 20 (line 133)

   0x00007f2f0d19f445: cmp    %r10d,%r11d
   0x00007f2f0d19f448: jl     0x00007f2f0d19f420 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 4 (line 133)

   0x00007f2f0d19f44a: cmp    %edx,%r11d
   0x00007f2f0d19f44d: jge    0x00007f2f0d19f464
   0x00007f2f0d19f44f: nop
   0x00007f2f0d19f450: movl   $0x4321,0x10(%rsi)
   0x00007f2f0d19f457: lock addl $0x0,(%rsp) ;*invokevirtual putIntVolatile
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 17 (line 134)

   0x00007f2f0d19f45c: inc    %r11d              ;*iinc
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 20 (line 133)

   0x00007f2f0d19f45f: cmp    %edx,%r11d
   0x00007f2f0d19f462: jl     0x00007f2f0d19f450 ;*if_icmpge
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 4 (line 133)

   0x00007f2f0d19f464: add    $0x10,%rsp
   0x00007f2f0d19f468: pop    %rbp
   0x00007f2f0d19f469: test   %eax,0x1555ab91(%rip)        # 
0x00007f2f226fa000
                                                 ; {poll_return}
   0x00007f2f0d19f46f: retq ;*invokevirtual putIntVolatile
                                                 ; - 
IntFieldHandlesTest::unsafeSet at 17 (line 134)

   0x00007f2f0d19f470: hlt
   0x00007f2f0d19f471: hlt
   0x00007f2f0d19f472: hlt
   0x00007f2f0d19f473: hlt
   0x00007f2f0d19f474: hlt
   0x00007f2f0d19f475: hlt
   0x00007f2f0d19f476: hlt
   0x00007f2f0d19f477: hlt
   0x00007f2f0d19f478: hlt
   0x00007f2f0d19f479: hlt
   0x00007f2f0d19f47a: hlt
   0x00007f2f0d19f47b: hlt
   0x00007f2f0d19f47c: hlt
   0x00007f2f0d19f47d: hlt
   0x00007f2f0d19f47e: hlt
   0x00007f2f0d19f47f: hlt
[Exception Handler]
[Stub Code]
   0x00007f2f0d19f480: jmpq   0x00007f2f0d0f8e60  ; {no_reloc}
[Deopt Handler Code]
   0x00007f2f0d19f485: callq  0x00007f2f0d19f48a
   0x00007f2f0d19f48a: subq   $0x5,(%rsp)
   0x00007f2f0d19f48f: jmpq   0x00007f2f0d047100  ; {runtime_call}
   0x00007f2f0d19f494: hlt
   0x00007f2f0d19f495: hlt
   0x00007f2f0d19f496: hlt
   0x00007f2f0d19f497: hlt
OopMapSet contains 0 OopMaps



So it seems that the loop in javaSet() is unrolled with step 8 per 
check, while the loop in usafeSet() is unrolled with step 4 per check. 
The memory barrier (lock addl $0x0,(%rsp)) is placed after each 
iteration of unrolled loop, this means that javaSet() executes half the 
number of memory barriers that unsafeSet() does. That's the reason for 
2x speed of javaSet(), right?


Regards, Peter


> On 1/16/2014 9:26 AM, Peter Levart wrote:
>> On 01/13/2014 09:16 PM, Doug Lea wrote:
>>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>>> I don't remember if this has been covered already...  One problem 
>>>>> with
>>>>> the Atomic___FieldUpdater classes is that there are a bunch of 
>>>>> branches
>>>>> that have to be executed.  For example, compareAndSet has 6
>>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>>> directly.
>>>
>>> Yes, this is the main problem we are trying to solve.
>>>
>>>> The question is how many of those checks the JVM can eliminate or 
>>>> would be necessary anyway at those callsites.
>>>
>>> Nothing less than eliminating all of them will be acceptable for 
>>> target users.
>>> The FieldUpdater approach falls into the reflection-in-disguise
>>> category, which hasn't been amenable to this.
>>> The .volatile solution can in principle generate overhead-less
>>> optimal code. It will take some hard work to make this happen though.
>>>
>>>
>>> -Doug
>>>
>>
>> Hi,
>>
>> I did an experiment using MethodHandles in recent JDK 8, 
>> investigating their ability to avoid and/or optimize-away those 
>> checks. Here's an simple utility that merges together Unsafe methods 
>> with constant method handles:
>>
>> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/jdk/src/share/classes/java/lang/invoke/IntFieldHandles.java 
>>
>>
>> (this should be appended to JDK boot classpath in order to work, if 
>> someone wants to experiment with it)
>>
>> The following microbenchmark compares performance of direct Unsafe 
>> usage with MethodHandles wrapped Unsafe usage, which is safe, so a MH 
>> based utility could be used as an alternative to Unsafe and be 
>> exposed to user code even in security constrained environments:
>>
>> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/IntFieldHandlesTest.java 
>>
>>
>> The test creates an instance of IntFieldHandles object and assigns it 
>> to a static final field. IntFieldHandles contains final instance 
>> MethodHandle fields that reference MHs which implement various atomic 
>> operations. I suspect that results show that JIT is able to:
>> - detect that MHs referenced of final instance fields in object 
>> referenced from static final field are constant inside tight loop, so 
>> it inlines them into call-sites
>> - optimize the non-null check out of a tight loop
>>
>> These are results I get on my PC for 1 billion operations:
>>
>> volatile get...
>>                Java bytecode:    254529453 ns (  0.25 ns/op)
>>                       Unsafe:    282554699 ns (  0.28 ns/op)
>>              IntFieldHandles:    283295007 ns (  0.28 ns/op)
>>  AtomicIntegerFieldUpdaterMH:    283064319 ns (  0.28 ns/op)
>>    AtomicIntegerFieldUpdater:    791010695 ns (  0.79 ns/op)
>>
>> volatile set...
>>                Java bytecode:    875844892 ns (  0.88 ns/op)
>>                       Unsafe:   1694360893 ns (  1.69 ns/op)
>>              IntFieldHandles:   1694270390 ns (  1.69 ns/op)
>>  AtomicIntegerFieldUpdaterMH:   1694504218 ns (  1.69 ns/op)
>>    AtomicIntegerFieldUpdater:   5198716697 ns (  5.20 ns/op)
>>
>> volatile set followed by volatile get...
>>                Java bytecode:   5197015493 ns (  5.20 ns/op)
>>                       Unsafe:   5214028002 ns (  5.21 ns/op)
>>              IntFieldHandles:   5197769609 ns (  5.20 ns/op)
>>  AtomicIntegerFieldUpdaterMH:   5198323773 ns (  5.20 ns/op)
>>    AtomicIntegerFieldUpdater:   6779080084 ns (  6.78 ns/op)
>>
>> Java bytecode volatile get followed by compare-and-set loop...
>>                       Unsafe:   7909649848 ns (  7.91 ns/op)
>>              IntFieldHandles:   7909497393 ns (  7.91 ns/op)
>>  AtomicIntegerFieldUpdaterMH:   7921124292 ns (  7.92 ns/op)
>>    AtomicIntegerFieldUpdater:   8134981470 ns (  8.13 ns/op)
>>
>>
>> It is interesting to note that even classic AtomicIntegerFieldUpdater 
>> is not so bad compared to direct Unsafe usage when combining more 
>> that one atomic operation in a sequence on the same field. I don't 
>> know why normal bytecode volatile put is 2x faster than Unsafe 
>> volatile put. I also include comparison with special implementation 
>> of AtomicIntegerFieldUpdater based on constant MHs:
>>
>> https://github.com/plevart/jdk8-tl/blob/AtomicFieldHandles/test/src/AtomicIntegerFieldUpdaterMH.java 
>>
>>
>> It shows that even generic MHs (with receiver of type Object) can 
>> optimize the cast out of tight loop ('this' in our example test)...
>>
>> The problem with MHs in Java is that their invokeXXX() methods 
>> declare throws Throwable, so their direct usage in Java is clumsy. We 
>> need a language feature to overcome that.
>>
>>
>> Regards, Peter
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140119/d45b9412/attachment-0001.html>

From forax at univ-mlv.fr  Sun Jan 19 12:30:54 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Sun, 19 Jan 2014 18:30:54 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52D98552.2000703@infinite-source.de>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D8F9D7.3050100@univ-mlv.fr>	<52D94032.5060905@cs.oswego.edu>
	<52D964E4.6020506@univ-mlv.fr>
	<52D98552.2000703@infinite-source.de>
Message-ID: <52DC0BCE.6060808@univ-mlv.fr>

On 01/17/2014 08:32 PM, Aaron Grunthal wrote:
> I imagine type safety for Reference-Arrays that are not Object[] would 
> be an issue. How can we reduce that to compile-time checks?
>
> Expand it to something like
>
>   public void <T> setRelease(Class<T> actualType, T[] array, int 
> index, T newValue) {
>      ...
>   }
>
> and then hope that the compiler can optimize away 
> actualType.cast(newValue)?
>
> - Aaron

Because the compiler generate an invokedynamic with a signature that 
depend on the type of the arguments at callsite and do not use the 
signature of the called method, you don't need to declare a 
supplementary parameter actualType.

With,
   public void <T> setRelease(T[] array, int index, T newValue) {
      ...
   }

if you have an array of Entry, setRelease will be called:
   invokedynamic setRelease (Entry[], int, Entry)
in the bootstrap method, (so not at compile time but at link time), you 
can verifies the types, i.e. if the component type of the array match 
the type of newValue.

Note that this is not enough because at runtime the array can be a 
subtype of Entry[] so like any arraystore in Java, the code still have 
to check if the componentType of the array is an Entry and throw an 
ArrayStoreException otherwise.

cheers,
R?mi

>
>
> On 17.01.2014 18:14, Remi Forax wrote:
>> On 01/17/2014 03:37 PM, Doug Lea wrote:
>>> On 01/17/2014 04:37 AM, Remi Forax wrote:
>>>
>>>> I believe it's better to come with a general solution that allow
>>>> developers to
>>>> trap method calls and replace them by tree of method handles that to
>>>> have a
>>>> specific syntax just for concurrency.
>>>
>>> I downplayed in posted JEP draft that we must also support a
>>> way to operate on array elements, as in:
>>>   int[] a = ...
>>>   a[7].volatile.setRelease(17);
>>>
>>> I don't see a path to this without the .volatile syntax support
>>> or something essentially equivalent.
>>
>> I fail to see the issue here, perhaps it's because the semantics of
>> setRelease is very special ?
>> Why a method that takes an array an int and a new value is not enough
>>
>> public class Volatiles {
>>    public void setRelease(int[] array, int index, int newValue) {
>>       ...
>>    }
>> }
>>
>>
>>>
>>> The reason arrays were not otherwise covered is that it is
>>> still a TBD issue whether to allow access to elements in this way
>>> for any array, without any type or annotation. Most likely the
>>> answer will be yes; anything else hits some language, type,
>>> or usability snag.
>>
>> You don't have a similar issue with a field ?
>>
>>>
>>> -Doug
>>
>> R?mi
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From aph at redhat.com  Mon Jan 20 04:47:12 2014
From: aph at redhat.com (Andrew Haley)
Date: Mon, 20 Jan 2014 09:47:12 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DBE664.6010409@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>
	<52DBE664.6010409@gmail.com>
Message-ID: <52DCF0A0.1000605@redhat.com>

On 01/19/2014 02:51 PM, Peter Levart wrote:

> So it seems that the loop in javaSet() is unrolled with step 8 per
> check, while the loop in usafeSet() is unrolled with step 4 per
> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
> each iteration of unrolled loop, this means that javaSet() executes
> half the number of memory barriers that unsafeSet() does. That's the
> reason for 2x speed of javaSet(), right?

That's what it looks like.  It goes to show the risks of
microbenchmarking: the cost of the actual operations are exactly the
same, but the microbenchmark indicates a ratio of 2.

Andrew.

From aleksey.shipilev at oracle.com  Mon Jan 20 05:44:46 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 20 Jan 2014 14:44:46 +0400
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DCF0A0.1000605@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>	<52DBE664.6010409@gmail.com>
	<52DCF0A0.1000605@redhat.com>
Message-ID: <52DCFE1E.1010605@oracle.com>

On 01/20/2014 01:47 PM, Andrew Haley wrote:
> On 01/19/2014 02:51 PM, Peter Levart wrote:
> 
>> So it seems that the loop in javaSet() is unrolled with step 8 per
>> check, while the loop in usafeSet() is unrolled with step 4 per
>> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
>> each iteration of unrolled loop, this means that javaSet() executes
>> half the number of memory barriers that unsafeSet() does. That's the
>> reason for 2x speed of javaSet(), right?
> 
> That's what it looks like.  It goes to show the risks of
> microbenchmarking: the cost of the actual operations are exactly the
> same, but the microbenchmark indicates a ratio of 2.

More importantly, it goes to show the risks of winding up your own
broken benchmark harness ("I will hack something by the end of the day",
right?), and wasting your time dealing with surprising but preventable
issues. Use a harness which already deals with this for you, e.g. JMH:
  http://openjdk.java.net/projects/code-tools/jmh/

Exactly the same loop optimization pitfall is shown as anti-pattern in
the relevant JMH sample:

http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/JMHSample_11_Loops.java

-Aleksey.

From peter.levart at gmail.com  Mon Jan 20 07:42:47 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Mon, 20 Jan 2014 13:42:47 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DCFE1E.1010605@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>	<52DBE664.6010409@gmail.com>
	<52DCF0A0.1000605@redhat.com> <52DCFE1E.1010605@oracle.com>
Message-ID: <52DD19C7.2040201@gmail.com>

On 01/20/2014 11:44 AM, Aleksey Shipilev wrote:
> On 01/20/2014 01:47 PM, Andrew Haley wrote:
>> On 01/19/2014 02:51 PM, Peter Levart wrote:
>>
>>> So it seems that the loop in javaSet() is unrolled with step 8 per
>>> check, while the loop in usafeSet() is unrolled with step 4 per
>>> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
>>> each iteration of unrolled loop, this means that javaSet() executes
>>> half the number of memory barriers that unsafeSet() does. That's the
>>> reason for 2x speed of javaSet(), right?
>> That's what it looks like.  It goes to show the risks of
>> microbenchmarking: the cost of the actual operations are exactly the
>> same, but the microbenchmark indicates a ratio of 2.
> More importantly, it goes to show the risks of winding up your own
> broken benchmark harness ("I will hack something by the end of the day",
> right?), and wasting your time dealing with surprising but preventable
> issues. Use a harness which already deals with this for you, e.g. JMH:
>    http://openjdk.java.net/projects/code-tools/jmh/
>
> Exactly the same loop optimization pitfall is shown as anti-pattern in
> the relevant JMH sample:
>
> http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/JMHSample_11_Loops.java
>
> -Aleksey.

I confess, I've been beaten again. But using JMH instead of rolling my 
own test, I wouldn't learn something new (no time wasted ;-). I've had a 
false impression that each volatile write must be accompanied with a 
memory barrier, but it seems that optimizer can collapse several writes 
to same location and only issue one barrier after the batch. That's 
reasonable, since there's no guarantee that each intermediate value 
could be observed by other threads even if each write was flushed 
individually...

Part of why I haven't measured with JMH or similar is that I wanted to 
see the ability of various approaches in hoisting the checks out of 
loop. But that's not very relevant for real-world code. I feel obliged 
to produce a measurement of the same examples using JMH now. I will get 
back when I have some results...

Regards, Peter


From peter.levart at gmail.com  Mon Jan 20 07:53:17 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Mon, 20 Jan 2014 13:53:17 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DCF0A0.1000605@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>
	<52DBE664.6010409@gmail.com> <52DCF0A0.1000605@redhat.com>
Message-ID: <52DD1C3D.5010609@gmail.com>

On 01/20/2014 10:47 AM, Andrew Haley wrote:
> On 01/19/2014 02:51 PM, Peter Levart wrote:
>
>> So it seems that the loop in javaSet() is unrolled with step 8 per
>> check, while the loop in usafeSet() is unrolled with step 4 per
>> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
>> each iteration of unrolled loop, this means that javaSet() executes
>> half the number of memory barriers that unsafeSet() does. That's the
>> reason for 2x speed of javaSet(), right?
> That's what it looks like.  It goes to show the risks of
> microbenchmarking: the cost of the actual operations are exactly the
> same, but the microbenchmark indicates a ratio of 2.
>
> Andrew.

Yeah. An interesting observation is also that optimizer choose the step 
of loop unrolling differently for those two loops. It seems that the 
step is chosen according to some estimation of the cost of loop's body. 
Number of bytecodes?

Regards, Peter


From david.lloyd at redhat.com  Mon Jan 20 09:20:37 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 20 Jan 2014 08:20:37 -0600
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DA4F3E.30301@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>
	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>
	<52D971E3.80903@gmail.com>	<52D97CCE.9050005@univ-mlv.fr>	<1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>
	<52DA4F3E.30301@univ-mlv.fr>
Message-ID: <52DD30B5.3090109@redhat.com>

On 01/18/2014 03:54 AM, Remi Forax wrote:
> On 01/18/2014 03:19 AM, David Lloyd wrote:
>> Nah that syntax kinda sucks - it's obviously just a hack.  What about
>> being a bit more bold and adding an actual "in vs inout" method
>> parameter mechanism to JVM and JLS?  Then the method could just be a
>> plain intrinsic.
>>
>> --
>> - DML
>
> Hi David,
> It will never happen,
> inout => pointer aliasing => rewrite all interpreters and JITs => not
> Java anymore.

That's a really strange and arbitrary standard for what is and is not 
Java, considering that the language as of JDK 8 would not even be 
recognizable to someone from the 1.4 era.

-- 
- DML

From oleksandr.otenko at oracle.com  Mon Jan 20 09:52:04 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 20 Jan 2014 14:52:04 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DA4DF4.5000908@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D8F9D7.3050100@univ-mlv.fr>	<187ecc99bba94e39bfc5de7b7fd8ffae@exchmb01.office.devexperts.com>
	<52DA4DF4.5000908@univ-mlv.fr>
Message-ID: <52DD3814.6090007@oracle.com>

Well, it's not just type safety here at stake.

We hit the bug that security settings can prevent a class to set up a 
Atomic_FieldUpdater, because it is not allowed to list fields.

This has been addressed, but the point is that using strings means using 
API, whereas using method or field reference means fields and methods 
are first class objects.


Alex


On 18/01/2014 09:48, Remi Forax wrote:
> On 01/17/2014 11:09 AM, Roman Elizarov wrote:
>> Syntax is as important as implementation and its performance. The 
>> problem with "String fieldName" is that it looks like a string in a 
>> source code and even if javac knows that the method is intrinsic and 
>> does the actual compile-time checking that the string is constant and 
>> refers to the actual field, it still looks scripty, hacky, and ugly 
>> in the source code. It is an improvement upon AtomicFieldUpdater 
>> classes in terms of performance, but it offers no improvement in 
>> terms of syntax. I write a lot of code with volatiles/Unsafe and I 
>> don't want it to look ugly. It becomes hard to maintain and buggy, 
>> because of bad syntax of both Unsafe and AFU ways.
>>
>> I will **very much*** prefer this:
>>
>>     head.volatile.compareAndSet(expected, newValue)
>>
>> to this:
>>
>>     Volatiles.compareAndSet("head", this, expected, newValue)
>>
>> The concern of "specific syntax for concurrency" is legit, but moot, 
>> because Java _already_ has a lot of specific syntax for concurrency 
>> (but no specific syntax for HPC, for example) and extending Java's 
>> concurrency syntax does not break the spirit of Java, but enhances it.
>>
>> Actually, I would consider the second syntax to be a total failure to 
>> give Java a good concurrency library, regardless of its performance. 
>> If giving Java a specific syntax for concurrency is indeed a concern, 
>> then consider supporting field handles in Java instead. I can live 
>> with something like this:
>>
>>     Volatiles.compareAndSet(this::head, expected, newValue)
>>
>> Sincerely,
>> Roman Elizarov
>
> yes,
> a String is less typesafe than a dedicated syntax but it's because we 
> don't have a field reference syntax in Java. The 'right' API should be
>
>   Volatiles.compareAndSet(Linked::head, this, expected, newValue)
>
>
> regards,
> R?mi
>
>>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu 
>> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Remi 
>> Forax
>> Sent: Friday, January 17, 2014 1:37 PM
>> To: concurrency-interest at cs.oswego.edu
>> Cc: Christian Thalinger; John Rose
>> Subject: Re: [concurrency-interest] JDK9 concurrency preliminaries
>>
>> On 01/13/2014 09:16 PM, Doug Lea wrote:
>>> On 01/13/2014 01:52 PM, Aaron Grunthal wrote:
>>>> On 13.01.2014 18:28, Nathan Reynolds wrote:
>>>>> I don't remember if this has been covered already...  One problem
>>>>> with the Atomic___FieldUpdater classes is that there are a bunch of
>>>>> branches that have to be executed.  For example, compareAndSet has 6
>>>>> comparisons.  For this reason, many will resort to using Unsafe
>>>>> directly.
>>> Yes, this is the main problem we are trying to solve.
>>>
>>>> The question is how many of those checks the JVM can eliminate or
>>>> would be necessary anyway at those callsites.
>>> Nothing less than eliminating all of them will be acceptable for
>>> target users.
>>> The FieldUpdater approach falls into the reflection-in-disguise
>>> category, which hasn't been amenable to this.
>>> The .volatile solution can in principle generate overhead-less optimal
>>> code. It will take some hard work to make this happen though.
>> I've written a small proof of concept of how this can work and there 
>> are so good news and some things that must be improved.
>>
>> First, you can separate the problem in two independant questions, one 
>> is the .volatile syntax and the other is how to talk to the JIT to 
>> avoid those stupid runtime checks.
>>
>> For the former question, I see several good reasons to not use the 
>> .volatile syntax.
>> The first one is that the syntax doesn't cover all use cases, you can 
>> not do a double CAS with the .volatile syntax by example, because the 
>> syntax consider only one field.
>> The second one, is a problem that I have discovered only when coding 
>> a solution, the world that the VM see and the world that Java 
>> proposes to an user are not perfectly aligned. In Java, you can 
>> access to a private field of an inner class from the enclosing class 
>> (and vice versa). The VM can not do that. The compiler bridge that 
>> gap by generating getter and setter (the access$xxx method). 
>> Obviously, the .volatile syntax can not use the same trick and will 
>> have at runtime to do some check and bypass the security model. While 
>> it's not a dig deal because the check can be done once for all, it 
>> means that you offer a possible angle of attack from the security 
>> perspective because the code has to elevate its privilege.
>> The third one is more conceptual, if Java offers a specific syntax 
>> for concurrency, uses will want a specific syntax for any other 
>> fields like by example a specific syntax for HPC.
>>
>> Basically, what we want is to have an intrinsic, like a C++ 
>> instrinsic provided by the C++ compiler, also like a VM instrinsic 
>> that transform a method like unsafe.compareAndSwapObject to assembly 
>> code.
>> That's why I think it's better to provide an instrinsic-like 
>> mechanism that will replace a call to a Java method to a specific 
>> sequence of bytecodes. We have the tool for specifying the sequence 
>> of bytecode it's the method handle combiners of the package 
>> java.lang.invoke. All we need is something in the Java compiler that 
>> says, the call to this method is not a classical Java code but a call 
>> to something that will be turned to a method handle tree, i.e. a call 
>> through invokedynamic.
>>
>> Using invokedynamic and the method handles are the answer to the 
>> question 2, the .volatile syntax will use invokedynamic, the 
>> instrinsic-like mecanism I propose will use invokedynamic. That's why 
>> I think it's important so separate the discussion about the syntax 
>> from the discussion about how to about the class check at runtime.
>>
>> So let me explain how to code a Java instrinsic in Java.
>> You need two parts, the first one is the declaration of methods that 
>> will be turned to an intrinsic.
>> This can be done by writing a classical method that throw an error. 
>> The method body will be never called, the method is just here for the 
>> typechecking.
>> The second part is that javac has to know that this method is an 
>> intrinsic, using a keyword by example, and generate an invokedynamic 
>> instead of the callsicall invoke* bytecode.
>> And at runtime, the first time that a method tagged intrinsic will be 
>> called for a callsite, the VM will call the bootstrap method.
>>
>> Here is an example for compareAndSet:
>> public class Volatiles {
>>     public static intrinsic boolean compareAndSet(String fieldName, 
>> Object current, int expected, int newValue) {
>>       throw new InternalError();
>>     }
>>
>>     public static intrinsic <T> boolean compareAndSet(String 
>> fieldName, Object current, T expected, T newValue) {
>>       throw new InternalError();
>>     }
>>
>>     public static CallSite bootstrap(Lookup lookup, String name, 
>> MethodType type, MethodHandle impl) {
>>       ...
>>     }
>> }
>>
>> and it will be used that way:
>> public class Linked {
>>     private volatile Node head;
>>
>>     private boolean compareAndSet(Node expected, Node newValue) {
>>       return Volatiles.compareAndSet("head", this, expected, newValue);
>>     }
>> ...
>>
>> Here I know what you think, it uses a String, it will do reflection, 
>> it will be slow, obviously the answer is no.
>> Let me detail how it works, first you can notice that you don't have 
>> to specify the class, when the bootstrap method is called, the Lookup 
>> parameter contains the class that call the method so it's not needed 
>> and it's even better, it restrict the API because it can only be used 
>> to access to a member that is declared in the class to call 
>> "Volatiles.compareAndSet" so there is no security privilege 
>> enhancement, it fully relies on the Lookup object for doing the 
>> security check so no potential new security hole.
>>
>> Now the string parameter, Java has no way to reference a field so you 
>> need to send the name of the field, but there is a trick here. The 
>> implementation use the method handle guardWithTest (a glorified 'if') 
>> to check that the String will never changed (doing a pointer check), 
>> The things is that if the API is used correctly, the string will be 
>> always a string literal so the JIT will prove easily that the String 
>> never changed so will just remove the pointer check.
>> The else branch throws an exception to inform the user of the API 
>> that the String must be a constant.
>> This trick allows to specify the field to be updated in a nice way 
>> (just a string) without any performance penalty.
>>
>> Now, how to get ride of the value check that check dynamically that 
>> you can not use Volatiles.compareAndSet to set a String inside the 
>> field 'head'.
>> The trick here is to ask the compiler to do a little more work that 
>> usual when computing the signature of the invokedynamic call. Instead 
>> of using the signature of Volatiles.compareAndSet which is (String, 
>> Object, Object, Object)boolean due to the erasure, javac will use the 
>> type of the expression found during the typechecking phase (this is 
>> something javac already does for signature polymorphic method like 
>> MethodHandle.invokeExact, so no big deal). Here in the example, the 
>> signature of invokedynamic will be (String, Linked, Node, Node)boolean.
>> That the the signature convey the real type information, the boostrap 
>> method can check once that the type of newValue is correct with 
>> respect to the type of the field. Note: technically it can not be 
>> done in the bootstrap method because to get the field you need the 
>> field name and the bootstrap method doesn't have the argument. But 
>> the usual trick, is to register a method that will be called the 
>> first time in the boostrap method and in the method, the code have 
>> access to the value of the first call. At the end of the method, the 
>> method will relink the call site with the method handle tree that 
>> call unsafe.compareAndSwapObject.
>> Basically, it just an extra level of indirection for the first call. 
>> Not something that the JIT will see because when the JIT will be 
>> triggered there will be no reference to that intermediary method 
>> anymore.
>>
>> The signature trick allows also to get ride of the check that verifie 
>> that the second parameter is an object of the current class ('this' 
>> in the example).
>>
>> Now, I've done some simple test to check that the JIT was really able 
>> to not insert check and correctly generate the same code as calling 
>> directly Unsafe.compareAndSwapObject.
>> It mostly work, the JIT correctly remove the String pointer check, 
>> but it insert two null supplementary checks that verifies that 
>> expected and newValue are not null when I compare with a code that 
>> use Unsafe.compareAndSwapObject directly.
>>
>> I believe (I may be wrong, hence John and Christian in CC) that, 
>> these checks are artifacts that comes from the way the method handle 
>> tree is transformed to assembly code, the lambda form.
>> Lambda forms internally erases the types to Object and use a 
>> Class.cast to ensure safety, Class.cast is transformed to an 
>> instanceof. The part that check the class hierarchy of instanceof is 
>> removed because Unsafe.compareAndSwapObject use Object as parameter 
>> but the null check still float around.
>>
>> I use a fairly old build (jdk8b155) so perhaps, these artifacts are 
>> removed now.
>>
>> In conclusion, we are close enough (far more close that I was thinking
>> initially) to provide a solution that allow people to have the 
>> performance of unsafe.compareAndSwapObject without the unsafe bits I 
>> believe it's better to come with a general solution that allow 
>> developers to trap method calls and replace them by tree of method 
>> handles that to have a specific syntax just for concurrency.
>>
>> regards,
>> R?mi
>>
>> Here is the full code of the bootstrap method:
>> public static CallSite bootstrap(Lookup lookup, String name, 
>> MethodType type, MethodHandle impls) {
>>       if (type.parameterType(1) != lookup.lookupClass()) {
>>         throw new LinkageError("the second parameter of compareAndSet 
>> must be this");
>>       }
>>
>>       // also check that the parameter(2) and parameter(3) have the 
>> same type
>>       if (type.parameterType(2) != type.parameterType(3)) {
>>         throw new LinkageError("expected value and new value should 
>> have the same type");
>>       }
>>
>>       MethodHandle fallback;
>>       if (type.parameterType(2) == int.class) {
>>         throw new AssertionError("NIY");
>>       } else {
>>         fallback = CASCallSite.FALLBACK_OBJECT;
>>       }
>>
>>       return new CASCallSite(lookup, type, fallback);
>>     }
>>
>>     static final Unsafe UNSAFE;
>>     static final MethodHandle UNSAFE_CAS, CHECK_FIELD_NAME, THROW_ERROR;
>>     static {
>>       Unsafe unsafe;
>>       try {
>>         Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
>>         theUnsafe.setAccessible(true);
>>         unsafe = (Unsafe)theUnsafe.get(null);
>>       } catch (NoSuchFieldException | IllegalAccessException e) {
>>         throw new AssertionError(e);
>>       }
>>       UNSAFE = unsafe;
>>
>>       MethodHandle unsafeMH;
>>       Lookup lookup = MethodHandles.lookup();
>>       try {
>>         CHECK_FIELD_NAME = lookup.findStatic(Volatiles.class,
>> "checkFieldName",
>>             MethodType.methodType(boolean.class, String.class, 
>> String.class));
>>         THROW_ERROR = lookup.findStatic(Volatiles.class, "throwError",
>>             MethodType.methodType(boolean.class));
>>         unsafeMH = lookup.findVirtual(Unsafe.class, 
>> "compareAndSwapObject",
>>             MethodType.methodType(boolean.class, Object.class, 
>> long.class, Object.class, Object.class));
>>       } catch (NoSuchMethodException | IllegalAccessException e) {
>>         throw new AssertionError(e);
>>       }
>>       UNSAFE_CAS = unsafeMH.bindTo(unsafe);
>>     }
>>
>>     @SuppressWarnings("unused")  // used by a method handle
>>     private static boolean checkFieldName(String expected, String 
>> value) {
>>       return expected == value;
>>     }
>>
>>     @SuppressWarnings("unused")  // used by a method handle
>>     private static boolean throwError() {
>>       throw new IllegalStateException("the field name must be 
>> constant");
>>     }
>>
>>     static class CASCallSite extends MutableCallSite {
>>       static MethodHandle FALLBACK_OBJECT;
>>       static {
>>         try {
>>           FALLBACK_OBJECT =
>> MethodHandles.lookup().findVirtual(CASCallSite.class, "fallback",
>>               MethodType.methodType(boolean.class, String.class, 
>> Object.class, Object.class, Object.class));
>>         } catch (NoSuchMethodException | IllegalAccessException e) {
>>           throw new AssertionError(e);
>>         }
>>       }
>>
>>       private final Lookup lookup;
>>
>>       CASCallSite(Lookup lookup, MethodType type, MethodHandle 
>> fallback) {
>>         super(type);
>>         this.lookup = lookup;
>>         setTarget(fallback.bindTo(this).asType(type));
>>       }
>>
>>       boolean fallback(String name, Object self, Object expected, Object
>> newValue) throws Throwable {
>>         MethodHandle getter;
>>         try {
>>           getter = lookup.findGetter(lookup.lookupClass(), name, 
>> type().parameterType(2));
>>           // use a horrible workaround
>>           //getter = lookup.findGetter(lookup.lookupClass(), name, 
>> newValue.getClass());
>>         } catch (NoSuchFieldException | IllegalAccessException e) {
>>           throw new IllegalStateException(e);
>>         }
>>         Field field = MethodHandles.reflectAs(Field.class, getter);
>>         long offset = UNSAFE.objectFieldOffset(field);
>>         MethodHandle target = MethodHandles.insertArguments(UNSAFE_CAS,
>> 1, offset);
>>         MethodHandle unsafeCas = MethodHandles.dropArguments(target, 
>> 0, String.class);
>>         MethodHandle throwError =
>> MethodHandles.dropArguments(THROW_ERROR, 0, type().parameterArray());
>>         MethodHandle guard =
>> MethodHandles.guardWithTest(CHECK_FIELD_NAME.bindTo(name),
>> unsafeCas.asType(type()), throwError);
>>         setTarget(guard);
>>         return (boolean)target.invokeExact(self, expected, newValue);
>>       }
>>     }
>>
>>>
>>> -Doug
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Mon Jan 20 09:58:31 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 20 Jan 2014 14:58:31 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DD19C7.2040201@gmail.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>	<52DBE664.6010409@gmail.com>	<52DCF0A0.1000605@redhat.com>
	<52DCFE1E.1010605@oracle.com> <52DD19C7.2040201@gmail.com>
Message-ID: <52DD3997.5040805@oracle.com>

The merging of store-store barriers is a common consequence on TSO 
architectures (so you could even have that as a rule of thumb - several 
volatile writes without volatile loads between them, even if not to the 
same field, can be optimized to have the cost of just a write, except 
the last write preceding a volatile load).

It is also possible to merge all stores to the same location, too.

Alex

On 20/01/2014 12:42, Peter Levart wrote:
> On 01/20/2014 11:44 AM, Aleksey Shipilev wrote:
>> On 01/20/2014 01:47 PM, Andrew Haley wrote:
>>> On 01/19/2014 02:51 PM, Peter Levart wrote:
>>>
>>>> So it seems that the loop in javaSet() is unrolled with step 8 per
>>>> check, while the loop in usafeSet() is unrolled with step 4 per
>>>> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
>>>> each iteration of unrolled loop, this means that javaSet() executes
>>>> half the number of memory barriers that unsafeSet() does. That's the
>>>> reason for 2x speed of javaSet(), right?
>>> That's what it looks like.  It goes to show the risks of
>>> microbenchmarking: the cost of the actual operations are exactly the
>>> same, but the microbenchmark indicates a ratio of 2.
>> More importantly, it goes to show the risks of winding up your own
>> broken benchmark harness ("I will hack something by the end of the day",
>> right?), and wasting your time dealing with surprising but preventable
>> issues. Use a harness which already deals with this for you, e.g. JMH:
>>    http://openjdk.java.net/projects/code-tools/jmh/
>>
>> Exactly the same loop optimization pitfall is shown as anti-pattern in
>> the relevant JMH sample:
>>
>> http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/JMHSample_11_Loops.java 
>>
>>
>> -Aleksey.
>
> I confess, I've been beaten again. But using JMH instead of rolling my 
> own test, I wouldn't learn something new (no time wasted ;-). I've had 
> a false impression that each volatile write must be accompanied with a 
> memory barrier, but it seems that optimizer can collapse several 
> writes to same location and only issue one barrier after the batch. 
> That's reasonable, since there's no guarantee that each intermediate 
> value could be observed by other threads even if each write was 
> flushed individually...
>
> Part of why I haven't measured with JMH or similar is that I wanted to 
> see the ability of various approaches in hoisting the checks out of 
> loop. But that's not very relevant for real-world code. I feel obliged 
> to produce a measurement of the same examples using JMH now. I will 
> get back when I have some results...
>
> Regards, Peter
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Mon Jan 20 10:03:07 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 20 Jan 2014 15:03:07 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DD3997.5040805@oracle.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D4222C.6050404@oracle.com>	<52D435F9.409@infinite-source.de>	<52D449A3.9010907@cs.oswego.edu>	<52D80825.9070403@gmail.com>	<52D81DFA.6080103@oracle.com>	<52DBE664.6010409@gmail.com>	<52DCF0A0.1000605@redhat.com>
	<52DCFE1E.1010605@oracle.com> <52DD19C7.2040201@gmail.com>
	<52DD3997.5040805@oracle.com>
Message-ID: <52DD3AAB.7060905@oracle.com>

Ugh, should have said "merging store-load + store serialization", which 
is implemented using a locked instruction or mfence.

store-store isn't needed on TSO in any circumstances.


Alex

On 20/01/2014 14:58, Oleksandr Otenko wrote:
> The merging of store-store barriers is a common consequence on TSO 
> architectures (so you could even have that as a rule of thumb - 
> several volatile writes without volatile loads between them, even if 
> not to the same field, can be optimized to have the cost of just a 
> write, except the last write preceding a volatile load).
>
> It is also possible to merge all stores to the same location, too.
>
> Alex
>
> On 20/01/2014 12:42, Peter Levart wrote:
>> On 01/20/2014 11:44 AM, Aleksey Shipilev wrote:
>>> On 01/20/2014 01:47 PM, Andrew Haley wrote:
>>>> On 01/19/2014 02:51 PM, Peter Levart wrote:
>>>>
>>>>> So it seems that the loop in javaSet() is unrolled with step 8 per
>>>>> check, while the loop in usafeSet() is unrolled with step 4 per
>>>>> check. The memory barrier (lock addl $0x0,(%rsp)) is placed after
>>>>> each iteration of unrolled loop, this means that javaSet() executes
>>>>> half the number of memory barriers that unsafeSet() does. That's the
>>>>> reason for 2x speed of javaSet(), right?
>>>> That's what it looks like.  It goes to show the risks of
>>>> microbenchmarking: the cost of the actual operations are exactly the
>>>> same, but the microbenchmark indicates a ratio of 2.
>>> More importantly, it goes to show the risks of winding up your own
>>> broken benchmark harness ("I will hack something by the end of the 
>>> day",
>>> right?), and wasting your time dealing with surprising but preventable
>>> issues. Use a harness which already deals with this for you, e.g. JMH:
>>>    http://openjdk.java.net/projects/code-tools/jmh/
>>>
>>> Exactly the same loop optimization pitfall is shown as anti-pattern in
>>> the relevant JMH sample:
>>>
>>> http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/JMHSample_11_Loops.java 
>>>
>>>
>>> -Aleksey.
>>
>> I confess, I've been beaten again. But using JMH instead of rolling 
>> my own test, I wouldn't learn something new (no time wasted ;-). I've 
>> had a false impression that each volatile write must be accompanied 
>> with a memory barrier, but it seems that optimizer can collapse 
>> several writes to same location and only issue one barrier after the 
>> batch. That's reasonable, since there's no guarantee that each 
>> intermediate value could be observed by other threads even if each 
>> write was flushed individually...
>>
>> Part of why I haven't measured with JMH or similar is that I wanted 
>> to see the ability of various approaches in hoisting the checks out 
>> of loop. But that's not very relevant for real-world code. I feel 
>> obliged to produce a measurement of the same examples using JMH now. 
>> I will get back when I have some results...
>>
>> Regards, Peter
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From oleksandr.otenko at oracle.com  Mon Jan 20 15:03:48 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 20 Jan 2014 20:03:48 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model: table
	17.5
Message-ID: <52DD8124.1060103@oracle.com>

Hi

Thread1:
A=1;
r2=B;

Thread2:
B=2;
r1=A;


Table 17.5 
<http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1> 
permits a reordering such that both r2 and r1 see 0, yet the Cookbook 
does not.

Is this point going to be addressed, and in whose favour it is likely to 
shift?

I find Cookbook's interpretation a important step for cooperative 
concurrency.


Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140120/cf2d5413/attachment.html>

From aph at redhat.com  Tue Jan 21 04:47:43 2014
From: aph at redhat.com (Andrew Haley)
Date: Tue, 21 Jan 2014 09:47:43 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DD30B5.3090109@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D971E3.80903@gmail.com>	<52D97CCE.9050005@univ-mlv.fr>	<1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>	<52DA4F3E.30301@univ-mlv.fr>
	<52DD30B5.3090109@redhat.com>
Message-ID: <52DE423F.70408@redhat.com>

On 01/20/2014 02:20 PM, David M. Lloyd wrote:
> On 01/18/2014 03:54 AM, Remi Forax wrote:
>> On 01/18/2014 03:19 AM, David Lloyd wrote:
>>> Nah that syntax kinda sucks - it's obviously just a hack.  What about
>>> being a bit more bold and adding an actual "in vs inout" method
>>> parameter mechanism to JVM and JLS?  Then the method could just be a
>>> plain intrinsic.
>>>
>> It will never happen,
>> inout => pointer aliasing => rewrite all interpreters and JITs => not
>> Java anymore.

Why does inout lead to any more pointer aliasing than we already have?

> That's a really strange and arbitrary standard for what is and is not 
> Java, considering that the language as of JDK 8 would not even be 
> recognizable to someone from the 1.4 era.

True enough, but an awful lot of that - in fact almost all of it - is
just syntactic sugar.  By contrast, inout parameters would require
some pretty drastic redesigning of the VM.  At present the single
return value is usually passed in a register.

Andrew.

From aph at redhat.com  Tue Jan 21 04:52:19 2014
From: aph at redhat.com (Andrew Haley)
Date: Tue, 21 Jan 2014 09:52:19 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DD8124.1060103@oracle.com>
References: <52DD8124.1060103@oracle.com>
Message-ID: <52DE4353.3000809@redhat.com>

On 01/20/2014 08:03 PM, Oleksandr Otenko wrote:
> 
> Thread1:
> A=1;
> r2=B;
> 
> Thread2:
> B=2;
> r1=A;
> 
> 
> Table 17.5
> <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>
> permits a reordering such that both r2 and r1 see 0, yet the
> Cookbook does not.

Why do you say that the Cookbook does not allow this?

Andrew.

From forax at univ-mlv.fr  Tue Jan 21 05:10:39 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Tue, 21 Jan 2014 11:10:39 +0100
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DE423F.70408@redhat.com>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D971E3.80903@gmail.com>	<52D97CCE.9050005@univ-mlv.fr>	<1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>	<52DA4F3E.30301@univ-mlv.fr>	<52DD30B5.3090109@redhat.com>
	<52DE423F.70408@redhat.com>
Message-ID: <52DE479F.6030406@univ-mlv.fr>

On 01/21/2014 10:47 AM, Andrew Haley wrote:
> On 01/20/2014 02:20 PM, David M. Lloyd wrote:
>> On 01/18/2014 03:54 AM, Remi Forax wrote:
>>> On 01/18/2014 03:19 AM, David Lloyd wrote:
>>>> Nah that syntax kinda sucks - it's obviously just a hack.  What about
>>>> being a bit more bold and adding an actual "in vs inout" method
>>>> parameter mechanism to JVM and JLS?  Then the method could just be a
>>>> plain intrinsic.
>>>>
>>> It will never happen,
>>> inout => pointer aliasing => rewrite all interpreters and JITs => not
>>> Java anymore.
> Why does inout lead to any more pointer aliasing than we already have?

pointer aliasing on things that are on stack,
   int i = 3;
   foo(&i, &i);

>
>> That's a really strange and arbitrary standard for what is and is not
>> Java, considering that the language as of JDK 8 would not even be
>> recognizable to someone from the 1.4 era.
> True enough, but an awful lot of that - in fact almost all of it - is
> just syntactic sugar.  By contrast, inout parameters would require
> some pretty drastic redesigning of the VM.  At present the single
> return value is usually passed in a register.
>
> Andrew.

R?mi


From aph at redhat.com  Tue Jan 21 06:28:45 2014
From: aph at redhat.com (Andrew Haley)
Date: Tue, 21 Jan 2014 11:28:45 +0000
Subject: [concurrency-interest] JDK9 concurrency preliminaries
In-Reply-To: <52DE479F.6030406@univ-mlv.fr>
References: <52CDB41C.70601@cs.oswego.edu>	<52D03CB6.8000307@univ-mlv.fr>	<52D13633.5000706@cs.oswego.edu>	<52D971E3.80903@gmail.com>	<52D97CCE.9050005@univ-mlv.fr>	<1799EDB8-C4D1-4EAF-9CF2-D1A533FF9582@redhat.com>	<52DA4F3E.30301@univ-mlv.fr>	<52DD30B5.3090109@redhat.com>	<52DE423F.70408@redhat.com>
	<52DE479F.6030406@univ-mlv.fr>
Message-ID: <52DE59ED.7070506@redhat.com>

On 01/21/2014 10:10 AM, Remi Forax wrote:
> On 01/21/2014 10:47 AM, Andrew Haley wrote:
>> On 01/20/2014 02:20 PM, David M. Lloyd wrote:
>>> On 01/18/2014 03:54 AM, Remi Forax wrote:
>>>> On 01/18/2014 03:19 AM, David Lloyd wrote:
>>>>> Nah that syntax kinda sucks - it's obviously just a hack.  What about
>>>>> being a bit more bold and adding an actual "in vs inout" method
>>>>> parameter mechanism to JVM and JLS?  Then the method could just be a
>>>>> plain intrinsic.
>>>>>
>>>> It will never happen,
>>>> inout => pointer aliasing => rewrite all interpreters and JITs => not
>>>> Java anymore.
>> Why does inout lead to any more pointer aliasing than we already have?
> 
> pointer aliasing on things that are on stack,
>    int i = 3;
>    foo(&i, &i);

Oh, yuck.  It never even occurred to me that anyone might consider
doing this.  That's ref parameters, which aren't the really same thing.

Andrew.

From oleksandr.otenko at oracle.com  Tue Jan 21 10:59:15 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 15:59:15 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DE4353.3000809@redhat.com>
References: <52DD8124.1060103@oracle.com> <52DE4353.3000809@redhat.com>
Message-ID: <52DE9953.4070008@oracle.com>

Assuming table 17.5 is talking about volatiles. If not, the point is moot.

Because the table of required barriers requires a Store-Load barrier 
between each of the lines, and defines the barriers as such that the 
preceding stores become visible before load is executed.

This means that by observing r2==0 one can conclude that A=1 was 
executed before r2=B (Store-Load required), that B=2 will be executed 
after r2=B (causal dependency), and r1=A will be executed after B=2 
(Store-Load required). So, by definition of Store-Load, A=1 will be 
visible before r2=B observed that B=2 hasn't executed yet, therefore, 
r1=A cannot observe r1==0.


The beauty of this is that by excluding r1==0 && r2==0, you now can 
/infer/ the code path the other thread is going to take - /without 
contention/ for updating a shared bit.

Alex


On 21/01/2014 09:52, Andrew Haley wrote:
> On 01/20/2014 08:03 PM, Oleksandr Otenko wrote:
>> Thread1:
>> A=1;
>> r2=B;
>>
>> Thread2:
>> B=2;
>> r1=A;
>>
>>
>> Table 17.5
>> <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>
>> permits a reordering such that both r2 and r1 see 0, yet the
>> Cookbook does not.
> Why do you say that the Cookbook does not allow this?
>
> Andrew.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/988b462e/attachment.html>

From vitalyd at gmail.com  Tue Jan 21 11:29:49 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 21 Jan 2014 11:29:49 -0500
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DE9953.4070008@oracle.com>
References: <52DD8124.1060103@oracle.com> <52DE4353.3000809@redhat.com>
	<52DE9953.4070008@oracle.com>
Message-ID: <CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>

Pretty sure that table is not talking about volatiles.

Sent from my phone
On Jan 21, 2014 11:11 AM, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
wrote:

>  Assuming table 17.5 is talking about volatiles. If not, the point is moot.
>
> Because the table of required barriers requires a Store-Load barrier
> between each of the lines, and defines the barriers as such that the
> preceding stores become visible before load is executed.
>
> This means that by observing r2==0 one can conclude that A=1 was executed
> before r2=B (Store-Load required), that B=2 will be executed after r2=B
> (causal dependency), and r1=A will be executed after B=2 (Store-Load
> required). So, by definition of Store-Load, A=1 will be visible before r2=B
> observed that B=2 hasn't executed yet, therefore, r1=A cannot observe r1==0.
>
>
> The beauty of this is that by excluding r1==0 && r2==0, you now can
> *infer* the code path the other thread is going to take - *without
> contention* for updating a shared bit.
>
> Alex
>
>
> On 21/01/2014 09:52, Andrew Haley wrote:
>
> On 01/20/2014 08:03 PM, Oleksandr Otenko wrote:
>
>
> Thread1:
> A=1;
> r2=B;
>
> Thread2:
> B=2;
> r1=A;
>
>
> Table 17.5<http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1> <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>
> permits a reordering such that both r2 and r1 see 0, yet the
> Cookbook does not.
>
>
> Why do you say that the Cookbook does not allow this?
>
> Andrew.
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/8048a17e/attachment.html>

From viktor.klang at gmail.com  Tue Jan 21 11:38:38 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 21 Jan 2014 17:38:38 +0100
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
References: <52DD8124.1060103@oracle.com> <52DE4353.3000809@redhat.com>
	<52DE9953.4070008@oracle.com>
	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
Message-ID: <CANPzfU8RO9E_-=nt+J_k2QjL05x1zcBDVto1H1JBwg5eObXgDQ@mail.gmail.com>

+1


On Tue, Jan 21, 2014 at 5:29 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Pretty sure that table is not talking about volatiles.
>
> Sent from my phone
> On Jan 21, 2014 11:11 AM, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
> wrote:
>
>>  Assuming table 17.5 is talking about volatiles. If not, the point is
>> moot.
>>
>> Because the table of required barriers requires a Store-Load barrier
>> between each of the lines, and defines the barriers as such that the
>> preceding stores become visible before load is executed.
>>
>> This means that by observing r2==0 one can conclude that A=1 was executed
>> before r2=B (Store-Load required), that B=2 will be executed after r2=B
>> (causal dependency), and r1=A will be executed after B=2 (Store-Load
>> required). So, by definition of Store-Load, A=1 will be visible before r2=B
>> observed that B=2 hasn't executed yet, therefore, r1=A cannot observe r1==0.
>>
>>
>> The beauty of this is that by excluding r1==0 && r2==0, you now can
>> *infer* the code path the other thread is going to take - *without
>> contention* for updating a shared bit.
>>
>> Alex
>>
>>
>> On 21/01/2014 09:52, Andrew Haley wrote:
>>
>> On 01/20/2014 08:03 PM, Oleksandr Otenko wrote:
>>
>>  Thread1:
>> A=1;
>> r2=B;
>>
>> Thread2:
>> B=2;
>> r1=A;
>>
>>
>> Table 17.5<http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1> <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>
>> permits a reordering such that both r2 and r1 see 0, yet the
>> Cookbook does not.
>>
>>  Why do you say that the Cookbook does not allow this?
>>
>> Andrew.
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/7446af62/attachment-0001.html>

From oleksandr.otenko at oracle.com  Tue Jan 21 13:52:48 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 18:52:48 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>
	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
Message-ID: <52DEC200.9090006@oracle.com>

I'd like a definitive answer.

Per JMM, the only thing ordering A=1 and r2=B is program order, which is 
not different for A and B treated either as volatiles or as 
non-volatiles - or is it. In that case since A=1 and r2=B are allowed to 
be executed in a different order for non-volatiles (ie in a order that 
permits the same visibility of their effects in one thread), which 
statement in JMM precludes this reordering for volatiles?


Alex


On 21/01/2014 16:29, Vitaly Davidovich wrote:
>
> Pretty sure that table is not talking about volatiles.
>
> Sent from my phone
>
> On Jan 21, 2014 11:11 AM, "Oleksandr Otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Assuming table 17.5 is talking about volatiles. If not, the point
>     is moot.
>
>     Because the table of required barriers requires a Store-Load
>     barrier between each of the lines, and defines the barriers as
>     such that the preceding stores become visible before load is executed.
>
>     This means that by observing r2==0 one can conclude that A=1 was
>     executed before r2=B (Store-Load required), that B=2 will be
>     executed after r2=B (causal dependency), and r1=A will be executed
>     after B=2 (Store-Load required). So, by definition of Store-Load,
>     A=1 will be visible before r2=B observed that B=2 hasn't executed
>     yet, therefore, r1=A cannot observe r1==0.
>
>
>     The beauty of this is that by excluding r1==0 && r2==0, you now
>     can /infer/ the code path the other thread is going to take -
>     /without contention/ for updating a shared bit.
>
>     Alex
>
>
>     On 21/01/2014 09:52, Andrew Haley wrote:
>>     On 01/20/2014 08:03 PM, Oleksandr Otenko wrote:
>>>     Thread1:
>>>     A=1;
>>>     r2=B;
>>>
>>>     Thread2:
>>>     B=2;
>>>     r1=A;
>>>
>>>
>>>     Table 17.5
>>>     <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>  <http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5-table-1>
>>>     permits a reordering such that both r2 and r1 see 0, yet the
>>>     Cookbook does not.
>>     Why do you say that the Cookbook does not allow this?
>>
>>     Andrew.
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/75a02d44/attachment.html>

From aleksey.shipilev at oracle.com  Tue Jan 21 14:05:18 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Tue, 21 Jan 2014 23:05:18 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEC200.9090006@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com>
Message-ID: <52DEC4EE.9040303@oracle.com>

On 01/21/2014 10:52 PM, Oleksandr Otenko wrote:
> I'd like a definitive answer.
> 
> Per JMM, the only thing ordering A=1 and r2=B is program order, which is
> not different for A and B treated either as volatiles or as
> non-volatiles - or is it. In that case since A=1 and r2=B are allowed to
> be executed in a different order for non-volatiles (ie in a order that
> permits the same visibility of their effects in one thread), which
> statement in JMM precludes this reordering for volatiles?

Volatile reads/writes are "synchronization actions" (JLS 17.4.2)
Synchronization actions form the Synchronization Order. Synchronization
Order is *total* order (JLS 17.4.4).

BTW, the example with volatiles is better known as "Dekker example",
because it is the core of Dekker lock. The outcome (0, 0) is forbidden
because it breaks Dekker lock mutual exclusion guarantees.

jcstress has the relevant example here:
 http://hg.openjdk.java.net/code-tools/jcstress/file/ecfe9e112bc6/tests-custom/src/main/java/org/openjdk/jcstress/tests/volatiles/DekkerTest.java

-Aleksey.


From oleksandr.otenko at oracle.com  Tue Jan 21 14:52:11 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 19:52:11 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEC4EE.9040303@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
Message-ID: <52DECFEB.9070105@oracle.com>

This is where you first need to tell me what is meant by "total order".

What I understand by total order here, is a total order representing the 
partial order at the time of execution - like, if someone took out the 
ruler representing the time line, and arranged the partially ordered 
events along it, that would become a total order - one of many possible 
total orders that represent the same partial order.

The partial order here is constructed of synchronizes-with edges, which 
only relate to the events on the same variable, and program order, which 
only respects intra-thread semantics (and which is also declared to be 
"total", so reordering of non-volatiles is by virtue of.... absence of 
dependency between two events in partial order, making different total 
orders valid).

Alex


On 21/01/2014 19:05, Aleksey Shipilev wrote:
> On 01/21/2014 10:52 PM, Oleksandr Otenko wrote:
>> I'd like a definitive answer.
>>
>> Per JMM, the only thing ordering A=1 and r2=B is program order, which is
>> not different for A and B treated either as volatiles or as
>> non-volatiles - or is it. In that case since A=1 and r2=B are allowed to
>> be executed in a different order for non-volatiles (ie in a order that
>> permits the same visibility of their effects in one thread), which
>> statement in JMM precludes this reordering for volatiles?
> Volatile reads/writes are "synchronization actions" (JLS 17.4.2)
> Synchronization actions form the Synchronization Order. Synchronization
> Order is *total* order (JLS 17.4.4).
>
> BTW, the example with volatiles is better known as "Dekker example",
> because it is the core of Dekker lock. The outcome (0, 0) is forbidden
> because it breaks Dekker lock mutual exclusion guarantees.
>
> jcstress has the relevant example here:
>   http://hg.openjdk.java.net/code-tools/jcstress/file/ecfe9e112bc6/tests-custom/src/main/java/org/openjdk/jcstress/tests/volatiles/DekkerTest.java
>
> -Aleksey.
>


From aleksey.shipilev at oracle.com  Tue Jan 21 16:19:40 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 22 Jan 2014 01:19:40 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DECFEB.9070105@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com>
Message-ID: <52DEE46C.3000302@oracle.com>

On 01/21/2014 11:52 PM, Oleksandr Otenko wrote:
> This is where you first need to tell me what is meant by "total order".

http://en.wikipedia.org/wiki/Total_order

> What I understand by total order here, is a total order representing the
> partial order at the time of execution - like, if someone took out the
> ruler representing the time line, and arranged the partially ordered
> events along it, that would become a total order - one of many possible
> total orders that represent the same partial order.

Right. The tidbit is that the final order should still satisfy a few
conditions.

> The partial order here is constructed of synchronizes-with edges, which
> only relate to the events on the same variable, and program order, which
> only respects intra-thread semantics (and which is also declared to be
> "total", so reordering of non-volatiles is by virtue of.... absence of
> dependency between two events in partial order, making different total
> orders valid).

Not sure what synchronizes-with has to do with this. Non-volatiles are
irrelevant here because they don't participate in synchronization order.

Synchronization order is consistent with program order (JLS 17.4.4).
Together with the definition well-formed execution, which requires
"synchronization-order consistency" (JLS 17.4.7, point 5) to observe the
written values, DekkerTest can only have SO-s in which (0, 0) is not the
possible result.

Example:

    volatile int A, B;
-----------------------------
  (1) A = 1   |  (3) B = 1
  (2) r1 = B  |  (4) r2 = A

We can have some fun and construct all the possible total orders, by
exactly the method you described. I'll just use the statement indexes as
digits to represent the order. The peculiarity is that the constructed
order still needs to be consistent with PO. Note that any SO order
containing *2*1* or *4*3* violates PO consistency.

Let's do this:

 1234 // ok, yields (0, 1)
 1243 // inconsistent with PO
 1324 // ok, yields (1, 1)
 1342 // ok, yields (1, 1)
 1423 // inconsistent with PO
 1432 // inconsistent with PO

 2134 // inconsistent with PO
 2143 // inconsistent with PO
 2314 // inconsistent with PO
 2341 // inconsistent with PO
 2413 // inconsistent with PO
 2431 // inconsistent with PO

 3124 // ok, yields (1, 1)
 3142 // ok, yields (1, 1)
 3214 // inconsistent with PO
 3241 // inconsistent with PO
 3412 // ok, yields (1, 0)
 3421 // inconsistent with PO

 4123 // inconsistent with PO
 4132 // inconsistent with PO
 4213 // inconsistent with PO
 4231 // inconsistent with PO
 4312 // inconsistent with PO
 4321 // inconsistent with PO

I.e. the exhaustive search yields no synchronization orders that yield
(0, 0). Q.E.D.

This construction, BTW, has a nice and short interpretation: since SO is
total and consistent with PO, either (2) or (4) should come last, which
means at least one of (1) or (3) is visible. Hence, either r1, or r2, or
both should be 1.

There are more peculiar corollaries from this, one of my favorite is
IRIW:
http://cs.oswego.edu/pipermail/concurrency-interest/2012-December/010455.html

-Aleksey.


From oleksandr.otenko at oracle.com  Tue Jan 21 16:32:11 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 21:32:11 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEE46C.3000302@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
Message-ID: <52DEE75B.3060709@oracle.com>

On 21/01/2014 21:19, Aleksey Shipilev wrote:
> On 01/21/2014 11:52 PM, Oleksandr Otenko wrote:
>> This is where you first need to tell me what is meant by "total order".
> http://en.wikipedia.org/wiki/Total_order

This is basics. The question was "Total order" when? See, below you too 
talk about partial order first, so initially operations are in a partial 
order representing the causal structure of the program.


>> What I understand by total order here, is a total order representing the
>> partial order at the time of execution - like, if someone took out the
>> ruler representing the time line, and arranged the partially ordered
>> events along it, that would become a total order - one of many possible
>> total orders that represent the same partial order.
> Right. The tidbit is that the final order should still satisfy a few
> conditions.
Yes. Which condition then is related to volatiles, is the question.


>> The partial order here is constructed of synchronizes-with edges, which
>> only relate to the events on the same variable, and program order, which
>> only respects intra-thread semantics (and which is also declared to be
>> "total", so reordering of non-volatiles is by virtue of.... absence of
>> dependency between two events in partial order, making different total
>> orders valid).
> Not sure what synchronizes-with has to do with this. Non-volatiles are
> irrelevant here because they don't participate in synchronization order.

It matters, because between volatiles and non-volatiles 
synchronizes-with is the only difference, so you need to show how that 
influences the layout of partial order into total order.

(or by what clause the program order for volatiles and non-volatiles is 
different)


>
> Synchronization order is consistent with program order (JLS 17.4.4).
> Together with the definition well-formed execution, which requires
> "synchronization-order consistency" (JLS 17.4.7, point 5) to observe the
> written values, DekkerTest can only have SO-s in which (0, 0) is not the
> possible result.
>
> Example:
>
>      volatile int A, B;
> -----------------------------
>    (1) A = 1   |  (3) B = 1
>    (2) r1 = B  |  (4) r2 = A
>
> We can have some fun and construct all the possible total orders, by
> exactly the method you described. I'll just use the statement indexes as
> digits to represent the order. The peculiarity is that the constructed
> order still needs to be consistent with PO. Note that any SO order
> containing *2*1* or *4*3* violates PO consistency.
This is the statement I was looking for. Let's focus on which statement 
forbids *2*1* or *4*3* for volatiles, but doesn't forbid for non-volatiles.

In other words, if reodrering 2 and 1 doesn't break PO for 
non-volatiles, what statement in JMM makes *PO* break for volatiles?


Alex


>
> Let's do this:
>
>   1234 // ok, yields (0, 1)
>   1243 // inconsistent with PO
>   1324 // ok, yields (1, 1)
>   1342 // ok, yields (1, 1)
>   1423 // inconsistent with PO
>   1432 // inconsistent with PO
>
>   2134 // inconsistent with PO
>   2143 // inconsistent with PO
>   2314 // inconsistent with PO
>   2341 // inconsistent with PO
>   2413 // inconsistent with PO
>   2431 // inconsistent with PO
>
>   3124 // ok, yields (1, 1)
>   3142 // ok, yields (1, 1)
>   3214 // inconsistent with PO
>   3241 // inconsistent with PO
>   3412 // ok, yields (1, 0)
>   3421 // inconsistent with PO
>
>   4123 // inconsistent with PO
>   4132 // inconsistent with PO
>   4213 // inconsistent with PO
>   4231 // inconsistent with PO
>   4312 // inconsistent with PO
>   4321 // inconsistent with PO
>
> I.e. the exhaustive search yields no synchronization orders that yield
> (0, 0). Q.E.D.
>
> This construction, BTW, has a nice and short interpretation: since SO is
> total and consistent with PO, either (2) or (4) should come last, which
> means at least one of (1) or (3) is visible. Hence, either r1, or r2, or
> both should be 1.
>
> There are more peculiar corollaries from this, one of my favorite is
> IRIW:
> http://cs.oswego.edu/pipermail/concurrency-interest/2012-December/010455.html
>
> -Aleksey.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/08b5345a/attachment-0001.html>

From aleksey.shipilev at oracle.com  Tue Jan 21 16:55:26 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 22 Jan 2014 01:55:26 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEE75B.3060709@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com>
Message-ID: <52DEECCE.5080707@oracle.com>

On 01/22/2014 01:32 AM, Oleksandr Otenko wrote:
>>> The partial order here is constructed of synchronizes-with edges, which
>>> only relate to the events on the same variable, and program order, which
>>> only respects intra-thread semantics (and which is also declared to be
>>> "total", so reordering of non-volatiles is by virtue of.... absence of
>>> dependency between two events in partial order, making different total
>>> orders valid).
>> Not sure what synchronizes-with has to do with this. Non-volatiles are
>> irrelevant here because they don't participate in synchronization order.
> 
> It matters, because between volatiles and non-volatiles
> synchronizes-with is the only difference, so you need to show how that
> influences the layout of partial order into total order.

I'm confused. What synchronizes-with (SW) has to do with this? As far as
I understand, SW is needed to construct HB, and HB is irrelevant here,
we talk about different order, SO.

Also, why the "only" difference? I just gave you the spec reference
where it says specifically about volatile actions being synchronization
actions and specific treatment of synchronization actions through SO
(JLS 17.4.4). Is that different enough vs. non-volatiles?

>> We can have some fun and construct all the possible total orders, by
>> exactly the method you described. I'll just use the statement indexes as
>> digits to represent the order. The peculiarity is that the constructed
>> order still needs to be consistent with PO. Note that any SO order
>> containing *2*1* or *4*3* violates PO consistency.
> This is the statement I was looking for. Let's focus on which statement
> forbids *2*1* or *4*3* for volatiles, but doesn't forbid for non-volatiles.
> 
> In other words, if reodrering 2 and 1 doesn't break PO for
> non-volatiles, what statement in JMM makes *PO* break for volatiles?

Nowhere in spec it says PO should be maintained.

The properties of the *derived* orders should be maintained to make an
execution plausible under JMM. E.g. SO should be total and consistent
with PO. By requiring SO being coherent with PO we "leak" the ordering
information from the PO into SO, and in effect require the intra-thread
order of volatile actions. This luxury does not extend to non-volatile
actions, because they are not the part of SO. The ordering guarantees
for non-volatile actions are governed elsewhere, e.g. through HB order.

-Aleksey.


From oleksandr.otenko at oracle.com  Tue Jan 21 17:25:29 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 22:25:29 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEE46C.3000302@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
Message-ID: <52DEF3D9.7040500@oracle.com>

On 21/01/2014 21:19, Aleksey Shipilev wrote:

> This construction, BTW, has a nice and short interpretation: since SO is
> total and consistent with PO, either (2) or (4) should come last, which
> means at least one of (1) or (3) is visible. Hence, either r1, or r2, or
> both should be 1.
>
> There are more peculiar corollaries from this, one of my favorite is
> IRIW:
> http://cs.oswego.edu/pipermail/concurrency-interest/2012-December/010455.html
>
> -Aleksey.
>

By the way, IRIW outcomes can be shown like so:

because the values of x and y can only grow, it is the same as saying 
that (x=0) occurred before (x=1), and the same for y. It is convenient, 
because now seeing a < b is a witness that a occurred before b. The 
order of execution of volatile accesses in threads 3 and 4 is connected 
with the magnitude of the values like so:

if thread 3 observes x <= y, it is a witness that y=1 executed after 
x=*0*, which is vacuously true, and permits any order of events to be 
observed by thread 4.

However, if thread 3 observes x > y, it is a witness that y=1 (will be) 
executed after x=1. This forbids thread 4 to observe y > x, which is 
what you were asking: the only broken case is, indeed, 1,0,0,1.


Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140121/21f9d2de/attachment.html>

From oleksandr.otenko at oracle.com  Tue Jan 21 17:49:02 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 22:49:02 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEECCE.5080707@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com> <52DEECCE.5080707@oracle.com>
Message-ID: <52DEF95E.1000800@oracle.com>

Let's put SW aside for a moment.

What ordering permits r1==0 && r2==0, if A and B are non-volatile? 
Something like this: 2413, no? But you quote this as breaking PO.

This is the bit that I don't get. If it breaks PO for volatiles, why 
doesn't it break PO for non-volatiles?


Alex

On 21/01/2014 21:55, Aleksey Shipilev wrote:
> On 01/22/2014 01:32 AM, Oleksandr Otenko wrote:
>>>> The partial order here is constructed of synchronizes-with edges, which
>>>> only relate to the events on the same variable, and program order, which
>>>> only respects intra-thread semantics (and which is also declared to be
>>>> "total", so reordering of non-volatiles is by virtue of.... absence of
>>>> dependency between two events in partial order, making different total
>>>> orders valid).
>>> Not sure what synchronizes-with has to do with this. Non-volatiles are
>>> irrelevant here because they don't participate in synchronization order.
>> It matters, because between volatiles and non-volatiles
>> synchronizes-with is the only difference, so you need to show how that
>> influences the layout of partial order into total order.
> I'm confused. What synchronizes-with (SW) has to do with this? As far as
> I understand, SW is needed to construct HB, and HB is irrelevant here,
> we talk about different order, SO.
>
> Also, why the "only" difference? I just gave you the spec reference
> where it says specifically about volatile actions being synchronization
> actions and specific treatment of synchronization actions through SO
> (JLS 17.4.4). Is that different enough vs. non-volatiles?
>
>>> We can have some fun and construct all the possible total orders, by
>>> exactly the method you described. I'll just use the statement indexes as
>>> digits to represent the order. The peculiarity is that the constructed
>>> order still needs to be consistent with PO. Note that any SO order
>>> containing *2*1* or *4*3* violates PO consistency.
>> This is the statement I was looking for. Let's focus on which statement
>> forbids *2*1* or *4*3* for volatiles, but doesn't forbid for non-volatiles.
>>
>> In other words, if reodrering 2 and 1 doesn't break PO for
>> non-volatiles, what statement in JMM makes *PO* break for volatiles?
> Nowhere in spec it says PO should be maintained.
>
> The properties of the *derived* orders should be maintained to make an
> execution plausible under JMM. E.g. SO should be total and consistent
> with PO. By requiring SO being coherent with PO we "leak" the ordering
> information from the PO into SO, and in effect require the intra-thread
> order of volatile actions. This luxury does not extend to non-volatile
> actions, because they are not the part of SO. The ordering guarantees
> for non-volatile actions are governed elsewhere, e.g. through HB order.
>
> -Aleksey.
>


From hans.boehm at hp.com  Tue Jan 21 18:10:09 2014
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 21 Jan 2014 23:10:09 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEE75B.3060709@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>
	<52DE9953.4070008@oracle.com>
	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>

> Example:

>     volatile int A, B;
> -----------------------------
>   (1) A = 1   |  (3) B = 1
>   (2) r1 = B  |  (4) r2 = A

Another way to see r1 = r2 = 0 is impossible with volatile A and B:

- Either (1) or (3) occurs first in the synchronization order (17.4.4).  Assume (1) occurs first.  (The other case is similar.)

- (1) synchronizes with (4) (17.4.4), and therefore (1) happens before (4) (17.4.5).

- (4) must see the write at (1), which happens after the initializing write, but happens before (4).  (17.4.5, intervening write.) Thus r2 = 1.  (In the other case r1 = 1.)

None of this applies if wither A or B is not volatile.

Hans




From oleksandr.otenko at oracle.com  Tue Jan 21 18:30:50 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 21 Jan 2014 23:30:50 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>	<52DEC200.9090006@oracle.com>
	<52DEC4EE.9040303@oracle.com>	<52DECFEB.9070105@oracle.com>
	<52DEE46C.3000302@oracle.com> <52DEE75B.3060709@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
Message-ID: <52DF032A.4040502@oracle.com>

On 21/01/2014 23:10, Boehm, Hans wrote:
>> Example:
>>      volatile int A, B;
>> -----------------------------
>>    (1) A = 1   |  (3) B = 1
>>    (2) r1 = B  |  (4) r2 = A
> Another way to see r1 = r2 = 0 is impossible with volatile A and B:
>
> - Either (1) or (3) occurs first in the synchronization order (17.4.4).  Assume (1) occurs first.  (The other case is similar.)
>
> - (1) synchronizes with (4) (17.4.4), and therefore (1) happens before (4) (17.4.5).

Hang on. What is the meaning of "synchronizes with"? It is mentioned in 
JMM, but it doesn't explain how that "synchronization" "happens". In 
reality (4) can be executed before (1) as well as after it, so I don't 
see what it means that (1) "synchronizes with" (4). So I expect a step 
somewhere here that says "(4) is after (3)", and Aleksey mentions PO.

So far so good, but (4) is after (3) even in non-volatile case, isn't 
it? If so, then what execution order permits to observe r1==0 and r2==0, 
if B==1 before r2==0?

Well, it could work, if (4) and (3) aren't really ordered like that in 
non-volatile case, so executing (4) then (3) doesn't break Program 
Order. Why then do we say PO gets broken, if (4) is before (3)?


Alex


>
> - (4) must see the write at (1), which happens after the initializing write, but happens before (4).  (17.4.5, intervening write.) Thus r2 = 1.  (In the other case r1 = 1.)
>
> None of this applies if wither A or B is not volatile.
>
> Hans
>
>


From aleksey.shipilev at oracle.com  Tue Jan 21 18:55:59 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 22 Jan 2014 03:55:59 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DEF95E.1000800@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com> <52DEECCE.5080707@oracle.com>
	<52DEF95E.1000800@oracle.com>
Message-ID: <52DF090F.4080004@oracle.com>

On 01/22/2014 02:49 AM, Oleksandr Otenko wrote:
> What ordering permits r1==0 && r2==0, if A and B are non-volatile?
> Something like this: 2413, no? But you quote this as breaking PO.

1. I never said "breaking PO", only you keep repeating it. I only said
"SO is inconsistent with PO".

2. Once again, we do not require PO to be maintained. The very reason
for memory model to exist is to mess with PO. We only require the
properties of the *derived* orders to hold true.

3. If A and B are non-volatile, then nothing prevents from committing
the actions in order 2413.

4. If A and B are volatile, then SO intervenes, and makes 2413
non-plausible execution because... [see previous note]

-Aleksey.


From hans.boehm at hp.com  Tue Jan 21 19:01:32 2014
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 22 Jan 2014 00:01:32 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DF032A.4040502@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>
	<52DE9953.4070008@oracle.com>
	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
	<52DF032A.4040502@oracle.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23D551B7A@G9W0725.americas.hpqcorp.net>

> From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
> 
> On 21/01/2014 23:10, Boehm, Hans wrote:
> >> Example:
> >>      volatile int A, B;
> >> -----------------------------
> >>    (1) A = 1   |  (3) B = 1
> >>    (2) r1 = B  |  (4) r2 = A
> > Another way to see r1 = r2 = 0 is impossible with volatile A and B:
> >
> > - Either (1) or (3) occurs first in the synchronization order
> (17.4.4).  Assume (1) occurs first.  (The other case is similar.)
> >
> > - (1) synchronizes with (4) (17.4.4), and therefore (1) happens
> before (4) (17.4.5).
> 
> Hang on. What is the meaning of "synchronizes with"? It is mentioned in
> JMM, but it doesn't explain how that "synchronization" "happens". In
> reality (4) can be executed before (1) as well as after it, so I don't
> see what it means that (1) "synchronizes with" (4). So I expect a step
> somewhere here that says "(4) is after (3)", and Aleksey mentions PO.
The memory model is a semi-formal description of what writes can be seen
by a read in your program, in spite of the reality that there is no total
(e.g. time) order in which the instructions execute.  The only total order
that spans the whole program is on synchronization operations.  (These do
behave as though they were executed in a single total order, though the
JMM says that only somewhat indirectly.)  Program order
does figure into the argument that (1) or (3) must be first in
the synchronization order.  The synchronization order is effectively an
interleaving of the synchronization operations from each thread, i.e.
synchronization operations of each thread must appear in program order.
> 
> So far so good, but (4) is after (3) even in non-volatile case, isn't
> it? If so, then what execution order permits to observe r1==0 and
> r2==0,
> if B==1 before r2==0?
There is no notion of "is after", except in the synchronization order.
Instructions don't execute in some total "time" order.  A write by
one thread may be seen at different times by each of the other threads.
In the non-volatile case, there are no synchronization operations, and the
synchronization order is empty.
> 
> Well, it could work, if (4) and (3) aren't really ordered like that in
> non-volatile case, so executing (4) then (3) doesn't break Program
> Order. Why then do we say PO gets broken, if (4) is before (3)?
I don't understand the notion of breaking program order.  Program order
contributes to happens-before, which largely determines what values can
be seen by a read.  In the non-volatile case, the happens-before order
is the program-order, with initializations happening before everything
else.  That means that each read can see either write, with absolutely
no constraint.  The initialization happens before the read, and the write
of 1 is unordered with respect to the read, meaning that each read can see
either, independent of what the other read sees.

A far simpler alternate model is that so long as there are no data races
(simultaneous accesses to the same non-volatile object, at least one of which
is a write), you get sequential consistency, and everything behaves as you would
expect.  If there is a data race, very weird things happen, and if you care
precisely what happens, you have to understand chapter 17 details.  This
view is entirely consistent with chapter 17. The volatile case is
data-race-free, and nothing weird happens.

Hans

> 
> 
> Alex
> 
> 
> >
> > - (4) must see the write at (1), which happens after the initializing
> write, but happens before (4).  (17.4.5, intervening write.) Thus r2 =
> 1.  (In the other case r1 = 1.)
> >
> > None of this applies if wither A or B is not volatile.
> >
> > Hans
> >
> >



From oleksandr.otenko at oracle.com  Wed Jan 22 10:58:23 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 22 Jan 2014 15:58:23 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DF090F.4080004@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com> <52DEECCE.5080707@oracle.com>
	<52DEF95E.1000800@oracle.com> <52DF090F.4080004@oracle.com>
Message-ID: <52DFEA9F.3080309@oracle.com>

On 21/01/2014 23:55, Aleksey Shipilev wrote:
> On 01/22/2014 02:49 AM, Oleksandr Otenko wrote:
>> What ordering permits r1==0 && r2==0, if A and B are non-volatile?
>> Something like this: 2413, no? But you quote this as breaking PO.
> 1. I never said "breaking PO", only you keep repeating it. I only said
> "SO is inconsistent with PO".
Yes, you didn't use the word "breaking" but I don't see how 
"inconsistent" is better than "breaking".


> 2. Once again, we do not require PO to be maintained. The very reason
> for memory model to exist is to mess with PO. We only require the
> properties of the *derived* orders to hold true.

ok, "An execution /E/ is described by a tuple < /P, A, po, so, W, V, sw, 
hb/ >" - which of these is a *derived* order?


Alex


> 3. If A and B are non-volatile, then nothing prevents from committing
> the actions in order 2413.
>
> 4. If A and B are volatile, then SO intervenes, and makes 2413
> non-plausible execution because... [see previous note]
>
> -Aleksey.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140122/5f83746b/attachment.html>

From oleksandr.otenko at oracle.com  Wed Jan 22 11:43:33 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 22 Jan 2014 16:43:33 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23D551B7A@G9W0725.americas.hpqcorp.net>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>	<52DEC200.9090006@oracle.com>
	<52DEC4EE.9040303@oracle.com>	<52DECFEB.9070105@oracle.com>
	<52DEE46C.3000302@oracle.com> <52DEE75B.3060709@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
	<52DF032A.4040502@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B7A@G9W0725.americas.hpqcorp.net>
Message-ID: <52DFF535.4070500@oracle.com>

On 22/01/2014 00:01, Boehm, Hans wrote:
>> From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
>>
>> On 21/01/2014 23:10, Boehm, Hans wrote:
>>>> Example:
>>>>       volatile int A, B;
>>>> -----------------------------
>>>>     (1) A = 1   |  (3) B = 1
>>>>     (2) r1 = B  |  (4) r2 = A
>>> Another way to see r1 = r2 = 0 is impossible with volatile A and B:
>>>
>>> - Either (1) or (3) occurs first in the synchronization order
>> (17.4.4).  Assume (1) occurs first.  (The other case is similar.)
>>> - (1) synchronizes with (4) (17.4.4), and therefore (1) happens
>> before (4) (17.4.5).
>>
>> Hang on. What is the meaning of "synchronizes with"? It is mentioned in
>> JMM, but it doesn't explain how that "synchronization" "happens". In
>> reality (4) can be executed before (1) as well as after it, so I don't
>> see what it means that (1) "synchronizes with" (4). So I expect a step
>> somewhere here that says "(4) is after (3)", and Aleksey mentions PO.
> The memory model is a semi-formal description of what writes can be seen
> by a read in your program, in spite of the reality that there is no total
> (e.g. time) order in which the instructions execute.

Yes, this is clear.  But we can project this into a total order, and 
that's what I think JMM tries to specify, right?

At first I thought that hb is that partial order of instructions. It 
makes sense that if hb order can be projected into program order, then 
hb is the implementation of the program order. It also makes sense, if 
synchronization order can be projected into hb, and that way determine 
how the volatiles can be ordered.

However, this understanding doesn't add up: "It should be noted that the 
presence of a /happens-before/ relationship between two actions does not 
necessarily imply that they have to take place in that order in an 
implementation.", and the way hb is /constructed/ seems backwards w.r.t. 
that implementation: "If /x/ and /y/ are actions of the same thread and 
/x/ comes before /y/ in program order, then /hb(x, y)/.". This latter 
statement says that if there is PO between any actions, including 
non-volatiles, there is hb between them.

What's the point of having hb then, if PO already defines all the edges 
in the order? It would make sense, if PO /didn't/ define all the edges. 
For example, say it the other way around: for all x and y in hb there is 
x and y in po (all vertices can be projected); if hb(x,y) for some x and 
y, then x must appear before y in program order (all edges can be 
projected pointing the same way around); this defines a function from hb 
to po. Same for synchronization order: projecting so into hb has the 
meaning that hb can only have those operations in total order.

Also, then add to confusion that hb doesn't determine even the order of 
instructions in the implementation, because they "don't necessarily take 
place in that order".



>   The only total order
> that spans the whole program is on synchronization operations.  (These do
> behave as though they were executed in a single total order, though the
> JMM says that only somewhat indirectly.)  Program order
> does figure into the argument that (1) or (3) must be first in
> the synchronization order.  The synchronization order is effectively an
> interleaving of the synchronization operations from each thread, i.e.
> synchronization operations of each thread must appear in program order.
>> So far so good, but (4) is after (3) even in non-volatile case, isn't
>> it? If so, then what execution order permits to observe r1==0 and
>> r2==0,
>> if B==1 before r2==0?
> There is no notion of "is after", except in the synchronization order.
> Instructions don't execute in some total "time" order.  A write by
> one thread may be seen at different times by each of the other threads.
Yes, this is clear from the Cookbook, but isn't clear how this is 
expressed in JMM.

For different threads to observe different order of operations there 
must be some order of all instructions of the program as seen by each 
thread individually. Which concept in JMM reflects this?

> In the non-volatile case, there are no synchronization operations, and the
> synchronization order is empty.
>> Well, it could work, if (4) and (3) aren't really ordered like that in
>> non-volatile case, so executing (4) then (3) doesn't break Program
>> Order. Why then do we say PO gets broken, if (4) is before (3)?
> I don't understand the notion of breaking program order.  Program order
> contributes to happens-before, which largely determines what values can
> be seen by a read.  In the non-volatile case, the happens-before order
> is the program-order, with initializations happening before everything
> else.  That means that each read can see either write, with absolutely
> no constraint.  The initialization happens before the read, and the write
> of 1 is unordered with respect to the read, meaning that each read can see
> either, independent of what the other read sees.
This is the thing I don't understand about "synchronizes with". A 
volatile read can also be executed in any order w.r.t. the write of 1, 
so can also observe either 0, or 1.


>
> A far simpler alternate model is that so long as there are no data races
> (simultaneous accesses to the same non-volatile object, at least one of which
> is a write), you get sequential consistency, and everything behaves as you would
> expect.  If there is a data race, very weird things happen, and if you care
> precisely what happens, you have to understand chapter 17 details.  This
> view is entirely consistent with chapter 17. The volatile case is
> data-race-free, and nothing weird happens.

Yes, that's what I am trying to understand :)


Alex


>
> Hans
>
>>
>> Alex
>>
>>
>>> - (4) must see the write at (1), which happens after the initializing
>> write, but happens before (4).  (17.4.5, intervening write.) Thus r2 =
>> 1.  (In the other case r1 = 1.)
>>> None of this applies if wither A or B is not volatile.
>>>
>>> Hans
>>>
>>>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140122/6e855a97/attachment.html>

From aleksey.shipilev at oracle.com  Wed Jan 22 14:25:13 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 22 Jan 2014 23:25:13 +0400
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DFEA9F.3080309@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com> <52DEECCE.5080707@oracle.com>
	<52DEF95E.1000800@oracle.com> <52DF090F.4080004@oracle.com>
	<52DFEA9F.3080309@oracle.com>
Message-ID: <52E01B19.2000509@oracle.com>

On 01/22/2014 07:58 PM, Oleksandr Otenko wrote:
> On 21/01/2014 23:55, Aleksey Shipilev wrote:
>> On 01/22/2014 02:49 AM, Oleksandr Otenko wrote:
>>> What ordering permits r1==0 && r2==0, if A and B are non-volatile?
>>> Something like this: 2413, no? But you quote this as breaking PO.
>> 1. I never said "breaking PO", only you keep repeating it. I only said
>> "SO is inconsistent with PO".
> Yes, you didn't use the word "breaking" but I don't see how
> "inconsistent" is better than "breaking".

This is not the same. Because you seem to be saying "execution is
breaking PO", and I'm saying "in execution, SO is inconsistent with PO".
Different subjects right there.

> 
>> 2. Once again, we do not require PO to be maintained. The very reason
>> for memory model to exist is to mess with PO. We only require the
>> properties of the *derived* orders to hold true.
> 
> ok, "An execution /E/ is described by a tuple < /P, A, po, so, W, V, sw,
> hb/ >" - which of these is a *derived* order?

Obviously, the derived orders are SO, SW, and HB. These derived orders
then participate in defining what constitutes a valid execution. Nowhere
in spec PO per se is used to define the properties of valid executions;
the only two places where PO disseminates the information about the
source program are SO for synchronization actions, and HB for everything
else.

It is important to understand that the "reordering" (God I hate this
word) is only detectable by reads observing the particular state. In
JMM, what is observed by reads is governed by HB (specifically, reads
see either the last write in HB, or any other write outside the HB [race]).

Any transformation on source program (e.g. any change in actual sequence
of instructions) is fine if we maintain the same observables through the
HB. This is what is meant in spec by "not implying the order by which
the actions take place in the implementation". As long as reads observe
the same, nobody cares.

-Aleksey.

From oleksandr.otenko at oracle.com  Wed Jan 22 18:46:32 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 22 Jan 2014 23:46:32 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52E01B19.2000509@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com> <52DEECCE.5080707@oracle.com>
	<52DEF95E.1000800@oracle.com> <52DF090F.4080004@oracle.com>
	<52DFEA9F.3080309@oracle.com> <52E01B19.2000509@oracle.com>
Message-ID: <52E05858.9030701@oracle.com>

On 22/01/2014 19:25, Aleksey Shipilev wrote:
> On 01/22/2014 07:58 PM, Oleksandr Otenko wrote:
>> On 21/01/2014 23:55, Aleksey Shipilev wrote:
>>> On 01/22/2014 02:49 AM, Oleksandr Otenko wrote:
>>>> What ordering permits r1==0 && r2==0, if A and B are non-volatile?
>>>> Something like this: 2413, no? But you quote this as breaking PO.
>>> 1. I never said "breaking PO", only you keep repeating it. I only said
>>> "SO is inconsistent with PO".
>> Yes, you didn't use the word "breaking" but I don't see how
>> "inconsistent" is better than "breaking".
> This is not the same. Because you seem to be saying "execution is
> breaking PO", and I'm saying "in execution, SO is inconsistent with PO".
> Different subjects right there.
>
>>> 2. Once again, we do not require PO to be maintained. The very reason
>>> for memory model to exist is to mess with PO. We only require the
>>> properties of the *derived* orders to hold true.
>> ok, "An execution /E/ is described by a tuple < /P, A, po, so, W, V, sw,
>> hb/ >" - which of these is a *derived* order?
> Obviously, the derived orders are SO, SW, and HB. These derived orders
> then participate in defining what constitutes a valid execution. Nowhere
> in spec PO per se is used to define the properties of valid executions;
Not so obvious, not so obvious.

Take this: "If /x/ and /y/ are actions of the same thread and /x/ comes 
before /y/ in program order, then /hb(x, y)/. "

and explain how that statement defines HB to be a "derived" order (I 
think you mean "derived" as in implementation can choose what it likes)

To me the above reads as "hb has all the vertices and edges of PO" - 
where's the implementation's choice there? Also, this shouldn't mean, 
but it does, that "B=2; r1=A;" have a hb between them, because their 
program order induces hb.


> the only two places where PO disseminates the information about the
> source program are SO for synchronization actions, and HB for everything
> else.
>
> It is important to understand that the "reordering" (God I hate this
> word) is only detectable by reads observing the particular state. In
> JMM, what is observed by reads is governed by HB (specifically, reads
> see either the last write in HB, or any other write outside the HB [race]).
Which order captures this fact? The fact that a read observes a write 
outside the HB?



>
> Any transformation on source program (e.g. any change in actual sequence
> of instructions) is fine if we maintain the same observables through the
> HB.
Yes, I can buy this. This was my original inkling, but some statements 
about how HB is constructed are confusing.

So, we say the program is free of races, if all reads see writes 
preceding them in HB, which only links together the /intended/ ordering. 
HB reflects causal dependencies in the same thread, and links to 
volatile writes in other threads. Then HB does not reflect the actual 
execution, but instead is a link showing all the writes in the /program/ 
that a particular read is allowed to see (so "happens-before" is more 
like "can-happen-before", and "synchronize-with" is 
"might-synchronize-with").

Then a execution will have writes of all kinds in yet another order, and 
we need to check that a read always sees only one of the intended writes.

If that is so, then need to understand where the order of writes is 
established (to see that some are in or out of HB), and where the 
different orders can be observed by different threads.


Alex

>   This is what is meant in spec by "not implying the order by which
> the actions take place in the implementation". As long as reads observe
> the same, nobody cares.
>
> -Aleksey.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140122/5a8bf5a2/attachment.html>

From hans.boehm at hp.com  Wed Jan 22 19:17:47 2014
From: hans.boehm at hp.com (Boehm, Hans)
Date: Thu, 23 Jan 2014 00:17:47 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <52DFF535.4070500@oracle.com>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>
	<52DE9953.4070008@oracle.com>
	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>
	<52DEC200.9090006@oracle.com> <52DEC4EE.9040303@oracle.com>
	<52DECFEB.9070105@oracle.com> <52DEE46C.3000302@oracle.com>
	<52DEE75B.3060709@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
	<52DF032A.4040502@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B7A@G9W0725.americas.hpqcorp.net>
	<52DFF535.4070500@oracle.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23D5523AF@G9W0725.americas.hpqcorp.net>



From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
Sent: Wednesday, January 22, 2014 8:44 AM
To: Boehm, Hans; Aleksey Shipilev
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model: table 17.5

On 22/01/2014 00:01, Boehm, Hans wrote:


From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]



On 21/01/2014 23:10, Boehm, Hans wrote:

Example:

     volatile int A, B;

-----------------------------

   (1) A = 1   |  (3) B = 1

   (2) r1 = B  |  (4) r2 = A

Another way to see r1 = r2 = 0 is impossible with volatile A and B:



- Either (1) or (3) occurs first in the synchronization order

(17.4.4).  Assume (1) occurs first.  (The other case is similar.)



- (1) synchronizes with (4) (17.4.4), and therefore (1) happens

before (4) (17.4.5).



Hang on. What is the meaning of "synchronizes with"? It is mentioned in

JMM, but it doesn't explain how that "synchronization" "happens". In

reality (4) can be executed before (1) as well as after it, so I don't

see what it means that (1) "synchronizes with" (4). So I expect a step

somewhere here that says "(4) is after (3)", and Aleksey mentions PO.

The memory model is a semi-formal description of what writes can be seen

by a read in your program, in spite of the reality that there is no total

(e.g. time) order in which the instructions execute.

Yes, this is clear.  But we can project this into a total order, and that's what I think JMM tries to specify, right?

No, not in any meaningful sense.  There are valid program executions that correspond to no total order of the actions, e.g. if updates to two shared variables are seen in inconsistent orders by two observer threads.


At first I thought that hb is that partial order of instructions. It makes sense that if hb order can be projected into program order, then hb is the implementation of the program order. It also makes sense, if synchronization order can be projected into hb, and that way determine how the volatiles can be ordered.

However, this understanding doesn't add up: "It should be noted that the presence of a happens-before relationship between two actions does not necessarily imply that they have to take place in that order in an implementation.", and the way hb is constructed seems backwards w.r.t. that implementation: "If x and y are actions of the same thread and x comes before y in program order, then hb(x, y).". This latter statement says that if there is PO between any actions, including non-volatiles, there is hb between them.

What's the point of having hb then, if PO already defines all the edges in the order? It would make sense, if PO didn't define all the edges. For example, say it the other way around: for all x and y in hb there is x and y in po (all vertices can be projected); if hb(x,y) for some x and y, then x must appear before y in program order (all edges can be projected pointing the same way around); this defines a function from hb to po. Same for synchronization order: projecting so into hb has the meaning that hb can only have those operations in total order.

Program order only orders actions within each individual thread.  Happens-before is the combination of that and synchronizes-with, which describes inter-thread interaction.  Happens-before describes orderings that are guaranteed to be enforced, either because they are performed by the same thread, or because of synchronization.  Many actions by different threads remain unordered by happens-before, which is not a total order.  It can be extended to a total order, but not necessarily such that reads see the last write in that order.


Also, then add to confusion that hb doesn't determine even the order of instructions in the implementation, because they "don't necessarily take place in that order".





 The only total order

that spans the whole program is on synchronization operations.  (These do

behave as though they were executed in a single total order, though the

JMM says that only somewhat indirectly.)  Program order

does figure into the argument that (1) or (3) must be first in

the synchronization order.  The synchronization order is effectively an

interleaving of the synchronization operations from each thread, i.e.

synchronization operations of each thread must appear in program order.



So far so good, but (4) is after (3) even in non-volatile case, isn't

it? If so, then what execution order permits to observe r1==0 and

r2==0,

if B==1 before r2==0?

There is no notion of "is after", except in the synchronization order.

Instructions don't execute in some total "time" order.  A write by

one thread may be seen at different times by each of the other threads.
Yes, this is clear from the Cookbook, but isn't clear how this is expressed in JMM.

For different threads to observe different order of operations there must be some order of all instructions of the program as seen by each thread individually. Which concept in JMM reflects this?

It talks about possible writes seen by each read, which is a different way of looking at the same thing.  There is no explicit order for each thread.  There is only the (partial) happens-before order respected by all threads.



In the non-volatile case, there are no synchronization operations, and the

synchronization order is empty.



Well, it could work, if (4) and (3) aren't really ordered like that in

non-volatile case, so executing (4) then (3) doesn't break Program

Order. Why then do we say PO gets broken, if (4) is before (3)?

I don't understand the notion of breaking program order.  Program order

contributes to happens-before, which largely determines what values can

be seen by a read.  In the non-volatile case, the happens-before order

is the program-order, with initializations happening before everything

else.  That means that each read can see either write, with absolutely

no constraint.  The initialization happens before the read, and the write

of 1 is unordered with respect to the read, meaning that each read can see

either, independent of what the other read sees.
This is the thing I don't understand about "synchronizes with". A volatile read can also be executed in any order w.r.t. the write of 1, so can also observe either 0, or 1.

volatile operations are executed in a single total order.






A far simpler alternate model is that so long as there are no data races

(simultaneous accesses to the same non-volatile object, at least one of which

is a write), you get sequential consistency, and everything behaves as you would

expect.  If there is a data race, very weird things happen, and if you care

precisely what happens, you have to understand chapter 17 details.  This

view is entirely consistent with chapter 17. The volatile case is

data-race-free, and nothing weird happens.

Yes, that's what I am trying to understand :)


Alex








Hans







Alex







- (4) must see the write at (1), which happens after the initializing

write, but happens before (4).  (17.4.5, intervening write.) Thus r2 =

1.  (In the other case r1 = 1.)



None of this applies if wither A or B is not volatile.



Hans







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140123/c21e32eb/attachment-0001.html>

From dl at cs.oswego.edu  Fri Jan 24 15:22:35 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 24 Jan 2014 15:22:35 -0500
Subject: [concurrency-interest] Fwd: Survey on sun.misc.Unsafe
In-Reply-To: <1229496F-0624-436A-A08F-8127CB4FE065@oracle.com>
References: <1229496F-0624-436A-A08F-8127CB4FE065@oracle.com>
Message-ID: <52E2CB8B.6000207@cs.oswego.edu>


People on this list might be interested in responding to this...

-------- Original Message --------
Subject: Survey on sun.misc.Unsafe
Date: Fri, 24 Jan 2014 16:35:37 +0100
From: Paul Sandoz <paul.sandoz at oracle.com>
To: lambda-dev at openjdk.java.net <lambda-dev at openjdk.java.net>, 
core-libs-dev Libs <core-libs-dev at openjdk.java.net>

Hi,

We are gathering feedback on sun.misc.Unsafe usage. If you have ever used it 
please consider taking this survey and helping us out:

   https://www.surveymonkey.com/s/sun-misc-Unsafe

--

We also plan to trawl stuff on repos. I have done a selective bit of that 
already, running with a little tool spitting out method usage stats. I would 
have included a link to that tool but it is dependent on Java 8. If anyone still 
wants to use it let me know and i can put that code on GitHub.

Paul.




From tball at google.com  Fri Jan 24 17:07:22 2014
From: tball at google.com (Tom Ball)
Date: Fri, 24 Jan 2014 14:07:22 -0800
Subject: [concurrency-interest] java.util.concurrent on iOS
Message-ID: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>

I don't know if this alias is interested, but j2objc supports the
java.util.concurrent packages
<https://code.google.com/p/j2objc/source/browse/#git%2Fjre_emul%2Fandroid%2Flibcore%2Fluni%2Fsrc%2Fmain%2Fjava%2Fjava%2Futil%2Fconcurrent>for
iOS apps. Those of you with iPhones or iPads may be already running the
code you've designed, and the developers using your API appreciate it. :-)

Thanks for all your hard work,
Tom
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140124/f30e9a9e/attachment.html>

From aleksey.shipilev at oracle.com  Fri Jan 24 17:30:47 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Sat, 25 Jan 2014 02:30:47 +0400
Subject: [concurrency-interest] java.util.concurrent on iOS
In-Reply-To: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>
References: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>
Message-ID: <52E2E997.9030305@oracle.com>

On 01/25/2014 02:07 AM, Tom Ball wrote:
> I don't know if this alias is interested, but j2objc supports the
> java.util.concurrent packages

I would rather say "it supports compiling them into ObjC". I wouldn't
specifically count these primitives to work without Java Memory Model
backing them up.

-Aleksey.


From oleksandr.otenko at oracle.com  Fri Jan 24 17:50:44 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 24 Jan 2014 22:50:44 +0000
Subject: [concurrency-interest] JSR 133 Cookbook vs Java Memory Model:
 table 17.5
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23D5523AF@G9W0725.americas.hpqcorp.net>
References: <52DD8124.1060103@oracle.com>	<52DE4353.3000809@redhat.com>	<52DE9953.4070008@oracle.com>	<CAHjP37EPtTfkk9DGk9tok5r7aMiQ4CJS_BvCmEZzgcjNcxVu_Q@mail.gmail.com>	<52DEC200.9090006@oracle.com>
	<52DEC4EE.9040303@oracle.com>	<52DECFEB.9070105@oracle.com>
	<52DEE46C.3000302@oracle.com> <52DEE75B.3060709@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B05@G9W0725.americas.hpqcorp.net>
	<52DF032A.4040502@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D551B7A@G9W0725.americas.hpqcorp.net>
	<52DFF535.4070500@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23D5523AF@G9W0725.americas.hpqcorp.net>
Message-ID: <52E2EE44.5050402@oracle.com>

ok, it seems to settle in now.

I thought HB is also responsible for reflecting normal reads/writes 
reordering (= partial order reflecting causal dependency of data used in 
instructions) within one thread.

Alex

On 23/01/2014 00:17, Boehm, Hans wrote:
>
> *From:*Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
> *Sent:* Wednesday, January 22, 2014 8:44 AM
> *To:* Boehm, Hans; Aleksey Shipilev
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] JSR 133 Cookbook vs Java Memory 
> Model: table 17.5
>
> On 22/01/2014 00:01, Boehm, Hans wrote:
>
>     From: Oleksandr Otenko [mailto:oleksandr.otenko at oracle.com]
>
>       
>
>     On 21/01/2014 23:10, Boehm, Hans wrote:
>
>             Example:
>
>                   volatile int A, B;
>
>             -----------------------------
>
>                 (1) A = 1   |  (3) B = 1
>
>                 (2) r1 = B  |  (4) r2 = A
>
>         Another way to see r1 = r2 = 0 is impossible with volatile A and B:
>
>           
>
>         - Either (1) or (3) occurs first in the synchronization order
>
>     (17.4.4).  Assume (1) occurs first.  (The other case is similar.)
>
>           
>
>         - (1) synchronizes with (4) (17.4.4), and therefore (1) happens
>
>     before (4) (17.4.5).
>
>       
>
>     Hang on. What is the meaning of "synchronizes with"? It is mentioned in
>
>     JMM, but it doesn't explain how that "synchronization" "happens". In
>
>     reality (4) can be executed before (1) as well as after it, so I don't
>
>     see what it means that (1) "synchronizes with" (4). So I expect a step
>
>     somewhere here that says "(4) is after (3)", and Aleksey mentions PO.
>
> The memory model is a semi-formal description of what writes can be seen
> by a read in your program, in spite of the reality that there is no total
> (e.g. time) order in which the instructions execute.
>
>
> Yes, this is clear.  But we can project this into a total order, and 
> that's what I think JMM tries to specify, right?
>
> No, not in any meaningful sense.  There are valid program executions 
> that correspond to no total order of the actions, e.g. if updates to 
> two shared variables are seen in inconsistent orders by two observer 
> threads.
>
>
>
> At first I thought that hb is that partial order of instructions. It 
> makes sense that if hb order can be projected into program order, then 
> hb is the implementation of the program order. It also makes sense, if 
> synchronization order can be projected into hb, and that way determine 
> how the volatiles can be ordered.
>
> However, this understanding doesn't add up: "It should be noted that 
> the presence of a /happens-before/ relationship between two actions 
> does not necessarily imply that they have to take place in that order 
> in an implementation.", and the way hb is /constructed/ seems 
> backwards w.r.t. that implementation: "If /x/ and /y/ are actions of 
> the same thread and /x/ comes before /y/ in program order, then /hb(x, 
> y)/.". This latter statement says that if there is PO between any 
> actions, including non-volatiles, there is hb between them.
>
> What's the point of having hb then, if PO already defines all the 
> edges in the order? It would make sense, if PO /didn't/ define all the 
> edges. For example, say it the other way around: for all x and y in hb 
> there is x and y in po (all vertices can be projected); if hb(x,y) for 
> some x and y, then x must appear before y in program order (all edges 
> can be projected pointing the same way around); this defines a 
> function from hb to po. Same for synchronization order: projecting so 
> into hb has the meaning that hb can only have those operations in 
> total order.
>
> Program order only orders actions within each individual thread. 
> Happens-before is the combination of that and synchronizes-with, which 
> describes inter-thread interaction.  Happens-before describes 
> orderings that are guaranteed to be enforced, either because they are 
> performed by the same thread, or because of synchronization.  Many 
> actions by different threads remain unordered by happens-before, which 
> is not a total order. It can be extended to a total order, but not 
> necessarily such that reads see the last write in that order.
>
>
>
> Also, then add to confusion that hb doesn't determine even the order 
> of instructions in the implementation, because they "don't necessarily 
> take place in that order".
>
>
>
>
>   The only total order
> that spans the whole program is on synchronization operations.  (These do
> behave as though they were executed in a single total order, though the
> JMM says that only somewhat indirectly.)  Program order
> does figure into the argument that (1) or (3) must be first in
> the synchronization order.  The synchronization order is effectively an
> interleaving of the synchronization operations from each thread, i.e.
> synchronization operations of each thread must appear in program order.
>
>       
>
>     So far so good, but (4) is after (3) even in non-volatile case, isn't
>
>     it? If so, then what execution order permits to observe r1==0 and
>
>     r2==0,
>
>     if B==1 before r2==0?
>
> There is no notion of "is after", except in the synchronization order.
> Instructions don't execute in some total "time" order.  A write by
> one thread may be seen at different times by each of the other threads.
>
> Yes, this is clear from the Cookbook, but isn't clear how this is 
> expressed in JMM.
>
> For different threads to observe different order of operations there 
> must be some order of all instructions of the program as seen by each 
> thread individually. Which concept in JMM reflects this?
>
> It talks about possible writes seen by each read, which is a different 
> way of looking at the same thing.  There is no explicit order for each 
> thread.  There is only the (partial) happens-before order respected by 
> all threads.
>
>   
> In the non-volatile case, there are no synchronization operations, and the
> synchronization order is empty.
>
>       
>
>     Well, it could work, if (4) and (3) aren't really ordered like that in
>
>     non-volatile case, so executing (4) then (3) doesn't break Program
>
>     Order. Why then do we say PO gets broken, if (4) is before (3)?
>
> I don't understand the notion of breaking program order.  Program order
> contributes to happens-before, which largely determines what values can
> be seen by a read.  In the non-volatile case, the happens-before order
> is the program-order, with initializations happening before everything
> else.  That means that each read can see either write, with absolutely
> no constraint.  The initialization happens before the read, and the write
> of 1 is unordered with respect to the read, meaning that each read can see
> either, independent of what the other read sees.
>
> This is the thing I don't understand about "synchronizes with". A 
> volatile read can also be executed in any order w.r.t. the write of 1, 
> so can also observe either 0, or 1.
>
> volatile operations are executed in a single total order.
>
>   
>   
> A far simpler alternate model is that so long as there are no data races
> (simultaneous accesses to the same non-volatile object, at least one of which
> is a write), you get sequential consistency, and everything behaves as you would
> expect.  If there is a data race, very weird things happen, and if you care
> precisely what happens, you have to understand chapter 17 details.  This
> view is entirely consistent with chapter 17. The volatile case is
> data-race-free, and nothing weird happens.
>
>
> Yes, that's what I am trying to understand :)
>
>
> Alex
>
>
>
>   
>   
> Hans
>   
>
>       
>
>       
>
>     Alex
>
>       
>
>       
>
>           
>
>         - (4) must see the write at (1), which happens after the initializing
>
>     write, but happens before (4).  (17.4.5, intervening write.) Thus r2 =
>
>     1.  (In the other case r1 = 1.)
>
>           
>
>         None of this applies if wither A or B is not volatile.
>
>           
>
>         Hans
>
>           
>
>           
>
>   
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140124/f5ccc865/attachment-0001.html>

From tball at google.com  Fri Jan 24 18:24:02 2014
From: tball at google.com (Tom Ball)
Date: Fri, 24 Jan 2014 15:24:02 -0800
Subject: [concurrency-interest] java.util.concurrent on iOS
In-Reply-To: <52E2E997.9030305@oracle.com>
References: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>
	<52E2E997.9030305@oracle.com>
Message-ID: <CAPLadK6Mu0ZensQgMrnVzYvM0E=-a9t4kGh1_FZtaRSAjmvJ3w@mail.gmail.com>

> I wouldn't specifically count these primitives to work without Java
Memory Model backing them up.

That would suggest the test suite from Apache Harmony is incomplete, as the
tests pass on iOS. Aren't these classes the expert group's test
suite?<https://code.google.com/p/j2objc/source/browse/#git%2Fjre_emul%2Fapache_harmony%2Fclasslib%2Fmodules%2Fconcurrent%2Fsrc%2Ftest%2Fjava>
A
lot of work went into enforcing memory model constraints, though there's
always room for improvement.


On Fri, Jan 24, 2014 at 2:30 PM, Aleksey Shipilev <
aleksey.shipilev at oracle.com> wrote:

> On 01/25/2014 02:07 AM, Tom Ball wrote:
> > I don't know if this alias is interested, but j2objc supports the
> > java.util.concurrent packages
>
> I would rather say "it supports compiling them into ObjC". I wouldn't
> specifically count these primitives to work without Java Memory Model
> backing them up.
>
> -Aleksey.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140124/af9497fb/attachment.html>

From david.lloyd at redhat.com  Fri Jan 24 18:37:39 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 24 Jan 2014 17:37:39 -0600
Subject: [concurrency-interest] java.util.concurrent on iOS
In-Reply-To: <CAPLadK6Mu0ZensQgMrnVzYvM0E=-a9t4kGh1_FZtaRSAjmvJ3w@mail.gmail.com>
References: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>	<52E2E997.9030305@oracle.com>
	<CAPLadK6Mu0ZensQgMrnVzYvM0E=-a9t4kGh1_FZtaRSAjmvJ3w@mail.gmail.com>
Message-ID: <52E2F943.1090009@redhat.com>

Of course the JMM is just a set of rules.  If the implementation adheres 
to the rules, then by definition the JMM is "backing it up".

On 01/24/2014 05:24 PM, Tom Ball wrote:
>  > I wouldn't specifically count these primitives to work without Java
> Memory Model backing them up.
>
> That would suggest the test suite from Apache Harmony is incomplete, as
> the tests pass on iOS. Aren't these classes the expert group's test
> suite?
> <https://code.google.com/p/j2objc/source/browse/#git%2Fjre_emul%2Fapache_harmony%2Fclasslib%2Fmodules%2Fconcurrent%2Fsrc%2Ftest%2Fjava> A
> lot of work went into enforcing memory model constraints, though there's
> always room for improvement.
>
>
> On Fri, Jan 24, 2014 at 2:30 PM, Aleksey Shipilev
> <aleksey.shipilev at oracle.com <mailto:aleksey.shipilev at oracle.com>> wrote:
>
>     On 01/25/2014 02:07 AM, Tom Ball wrote:
>      > I don't know if this alias is interested, but j2objc supports the
>      > java.util.concurrent packages
>
>     I would rather say "it supports compiling them into ObjC". I wouldn't
>     specifically count these primitives to work without Java Memory Model
>     backing them up.
>
>     -Aleksey.
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
- DML

From aleksey.shipilev at oracle.com  Fri Jan 24 18:49:26 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Sat, 25 Jan 2014 03:49:26 +0400
Subject: [concurrency-interest] java.util.concurrent on iOS
In-Reply-To: <CAPLadK6Mu0ZensQgMrnVzYvM0E=-a9t4kGh1_FZtaRSAjmvJ3w@mail.gmail.com>
References: <CAPLadK6WN1QKPR9H=VDmBwDGPzkXqQ3p8sRPRF2TQdyZhjDrAQ@mail.gmail.com>
	<52E2E997.9030305@oracle.com>
	<CAPLadK6Mu0ZensQgMrnVzYvM0E=-a9t4kGh1_FZtaRSAjmvJ3w@mail.gmail.com>
Message-ID: <52E2FC06.2000708@oracle.com>

On 01/25/2014 03:24 AM, Tom Ball wrote:
> That would suggest the test suite from Apache Harmony is incomplete, as
> the tests pass on iOS. Aren't these classes the expert group's test
> suite? https://code.google.com/p/j2objc/source/browse/#git%2Fjre_emul%2Fapache_harmony%2Fclasslib%2Fmodules%2Fconcurrent%2Fsrc%2Ftest%2Fjava

This seems to be the copy of JSR 166 TCK, maintained by Doug. While
covering j.u.c.* quite well, those tests are not nearly enough to test
the provisions of memory model. Running the converted Java code which
assumes proper JVM on some other non-JVM runtime seems unreliable to me.

Thanks,
-Aleksey.

From paul.sandoz at oracle.com  Tue Jan 28 09:50:13 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Tue, 28 Jan 2014 15:50:13 +0100
Subject: [concurrency-interest] MethodHandle and Unsafe <was> JDK9
	concurrency preliminaries
Message-ID: <CC4FA435-AC4D-431B-A1FE-2E163FB2AD2B@oracle.com>

Doug Lea <dl at cs.oswego.edu> wrote:
> On 01/16/2014 11:26 AM, Peter Levart wrote:
> >
> > I did an experiment using MethodHandles in recent JDK 8, investigating their
> > ability to avoid and/or optimize-away those checks.
> 
> Thanks! I should have mentioned that Paul Sandoz had also experimented
> with this enough to know that in principle, MH-based compilation of
> the proposed .volatile could work well. Thanks for helping to confirm this.
[Late to the party...] 

Yes, thanks, good to know.

I took a slightly different route to that of Peter's.

The direct method handles to fields in the OpenJDK implementation use Unsafe. See MethodHandles.Lookup.find{Static}Getter/Setter. I patched the method handle API and impl to support compare-and-swap etc. I wrote a jmh benchmark comparing direct method handles with Unsafe and get/putfield. 

Here is an inlining trace for non-volatile get/put using direct method handles (which somewhat mirrors the shape of the lambda forms for get and set).

                            @ 13   unsafe.UnvolatileSetGetTest::invokeExact (24 bytes)   inline (hot)
                              @ 13   java.lang.invoke.LambdaForm$MH000/1541360201::invokeExact_MT (15 bytes)   inline (hot)
                                @ 2   java.lang.invoke.Invokers::checkExactType (30 bytes)   inline (hot)
                                  @ 11   java.lang.invoke.MethodHandle::type (5 bytes)   accessor
                                @ 11   java.lang.invoke.LambdaForm$MH002/353292828::putObjectFieldCast (32 bytes)   inline (hot)
                                  @ 1   java.lang.invoke.DirectMethodHandle::fieldOffset (9 bytes)   inline (hot)
                                  @ 6   java.lang.invoke.DirectMethodHandle::checkBase (7 bytes)   inline (hot)
                                    @ 1   java.lang.Object::getClass (0 bytes)   (intrinsic)
                                  @ 13   java.lang.invoke.DirectMethodHandle::checkCast (9 bytes)   inline (hot)
                                    @ 5   java.lang.invoke.DirectMethodHandle$Accessor::checkCast (9 bytes)   inline (hot)
                                      @ 5   java.lang.Class::cast (27 bytes)   inline (hot)
                                        @ 6   java.lang.Class::isInstance (0 bytes)   (intrinsic)
                                  @ 28   sun.misc.Unsafe::putObject (0 bytes)   (intrinsic)
                              @ 20   java.lang.invoke.LambdaForm$MH001/694037416::invokeExact_MT (14 bytes)   inline (hot)
                                @ 2   java.lang.invoke.Invokers::checkExactType (30 bytes)   inline (hot)
                                  @ 11   java.lang.invoke.MethodHandle::type (5 bytes)   accessor
                                @ 10   java.lang.invoke.LambdaForm$MH003/1676338316::getObjectFieldCast (31 bytes)   inline (hot)
                                  @ 1   java.lang.invoke.DirectMethodHandle::fieldOffset (9 bytes)   inline (hot)
                                  @ 6   java.lang.invoke.DirectMethodHandle::checkBase (7 bytes)   inline (hot)
                                    @ 1   java.lang.Object::getClass (0 bytes)   (intrinsic)
                                  @ 19   sun.misc.Unsafe::getObject (0 bytes)   (intrinsic)
                                  @ 27   java.lang.invoke.DirectMethodHandle::checkCast (9 bytes)   inline (hot)
                                    @ 5   java.lang.invoke.DirectMethodHandle$Accessor::checkCast (9 bytes)   inline (hot)
                                      @ 5   java.lang.Class::cast (27 bytes)   inline (hot)
                                        @ 6   java.lang.Class::isInstance (0 bytes)   (intrinsic)

The main block of generated machine code was quite similar to that generated for direct Unsafe usage. There were a few more instructions related to the calls to checkBase (basically if the instance holding the field value is null or not) and checkCast. It is not clear to me why the checkCast calls are required since i would presume invokeExact should provide the necessary guard to avoid such casts.

Some interesting points:

- the lambda forms for static fields ensure the class is safely initialized before field access. Once initialized the form is substituted for one without the initialization check.

- the global instance of sun.misc.Unsafe is patched directly into the constant pool of the defined field-based lambda form classes, thus avoiding the need for a static final field whose value refers to that Unsafe instance.

Some areas for further investigation:

1) Warm up costs. The lambda forms require some warm up, first they are interpreted then after a number of invocations compiled to byte code, after which the JIT can work on 'em.

2) Throwing JIT inlining off the scent. Perhaps the extra inlining required for method handles will perturb the inlining of methods up the call chain?

3) The types of direct method handle could be expanded to include atomic access types, which means IIUC such method handles can be placed into the constant pool. That will require an update to the JVMS but, thankfully, no new bytecodes!

Paul.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140128/013b5bc8/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140128/013b5bc8/attachment.bin>

From ylt at letallec.org  Thu Jan 30 10:22:10 2014
From: ylt at letallec.org (Yann Le Tallec)
Date: Thu, 30 Jan 2014 15:22:10 +0000
Subject: [concurrency-interest] Side effect of the new
	ForkJoinPool.commonPool & InnocuousForkJoinWorkerThreadFactory
Message-ID: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>

Hi all,

following the introduction of the "InnocuousForkJoinWorkerThreadFactory" in
java 8 b123 (
http://cs.oswego.edu/pipermail/concurrency-interest/2013-December/012123.html),
calling `setContextClassLoader` inside a `CompletableFuture.runAsync()`
throws a SecurityException if a SecurityManager is installed, as expected
when looking at the InnocuousForkJoinWorkerThread code:

        @Override // paranoically
        public void setContextClassLoader(ClassLoader cl) {
            throw new SecurityException("setContextClassLoader");
        }

It is possible to provide a different factory through the system
properties, which gets loaded with (ForkJoinPool#makeCommonPool):

    String fp =
System.getProperty("java.util.concurrent.ForkJoinPool.common.threadFactory");
    factory =
((ForkJoinWorkerThreadFactory)ClassLoader.getSystemClassLoader().loadClass(fp).newInstance());

However, when the application is launched via Java Web Start, the last
statement throws a ClassNotFoundException (I suppose because JWS uses a
different class loader system) even if the JWS application has all
permissions enabled (in the manifest and the jnlp). Therefore it looks like
there is no way to replace the default, no permission,
InnocuousForkJoinWorkerThreadFactory in a JWS application.

Is this by design? Is there a workaround?

Many thanks,
Yann
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/a97f64ad/attachment.html>

From dl at cs.oswego.edu  Thu Jan 30 12:34:52 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 30 Jan 2014 12:34:52 -0500
Subject: [concurrency-interest] Side effect of the new
	ForkJoinPool.commonPool & InnocuousForkJoinWorkerThreadFactory
In-Reply-To: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>
References: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>
Message-ID: <52EA8D3C.5040206@cs.oswego.edu>

On 01/30/2014 10:22 AM, Yann Le Tallec wrote:
> Hi all,
>
> following the introduction of the "InnocuousForkJoinWorkerThreadFactory" in java
> 8 b123
> (http://cs.oswego.edu/pipermail/concurrency-interest/2013-December/012123.html),
> calling `setContextClassLoader` inside a `CompletableFuture.runAsync()` throws a
> SecurityException if a SecurityManager is installed, as expected when looking at
> the InnocuousForkJoinWorkerThread code:
>
>          @Override // paranoically
>          public void setContextClassLoader(ClassLoader cl) {
>              throw new SecurityException("setContextClassLoader");
>          }
>
> It is possible to provide a different factory through the system properties,
> which gets loaded with (ForkJoinPool#makeCommonPool):
>
>      String fp =
> System.getProperty("java.util.concurrent.ForkJoinPool.common.threadFactory");
>      factory =
> ((ForkJoinWorkerThreadFactory)ClassLoader.getSystemClassLoader().loadClass(fp).newInstance());
>
> However, when the application is launched via Java Web Start, the last statement
> throws a ClassNotFoundException (I suppose because JWS uses a different class
> loader system) even if the JWS application has all permissions enabled (in the
> manifest and the jnlp). Therefore it looks like there is no way to replace the
> default, no permission, InnocuousForkJoinWorkerThreadFactory in a JWS application.
>
> Is this by design? Is there a workaround?
>

Disabling setContextClassLoader was intended to be tolerable
(and to rule out other potential problems in a simple way)
across known uses. Here, because JWS can support multiple applications,
none of them should be setting common pool policies for the others. This
might not mesh well with current JWS administration, but I don't
see anything ForkJoinPool itself can or should do about this. Do you?

-Doug




From viktor.klang at gmail.com  Thu Jan 30 13:25:06 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 30 Jan 2014 19:25:06 +0100
Subject: [concurrency-interest] Side effect of the new
 ForkJoinPool.commonPool & InnocuousForkJoinWorkerThreadFactory
In-Reply-To: <52EA8D3C.5040206@cs.oswego.edu>
References: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>
	<52EA8D3C.5040206@cs.oswego.edu>
Message-ID: <CANPzfU9cq1M8X526+hgSU4oMZP7jfRsmb9YLyfQ30T4QRFQ5Mg@mail.gmail.com>

Off the top of my head: What if we allow setCCL but always make sure it's
cleared after every task?


On Thu, Jan 30, 2014 at 6:34 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 01/30/2014 10:22 AM, Yann Le Tallec wrote:
>
>> Hi all,
>>
>> following the introduction of the "InnocuousForkJoinWorkerThreadFactory"
>> in java
>> 8 b123
>> (http://cs.oswego.edu/pipermail/concurrency-
>> interest/2013-December/012123.html),
>> calling `setContextClassLoader` inside a `CompletableFuture.runAsync()`
>> throws a
>> SecurityException if a SecurityManager is installed, as expected when
>> looking at
>> the InnocuousForkJoinWorkerThread code:
>>
>>          @Override // paranoically
>>          public void setContextClassLoader(ClassLoader cl) {
>>              throw new SecurityException("setContextClassLoader");
>>          }
>>
>> It is possible to provide a different factory through the system
>> properties,
>> which gets loaded with (ForkJoinPool#makeCommonPool):
>>
>>      String fp =
>> System.getProperty("java.util.concurrent.ForkJoinPool.
>> common.threadFactory");
>>      factory =
>> ((ForkJoinWorkerThreadFactory)ClassLoader.getSystemClassLoader().
>> loadClass(fp).newInstance());
>>
>> However, when the application is launched via Java Web Start, the last
>> statement
>> throws a ClassNotFoundException (I suppose because JWS uses a different
>> class
>> loader system) even if the JWS application has all permissions enabled
>> (in the
>> manifest and the jnlp). Therefore it looks like there is no way to
>> replace the
>> default, no permission, InnocuousForkJoinWorkerThreadFactory in a JWS
>> application.
>>
>> Is this by design? Is there a workaround?
>>
>>
> Disabling setContextClassLoader was intended to be tolerable
> (and to rule out other potential problems in a simple way)
> across known uses. Here, because JWS can support multiple applications,
> none of them should be setting common pool policies for the others. This
> might not mesh well with current JWS administration, but I don't
> see anything ForkJoinPool itself can or should do about this. Do you?
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/2e1c95a2/attachment.html>

From heinz at javaspecialists.eu  Thu Jan 30 14:11:59 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 30 Jan 2014 14:11:59 -0500
Subject: [concurrency-interest] TLR Puzzle
Message-ID: <52EAA3FF.1020109@javaspecialists.eu>

In Java 8, TLR has become a Singleton.  Prior to that, we had to be 
careful to not let it escape from being thread confined.  However, the 
current() method call was also a ThreadLocal lookup, so it was fairly 
slow to call.  It was thus tempting to store the TLR in a field.  Thus 
in Java 8, the seed and all the related information was moved to the 
Thread class.  I think most concurrency-interest readers would be aware 
of this.  But consider this class:

import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

public class MagicMirror {
  private static final ThreadLocalRandom tlr =
      ThreadLocalRandom.current();

  public boolean amIPretty() {
    return tlr.nextBoolean();
  }

  public static void main(String... args) {
    final AtomicBoolean vanity = new AtomicBoolean(true);
    while (vanity.get()) {
      new Thread(new Runnable() {
        public void run() {
          MagicMirror mirrorOnTheWall = new MagicMirror();
          boolean beauty = mirrorOnTheWall.amIPretty();
          if (!beauty) vanity.set(false);
        }
      }).start();
    }
    System.out.println("Oh no, now I am depressed!");
  }
}

What do you think this will return in Java 7?  In Java 8?  Obviously in 
Java 7 this would be quite bad, because each thread is supposed to have 
his or her own TLR instance.  But in Java 8 it's a Singleton anyway, so 
who cares?

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Oracle Java Champion 2005-2013
JavaOne Rock Star Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz


From aleksey.shipilev at oracle.com  Thu Jan 30 14:36:28 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 30 Jan 2014 23:36:28 +0400
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA3FF.1020109@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>
Message-ID: <52EAA9BC.30505@oracle.com>

On 01/30/2014 11:11 PM, Dr Heinz M. Kabutz wrote:
> In Java 8, TLR has become a Singleton.  Prior to that, we had to be
> careful to not let it escape from being thread confined.  However, the
> current() method call was also a ThreadLocal lookup, so it was fairly
> slow to call.  It was thus tempting to store the TLR in a field.  Thus
> in Java 8, the seed and all the related information was moved to the
> Thread class.  I think most concurrency-interest readers would be aware
> of this.  But consider this class:
> 
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
> 
> public class MagicMirror {
>  private static final ThreadLocalRandom tlr =
>      ThreadLocalRandom.current();
> 
>  public boolean amIPretty() {
>    return tlr.nextBoolean();
>  }
> 
>  public static void main(String... args) {
>    final AtomicBoolean vanity = new AtomicBoolean(true);
>    while (vanity.get()) {
>      new Thread(new Runnable() {
>        public void run() {
>          MagicMirror mirrorOnTheWall = new MagicMirror();
>          boolean beauty = mirrorOnTheWall.amIPretty();
>          if (!beauty) vanity.set(false);
>        }
>      }).start();
>    }
>    System.out.println("Oh no, now I am depressed!");
>  }
> }
> 
> What do you think this will return in Java 7?  

This is a puzzler, so the most oddball (even the remotely possible)
answer suffices? OOME, because the unbounded number of threads is
created in a busy-loop without recycling.

> In Java 8? 

Ditto.

-Aleksey.

From nathan.reynolds at oracle.com  Thu Jan 30 14:38:18 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 30 Jan 2014 12:38:18 -0700
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA3FF.1020109@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>
Message-ID: <52EAAA2A.9080901@oracle.com>

The obvious answer is that eventually you are going to recognize that 
you are ugly and that you are going to end up depressed.  ;)  But, since 
it is you that is proposing the puzzle, I have my doubts even though I 
can't fathom why.

It seems to me that the main thread is going to spin until vanity is set 
to false.  Some thread is going to see !amIPretty() and set vanity to 
false.  The main thread is going to exit and the JVM won't exit until 
the rest of the created threads have begun, executed and terminated.  
These threads are not daemon threads.

Here's another scenario.  This is going to create a lot of threads.  In 
some cases, the main thread is going to throw an OutOfMemoryError 
because another thread can't be created.  There are too many call stacks 
consuming virtual address space but they can't be cleaned up by the JVM 
because the threads haven't even begun execution.  You have previously 
shown that it can take several tens or hundreds (?) of milliseconds to 
get threads started.  Even worse is if the call stacks can be cleaned up 
with a full GC because the threads have terminated but a bug doesn't 
cause the JVM to execute a full GC when trying to create another thread.

-Nathan

On 1/30/2014 12:11 PM, Dr Heinz M. Kabutz wrote:
> In Java 8, TLR has become a Singleton.  Prior to that, we had to be 
> careful to not let it escape from being thread confined.  However, the 
> current() method call was also a ThreadLocal lookup, so it was fairly 
> slow to call.  It was thus tempting to store the TLR in a field.  Thus 
> in Java 8, the seed and all the related information was moved to the 
> Thread class.  I think most concurrency-interest readers would be 
> aware of this. But consider this class:
>
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
>
> public class MagicMirror {
>  private static final ThreadLocalRandom tlr =
>      ThreadLocalRandom.current();
>
>  public boolean amIPretty() {
>    return tlr.nextBoolean();
>  }
>
>  public static void main(String... args) {
>    final AtomicBoolean vanity = new AtomicBoolean(true);
>    while (vanity.get()) {
>      new Thread(new Runnable() {
>        public void run() {
>          MagicMirror mirrorOnTheWall = new MagicMirror();
>          boolean beauty = mirrorOnTheWall.amIPretty();
>          if (!beauty) vanity.set(false);
>        }
>      }).start();
>    }
>    System.out.println("Oh no, now I am depressed!");
>  }
> }
>
> What do you think this will return in Java 7?  In Java 8? Obviously in 
> Java 7 this would be quite bad, because each thread is supposed to 
> have his or her own TLR instance.  But in Java 8 it's a Singleton 
> anyway, so who cares?
>
> Regards
>
> Heinz

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/c36510c7/attachment-0001.html>

From heinz at javaspecialists.eu  Thu Jan 30 14:39:31 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 30 Jan 2014 14:39:31 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA9BC.30505@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAA9BC.30505@oracle.com>
Message-ID: <52EAAA73.9060402@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/4ecd35be/attachment.html>

From heinz at javaspecialists.eu  Thu Jan 30 14:44:43 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 30 Jan 2014 14:44:43 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAAA73.9060402@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAA9BC.30505@oracle.com>
	<52EAAA73.9060402@javaspecialists.eu>
Message-ID: <52EAABAB.80901@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/c666be80/attachment.html>

From heinz at javaspecialists.eu  Thu Jan 30 14:46:48 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 30 Jan 2014 14:46:48 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAAA2A.9080901@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAAA2A.9080901@oracle.com>
Message-ID: <52EAAC28.5090005@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/e86cc61e/attachment.html>

From aleksey.shipilev at oracle.com  Thu Jan 30 14:49:39 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 30 Jan 2014 23:49:39 +0400
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA3FF.1020109@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>
Message-ID: <52EAACD3.8000405@oracle.com>

On 01/30/2014 11:11 PM, Dr Heinz M. Kabutz wrote:
> In Java 8, TLR has become a Singleton.  Prior to that, we had to be
> careful to not let it escape from being thread confined.  However, the
> current() method call was also a ThreadLocal lookup, so it was fairly
> slow to call.  It was thus tempting to store the TLR in a field.  Thus
> in Java 8, the seed and all the related information was moved to the
> Thread class.  I think most concurrency-interest readers would be aware
> of this.  But consider this class:
> 
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
> 
> public class MagicMirror {
>  private static final ThreadLocalRandom tlr =
>      ThreadLocalRandom.current();
> 
>  public boolean amIPretty() {
>    return tlr.nextBoolean();
>  }
> 
>  public static void main(String... args) {
>    final AtomicBoolean vanity = new AtomicBoolean(true);
>    while (vanity.get()) {
>      new Thread(new Runnable() {
>        public void run() {
>          MagicMirror mirrorOnTheWall = new MagicMirror();
>          boolean beauty = mirrorOnTheWall.amIPretty();
>          if (!beauty) vanity.set(false);
>        }
>      }).start();
>    }
>    System.out.println("Oh no, now I am depressed!");
>  }
> }
> 
> What do you think this will return in Java 7?  In Java 8?  Obviously in
> Java 7 this would be quite bad, because each thread is supposed to have
> his or her own TLR instance.  But in Java 8 it's a Singleton anyway, so
> who cares?

Anyway, I think it calls for eager TLR state initialization in Thread
itself; otherwise we are bound by the implicit contract "current()
should be called by user thread at least once before pulling the values
out of thread", which might be surprising. This will couple Thread and
TLR more... but I can put the relevant change into JDK. Doug?

-Aleksey.


From hallorant at gmail.com  Thu Jan 30 15:03:12 2014
From: hallorant at gmail.com (Tim Halloran)
Date: Thu, 30 Jan 2014 15:03:12 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAACD3.8000405@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
Message-ID: <CAMyLHFx5-FpvHtGtkyGPM2xbWoEzrxpxUU1pdcfZJKM3kHuBog@mail.gmail.com>

>
> Anyway, I think it calls for eager TLR state initialization in Thread
> itself; otherwise we are bound by the implicit contract "current()
> should be called by user thread at least once before pulling the values
> out of thread", which might be surprising. This will couple Thread and
> TLR more... but I can put the relevant change into JDK. Doug?
>
> -Aleksey.


+1

I think this is right, I see no reason this code won't work under Java 7 --
unless it runs out of memory creating threads too fast.  But Java 8 is
probably going not behave like Java 7.  Off to try it on the computer.

Tim H
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140130/dde102b2/attachment.html>

From zhong.j.yu at gmail.com  Thu Jan 30 15:03:37 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 30 Jan 2014 14:03:37 -0600
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAAA2A.9080901@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAAA2A.9080901@oracle.com>
Message-ID: <CACuKZqEqJySe_B056RTOm4bGdrDqsm3yEKiz1beOFiFiFTCZvQ@mail.gmail.com>

A modest version with only one thread at a time:

    private static final ThreadLocalRandom tlr =
        ThreadLocalRandom.current();

    public static void main(String... args) throws InterruptedException
    {
        final AtomicBoolean vanity = new AtomicBoolean(true);
        while (vanity.get())
        {
            Thread t = new Thread(() ->
            {
                if (!tlr.nextBoolean())
                    vanity.set(false);
            });
            t.start();
            t.join();
        }
        System.out.println("Oh no, now I am depressed!");
    }

And the loop never terminates...

Zhong Yu


On Thu, Jan 30, 2014 at 1:38 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:
> The obvious answer is that eventually you are going to recognize that you
> are ugly and that you are going to end up depressed.  ;)  But, since it is
> you that is proposing the puzzle, I have my doubts even though I can't
> fathom why.
>
> It seems to me that the main thread is going to spin until vanity is set to
> false.  Some thread is going to see !amIPretty() and set vanity to false.
> The main thread is going to exit and the JVM won't exit until the rest of
> the created threads have begun, executed and terminated.  These threads are
> not daemon threads.
>
> Here's another scenario.  This is going to create a lot of threads.  In some
> cases, the main thread is going to throw an OutOfMemoryError because another
> thread can't be created.  There are too many call stacks consuming virtual
> address space but they can't be cleaned up by the JVM because the threads
> haven't even begun execution.  You have previously shown that it can take
> several tens or hundreds (?) of milliseconds to get threads started.  Even
> worse is if the call stacks can be cleaned up with a full GC because the
> threads have terminated but a bug doesn't cause the JVM to execute a full GC
> when trying to create another thread.
>
> -Nathan
>
> On 1/30/2014 12:11 PM, Dr Heinz M. Kabutz wrote:
>
> In Java 8, TLR has become a Singleton.  Prior to that, we had to be careful
> to not let it escape from being thread confined.  However, the current()
> method call was also a ThreadLocal lookup, so it was fairly slow to call.
> It was thus tempting to store the TLR in a field.  Thus in Java 8, the seed
> and all the related information was moved to the Thread class.  I think most
> concurrency-interest readers would be aware of this.  But consider this
> class:
>
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
>
> public class MagicMirror {
>  private static final ThreadLocalRandom tlr =
>      ThreadLocalRandom.current();
>
>  public boolean amIPretty() {
>    return tlr.nextBoolean();
>  }
>
>  public static void main(String... args) {
>    final AtomicBoolean vanity = new AtomicBoolean(true);
>    while (vanity.get()) {
>      new Thread(new Runnable() {
>        public void run() {
>          MagicMirror mirrorOnTheWall = new MagicMirror();
>          boolean beauty = mirrorOnTheWall.amIPretty();
>          if (!beauty) vanity.set(false);
>        }
>      }).start();
>    }
>    System.out.println("Oh no, now I am depressed!");
>  }
> }
>
> What do you think this will return in Java 7?  In Java 8?  Obviously in Java
> 7 this would be quite bad, because each thread is supposed to have his or
> her own TLR instance.  But in Java 8 it's a Singleton anyway, so who cares?
>
> Regards
>
> Heinz
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dl at cs.oswego.edu  Thu Jan 30 16:01:40 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 30 Jan 2014 16:01:40 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAACD3.8000405@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
Message-ID: <52EABDB4.1030409@cs.oswego.edu>

On 01/30/2014 02:49 PM, Aleksey Shipilev wrote:
> On 01/30/2014 11:11 PM, Dr Heinz M. Kabutz wrote:
>> In Java 8, TLR has become a Singleton.  Prior to that, we had to be
>> careful to not let it escape from being thread confined.  However, the
>> current() method call was also a ThreadLocal lookup, so it was fairly
>> slow to call.  It was thus tempting to store the TLR in a field.  Thus
>> in Java 8, the seed and all the related information was moved to the
>> Thread class.  I think most concurrency-interest readers would be aware
>> of this.  But consider this class:
>>
>> import java.util.concurrent.*;
>> import java.util.concurrent.atomic.*;
>>
>> public class MagicMirror {
>>   private static final ThreadLocalRandom tlr =
>>       ThreadLocalRandom.current();
>>
>>   public boolean amIPretty() {
>>     return tlr.nextBoolean();
>>   }
>>
>>   public static void main(String... args) {
>>     final AtomicBoolean vanity = new AtomicBoolean(true);
>>     while (vanity.get()) {
>>       new Thread(new Runnable() {
>>         public void run() {
>>           MagicMirror mirrorOnTheWall = new MagicMirror();
>>           boolean beauty = mirrorOnTheWall.amIPretty();
>>           if (!beauty) vanity.set(false);
>>         }
>>       }).start();
>>     }
>>     System.out.println("Oh no, now I am depressed!");
>>   }
>> }
>>
>> What do you think this will return in Java 7?  In Java 8?  Obviously in
>> Java 7 this would be quite bad, because each thread is supposed to have
>> his or her own TLR instance.  But in Java 8 it's a Singleton anyway, so
>> who cares?
>
> Anyway, I think it calls for eager TLR state initialization in Thread
> itself; otherwise we are bound by the implicit contract "current()
> should be called by user thread at least once before pulling the values
> out of thread", which might be surprising. This will couple Thread and
> TLR more... but I can put the relevant change into JDK. Doug?
>

The question amounts to: what are the consequences of the error
of leaking your TLR into a static?
They are a little different in JDK7 and JDK8, but this doesn't
make a very compelling argument for changing either one.

-Doug









From aleksey.shipilev at oracle.com  Thu Jan 30 16:21:10 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 31 Jan 2014 01:21:10 +0400
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EABDB4.1030409@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com> <52EABDB4.1030409@cs.oswego.edu>
Message-ID: <52EAC246.1080606@oracle.com>

On 01/31/2014 01:01 AM, Doug Lea wrote:
> On 01/30/2014 02:49 PM, Aleksey Shipilev wrote:
>> Anyway, I think it calls for eager TLR state initialization in Thread
>> itself; otherwise we are bound by the implicit contract "current()
>> should be called by user thread at least once before pulling the values
>> out of thread", which might be surprising. This will couple Thread and
>> TLR more... but I can put the relevant change into JDK. Doug?
>>
> 
> The question amounts to: what are the consequences of the error
> of leaking your TLR into a static?
> They are a little different in JDK7 and JDK8, but this doesn't
> make a very compelling argument for changing either one.

I think we talk about how badly it breaks if TLR is accidentally shared
to non-initializing thread. JDK 7-ish version provided at least some
entropy in that case, JDK 8 provides zero.

I believe the more frequent case would be:

class ObliviousUser {
 final Random rnd;

 ObliviousUser(Random rnd) {
    this.rnd = rnd;
 }

 void ch() {
    ... rnd.nextInt(); ...
 }
}

Thread 1:
  // publish
  ou = new ObliviousUser(ThreadLocalRandom.current());

Thread 2:
  // assume (ou != null)
  ou.ch(); // "chosen by fair dice roll. guaranteed to be random" (c)

-Aleksey.

From kirk at kodewerk.com  Fri Jan 31 03:29:05 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Fri, 31 Jan 2014 09:29:05 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA3FF.1020109@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>
Message-ID: <676DA33F-D23C-4BA3-AEEB-AFEC522A5052@kodewerk.com>

Simple, it runs until the TLR finally returns false. If the TRL never returns false this will run forever. It?s unlikely.. I?d say impossible for it to OOME as back-pressure from the pause will allow the JVM to clean up all the dead threads.

? Kirk

On Jan 30, 2014, at 8:11 PM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:

> In Java 8, TLR has become a Singleton.  Prior to that, we had to be careful to not let it escape from being thread confined.  However, the current() method call was also a ThreadLocal lookup, so it was fairly slow to call.  It was thus tempting to store the TLR in a field.  Thus in Java 8, the seed and all the related information was moved to the Thread class.  I think most concurrency-interest readers would be aware of this.  But consider this class:
> 
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
> 
> public class MagicMirror {
> private static final ThreadLocalRandom tlr =
>     ThreadLocalRandom.current();
> 
> public boolean amIPretty() {
>   return tlr.nextBoolean();
> }
> 
> public static void main(String... args) {
>   final AtomicBoolean vanity = new AtomicBoolean(true);
>   while (vanity.get()) {
>     new Thread(new Runnable() {
>       public void run() {
>         MagicMirror mirrorOnTheWall = new MagicMirror();
>         boolean beauty = mirrorOnTheWall.amIPretty();
>         if (!beauty) vanity.set(false);
>       }
>     }).start();
>   }
>   System.out.println("Oh no, now I am depressed!");
> }
> }
> 
> What do you think this will return in Java 7?  In Java 8?  Obviously in Java 7 this would be quite bad, because each thread is supposed to have his or her own TLR instance.  But in Java 8 it's a Singleton anyway, so who cares?
> 
> Regards
> 
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Oracle Java Champion 2005-2013
> JavaOne Rock Star Speaker 2012
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From kirk at kodewerk.com  Fri Jan 31 03:35:23 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Fri, 31 Jan 2014 09:35:23 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAA3FF.1020109@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>
Message-ID: <18C33C3C-A472-488E-9334-B5F15A61FE70@kodewerk.com>

ok, now that I?ve run it, 7.0_45 seems to work as predicted but 8.0_ea works it?s way into an infinite loop. I was thinking that maybe the corruption would be either to true or false and then just stay that way but repeating the runs several times doesn?t yield the true case. I might file this as a bug.

Regards,
Kirk

On Jan 30, 2014, at 8:11 PM, Dr Heinz M. Kabutz <heinz at javaspecialists.eu> wrote:

> In Java 8, TLR has become a Singleton.  Prior to that, we had to be careful to not let it escape from being thread confined.  However, the current() method call was also a ThreadLocal lookup, so it was fairly slow to call.  It was thus tempting to store the TLR in a field.  Thus in Java 8, the seed and all the related information was moved to the Thread class.  I think most concurrency-interest readers would be aware of this.  But consider this class:
> 
> import java.util.concurrent.*;
> import java.util.concurrent.atomic.*;
> 
> public class MagicMirror {
> private static final ThreadLocalRandom tlr =
>     ThreadLocalRandom.current();
> 
> public boolean amIPretty() {
>   return tlr.nextBoolean();
> }
> 
> public static void main(String... args) {
>   final AtomicBoolean vanity = new AtomicBoolean(true);
>   while (vanity.get()) {
>     new Thread(new Runnable() {
>       public void run() {
>         MagicMirror mirrorOnTheWall = new MagicMirror();
>         boolean beauty = mirrorOnTheWall.amIPretty();
>         if (!beauty) vanity.set(false);
>       }
>     }).start();
>   }
>   System.out.println("Oh no, now I am depressed!");
> }
> }
> 
> What do you think this will return in Java 7?  In Java 8?  Obviously in Java 7 this would be quite bad, because each thread is supposed to have his or her own TLR instance.  But in Java 8 it's a Singleton anyway, so who cares?
> 
> Regards
> 
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Oracle Java Champion 2005-2013
> JavaOne Rock Star Speaker 2012
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From ylt at letallec.org  Fri Jan 31 04:28:51 2014
From: ylt at letallec.org (Yann Le Tallec)
Date: Fri, 31 Jan 2014 09:28:51 +0000
Subject: [concurrency-interest] Side effect of the new
	ForkJoinPool.commonPool & InnocuousForkJoinWorkerThreadFactory
In-Reply-To: <52EA8D3C.5040206@cs.oswego.edu>
References: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>
	<52EA8D3C.5040206@cs.oswego.edu>
Message-ID: <CAOPu7Ejho43URgQcKcXhPQxvwjk=Mbj3wH32P9w=djpUsts6mA@mail.gmail.com>

I guess I was wondering why the policy is more restrictive than what is
implemented by the Thread class, i.e. `sm.checkPermission(new
RuntimePermission("setContextClassLoader"));`, which seemed like a
reasonable default in the presence of a security manager.


On 30 January 2014 17:34, Doug Lea <dl at cs.oswego.edu> wrote:

> On 01/30/2014 10:22 AM, Yann Le Tallec wrote:
>
>> Hi all,
>>
>> following the introduction of the "InnocuousForkJoinWorkerThreadFactory"
>> in java
>> 8 b123
>> (http://cs.oswego.edu/pipermail/concurrency-
>> interest/2013-December/012123.html),
>> calling `setContextClassLoader` inside a `CompletableFuture.runAsync()`
>> throws a
>> SecurityException if a SecurityManager is installed, as expected when
>> looking at
>> the InnocuousForkJoinWorkerThread code:
>>
>>          @Override // paranoically
>>          public void setContextClassLoader(ClassLoader cl) {
>>              throw new SecurityException("setContextClassLoader");
>>          }
>>
>> It is possible to provide a different factory through the system
>> properties,
>> which gets loaded with (ForkJoinPool#makeCommonPool):
>>
>>      String fp =
>> System.getProperty("java.util.concurrent.ForkJoinPool.
>> common.threadFactory");
>>      factory =
>> ((ForkJoinWorkerThreadFactory)ClassLoader.getSystemClassLoader().
>> loadClass(fp).newInstance());
>>
>> However, when the application is launched via Java Web Start, the last
>> statement
>> throws a ClassNotFoundException (I suppose because JWS uses a different
>> class
>> loader system) even if the JWS application has all permissions enabled
>> (in the
>> manifest and the jnlp). Therefore it looks like there is no way to
>> replace the
>> default, no permission, InnocuousForkJoinWorkerThreadFactory in a JWS
>> application.
>>
>> Is this by design? Is there a workaround?
>>
>>
> Disabling setContextClassLoader was intended to be tolerable
> (and to rule out other potential problems in a simple way)
> across known uses. Here, because JWS can support multiple applications,
> none of them should be setting common pool policies for the others. This
> might not mesh well with current JWS administration, but I don't
> see anything ForkJoinPool itself can or should do about this. Do you?
>
> -Doug
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/8ef49fde/attachment.html>

From chris.hegarty at oracle.com  Fri Jan 31 06:08:49 2014
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Fri, 31 Jan 2014 11:08:49 +0000
Subject: [concurrency-interest] Side effect of the new
 ForkJoinPool.commonPool & InnocuousForkJoinWorkerThreadFactory
In-Reply-To: <CAOPu7Ejho43URgQcKcXhPQxvwjk=Mbj3wH32P9w=djpUsts6mA@mail.gmail.com>
References: <CAOPu7Eg5cwXqujLYi62jo8TY1O18LNrpQY85Vco7YZ=ZfVTXKg@mail.gmail.com>	<52EA8D3C.5040206@cs.oswego.edu>
	<CAOPu7Ejho43URgQcKcXhPQxvwjk=Mbj3wH32P9w=djpUsts6mA@mail.gmail.com>
Message-ID: <52EB8441.5050400@oracle.com>

On 31/01/14 09:28, Yann Le Tallec wrote:
> I guess I was wondering why the policy is more restrictive than what is
> implemented by the Thread class, i.e. `sm.checkPermission(new
> RuntimePermission("setContextClassLoader"));`, which seemed like a
> reasonable default in the presence of a security manager.

With multiple applications running in the same VM, it us not enough to 
check this permission. If one application is granted this permission, it 
could then possibly cause an impact on another.

-Chris.

>
>
> On 30 January 2014 17:34, Doug Lea <dl at cs.oswego.edu
> <mailto:dl at cs.oswego.edu>> wrote:
>
>     On 01/30/2014 10:22 AM, Yann Le Tallec wrote:
>
>         Hi all,
>
>         following the introduction of the
>         "__InnocuousForkJoinWorkerThreadF__actory" in java
>         8 b123
>         (http://cs.oswego.edu/__pipermail/concurrency-__interest/2013-December/012123.__html
>         <http://cs.oswego.edu/pipermail/concurrency-interest/2013-December/012123.html>),
>         calling `setContextClassLoader` inside a
>         `CompletableFuture.runAsync()` throws a
>         SecurityException if a SecurityManager is installed, as expected
>         when looking at
>         the InnocuousForkJoinWorkerThread code:
>
>                   @Override // paranoically
>                   public void setContextClassLoader(__ClassLoader cl) {
>                       throw new
>         SecurityException("__setContextClassLoader");
>                   }
>
>         It is possible to provide a different factory through the system
>         properties,
>         which gets loaded with (ForkJoinPool#makeCommonPool):
>
>               String fp =
>         System.getProperty("java.util.__concurrent.ForkJoinPool.__common.threadFactory");
>               factory =
>         ((ForkJoinWorkerThreadFactory)__ClassLoader.__getSystemClassLoader().__loadClass(fp).newInstance());
>
>         However, when the application is launched via Java Web Start,
>         the last statement
>         throws a ClassNotFoundException (I suppose because JWS uses a
>         different class
>         loader system) even if the JWS application has all permissions
>         enabled (in the
>         manifest and the jnlp). Therefore it looks like there is no way
>         to replace the
>         default, no permission, InnocuousForkJoinWorkerThreadF__actory
>         in a JWS application.
>
>         Is this by design? Is there a workaround?
>
>
>     Disabling setContextClassLoader was intended to be tolerable
>     (and to rule out other potential problems in a simple way)
>     across known uses. Here, because JWS can support multiple applications,
>     none of them should be setting common pool policies for the others. This
>     might not mesh well with current JWS administration, but I don't
>     see anything ForkJoinPool itself can or should do about this. Do you?
>
>     -Doug
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From heinz at javaspecialists.eu  Fri Jan 31 06:46:17 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 06:46:17 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <18C33C3C-A472-488E-9334-B5F15A61FE70@kodewerk.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<18C33C3C-A472-488E-9334-B5F15A61FE70@kodewerk.com>
Message-ID: <52EB8D09.3030601@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/36a74069/attachment-0001.html>

From dl at cs.oswego.edu  Fri Jan 31 07:00:16 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 31 Jan 2014 07:00:16 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EAC246.1080606@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com> <52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com>
Message-ID: <52EB9050.7050503@cs.oswego.edu>

On 01/30/2014 04:21 PM, Aleksey Shipilev wrote:
> On 01/31/2014 01:01 AM, Doug Lea wrote:
>> The question amounts to: what are the consequences of the error
>> of leaking your TLR into a static?
>> They are a little different in JDK7 and JDK8, but this doesn't
>> make a very compelling argument for changing either one.
>
> I think we talk about how badly it breaks if TLR is accidentally shared
> to non-initializing thread. JDK 7-ish version provided at least some
> entropy in that case, JDK 8 provides zero.
>

I don't understand the concern.
It is an error to share a TLR across threads (as the
spec/javadoc makes perfectly clear). Ideally, it would
be some sort of syntax of type error. But given that it
is not, and cannot easily be dynamically trapped, what's
a good choice of behavior that will cause programmers
to notice and fix their errors? Returning zero
(in this scenario) seems like a fine choice.

If there were pre-JDK8 applications out there that relied on this
erroneous use having some other outcome, we might have
some motivation to change it, but it is hard to imagine any.

-Doug


From kirk at kodewerk.com  Fri Jan 31 07:10:21 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Fri, 31 Jan 2014 13:10:21 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EB9050.7050503@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com> <52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com> <52EB9050.7050503@cs.oswego.edu>
Message-ID: <86D8B385-2EBC-4070-9E78-A4CA1092CE7D@kodewerk.com>


>> 
> 
> I don't understand the concern.
> It is an error to share a TLR across threads (as the
> spec/javadoc makes perfectly clear). Ideally, it would
> be some sort of syntax of type error. But given that it
> is not, and cannot easily be dynamically trapped, what's
> a good choice of behavior that will cause programmers
> to notice and fix their errors? Returning zero
> (in this scenario) seems like a fine choice.

All these good arguments aside.. it is a bug because it is a violation of separation of concerns to have the TLR initialization be contained in the thread. The fact that it?s thread local is a side show IMHO.

Regards,
Kirk



From heinz at javaspecialists.eu  Fri Jan 31 07:51:19 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 07:51:19 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EB9050.7050503@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
Message-ID: <52EB9C47.3080908@javaspecialists.eu>

Doug Lea wrote:
> On 01/30/2014 04:21 PM, Aleksey Shipilev wrote:
>> On 01/31/2014 01:01 AM, Doug Lea wrote:
>>> The question amounts to: what are the consequences of the error
>>> of leaking your TLR into a static?
>>> They are a little different in JDK7 and JDK8, but this doesn't
>>> make a very compelling argument for changing either one.
>>
>> I think we talk about how badly it breaks if TLR is accidentally shared
>> to non-initializing thread. JDK 7-ish version provided at least some
>> entropy in that case, JDK 8 provides zero.
>>
>
> I don't understand the concern.
> It is an error to share a TLR across threads (as the
> spec/javadoc makes perfectly clear). Ideally, it would
> be some sort of syntax of type error. But given that it
> is not, and cannot easily be dynamically trapped, what's
> a good choice of behavior that will cause programmers
> to notice and fix their errors? Returning zero
> (in this scenario) seems like a fine choice.
>
> If there were pre-JDK8 applications out there that relied on this
> erroneous use having some other outcome, we might have
> some motivation to change it, but it is hard to imagine any.
Principle of least surprises.  I have not said it is a "bug", but we all 
were surprised when we saw the result.  Obviously it is incorrect to 
share TLR across threads.  However, if I knew it was a Singleton in Java 
8, I might be tempted to think it does not matter if you do.  I think my 
code showed that the results are quite surprising.  It does not always 
return zero, but instead it returns a sequence of random numbers that 
start at seed zero.

import java.util.concurrent.*;

public class LeastSurprises {
  private static final ThreadLocalRandom tlr = ThreadLocalRandom.current();
  public static void main(String... args) throws InterruptedException {
    for (int i = 0; i < 10; i++) {
      System.out.println("Thread " + (i+1));
      Thread t = new Thread() {
        public void run() {
          for (int j = 0; j < 10; j++) {
            System.out.println(tlr.nextGaussian());
          }
        }
      };
      t.start();
      t.join();
      System.out.println();
    }
  }
}

In Java 7, this returns random values.  As we know, in Java 7, the 
current() method required a ThreadLocal lookup, so it wasn't as fast as 
caching it in a local variable.  And the step from a local variable to a 
field is quickly done.  Now I agree of course that the code is 
incorrect, but since all we are doing is generating random values, does 
it matter if occasionally we have duplicates?  Isn't that what random is 
all about anyway?

So, in Java 8, you will currently get this output, regardless of which 
machine you run it on and when:

Thread 1
0.3999564263366546
1.1602368073797789
1.1461698444484156
-0.2750826025815922
-0.7942920693093543
-0.7969162010067281
0.37183586790086887
0.08252530331332697
-0.640823054843121
-0.972395618004264

Thread 2
0.3999564263366546
1.1602368073797789
1.1461698444484156
-0.2750826025815922
-0.7942920693093543
-0.7969162010067281
0.37183586790086887
0.08252530331332697
-0.640823054843121
-0.972395618004264

Thread 3
0.3999564263366546
1.1602368073797789
1.1461698444484156
-0.2750826025815922
-0.7942920693093543
-0.7969162010067281
0.37183586790086887
0.08252530331332697
-0.640823054843121
-0.972395618004264

etc.

Now that does seem a bit surprising to me :-)

Heinz

From vitalyd at gmail.com  Fri Jan 31 08:25:32 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 31 Jan 2014 08:25:32 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EB9C47.3080908@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu> <52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
Message-ID: <CAHjP37H7dMRd-Fa17MW6mfJsNHbDR=PHBNPs4O0cRJuHKUUppA@mail.gmail.com>

It's not really a singleton though - it's a "multiplexed" instance :).

If we all agree that the example code is broken and TLR is used
incorrectly, then why should there be an expectation of it working? Just
because java 7 did? Seems like java 7 would simply mask this user bug, I
wouldn't call it "working" in the strict definition.

As for principle of least surprise, that should only apply if one is using
the API as intended; otherwise, any surprise is fair game.

Sent from my phone
On Jan 31, 2014 8:00 AM, "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
wrote:

> Doug Lea wrote:
>
>> On 01/30/2014 04:21 PM, Aleksey Shipilev wrote:
>>
>>> On 01/31/2014 01:01 AM, Doug Lea wrote:
>>>
>>>> The question amounts to: what are the consequences of the error
>>>> of leaking your TLR into a static?
>>>> They are a little different in JDK7 and JDK8, but this doesn't
>>>> make a very compelling argument for changing either one.
>>>>
>>>
>>> I think we talk about how badly it breaks if TLR is accidentally shared
>>> to non-initializing thread. JDK 7-ish version provided at least some
>>> entropy in that case, JDK 8 provides zero.
>>>
>>>
>> I don't understand the concern.
>> It is an error to share a TLR across threads (as the
>> spec/javadoc makes perfectly clear). Ideally, it would
>> be some sort of syntax of type error. But given that it
>> is not, and cannot easily be dynamically trapped, what's
>> a good choice of behavior that will cause programmers
>> to notice and fix their errors? Returning zero
>> (in this scenario) seems like a fine choice.
>>
>> If there were pre-JDK8 applications out there that relied on this
>> erroneous use having some other outcome, we might have
>> some motivation to change it, but it is hard to imagine any.
>>
> Principle of least surprises.  I have not said it is a "bug", but we all
> were surprised when we saw the result.  Obviously it is incorrect to share
> TLR across threads.  However, if I knew it was a Singleton in Java 8, I
> might be tempted to think it does not matter if you do.  I think my code
> showed that the results are quite surprising.  It does not always return
> zero, but instead it returns a sequence of random numbers that start at
> seed zero.
>
> import java.util.concurrent.*;
>
> public class LeastSurprises {
>  private static final ThreadLocalRandom tlr = ThreadLocalRandom.current();
>  public static void main(String... args) throws InterruptedException {
>    for (int i = 0; i < 10; i++) {
>      System.out.println("Thread " + (i+1));
>      Thread t = new Thread() {
>        public void run() {
>          for (int j = 0; j < 10; j++) {
>            System.out.println(tlr.nextGaussian());
>          }
>        }
>      };
>      t.start();
>      t.join();
>      System.out.println();
>    }
>  }
> }
>
> In Java 7, this returns random values.  As we know, in Java 7, the
> current() method required a ThreadLocal lookup, so it wasn't as fast as
> caching it in a local variable.  And the step from a local variable to a
> field is quickly done.  Now I agree of course that the code is incorrect,
> but since all we are doing is generating random values, does it matter if
> occasionally we have duplicates?  Isn't that what random is all about
> anyway?
>
> So, in Java 8, you will currently get this output, regardless of which
> machine you run it on and when:
>
> Thread 1
> 0.3999564263366546
> 1.1602368073797789
> 1.1461698444484156
> -0.2750826025815922
> -0.7942920693093543
> -0.7969162010067281
> 0.37183586790086887
> 0.08252530331332697
> -0.640823054843121
> -0.972395618004264
>
> Thread 2
> 0.3999564263366546
> 1.1602368073797789
> 1.1461698444484156
> -0.2750826025815922
> -0.7942920693093543
> -0.7969162010067281
> 0.37183586790086887
> 0.08252530331332697
> -0.640823054843121
> -0.972395618004264
>
> Thread 3
> 0.3999564263366546
> 1.1602368073797789
> 1.1461698444484156
> -0.2750826025815922
> -0.7942920693093543
> -0.7969162010067281
> 0.37183586790086887
> 0.08252530331332697
> -0.640823054843121
> -0.972395618004264
>
> etc.
>
> Now that does seem a bit surprising to me :-)
>
> Heinz
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/d0e841d7/attachment.html>

From dl at cs.oswego.edu  Fri Jan 31 08:36:35 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 31 Jan 2014 08:36:35 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EB9C47.3080908@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
Message-ID: <52EBA6E3.2060707@cs.oswego.edu>

On 01/31/2014 07:51 AM, Dr Heinz M. Kabutz wrote:
> Principle of least surprises.  I have not said it is a "bug", but we all were
> surprised when we saw the result.  Obviously it is incorrect to share TLR across
> threads.  However, if I knew it was a Singleton in Java 8, I might be tempted to
> think it does not matter if you do.  I think my code showed that the results are
> quite surprising.  It does not always return zero, but instead it returns a
> sequence of random numbers that start at seed zero.
>

Your program is a good puzzler because people can be led down
a path to find it surprising:
1. The spec says that sharing a TLR across threads is an error
(with unspecified consequences).
2. Someone looks at the implementation and overgeneralizes the
singleton usage to imply that maybe it isn't really an error.
3. They then write a program and find out that the spec was right
after all.

I'm still a little hesitant to do anything for the sake of people
making this mistake based on your cleverly broken examples :-)

-Doug


From aleksey.shipilev at oracle.com  Fri Jan 31 09:16:20 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 31 Jan 2014 18:16:20 +0400
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBA6E3.2060707@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu>
Message-ID: <52EBB034.3000305@oracle.com>

On 01/31/2014 05:36 PM, Doug Lea wrote:
> 1. The spec says that sharing a TLR across threads is an error
> (with unspecified consequences).

I think we should at least put a good warning sign in Javadocs then. It
now says [1]: "Usages of this class should typically be of the form:
ThreadLocalRandom.current().nextX(...)".

This does not sound like the prohibitive "sharing a TLR across threads
is an error (with unspecified consequences", but merely like a soft
warning about the performance characteristics?

-Aleksey.

From hallorant at gmail.com  Fri Jan 31 09:49:39 2014
From: hallorant at gmail.com (Tim Halloran)
Date: Fri, 31 Jan 2014 09:49:39 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBB034.3000305@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu> <52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
Message-ID: <CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>

On Fri, Jan 31, 2014 at 9:16 AM, Aleksey Shipilev <
aleksey.shipilev at oracle.com> wrote:

> On 01/31/2014 05:36 PM, Doug Lea wrote:
> > 1. The spec says that sharing a TLR across threads is an error
> > (with unspecified consequences).
>
> I think we should at least put a good warning sign in Javadocs then. It
> now says [1]: "Usages of this class should typically be of the form:
> ThreadLocalRandom.current().nextX(...)".
>
> This does not sound like the prohibitive "sharing a TLR across threads
> is an error (with unspecified consequences", but merely like a soft
> warning about the performance characteristics?
>

I read the Javadoc and thought it was clear without sounding alarming to
the programmer.  I speculate the word "typically" is used because it is
perfectly fine to stash the reference returned from current() into a field
or (more likely) a local variable so long as all references remain
thread-confined to the thread current() was invoked within.

Being fail-fast might be helpful, but may not be possible. Is there any
way, without destroying the performance characteristics of the
implementation, an IllegalStateException (or perhaps something more
precise) can be thrown? SWT does this when event thread calls are detected
outside of the SWT thread -- sadly, Swing doesn't.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/166ea308/attachment.html>

From heinz at javaspecialists.eu  Fri Jan 31 10:00:46 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 10:00:46 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBB034.3000305@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
Message-ID: <52EBBA9E.8010906@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/e6c29c69/attachment.html>

From heinz at javaspecialists.eu  Fri Jan 31 10:03:34 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 10:03:34 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>
	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
Message-ID: <52EBBB46.5080002@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/70883817/attachment.html>

From nathan.reynolds at oracle.com  Fri Jan 31 11:12:25 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 31 Jan 2014 09:12:25 -0700
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBB034.3000305@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>
Message-ID: <52EBCB69.20000@oracle.com>

We can put as much as we want into the documentation.  We will help a 
few people.  But, many will simply ignore it.  What about adding a rule 
to FindBugs?  This would be able to flag the issue and help a few more 
people.

-Nathan

On 1/31/2014 7:16 AM, Aleksey Shipilev wrote:
> On 01/31/2014 05:36 PM, Doug Lea wrote:
>> 1. The spec says that sharing a TLR across threads is an error
>> (with unspecified consequences).
> I think we should at least put a good warning sign in Javadocs then. It
> now says [1]: "Usages of this class should typically be of the form:
> ThreadLocalRandom.current().nextX(...)".
>
> This does not sound like the prohibitive "sharing a TLR across threads
> is an error (with unspecified consequences", but merely like a soft
> warning about the performance characteristics?
>
> -Aleksey.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/b22e82b1/attachment.html>

From heinz at javaspecialists.eu  Fri Jan 31 11:40:11 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 11:40:11 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBCB69.20000@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>
	<52EBCB69.20000@oracle.com>
Message-ID: <52EBD1EB.3020204@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/4bfde7f5/attachment.html>

From zhong.j.yu at gmail.com  Fri Jan 31 12:47:09 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 31 Jan 2014 11:47:09 -0600
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBBB46.5080002@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu> <52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
	<52EBBB46.5080002@javaspecialists.eu>
Message-ID: <CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>

If we make TLR behave "as expected" even if it's used incorrectly,
we'll just encourage incorrect usages. People will begin to use it as
a global random instead of a thread local one, and that will become a
de facto contract of TLR, making further changes difficult.

If we add a check in nextX()
    if( currentThread.PROBE==0 )
        throw new IllegalStateException()
it should not be too expensive, right? Or just an "assert PROBE!=0"?

Zhong Yu



On Fri, Jan 31, 2014 at 9:03 AM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> Tim Halloran wrote:
>
> On Fri, Jan 31, 2014 at 9:16 AM, Aleksey Shipilev
> <aleksey.shipilev at oracle.com> wrote:
>>
>> On 01/31/2014 05:36 PM, Doug Lea wrote:
>> > 1. The spec says that sharing a TLR across threads is an error
>> > (with unspecified consequences).
>>
>> I think we should at least put a good warning sign in Javadocs then. It
>> now says [1]: "Usages of this class should typically be of the form:
>> ThreadLocalRandom.current().nextX(...)".
>>
>> This does not sound like the prohibitive "sharing a TLR across threads
>> is an error (with unspecified consequences", but merely like a soft
>> warning about the performance characteristics?
>
>
> I read the Javadoc and thought it was clear without sounding alarming to the
> programmer.  I speculate the word "typically" is used because it is
> perfectly fine to stash the reference returned from current() into a field
> or (more likely) a local variable so long as all references remain
> thread-confined to the thread current() was invoked within.
>
> Thanks, that's just proved my point - I think that storing it in a "field"
> is definitely incorrect and unless it is guaranteed that no other thread
> would ever see that object, Java 8 would lead to possibly surprising
> results.
>
> Being fail-fast might be helpful, but may not be possible. Is there any way,
> without destroying the performance characteristics of the implementation, an
> IllegalStateException (or perhaps something more precise) can be thrown? SWT
> does this when event thread calls are detected outside of the SWT thread --
> sadly, Swing doesn't.
>
> Or we could just initialize the seed variables eagerly instead of lazily?
> That would make all this go away, plus would require one less check every
> time we call current().
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From heinz at javaspecialists.eu  Fri Jan 31 12:48:41 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 31 Jan 2014 12:48:41 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>
	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
Message-ID: <52EBE1F9.9030206@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/b19a0fb5/attachment.html>

From kirk at kodewerk.com  Fri Jan 31 13:00:32 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Fri, 31 Jan 2014 19:00:32 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBA6E3.2060707@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu>
Message-ID: <36E58701-A649-4BB6-A705-30868F59FB5A@kodewerk.com>

Hi Doug,

> 
> Your program is a good puzzler because people can be led down
> a path to find it surprising:
> 1. The spec says that sharing a TLR across threads is an error
> (with unspecified consequences).
> 2. Someone looks at the implementation and overgeneralizes the
> singleton usage to imply that maybe it isn't really an error.
> 3. They then write a program and find out that the spec was right
> after all.

I?m not sure how to express this but it feels somewhat wrong that some that intuativily seems like it should be thread safe.. isn?t. Or should I say, there isn?t anything about random number generation that would lead me to believe that I need to worry about threading concerns. In my world this seems like a very fragile spec/desing/implementation.. don?t know which one to pick.

? Kirk



From oleksandr.otenko at oracle.com  Fri Jan 31 13:09:15 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 31 Jan 2014 18:09:15 +0000
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>
	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
Message-ID: <52EBE6CB.6070000@oracle.com>

Is the point to make the source of randomness scalable, or is the point 
to make the source of randomness unique for each thread?

It is not entirely clear from the documentation.

I think these requirements imply different behaviours around the use of 
shared ThreadLocalRandom from other threads. So, in the first case I 
would make it clear that if the ThreadLocalRandom is not shared by the 
threads, the algorithm takes advantage of that to scale better. The 
second case makes sharing of the TLR a illegal state.

As it is, the implementation that seeds 0 does not meet neither of those 
cases.


Alex


On 31/01/2014 17:47, Zhong Yu wrote:
> If we make TLR behave "as expected" even if it's used incorrectly,
> we'll just encourage incorrect usages. People will begin to use it as
> a global random instead of a thread local one, and that will become a
> de facto contract of TLR, making further changes difficult.
>
> If we add a check in nextX()
>      if( currentThread.PROBE==0 )
>          throw new IllegalStateException()
> it should not be too expensive, right? Or just an "assert PROBE!=0"?
>
> Zhong Yu
>
>
>
> On Fri, Jan 31, 2014 at 9:03 AM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>> Tim Halloran wrote:
>>
>> On Fri, Jan 31, 2014 at 9:16 AM, Aleksey Shipilev
>> <aleksey.shipilev at oracle.com> wrote:
>>> On 01/31/2014 05:36 PM, Doug Lea wrote:
>>>> 1. The spec says that sharing a TLR across threads is an error
>>>> (with unspecified consequences).
>>> I think we should at least put a good warning sign in Javadocs then. It
>>> now says [1]: "Usages of this class should typically be of the form:
>>> ThreadLocalRandom.current().nextX(...)".
>>>
>>> This does not sound like the prohibitive "sharing a TLR across threads
>>> is an error (with unspecified consequences", but merely like a soft
>>> warning about the performance characteristics?
>>
>> I read the Javadoc and thought it was clear without sounding alarming to the
>> programmer.  I speculate the word "typically" is used because it is
>> perfectly fine to stash the reference returned from current() into a field
>> or (more likely) a local variable so long as all references remain
>> thread-confined to the thread current() was invoked within.
>>
>> Thanks, that's just proved my point - I think that storing it in a "field"
>> is definitely incorrect and unless it is guaranteed that no other thread
>> would ever see that object, Java 8 would lead to possibly surprising
>> results.
>>
>> Being fail-fast might be helpful, but may not be possible. Is there any way,
>> without destroying the performance characteristics of the implementation, an
>> IllegalStateException (or perhaps something more precise) can be thrown? SWT
>> does this when event thread calls are detected outside of the SWT thread --
>> sadly, Swing doesn't.
>>
>> Or we could just initialize the seed variables eagerly instead of lazily?
>> That would make all this go away, plus would require one less check every
>> time we call current().
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Fri Jan 31 14:10:55 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 31 Jan 2014 19:10:55 +0000
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBE6CB.6070000@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE6CB.6070000@oracle.com>
Message-ID: <52EBF53F.6060203@oracle.com>

Looking at the difference between Random and ThreadLocalRandom in JDK7, 
it seems TLR isn't really "concurrent" - instead, we are relaxing the 
consistency guarantees in concurrent uses. The guarantee is there only 
in case of single-threaded access, and using ThreadLocal is one way to 
achieve that. It is not obvious that it is meant to be the */only/* way 
to achieve single-threaded access.

Besides, I see no reason why someone wouldn't want more than one 
single-threaded-access-Random per thread (throughout the Thread's 
lifetime) - one per unit of work, perhaps? In that case I don't need to 
consume the cost of ThreadLocal access.


Alex


On 31/01/2014 18:09, Oleksandr Otenko wrote:
> Is the point to make the source of randomness scalable, or is the 
> point to make the source of randomness unique for each thread?
>
> It is not entirely clear from the documentation.
>
> I think these requirements imply different behaviours around the use 
> of shared ThreadLocalRandom from other threads. So, in the first case 
> I would make it clear that if the ThreadLocalRandom is not shared by 
> the threads, the algorithm takes advantage of that to scale better. 
> The second case makes sharing of the TLR a illegal state.
>
> As it is, the implementation that seeds 0 does not meet neither of 
> those cases.
>
>
> Alex
>
>
> On 31/01/2014 17:47, Zhong Yu wrote:
>> If we make TLR behave "as expected" even if it's used incorrectly,
>> we'll just encourage incorrect usages. People will begin to use it as
>> a global random instead of a thread local one, and that will become a
>> de facto contract of TLR, making further changes difficult.
>>
>> If we add a check in nextX()
>>      if( currentThread.PROBE==0 )
>>          throw new IllegalStateException()
>> it should not be too expensive, right? Or just an "assert PROBE!=0"?
>>
>> Zhong Yu
>>
>>
>>
>> On Fri, Jan 31, 2014 at 9:03 AM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu> wrote:
>>> Tim Halloran wrote:
>>>
>>> On Fri, Jan 31, 2014 at 9:16 AM, Aleksey Shipilev
>>> <aleksey.shipilev at oracle.com> wrote:
>>>> On 01/31/2014 05:36 PM, Doug Lea wrote:
>>>>> 1. The spec says that sharing a TLR across threads is an error
>>>>> (with unspecified consequences).
>>>> I think we should at least put a good warning sign in Javadocs 
>>>> then. It
>>>> now says [1]: "Usages of this class should typically be of the form:
>>>> ThreadLocalRandom.current().nextX(...)".
>>>>
>>>> This does not sound like the prohibitive "sharing a TLR across threads
>>>> is an error (with unspecified consequences", but merely like a soft
>>>> warning about the performance characteristics?
>>>
>>> I read the Javadoc and thought it was clear without sounding 
>>> alarming to the
>>> programmer.  I speculate the word "typically" is used because it is
>>> perfectly fine to stash the reference returned from current() into a 
>>> field
>>> or (more likely) a local variable so long as all references remain
>>> thread-confined to the thread current() was invoked within.
>>>
>>> Thanks, that's just proved my point - I think that storing it in a 
>>> "field"
>>> is definitely incorrect and unless it is guaranteed that no other 
>>> thread
>>> would ever see that object, Java 8 would lead to possibly surprising
>>> results.
>>>
>>> Being fail-fast might be helpful, but may not be possible. Is there 
>>> any way,
>>> without destroying the performance characteristics of the 
>>> implementation, an
>>> IllegalStateException (or perhaps something more precise) can be 
>>> thrown? SWT
>>> does this when event thread calls are detected outside of the SWT 
>>> thread --
>>> sadly, Swing doesn't.
>>>
>>> Or we could just initialize the seed variables eagerly instead of 
>>> lazily?
>>> That would make all this go away, plus would require one less check 
>>> every
>>> time we call current().
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/1644a971/attachment-0001.html>

From kirk at kodewerk.com  Fri Jan 31 14:36:25 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Fri, 31 Jan 2014 20:36:25 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBF53F.6060203@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE6CB.6070000@oracle.com> <52EBF53F.6060203@oracle.com>
Message-ID: <C675BC40-51A8-484D-9DBF-3E5953C7FD07@kodewerk.com>

you can choose to break hard, break softly or not break at all. In this case irregardless of the spec. IME you want to be accommodating and not break unless you really are forced to.

Regards,
Kirk

On Jan 31, 2014, at 8:10 PM, Oleksandr Otenko <oleksandr.otenko at oracle.com> wrote:

> Looking at the difference between Random and ThreadLocalRandom in JDK7, it seems TLR isn't really "concurrent" - instead, we are relaxing the consistency guarantees in concurrent uses. The guarantee is there only in case of single-threaded access, and using ThreadLocal is one way to achieve that. It is not obvious that it is meant to be the only way to achieve single-threaded access.
> 
> Besides, I see no reason why someone wouldn't want more than one single-threaded-access-Random per thread (throughout the Thread's lifetime) - one per unit of work, perhaps? In that case I don't need to consume the cost of ThreadLocal access.
> 
> 
> Alex
> 
> 
> On 31/01/2014 18:09, Oleksandr Otenko wrote:
>> Is the point to make the source of randomness scalable, or is the point to make the source of randomness unique for each thread? 
>> 
>> It is not entirely clear from the documentation. 
>> 
>> I think these requirements imply different behaviours around the use of shared ThreadLocalRandom from other threads. So, in the first case I would make it clear that if the ThreadLocalRandom is not shared by the threads, the algorithm takes advantage of that to scale better. The second case makes sharing of the TLR a illegal state. 
>> 
>> As it is, the implementation that seeds 0 does not meet neither of those cases. 
>> 
>> 
>> Alex 
>> 
>> 
>> On 31/01/2014 17:47, Zhong Yu wrote: 
>>> If we make TLR behave "as expected" even if it's used incorrectly, 
>>> we'll just encourage incorrect usages. People will begin to use it as 
>>> a global random instead of a thread local one, and that will become a 
>>> de facto contract of TLR, making further changes difficult. 
>>> 
>>> If we add a check in nextX() 
>>>      if( currentThread.PROBE==0 ) 
>>>          throw new IllegalStateException() 
>>> it should not be too expensive, right? Or just an "assert PROBE!=0"? 
>>> 
>>> Zhong Yu 
>>> 
>>> 
>>> 
>>> On Fri, Jan 31, 2014 at 9:03 AM, Dr Heinz M. Kabutz 
>>> <heinz at javaspecialists.eu> wrote: 
>>>> Tim Halloran wrote: 
>>>> 
>>>> On Fri, Jan 31, 2014 at 9:16 AM, Aleksey Shipilev 
>>>> <aleksey.shipilev at oracle.com> wrote: 
>>>>> On 01/31/2014 05:36 PM, Doug Lea wrote: 
>>>>>> 1. The spec says that sharing a TLR across threads is an error 
>>>>>> (with unspecified consequences). 
>>>>> I think we should at least put a good warning sign in Javadocs then. It 
>>>>> now says [1]: "Usages of this class should typically be of the form: 
>>>>> ThreadLocalRandom.current().nextX(...)". 
>>>>> 
>>>>> This does not sound like the prohibitive "sharing a TLR across threads 
>>>>> is an error (with unspecified consequences", but merely like a soft 
>>>>> warning about the performance characteristics? 
>>>> 
>>>> I read the Javadoc and thought it was clear without sounding alarming to the 
>>>> programmer.  I speculate the word "typically" is used because it is 
>>>> perfectly fine to stash the reference returned from current() into a field 
>>>> or (more likely) a local variable so long as all references remain 
>>>> thread-confined to the thread current() was invoked within. 
>>>> 
>>>> Thanks, that's just proved my point - I think that storing it in a "field" 
>>>> is definitely incorrect and unless it is guaranteed that no other thread 
>>>> would ever see that object, Java 8 would lead to possibly surprising 
>>>> results. 
>>>> 
>>>> Being fail-fast might be helpful, but may not be possible. Is there any way, 
>>>> without destroying the performance characteristics of the implementation, an 
>>>> IllegalStateException (or perhaps something more precise) can be thrown? SWT 
>>>> does this when event thread calls are detected outside of the SWT thread -- 
>>>> sadly, Swing doesn't. 
>>>> 
>>>> Or we could just initialize the seed variables eagerly instead of lazily? 
>>>> That would make all this go away, plus would require one less check every 
>>>> time we call current(). 
>>>> 
>>>> _______________________________________________ 
>>>> Concurrency-interest mailing list 
>>>> Concurrency-interest at cs.oswego.edu 
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
>>>> 
>>> _______________________________________________ 
>>> Concurrency-interest mailing list 
>>> Concurrency-interest at cs.oswego.edu 
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
>> 
>> _______________________________________________ 
>> Concurrency-interest mailing list 
>> Concurrency-interest at cs.oswego.edu 
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/86704ab2/attachment.html>

From jeffhain at rocketmail.com  Fri Jan 31 17:36:25 2014
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Fri, 31 Jan 2014 22:36:25 +0000 (GMT)
Subject: [concurrency-interest] TLR Puzzle - UI threading
Message-ID: <1391207785.7809.YahooMailNeo@web172406.mail.ir2.yahoo.com>


Tim Halloran wrote:
>SWT does this [exception] when event thread calls are 
detected outside of
>the SWT thread -- sadly, Swing doesn't.

I'm doing a lightweight GUI framework on top of AWT, but
something much more simple than AWT and Swing (which were
slowing me down to a halt, not counting their glitches and hostility
to huge data models).
As a side effect of the simplicity, I found it was easy to parallelize
painting, so I'm glad Graphics2D class lets me paint stuffs from
different threads (I do check EDT at some places, but through an
interface, so that it can also work from JUnit thread).


As for the TLR puzzle, I agree with those that don't feel the need
to touch anything except maybe add more warning in the spec.
I even think that Java 8 behavior is preferable to Java 7 one,
since it makes the coding error deterministically visible
instead of hiding it behind some randomness.


-Jeff
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140131/8f042cdd/attachment.html>

From zhong.j.yu at gmail.com  Fri Jan 31 23:19:26 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 31 Jan 2014 22:19:26 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread timeout
Message-ID: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>

In this simple example, the JVM never exits:

    public static void main(String[] args)
    {
        ScheduledThreadPoolExecutor exec =
            new ScheduledThreadPoolExecutor(1);
        exec.schedule( ()-> System.out.println("done"),
            1, TimeUnit.SECONDS );
    }

because the core thread cannot timeout.

This creates a problem in a hot-reload environment, where each new app
instance creates a new scheduler thread that never terminates. Is
there a workaround to the effect that the thread can timeout? Thanks.

Zhong Yu

