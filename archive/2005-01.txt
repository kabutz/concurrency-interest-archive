From ozeigermann@apache.org  Fri Jan  7 12:47:19 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Fri, 7 Jan 2005 13:47:19 +0100
Subject: [concurrency-interest] Is there something like an ordered or counting barrier
In-Reply-To: <9da4f452041231043055c8bf8c@mail.gmail.com>
References: <9da4f4520412291506303a153f@mail.gmail.com>
 <NFBBKALFDCPFIDBNKAPCIECFFDAA.dholmes@dltech.com.au>
 <9da4f452041231043055c8bf8c@mail.gmail.com>
Message-ID: <9da4f4520501070447762ab5db@mail.gmail.com>

On Fri, 31 Dec 2004 13:30:12 +0100, Oliver Zeigermann
<oliver.zeigermann@gmail.com> wrote:
> Well, this - simple positioning - is what I was trying to achieve with
> the sequence barrier. I was using something like a CyclicBarrier or
> pure synchronized blocks, but this let the code get soooo complicated.
> 
> Anyway, thanks for your suggestions for the sequence barrier (the
> waitForTurn, signalNextTurn thing), I will incorporate it...

In case anyone is intereseted, I have created a turn barrier based on
David's suggestions - or at least based on my interpretations of them
;)

http://cvs.apache.org/viewcvs.cgi/jakarta-commons/transaction/src/java/org/apache/commons/transaction/util/TurnBarrier.java?view=markup

These tests make use of it:

http://cvs.apache.org/viewcvs.cgi/jakarta-commons/transaction/src/test/org/apache/commons/transaction/locking/GenericLockTest.java?view=markup

Thanks for the help and cheers,

Oliver

From matthias.ernst@coremedia.com  Fri Jan  7 13:06:49 2005
From: matthias.ernst@coremedia.com (Ernst, Matthias)
Date: Fri, 7 Jan 2005 14:06:49 +0100
Subject: AW: [concurrency-interest] Is there something like an ordered or counting barrier
Message-ID: <F34C8A704C489B46B9E9FBDBD1B91D5FC04333@MARS.coremedia.com>

I would be afraid of using numbers. Too easily renumbered and mixed up.
Have you thought about using enums and a set of enabled turns ? This way
you could neatly name threads.

barrier.waitFor(Turn.AsyncInvalidation);
try {
} finally {
  barrier.signalTurn(Turn.SecondAccess);
}

Dienstag
Matthias


From ozeigermann@apache.org  Fri Jan  7 13:15:16 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Fri, 7 Jan 2005 14:15:16 +0100
Subject: AW: [concurrency-interest] Is there something like an ordered or counting barrier
In-Reply-To: <F34C8A704C489B46B9E9FBDBD1B91D5FC04333@MARS.coremedia.com>
References: <F34C8A704C489B46B9E9FBDBD1B91D5FC04333@MARS.coremedia.com>
Message-ID: <9da4f4520501070515224a1b68@mail.gmail.com>

Hmmm, would be better, but required 1.5, right? For now using
constants might do as well...

Oliver

On Fri, 7 Jan 2005 14:06:49 +0100, Ernst, Matthias
<matthias.ernst@coremedia.com> wrote:
> I would be afraid of using numbers. Too easily renumbered and mixed up.
> Have you thought about using enums and a set of enabled turns ? This way
> you could neatly name threads.
> 
> barrier.waitFor(Turn.AsyncInvalidation);
> try {
> } finally {
>   barrier.signalTurn(Turn.SecondAccess);
> }
> 
> Dienstag
> Matthias
>

From matthias.ernst@coremedia.com  Fri Jan  7 13:27:28 2005
From: matthias.ernst@coremedia.com (Ernst, Matthias)
Date: Fri, 7 Jan 2005 14:27:28 +0100
Subject: AW: AW: [concurrency-interest] Is there something like an ordered or counting barrier
Message-ID: <F34C8A704C489B46B9E9FBDBD1B91D5FC04334@MARS.coremedia.com>

> Hmmm, would be better, but required 1.5, right? For now using 
> constants might do as well...

Indeed. I've started associating concurrency-interest with 5 / JSR 166. 

Matthias



From ozeigermann@apache.org  Fri Jan  7 23:52:11 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Sat, 8 Jan 2005 00:52:11 +0100
Subject: [concurrency-interest] General question about deadlock detection
Message-ID: <9da4f45205010715522c875bb6@mail.gmail.com>

Folks,

I have a problem with deadlock detection or better to say deadlock
prevention. I have an algorithm that checks if acquiring a certain
lock would cause a deadlock. The check is simple and the way you would
expect it. All threads trying to acquire a lock are added to a list of
waiters and are removed as soon as they have the lock.

Now, the problem is that a thread will have to be added to the list of
waiters before checking for a deadlock so that other threads can take
it into account for their own checks. If things work out bad and two
threads that would deadlock just with the current locking request both
may end up being rolled back as a deadlock victim while one of them
would be sufficient.

Is this understandable to anyone or just nonsense. If it makes sense,
how can one avoid this?

Cheers and thanks in advance,

Oliver

P.S.: Please tell me if you think posting general concurrency
questions to this list is a misuse. If so I will stop this ASAP.

From jean.morissette666@videotron.ca  Sat Jan  8 17:54:58 2005
From: jean.morissette666@videotron.ca (Jean Morissette)
Date: Sat, 08 Jan 2005 12:54:58 -0500
Subject: [concurrency-interest] LinkedBlockingDeque Performance
Message-ID: <41E01E72.7050700@videotron.ca>

Hi,
I would like to know if LinkedBlockingDeque have the same performance 
than LinkedBlockingQueue when used as a BlockingQueue?

Thanks
Jean

From dl@cs.oswego.edu  Sat Jan  8 18:01:58 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Sat, 8 Jan 2005 13:01:58 -0500
Subject: [concurrency-interest] LinkedBlockingDeque Performance
In-Reply-To: <41E01E72.7050700@videotron.ca>
References: <41E01E72.7050700@videotron.ca>
Message-ID: <16864.8214.541321.812039@altair.cs.oswego.edu>

> I would like to know if LinkedBlockingDeque have the same performance 
> than LinkedBlockingQueue when used as a BlockingQueue?

Single-threaded, they are about the same. But LinkedBlockingQueue is
more scalable because it allows concurrent puts and takes.
LinkedBlockingDeque can't do this.

-Doug



From dawidk@mathcs.emory.edu  Sat Jan  8 18:29:09 2005
From: dawidk@mathcs.emory.edu (Dawid Kurzyniec)
Date: Sat, 08 Jan 2005 13:29:09 -0500
Subject: [concurrency-interest] LinkedBlockingDeque Performance
In-Reply-To: <16864.8214.541321.812039@altair.cs.oswego.edu>
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu>
Message-ID: <41E02675.3040102@mathcs.emory.edu>

Doug Lea wrote:

>>I would like to know if LinkedBlockingDeque have the same performance 
>>than LinkedBlockingQueue when used as a BlockingQueue?
>>    
>>
>
>Single-threaded, they are about the same. But LinkedBlockingQueue is
>more scalable because it allows concurrent puts and takes.
>LinkedBlockingDeque can't do this.
>  
>
On a related issue: I am curious what is the performance of 
LinkedBlockingQueue vs ArrayBlockingQueue. Is there a non-negligible 
penalty due to memory allocation/deallocation and gc? If there is, what 
would you think about providing some hybrid solution, e.g. resizable 
implementation based on linked list of arrays, that would be unbounded, 
with support for concurrent puts/takes, but with performance close to 
ArrayBlockingQueue?

I once written a simple array-based queue implementation with dynamic 
resizing, but it does not support concurrent puts/takes (all methods 
synchronized). Which one (LinkedBlockingQueue vs 
DynamicArrayBlockingQueue) would you expect to perform better in a (1 
producer, 1 consumer) scenario?

Regards,
Dawid



From dl@cs.oswego.edu  Sat Jan  8 20:16:08 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Sat, 8 Jan 2005 15:16:08 -0500
Subject: [concurrency-interest] LinkedBlockingDeque Performance
In-Reply-To: <41E02675.3040102@mathcs.emory.edu>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu>
Message-ID: <16864.16264.942851.711643@altair.cs.oswego.edu>

> On a related issue: I am curious what is the performance of 
> LinkedBlockingQueue vs ArrayBlockingQueue. Is there a non-negligible 
> penalty due to memory allocation/deallocation and gc? 

There's no sure winner, which is why we supply both.

Usually, when you are putting something into a queue, you will have
just allocated that new something.  And similarly, when you take
something out you usually use it and then let it become garbage.  In
which case the extra allocation for a queue node is not going to make
much difference in overall GC, so you might as well go for the better
scalability of LinkedBlockingQueue. I think this is the most common
use case.

But, if you aren't allocating the things put into queues, and don't
expect lots of threads to be contending when the queue is neither
empty nor full, then ArrayBlockingQueue is likely to work better.

In programs where all consumer threads tend to usually be blocked
waiting for a queue to become non-empty, you probably won't see much
difference between these.  Except that on older JVMs without good
concurrent/parallel GC, you might expect worse performance of linked
queues.  But on newer JVMs, as a rule of thumb, it is cheaper to
allocate memory than to block a thread (due to a lock or whatever). If
you are going to block a lot anyway, you might save overall by not
allocating, but even here the differences will usually be small.


> If there is, what 
> would you think about providing some hybrid solution, e.g. resizable 
> implementation based on linked list of arrays, that would be unbounded, 
> with support for concurrent puts/takes, but with performance close to 
> ArrayBlockingQueue?

My sense is that the cases for which this would be the best option
are not common. I'm sure a few exist though.

BTW, there is a also resizable-array-based (not linked-array)
BlockingQueue in java.util.concurrent -- PriorityBlockingQueue. You
can even use it as a regular FIFO queue by using sequence numbers as
keys. Although the comparison overhead probably overwhelms any
advantages it might otherwise have in niche situations as a FIFO
queue.

-Doug


From dl@cs.oswego.edu  Tue Jan 11 01:09:18 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Mon, 10 Jan 2005 20:09:18 -0500
Subject: [concurrency-interest] General question about deadlock detection
In-Reply-To: <9da4f45205010715522c875bb6@mail.gmail.com>
References: <9da4f45205010715522c875bb6@mail.gmail.com>
Message-ID: <16867.10046.133501.205575@altair.cs.oswego.edu>

> I have a problem with deadlock detection or better to say deadlock
> prevention. I have an algorithm that checks if acquiring a certain
> lock would cause a deadlock. The check is simple and the way you would
> expect it. All threads trying to acquire a lock are added to a list of
> waiters and are removed as soon as they have the lock.
> 
> Now, the problem is that a thread will have to be added to the list of
> waiters before checking for a deadlock so that other threads can take
> it into account for their own checks. If things work out bad and two
> threads that would deadlock just with the current locking request both
> may end up being rolled back as a deadlock victim while one of them
> would be sufficient.

I don't know offhand, but you might check the literature on deadlock
detection algorithms.  One place to start is Klaus Havelund's work:
http://ase.arc.nasa.gov/havelund/

-Doug

From ozeigermann@apache.org  Tue Jan 11 10:24:43 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Tue, 11 Jan 2005 11:24:43 +0100
Subject: [concurrency-interest] General question about deadlock detection
In-Reply-To: <16867.10046.133501.205575@altair.cs.oswego.edu>
References: <9da4f45205010715522c875bb6@mail.gmail.com>
 <16867.10046.133501.205575@altair.cs.oswego.edu>
Message-ID: <9da4f452050111022454c1b694@mail.gmail.com>

On Mon, 10 Jan 2005 20:09:18 -0500, Doug Lea <dl@cs.oswego.edu> wrote:
> 
> > I have a problem with deadlock detection or better to say deadlock
> > prevention. I have an algorithm that checks if acquiring a certain
> > lock would cause a deadlock. The check is simple and the way you would
> > expect it. All threads trying to acquire a lock are added to a list of
> > waiters and are removed as soon as they have the lock.
> >
> > Now, the problem is that a thread will have to be added to the list of
> > waiters before checking for a deadlock so that other threads can take
> > it into account for their own checks. If things work out bad and two
> > threads that would deadlock just with the current locking request both
> > may end up being rolled back as a deadlock victim while one of them
> > would be sufficient.
> 
> I don't know offhand, but you might check the literature on deadlock
> detection algorithms.  One place to start is Klaus Havelund's work:
> http://ase.arc.nasa.gov/havelund/

Yes, my description isn't very good, but apart from showing the actual
code is the best I can do :(

Thanks for the pointer!

Oliver

From ozeigermann@apache.org  Wed Jan 12 00:08:54 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Wed, 12 Jan 2005 01:08:54 +0100
Subject: [concurrency-interest] General question about deadlock detection
In-Reply-To: <9da4f452050111022454c1b694@mail.gmail.com>
References: <9da4f45205010715522c875bb6@mail.gmail.com>
 <16867.10046.133501.205575@altair.cs.oswego.edu>
 <9da4f452050111022454c1b694@mail.gmail.com>
Message-ID: <9da4f452050111160825ddc04@mail.gmail.com>

Thanks again for the attention,

all I have found is about detecting and resolving a deadlock that
already exists. In this case it is easy to just choose just one of the
threads as the deadlock victim.

My problem is that I deny to grant a certain lock to a certain
transaction if it would cause a deadlock. In order not to effectively
cut concurrency to zero I do not synchronize the whole checked lock
request, but add the transaction as a waiter to the lock before it and
remove it afterwards. This, however, sometimes causes two threads to
be rolled back while one would be sufficient.

This isn't that bad, I was just wondering if anyone came across it...

Cheers,
Oliver


On Tue, 11 Jan 2005 11:24:43 +0100, Oliver Zeigermann
<oliver.zeigermann@gmail.com> wrote:
> On Mon, 10 Jan 2005 20:09:18 -0500, Doug Lea <dl@cs.oswego.edu> wrote:
> >
> > > I have a problem with deadlock detection or better to say deadlock
> > > prevention. I have an algorithm that checks if acquiring a certain
> > > lock would cause a deadlock. The check is simple and the way you would
> > > expect it. All threads trying to acquire a lock are added to a list of
> > > waiters and are removed as soon as they have the lock.
> > >
> > > Now, the problem is that a thread will have to be added to the list of
> > > waiters before checking for a deadlock so that other threads can take
> > > it into account for their own checks. If things work out bad and two
> > > threads that would deadlock just with the current locking request both
> > > may end up being rolled back as a deadlock victim while one of them
> > > would be sufficient.
> >
> > I don't know offhand, but you might check the literature on deadlock
> > detection algorithms.  One place to start is Klaus Havelund's work:
> > http://ase.arc.nasa.gov/havelund/
> 
> Yes, my description isn't very good, but apart from showing the actual
> code is the best I can do :(
> 
> Thanks for the pointer!
> 
> Oliver
>

From Victor.Luchangco@Sun.COM  Wed Jan 12 02:01:27 2005
From: Victor.Luchangco@Sun.COM (Victor Luchangco)
Date: Tue, 11 Jan 2005 18:01:27 -0800
Subject: [concurrency-interest] General question about deadlock detection
In-Reply-To: <9da4f452050111160825ddc04@mail.gmail.com>
References: <9da4f45205010715522c875bb6@mail.gmail.com>
 <16867.10046.133501.205575@altair.cs.oswego.edu>
 <9da4f452050111022454c1b694@mail.gmail.com>
 <9da4f452050111160825ddc04@mail.gmail.com>
Message-ID: <41E484F7.4000403@Sun.COM>

Oliver Zeigermann wrote:
> Thanks again for the attention,
> 
> all I have found is about detecting and resolving a deadlock that
> already exists. In this case it is easy to just choose just one of the
> threads as the deadlock victim.
> 
> My problem is that I deny to grant a certain lock to a certain
> transaction if it would cause a deadlock. In order not to effectively
> cut concurrency to zero I do not synchronize the whole checked lock
> request, but add the transaction as a waiter to the lock before it and
> remove it afterwards. This, however, sometimes causes two threads to
> be rolled back while one would be sufficient.
> 
> This isn't that bad, I was just wondering if anyone came across it...
> 
> Cheers,
> Oliver

Hi Oliver,

I'm not sure what exactly you are trying to achieve here.  There are
well-known techniques to ensure that you don't have any deadlocks,
the main one being that you order the locks, and always acquire only
locks that are "bigger" than the ones you have already acquired.
One problem with this approach is that you need to know what locks
you are going to acquire ahead of time, or at least that once you
acquire a lock, you have already acquired all the "smaller" locks
that you are going to need.  If you can back out, then you could
simply release all the locks bigger than the one you want to
acquire, and then reacquire them after you have gotten the smaller
lock.  (The locks need not be totally ordered, but all the locks
required by a single transaction must be ordered with respect to
each other.)  With this back-out strategy, I think (but you should
reason it out for yourself) that you can acquire locks out of order
until you run into a lock is already owned by some other transaction.
Then you need to release your bigger locks in case transaction you
are waiting for needs them.  If you can tell what locks that all
other transactions need, you only need to release those ones that
are involved in a potential deadlock.  (I don't know what "simple"
check you are doing to determine whether acquiring a lock would
cause a deadlock--it seems that this check potentially requires
global information because many transactions may be involved in a
deadlock cycle.)

I know that doesn't fully answer your question, but I hope it helps.

- Victor


From ozeigermann@apache.org  Wed Jan 12 12:12:40 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Wed, 12 Jan 2005 13:12:40 +0100
Subject: [concurrency-interest] General question about deadlock detection
In-Reply-To: <41E484F7.4000403@Sun.COM>
References: <9da4f45205010715522c875bb6@mail.gmail.com>
 <16867.10046.133501.205575@altair.cs.oswego.edu>
 <9da4f452050111022454c1b694@mail.gmail.com>
 <9da4f452050111160825ddc04@mail.gmail.com> <41E484F7.4000403@Sun.COM>
Message-ID: <9da4f452050112041214746d7c@mail.gmail.com>

Hi Victor,

thanks for taking the time for your detailed reply :) 

Details inline...

On Tue, 11 Jan 2005 18:01:27 -0800, Victor Luchangco
<Victor.Luchangco@sun.com> > I'm not sure what exactly you are trying
to achieve here.  There are
> well-known techniques to ensure that you don't have any deadlocks,
> the main one being that you order the locks, and always acquire only
> locks that are "bigger" than the ones you have already acquired.

I guess bigger applies to hierarchical data and thus locks, right? Or
are you talking about something like e.g. read < write?

> One problem with this approach is that you need to know what locks
> you are going to acquire ahead of time, or at least that once you
> acquire a lock, you have already acquired all the "smaller" locks
> that you are going to need.  If you can back out, then you could
> simply release all the locks bigger than the one you want to
> acquire, and then reacquire them after you have gotten the smaller
> lock.  (The locks need not be totally ordered, but all the locks
> required by a single transaction must be ordered with respect to
> each other.)  With this back-out strategy, I think (but you should
> reason it out for yourself) that you can acquire locks out of order
> until you run into a lock is already owned by some other transaction.
> Then you need to release your bigger locks in case transaction you
> are waiting for needs them.  If you can tell what locks that all
> other transactions need, you only need to release those ones that

I can not back out, except by rolling back the complete transaction.
Other than that your approach sounds very interesting! Do you have
pointers do papers or anything like that?

> are involved in a potential deadlock.  (I don't know what "simple"
> check you are doing to determine whether acquiring a lock would
> cause a deadlock--it seems that this check potentially requires
> global information because many transactions may be involved in a
> deadlock cycle.)

Yes, I have global information, construct a wait dependency graph
(transactions waiting for others) and see if there is a cycle in it. I
do this check upon every request to acquire a lock. As the algorithm
is simple, but it may be computationally expensive I first try to
apply for the lock and only if I can not get it in some short
configurable timeframe I do the check.

Oliver

From ozeigermann@apache.org  Thu Jan 13 23:29:07 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Fri, 14 Jan 2005 00:29:07 +0100
Subject: [concurrency-interest] CopyOnWriteArrayList alternative
Message-ID: <9da4f4520501131529fdcf4a8@mail.gmail.com>

Folks,

I am generally happy there is something like CopyOnWriteArrayList as
it allows me to avoid snapshots as described in Doug's book in
2.2.3.2.

However, there are situations where I would like a global read/write
lock version. Where e.g. #add would require a write lock and #get a
read lock. #iterator would acquire a read lock and keep it while it is
being iterated. Using a result set as in JDBC analogy this would
require something like a close on an iterator to indicate when the
read lock shall be released. However, there is nothing like this for
an iterator.

An alternative would be to release the read lock as soon as all
elements of the iterator have been traversed, i.e. where #hasNext
would return false. Would probably error prone, though. Consider an
exception thrown while traversing the iterator: how should a finally
block look like in this case. Difficult...

Thanks for any ideas or comments and cheers

Oliver

From dholmes@dltech.com.au  Fri Jan 14 00:27:28 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Fri, 14 Jan 2005 10:27:28 +1000
Subject: [concurrency-interest] CopyOnWriteArrayList alternative
In-Reply-To: <9da4f4520501131529fdcf4a8@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOELIFDAA.dholmes@dltech.com.au>

> Thanks for any ideas or comments and cheers

I think it would be simpler to expose the RW lock and manually
acquire/release the read lock when using the iterator. The iterator API
isn't really amenable to this sort of locking.

Cheers,
David Holmes


From Hanson Char <hanson.char@gmail.com>  Fri Jan 14 01:08:07 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 14 Jan 2005 12:08:07 +1100
Subject: [concurrency-interest] CopyOnWriteArrayList alternative
In-Reply-To: <9da4f4520501131529fdcf4a8@mail.gmail.com>
References: <9da4f4520501131529fdcf4a8@mail.gmail.com>
Message-ID: <ca53c8f805011317083ca0f071@mail.gmail.com>

How about using the ConcurrentLinkedQueue instead so one doesn't need
to worry about locking at all ?

Hanson


On Fri, 14 Jan 2005 00:29:07 +0100, Oliver Zeigermann
<oliver.zeigermann@gmail.com> wrote:
> Folks,
> 
> I am generally happy there is something like CopyOnWriteArrayList as
> it allows me to avoid snapshots as described in Doug's book in
> 2.2.3.2.
> 
> However, there are situations where I would like a global read/write
> lock version. Where e.g. #add would require a write lock and #get a
> read lock. #iterator would acquire a read lock and keep it while it is
> being iterated. Using a result set as in JDBC analogy this would
> require something like a close on an iterator to indicate when the
> read lock shall be released. However, there is nothing like this for
> an iterator.
> 
> An alternative would be to release the read lock as soon as all
> elements of the iterator have been traversed, i.e. where #hasNext
> would return false. Would probably error prone, though. Consider an
> exception thrown while traversing the iterator: how should a finally
> block look like in this case. Difficult...
> 
> Thanks for any ideas or comments and cheers
> 
> Oliver
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From gregg.wonderly@pobox.com  Fri Jan 14 18:58:59 2005
From: gregg.wonderly@pobox.com (Gregg Wonderly)
Date: Fri, 14 Jan 2005 12:58:59 -0600
Subject: [concurrency-interest] CopyOnWriteArrayList alternative
In-Reply-To: <9da4f4520501131529fdcf4a8@mail.gmail.com>
References: <9da4f4520501131529fdcf4a8@mail.gmail.com>
Message-ID: <41E81673.5090705@cytetech.com>

Oliver Zeigermann wrote:
> An alternative would be to release the read lock as soon as all
> elements of the iterator have been traversed, i.e. where #hasNext
> would return false. Would probably error prone, though. Consider an
> exception thrown while traversing the iterator: how should a finally
> block look like in this case. Difficult...
> 
> Thanks for any ideas or comments and cheers

I created a similar solution that I use in my JDBC factory/caching 
system.  Internally, it does manage all states and frees resources of 
ResultSet and Connection resources so that I don't have to do that as I 
reuse a Connection.  It also has a release() method that should be 
called when done.  Thus, the code structure:

	DatabaseManager mgr = SQLFactory.getManager( ...args... );
	try {
		ResultSet rs = mgr.executeQuery("select ...");
		while( rs.next() ) {
			...
		}
		mgr.executeUpdate("insert into...");
	} finally {
		mgr.release();
	}

The important thing is that DatabaseManager is actually a leased 
resource.  If you don't release it, the lease will expire and it will be 
released for you.  The lease time can be tuned to be somewhat effective.
But in the end, I use the lease expiration as notification of a bug.

But, also, the above code structure is simple and direct in 
demonstrating the correct way to use the class, and is an easy pattern 
to get right all of the time.

Gregg Wonderly

From puff@darksleep.com  Tue Jan 18 03:11:35 2005
From: puff@darksleep.com (Steven J. Owens)
Date: Mon, 17 Jan 2005 22:11:35 -0500
Subject: [concurrency-interest] BlockingQueue, ThreadExecutorPool and encapsulation
Message-ID: <20050118031135.GA1805@darksleep.com>

Hi,

     I'm using a ThreadExecutorPool with a LinkedBlockingQueue and I'm
finding myself in a situation where I have to break encapsulation,
getting at the LinkedBlockingQueue directly to check its state.  I'm a
little unclear as to how dangerous this is.  

     I'm more than a little unclear as to how the Executor is supposed
to use the Queue.  Is there any documentation on what's required to
implement your own Queue?  The Queue interface is clear enough, what's
not clear to me is the life cycle of the Queue in the Executor.  What
Queue methods does the Executor call, when?  Which methods can I
simply stub out and which are intrinsic the Executor's normal
operation?

     I'm using this arrangement currently to send several hundred HTTP
posts to an external system.  The posts take 30-60 seconds to complete
(they have to wait for a response before closing), there are several
hundred posts to send, and there's a limited time window they can go
out in.  I'm using multiple threads to send out several posts
concurrently.  I'm using a pool to limit resource usage.  So far, so
good, ThreadExecutorPool and LinkedBlocking Queue work like a charm.

     However, the time window moves, and new jobs become eligible.
I'm concerned that the recurring thread that selects eligible jobs
might overlap, so I either have to check to make sure the job isn't
already in the queue, or wait until the queued jobs are all sent
before doing the next select, or set a status flag on the job row in
the database when the job is put in the queue (and then have further
checks to handle what happens if the server is shut down or the JVM
crashes before the jobs are completed).

     When I first started working on this, my thought was that the
pool would poll the queue, and the queue would poll the database.
That doesn't really seem to fit with the way ThreadExecutorPool and
BlockingQueue are set up, so I ended up selecting all of the
"eligible" jobs and dumping them into a LinkedBlockingQueue

     My current solution is to keep the pool in a singleton with a
runJobs() method that checks a ReentrantLock and returns if it can't
get the lock.  If it can get the lock, it submits all of the jobs to
the pool, then waits until the queue is empty before letting go of the
lock.

public class SchedulerPool {

    // usual singleton constructor & instance variable
    // queue instance variable
    // threadexecutor instance variable

    private final Lock cronLock = new ReentrantLock() ;
    public void runJobs() {
        if (!this.cronLock.tryLock()) {
            return ;
        }
        try {
            runJobsWithLock() ;
            sleepUntilDone() ;
        } finally {
            this.cronLock.unlock() ;
        }
    }

    public void runJobsWithLock() {
        // select jobs from database
        // loop through jobs, calling pool.execute(job)
    }

    public void sleepUntilDone() {
        while (!(getQueue().isEmpty())) {
            try {
                Thread.sleep(1000) ;
            } catch (InterruptedException e) {
                System.out.println("InterruptedException while waiting for queue to clear, returning.") ;
                e.printStackTrace() ;
                return ;
            }
        }
    }


-- 
Steven J. Owens
puff@darksleep.com

"I'm going to make broad, sweeping generalizations and strong,
 declarative statements, because otherwise I'll be here all night and
 this document will be four times longer and much less fun to read.
 Take it all with a grain of salt." - http://darksleep.com/notablog


From ozeigermann@apache.org  Thu Jan 20 21:17:11 2005
From: ozeigermann@apache.org (Oliver Zeigermann)
Date: Thu, 20 Jan 2005 22:17:11 +0100
Subject: [concurrency-interest] Re: CopyOnWriteArrayList alternative
In-Reply-To: <9da4f4520501131529fdcf4a8@mail.gmail.com>
References: <9da4f4520501131529fdcf4a8@mail.gmail.com>
Message-ID: <9da4f45205012013174de73187@mail.gmail.com>

David, Hanson, Gregg,

thanks for your input! 

Thinking about it, blocking locks for lists really aren't the best
solution so I abandoned that idea.

Oliver

From Shailender.Bathula@airnz.co.nz  Thu Jan 20 23:31:08 2005
From: Shailender.Bathula@airnz.co.nz (Bathula, Shailender)
Date: Fri, 21 Jan 2005 12:31:08 +1300
Subject: [concurrency-interest] dl.util.concurrent v1.3.4, PooledExecutor, LinkedQueue, shutdownN
 ow and hangup
Message-ID: <C455FDCD31B75E4F88A8B37435A01C8E80360B@aklex017.corp.ad.airnz.co.nz>

This message is in MIME format. Since your mail reader does not understand
this format, some or all of this message may not be legible.

------_=_NextPart_000_01C4FF48.1E5504DB
Content-Type: text/plain

Hi,

I am using v1.3.4 of dl.util.concurrent library in a project and I am facing
a problem with PooledExecutor's shutdownNow method. It looks as if the
Worker threads do not receive the interrupt generated by shutdownNow ->
interruptAll and busy doing something else. I hope someone can guide me to
what I am doing wrong.

The scenario of how I use the PooledExecutor is: A request is received in a
servlet thread and to speed up the processing the tasks are submitted to the
PooledExecutor (using LinkedQueue, Callable and FutureResult). Then servlet
thread waits until all the tasks are completed using FutureResult's get
method. Then the results generated by the tasks are used to generate the
response in the servlet thread. To start off with I created the
PooledExecutor in every request and shut it down at the end of request (not
a good idea, I know. Intention was to make the executor static, thus pool
per web app). Because I was unable to execute the tasks in parallel yet, I
fixed the minimum and maximum pool size of the PooledExecutor to 1, that is
tasks are executed sequentially. This works for a few concurrent requests
and suddenly threads start to leak, that is worker threads do not get
terminated and the server shows high system CPU usage and user CPU usage
(keeps shifting). Since, there is no awaiting to make sure the worker
threads are terminated after shutdownNow, the next request comes, new pool
is created and things get worst, until the server goes down.

The IBM JVM and server OS details under which this happens are:

java version "1.4.2"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.4.2)
Classic VM (build 1.4.2, J2RE 1.4.2 IBM build cxia321420-20040626 (JIT
enabled: jitc))

Linux version 2.4.9-e.41 (bhcompile@porky.build.redhat.com) (gcc version
2.96 20000731 (Red Hat Linux 7.2 2.96-128.7.2))  1 Wed Jun 16 23:50:19 EDT
2004

I think, I have re-created above described real scenario in an isolated test
case. It is reproducible on the server/JVM combination and the error
condition occurs exactly at the same time in program, across multiple
executions. This test case's "main" creates given number of user threads,
each user thread runs a given number of tasks for given a number of runs
using supplied maxConcurrentTasks parameter. User thread corresponds to a
servlet thread, each run of a user thread corresponds to a servlet request
and maxConcurrentTasks corresponds to the min/max pool size of the executor.
"main" waits until all the user threads run to completion. Task sleeps for 5
seconds, since that is the average time a task would have taken in the
actual scenario. For testing purpose, I call PooledExecutor's
awaitTerminationAfterShutdown after shutdownNow. Here is the code of test
case:

import java.util.Date;

import EDU.oswego.cs.dl.util.concurrent.Callable;
import EDU.oswego.cs.dl.util.concurrent.DirectExecutor;
import EDU.oswego.cs.dl.util.concurrent.FutureResult;
import EDU.oswego.cs.dl.util.concurrent.LinkedQueue;
import EDU.oswego.cs.dl.util.concurrent.PooledExecutor;

public class TestPooledExecutor implements Runnable {
    private int userNumber;
    private int runCount;
    private int taskCount;
    private int maxConcurrentTasks;

    public TestPooledExecutor(int userNumber, int runCount, int taskCount,
int maxConcurrentTasks) {
	this.userNumber = userNumber;
	this.runCount = runCount;
	this.taskCount = taskCount;
	this.maxConcurrentTasks = maxConcurrentTasks;
    }

    public static class Task implements Runnable {
	private int taskNumber;
	private String runId;
	private boolean result;

	public Task(int n, String runId) {
	    this.taskNumber = n;
	    this.runId = runId;
	    this.result = false;
	}

	public void run() {
	    String taskId = null;
	    try {
		taskId = runId + " " + "Task: " + taskNumber + " in " +
Thread.currentThread().getName();
		System.out.println((new Date()) + " " + taskId);
		// simulate that each task takes around 5 seconds to
complete
		Thread.sleep(5 * 1000);
		result = true;
	    }
	    catch (Throwable t) {
		System.out.println((new Date()) + " " + "Error in " +
taskId);
		t.printStackTrace();
		result = false;
	    }
	}

	public boolean getResult() {
	    return result;
	}
    }

    public void run() {
	PooledExecutor pooledExecutor = null;

	try {
	    for ( int i = 0; i < runCount; i++ ) {
		String runId = "User: " + userNumber + " " + "Run: " + (i+1)
+ " in " + Thread.currentThread().getName();;
		System.out.println((new Date()) + " " + "Starting " +
runId);

		try {
		    pooledExecutor = new PooledExecutor(new LinkedQueue(),
maxConcurrentTasks);
	
pooledExecutor.setMinimumPoolSize(pooledExecutor.getMaximumPoolSize());

		    Task tasks[] = new Task[taskCount];
		    FutureResult taskFutures[] = new
FutureResult[taskCount];

		    for ( int n = 0; n < taskCount; n++ ) {
			final Task task = new Task(n+1, runId);
			tasks[n] = task;

			Callable taskCallable = new Callable() {
			    public Object call() {
				task.run();
				return null;
			    }
			};

			// Create a task future so that we can later wait
			// until each task is completed
			taskFutures[n] = new FutureResult();
			Runnable taskRunnable =
taskFutures[n].setter(taskCallable);

			// Submit the task to the executor
			pooledExecutor.execute(taskRunnable);
		    }

		    // Wait until all tasks are completed
		    for ( int n = 0; n < taskCount; n++ ) {
			taskFutures[n].get();
		    }

		    // Use the results computed by each task
		    // ...
		}
		finally {
		    if ( pooledExecutor != null ) {
			pooledExecutor.shutdownNow();
			try {
			    System.out.println((new Date()) + " " +
"Awaiting termination " + runId);
			    pooledExecutor.awaitTerminationAfterShutdown();
			    System.out.println((new Date()) + " " +
"Terminated " + runId);
			}
			catch (Throwable t) {
			    t.printStackTrace();
			}
		    }
		}
	    }
	}
	catch (Throwable t) {
	    t.printStackTrace();
	}
    }

    public static void main(String args[]) throws Exception {
	if ( args.length != 4 ) {
	    System.out.println("Usage: java TestPooledExecutor
<concurrentUsers> <runCount> <taskCount> <maxConcurrentTasks>");
	    System.exit(1);
	}

	int concurrentUsers        = Integer.parseInt(args[0]);
	int runCount               = Integer.parseInt(args[1]);
	int taskCount              = Integer.parseInt(args[2]);
	int maxConcurrentTasks     = Integer.parseInt(args[3]);

	Thread userThreads[] = new Thread[concurrentUsers];
	for ( int n = 0; n < concurrentUsers; n++ ) {
	    TestPooledExecutor tpe = new TestPooledExecutor((n+1), runCount,
taskCount, maxConcurrentTasks);
	    Thread t = new Thread(tpe);
	    userThreads[n] = t;

	    // simulate each user's run in a separate thread
	    t.start();
	}

	for ( int n = 0; n < concurrentUsers; n++ ) {
	    // wait until all user threads run the specified number of runs
	    userThreads[n].join();
	}
    }
}

Test case is run as: java -cp .:concurrent.jar -Xms256m -Xmx512m
TestPooledExecutor 12 50 30 1
That is 12 user threads, each running 30 tasks, using a single thread and
for 50 times.

System out log generated (prefixed with line number) for a run of test case
is:

      1 Fri Jan 21 10:40:22 NZDT 2005 Starting User: 1 Run: 1 in Thread-0
      2 Fri Jan 21 10:40:23 NZDT 2005 User: 1 Run: 1 in Thread-0 Task: 1 in
Thread-2
      3 Fri Jan 21 10:40:22 NZDT 2005 Starting User: 2 Run: 1 in Thread-1 
      4 Fri Jan 21 10:40:23 NZDT 2005 User: 2 Run: 1 in Thread-1 Task: 1 in
Thread-3
      5 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 3 Run: 1 in Thread-4 
      6 Fri Jan 21 10:40:23 NZDT 2005 User: 3 Run: 1 in Thread-4 Task: 1 in
Thread-5
      7 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 4 Run: 1 in Thread-6
      8 Fri Jan 21 10:40:23 NZDT 2005 User: 4 Run: 1 in Thread-6 Task: 1 in
Thread-7
      9 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 5 Run: 1 in Thread-8
     10 Fri Jan 21 10:40:23 NZDT 2005 User: 5 Run: 1 in Thread-8 Task: 1 in
Thread-9
     11 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 6 Run: 1 in Thread-10
     12 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 7 Run: 1 in Thread-12
     13 Fri Jan 21 10:40:23 NZDT 2005 User: 6 Run: 1 in Thread-10 Task: 1 in
Thread-11
     14 Fri Jan 21 10:40:23 NZDT 2005 User: 7 Run: 1 in Thread-12 Task: 1 in
Thread-13
     15 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 8 Run: 1 in Thread-14
     16 Fri Jan 21 10:40:23 NZDT 2005 User: 8 Run: 1 in Thread-14 Task: 1 in
Thread-15
     17 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 9 Run: 1 in Thread-16
     18 Fri Jan 21 10:40:23 NZDT 2005 User: 9 Run: 1 in Thread-16 Task: 1 in
Thread-17
     19 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 10 Run: 1 in Thread-18
     20 Fri Jan 21 10:40:23 NZDT 2005 User: 10 Run: 1 in Thread-18 Task: 1
in Thread-19
     21 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 11 Run: 1 in Thread-20
     22 Fri Jan 21 10:40:23 NZDT 2005 User: 11 Run: 1 in Thread-20 Task: 1
in Thread-21
     23 Fri Jan 21 10:40:23 NZDT 2005 Starting User: 12 Run: 1 in Thread-22 
     24 Fri Jan 21 10:40:23 NZDT 2005 User: 12 Run: 1 in Thread-22 Task: 1
in Thread-23
     25 Fri Jan 21 10:40:28 NZDT 2005 User: 1 Run: 1 in Thread-0 Task: 2 in
Thread-2
     26 Fri Jan 21 10:40:28 NZDT 2005 User: 2 Run: 1 in Thread-1 Task: 2 in
Thread-3
     27 Fri Jan 21 10:40:28 NZDT 2005 User: 3 Run: 1 in Thread-4 Task: 2 in
Thread-5
     28 Fri Jan 21 10:40:28 NZDT 2005 User: 4 Run: 1 in Thread-6 Task: 2 in
Thread-7
     29 Fri Jan 21 10:40:28 NZDT 2005 User: 5 Run: 1 in Thread-8 Task: 2 in
Thread-9
     30 Fri Jan 21 10:40:28 NZDT 2005 User: 6 Run: 1 in Thread-10 Task: 2 in
Thread-11
     31 Fri Jan 21 10:40:28 NZDT 2005 User: 7 Run: 1 in Thread-12 Task: 2 in
Thread-13
     32 Fri Jan 21 10:40:28 NZDT 2005 User: 8 Run: 1 in Thread-14 Task: 2 in
Thread-15
     33 Fri Jan 21 10:40:28 NZDT 2005 User: 9 Run: 1 in Thread-16 Task: 2 in
Thread-17
     34 Fri Jan 21 10:40:28 NZDT 2005 User: 10 Run: 1 in Thread-18 Task: 2
in Thread-19
     35 Fri Jan 21 10:40:28 NZDT 2005 User: 11 Run: 1 in Thread-20 Task: 2
in Thread-21
     36 Fri Jan 21 10:40:28 NZDT 2005 User: 12 Run: 1 in Thread-22 Task: 2
in Thread-23
     37 Fri Jan 21 10:40:33 NZDT 2005 User: 1 Run: 1 in Thread-0 Task: 3 in
Thread-2
     38 Fri Jan 21 10:40:33 NZDT 2005 User: 2 Run: 1 in Thread-1 Task: 3 in
Thread-3
     39 Fri Jan 21 10:40:33 NZDT 2005 User: 3 Run: 1 in Thread-4 Task: 3 in
Thread-5
     40 Fri Jan 21 10:40:33 NZDT 2005 User: 4 Run: 1 in Thread-6 Task: 3 in
Thread-7
     41 Fri Jan 21 10:40:33 NZDT 2005 User: 5 Run: 1 in Thread-8 Task: 3 in
Thread-9

[deleted]

    361 Fri Jan 21 10:42:48 NZDT 2005 User: 1 Run: 1 in Thread-0 Task: 30 in
Thread-2
    362 Fri Jan 21 10:42:48 NZDT 2005 User: 2 Run: 1 in Thread-1 Task: 30 in
Thread-3
    363 Fri Jan 21 10:42:48 NZDT 2005 User: 3 Run: 1 in Thread-4 Task: 30 in
Thread-5
    364 Fri Jan 21 10:42:48 NZDT 2005 User: 4 Run: 1 in Thread-6 Task: 30 in
Thread-7
    365 Fri Jan 21 10:42:48 NZDT 2005 User: 5 Run: 1 in Thread-8 Task: 30 in
Thread-9
    366 Fri Jan 21 10:42:48 NZDT 2005 User: 6 Run: 1 in Thread-10 Task: 30
in Thread-11
    367 Fri Jan 21 10:42:48 NZDT 2005 User: 7 Run: 1 in Thread-12 Task: 30
in Thread-13
    368 Fri Jan 21 10:42:48 NZDT 2005 User: 8 Run: 1 in Thread-14 Task: 30
in Thread-15
    369 Fri Jan 21 10:42:48 NZDT 2005 User: 9 Run: 1 in Thread-16 Task: 30
in Thread-17
    370 Fri Jan 21 10:42:48 NZDT 2005 User: 10 Run: 1 in Thread-18 Task: 30
in Thread-19
    371 Fri Jan 21 10:42:48 NZDT 2005 User: 12 Run: 1 in Thread-22 Task: 30
in Thread-23
    372 Fri Jan 21 10:42:48 NZDT 2005 User: 11 Run: 1 in Thread-20 Task: 30
in Thread-21
    373 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 1 Run: 1 in
Thread-0
    374 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 2 Run: 1 in
Thread-1
    375 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 1 Run: 1 in Thread-0
    376 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 1 Run: 2 in Thread-0
    377 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 2 Run: 1 in Thread-1
    378 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 2 Run: 2 in Thread-1
    379 Fri Jan 21 10:42:53 NZDT 2005 User: 1 Run: 2 in Thread-0 Task: 1 in
Thread-24
    380 Fri Jan 21 10:42:53 NZDT 2005 User: 2 Run: 2 in Thread-1 Task: 1 in
Thread-25
    381 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 3 Run: 1 in
Thread-4
    382 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 4 Run: 1 in
Thread-6
    383 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 3 Run: 1 in Thread-4 
    384 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 3 Run: 2 in Thread-4
    385 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 4 Run: 1 in Thread-6 
    386 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 4 Run: 2 in Thread-6
    387 Fri Jan 21 10:42:53 NZDT 2005 User: 3 Run: 2 in Thread-4 Task: 1 in
Thread-26
    388 Fri Jan 21 10:42:53 NZDT 2005 User: 4 Run: 2 in Thread-6 Task: 1 in
Thread-27
    389 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 5 Run: 1 in
Thread-8
    390 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 6 Run: 1 in
Thread-10
    391 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 7 Run: 1 in
Thread-12
    392 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 8 Run: 1 in
Thread-14
    393 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 9 Run: 1 in
Thread-16
    394 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 5 Run: 1 in Thread-8 
    395 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 5 Run: 2 in Thread-8
    396 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 6 Run: 1 in Thread-10
    397 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 6 Run: 2 in Thread-10
    398 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 7 Run: 1 in Thread-12
    399 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 7 Run: 2 in Thread-12
    400 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 8 Run: 1 in Thread-14
    401 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 8 Run: 2 in Thread-14
    402 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 9 Run: 1 in Thread-16

    403 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 9 Run: 2 in Thread-16
    404 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 10 Run: 1
in Thread-18
    405 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 10 Run: 1 in
Thread-18 
    406 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 10 Run: 2 in Thread-18
    407 Fri Jan 21 10:42:53 NZDT 2005 User: 5 Run: 2 in Thread-8 Task: 1 in
Thread-28
    408 Fri Jan 21 10:42:53 NZDT 2005 User: 6 Run: 2 in Thread-10 Task: 1 in
Thread-29
    409 Fri Jan 21 10:42:53 NZDT 2005 User: 7 Run: 2 in Thread-12 Task: 1 in
Thread-30
    410 Fri Jan 21 10:42:53 NZDT 2005 User: 8 Run: 2 in Thread-14 Task: 1 in
Thread-31
    411 Fri Jan 21 10:42:53 NZDT 2005 User: 9 Run: 2 in Thread-16 Task: 1 in
Thread-32
    412 Fri Jan 21 10:42:53 NZDT 2005 User: 10 Run: 2 in Thread-18 Task: 1
in Thread-33
    413 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 12 Run: 1
in Thread-22
    414 Fri Jan 21 10:42:53 NZDT 2005 Awaiting termination User: 11 Run: 1
in Thread-20
    415 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 12 Run: 1 in
Thread-22
    416 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 12 Run: 2 in Thread-22
    417 Fri Jan 21 10:42:53 NZDT 2005 Terminated User: 11 Run: 1 in
Thread-20
    418 Fri Jan 21 10:42:53 NZDT 2005 Starting User: 11 Run: 2 in Thread-20

[deleted]

   2341 Fri Jan 21 10:55:19 NZDT 2005 User: 1 Run: 6 in Thread-0 Task: 30 in
Thread-72
   2342 Fri Jan 21 10:55:19 NZDT 2005 User: 2 Run: 6 in Thread-1 Task: 30 in
Thread-73
   2343 Fri Jan 21 10:55:19 NZDT 2005 User: 4 Run: 6 in Thread-6 Task: 30 in
Thread-74
   2344 Fri Jan 21 10:55:19 NZDT 2005 User: 3 Run: 6 in Thread-4 Task: 30 in
Thread-75
   2345 Fri Jan 21 10:55:19 NZDT 2005 User: 5 Run: 6 in Thread-8 Task: 30 in
Thread-76
   2346 Fri Jan 21 10:55:19 NZDT 2005 User: 6 Run: 6 in Thread-10 Task: 30
in Thread-77
   2347 Fri Jan 21 10:55:19 NZDT 2005 User: 7 Run: 6 in Thread-12 Task: 30
in Thread-78
   2348 Fri Jan 21 10:55:19 NZDT 2005 User: 8 Run: 6 in Thread-14 Task: 30
in Thread-79
   2349 Fri Jan 21 10:55:19 NZDT 2005 User: 10 Run: 6 in Thread-18 Task: 30
in Thread-81
   2350 Fri Jan 21 10:55:19 NZDT 2005 User: 9 Run: 6 in Thread-16 Task: 30
in Thread-80
   2351 Fri Jan 21 10:55:19 NZDT 2005 User: 12 Run: 6 in Thread-22 Task: 30
in Thread-82
   2352 Fri Jan 21 10:55:19 NZDT 2005 User: 11 Run: 6 in Thread-20 Task: 30
in Thread-83
   2353 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 1 Run: 6 in
Thread-0
   2354 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 2 Run: 6 in
Thread-1
   2355 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 4 Run: 6 in
Thread-6
   2356 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 3 Run: 6 in
Thread-4
   2357 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 5 Run: 6 in
Thread-8
   2358 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 6 Run: 6 in
Thread-10
   2359 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 7 Run: 6 in
Thread-12
   2360 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 8 Run: 6 in
Thread-14
   2361 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 10 Run: 6
in Thread-18
   2362 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 9 Run: 6 in
Thread-16
   2363 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 12 Run: 6
in Thread-22
   2364 Fri Jan 21 10:55:24 NZDT 2005 Awaiting termination User: 11 Run: 6
in Thread-20

This is the end of the System out log, the worker threads created in Run 6
never get terminated. The system CPU usage and user CPU usage increases
(keeps shifting). It is almost as if the interrupt generated in shutdownNow
-> interruptAll method was never received by the Worker threads. If the test
case is run again, error condition occurs at the same time, that is after
Run 6 and awaiting termination of Worker threads. It is even reproducible
with a different number of user threads, for example if using 3 user
threads, the error condition occurs after the 22nd Run, again same across
multiple executions.

The stack trace of all the Worker threads as seen in Java dump of the
process when in error condition is similar to one of the following two (I
can supply complete Java dump if needed):

3XMTHREADINFO      "Thread-83" (TID:10069A78, sys_thread_t:82899D8,
state:MW, native ID:B201C) prio=5
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.LinkedQueue.poll(LinkedQueue.java(Compiled
Code))
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.PooledExecutor.getTask(PooledExecutor.java(
Compiled Code))
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(PooledExecutor.ja
va:747)
4XESTACKTRACE          at java.lang.Thread.run(Thread.java:567)
NULL
3HPREGISTERS           Register Values
NULL                   ---------------
3HPREGVALUES            EAX : 00000008, EBX : 08289CC8, ECX : 00000000
3HPREGVALUES            EDX : 082899D8, ESI : 08289D8C, EDI : 412E1D0C
3HPREGVALUES            EBP : 412E1D0C, ESP : 412E1C14, EIP : 4040A81F
3HPREGVALUES            EFLAGS : 00000202
NULL
3HPNATIVESTACK         Native Stack of "Thread-83" PID 27405
NULL                   -------------------------
3HPSTACKLINE            sysMonitorEnter at 4040A81F in libhpi.so


3XMTHREADINFO      "Thread-82" (TID:10069AD0, sys_thread_t:8280418, state:R,
native ID:B001F) prio=5
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.LinkedQueue.poll(LinkedQueue.java(Compiled
Code))
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.PooledExecutor.getTask(PooledExecutor.java(
Compiled Code))
4XESTACKTRACE          at
EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(PooledExecutor.ja
va:747)
4XESTACKTRACE          at java.lang.Thread.run(Thread.java:567)
NULL                   
3HPREGISTERS           Register Values
NULL                   ---------------
3HPREGVALUES            EAX : 00000101, EBX : 08280708, ECX : 00000000
3HPREGVALUES            EDX : 08280418, ESI : 082807CC, EDI : 413A7894
3HPREGVALUES            EBP : 413A789C, ESP : 413A7794, EIP : 404141B0
3HPREGVALUES            EFLAGS : 00000202
NULL                   
3HPNATIVESTACK         Native Stack of "Thread-82" PID 27404
NULL                   ------------------------- 
3HPSTACKLINE            _hpiThreadHardSuspend at 404141B0 in libhpi.so

If it helps, the same test case goes past the error condition when run on
the same Linux server using Sun's 1.4.2 JVM and using IBM's JVM on Windows.
I am constrained to using IBM's JVM though.

Can someone guide me to what may be wrong?

1. Is my usage of dl.util.concurrent library correct?

2. Since the error condition happens at the same time across multiple
executions, suggests that some kind of a limit on the user account I am
using. Can this be the case?

3. I have looked through the PooledExecutor$Worker.run,
PooledExecutor.getTask and LinkedQueue.poll. The interrupt generated in
shutdownNow -> interruptAll, should be detected in LinkedQueue.poll. Either
at the start of the method or when the LinkedQueue waits for default 60secs
(InterruptedException).

4. Something I noticed is that Java dump's collected during normal run of
the test case (prior to error condition) do not show any Native stack trace
of "_hpiThreadHardSuspend in libhpi.so". Don't know if that can be the
cause.

5. Creating the PooledExecutor only once per user thread and shutting down
at the end of all the runs removes the error. Suggesting, creating threads
frequently and interrupting/destroying them often does not go well with
Linux and IBM's JVM. Can this be right?

Thanks,
Shailender


____________________________________________________________________
CAUTION - This message may contain privileged and confidential 
information intended only for the use of the addressee named above.
If you are not the intended recipient of this message you are hereby 
notified that any use, dissemination, distribution or reproduction 
of this message is prohibited. If you have received this message in 
error please notify Air New Zealand immediately. Any views expressed 
in this message are those of the individual sender and may not 
necessarily reflect the views of Air New Zealand.
_____________________________________________________________________
For more information on the Air New Zealand Group, visit us online
at http://www.airnewzealand.com 
_____________________________________________________________________

------_=_NextPart_000_01C4FF48.1E5504DB
Content-Type: application/octet-stream;
	name="TestPooledExecutor.java"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: attachment;
	filename="TestPooledExecutor.java"

import java.util.Date;=0A=
=0A=
import EDU.oswego.cs.dl.util.concurrent.Callable;=0A=
import EDU.oswego.cs.dl.util.concurrent.DirectExecutor;=0A=
import EDU.oswego.cs.dl.util.concurrent.FutureResult;=0A=
import EDU.oswego.cs.dl.util.concurrent.LinkedQueue;=0A=
import EDU.oswego.cs.dl.util.concurrent.PooledExecutor;=0A=
=0A=
public class TestPooledExecutor implements Runnable {=0A=
    private int userNumber;=0A=
    private int runCount;=0A=
    private int taskCount;=0A=
    private int maxConcurrentTasks;=0A=
=0A=
    public TestPooledExecutor(int userNumber, int runCount, int =
taskCount, int maxConcurrentTasks) {=0A=
	this.userNumber =3D userNumber;=0A=
	this.runCount =3D runCount;=0A=
	this.taskCount =3D taskCount;=0A=
	this.maxConcurrentTasks =3D maxConcurrentTasks;=0A=
    }=0A=
=0A=
    public static class Task implements Runnable {=0A=
	private int taskNumber;=0A=
	private String runId;=0A=
	private boolean result;=0A=
=0A=
	public Task(int n, String runId) {=0A=
	    this.taskNumber =3D n;=0A=
	    this.runId =3D runId;=0A=
	    this.result =3D false;=0A=
	}=0A=
=0A=
	public void run() {=0A=
	    String taskId =3D null;=0A=
	    try {=0A=
		taskId =3D runId + " " + "Task: " + taskNumber + " in " + =
Thread.currentThread().getName();=0A=
		System.out.println((new Date()) + " " + taskId);=0A=
		// simulate that each task takes around 5 seconds to complete=0A=
		Thread.sleep(5 * 1000);=0A=
		result =3D true;=0A=
	    }=0A=
	    catch (Throwable t) {=0A=
		System.out.println((new Date()) + " " + "Error in " + taskId);=0A=
		t.printStackTrace();=0A=
		result =3D false;=0A=
	    }=0A=
	}=0A=
=0A=
	public boolean getResult() {=0A=
	    return result;=0A=
	}=0A=
    }=0A=
=0A=
    public void run() {=0A=
	PooledExecutor pooledExecutor =3D null;=0A=
=0A=
	try {=0A=
	    for ( int i =3D 0; i < runCount; i++ ) {=0A=
		String runId =3D "User: " + userNumber + " " + "Run: " + (i+1) + " in =
" + Thread.currentThread().getName();;=0A=
		System.out.println((new Date()) + " " + "Starting " + runId);=0A=
=0A=
		try {=0A=
		    pooledExecutor =3D new PooledExecutor(new LinkedQueue(), =
maxConcurrentTasks);=0A=
		    =
pooledExecutor.setMinimumPoolSize(pooledExecutor.getMaximumPoolSize());=0A=
=0A=
		    Task tasks[] =3D new Task[taskCount];=0A=
		    FutureResult taskFutures[] =3D new FutureResult[taskCount];=0A=
=0A=
		    for ( int n =3D 0; n < taskCount; n++ ) {=0A=
			final Task task =3D new Task(n+1, runId);=0A=
			tasks[n] =3D task;=0A=
=0A=
			Callable taskCallable =3D new Callable() {=0A=
			    public Object call() {=0A=
				task.run();=0A=
				return null;=0A=
			    }=0A=
			};=0A=
=0A=
			// Create a task future so that we can later wait=0A=
			// until each task is completed=0A=
			taskFutures[n] =3D new FutureResult();=0A=
			Runnable taskRunnable =3D taskFutures[n].setter(taskCallable);=0A=
=0A=
			// Submit the task to the executor=0A=
			pooledExecutor.execute(taskRunnable);=0A=
		    }=0A=
=0A=
		    // Wait until all tasks are completed=0A=
		    for ( int n =3D 0; n < taskCount; n++ ) {=0A=
			taskFutures[n].get();=0A=
		    }=0A=
=0A=
		    // Use the results computed by each task=0A=
		    // ...=0A=
		}=0A=
		finally {=0A=
		    if ( pooledExecutor !=3D null ) {=0A=
			pooledExecutor.shutdownNow();=0A=
			try {=0A=
			    System.out.println((new Date()) + " " + "Awaiting termination " =
+ runId);=0A=
			    pooledExecutor.awaitTerminationAfterShutdown();=0A=
			    System.out.println((new Date()) + " " + "Terminated " + =
runId);=0A=
			}=0A=
			catch (Throwable t) {=0A=
			    t.printStackTrace();=0A=
			}=0A=
		    }=0A=
		}=0A=
	    }=0A=
	}=0A=
	catch (Throwable t) {=0A=
	    t.printStackTrace();=0A=
	}=0A=
    }=0A=
=0A=
    public static void main(String args[]) throws Exception {=0A=
	if ( args.length !=3D 4 ) {=0A=
	    System.out.println("Usage: java TestPooledExecutor =
<concurrentUsers> <runCount> <taskCount> <maxConcurrentTasks>");=0A=
	    System.exit(1);=0A=
	}=0A=
=0A=
	int concurrentUsers        =3D Integer.parseInt(args[0]);=0A=
	int runCount               =3D Integer.parseInt(args[1]);=0A=
	int taskCount              =3D Integer.parseInt(args[2]);=0A=
	int maxConcurrentTasks     =3D Integer.parseInt(args[3]);=0A=
=0A=
	Thread userThreads[] =3D new Thread[concurrentUsers];=0A=
	for ( int n =3D 0; n < concurrentUsers; n++ ) {=0A=
	    TestPooledExecutor tpe =3D new TestPooledExecutor((n+1), runCount, =
taskCount, maxConcurrentTasks);=0A=
	    Thread t =3D new Thread(tpe);=0A=
	    userThreads[n] =3D t;=0A=
=0A=
	    // simulate each user's run in a separate thread=0A=
	    t.start();=0A=
	}=0A=
=0A=
	for ( int n =3D 0; n < concurrentUsers; n++ ) {=0A=
	    // wait until all user threads run the specified number of runs=0A=
	    userThreads[n].join();=0A=
	}=0A=
    }=0A=
}=0A=

------_=_NextPart_000_01C4FF48.1E5504DB--

From dl@cs.oswego.edu  Fri Jan 21 14:45:45 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Fri, 21 Jan 2005 09:45:45 -0500
Subject: [concurrency-interest] dl.util.concurrent v1.3.4, PooledExecutor, LinkedQueue, shutdownN
 ow and hangup
In-Reply-To: <C455FDCD31B75E4F88A8B37435A01C8E80360B@aklex017.corp.ad.airnz.co.nz>
References: <C455FDCD31B75E4F88A8B37435A01C8E80360B@aklex017.corp.ad.airnz.co.nz>
Message-ID: <16881.5529.478924.948298@altair.cs.oswego.edu>

I ran your test program a few times to completion without errors or
problems on a more recent linux kernel and using hotspot. My best
guess is that your very old (2.4.9) linux kernel is to blame
here. Everyone running Java on linux should be using either
NPTL-enhanced 2.4 kernels (e.g., from redhat 9+) or 2.6 kernels. There
were many, many Java threading problems on pre-NPTL kernels.

-Doug


From dawidk@mathcs.emory.edu  Fri Jan 21 22:34:40 2005
From: dawidk@mathcs.emory.edu (Dawid Kurzyniec)
Date: Fri, 21 Jan 2005 17:34:40 -0500
Subject: [concurrency-interest] Announcing: release 1.1 of backport-util-concurrent
Message-ID: <41F18380.5090601@mathcs.emory.edu>

Hello everybody,

New release of backport-util-concurrent, version 1.1, is now available 
for download:

http://www.mathcs.emory.edu/dcl/util/backport-util-concurrent/

This release contains an important bug fix (details follow), and 
includes new fixes and advancements in JSR 166 APIs up to Jan 14, 2005. 
Backported new features include: support for deques, enhancements in 
ThreadPoolExecutor, and Javadoc improvements. Please refer to the 
project Web page for details.

About the bug that was fixed in this release: on Windows platforms with 
Java 1.4.2, the library were sometimes behaving as if timeouts were 
ignored or misinterpreted, typically resulting in indefinite waits. This 
resulted from an internal timer overflow that occurred every several 
hours, and it was also manifested as a discontinuity in 
System.nanoTime() reporting. The problem would happen if such overflow 
occurred during blocked timed wait, if additionally a spurious wakeup 
occurred in the underlying Object.wait() after the overflow but before 
the original timeout.

This bug has been introduced in 1.0_01 and fixed in 1.1; users of 1.0_01 
are thus urged to upgrade.

Thanks to Ramesh Nethi for reporting this bug and greatly contributing 
to tracking it down.


Regards,
Dawid Kurzyniec


From jean.morissette666@videotron.ca  Mon Jan 24 20:04:53 2005
From: jean.morissette666@videotron.ca (Jean Morissette)
Date: Mon, 24 Jan 2005 15:04:53 -0500
Subject: [concurrency-interest] DynamicArrayBlockingQueue
In-Reply-To: <41E02675.3040102@mathcs.emory.edu>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu>
Message-ID: <41F554E5.20108@videotron.ca>

Dawid Kurzyniec wrote:
> I once written a simple array-based queue implementation with dynamic 
> resizing, but it does not support concurrent puts/takes (all methods 
> synchronized).

If you are interested, I have written a concurrent 
DynamicArrayBlockingQueue (that is, with dynamic resizing), JDK 1.4 
compliant:
http://cvs.sourceforge.net/viewcvs.py/seda/seda3/sandstorm/src/seda/sandstorm/core/DynamicArrayBlockingQueue.java?rev=1.14&view=log

This implementation has similar performance than backported 
ArrayBlockingQueue.  Interesting methods are setCapacity, 
ensureCapacity() and trimToSize().

Also, I would like to create a hybrid queue (linked array), so the 
resizing would be more fast (and we could probably increase the 
concurrency).

Best regards,
Jean


From jean.morissette666@videotron.ca  Mon Jan 24 22:31:05 2005
From: jean.morissette666@videotron.ca (Jean Morissette)
Date: Mon, 24 Jan 2005 17:31:05 -0500
Subject: [concurrency-interest] DynamicArrayBlockingQueue
In-Reply-To: <41F554E5.20108@videotron.ca>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
Message-ID: <41F57729.9040509@videotron.ca>

Jean Morissette wrote:
> If you are interested, I have written a concurrent 
> DynamicArrayBlockingQueue (that is, with dynamic resizing), JDK 1.4 
> compliant

The internal array length of this queue raises immediately as needed. 
But, I would like to lowers it slowly after long enough delay, to avoid 
trashing?  Is-it possible to achieve that?

Thanks,
Jean

From dawidk@mathcs.emory.edu  Tue Jan 25 00:39:41 2005
From: dawidk@mathcs.emory.edu (Dawid Kurzyniec)
Date: Mon, 24 Jan 2005 19:39:41 -0500
Subject: [concurrency-interest] DynamicArrayBlockingQueue
In-Reply-To: <41F554E5.20108@videotron.ca>
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
Message-ID: <41F5954D.4020609@mathcs.emory.edu>

Jean Morissette wrote:

> Dawid Kurzyniec wrote:
>
>> I once written a simple array-based queue implementation with dynamic 
>> resizing, but it does not support concurrent puts/takes (all methods 
>> synchronized).
>
>
> If you are interested, I have written a concurrent 
> DynamicArrayBlockingQueue (that is, with dynamic resizing), JDK 1.4 
> compliant:
> http://cvs.sourceforge.net/viewcvs.py/seda/seda3/sandstorm/src/seda/sandstorm/core/DynamicArrayBlockingQueue.java?rev=1.14&view=log 
>
>
Looks interesting, but I would be very, very careful about that - yet. 
Did you test it? First, it seems that in many places, you have waits and 
notifications on "this" instead of on "takeMonitor". Also, I can see 
some potential subtle issues. For one, I am not sure if pre-1.5 JVMs do 
guarantee consistency of array access if writers synchronize on 
different lock that readers. If not, that would mean that no 
single-array-based lock-free queue is implementable at all. I guess this 
is the question to the EG?... Another one is, it seems that that class 
may suffer from a deadlock. Suppose that the queue is empty, and a 
thread comes along with a "take" request, and starts waiting on 
takeMonitor. Then, suppose other thread invokes enqueue_many, with the 
input array that exceeds elements.length. The method then synchronizes 
on putMonitor, then, in ensureCapacity, it attempts to synchronize on 
takeMonitor, and it deadlocks. Interestingly, this is the exact same 
type of deadlock that you once reported against 
backport.java.util.concurrent.LinkedBlockingQueue put/drainTo :)

Regards,
Dawid


From Hanson Char <hanson.char@gmail.com>  Tue Jan 25 05:43:35 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Tue, 25 Jan 2005 16:43:35 +1100
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <41F5954D.4020609@mathcs.emory.edu>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
Message-ID: <ca53c8f80501242143239c353f@mail.gmail.com>

Imagine a system which has only 2 types of operations {foo, bar} on
different keys, and must obey the following rules:

1) Concurrent foo's are allowed on the same key;
2) Concurrent bar's are allowed on the same key;
3) If foo and bar are concurrent on the same key, then
    a) if foo happens before bar, bar must wait for all foo's in
progress to complete before proceeding;
    b) if bar happens before foo, foo must abort.

I have the following code to try to achieve/illustrate the above.  Is
there any simpler/better/faster way to do it ?  Any way to avoid the
synchronized block altogether ?  Or any utility classes I may use to
reduce the complexity ?

Thanks in advance,
Hanson

public enum FooBarType {
    FOO,
    BAR;
}

public class FooBar {
    ConcurrentMap<String, FooBarType[]> synMap = 
            new ConcurrentHashMap<String,FooBarType[]>();

    public void foo(String key) {
        FooBarType[] lock = {FooBarType.FOO};
        FooBarType[] otherLock = null;

        synchronized(lock) {
            otherLock = synMap.putIfAbsent(key, lock);

            if (otherLock == null) {
                // no concurrent foo nor bar on the same key, so doFoo.
                this.doFoo(key);
                synMap.remove(key); // release lock.
                return;
            }
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same time.
        switch(otherLock[0]) {
            case FOO:
                System.out.println("Concurrent foo on the same key: proceed.");
                this.doFoo(key);
                return;
            case BAR:
                System.out.println("Concurrent bar on the same key: abort.");
                return;
        }
        
    }
    public void bar(String key) {
        FooBarType[] lock = {FooBarType.BAR};
        FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);

        if (otherLock == null) {
            // No concurrent foo nor bar, so doBar.
            this.doBar(key);
            synMap.remove(key); // release lock
            return;
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same time.
        switch(otherLock[0]) {
            case FOO:
                do {
                    // Wait till all FOO's are finished.
                    synchronized(otherLock) {
                        otherLock = synMap.putIfAbsent(key,  lock);
                    }
                } while (otherLock != null && otherLock[0] == FooBarType.FOO);
                
                if (otherLock == null) {
                    // no concurrent FOO nor BAR.
                    this.doBar(key);
                    synMap.remove(key); // release lock
                    return;
                }
                // Must be a concurrent BAR.
                // drop thru.
            case BAR:
                // Concurrent BAR.
                this.doBar(key);
                return;
        }
    }
    private void doFoo(String key) {
        System.out.println("doFoo must be only invoked when there is
no concurrent doBar on the same key.");
    }
    private void doBar(String key) {
        System.out.println("doBar must be only invoked after all
concurrent Foo's are finished on the same key.");
    }
}

From jozart@blarg.net  Tue Jan 25 06:52:52 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Mon, 24 Jan 2005 22:52:52 -0800
Subject: [concurrency-interest] FooBar concurrency
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com>
Message-ID: <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>

Have you checked out the ReentrantReadWriteLock implementation and ruled it 
out?

If you can you use a ReadWriteLock for each key instead of a Foo token and a 
Bar token, then you can eliminate some code.

  foo ~= read
  bar ~= write

  public void foo(String key) {
      ReadWriteLock rwl = rwlMap.get(key);
      if (!rwl.readLock().tryLock()) return; // abort
      try {
          doFoo();
      } finally {
          rwl.readLock().unlock();
      }
  }

  public void bar(String key) {
      ReadWriteLock rwl = rwlMap.get(key);
      rwl.writeLock().lock();
      try {
          doFoo();
      } finally {
          rwl.writeLock().unlock();
      }
  }


Ideally, it seems you'd want an API like:

  rwl.readLock(key)
  rwl.writeLock(key)

that might allow you to pool the locks.



From dholmes@dltech.com.au  Tue Jan 25 07:15:12 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Tue, 25 Jan 2005 17:15:12 +1000
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEHGFEAA.dholmes@dltech.com.au>

Joe Bowbeer wrote:
> Have you checked out the ReentrantReadWriteLock implementation
> and ruled it out?
>
> If you can you use a ReadWriteLock for each key instead of a Foo
> token and a Bar token, then you can eliminate some code.
>
>   foo ~= read
>   bar ~= write

The requirements don't fit read/write semantics because concurrent writes
and concurrent reads are allowed - just not with each other.

You can use the basic idea of a ReadWriteLock to define a ReadReadLock -
poor name but semantically readers in the same read-set are allowed while
concurrent execution in different read-sets is forbidden. So when acquiring
readLockA it checks if readLockB is held and vice-versa. You can choose how
to respond to the other lock being held. The abort is easy. To wait-out the
other action you need a preference-based policy rather than the default
FIFO policy of ReentrantReadWriteLock.

David Holmes


From jozart@blarg.net  Tue Jan 25 12:31:20 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Tue, 25 Jan 2005 04:31:20 -0800
Subject: [concurrency-interest] FooBar concurrency (cont'd)
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com>
Message-ID: <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>

2nd try.

The two most significant problems I see in your code sketch are:

1. A foo may remove the foo lock while other foos are still active.  Same 
goes for bar.
2. The do-while in bar is an inefficient busy-wait.  It should wait for the 
last foo to notify it.

To solve these problems, I suggest maintaining a counter of active foos and 
active bars per key.  While a single counter per key could suffice, with, 
say, the negative range dedicated to foos and the positive range dedicated 
to bars, I think the code is easier to read if separate counters are used.

Note that no attempt is made to remove unused locks.  Perhaps someone else 
can add that part.

public class FooBar {

    private static final int FOO = 0;
    private static final int BAR = 1;

    private final ConcurrentMap<String, int[]> synMap =
            new ConcurrentHashMap<String,int[]>();

    public void foo(String key) {
        int[] counts = {1, 0}; // we are the foo
        int[] prev = synMap.putIfAbsent(key, counts);

        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                if (counts[BAR] > 0) return; // abort
                counts[FOO]++;
            }
        }
        try {
            doFoo(key);
        } finally {
            synchronized (counts) {
                if (--counts[FOO] == 0) {
                    counts.notifyAll();
                }
            }
        }
    }

    public void bar(String key) throws InterruptedException {
        int[] counts = {0, 1}; // we are the bar
        int[] prev = synMap.putIfAbsent(key, counts);

        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                while (counts[FOO] > 0) {
                    counts.wait();
                }
                counts[BAR]++;
            }
        }
        try {
            doBar(key);
        } finally {
            synchronized (counts) {
                --counts[BAR];
            }
        }
    }
}


----- Original Message ----- 
From: "Hanson Char" <hanson.char@gmail.com>
To: <concurrency-interest@altair.cs.oswego.edu>
Cc: "Tim Lavers" <t.lavers@pks.com.au>
Sent: Monday, January 24, 2005 9:43 PM
Subject: [concurrency-interest] FooBar concurrency


Imagine a system which has only 2 types of operations {foo, bar} on
different keys, and must obey the following rules:

1) Concurrent foo's are allowed on the same key;
2) Concurrent bar's are allowed on the same key;
3) If foo and bar are concurrent on the same key, then
    a) if foo happens before bar, bar must wait for all foo's in
progress to complete before proceeding;
    b) if bar happens before foo, foo must abort.

I have the following code to try to achieve/illustrate the above.  Is
there any simpler/better/faster way to do it ?  Any way to avoid the
synchronized block altogether ?  Or any utility classes I may use to
reduce the complexity ?

Thanks in advance,
Hanson

public enum FooBarType {
    FOO,
    BAR;
}

public class FooBar {
    ConcurrentMap<String, FooBarType[]> synMap =
            new ConcurrentHashMap<String,FooBarType[]>();

    public void foo(String key) {
        FooBarType[] lock = {FooBarType.FOO};
        FooBarType[] otherLock = null;

        synchronized(lock) {
            otherLock = synMap.putIfAbsent(key, lock);

            if (otherLock == null) {
                // no concurrent foo nor bar on the same key, so doFoo.
                this.doFoo(key);
                synMap.remove(key); // release lock.
                return;
            }
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same 
time.
        switch(otherLock[0]) {
            case FOO:
                System.out.println("Concurrent foo on the same key: 
proceed.");
                this.doFoo(key);
                return;
            case BAR:
                System.out.println("Concurrent bar on the same key: 
abort.");
                return;
        }

    }
    public void bar(String key) {
        FooBarType[] lock = {FooBarType.BAR};
        FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);

        if (otherLock == null) {
            // No concurrent foo nor bar, so doBar.
            this.doBar(key);
            synMap.remove(key); // release lock
            return;
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same 
time.
        switch(otherLock[0]) {
            case FOO:
                do {
                    // Wait till all FOO's are finished.
                    synchronized(otherLock) {
                        otherLock = synMap.putIfAbsent(key,  lock);
                    }
                } while (otherLock != null && otherLock[0] == 
FooBarType.FOO);

                if (otherLock == null) {
                    // no concurrent FOO nor BAR.
                    this.doBar(key);
                    synMap.remove(key); // release lock
                    return;
                }
                // Must be a concurrent BAR.
                // drop thru.
            case BAR:
                // Concurrent BAR.
                this.doBar(key);
                return;
        }
    }
    private void doFoo(String key) {
        System.out.println("doFoo must be only invoked when there is
no concurrent doBar on the same key.");
    }
    private void doBar(String key) {
        System.out.println("doBar must be only invoked after all
concurrent Foo's are finished on the same key.");
    }
}


From tim@peierls.net  Tue Jan 25 14:24:17 2005
From: tim@peierls.net (Tim Peierls)
Date: Tue, 25 Jan 2005 09:24:17 -0500
Subject: [concurrency-interest] FooBar concurrency (cont'd)
In-Reply-To: <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
Message-ID: <41F65691.9050804@peierls.net>

Doesn't this seem like a job for AQS?

public class FooBar {
     enum Type {
         FOO(1), BAR(-1);
         Type(int i) { this.i = i; }
         final int i;
     }

     private final ConcurrentMap<String, Sync> synMap =
             new ConcurrentHashMap<String, Sync>();


     public void foo(String key) {
         Sync sync = syncFor(key);
         if (sync.tryAcquireShared(FOO.i) > 0)
             try     { doFoo(key); }
             finally { sync.releaseShared(FOO.i); }
     }

     public void bar(String key) throws InterruptedException {
         Sync sync = syncFor(key);
         sync.acquireSharedInterruptibly(BAR.i);
         try     { doBar(key); }
         finally { sync.releaseShared(BAR.i); }
     }


     private Sync syncFor(String key) {
         Sync sync = synMap.get(key);
         if (sync == null) {
             sync = new Sync();
             Sync prev = synMap.putIfAbsent(key, sync);
             if (prev != null) sync = prev;
         }
         return sync;
     }

     private static class Sync extends AbstractQueuedSynchronizer {
         protected int tryAcquireShared(int arg) {
             while (true) {
                 int s = getState();
                 if (arg == FOO.i ? s < 0 : s > 0)
                     return -1;
                 if (compareAndSetState(s, s+arg))
                     return 1;
             }
         }

         protected boolean tryReleaseShared(int arg) {
             while (true) {
                 int s = getState();
                 if (compareAndSetState(s, s-arg)) return true;
             }
         }
     }

     //...
}

Not that I've done any real testing... :-(

--tim


Joe Bowbeer wrote:
 > To solve these problems, I suggest maintaining a counter of active foos and
 > active bars per key.  While a single counter per key could suffice, with,
 > say, the negative range dedicated to foos and the positive range dedicated
 > to bars, I think the code is easier to read if separate counters are used.
 >
 > Note that no attempt is made to remove unused locks.  Perhaps someone else
 > can add that part.



From gregg.wonderly@pobox.com  Tue Jan 25 15:24:55 2005
From: gregg.wonderly@pobox.com (Gregg Wonderly)
Date: Tue, 25 Jan 2005 09:24:55 -0600
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <ca53c8f80501242143239c353f@mail.gmail.com>
References: <41E01E72.7050700@videotron.ca>	 <16864.8214.541321.812039@altair.cs.oswego.edu>	 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>	 <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com>
Message-ID: <41F664C7.9000005@cytetech.com>

Hanson Char wrote:
> public enum FooBarType {
>     FOO,
>     BAR;
> }
> 
> public class FooBar {
>     ConcurrentMap<String, FooBarType[]> synMap = 
>             new ConcurrentHashMap<String,FooBarType[]>();
> 
>     public void foo(String key) {
>         FooBarType[] lock = {FooBarType.FOO};
>         FooBarType[] otherLock = null;
> 
>         synchronized(lock) {

I believe that lock will be a new object for each thread of execution 
through this code and not result in synchronizing on FOO based locks.

Gregg Wonderly

From jozart@blarg.net  Tue Jan 25 19:10:21 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Tue, 25 Jan 2005 11:10:21 -0800
Subject: [concurrency-interest] FooBar concurrency (cont'd)
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com> <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
Message-ID: <0bde01c50311$841c9440$0200a8c0@REPLICANT2>

Btw, it occurs to me that there might still be a race in my solution:

Foo says:

  if (counts[BAR] > 0) return; // abort

This looks like the kind of place where a notification could be lost.

If this foo, the aborting foo, were the one that was notified, then 
shouldn't it re-notify?

For example:

  if (counts[BAR] > 0) {
      counts.notify();
      return; // abort
  }

On second thought, however, I don't believe there is a problem with lost 
notification because (1) foos notifyAll rather than using single notify, 
and, more to the point, (2) bars are the only ones that wait.


Note that this approach, like your original, has very little machinery, but 
can be (very) inefficient if there is a lot of contention.



----- Original Message ----- 
From: "Joe Bowbeer" <jozart@blarg.net>
To: "Hanson Char" <hanson.char@gmail.com>; 
<concurrency-interest@altair.cs.oswego.edu>
Cc: "Tim Lavers" <t.lavers@pks.com.au>
Sent: Tuesday, January 25, 2005 4:31 AM
Subject: Re: [concurrency-interest] FooBar concurrency (cont'd)


2nd try.

The two most significant problems I see in your code sketch are:

1. A foo may remove the foo lock while other foos are still active.  Same
goes for bar.
2. The do-while in bar is an inefficient busy-wait.  It should wait for the
last foo to notify it.

To solve these problems, I suggest maintaining a counter of active foos and
active bars per key.  While a single counter per key could suffice, with,
say, the negative range dedicated to foos and the positive range dedicated
to bars, I think the code is easier to read if separate counters are used.

Note that no attempt is made to remove unused locks.  Perhaps someone else
can add that part.

public class FooBar {

    private static final int FOO = 0;
    private static final int BAR = 1;

    private final ConcurrentMap<String, int[]> synMap =
            new ConcurrentHashMap<String,int[]>();

    public void foo(String key) {
        int[] counts = {1, 0}; // we are the foo
        int[] prev = synMap.putIfAbsent(key, counts);

        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                if (counts[BAR] > 0) return; // abort
                counts[FOO]++;
            }
        }
        try {
            doFoo(key);
        } finally {
            synchronized (counts) {
                if (--counts[FOO] == 0) {
                    counts.notifyAll();
                }
            }
        }
    }

    public void bar(String key) throws InterruptedException {
        int[] counts = {0, 1}; // we are the bar
        int[] prev = synMap.putIfAbsent(key, counts);

        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                while (counts[FOO] > 0) {
                    counts.wait();
                }
                counts[BAR]++;
            }
        }
        try {
            doBar(key);
        } finally {
            synchronized (counts) {
                --counts[BAR];
            }
        }
    }
}


----- Original Message ----- 
From: "Hanson Char" <hanson.char@gmail.com>
To: <concurrency-interest@altair.cs.oswego.edu>
Cc: "Tim Lavers" <t.lavers@pks.com.au>
Sent: Monday, January 24, 2005 9:43 PM
Subject: [concurrency-interest] FooBar concurrency


Imagine a system which has only 2 types of operations {foo, bar} on
different keys, and must obey the following rules:

1) Concurrent foo's are allowed on the same key;
2) Concurrent bar's are allowed on the same key;
3) If foo and bar are concurrent on the same key, then
    a) if foo happens before bar, bar must wait for all foo's in
progress to complete before proceeding;
    b) if bar happens before foo, foo must abort.

I have the following code to try to achieve/illustrate the above.  Is
there any simpler/better/faster way to do it ?  Any way to avoid the
synchronized block altogether ?  Or any utility classes I may use to
reduce the complexity ?

Thanks in advance,
Hanson

public enum FooBarType {
    FOO,
    BAR;
}

public class FooBar {
    ConcurrentMap<String, FooBarType[]> synMap =
            new ConcurrentHashMap<String,FooBarType[]>();

    public void foo(String key) {
        FooBarType[] lock = {FooBarType.FOO};
        FooBarType[] otherLock = null;

        synchronized(lock) {
            otherLock = synMap.putIfAbsent(key, lock);

            if (otherLock == null) {
                // no concurrent foo nor bar on the same key, so doFoo.
                this.doFoo(key);
                synMap.remove(key); // release lock.
                return;
            }
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same
time.
        switch(otherLock[0]) {
            case FOO:
                System.out.println("Concurrent foo on the same key:
proceed.");
                this.doFoo(key);
                return;
            case BAR:
                System.out.println("Concurrent bar on the same key:
abort.");
                return;
        }

    }
    public void bar(String key) {
        FooBarType[] lock = {FooBarType.BAR};
        FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);

        if (otherLock == null) {
            // No concurrent foo nor bar, so doBar.
            this.doBar(key);
            synMap.remove(key); // release lock
            return;
        }
        // Race condition:
        // either a FOO or BAR is being done on the same key at the same
time.
        switch(otherLock[0]) {
            case FOO:
                do {
                    // Wait till all FOO's are finished.
                    synchronized(otherLock) {
                        otherLock = synMap.putIfAbsent(key,  lock);
                    }
                } while (otherLock != null && otherLock[0] ==
FooBarType.FOO);

                if (otherLock == null) {
                    // no concurrent FOO nor BAR.
                    this.doBar(key);
                    synMap.remove(key); // release lock
                    return;
                }
                // Must be a concurrent BAR.
                // drop thru.
            case BAR:
                // Concurrent BAR.
                this.doBar(key);
                return;
        }
    }
    private void doFoo(String key) {
        System.out.println("doFoo must be only invoked when there is
no concurrent doBar on the same key.");
    }
    private void doBar(String key) {
        System.out.println("doBar must be only invoked after all
concurrent Foo's are finished on the same key.");
    }
}

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



From jozart@blarg.net  Tue Jan 25 19:42:18 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Tue, 25 Jan 2005 11:42:18 -0800
Subject: [concurrency-interest] FooBar concurrency (cont'd)
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com> <0b7401c502d9$c6469380$0200a8c0@REPLICANT2> <41F65691.9050804@peierls.net>
Message-ID: <0bfa01c50315$faeb5350$0200a8c0@REPLICANT2>

Tim writes:

> Doesn't this seem like a job for AQS?

Now we're getting somewhere.

Looks promising.

This would be the approach that used more machinery, but required less 
handcoding, and was more efficient when the locks were contended.  (These 
characteristics are typical for most java.util.concurrent solutions.)


----- Original Message ----- 
From: "Tim Peierls" <tim@peierls.net>
To: "Joe Bowbeer" <jozart@blarg.net>
Cc: "Hanson Char" <hanson.char@gmail.com>; 
<concurrency-interest@altair.cs.oswego.edu>; "Tim Lavers" 
<t.lavers@pks.com.au>
Sent: Tuesday, January 25, 2005 6:24 AM
Subject: Re: [concurrency-interest] FooBar concurrency (cont'd)


Doesn't this seem like a job for AQS?

public class FooBar {
     enum Type {
         FOO(1), BAR(-1);
         Type(int i) { this.i = i; }
         final int i;
     }

     private final ConcurrentMap<String, Sync> synMap =
             new ConcurrentHashMap<String, Sync>();


     public void foo(String key) {
         Sync sync = syncFor(key);
         if (sync.tryAcquireShared(FOO.i) > 0)
             try     { doFoo(key); }
             finally { sync.releaseShared(FOO.i); }
     }

     public void bar(String key) throws InterruptedException {
         Sync sync = syncFor(key);
         sync.acquireSharedInterruptibly(BAR.i);
         try     { doBar(key); }
         finally { sync.releaseShared(BAR.i); }
     }


     private Sync syncFor(String key) {
         Sync sync = synMap.get(key);
         if (sync == null) {
             sync = new Sync();
             Sync prev = synMap.putIfAbsent(key, sync);
             if (prev != null) sync = prev;
         }
         return sync;
     }

     private static class Sync extends AbstractQueuedSynchronizer {
         protected int tryAcquireShared(int arg) {
             while (true) {
                 int s = getState();
                 if (arg == FOO.i ? s < 0 : s > 0)
                     return -1;
                 if (compareAndSetState(s, s+arg))
                     return 1;
             }
         }

         protected boolean tryReleaseShared(int arg) {
             while (true) {
                 int s = getState();
                 if (compareAndSetState(s, s-arg)) return true;
             }
         }
     }

     //...
}

Not that I've done any real testing... :-(

--tim


Joe Bowbeer wrote:
 > To solve these problems, I suggest maintaining a counter of active foos 
and
 > active bars per key.  While a single counter per key could suffice, with,
 > say, the negative range dedicated to foos and the positive range 
dedicated
 > to bars, I think the code is easier to read if separate counters are 
used.
 >
 > Note that no attempt is made to remove unused locks.  Perhaps someone 
else
 > can add that part.



From tim@peierls.net  Tue Jan 25 19:43:17 2005
From: tim@peierls.net (Tim Peierls)
Date: Tue, 25 Jan 2005 14:43:17 -0500
Subject: [concurrency-interest] Adrian Colyer blog entry on concurrency and AspectJ
Message-ID: <41F6A155.8070205@peierls.net>

Interesting post for those of use who follow AOP:

  http://www.aspectprogrammer.org/blogs/adrian/2005/01/making_concurre.html

--tim


From Hanson Char <hanson.char@gmail.com>  Wed Jan 26 11:11:39 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Wed, 26 Jan 2005 22:11:39 +1100
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <41F664C7.9000005@cytetech.com>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <41F664C7.9000005@cytetech.com>
Message-ID: <ca53c8f8050126031136716cd2@mail.gmail.com>

Hi Gregg,

The idea is to avoid synchronization whenever possible.  A lock object
appears only transiently for a specific key, and synchronization only
occurs should a "collision" occur between a thread executing foo and
another thread executing bar in that order for the same key
concurrently.

Consider the case when thread A enters the synchronized block in foo()
and successfully deposits a newly created lock into synMap for a
specific key.  Meanwhile, thread B invokes bar() with the same key,
resulting in the synMap.putIfAbsent() returning the very same lock
object just deposited by A.  That's when a synchronization is possible
between the 2 threads forcing B to wait for A to complete.

H

On Tue, 25 Jan 2005 09:24:55 -0600, Gregg Wonderly <gregg@cytetech.com> wrote:
> Hanson Char wrote:
> > public enum FooBarType {
> >     FOO,
> >     BAR;
> > }
> >
> > public class FooBar {
> >     ConcurrentMap<String, FooBarType[]> synMap =
> >             new ConcurrentHashMap<String,FooBarType[]>();
> >
> >     public void foo(String key) {
> >         FooBarType[] lock = {FooBarType.FOO};
> >         FooBarType[] otherLock = null;
> >
> >         synchronized(lock) {
> 
> I believe that lock will be a new object for each thread of execution
> through this code and not result in synchronizing on FOO based locks.
> 
> Gregg Wonderly
>

From moran_avigdor@hotmail.com  Wed Jan 26 10:04:22 2005
From: moran_avigdor@hotmail.com (moran avigdor)
Date: Wed, 26 Jan 2005 10:04:22 +0000
Subject: [concurrency-interest] ConcurrentHashMap isEmpty and size
Message-ID: <BAY20-F3732EC47DA6946A36C0E4C8F870@phx.gbl>

<html><div style='background-color:'><DIV class=RTE align=left><FONT size=2>
<P><FONT color=#000000>Concurrency-interest members,<BR></FONT><BR>While profiling the use of ConcurrentHashMap we have noticed a significant time spent on<BR>ConcurrentHashMap.isEmpty() and ConcurrentHashMap.size(). When browsing the code of these<BR>two methods, the twice-traversal over the segments and then resorting to lock seems to raise a question.</P>
<P>Why wasn't an AtomicInteger used as the size count? increased on insertion, decreased on removal of elements...<BR>Are there any problems with this approach?</P>
<P>Thank you,<BR>Moran Avigdor</P></FONT></DIV></div></html>


From jozart@blarg.net  Wed Jan 26 11:44:19 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Wed, 26 Jan 2005 03:44:19 -0800
Subject: [concurrency-interest] FooBar concurrency
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com> <41F664C7.9000005@cytetech.com> <ca53c8f8050126031136716cd2@mail.gmail.com>
Message-ID: <005701c5039c$5f87bd40$0200a8c0@REPLICANT2>

I agree that the "synchronized (lock)" in foo can prevent a conflicting bar.

Do you see, though, that this doesn't prevent a bar from conflicting with a 
subsequent, overlapping foo?

Say foo1 inserts its lock, then foo2 enters.  Then foo1 removes its lock, 
leaving foo2 unprotected.  Then bar1 enters and clobbers foo2.

(And the same can happen in reverse with foos clobbering bars.)


----- Original Message ----- 
From: "Hanson Char" <hanson.char@gmail.com>
To: <gregg.wonderly@pobox.com>
Cc: <concurrency-interest@altair.cs.oswego.edu>; "Tim Lavers" 
<t.lavers@pks.com.au>
Sent: Wednesday, January 26, 2005 3:11 AM
Subject: Re: [concurrency-interest] FooBar concurrency


Hi Gregg,

The idea is to avoid synchronization whenever possible.  A lock object
appears only transiently for a specific key, and synchronization only
occurs should a "collision" occur between a thread executing foo and
another thread executing bar in that order for the same key
concurrently.

Consider the case when thread A enters the synchronized block in foo()
and successfully deposits a newly created lock into synMap for a
specific key.  Meanwhile, thread B invokes bar() with the same key,
resulting in the synMap.putIfAbsent() returning the very same lock
object just deposited by A.  That's when a synchronization is possible
between the 2 threads forcing B to wait for A to complete.

H

On Tue, 25 Jan 2005 09:24:55 -0600, Gregg Wonderly <gregg@cytetech.com> 
wrote:
> Hanson Char wrote:
> > public enum FooBarType {
> >     FOO,
> >     BAR;
> > }
> >
> > public class FooBar {
> >     ConcurrentMap<String, FooBarType[]> synMap =
> >             new ConcurrentHashMap<String,FooBarType[]>();
> >
> >     public void foo(String key) {
> >         FooBarType[] lock = {FooBarType.FOO};
> >         FooBarType[] otherLock = null;
> >
> >         synchronized(lock) {
>
> I believe that lock will be a new object for each thread of execution
> through this code and not result in synchronizing on FOO based locks.
>
> Gregg Wonderly
>


From dl@cs.oswego.edu  Wed Jan 26 11:53:28 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Wed, 26 Jan 2005 06:53:28 -0500
Subject: [concurrency-interest] ConcurrentHashMap isEmpty and size
In-Reply-To: <BAY20-F3732EC47DA6946A36C0E4C8F870@phx.gbl>
References: <BAY20-F3732EC47DA6946A36C0E4C8F870@phx.gbl>
Message-ID: <16887.33976.816196.101422@altair.cs.oswego.edu>

> While profiling the use of ConcurrentHashMap we have noticed a
> significant time spent on ConcurrentHashMap.isEmpty() and
> ConcurrentHashMap.size(). 

Yes. In general, size() and isEmpty on any "Concurrent" data structure
(also including ConcurrentLinkedQueue, and ConcurrentSkipListMap) are
slower than in either non-thread-safe or fully synchronized data
structures because they have to traverse through nodes, segments, etc.

This tradeoff usually works out well because it is not at all common
to ask if a concurrent data structure is empty: it may become
non-empty (due to concurrent adds) immediately after saying it is
empty, or vice versa, so why bother asking? Usually, doing so
represents some kind of usage error or race bug.

Among the few good reasons to call isEmpty anyway is to check for the
need for some kind of cleanup after a ConcurrentHashMap is no longer
being used. But in this case, it is usually faster just to try to
iterate through the map doing this cleanup rather than checking
first. And among the few common legitimate reasons for calling size()
is resource monitoring, which in general should not be done often
enough to worry about the overhead. (Additionally, it is possible to
make simple subclasses that keep an "approximate count" field that
might not be accurate, but is good enough for monitoring. We
considered adding such a field/method, but decided that the lack of
any guarantees about what its value represents makes it a poor
candidate for inclusion in a general library class.)

> Why wasn't an AtomicInteger used as the size count?  increased on
> insertion, decreased on removal of elements... Are there any problems
> with this approach?

Among several related problems, suppose a thread adds a node to an
empty concurrent data structure but then stalls for a while (gets
swapped out) immediately before incrementing the count.

-Doug

From gregg.wonderly@pobox.com  Wed Jan 26 14:36:25 2005
From: gregg.wonderly@pobox.com (Gregg Wonderly)
Date: Wed, 26 Jan 2005 08:36:25 -0600
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <ca53c8f8050126031136716cd2@mail.gmail.com>
References: <41E01E72.7050700@videotron.ca>	 <16864.8214.541321.812039@altair.cs.oswego.edu>	 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>	 <41F5954D.4020609@mathcs.emory.edu>	 <ca53c8f80501242143239c353f@mail.gmail.com>	 <41F664C7.9000005@cytetech.com> <ca53c8f8050126031136716cd2@mail.gmail.com>
Message-ID: <41F7AAE9.1040506@cytetech.com>

Hanson Char wrote:
> The idea is to avoid synchronization whenever possible.  A lock object
> appears only transiently for a specific key, and synchronization only
> occurs should a "collision" occur between a thread executing foo and
> another thread executing bar in that order for the same key
> concurrently.

Yes, I understand this is what you want.  The problem is that in the 
code below, the 'lock' value would be unique for every thread and thus 
the synchronized() code would never do anything to lock out any other 
thread.  Thus, you will never create isolation between threads calling 
foo(String).

>>>    public void foo(String key) {
>>>        FooBarType[] lock = {FooBarType.FOO};
>>>        FooBarType[] otherLock = null;
>>>
>>>        synchronized(lock) {

Said more explicitly,

	FooBarType[] lock = {FooBarType.FOO};

is a more terse form of the statement

	FooBarType[] lock = new FooBarType[]{FooBarType.FOO};

And thus lock is always a unique object and synchronized() on
such an object will never be able to isolate one thread from another.

Try this in a test program:


import java.util.*;

public class FooTest {
	static int a;
	public static void main( String args[] ) {
		for( int i = 0; i < 15; ++i ) {
			new Thread( "counter: "+i ) {
				public void run() {
					while( true ) {
						foo();
					}
				}
			}.start();
		}
	}
	
	
	public static enum FooBarType {
		FOO,
      	BAR;
	}
	
	public static int aplusone() {
		return a + 1;
	}
	
	static HashMap<Integer,Thread> table = new HashMap<Integer,Thread>();
	
	public static void foo() {
		FooBarType[] lock = {FooBarType.FOO};
		int b;
		boolean err = false;
		synchronized(lock) {
			b = aplusone();
			if( table.get(b) != null ) {
				err = true;
			}
			table.put(b,Thread.currentThread());
			table.remove(b-5);
			a = b;
		}
		if( err )
			System.out.println(Thread.currentThread()+": "+b);
	}
}

Where the synchronized(lock) call is made, no isolation occurs, so there 
will be occasions where aplusone() will be called with the same value of 
'a' for multiple threads.  Those threads will then report the duplicity 
of the value after they query the 'table'.  You can move the assignment 
of 'a = b' closer to the 'b = aplusone()' call and you'll find that less 
or no errors occur.

Next, change synchronized(lock) to synchronized(table) and you'll see 
that complete isolation now occurs because 'table' is a constant valued 
reference that will cause all threads to be synchronized in that block.

Gregg Wonderly

From Paul.A.Martin@Sun.COM  Wed Jan 26 15:22:02 2005
From: Paul.A.Martin@Sun.COM (Paul Martin)
Date: Wed, 26 Jan 2005 10:22:02 -0500
Subject: [concurrency-interest] ConcurrentHashMap isEmpty and size
In-Reply-To: <BAY20-F3732EC47DA6946A36C0E4C8F870@phx.gbl>
References: <BAY20-F3732EC47DA6946A36C0E4C8F870@phx.gbl>
Message-ID: <41F7B59A.5000306@Sun.COM>

I have been working on a lock-free hash table based on the
Shanir/Shavit paper -- it is not as fast the multi-lock one
until the active concurrency exceeds the number of locks in
the multi-locker.  It used the AtomicInteger approach to
keeping the size count, but that became a bottle neck as
the concurrent cpu count rose (above about 16 cpus on tight
test loop).

So if the size is a rare issue, making it expensive but not
slowing every insert and delete may well be the best tradeoff.

Paul


From jozart@blarg.net  Wed Jan 26 16:36:52 2005
From: jozart@blarg.net (Joe Bowbeer)
Date: Wed, 26 Jan 2005 08:36:52 -0800
Subject: [concurrency-interest] FooBar concurrency
References: <41E01E72.7050700@videotron.ca>	 <16864.8214.541321.812039@altair.cs.oswego.edu>	 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>	 <41F5954D.4020609@mathcs.emory.edu>	 <ca53c8f80501242143239c353f@mail.gmail.com>	 <41F664C7.9000005@cytetech.com> <ca53c8f8050126031136716cd2@mail.gmail.com> <41F7AAE9.1040506@cytetech.com>
Message-ID: <00a201c503c5$3df898b0$0200a8c0@REPLICANT2>

Greg,

Note that the "lock" that foo created is the "otherLock" in bar, below

    public void bar(String key) {
        FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);
        // ...
        synchronized(otherLock) {
            otherLock = synMap.putIfAbsent(key,  lock);
        }


----- Original Message ----- 
From: "Gregg Wonderly" <gregg@cytetech.com>
To: "Hanson Char" <hanson.char@gmail.com>
Cc: <gregg.wonderly@pobox.com>; <concurrency-interest@altair.cs.oswego.edu>; 
"Tim Lavers" <t.lavers@pks.com.au>
Sent: Wednesday, January 26, 2005 6:36 AM
Subject: Re: [concurrency-interest] FooBar concurrency


Hanson Char wrote:
> The idea is to avoid synchronization whenever possible.  A lock object
> appears only transiently for a specific key, and synchronization only
> occurs should a "collision" occur between a thread executing foo and
> another thread executing bar in that order for the same key
> concurrently.

Yes, I understand this is what you want.  The problem is that in the
code below, the 'lock' value would be unique for every thread and thus
the synchronized() code would never do anything to lock out any other
thread.  Thus, you will never create isolation between threads calling
foo(String).



From gregg.wonderly@pobox.com  Wed Jan 26 17:04:09 2005
From: gregg.wonderly@pobox.com (Gregg Wonderly)
Date: Wed, 26 Jan 2005 11:04:09 -0600
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <00a201c503c5$3df898b0$0200a8c0@REPLICANT2>
References: <41E01E72.7050700@videotron.ca>	 <16864.8214.541321.812039@altair.cs.oswego.edu>	 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>	 <41F5954D.4020609@mathcs.emory.edu>	 <ca53c8f80501242143239c353f@mail.gmail.com>	 <41F664C7.9000005@cytetech.com> <ca53c8f8050126031136716cd2@mail.gmail.com> <41F7AAE9.1040506@cytetech.com> <00a201c503c5$3df898b0$0200a8c0@REPLICANT2>
Message-ID: <41F7CD89.5010306@cytetech.com>

Joe Bowbeer wrote:
> Greg,
> 
> Note that the "lock" that foo created is the "otherLock" in bar, below
> 
>     public void bar(String key) {
>         FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);
>         // ...
>         synchronized(otherLock) {
>             otherLock = synMap.putIfAbsent(key,  lock);
>         }

I am specifically referring to the original code where the 'lock' in 
foo(String) was a dynamic Object created using:

	FooBarType[] lock = {FooBarType.FOO};

This statement is the issue I am pointing out.

Gregg

From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 02:35:55 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Thu, 27 Jan 2005 13:35:55 +1100
Subject: [concurrency-interest] FooBar concurrency (cont'd)
In-Reply-To: <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
Message-ID: <ca53c8f805012618352c1fabd3@mail.gmail.com>

Hi Joe,

This is such a brilliant forum.

I like (or at least I can understand) your proposed solution, except
the clean-up of unused lock remains a problem which doesn't seem to
have an easy solution.  The AQS solution proposed by Tim looks like
black magic to me at this stage, and it has the same clean-up problem.

For my application, the clean up is critical.  So I am thinking maybe
I can take advantage of the GC.  Below is the proposed code.   I
wonder if there is any better way.

H

import java.lang.ref.ReferenceQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

public class FooBar {
    private static final int FOO = 0;
    private static final int BAR = 1;
    
    private final ConcurrentMap<String, FooBarLockRef<int[]>> synMap =
            new ConcurrentHashMap<String,FooBarLockRef<int[]>>();
    // Used to clean up unused locks which are garbage collected.
    private final FooBarLockRefCollector<int[]> collector = 
            new FooBarLockRefCollector<int[]>(new
ReferenceQueue<int[]>(), synMap);
    
    public void foo(String key) {
        int[] counts = {1, 0}; // we are the foo
        int[] prev = this.lock(key, counts);
        
        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                if (counts[BAR] > 0) return; // abort
                counts[FOO]++;
            }
        }
        try {
            doFoo(key);
        } finally {
            synchronized (counts) {
                if (--counts[FOO] == 0) {
                    counts.notifyAll();
                }
            }
        }
    }
    
    public void bar(String key) throws InterruptedException {
        int[] counts = {0, 1}; // we are the bar
        int[] prev = this.lock(key, counts);
        
        if (prev != null) {
            counts = prev;
            synchronized (counts) {
                while (counts[FOO] > 0) {
                    counts.wait();
                }
                counts[BAR]++;
            }
        }
        try {
            doBar(key);
        } finally {
            synchronized (counts) {
                --counts[BAR];
            }
        }
    }
    /** 
     * Return null if the given new lock is successfully put into synMap.
     * Else, return the lock deposited by another thread.
     */
    private int[] lock(final String key, final int[] newLock) 
    {
        this.collector.removeUnusedLocks();
        final FooBarLockRef<int[]> newLockRef = 
                new FooBarLockRef<int[]>(key, newLock);
        FooBarLockRef<int[]> prevRef = this.synMap.putIfAbsent(key, newLockRef);
        
        if (prevRef == null) {
            // succesfully deposited the new lock.
            return null;
        }
        int[] prev = prevRef.get();
        
        for (; prev == null; prev=prevRef.get()) {
            // Unused lock is garbage collected.  So clean it up.
            synMap.remove(key, prevRef);  // remove may fail, but that's fine.
            prevRef = this.synMap.putIfAbsent(key, newLockRef);

            if (prevRef == null) {
                // succesfully deposited the new lock.
                return null;
            }
            // data race: someone else has just put in a lock.
        }
        // Return the lock deposited by another thread.
        return prev;
    }
    private void doFoo(String key) {}
    private void doBar(String key) {}
}

// Wrap a lock with a WeakReference.
import java.lang.ref.WeakReference;

class FooBarLockRef<L> extends WeakReference<L> {
    final String key;

    FooBarLockRef(String key, L counts) {
        super(counts);
        this.key = key;
    }
}

// Used to clean up unused locks garbage collected.
import java.lang.ref.Reference;
import java.lang.ref.ReferenceQueue;
import java.util.concurrent.ConcurrentMap;

class FooBarLockRefCollector<L> {
    private final ReferenceQueue<L> q;
    private final ConcurrentMap<String, FooBarLockRef<L>> synMap;

    FooBarLockRefCollector(
            ReferenceQueue<L> q, ConcurrentMap<String, FooBarLockRef<L>> synMap)
    {
        this.q = q;
        this.synMap = synMap;
    }
    void removeUnusedLocks() {
        Reference<? extends L> r;
        
        while ((r = this.q.poll()) != null) {
            FooBarLockRef ref = (FooBarLockRef)r;
            // remove unused lock;  may fail but that's fine.
            synMap.remove(ref.key, ref);
            // referent should have been cleared by GC.
        }        
    }
}



On Tue, 25 Jan 2005 04:31:20 -0800, Joe Bowbeer <jozart@blarg.net> wrote:
> 2nd try.
> 
> The two most significant problems I see in your code sketch are:
> 
> 1. A foo may remove the foo lock while other foos are still active.  Same
> goes for bar.
> 2. The do-while in bar is an inefficient busy-wait.  It should wait for the
> last foo to notify it.
> 
> To solve these problems, I suggest maintaining a counter of active foos and
> active bars per key.  While a single counter per key could suffice, with,
> say, the negative range dedicated to foos and the positive range dedicated
> to bars, I think the code is easier to read if separate counters are used.
> 
> Note that no attempt is made to remove unused locks.  Perhaps someone else
> can add that part.
> 
> public class FooBar {
> 
>     private static final int FOO = 0;
>     private static final int BAR = 1;
> 
>     private final ConcurrentMap<String, int[]> synMap =
>             new ConcurrentHashMap<String,int[]>();
> 
>     public void foo(String key) {
>         int[] counts = {1, 0}; // we are the foo
>         int[] prev = synMap.putIfAbsent(key, counts);
> 
>         if (prev != null) {
>             counts = prev;
>             synchronized (counts) {
>                 if (counts[BAR] > 0) return; // abort
>                 counts[FOO]++;
>             }
>         }
>         try {
>             doFoo(key);
>         } finally {
>             synchronized (counts) {
>                 if (--counts[FOO] == 0) {
>                     counts.notifyAll();
>                 }
>             }
>         }
>     }
> 
>     public void bar(String key) throws InterruptedException {
>         int[] counts = {0, 1}; // we are the bar
>         int[] prev = synMap.putIfAbsent(key, counts);
> 
>         if (prev != null) {
>             counts = prev;
>             synchronized (counts) {
>                 while (counts[FOO] > 0) {
>                     counts.wait();
>                 }
>                 counts[BAR]++;
>             }
>         }
>         try {
>             doBar(key);
>         } finally {
>             synchronized (counts) {
>                 --counts[BAR];
>             }
>         }
>     }
> }
> 
> ----- Original Message -----
> From: "Hanson Char" <hanson.char@gmail.com>
> To: <concurrency-interest@altair.cs.oswego.edu>
> Cc: "Tim Lavers" <t.lavers@pks.com.au>
> Sent: Monday, January 24, 2005 9:43 PM
> Subject: [concurrency-interest] FooBar concurrency
> 
> Imagine a system which has only 2 types of operations {foo, bar} on
> different keys, and must obey the following rules:
> 
> 1) Concurrent foo's are allowed on the same key;
> 2) Concurrent bar's are allowed on the same key;
> 3) If foo and bar are concurrent on the same key, then
>     a) if foo happens before bar, bar must wait for all foo's in
> progress to complete before proceeding;
>     b) if bar happens before foo, foo must abort.
> 
> I have the following code to try to achieve/illustrate the above.  Is
> there any simpler/better/faster way to do it ?  Any way to avoid the
> synchronized block altogether ?  Or any utility classes I may use to
> reduce the complexity ?
> 
> Thanks in advance,
> Hanson
> 
> public enum FooBarType {
>     FOO,
>     BAR;
> }
> 
> public class FooBar {
>     ConcurrentMap<String, FooBarType[]> synMap =
>             new ConcurrentHashMap<String,FooBarType[]>();
> 
>     public void foo(String key) {
>         FooBarType[] lock = {FooBarType.FOO};
>         FooBarType[] otherLock = null;
> 
>         synchronized(lock) {
>             otherLock = synMap.putIfAbsent(key, lock);
> 
>             if (otherLock == null) {
>                 // no concurrent foo nor bar on the same key, so doFoo.
>                 this.doFoo(key);
>                 synMap.remove(key); // release lock.
>                 return;
>             }
>         }
>         // Race condition:
>         // either a FOO or BAR is being done on the same key at the same
> time.
>         switch(otherLock[0]) {
>             case FOO:
>                 System.out.println("Concurrent foo on the same key:
> proceed.");
>                 this.doFoo(key);
>                 return;
>             case BAR:
>                 System.out.println("Concurrent bar on the same key:
> abort.");
>                 return;
>         }
> 
>     }
>     public void bar(String key) {
>         FooBarType[] lock = {FooBarType.BAR};
>         FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);
> 
>         if (otherLock == null) {
>             // No concurrent foo nor bar, so doBar.
>             this.doBar(key);
>             synMap.remove(key); // release lock
>             return;
>         }
>         // Race condition:
>         // either a FOO or BAR is being done on the same key at the same
> time.
>         switch(otherLock[0]) {
>             case FOO:
>                 do {
>                     // Wait till all FOO's are finished.
>                     synchronized(otherLock) {
>                         otherLock = synMap.putIfAbsent(key,  lock);
>                     }
>                 } while (otherLock != null && otherLock[0] ==
> FooBarType.FOO);
> 
>                 if (otherLock == null) {
>                     // no concurrent FOO nor BAR.
>                     this.doBar(key);
>                     synMap.remove(key); // release lock
>                     return;
>                 }
>                 // Must be a concurrent BAR.
>                 // drop thru.
>             case BAR:
>                 // Concurrent BAR.
>                 this.doBar(key);
>                 return;
>         }
>     }
>     private void doFoo(String key) {
>         System.out.println("doFoo must be only invoked when there is
> no concurrent doBar on the same key.");
>     }
>     private void doBar(String key) {
>         System.out.println("doBar must be only invoked after all
> concurrent Foo's are finished on the same key.");
>     }
> }
> 
>

From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 04:20:33 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Thu, 27 Jan 2005 15:20:33 +1100
Subject: [concurrency-interest] FooBar concurrency
In-Reply-To: <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
Message-ID: <ca53c8f805012620201b6eb107@mail.gmail.com>

> Ideally, it seems you'd want an API like:
> 
>   rwl.readLock(key)
>   rwl.writeLock(key)

I suppose it would be something like the following code ?  To clean up
the unused locks, we may again make use of the GC and WeakReference.

H

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

public class KeyedReadWriteLock {
    private final ConcurrentMap<String, ReadWriteLock> rwlMap = 
            new ConcurrentHashMap<String, ReadWriteLock>();
    private final Class<? extends ReadWriteLock> rwlClass;
    
    public KeyedReadWriteLock() {
        this.rwlClass = ReentrantReadWriteLock.class;
    }
    public KeyedReadWriteLock(Class<? extends ReadWriteLock> rwlClass) {
        this.rwlClass = rwlClass;
    }
    public Lock readLock(String key) {
        return this.readWriteLock(key).readLock();
    }
    public Lock writeLock(String key) {
        return this.readWriteLock(key).writeLock();
    }
    private ReadWriteLock readWriteLock(String key) {
        ReadWriteLock newLock = null;
        try {
            newLock = rwlClass.newInstance();
        } catch(IllegalAccessException ex) {
            throw new RuntimeException(ex);
        } catch(InstantiationException ex) {
            throw new RuntimeException(ex);
        }
        ReadWriteLock oldLock = this.rwlMap.putIfAbsent(key, newLock);
        return oldLock == null ? newLock : oldLock;
    }
}

From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 05:26:35 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Thu, 27 Jan 2005 16:26:35 +1100
Subject: [concurrency-interest] FooBar concurrency (cont'd)
In-Reply-To: <ca53c8f805012618352c1fabd3@mail.gmail.com>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b7401c502d9$c6469380$0200a8c0@REPLICANT2>
 <ca53c8f805012618352c1fabd3@mail.gmail.com>
Message-ID: <ca53c8f80501262126143db64c@mail.gmail.com>

Just found a bug in not passing the necessary reference queue to the
weak reference constructor.  Here is the replacement.

H

import java.lang.ref.ReferenceQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

public class FooBar {
   private static final int FOO = 0;
   private static final int BAR = 1;
   
   private final ConcurrentMap<String, FooBarLockRef<int[]>> synMap =
           new ConcurrentHashMap<String,FooBarLockRef<int[]>>();
   // Used to clean up unused locks which are garbage collected.
    private final ReferenceQueue<int[]> refQ = new ReferenceQueue<int[]>();
    private final FooBarLockRefCollector<int[]> collector = 
            new FooBarLockRefCollector<int[]>(refQ, synMap);

   public void foo(String key) {
       int[] counts = {1, 0}; // we are the foo
       int[] prev = this.lock(key, counts);

       if (prev != null) {
           counts = prev;
           synchronized (counts) {
               if (counts[BAR] > 0) return; // abort
               counts[FOO]++;
           }
       }
       try {
           doFoo(key);
       } finally {
           synchronized (counts) {
               if (--counts[FOO] == 0) {
                   counts.notifyAll();
               }
           }
       }
   }

   public void bar(String key) throws InterruptedException {
       int[] counts = {0, 1}; // we are the bar
       int[] prev = this.lock(key, counts);

       if (prev != null) {
           counts = prev;
           synchronized (counts) {
               while (counts[FOO] > 0) {
                   counts.wait();
               }
               counts[BAR]++;
           }
       }
       try {
           doBar(key);
       } finally {
           synchronized (counts) {
               --counts[BAR];
           }
       }
   }
   /**
    * Return null if the given new lock is successfully put into synMap.
    * Else, return the lock deposited by another thread.
    */
   private int[] lock(final String key, final int[] newLock)
   {
       this.collector.removeUnusedLocks();
       final FooBarLockRef<int[]> newLockRef =
               new FooBarLockRef<int[]>(key, newLock, this.refQ);
       FooBarLockRef<int[]> prevRef = this.synMap.putIfAbsent(key, newLockRef);

       if (prevRef == null) {
           // succesfully deposited the new lock.
           return null;
       }
       int[] prev = prevRef.get();

       for (; prev == null; prev=prevRef.get()) {
           // Unused lock is garbage collected.  So clean it up.
           synMap.remove(key, prevRef);  // remove may fail, but that's fine.
           prevRef = this.synMap.putIfAbsent(key, newLockRef);

           if (prevRef == null) {
               // succesfully deposited the new lock.
               return null;
           }
           // data race: someone else has just put in a lock.
       }
       // Return the lock deposited by another thread.
       return prev;
   }
   private void doFoo(String key) {}
   private void doBar(String key) {}
}

// Wrap a lock with a WeakReference.
import java.lang.ref.ReferenceQueue;
import java.lang.ref.WeakReference;

class FooBarLockRef<L> extends WeakReference<L> {
    final String key;
    /** Creates a new instance of LockWeakRef */
    FooBarLockRef(String key, L counts, ReferenceQueue<? super L> q) {
        super(counts, q);
        this.key = key;
    }
}

// Used to clean up unused locks garbage collected.
import java.lang.ref.Reference;
import java.lang.ref.ReferenceQueue;
import java.util.concurrent.ConcurrentMap;

class FooBarLockRefCollector<L> {
   private final ReferenceQueue<L> q;
   private final ConcurrentMap<String, FooBarLockRef<L>> synMap;

   FooBarLockRefCollector(
           ReferenceQueue<L> q, ConcurrentMap<String, FooBarLockRef<L>> synMap)
   {
       this.q = q;
       this.synMap = synMap;
   }
   void removeUnusedLocks() {
       Reference<? extends L> r;

       while ((r = this.q.poll()) != null) {
           FooBarLockRef ref = (FooBarLockRef)r;
           // remove unused lock;  may fail but that's fine.
           synMap.remove(ref.key, ref);
           // referent should have been cleared by GC.
- Hide quoted text -
       }
   }
}



On Thu, 27 Jan 2005 13:35:55 +1100, Hanson Char <hanson.char@gmail.com> wrote:
> Hi Joe,
> 
> This is such a brilliant forum.
> 
> I like (or at least I can understand) your proposed solution, except
> the clean-up of unused lock remains a problem which doesn't seem to
> have an easy solution.  The AQS solution proposed by Tim looks like
> black magic to me at this stage, and it has the same clean-up problem.
> 
> For my application, the clean up is critical.  So I am thinking maybe
> I can take advantage of the GC.  Below is the proposed code.   I
> wonder if there is any better way.
> 
> H
> 
> import java.lang.ref.ReferenceQueue;
> import java.util.concurrent.ConcurrentHashMap;
> import java.util.concurrent.ConcurrentMap;
> 
> public class FooBar {
>     private static final int FOO = 0;
>     private static final int BAR = 1;
>     
>     private final ConcurrentMap<String, FooBarLockRef<int[]>> synMap =
>             new ConcurrentHashMap<String,FooBarLockRef<int[]>>();
>     // Used to clean up unused locks which are garbage collected.
>     private final FooBarLockRefCollector<int[]> collector =
>             new FooBarLockRefCollector<int[]>(new
> ReferenceQueue<int[]>(), synMap);
> 
>     public void foo(String key) {
>         int[] counts = {1, 0}; // we are the foo
>         int[] prev = this.lock(key, counts);
> 
>         if (prev != null) {
>             counts = prev;
>             synchronized (counts) {
>                 if (counts[BAR] > 0) return; // abort
>                 counts[FOO]++;
>             }
>         }
>         try {
>             doFoo(key);
>         } finally {
>             synchronized (counts) {
>                 if (--counts[FOO] == 0) {
>                     counts.notifyAll();
>                 }
>             }
>         }
>     }
> 
>     public void bar(String key) throws InterruptedException {
>         int[] counts = {0, 1}; // we are the bar
>         int[] prev = this.lock(key, counts);
> 
>         if (prev != null) {
>             counts = prev;
>             synchronized (counts) {
>                 while (counts[FOO] > 0) {
>                     counts.wait();
>                 }
>                 counts[BAR]++;
>             }
>         }
>         try {
>             doBar(key);
>         } finally {
>             synchronized (counts) {
>                 --counts[BAR];
>             }
>         }
>     }
>     /**
>      * Return null if the given new lock is successfully put into synMap.
>      * Else, return the lock deposited by another thread.
>      */
>     private int[] lock(final String key, final int[] newLock)
>     {
>         this.collector.removeUnusedLocks();
>         final FooBarLockRef<int[]> newLockRef =
>                 new FooBarLockRef<int[]>(key, newLock);
>         FooBarLockRef<int[]> prevRef = this.synMap.putIfAbsent(key, newLockRef);
> 
>         if (prevRef == null) {
>             // succesfully deposited the new lock.
>             return null;
>         }
>         int[] prev = prevRef.get();
> 
>         for (; prev == null; prev=prevRef.get()) {
>             // Unused lock is garbage collected.  So clean it up.
>             synMap.remove(key, prevRef);  // remove may fail, but that's fine.
>             prevRef = this.synMap.putIfAbsent(key, newLockRef);
> 
>             if (prevRef == null) {
>                 // succesfully deposited the new lock.
>                 return null;
>             }
>             // data race: someone else has just put in a lock.
>         }
>         // Return the lock deposited by another thread.
>         return prev;
>     }
>     private void doFoo(String key) {}
>     private void doBar(String key) {}
> }
> 
> // Wrap a lock with a WeakReference.
> import java.lang.ref.WeakReference;
> 
> class FooBarLockRef<L> extends WeakReference<L> {
>     final String key;
> 
>     FooBarLockRef(String key, L counts) {
>         super(counts);
>         this.key = key;
>     }
> }
> 
> // Used to clean up unused locks garbage collected.
> import java.lang.ref.Reference;
> import java.lang.ref.ReferenceQueue;
> import java.util.concurrent.ConcurrentMap;
> 
> class FooBarLockRefCollector<L> {
>     private final ReferenceQueue<L> q;
>     private final ConcurrentMap<String, FooBarLockRef<L>> synMap;
> 
>     FooBarLockRefCollector(
>             ReferenceQueue<L> q, ConcurrentMap<String, FooBarLockRef<L>> synMap)
>     {
>         this.q = q;
>         this.synMap = synMap;
>     }
>     void removeUnusedLocks() {
>         Reference<? extends L> r;
> 
>         while ((r = this.q.poll()) != null) {
>             FooBarLockRef ref = (FooBarLockRef)r;
>             // remove unused lock;  may fail but that's fine.
>             synMap.remove(ref.key, ref);
>             // referent should have been cleared by GC.
>         }
>     }
> }
> 
> On Tue, 25 Jan 2005 04:31:20 -0800, Joe Bowbeer <jozart@blarg.net> wrote:
> > 2nd try.
> >
> > The two most significant problems I see in your code sketch are:
> >
> > 1. A foo may remove the foo lock while other foos are still active.  Same
> > goes for bar.
> > 2. The do-while in bar is an inefficient busy-wait.  It should wait for the
> > last foo to notify it.
> >
> > To solve these problems, I suggest maintaining a counter of active foos and
> > active bars per key.  While a single counter per key could suffice, with,
> > say, the negative range dedicated to foos and the positive range dedicated
> > to bars, I think the code is easier to read if separate counters are used.
> >
> > Note that no attempt is made to remove unused locks.  Perhaps someone else
> > can add that part.
> >
> > public class FooBar {
> >
> >     private static final int FOO = 0;
> >     private static final int BAR = 1;
> >
> >     private final ConcurrentMap<String, int[]> synMap =
> >             new ConcurrentHashMap<String,int[]>();
> >
> >     public void foo(String key) {
> >         int[] counts = {1, 0}; // we are the foo
> >         int[] prev = synMap.putIfAbsent(key, counts);
> >
> >         if (prev != null) {
> >             counts = prev;
> >             synchronized (counts) {
> >                 if (counts[BAR] > 0) return; // abort
> >                 counts[FOO]++;
> >             }
> >         }
> >         try {
> >             doFoo(key);
> >         } finally {
> >             synchronized (counts) {
> >                 if (--counts[FOO] == 0) {
> >                     counts.notifyAll();
> >                 }
> >             }
> >         }
> >     }
> >
> >     public void bar(String key) throws InterruptedException {
> >         int[] counts = {0, 1}; // we are the bar
> >         int[] prev = synMap.putIfAbsent(key, counts);
> >
> >         if (prev != null) {
> >             counts = prev;
> >             synchronized (counts) {
> >                 while (counts[FOO] > 0) {
> >                     counts.wait();
> >                 }
> >                 counts[BAR]++;
> >             }
> >         }
> >         try {
> >             doBar(key);
> >         } finally {
> >             synchronized (counts) {
> >                 --counts[BAR];
> >             }
> >         }
> >     }
> > }
> >
> > ----- Original Message -----
> > From: "Hanson Char" <hanson.char@gmail.com>
> > To: <concurrency-interest@altair.cs.oswego.edu>
> > Cc: "Tim Lavers" <t.lavers@pks.com.au>
> > Sent: Monday, January 24, 2005 9:43 PM
> > Subject: [concurrency-interest] FooBar concurrency
> >
> > Imagine a system which has only 2 types of operations {foo, bar} on
> > different keys, and must obey the following rules:
> >
> > 1) Concurrent foo's are allowed on the same key;
> > 2) Concurrent bar's are allowed on the same key;
> > 3) If foo and bar are concurrent on the same key, then
> >     a) if foo happens before bar, bar must wait for all foo's in
> > progress to complete before proceeding;
> >     b) if bar happens before foo, foo must abort.
> >
> > I have the following code to try to achieve/illustrate the above.  Is
> > there any simpler/better/faster way to do it ?  Any way to avoid the
> > synchronized block altogether ?  Or any utility classes I may use to
> > reduce the complexity ?
> >
> > Thanks in advance,
> > Hanson
> >
> > public enum FooBarType {
> >     FOO,
> >     BAR;
> > }
> >
> > public class FooBar {
> >     ConcurrentMap<String, FooBarType[]> synMap =
> >             new ConcurrentHashMap<String,FooBarType[]>();
> >
> >     public void foo(String key) {
> >         FooBarType[] lock = {FooBarType.FOO};
> >         FooBarType[] otherLock = null;
> >
> >         synchronized(lock) {
> >             otherLock = synMap.putIfAbsent(key, lock);
> >
> >             if (otherLock == null) {
> >                 // no concurrent foo nor bar on the same key, so doFoo.
> >                 this.doFoo(key);
> >                 synMap.remove(key); // release lock.
> >                 return;
> >             }
> >         }
> >         // Race condition:
> >         // either a FOO or BAR is being done on the same key at the same
> > time.
> >         switch(otherLock[0]) {
> >             case FOO:
> >                 System.out.println("Concurrent foo on the same key:
> > proceed.");
> >                 this.doFoo(key);
> >                 return;
> >             case BAR:
> >                 System.out.println("Concurrent bar on the same key:
> > abort.");
> >                 return;
> >         }
> >
> >     }
> >     public void bar(String key) {
> >         FooBarType[] lock = {FooBarType.BAR};
> >         FooBarType[] otherLock = synMap.putIfAbsent(key,  lock);
> >
> >         if (otherLock == null) {
> >             // No concurrent foo nor bar, so doBar.
> >             this.doBar(key);
> >             synMap.remove(key); // release lock
> >             return;
> >         }
> >         // Race condition:
> >         // either a FOO or BAR is being done on the same key at the same
> > time.
> >         switch(otherLock[0]) {
> >             case FOO:
> >                 do {
> >                     // Wait till all FOO's are finished.
> >                     synchronized(otherLock) {
> >                         otherLock = synMap.putIfAbsent(key,  lock);
> >                     }
> >                 } while (otherLock != null && otherLock[0] ==
> > FooBarType.FOO);
> >
> >                 if (otherLock == null) {
> >                     // no concurrent FOO nor BAR.
> >                     this.doBar(key);
> >                     synMap.remove(key); // release lock
> >                     return;
> >                 }
> >                 // Must be a concurrent BAR.
> >                 // drop thru.
> >             case BAR:
> >                 // Concurrent BAR.
> >                 this.doBar(key);
> >                 return;
> >         }
> >     }
> >     private void doFoo(String key) {
> >         System.out.println("doFoo must be only invoked when there is
> > no concurrent doBar on the same key.");
> >     }
> >     private void doBar(String key) {
> >         System.out.println("doBar must be only invoked after all
> > concurrent Foo's are finished on the same key.");
> >     }
> > }
> >
> >
>

From tim@peierls.net  Thu Jan 27 05:44:06 2005
From: tim@peierls.net (Tim Peierls)
Date: Thu, 27 Jan 2005 00:44:06 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f805012620201b6eb107@mail.gmail.com>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
 <ca53c8f805012620201b6eb107@mail.gmail.com>
Message-ID: <41F87FA6.1010204@peierls.net>

Hanson Char wrote:
>>Ideally, it seems you'd want an API like:
>>
>>  rwl.readLock(key)
>>  rwl.writeLock(key)
> 
> I suppose it would be something like the following code ?  
...
> The AQS solution proposed by Tim looks like
> black magic to me at this stage


That is a shame, because AbstractQueuedSynchronizer is truly
a wonderful thing. Most of the j.u.c synchronizer classes are
written in terms of it. The class documentation is very clear,
and it contains several illustrative examples.

For another example, here's a generalization of David Holmes'
suggestion for a "ReadReadLock" to more than two read-sets.
The generic parameter T is the read-set type.

T might be Integer, in which case typical usage might be:

     RRLock<Integer> rrlock;
     ...
     Lock lock = rrlock.lockFor(5);
     lock.lock();
     try {
         // Do something that can only be done concurrently
         // with other threads holding the "5" lock.
     } finally {
         lock.unlock();
     }

Here's the code for RRLock. The trickiness with the bit
manipulation at the end is to encode two relatively small
integers, a counter and a read-set index, into the one
int of state that AQS makes available, by storing the
read-set index reversed in the upper bits of the state
(flush-left, as it were) while the count is stored
normally in the lower bits. Read-set index 0 is special;
it means that no read-set has the lock.

/**
  * Analogous to ReadWriteLock, in that RRLock is not itself
  * a lock, but a factory for related Locks.
  */
public final class RRLock<T> {
     /**
      * Returns the lock for the given read-set.
      */
     public Lock lockFor(T readSet) {
         Lock lock = map.get(readSet);
         if (lock == null) {
             synchronized (sync) {
                 lock = new LockImpl(sync.nsets, sync);
                 Lock prev = map.putIfAbsent(readSet, lock);
                 if (prev == null)
                     sync.nsets++;
                 else
                     lock = prev;
             }
         }
         return lock;
     }

     private static class LockImpl implements Lock {
         public void lock() {
             sync.acquireShared(index);
         }

         public void lockInterruptibly() throws InterruptedException {
             sync.acquireSharedInterruptibly(index);
         }

         public boolean tryLock() {
             return sync.tryAcquireShared(index) > 0;
         }

         public boolean tryLock(long timeout, TimeUnit unit)
             throws InterruptedException {
             return sync.tryAcquireSharedNanos(index, unit.toNanos(timeout));
         }

         public void unlock() {
             sync.releaseShared(index);
         }

         public Condition newCondition() {
             throw new UnsupportedOperationException();
         }

         LockImpl(int index, Sync sync) {
             this.index = index;
             this.sync = sync;
         }

         private final int index;
         private final Sync sync;
     }

     private final ConcurrentMap<T, Lock> map =
         new ConcurrentHashMap<T, Lock>();

     private final Sync sync = new Sync();

     private static class Sync extends AbstractQueuedSynchronizer {

         private volatile int nsets = 1;

         protected int tryAcquireShared(int index) {
             int mask = indexMask();
             while (true) {
                 int s = getState();
                 if (!canAcquire(index, s, mask))
                     return -1;
                 if (compareAndSetState(s, acquiredState(index, s, mask)))
                     return 1;
             }
         }

         protected boolean tryReleaseShared(int index) {
             int mask = indexMask();
             while (true) {
                 int s = getState();
                 if (compareAndSetState(s, releasedState(index, s, mask)))
                     return true;
             }
         }

         private int indexMask() {
             return (Integer.highestOneBit(nsets) << 1) - 1;
         }

         private boolean canAcquire(int index, int s, int mask) {
             return s == 0 ? true : (index == extractIndex(s, mask));
         }

         private int acquiredState(int index, int s, int mask) {
             int count = extractCount(s, mask) + 1;
             return combineIndexAndCount(index, count);
         }

         private int releasedState(int index, int s, int mask) {
             int count = extractCount(s, mask) - 1;
             return count == 0 ? 0 : combineIndexAndCount(index, count);
         }

         private int combineIndexAndCount(int index, int count) {
             return count | Integer.reverse(index);
         }

         private int extractIndex(int s, int mask) {
             return Integer.reverse(s) & mask;
         }

         private int extractCount(int s, int mask) {
             return s & ~Integer.reverse(mask);
         }
     }
}


Here's how to use this class in your FooBar setting and get the
cleanup behavior that was missing from my earlier example. The
generic parameter K means the key type -- String in your examples,
but I see no reason not to make it generic.


public class FooBar<K> {

     public void foo(K key) {
         Lock lock = rrlockFor(key).lockFor(FOO);
         if (lock.tryLock())
             try     { doFoo(key); }
             finally { lock.unlock(); }
     }

     public void bar(K key) throws InterruptedException {
         Lock lock = rrlockFor(key).lockFor(BAR);
         lock.lockInterruptibly();
         try     { doBar(key); }
         finally { lock.unlock(); }
     }

     abstract void doFoo(K key);
     abstract void doBar(K key);


     enum FB { FOO, BAR }

     private RRLock<FB> rrlockFor(K key) {
         removeUnreachableLocks();

         Ref<K, RRLock<FB>> ref = lockMap.get(key);
         while (true) {
             if (ref != null) {
                 RRLock<FB> lock = ref.get();
                 if (lock != null) return lock;
                 lockMap.remove(key, ref);
             }
             ref = new Ref<K, RRLock<FB>>(key, new RRLock<FB>(), refq);
             Ref<K, RRLock<FB>> prev = lockMap.putIfAbsent(key, ref);
             if (prev != null) ref = prev;
         }
     }

     private void removeUnreachableLocks() {
         Reference<? extends RRLock<FB>> ref;
         while ((ref = refq.poll()) != null) {
             Ref<K, ? extends RRLock<FB>> r =
                 (Ref<K, ? extends RRLock<FB>>) ref;
             lockMap.remove(r.key, r);
         }
     }

     private static class Ref<K, T> extends WeakReference<T> {
         Ref(K key, T t, ReferenceQueue<T> refq) {
             super(t, refq);
             this.key = key;
         }
         final K key;
     }

     private final ConcurrentMap<K, Ref<K, RRLock<FB>>> lockMap =
             new ConcurrentHashMap<K, Ref<K, RRLock<FB>>>();

     private final ReferenceQueue<RRLock<FB>> refq =
         new ReferenceQueue<RRLock<FB>>();
}

There is a lot more code here than your original example, but
the RRLock part may be useful in other settings.

--tim


From thanot@infovista.com  Thu Jan 27 07:36:03 2005
From: thanot@infovista.com (Thierry Hanot)
Date: Thu, 27 Jan 2005 08:36:03 +0100
Subject: [concurrency-interest] Memory Leak in LinkedBlockingQueue
Message-ID: <F520B214418AD4119F7000508BD90CC207F839E3@ivhqsr02>

This message is in MIME format. Since your mail reader does not understand
this format, some or all of this message may not be legible.

------_=_NextPart_001_01C50442.DADEBBF0
Content-Type: text/plain

Hi 
 
I don't know if there is an open bug in the sun database( i've searched for
it but nothing )  but the simple following test case 
cause an out of memory every times on Windows 2000 with the jdk 1.5.0 :
 
 
 
public class PollMemoryLeak {
    public static void main(String[] args) throws InterruptedException {
        BlockingQueue  bl = new LinkedBlockingQueue(2000);
        while(true){
            bl.poll( 2,TimeUnit.MILLISECONDS);
        }
}
 
The number of AbstractQueuedSynchronizer.Node Object is increasing
constantly.( as the node are really small objects it take a little time to
crash ) 
 
 
After a small investigation in a debugger , it seems that the memory leak is
in the AbstractQueuedSynchronizer.java in ConditionObject( All the
synchronized queue should have 
the same problem ).
 
It seem's that the nextWaiter on the node is never resetted when the end of
offer is reached. That means at every called to offer a new Node is
allocated but none of them are removed since they all references each other
with the nextWaiter.( Node are double chained list if i'm rigth and only one
chain is broken with the setHead  ) .
 
I'm using concurrency since a while but it's was my first looks inside the
code of the JSR166 , so may be my analysis is not relevant .
 
Thks
 
Thierry 
 
 
 

------_=_NextPart_001_01C50442.DADEBBF0
Content-Type: text/html

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=us-ascii">
<TITLE>Message</TITLE>

<META content="MSHTML 6.00.2800.1479" name=GENERATOR></HEAD>
<BODY>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>Hi 
</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>I don't know if 
there is an open bug in the sun database( i've searched for it but nothing 
)&nbsp; but the simple following test case </SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>cause an out of 
memory every times on Windows 2000 with the jdk 1.5.0 :</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>public class 
PollMemoryLeak {</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>&nbsp;&nbsp;&nbsp; 
public static void main(String[] args) throws InterruptedException 
{</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
BlockingQueue&nbsp; bl = new LinkedBlockingQueue(2000);</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
while(true){<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
bl.poll( 2,TimeUnit.MILLISECONDS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
}</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005>}</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>The number of 
AbstractQueuedSynchronizer.Node Object is increasing constantly.( as the node 
are really small objects it take a little time to crash ) </SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>After a small 
investigation in a debugger , it seems that the memory leak is in the 
AbstractQueuedSynchronizer.java&nbsp;in ConditionObject( All the synchronized 
queue should have </SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>the same problem 
).</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>It seem's that the 
nextWaiter on the node is never resetted when the end of offer is reached. That 
means at every called to offer a new Node is allocated but none of them are 
removed since they all references each other with the nextWaiter.( Node are 
double chained list if&nbsp;i'm rigth and&nbsp;only one chain is broken with the 
setHead &nbsp;) .</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>I'm using 
concurrency since a while but it's was my first looks inside the code of the 
JSR166 , so may be my analysis is not relevant .</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005>Thks</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>Thierry 
</SPAN></FONT></DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
<DIV><FONT face=Arial size=2><SPAN 
class=739015819-26012005></SPAN></FONT>&nbsp;</DIV></BODY></HTML>

------_=_NextPart_001_01C50442.DADEBBF0--

From thanot@infovista.com  Thu Jan 27 08:41:39 2005
From: thanot@infovista.com (Thierry Hanot)
Date: Thu, 27 Jan 2005 09:41:39 +0100
Subject: [concurrency-interest] Memory Leak in LinkedBlockingQueue
Message-ID: <F520B214418AD4119F7000508BD90CC207F839E7@ivhqsr02>

This message is in MIME format. Since your mail reader does not understand
this format, some or all of this message may not be legible.

------_=_NextPart_001_01C5044C.04B036D0
Content-Type: text/plain

Sorry a few typo in my previous mail ... the problem is in the poll method
not offer ... 
 

-----Original Message-----
From: Thierry Hanot [mailto:thanot@infovista.com] 
Sent: Thursday, January 27, 2005 8:36 AM
To: concurrency-interest@altair.cs.oswego.edu
Subject: [concurrency-interest] Memory Leak in LinkedBlockingQueue


Hi 
 
I don't know if there is an open bug in the sun database( i've searched for
it but nothing )  but the simple following test case 
cause an out of memory every times on Windows 2000 with the jdk 1.5.0 :
 
 
 
public class PollMemoryLeak {
    public static void main(String[] args) throws InterruptedException {
        BlockingQueue  bl = new LinkedBlockingQueue(2000);
        while(true){
            bl.poll( 2,TimeUnit.MILLISECONDS);
        }
}
 
The number of AbstractQueuedSynchronizer.Node Object is increasing
constantly.( as the node are really small objects it take a little time to
crash ) 
 
 
After a small investigation in a debugger , it seems that the memory leak is
in the AbstractQueuedSynchronizer.java in ConditionObject( All the
synchronized queue should have 
the same problem ).
 
It seem's that the nextWaiter on the node is never resetted when the end of
poll is reached. That means at every called to  poll a new Node is allocated
but none of them are removed since they all references each other with the
nextWaiter.( Node are double chained list if i'm rigth and only one chain is
broken with the setHead  ) .
 
I'm using concurrency since a while but it's was my first looks inside the
code of the JSR166 , so may be my analysis is not relevant .
 
Thks
 
Thierry 
 
 
 


------_=_NextPart_001_01C5044C.04B036D0
Content-Type: text/html

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=us-ascii">
<TITLE>Message</TITLE>

<META content="MSHTML 6.00.2800.1479" name=GENERATOR></HEAD>
<BODY>
<DIV><FONT face=Arial color=#0000ff size=2><SPAN class=192174008-27012005>Sorry 
a few typo in my previous mail ... the problem is in the poll method not offer 
... </SPAN></FONT></DIV>
<DIV><FONT face=Arial color=#0000ff size=2><SPAN 
class=192174008-27012005></SPAN></FONT>&nbsp;</DIV>
<BLOCKQUOTE dir=ltr style="MARGIN-RIGHT: 0px">
  <DIV></DIV>
  <DIV class=OutlookMessageHeader lang=en-us dir=ltr align=left><FONT 
  face=Tahoma size=2>-----Original Message-----<BR><B>From:</B> Thierry Hanot 
  [mailto:thanot@infovista.com] <BR><B>Sent:</B> Thursday, January 27, 2005 8:36 
  AM<BR><B>To:</B> concurrency-interest@altair.cs.oswego.edu<BR><B>Subject:</B> 
  [concurrency-interest] Memory Leak in LinkedBlockingQueue<BR><BR></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>Hi 
  </SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>I don't know if 
  there is an open bug in the sun database( i've searched for it but nothing 
  )&nbsp; but the simple following test case </SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>cause an out of 
  memory every times on Windows 2000 with the jdk 1.5.0 :</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>public class 
  PollMemoryLeak {</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>&nbsp;&nbsp;&nbsp; 
  public static void main(String[] args) throws InterruptedException 
  {</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  BlockingQueue&nbsp; bl = new LinkedBlockingQueue(2000);</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  while(true){<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  bl.poll( 
  2,TimeUnit.MILLISECONDS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  }</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005>}</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>The number of 
  AbstractQueuedSynchronizer.Node Object is increasing constantly.( as the node 
  are really small objects it take a little time to crash ) </SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>After a small 
  investigation in a debugger , it seems that the memory leak is in the 
  AbstractQueuedSynchronizer.java&nbsp;in ConditionObject( All the synchronized 
  queue should have </SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>the same problem 
  ).</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>It seem's that the 
  nextWaiter on the node is never resetted when the end of&nbsp;<SPAN 
  class=192174008-27012005><FONT 
  color=#0000ff><STRONG>&nbsp;poll</STRONG>&nbsp;</FONT></SPAN>is reached. That 
  means at every called to&nbsp;<SPAN class=192174008-27012005><FONT 
  color=#0000ff>&nbsp;<STRONG>poll</STRONG>&nbsp;</FONT></SPAN>a new Node is 
  allocated but none of them are removed since they all references each other 
  with the nextWaiter.( Node are double chained list if&nbsp;i'm rigth 
  and&nbsp;only one chain is broken with the setHead &nbsp;) 
  .</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>I'm using 
  concurrency since a while but it's was my first looks inside the code of the 
  JSR166 , so may be my analysis is not relevant .</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005>Thks</SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN class=739015819-26012005>Thierry 
  </SPAN></FONT></DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV>
  <DIV><FONT face=Arial size=2><SPAN 
  class=739015819-26012005></SPAN></FONT>&nbsp;</DIV></BLOCKQUOTE></BODY></HTML>

------_=_NextPart_001_01C5044C.04B036D0--

From dl@cs.oswego.edu  Thu Jan 27 11:55:32 2005
From: dl@cs.oswego.edu (Doug Lea)
Date: Thu, 27 Jan 2005 06:55:32 -0500
Subject: [concurrency-interest] Memory Leak in LinkedBlockingQueue
In-Reply-To: <F520B214418AD4119F7000508BD90CC207F839E7@ivhqsr02>
References: <F520B214418AD4119F7000508BD90CC207F839E7@ivhqsr02>
Message-ID: <16888.54964.176366.561680@altair.cs.oswego.edu>

Thanks for reporting this!

Sorry for the problem. The leak is real, although your diagnosis is a
little off.  Space from aborted timed condition waits was designed to
be cleaned up if the condition is EVER signalled. I now see that this
isn't good enough for some applications.  (We should know better too!
Java.util.Timer has long had essentialy the same problem.)  We'll work
on improving this to self-limit in the case of an unbounded series of
aborted waits without a signal.  In the mean time, you might be able
to work around this by occasionally artificially inserting a dummy
element.

-Doug




From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 22:04:11 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 09:04:11 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <41F87FA6.1010204@peierls.net>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
 <ca53c8f805012620201b6eb107@mail.gmail.com>
 <41F87FA6.1010204@peierls.net>
Message-ID: <ca53c8f80501271404799107f@mail.gmail.com>

Hi Tim,

Why the synchronized block in method lockFor ?  It seems it can be
safely removed.

H

On Thu, 27 Jan 2005 00:44:06 -0500, Tim Peierls <tim@peierls.net> wrote:
> Hanson Char wrote:
> >>Ideally, it seems you'd want an API like:
> >>
> >>  rwl.readLock(key)
> >>  rwl.writeLock(key)
> >
> > I suppose it would be something like the following code ?
> ...
> > The AQS solution proposed by Tim looks like
> > black magic to me at this stage
> 
> That is a shame, because AbstractQueuedSynchronizer is truly
> a wonderful thing. Most of the j.u.c synchronizer classes are
> written in terms of it. The class documentation is very clear,
> and it contains several illustrative examples.
> 
> For another example, here's a generalization of David Holmes'
> suggestion for a "ReadReadLock" to more than two read-sets.
> The generic parameter T is the read-set type.
> 
> T might be Integer, in which case typical usage might be:
> 
>      RRLock<Integer> rrlock;
>      ...
>      Lock lock = rrlock.lockFor(5);
>      lock.lock();
>      try {
>          // Do something that can only be done concurrently
>          // with other threads holding the "5" lock.
>      } finally {
>          lock.unlock();
>      }
> 
> Here's the code for RRLock. The trickiness with the bit
> manipulation at the end is to encode two relatively small
> integers, a counter and a read-set index, into the one
> int of state that AQS makes available, by storing the
> read-set index reversed in the upper bits of the state
> (flush-left, as it were) while the count is stored
> normally in the lower bits. Read-set index 0 is special;
> it means that no read-set has the lock.
> 
> /**
>   * Analogous to ReadWriteLock, in that RRLock is not itself
>   * a lock, but a factory for related Locks.
>   */
> public final class RRLock<T> {
>      /**
>       * Returns the lock for the given read-set.
>       */
>      public Lock lockFor(T readSet) {
>          Lock lock = map.get(readSet);
>          if (lock == null) {
>              synchronized (sync) {
>                  lock = new LockImpl(sync.nsets, sync);
>                  Lock prev = map.putIfAbsent(readSet, lock);
>                  if (prev == null)
>                      sync.nsets++;
>                  else
>                      lock = prev;
>              }
>          }
>          return lock;
>      }
> 
>      private static class LockImpl implements Lock {
>          public void lock() {
>              sync.acquireShared(index);
>          }
> 
>          public void lockInterruptibly() throws InterruptedException {
>              sync.acquireSharedInterruptibly(index);
>          }
> 
>          public boolean tryLock() {
>              return sync.tryAcquireShared(index) > 0;
>          }
> 
>          public boolean tryLock(long timeout, TimeUnit unit)
>              throws InterruptedException {
>              return sync.tryAcquireSharedNanos(index, unit.toNanos(timeout));
>          }
> 
>          public void unlock() {
>              sync.releaseShared(index);
>          }
> 
>          public Condition newCondition() {
>              throw new UnsupportedOperationException();
>          }
> 
>          LockImpl(int index, Sync sync) {
>              this.index = index;
>              this.sync = sync;
>          }
> 
>          private final int index;
>          private final Sync sync;
>      }
> 
>      private final ConcurrentMap<T, Lock> map =
>          new ConcurrentHashMap<T, Lock>();
> 
>      private final Sync sync = new Sync();
> 
>      private static class Sync extends AbstractQueuedSynchronizer {
> 
>          private volatile int nsets = 1;
> 
>          protected int tryAcquireShared(int index) {
>              int mask = indexMask();
>              while (true) {
>                  int s = getState();
>                  if (!canAcquire(index, s, mask))
>                      return -1;
>                  if (compareAndSetState(s, acquiredState(index, s, mask)))
>                      return 1;
>              }
>          }
> 
>          protected boolean tryReleaseShared(int index) {
>              int mask = indexMask();
>              while (true) {
>                  int s = getState();
>                  if (compareAndSetState(s, releasedState(index, s, mask)))
>                      return true;
>              }
>          }
> 
>          private int indexMask() {
>              return (Integer.highestOneBit(nsets) << 1) - 1;
>          }
> 
>          private boolean canAcquire(int index, int s, int mask) {
>              return s == 0 ? true : (index == extractIndex(s, mask));
>          }
> 
>          private int acquiredState(int index, int s, int mask) {
>              int count = extractCount(s, mask) + 1;
>              return combineIndexAndCount(index, count);
>          }
> 
>          private int releasedState(int index, int s, int mask) {
>              int count = extractCount(s, mask) - 1;
>              return count == 0 ? 0 : combineIndexAndCount(index, count);
>          }
> 
>          private int combineIndexAndCount(int index, int count) {
>              return count | Integer.reverse(index);
>          }
> 
>          private int extractIndex(int s, int mask) {
>              return Integer.reverse(s) & mask;
>          }
> 
>          private int extractCount(int s, int mask) {
>              return s & ~Integer.reverse(mask);
>          }
>      }
> }
> 
> Here's how to use this class in your FooBar setting and get the
> cleanup behavior that was missing from my earlier example. The
> generic parameter K means the key type -- String in your examples,
> but I see no reason not to make it generic.
> 
> public class FooBar<K> {
> 
>      public void foo(K key) {
>          Lock lock = rrlockFor(key).lockFor(FOO);
>          if (lock.tryLock())
>              try     { doFoo(key); }
>              finally { lock.unlock(); }
>      }
> 
>      public void bar(K key) throws InterruptedException {
>          Lock lock = rrlockFor(key).lockFor(BAR);
>          lock.lockInterruptibly();
>          try     { doBar(key); }
>          finally { lock.unlock(); }
>      }
> 
>      abstract void doFoo(K key);
>      abstract void doBar(K key);
> 
>      enum FB { FOO, BAR }
> 
>      private RRLock<FB> rrlockFor(K key) {
>          removeUnreachableLocks();
> 
>          Ref<K, RRLock<FB>> ref = lockMap.get(key);
>          while (true) {
>              if (ref != null) {
>                  RRLock<FB> lock = ref.get();
>                  if (lock != null) return lock;
>                  lockMap.remove(key, ref);
>              }
>              ref = new Ref<K, RRLock<FB>>(key, new RRLock<FB>(), refq);
>              Ref<K, RRLock<FB>> prev = lockMap.putIfAbsent(key, ref);
>              if (prev != null) ref = prev;
>          }
>      }
> 
>      private void removeUnreachableLocks() {
>          Reference<? extends RRLock<FB>> ref;
>          while ((ref = refq.poll()) != null) {
>              Ref<K, ? extends RRLock<FB>> r =
>                  (Ref<K, ? extends RRLock<FB>>) ref;
>              lockMap.remove(r.key, r);
>          }
>      }
> 
>      private static class Ref<K, T> extends WeakReference<T> {
>          Ref(K key, T t, ReferenceQueue<T> refq) {
>              super(t, refq);
>              this.key = key;
>          }
>          final K key;
>      }
> 
>      private final ConcurrentMap<K, Ref<K, RRLock<FB>>> lockMap =
>              new ConcurrentHashMap<K, Ref<K, RRLock<FB>>>();
> 
>      private final ReferenceQueue<RRLock<FB>> refq =
>          new ReferenceQueue<RRLock<FB>>();
> }
> 
> There is a lot more code here than your original example, but
> the RRLock part may be useful in other settings.
> 
> --tim
> 
>

From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 22:10:36 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 09:10:36 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f80501271404799107f@mail.gmail.com>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
 <ca53c8f805012620201b6eb107@mail.gmail.com>
 <41F87FA6.1010204@peierls.net>
 <ca53c8f80501271404799107f@mail.gmail.com>
Message-ID: <ca53c8f8050127141094cd955@mail.gmail.com>

Oops.  Please disregard my previous question.

H

On Fri, 28 Jan 2005 09:04:11 +1100, Hanson Char <hanson.char@gmail.com> wrote:
> Hi Tim,
> 
> Why the synchronized block in method lockFor ?  It seems it can be
> safely removed.
> 
> H

From Hanson Char <hanson.char@gmail.com>  Thu Jan 27 22:25:46 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 09:25:46 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <41F87FA6.1010204@peierls.net>
References: <41E01E72.7050700@videotron.ca>
 <16864.8214.541321.812039@altair.cs.oswego.edu>
 <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca>
 <41F5954D.4020609@mathcs.emory.edu>
 <ca53c8f80501242143239c353f@mail.gmail.com>
 <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2>
 <ca53c8f805012620201b6eb107@mail.gmail.com>
 <41F87FA6.1010204@peierls.net>
Message-ID: <ca53c8f805012714254bf916e1@mail.gmail.com>

Hi Tim,

On 3rd look, it appears the synchronized block in method lockFor is
used to guard the statement

sync.nsets++;

But then nsets is a volatile int, which doesn't need to be
synchronized.  So the question comes back: why the synchronized block
in method lockFor ?

H


On Fri, 28 Jan 2005 09:10:36 +1100, Hanson Char <hanson.char@gmail.com> wrote:
> Oops.  Please disregard my previous question.
> 
> H
> 
> On Fri, 28 Jan 2005 09:04:11 +1100, Hanson Char <hanson.char@gmail.com> wrote:
> > Hi Tim,
> >
> > Why the synchronized block in method lockFor ?  It seems it can be
> > safely removed.
> >
> > H
> 


On Thu, 27 Jan 2005 00:44:06 -0500, Tim Peierls <tim@peierls.net> wrote:
> Hanson Char wrote:
> >>Ideally, it seems you'd want an API like:
> >>
> >>  rwl.readLock(key)
> >>  rwl.writeLock(key)
> >
> > I suppose it would be something like the following code ?
> ...
> > The AQS solution proposed by Tim looks like
> > black magic to me at this stage
> 
> That is a shame, because AbstractQueuedSynchronizer is truly
> a wonderful thing. Most of the j.u.c synchronizer classes are
> written in terms of it. The class documentation is very clear,
> and it contains several illustrative examples.
> 
> For another example, here's a generalization of David Holmes'
> suggestion for a "ReadReadLock" to more than two read-sets.
> The generic parameter T is the read-set type.
> 
> T might be Integer, in which case typical usage might be:
> 
>      RRLock<Integer> rrlock;
>      ...
>      Lock lock = rrlock.lockFor(5);
>      lock.lock();
>      try {
>          // Do something that can only be done concurrently
>          // with other threads holding the "5" lock.
>      } finally {
>          lock.unlock();
>      }
> 
> Here's the code for RRLock. The trickiness with the bit
> manipulation at the end is to encode two relatively small
> integers, a counter and a read-set index, into the one
> int of state that AQS makes available, by storing the
> read-set index reversed in the upper bits of the state
> (flush-left, as it were) while the count is stored
> normally in the lower bits. Read-set index 0 is special;
> it means that no read-set has the lock.
> 
> /**
>   * Analogous to ReadWriteLock, in that RRLock is not itself
>   * a lock, but a factory for related Locks.
>   */
> public final class RRLock<T> {
>      /**
>       * Returns the lock for the given read-set.
>       */
>      public Lock lockFor(T readSet) {
>          Lock lock = map.get(readSet);
>          if (lock == null) {
>              synchronized (sync) {
>                  lock = new LockImpl(sync.nsets, sync);
>                  Lock prev = map.putIfAbsent(readSet, lock);
>                  if (prev == null)
>                      sync.nsets++;
>                  else
>                      lock = prev;
>              }
>          }
>          return lock;
>      }
> 
>      private static class LockImpl implements Lock {
>          public void lock() {
>              sync.acquireShared(index);
>          }
> 
>          public void lockInterruptibly() throws InterruptedException {
>              sync.acquireSharedInterruptibly(index);
>          }
> 
>          public boolean tryLock() {
>              return sync.tryAcquireShared(index) > 0;
>          }
> 
>          public boolean tryLock(long timeout, TimeUnit unit)
>              throws InterruptedException {
>              return sync.tryAcquireSharedNanos(index, unit.toNanos(timeout));
>          }
> 
>          public void unlock() {
>              sync.releaseShared(index);
>          }
> 
>          public Condition newCondition() {
>              throw new UnsupportedOperationException();
>          }
> 
>          LockImpl(int index, Sync sync) {
>              this.index = index;
>              this.sync = sync;
>          }
> 
>          private final int index;
>          private final Sync sync;
>      }
> 
>      private final ConcurrentMap<T, Lock> map =
>          new ConcurrentHashMap<T, Lock>();
> 
>      private final Sync sync = new Sync();
> 
>      private static class Sync extends AbstractQueuedSynchronizer {
> 
>          private volatile int nsets = 1;
> 
>          protected int tryAcquireShared(int index) {
>              int mask = indexMask();
>              while (true) {
>                  int s = getState();
>                  if (!canAcquire(index, s, mask))
>                      return -1;
>                  if (compareAndSetState(s, acquiredState(index, s, mask)))
>                      return 1;
>              }
>          }
> 
>          protected boolean tryReleaseShared(int index) {
>              int mask = indexMask();
>              while (true) {
>                  int s = getState();
>                  if (compareAndSetState(s, releasedState(index, s, mask)))
>                      return true;
>              }
>          }
> 
>          private int indexMask() {
>              return (Integer.highestOneBit(nsets) << 1) - 1;
>          }
> 
>          private boolean canAcquire(int index, int s, int mask) {
>              return s == 0 ? true : (index == extractIndex(s, mask));
>          }
> 
>          private int acquiredState(int index, int s, int mask) {
>              int count = extractCount(s, mask) + 1;
>              return combineIndexAndCount(index, count);
>          }
> 
>          private int releasedState(int index, int s, int mask) {
>              int count = extractCount(s, mask) - 1;
>              return count == 0 ? 0 : combineIndexAndCount(index, count);
>          }
> 
>          private int combineIndexAndCount(int index, int count) {
>              return count | Integer.reverse(index);
>          }
> 
>          private int extractIndex(int s, int mask) {
>              return Integer.reverse(s) & mask;
>          }
> 
>          private int extractCount(int s, int mask) {
>              return s & ~Integer.reverse(mask);
>          }
>      }
> }
> 
> Here's how to use this class in your FooBar setting and get the
> cleanup behavior that was missing from my earlier example. The
> generic parameter K means the key type -- String in your examples,
> but I see no reason not to make it generic.
> 
> public class FooBar<K> {
> 
>      public void foo(K key) {
>          Lock lock = rrlockFor(key).lockFor(FOO);
>          if (lock.tryLock())
>              try     { doFoo(key); }
>              finally { lock.unlock(); }
>      }
> 
>      public void bar(K key) throws InterruptedException {
>          Lock lock = rrlockFor(key).lockFor(BAR);
>          lock.lockInterruptibly();
>          try     { doBar(key); }
>          finally { lock.unlock(); }
>      }
> 
>      abstract void doFoo(K key);
>      abstract void doBar(K key);
> 
>      enum FB { FOO, BAR }
> 
>      private RRLock<FB> rrlockFor(K key) {
>          removeUnreachableLocks();
> 
>          Ref<K, RRLock<FB>> ref = lockMap.get(key);
>          while (true) {
>              if (ref != null) {
>                  RRLock<FB> lock = ref.get();
>                  if (lock != null) return lock;
>                  lockMap.remove(key, ref);
>              }
>              ref = new Ref<K, RRLock<FB>>(key, new RRLock<FB>(), refq);
>              Ref<K, RRLock<FB>> prev = lockMap.putIfAbsent(key, ref);
>              if (prev != null) ref = prev;
>          }
>      }
> 
>      private void removeUnreachableLocks() {
>          Reference<? extends RRLock<FB>> ref;
>          while ((ref = refq.poll()) != null) {
>              Ref<K, ? extends RRLock<FB>> r =
>                  (Ref<K, ? extends RRLock<FB>>) ref;
>              lockMap.remove(r.key, r);
>          }
>      }
> 
>      private static class Ref<K, T> extends WeakReference<T> {
>          Ref(K key, T t, ReferenceQueue<T> refq) {
>              super(t, refq);
>              this.key = key;
>          }
>          final K key;
>      }
> 
>      private final ConcurrentMap<K, Ref<K, RRLock<FB>>> lockMap =
>              new ConcurrentHashMap<K, Ref<K, RRLock<FB>>>();
> 
>      private final ReferenceQueue<RRLock<FB>> refq =
>          new ReferenceQueue<RRLock<FB>>();
> }
> 
> There is a lot more code here than your original example, but
> the RRLock part may be useful in other settings.
> 
> --tim
> 
>

From dholmes@dltech.com.au  Thu Jan 27 22:45:10 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Fri, 28 Jan 2005 08:45:10 +1000
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f805012714254bf916e1@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>

Hanson,

> On 3rd look, it appears the synchronized block in method lockFor is
> used to guard the statement
> 
> sync.nsets++;
> 
> But then nsets is a volatile int, which doesn't need to be
> synchronized.  So the question comes back: why the synchronized block
> in method lockFor ?

volatiles still need synchronization for a get-modify-set sequence like ++

David Holmes

From Hanson Char <hanson.char@gmail.com>  Fri Jan 28 03:49:52 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 14:49:52 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
References: <ca53c8f805012714254bf916e1@mail.gmail.com>
 <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
Message-ID: <ca53c8f8050127194913db92f6@mail.gmail.com>

How about if we use an j.u.c.a.AtomicInteger instead of a primitive
int for syn.nets, so we can safely increment the count without the
synchronized block ?  Will that be faster ?

H

On Fri, 28 Jan 2005 08:45:10 +1000, David Holmes <dholmes@dltech.com.au> wrote:
> Hanson,
> 
> > On 3rd look, it appears the synchronized block in method lockFor is
> > used to guard the statement
> >
> > sync.nsets++;
> >
> > But then nsets is a volatile int, which doesn't need to be
> > synchronized.  So the question comes back: why the synchronized block
> > in method lockFor ?
> 
> volatiles still need synchronization for a get-modify-set sequence like ++
> 
> David Holmes
>

From dholmes@dltech.com.au  Fri Jan 28 03:58:45 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Fri, 28 Jan 2005 13:58:45 +1000
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f8050127194913db92f6@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEKOFEAA.dholmes@dltech.com.au>

Hanson,

> How about if we use an j.u.c.a.AtomicInteger instead of a primitive
> int for syn.nets, so we can safely increment the count without the
> synchronized block ?  Will that be faster ?

You could use an AtomicInteger. As for whether it would be faster - that's
hard to say. Do you expect high or low contention? - that could make a
difference. I think you'd have to code it up both ways and profile it.

David

>
> On Fri, 28 Jan 2005 08:45:10 +1000, David Holmes
> <dholmes@dltech.com.au> wrote:
> > Hanson,
> >
> > > On 3rd look, it appears the synchronized block in method lockFor is
> > > used to guard the statement
> > >
> > > sync.nsets++;
> > >
> > > But then nsets is a volatile int, which doesn't need to be
> > > synchronized.  So the question comes back: why the synchronized block
> > > in method lockFor ?
> >
> > volatiles still need synchronization for a get-modify-set
> sequence like ++
> >
> > David Holmes
> >
>


From dholmes@dltech.com.au  Fri Jan 28 04:14:31 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Fri, 28 Jan 2005 14:14:31 +1000
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEKOFEAA.dholmes@dltech.com.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEKOFEAA.dholmes@dltech.com.au>

I should also add that I'm only responding to the atomicity of volatile. I
haven't examined the code to see if there are other reasons why the sync
block might be needed.

David

> -----Original Message-----
> From: concurrency-interest-admin@cs.oswego.edu
> [mailto:concurrency-interest-admin@cs.oswego.edu]On Behalf Of David
> Holmes
> Sent: Friday, 28 January 2005 1:59 PM
> To: Hanson Char
> Cc: Tim Peierls; concurrency-interest@altair.cs.oswego.edu; Tim Lavers
> Subject: RE: [concurrency-interest] FooBar concurrency (long)
>
>
> Hanson,
>
> > How about if we use an j.u.c.a.AtomicInteger instead of a primitive
> > int for syn.nets, so we can safely increment the count without the
> > synchronized block ?  Will that be faster ?
>
> You could use an AtomicInteger. As for whether it would be faster - that's
> hard to say. Do you expect high or low contention? - that could make a
> difference. I think you'd have to code it up both ways and profile it.
>
> David
>
> >
> > On Fri, 28 Jan 2005 08:45:10 +1000, David Holmes
> > <dholmes@dltech.com.au> wrote:
> > > Hanson,
> > >
> > > > On 3rd look, it appears the synchronized block in method lockFor is
> > > > used to guard the statement
> > > >
> > > > sync.nsets++;
> > > >
> > > > But then nsets is a volatile int, which doesn't need to be
> > > > synchronized.  So the question comes back: why the
> synchronized block
> > > > in method lockFor ?
> > >
> > > volatiles still need synchronization for a get-modify-set
> > sequence like ++
> > >
> > > David Holmes
> > >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From tim@peierls.net  Fri Jan 28 04:19:55 2005
From: tim@peierls.net (Tim Peierls)
Date: Thu, 27 Jan 2005 23:19:55 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
Message-ID: <41F9BD6B.9080200@peierls.net>

Hanson Char wrote:
>>...why the synchronized block in method lockFor ?
> 
> volatiles still need synchronization for a get-modify-set sequence like ++

Also note that if the list of read-sets is static (as it is in the
FooBar example) or only rarely added to, then once the read-sets have
been given indices, this synchronized block is never entered.

Latest version of RRLock has comments, various fixes, and an example
that I hope is more amusingly helpful than offensive.

  https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RRLock.java

--tim




From tim@peierls.net  Fri Jan 28 04:32:24 2005
From: tim@peierls.net (Tim Peierls)
Date: Thu, 27 Jan 2005 23:32:24 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f8050127194913db92f6@mail.gmail.com>
References: <ca53c8f805012714254bf916e1@mail.gmail.com>
 <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
 <ca53c8f8050127194913db92f6@mail.gmail.com>
Message-ID: <41F9C058.10208@peierls.net>

Hanson Char wrote:
> How about if we use an j.u.c.a.AtomicInteger instead of a primitive
> int for syn.nets, so we can safely increment the count without the
> synchronized block ?  Will that be faster ?

It wouldn't be correct. Each read-set index must be used once. The
read-set count is read before the call to putIfAbsent. If putIfAbsent
succeeds, the read-set count must be bumped; if it fails, it must
be left alone. Without the synchronized block, two threads could
interfere with each other in such a way that an index was skipped
or used twice.

--tim


From Hanson Char <hanson.char@gmail.com>  Fri Jan 28 06:18:39 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 17:18:39 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEKOFEAA.dholmes@dltech.com.au>
References: <ca53c8f8050127194913db92f6@mail.gmail.com>
 <NFBBKALFDCPFIDBNKAPCEEKOFEAA.dholmes@dltech.com.au>
Message-ID: <ca53c8f805012722184ed8c1c5@mail.gmail.com>

I suppose in theory if the expected contention is high, synchronized
block would make a better choice than AtomicInteger, and vice-versa ? 
Since the implementation of, say, AtomicInteger.incrementAndGet is
done in a spin loop for the native compareAndSet to succeed, I bet it
would be more costly in a high contention situation than the
synchronized block.

H

On Fri, 28 Jan 2005 13:58:45 +1000, David Holmes <dholmes@dltech.com.au> wrote:
> Hanson,
> 
> > How about if we use an j.u.c.a.AtomicInteger instead of a primitive
> > int for syn.nets, so we can safely increment the count without the
> > synchronized block ?  Will that be faster ?
> 
> You could use an AtomicInteger. As for whether it would be faster - that's
> hard to say. Do you expect high or low contention? - that could make a
> difference. I think you'd have to code it up both ways and profile it.
> 
> David
> 
> >
> > On Fri, 28 Jan 2005 08:45:10 +1000, David Holmes
> > <dholmes@dltech.com.au> wrote:
> > > Hanson,
> > >
> > > > On 3rd look, it appears the synchronized block in method lockFor is
> > > > used to guard the statement
> > > >
> > > > sync.nsets++;
> > > >
> > > > But then nsets is a volatile int, which doesn't need to be
> > > > synchronized.  So the question comes back: why the synchronized block
> > > > in method lockFor ?
> > >
> > > volatiles still need synchronization for a get-modify-set
> > sequence like ++
> > >
> > > David Holmes
> > >
> >
> 
>

From dholmes@dltech.com.au  Fri Jan 28 06:31:39 2005
From: dholmes@dltech.com.au (David Holmes)
Date: Fri, 28 Jan 2005 16:31:39 +1000
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f805012722184ed8c1c5@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMELDFEAA.dholmes@dltech.com.au>

Hanson Char wrote:
> I suppose in theory if the expected contention is high, synchronized
> block would make a better choice than AtomicInteger, and vice-versa ?
> Since the implementation of, say, AtomicInteger.incrementAndGet is
> done in a spin loop for the native compareAndSet to succeed, I bet it
> would be more costly in a high contention situation than the
> synchronized block.

I think the point is moot given that the sync blocked is needed for more
than updating the integer, but I'd probably go for the AtomicInteger in a
high contention case. With contention on a lock you are going to encounter
forced context switches. With contention on a compare-and-swap you'll only
get contention if there is an incidental context switch; or on a MP system
the conflicts with throttle the bus a little. With no contention the highly
optimised code the VMs use for an uncontended monitor will probably out
perform the atomic sequence used by AtomicInteger. But it is probably close
enough that you'd want accurate profiling to check. It may also be
architecture dependent.

David Holmes


From Hanson Char <hanson.char@gmail.com>  Fri Jan 28 12:07:14 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Fri, 28 Jan 2005 23:07:14 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <41F9BD6B.9080200@peierls.net>
References: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
 <41F9BD6B.9080200@peierls.net>
Message-ID: <ca53c8f80501280407112b018e@mail.gmail.com>

Hi Tim,

1) LHL at RRLock.java. 

2) I understand the synchronized block is used to ensure the gender
index is only incremented whenever there is a new gender being put
into the same RRLock for the very first time.  This means every
LockImpl object in map must have a unique index specific to the
corresponding gender.

3) I refer to:

    private class Sync extends AbstractQueuedSynchronizer {
        protected int tryAcquireShared(int index) {
            int mask = indexMask();
            while (true) {
                int s = getState();
                if (!canAcquire(index, s, mask))
                    return -1;
                int ns = acquiredState(index, s, mask);
                if (compareAndSetState(s, ns)) {
                    int omask = mask;
                    mask = indexMask();
                    if (omask == mask)  // check if mask changed
                        return 1;       // if not, we're done
                    do {                // if so, release and try again
                        s = getState();
                        ns = releasedState(index, s, mask);
                    } while (!compareAndSetState(s, ns));
                }
            }
        }
//...

After the new state "ns" is returned from acquiredState(), if the
following compareAndSetState returns true, does't that mean the shared
lock must have been successfully acquired for the gender index
contained in "ns" ?  Doesn't that mean no gender of a different type
could have acquired any lock on the same RRLock ?  If so, why do we
need to check if the mask is changed (and release and try again, etc.)
?

4)  Why do we check if the mask is changed instead of if the gender
index is changed ?  When there is only 2 genders, checking either one
is fine.  But if there is more than 2, then a change in gender index
may not trigger a change in the mask.

I am confused.

H

On Thu, 27 Jan 2005 23:19:55 -0500, Tim Peierls <tim@peierls.net> wrote:
> Hanson Char wrote:
> >>...why the synchronized block in method lockFor ?
> >
> > volatiles still need synchronization for a get-modify-set sequence like ++
> 
> Also note that if the list of read-sets is static (as it is in the
> FooBar example) or only rarely added to, then once the read-sets have
> been given indices, this synchronized block is never entered.
> 
> Latest version of RRLock has comments, various fixes, and an example
> that I hope is more amusingly helpful than offensive.
> 
>   https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RRLock.java
> 
> --tim

From tim@peierls.net  Fri Jan 28 14:32:04 2005
From: tim@peierls.net (Tim Peierls)
Date: Fri, 28 Jan 2005 09:32:04 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f80501280407112b018e@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
 <41F9BD6B.9080200@peierls.net> <ca53c8f80501280407112b018e@mail.gmail.com>
Message-ID: <41FA4CE4.7010402@peierls.net>

Hanson Char wrote:
> 2) I understand the synchronized block is used to ensure the gender
> index is only incremented whenever there is a new gender being put
> into the same RRLock for the very first time.  This means every
> LockImpl object in map must have a unique index specific to the
> corresponding gender.

Yup.


> 3) I refer to:
>         protected int tryAcquireShared(int index) {
>             int mask = indexMask();
>             while (true) {
>                 int s = getState();
>                 if (!canAcquire(index, s, mask))
>                     return -1;
>                 int ns = acquiredState(index, s, mask);
>                 if (compareAndSetState(s, ns)) {
>                     int omask = mask;
>                     mask = indexMask();
>                     if (omask == mask)  // check if mask changed
>                         return 1;       // if not, we're done
>                     do {                // if so, release and try again
>                         s = getState();
>                         ns = releasedState(index, s, mask);
>                     } while (!compareAndSetState(s, ns));
>                 }
>             }
>         }
> 
> After the new state "ns" is returned from acquiredState(), if the
> following compareAndSetState returns true, does't that mean the shared
> lock must have been successfully acquired for the gender index
> contained in "ns" ?  Doesn't that mean no gender of a different type
> could have acquired any lock on the same RRLock ?  If so, why do we
> need to check if the mask is changed (and release and try again, etc.) ?

This bit of trickiness is needed because the largest LockImpl index
may have changed in between the call to canAcquire and compareAndSetState,
and another thread may have successfully acquired a lock whose index
shares lower bits with this lock's index. In that case the call to
compareAndSetState will incorrectly succeed.

For example, let's say we have one gender so far, index 1.
Here's a serialization of two threads that exhibits the problem.

Thread 1           Shared         Thread 2
--------           ------         --------
                    state = 0
                    ngenders = 1

in tryAcquireShared(1)
mask is 0x1
canAcquire(1, 0, 0x1) succeeds
reverse index mask is 0x80000000
                                   (two more genders introduced)

                    ngenders = 3

                                   in tryAcquireShared(3)
                                   mask is 0x11
                                   canAcquire(3, 0, 0x11) succeeds
                                   reverse index mask is 0xC00000000
                                   cas(0, 0xC00000001) succeeds

                    state = 0xC00000001

                                   Gender 3 now has the lock
cas(0, 0x80000001) fails
loop
canAcquire(1, 0xC0000001, 0x1) succeeds!
cas(0xC0000001, 0xC0000010) succeeds

                    state = 0xC0000010

Gender 1 thinks it has the lock, too, with count of 0x40000010!


My first reaction to this was, "OK, no problem, just move the
line that computes mask inside the loop." And this does solve
the problem, but potentially at a cost: indexMask() examines a
volatile field. Under heavy contention, with the mask evaluation
inside the loop, you could end up doing a lot of volatile reads.

Since in steady state use the gender count won't be changing
much -- or rather, I find it hard to imagine applications where
the gender count is constantly changing -- I designed for the
common case of unchanged mask, which only requires two volatile
reads, even under contention: one to get the mask initially and
one to check for mask change.

I'm not at all sure this is the right tradeoff; maybe under
heavy contention it's _preferable_ to slow down the loop with
volatile reads. [David Holmes, if you have time, could you weigh
in here?]


> 4)  Why do we check if the mask is changed instead of if the gender
> index is changed ?  When there is only 2 genders, checking either one
> is fine.  But if there is more than 2, then a change in gender index
> may not trigger a change in the mask.

If the mask hasn't changed, then the situation above doesn't arise.
So we check the mask rather than the gender count.

--tim


From Hanson Char <hanson.char@gmail.com>  Sun Jan 30 08:05:11 2005
From: Hanson Char <hanson.char@gmail.com> (Hanson Char)
Date: Sun, 30 Jan 2005 19:05:11 +1100
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <41FA4CE4.7010402@peierls.net>
References: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
 <41F9BD6B.9080200@peierls.net>
 <ca53c8f80501280407112b018e@mail.gmail.com>
 <41FA4CE4.7010402@peierls.net>
Message-ID: <ca53c8f8050130000537b1e8f9@mail.gmail.com>

Hi Tim,

1) ok, this is pretty tricky.  And all the trickiness is about
reducing the access of the volatile "ngender" (read-set index).  I
suppose the hypothetical simpler, yet slower, equivalent version would
be something like:

       protected int tryAcquireShared(int index) {
            while (true) {
                int mask = indexMask();
                int s = getState();
                if (!canAcquire(index, s, mask))
                    return -1;
                int ns = acquiredState(index, s, mask);
                if (compareAndSetState(s, ns))
                    return 1;
            }
        }

2) If the design of RRLock requires the user to specify the maximum
number of  genders (maybe in the constructor), I suppose both the
performance can be improved and complexity reduced, since we can
always use the same mask (calculated once for the maximum case)
instead of dynamically calculating it everytime a lock is requested.

3) Currently checking overflow is omitted from the implementation. 
Requiring the user to specify the max number of genders may also make
it easy to check for overflow both for the number of genders and the
number of shared locks of each specific gender.

Thanks to you.  I start to see the power and usefulness of AQS.

H

On Fri, 28 Jan 2005 09:32:04 -0500, Tim Peierls <tim@peierls.net> wrote:
> Hanson Char wrote:
> > 2) I understand the synchronized block is used to ensure the gender
> > index is only incremented whenever there is a new gender being put
> > into the same RRLock for the very first time.  This means every
> > LockImpl object in map must have a unique index specific to the
> > corresponding gender.
> 
> Yup.
> 
> > 3) I refer to:
> >         protected int tryAcquireShared(int index) {
> >             int mask = indexMask();
> >             while (true) {
> >                 int s = getState();
> >                 if (!canAcquire(index, s, mask))
> >                     return -1;
> >                 int ns = acquiredState(index, s, mask);
> >                 if (compareAndSetState(s, ns)) {
> >                     int omask = mask;
> >                     mask = indexMask();
> >                     if (omask == mask)  // check if mask changed
> >                         return 1;       // if not, we're done
> >                     do {                // if so, release and try again
> >                         s = getState();
> >                         ns = releasedState(index, s, mask);
> >                     } while (!compareAndSetState(s, ns));
> >                 }
> >             }
> >         }
> >
> > After the new state "ns" is returned from acquiredState(), if the
> > following compareAndSetState returns true, does't that mean the shared
> > lock must have been successfully acquired for the gender index
> > contained in "ns" ?  Doesn't that mean no gender of a different type
> > could have acquired any lock on the same RRLock ?  If so, why do we
> > need to check if the mask is changed (and release and try again, etc.) ?
> 
> This bit of trickiness is needed because the largest LockImpl index
> may have changed in between the call to canAcquire and compareAndSetState,
> and another thread may have successfully acquired a lock whose index
> shares lower bits with this lock's index. In that case the call to
> compareAndSetState will incorrectly succeed.
> 
> For example, let's say we have one gender so far, index 1.
> Here's a serialization of two threads that exhibits the problem.
> 
> Thread 1           Shared         Thread 2
> --------           ------         --------
>                     state = 0
>                     ngenders = 1
> 
> in tryAcquireShared(1)
> mask is 0x1
> canAcquire(1, 0, 0x1) succeeds
> reverse index mask is 0x80000000
>                                    (two more genders introduced)
> 
>                     ngenders = 3
> 
>                                    in tryAcquireShared(3)
>                                    mask is 0x11
>                                    canAcquire(3, 0, 0x11) succeeds
>                                    reverse index mask is 0xC00000000
>                                    cas(0, 0xC00000001) succeeds
> 
>                     state = 0xC00000001
> 
>                                    Gender 3 now has the lock
> cas(0, 0x80000001) fails
> loop
> canAcquire(1, 0xC0000001, 0x1) succeeds!
> cas(0xC0000001, 0xC0000010) succeeds
> 
>                     state = 0xC0000010
> 
> Gender 1 thinks it has the lock, too, with count of 0x40000010!
> 
> My first reaction to this was, "OK, no problem, just move the
> line that computes mask inside the loop." And this does solve
> the problem, but potentially at a cost: indexMask() examines a
> volatile field. Under heavy contention, with the mask evaluation
> inside the loop, you could end up doing a lot of volatile reads.
> 
> Since in steady state use the gender count won't be changing
> much -- or rather, I find it hard to imagine applications where
> the gender count is constantly changing -- I designed for the
> common case of unchanged mask, which only requires two volatile
> reads, even under contention: one to get the mask initially and
> one to check for mask change.
> 
> I'm not at all sure this is the right tradeoff; maybe under
> heavy contention it's _preferable_ to slow down the loop with
> volatile reads. [David Holmes, if you have time, could you weigh
> in here?]
> 
> > 4)  Why do we check if the mask is changed instead of if the gender
> > index is changed ?  When there is only 2 genders, checking either one
> > is fine.  But if there is more than 2, then a change in gender index
> > may not trigger a change in the mask.
> 
> If the mask hasn't changed, then the situation above doesn't arise.
> So we check the mask rather than the gender count.
> 
> --tim
> 
>

From tim@peierls.net  Sun Jan 30 16:30:26 2005
From: tim@peierls.net (Tim Peierls)
Date: Sun, 30 Jan 2005 11:30:26 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <ca53c8f8050130000537b1e8f9@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEKEFEAA.dholmes@dltech.com.au>
 <41F9BD6B.9080200@peierls.net> <ca53c8f80501280407112b018e@mail.gmail.com>
 <41FA4CE4.7010402@peierls.net> <ca53c8f8050130000537b1e8f9@mail.gmail.com>
Message-ID: <41FD0BA2.4000205@peierls.net>

Hanson Char wrote:
> And all the trickiness is about reducing the access of the volatile 
> "ngender" (read-set index).  I suppose the hypothetical simpler, yet 
> slower, equivalent version would be something like: ...

Yes, that's what I meant by "moving the mask calculation inside of the
loop".

I modified RRLock so that it uses one of three different implementations of
Sync.tryAcquire/ReleaseShared. The first version is what I was using
before. The second version is with the mask computation inside the loop.
The third version doesn't use a loop at all.
(And it doesn't work, either! I'm not sure why not...)

https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/RRLock.java


> 2) If the design of RRLock requires the user to specify the maximum 
> number of genders (maybe in the constructor), I suppose both the 
> performance can be improved and complexity reduced, ...

Yes. I started with that and then got intrigued by the idea of a
dynamically expandable set. In retrospect, I should have left it
alone. :-)

You can see the code for the simpler version, GenderLock, at

https://dev.priorartisans.com/repos/jcip/trunk/src/main/jcip/rrlock/GenderLock.java

You pass an array or collection of genders to the constructor, and
these are the only genders allowed thereafter. I haven't measured
the performance difference between RRLock and GenderLock.


> 3) Currently checking overflow is omitted from the implementation. 

I put an overflow check in GenderLock. There's no need for an overflow
check on the number of genders in this version, since the user provides
them at construct time.

--tim



From brian@quiotix.com  Mon Jan 31 16:51:46 2005
From: brian@quiotix.com (Brian Goetz)
Date: Mon, 31 Jan 2005 11:51:46 -0500
Subject: [concurrency-interest] FooBar concurrency (long)
In-Reply-To: <41F87FA6.1010204@peierls.net>
References: <41E01E72.7050700@videotron.ca> <16864.8214.541321.812039@altair.cs.oswego.edu> <41E02675.3040102@mathcs.emory.edu> <41F554E5.20108@videotron.ca> <41F5954D.4020609@mathcs.emory.edu> <ca53c8f80501242143239c353f@mail.gmail.com> <0b2701c502aa$7e209e90$0200a8c0@REPLICANT2> <ca53c8f805012620201b6eb107@mail.gmail.com> <41F87FA6.1010204@peierls.net>
Message-ID: <41FE6222.7070509@quiotix.com>

>> The AQS solution proposed by Tim looks like
>> black magic to me at this stage
> 
> That is a shame, because AbstractQueuedSynchronizer is truly
> a wonderful thing. Most of the j.u.c synchronizer classes are
> written in terms of it. The class documentation is very clear,
> and it contains several illustrative examples.

Just catching up on this discussion, AQS does appear to be a desirable 
solution.  In addition to the class Javadoc, you might find Doug's paper 
on it (http://gee.cs.oswego.edu/dl/papers/aqs.pdf) able to shed some 
light on it.  Basically, ReentrantLock, ReentrantReadWriteLock, 
Semaphore, CountDownLatch, and FutureTask are all built on top of it -- 
it abstracts away all of the thread queueing, and allows you to specify 
when a thread is allowed to acquire the resource or whether it has to 
wait for some condition.

If you search the paper for ReentrantReadWriteLock it shows the trick 
for using AQS for managing multiple lock flavors.


From dawidk@mathcs.emory.edu  Mon Jan 31 18:53:51 2005
From: dawidk@mathcs.emory.edu (Dawid Kurzyniec)
Date: Mon, 31 Jan 2005 13:53:51 -0500
Subject: [concurrency-interest] backport: race in ReentrantLock
Message-ID: <41FE7EBF.6070501@mathcs.emory.edu>

The following regards only the backport-util-concurrent 
(http://www.mathcs.emory.edu/dcl/util/backport-util-concurrent/), not 
the main 5.0 API:

Ramesh Nethi reported a race condition in the fair version of 
ReentrantLock, leading to occassional IllegalThreadState exceptions. 
Problem is being investigated; I will send notification when the fixed 
version is available. The following classes are also affected: fair 
ArrayBlockingQueue, fair SynchronousQueue, and PriorityBlockingQueue. I 
recommend using non-fair implementations (which do not have any known 
problems) until the problem is resolved.

Regards,
Dawid Kurzyniec



