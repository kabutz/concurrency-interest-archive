From joe.bowbeer at gmail.com  Thu Jun  1 00:57:07 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 31 May 2006 21:57:07 -0700
Subject: [concurrency-interest] Contract of
	java.io.OutputStream.write(byte b[])
In-Reply-To: <aa067ea10605312023u6fc732f0pcd58a4a4d8f814dc@mail.gmail.com>
References: <1149114801.15211.189.camel@scrub>
	<E16E3782-0640-4E17-9922-5D028DA1C171@cs.umd.edu>
	<aa067ea10605312023u6fc732f0pcd58a4a4d8f814dc@mail.gmail.com>
Message-ID: <31f2a7bd0605312157r397da541o229cd0042be6e2f@mail.gmail.com>

At the risk of drifting away from the original question, in which
locking of the output stream was the stated goal... see comments
below.

On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

> I would also suggest using wait() and notify() for deterministic
> synchronization at the producer level (user of the outputstream)
> as opposed to a synchronized block unless the latter is more
> appropriate (optimistic stream writes).

Can you explain further?

While I don't advocate upgrading every "synchronized" to some form of
java.util.concurrent.locks.Lock:

  New lock classes improve on synchronized -- but don't replace it
  http://www-128.ibm.com/developerworks/java/library/j-jtp10264/

I *do* advocate stamping-out all explicit obj.wait()s and
obj.notify()s.  Given all the tools in java.util.concurrent, there's
got to be something better already implemented.


If clean code is the goal, my preference is to avoid explicit locking
in favor or queueing.

In other words, producers insert their byte[]s onto a thread-safe
queue, while an outputter thread pulls byte[]s from the queue and
writes them to the stream.  This separation of concerns results in
very clean code. Furthermore, several flavors of queue have already
been implemented in java.util.concurrent.

--Joe


On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> On 6/1/06, Bill Pugh <pugh at cs.umd.edu> wrote:
> > The fact that many of the implementations of OutputStream are
> > synchronized was
> > a pretty horrible design mistake.
> >
> > If you have two different threads trying to push bytes into an output
> > stream, I'm hard pressed to
> > imagine situations in which allowing the threads to non-
> > deterministically interleave is a good idea.
> >
> > If you are creating your own implementation of OutputStream, I would
> > recommending avoiding any
> > use of synchronization. It serves no purpose, reduces performance,
> > and I don't believe the class
> > contract (or Sun's TCK tests) require it.
>
> that sounds quite sensible.
> I would also suggest using wait() and notify() for deterministic
> synchronization at the producer level (user of the outputstream) as
> opposed to a synchronized block unless the latter is more appropriate
> (optimistic stream writes).
> In any case isnt it better practise to synchronize on a buffer and
> allow only one thread access to the underlying outputstream?
>
> >
> >         Bill Pugh
> >
> >
> > On May 31, 2006, at 6:33 PM, Elias Ross wrote:
> >
> > >
> > > I know this isn't really the forum for asking this, but I've spent a
> > > number of hours looking into a definite yes or no...
> > >
> > > I wanted to know if OutputStream.write(byte b[]) was considered
> > > atomic.
> > > If two threads are writing to the same file, would the output from
> > > OS.write(...) overlap with another OS.write(...)?
> > >
> > > I eventually downloaded the Java source to answer this question.  The
> > > JavaDoc did not specify.  As it turns out, the answer is "no" -- which
> > > is something that you'd only be able to determine by looking at the C
> > > source code for the native calls.
> > >
> > > The JDK interpretation of write() is slightly different than the UNIX
> > > one, which looks like this:
> > >
> > >        ssize_t write(int fd, const void *buf, size_t count);
> > >
> > > so it makes sense that a Java write() call may have to do more than
> > > one
> > > system write() call.
> > >
> > > I wonder if there some better way that "concurrent" and "atomic"
> > > methods
> > > can be documented in the JDK?  It's also very helpful as a user to
> > > know
> > > if I should be locking on the OutputStream itself or create my own
> > > locks.
> > >
> >
>

From dhanji at gmail.com  Thu Jun  1 02:26:42 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 1 Jun 2006 16:26:42 +1000
Subject: [concurrency-interest] Contract of
	java.io.OutputStream.write(byte b[])
In-Reply-To: <31f2a7bd0605312157r397da541o229cd0042be6e2f@mail.gmail.com>
References: <1149114801.15211.189.camel@scrub>
	<E16E3782-0640-4E17-9922-5D028DA1C171@cs.umd.edu>
	<aa067ea10605312023u6fc732f0pcd58a4a4d8f814dc@mail.gmail.com>
	<31f2a7bd0605312157r397da541o229cd0042be6e2f@mail.gmail.com>
Message-ID: <aa067ea10605312326t33c3396fib2ed25fcb23e6159@mail.gmail.com>

On 6/1/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> At the risk of drifting away from the original question, in which
> locking of the output stream was the stated goal... see comments
> below.
>
> On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
>
> > I would also suggest using wait() and notify() for deterministic
> > synchronization at the producer level (user of the outputstream)
> > as opposed to a synchronized block unless the latter is more
> > appropriate (optimistic stream writes).
>
> Can you explain further?
>
> While I don't advocate upgrading every "synchronized" to some form of
> java.util.concurrent.locks.Lock:
>

wait(), notify() offers a simple way of ordering behavior in a
producer-consumer couple. That's all I meant. synchronized() will
yield non-deterministic behavior with regard to the order of the
queue/buffer as has been noted elsewhere in this thread.

>   New lock classes improve on synchronized -- but don't replace it
>   http://www-128.ibm.com/developerworks/java/library/j-jtp10264/
>
> I *do* advocate stamping-out all explicit obj.wait()s and
> obj.notify()s.  Given all the tools in java.util.concurrent, there's
> got to be something better already implemented.
>

Correct me if I'm wrong but to my understanding
java.util.concurrent.locks is an extended, more flexible toolkit for
concurrency (for situations such as releasing locks in non-lexical
strictness) and not a replacement for the language basics, whether
synchronized or wait/notify.
The 1.5 javadoc for java.util.concurrent.locks.Lock says something to
this effect.

Or am I totally on the wrong trail to oregon (the one that goes via
mexico ;)--are you suggesting deprecation of wait() and notify()
altogether?

>
> If clean code is the goal, my preference is to avoid explicit locking
> in favor or queueing.
>

I completely agree with this. Explicit locking should be hidden by the
api with threadsafe/concurrent queues. At the risk of drifting
(along), my point above is for academic or other areas where
threadsafe queues may not be feasible (like soft realtime apps).

> In other words, producers insert their byte[]s onto a thread-safe
> queue, while an outputter thread pulls byte[]s from the queue and
> writes them to the stream.  This separation of concerns results in
> very clean code. Furthermore, several flavors of queue have already
> been implemented in java.util.concurrent.
>
> --Joe
>
>
> On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> > On 6/1/06, Bill Pugh <pugh at cs.umd.edu> wrote:
> > > The fact that many of the implementations of OutputStream are
> > > synchronized was
> > > a pretty horrible design mistake.
> > >
> > > If you have two different threads trying to push bytes into an output
> > > stream, I'm hard pressed to
> > > imagine situations in which allowing the threads to non-
> > > deterministically interleave is a good idea.
> > >
> > > If you are creating your own implementation of OutputStream, I would
> > > recommending avoiding any
> > > use of synchronization. It serves no purpose, reduces performance,
> > > and I don't believe the class
> > > contract (or Sun's TCK tests) require it.
> >
> > that sounds quite sensible.
> > I would also suggest using wait() and notify() for deterministic
> > synchronization at the producer level (user of the outputstream) as
> > opposed to a synchronized block unless the latter is more appropriate
> > (optimistic stream writes).
> > In any case isnt it better practise to synchronize on a buffer and
> > allow only one thread access to the underlying outputstream?
> >
> > >
> > >         Bill Pugh
> > >
> > >
> > > On May 31, 2006, at 6:33 PM, Elias Ross wrote:
> > >
> > > >
> > > > I know this isn't really the forum for asking this, but I've spent a
> > > > number of hours looking into a definite yes or no...
> > > >
> > > > I wanted to know if OutputStream.write(byte b[]) was considered
> > > > atomic.
> > > > If two threads are writing to the same file, would the output from
> > > > OS.write(...) overlap with another OS.write(...)?
> > > >
> > > > I eventually downloaded the Java source to answer this question.  The
> > > > JavaDoc did not specify.  As it turns out, the answer is "no" -- which
> > > > is something that you'd only be able to determine by looking at the C
> > > > source code for the native calls.
> > > >
> > > > The JDK interpretation of write() is slightly different than the UNIX
> > > > one, which looks like this:
> > > >
> > > >        ssize_t write(int fd, const void *buf, size_t count);
> > > >
> > > > so it makes sense that a Java write() call may have to do more than
> > > > one
> > > > system write() call.
> > > >
> > > > I wonder if there some better way that "concurrent" and "atomic"
> > > > methods
> > > > can be documented in the JDK?  It's also very helpful as a user to
> > > > know
> > > > if I should be locking on the OutputStream itself or create my own
> > > > locks.
> > > >
> > >
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From joe.bowbeer at gmail.com  Thu Jun  1 02:44:30 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 31 May 2006 23:44:30 -0700
Subject: [concurrency-interest] Contract of
	java.io.OutputStream.write(byte b[])
In-Reply-To: <aa067ea10605312326t33c3396fib2ed25fcb23e6159@mail.gmail.com>
References: <1149114801.15211.189.camel@scrub>
	<E16E3782-0640-4E17-9922-5D028DA1C171@cs.umd.edu>
	<aa067ea10605312023u6fc732f0pcd58a4a4d8f814dc@mail.gmail.com>
	<31f2a7bd0605312157r397da541o229cd0042be6e2f@mail.gmail.com>
	<aa067ea10605312326t33c3396fib2ed25fcb23e6159@mail.gmail.com>
Message-ID: <31f2a7bd0605312344g276524e6n5039abf176b310a6@mail.gmail.com>

On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:

> are you suggesting deprecation of wait() and notify() altogether?

I wouldn't say "deprecate".  What I would say is that I advise against
their use :-)

There's very little need for anyone to write code that calls these
low-level methods, and when they do there are almost always bugs.
(Show me a wait and a notify and I'll show you a bug -- it almost
never fails!)

I would prefer that a higher level construct were used, such as a
Queue or Future or even an explicit Condition:

http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/locks/Condition.html


On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> On 6/1/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > At the risk of drifting away from the original question, in which
> > locking of the output stream was the stated goal... see comments
> > below.
> >
> > On 5/31/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> >
> > > I would also suggest using wait() and notify() for deterministic
> > > synchronization at the producer level (user of the outputstream)
> > > as opposed to a synchronized block unless the latter is more
> > > appropriate (optimistic stream writes).
> >
> > Can you explain further?
> >
> > While I don't advocate upgrading every "synchronized" to some form of
> > java.util.concurrent.locks.Lock:
> >
>
> wait(), notify() offers a simple way of ordering behavior in a
> producer-consumer couple. That's all I meant. synchronized() will
> yield non-deterministic behavior with regard to the order of the
> queue/buffer as has been noted elsewhere in this thread.
>
> >   New lock classes improve on synchronized -- but don't replace it
> >   http://www-128.ibm.com/developerworks/java/library/j-jtp10264/
> >
> > I *do* advocate stamping-out all explicit obj.wait()s and
> > obj.notify()s.  Given all the tools in java.util.concurrent, there's
> > got to be something better already implemented.
> >
>
> Correct me if I'm wrong but to my understanding
> java.util.concurrent.locks is an extended, more flexible toolkit for
> concurrency (for situations such as releasing locks in non-lexical
> strictness) and not a replacement for the language basics, whether
> synchronized or wait/notify.
> The 1.5 javadoc for java.util.concurrent.locks.Lock says something to
> this effect.
>
> Or am I totally on the wrong trail to oregon (the one that goes via
> mexico ;)--are you suggesting deprecation of wait() and notify()
> altogether?
>
> >
> > If clean code is the goal, my preference is to avoid explicit locking
> > in favor or queueing.
> >
>
> I completely agree with this. Explicit locking should be hidden by the
> api with threadsafe/concurrent queues. At the risk of drifting
> (along), my point above is for academic or other areas where
> threadsafe queues may not be feasible (like soft realtime apps).
>
> > In other words, producers insert their byte[]s onto a thread-safe
> > queue, while an outputter thread pulls byte[]s from the queue and
> > writes them to the stream.  This separation of concerns results in
> > very clean code. Furthermore, several flavors of queue have already
> > been implemented in java.util.concurrent.
> >
> > --Joe
> >

From pete at soper.us  Thu Jun  1 04:05:38 2006
From: pete at soper.us (Pete Soper)
Date: Thu, 01 Jun 2006 04:05:38 -0400
Subject: [concurrency-interest] Request for comment -- weakCompareAndSet
 specs
In-Reply-To: <447C2EBF.6030509@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCOEPKGOAA.dcholmes@optusnet.com.au>	<447A7D4E.6000602@quiotix.com>	<A5C12CF8-5B00-434C-B1B3-334AA65B66C8@cs.umd.edu>	<Pine.GHP.4.58.0605292126220.2321@tomil.hpl.hp.com>
	<447C2EBF.6030509@cs.oswego.edu>
Message-ID: <447E9FD2.7080603@soper.us>

Hi Doug,
> I also summarized this in each AtomicX.weakCompareAndSet method
> javadoc, as:
>       * May fail spuriously and does not provide ordering guarantees,
>       * so is only rarely an appropriate alternative to <tt>compareAndSet</tt>.
>   
Would it uglify the method docs too much to make "fail spuriously" a 
hyperlink to an anchor in the package doc?

-Pete


From forax at univ-mlv.fr  Thu Jun  1 04:51:55 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Thu, 01 Jun 2006 10:51:55 +0200
Subject: [concurrency-interest] SwingWorker a special producer/consumer
Message-ID: <447EAAAB.8070200@univ-mlv.fr>

Yesterday, i found a bug in the Sun implementation of the SwingWorker :
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6432565

Basically a swing worker permits to create a worker thread for
a long duration job that need to perform some refresh of the
swing ui without freezing the application.

Because only the Event Dispatch Thread can change the
swing UI, the worker thread publish data and
the EDT consume them.
see http://download.java.net/jdk6/docs/api/javax/swing/SwingWorker.html

It's a special producer/consumer because the EDT consume
all the available data in once.

Which data structure should be used in that case ?

R?mi Forax





From gregg at cytetech.com  Thu Jun  1 08:32:52 2006
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 01 Jun 2006 07:32:52 -0500
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <447EAAAB.8070200@univ-mlv.fr>
References: <447EAAAB.8070200@univ-mlv.fr>
Message-ID: <447EDE74.7070100@cytetech.com>



R?mi Forax wrote:
> Yesterday, i found a bug in the Sun implementation of the SwingWorker :
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6432565

That bug is not visible yet, can you give specifics?

Gregg Wonderly


From Pete.Soper at Sun.COM  Thu Jun  1 16:25:06 2006
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Thu, 01 Jun 2006 16:25:06 -0400
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <447EDE74.7070100@cytetech.com>
References: <447EAAAB.8070200@univ-mlv.fr> <447EDE74.7070100@cytetech.com>
Message-ID: <447F4D22.2040107@Sun.COM>

Hi R?mi,
	Nice to see your mail again. Are you looking for a suggestion for a 
thread-safe queue or the like to pass stuff between your EDT and your 
main thread?

Regards,
Pete

Gregg Wonderly wrote:
> 
> R?mi Forax wrote:
> 
>>Yesterday, i found a bug in the Sun implementation of the SwingWorker :
>>http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6432565
> 
> 
> That bug is not visible yet, can you give specifics?

Still in dispatch:

FULL PRODUCT VERSION :
java version "1.6.0-beta2"
Java(TM) SE Runtime Environment (build 1.6.0-beta2-b85)
Java HotSpot(TM) Client VM (build 1.6.0-beta2-b85, mixed mode, sharing)


ADDITIONAL OS VERSION INFORMATION :
Linux localhost.localdomain 2.6.15-1.1833_FC4 #1 Wed Mar 1 23:41:37 EST 
2006 i686 i686 i386 GNU/Linux


A DESCRIPTION OF THE PROBLEM :
The EDT (Event dispatch Thread) raises a ClassCastException
with the code below.

Data published by doInBackground() are stored in a list
and then converted in an array and send to method process()
in order to reduce synchronization time between EDT and worker thread.

The problem is to determine the class of the array passed to the process()
method at runtime. Because generics are erased, the class of V is not
available. The current implementation use the class of the array passed
as argument of the first call of the method publish() . This is clearly 
wrong.

Two solutions :
   - don't use an array in the signature of process() but use a List instead
   - take the class of V in the constructor.
     public SwingWorker(Class<T> tClass) {...}

Note : i had reviewed the SwingWorker code when it was integrated to
mustang (i think a year ago), it troubles me because
it mix runtime type and generics but i was not able to produce a test case
that show my insight until today.
So the test case is not issue from a real application.

R?mi Forax

STEPS TO FOLLOW TO REPRODUCE THE PROBLEM :
run the code

EXPECTED VERSUS ACTUAL BEHAVIOR :
EXPECTED -
it should work
ACTUAL -
it throws a ClassCastException

ERROR MESSAGES/STACK TRACES THAT OCCUR :
Exception in thread "AWT-EventQueue-0" java.lang.ArrayStoreException
	at java.lang.System.arraycopy(Native Method)
	at java.util.ArrayList.toArray(ArrayList.java:306)
	at sun.swing.AccumulativeRunnable.flush(AccumulativeRunnable.java:148)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:96)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:209)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:598)
	at 
java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:273)
	at 
java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:183)
	at 
java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:173)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:168)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:160)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:121)


REPRODUCIBILITY :
This bug can be reproduced always.

---------- BEGIN SOURCE ----------
import javax.swing.SwingWorker;

public class SwingWorkerTest {
     public static void main(String[] args) {
       new SwingWorker<Void,CharSequence>() {
         @Override
         protected Void doInBackground() {
           publish(new String[] {"hello"});
           publish(new StringBuilder("world"));
           return null;
         }
       }.execute();
     }
}

---------- END SOURCE ----------

CUSTOMER SUBMITTED WORKAROUND :
Add this line
publish(new CharSequence[0]);
as the first line of doInBackground().
*** (#1 of 1): 2006-05-31 19:56:56 EDT *.*@sun.com



From forax at univ-mlv.fr  Fri Jun  2 04:25:33 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 02 Jun 2006 10:25:33 +0200
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <447F4D22.2040107@Sun.COM>
References: <447EAAAB.8070200@univ-mlv.fr> <447EDE74.7070100@cytetech.com>
	<447F4D22.2040107@Sun.COM>
Message-ID: <447FF5FD.1090807@univ-mlv.fr>

Pete Soper a ?crit :

> Hi R?mi,
>     Nice to see your mail again. Are you looking for a suggestion for 
> a thread-safe queue or the like to pass stuff between your EDT and 
> your main thread?
>
> Regards,
> Pete

The bug reported is not a concurrency bug but
because the implementation must be changed
perhaps the signature of the process() method
can be changed to take a thread safe List or a Queue.

The SwingWorker is clearly a producer/consumer problem :
- i want to put arrays of values (V)
- i want to take all the values in one call.
all in a thread safe way.

The question is what is the best concurrent data structure
for this job.

R?mi Forax

>
> Gregg Wonderly wrote:
>
>>
>> R?mi Forax wrote:
>>
>>> Yesterday, i found a bug in the Sun implementation of the SwingWorker :
>>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6432565
>>
>>
>>
>> That bug is not visible yet, can you give specifics?
>
>
> Still in dispatch:
>
> FULL PRODUCT VERSION :
> java version "1.6.0-beta2"
> Java(TM) SE Runtime Environment (build 1.6.0-beta2-b85)
> Java HotSpot(TM) Client VM (build 1.6.0-beta2-b85, mixed mode, sharing)
>
>
> ADDITIONAL OS VERSION INFORMATION :
> Linux localhost.localdomain 2.6.15-1.1833_FC4 #1 Wed Mar 1 23:41:37 
> EST 2006 i686 i686 i386 GNU/Linux
>
>
> A DESCRIPTION OF THE PROBLEM :
> The EDT (Event dispatch Thread) raises a ClassCastException
> with the code below.
>
> Data published by doInBackground() are stored in a list
> and then converted in an array and send to method process()
> in order to reduce synchronization time between EDT and worker thread.
>
> The problem is to determine the class of the array passed to the 
> process()
> method at runtime. Because generics are erased, the class of V is not
> available. The current implementation use the class of the array passed
> as argument of the first call of the method publish() . This is 
> clearly wrong.
>
> Two solutions :
>   - don't use an array in the signature of process() but use a List 
> instead
>   - take the class of V in the constructor.
>     public SwingWorker(Class<T> tClass) {...}
>
> Note : i had reviewed the SwingWorker code when it was integrated to
> mustang (i think a year ago), it troubles me because
> it mix runtime type and generics but i was not able to produce a test 
> case
> that show my insight until today.
> So the test case is not issue from a real application.
>
> R?mi Forax
>
> STEPS TO FOLLOW TO REPRODUCE THE PROBLEM :
> run the code
>
> EXPECTED VERSUS ACTUAL BEHAVIOR :
> EXPECTED -
> it should work
> ACTUAL -
> it throws a ClassCastException
>
> ERROR MESSAGES/STACK TRACES THAT OCCUR :
> Exception in thread "AWT-EventQueue-0" java.lang.ArrayStoreException
>     at java.lang.System.arraycopy(Native Method)
>     at java.util.ArrayList.toArray(ArrayList.java:306)
>     at 
> sun.swing.AccumulativeRunnable.flush(AccumulativeRunnable.java:148)
>     at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:96)
>     at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:209)
>     at java.awt.EventQueue.dispatchEvent(EventQueue.java:598)
>     at 
> java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:273) 
>
>     at 
> java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:183) 
>
>     at 
> java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:173) 
>
>     at 
> java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:168)
>     at 
> java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:160)
>     at java.awt.EventDispatchThread.run(EventDispatchThread.java:121)
>
>
> REPRODUCIBILITY :
> This bug can be reproduced always.
>
> ---------- BEGIN SOURCE ----------
> import javax.swing.SwingWorker;
>
> public class SwingWorkerTest {
>     public static void main(String[] args) {
>       new SwingWorker<Void,CharSequence>() {
>         @Override
>         protected Void doInBackground() {
>           publish(new String[] {"hello"});
>           publish(new StringBuilder("world"));
>           return null;
>         }
>       }.execute();
>     }
> }
>
> ---------- END SOURCE ----------
>
> CUSTOMER SUBMITTED WORKAROUND :
> Add this line
> publish(new CharSequence[0]);
> as the first line of doInBackground().
> *** (#1 of 1): 2006-05-31 19:56:56 EDT *.*@sun.com




From joe.bowbeer at gmail.com  Fri Jun  2 07:20:15 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 2 Jun 2006 04:20:15 -0700
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <447FF5FD.1090807@univ-mlv.fr>
References: <447EAAAB.8070200@univ-mlv.fr> <447EDE74.7070100@cytetech.com>
	<447F4D22.2040107@Sun.COM> <447FF5FD.1090807@univ-mlv.fr>
Message-ID: <31f2a7bd0606020420x4f72a074wadbd02842338e1cb@mail.gmail.com>

On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
>
> The question is what is the best concurrent data structure
> for this job.
>

I'm looking at the source at https://swingworker.dev.java.net/

Is this sufficiently current?

If so, SwingWorker enqueues AccumulativeRunnable instances on the AWT
EventQueue by way of the SwingUtilities.invokeLater() method.

AccumulativeRunnable holds the accumulated arguments in an
ArrayList<T> and synchronizes internally.  So there's no need to pass
a thread-safe data structure to the process() method -- because
thread-safety is already handled by the SwingWorker internals.

I interpret the details as:

When the submitted runnable is executed on the event thread, it grabs
the existing elements from the internal ArrayList and calls the
run(T... args) method.  These elements are grabbed by the flush()
method.  The elements were added by the add() method.  Both methods
are synchronized.  In this way one or more process(V... chunks) calls
on the worker thread translate into a single run(T... args) call on
the event thread.

Are you proposing removing the synchronization from
AccumulativeRunnable and replacing it with some kind of thread-safe
collection?


On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
> Pete Soper a ?crit :
>
> > Hi R?mi,
> >     Nice to see your mail again. Are you looking for a suggestion for
> > a thread-safe queue or the like to pass stuff between your EDT and
> > your main thread?
> >
> > Regards,
> > Pete
>
> The bug reported is not a concurrency bug but
> because the implementation must be changed
> perhaps the signature of the process() method
> can be changed to take a thread safe List or a Queue.
>
> The SwingWorker is clearly a producer/consumer problem :
> - i want to put arrays of values (V)
> - i want to take all the values in one call.
> all in a thread safe way.
>
> The question is what is the best concurrent data structure
> for this job.
>
> R?mi Forax
>
> >
> > Gregg Wonderly wrote:
> >
> >>
> >> R?mi Forax wrote:
> >>
> >>> Yesterday, i found a bug in the Sun implementation of the SwingWorker :
> >>> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6432565
> >>
> >>
> >>
> >> That bug is not visible yet, can you give specifics?
> >
> >
> > Still in dispatch:
> >
> > FULL PRODUCT VERSION :
> > java version "1.6.0-beta2"
> > Java(TM) SE Runtime Environment (build 1.6.0-beta2-b85)
> > Java HotSpot(TM) Client VM (build 1.6.0-beta2-b85, mixed mode, sharing)
> >
> >
> > ADDITIONAL OS VERSION INFORMATION :
> > Linux localhost.localdomain 2.6.15-1.1833_FC4 #1 Wed Mar 1 23:41:37
> > EST 2006 i686 i686 i386 GNU/Linux
> >
> >
> > A DESCRIPTION OF THE PROBLEM :
> > The EDT (Event dispatch Thread) raises a ClassCastException
> > with the code below.
> >
> > Data published by doInBackground() are stored in a list
> > and then converted in an array and send to method process()
> > in order to reduce synchronization time between EDT and worker thread.
> >
> > The problem is to determine the class of the array passed to the
> > process()
> > method at runtime. Because generics are erased, the class of V is not
> > available. The current implementation use the class of the array passed
> > as argument of the first call of the method publish() . This is
> > clearly wrong.
> >
> > Two solutions :
> >   - don't use an array in the signature of process() but use a List
> > instead
> >   - take the class of V in the constructor.
> >     public SwingWorker(Class<T> tClass) {...}
> >
> > Note : i had reviewed the SwingWorker code when it was integrated to
> > mustang (i think a year ago), it troubles me because
> > it mix runtime type and generics but i was not able to produce a test
> > case
> > that show my insight until today.
> > So the test case is not issue from a real application.
> >
> > R?mi Forax
> >
> > STEPS TO FOLLOW TO REPRODUCE THE PROBLEM :
> > run the code
> >
> > EXPECTED VERSUS ACTUAL BEHAVIOR :
> > EXPECTED -
> > it should work
> > ACTUAL -
> > it throws a ClassCastException
> >
> > ERROR MESSAGES/STACK TRACES THAT OCCUR :
> > Exception in thread "AWT-EventQueue-0" java.lang.ArrayStoreException
> >     at java.lang.System.arraycopy(Native Method)
> >     at java.util.ArrayList.toArray(ArrayList.java:306)
> >     at
> > sun.swing.AccumulativeRunnable.flush(AccumulativeRunnable.java:148)
> >     at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:96)
> >     at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:209)
> >     at java.awt.EventQueue.dispatchEvent(EventQueue.java:598)
> >     at
> > java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:273)
> >
> >     at
> > java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:183)
> >
> >     at
> > java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:173)
> >
> >     at
> > java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:168)
> >     at
> > java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:160)
> >     at java.awt.EventDispatchThread.run(EventDispatchThread.java:121)
> >
> >
> > REPRODUCIBILITY :
> > This bug can be reproduced always.
> >
> > ---------- BEGIN SOURCE ----------
> > import javax.swing.SwingWorker;
> >
> > public class SwingWorkerTest {
> >     public static void main(String[] args) {
> >       new SwingWorker<Void,CharSequence>() {
> >         @Override
> >         protected Void doInBackground() {
> >           publish(new String[] {"hello"});
> >           publish(new StringBuilder("world"));
> >           return null;
> >         }
> >       }.execute();
> >     }
> > }
> >
> > ---------- END SOURCE ----------
> >
> > CUSTOMER SUBMITTED WORKAROUND :
> > Add this line
> > publish(new CharSequence[0]);
> > as the first line of doInBackground().
> > *** (#1 of 1): 2006-05-31 19:56:56 EDT *.*@sun.com
>


From forax at univ-mlv.fr  Fri Jun  2 08:03:28 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 02 Jun 2006 14:03:28 +0200
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <31f2a7bd0606020420x4f72a074wadbd02842338e1cb@mail.gmail.com>
References: <447EAAAB.8070200@univ-mlv.fr>
	<447EDE74.7070100@cytetech.com>	<447F4D22.2040107@Sun.COM>
	<447FF5FD.1090807@univ-mlv.fr>
	<31f2a7bd0606020420x4f72a074wadbd02842338e1cb@mail.gmail.com>
Message-ID: <44802910.3090202@univ-mlv.fr>

Joe Bowbeer a ?crit :

>On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
>  
>
>>The question is what is the best concurrent data structure
>>for this job.
>>
>>    
>>
>
>I'm looking at the source at https://swingworker.dev.java.net/
>  
>
it seems to be the same code.

>Is this sufficiently current?
>  
>
>If so, SwingWorker enqueues AccumulativeRunnable instances on the AWT
>EventQueue by way of the SwingUtilities.invokeLater() method.
>
>AccumulativeRunnable holds the accumulated arguments in an
>ArrayList<T> and synchronizes internally.  So there's no need to pass
>a thread-safe data structure to the process() method -- because
>thread-safety is already handled by the SwingWorker internals.
>
>I interpret the details as:
>
>When the submitted runnable is executed on the event thread, it grabs
>the existing elements from the internal ArrayList and calls the
>run(T... args) method.  These elements are grabbed by the flush()
>method.  The elements were added by the add() method.  Both methods
>are synchronized.  In this way one or more process(V... chunks) calls
>on the worker thread translate into a single run(T... args) call on
>the event thread.
>  
>
yes

>Are you proposing removing the synchronization from
>AccumulativeRunnable and replacing it with some kind of thread-safe
>collection?
>  
>
Yes.
The bug is due to the fact that there is no way to generate an array of 
T without
explicitly indicate the class of T.

One way to correct the bug is to change the signature of the run method
to run(List<T> args) or run(Queue<T> args).
In this case, its perhaps interresting to use a thread safe collection.

In perhaps it's a bad idea, i don't know, that why i ask for experts.

R?mi Forax




From joe.bowbeer at gmail.com  Fri Jun  2 09:30:01 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 2 Jun 2006 06:30:01 -0700
Subject: [concurrency-interest] SwingWorker a special producer/consumer
In-Reply-To: <44802910.3090202@univ-mlv.fr>
References: <447EAAAB.8070200@univ-mlv.fr> <447EDE74.7070100@cytetech.com>
	<447F4D22.2040107@Sun.COM> <447FF5FD.1090807@univ-mlv.fr>
	<31f2a7bd0606020420x4f72a074wadbd02842338e1cb@mail.gmail.com>
	<44802910.3090202@univ-mlv.fr>
Message-ID: <31f2a7bd0606020630n4e5a9afg9e152a75fb0d472b@mail.gmail.com>

On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
>
> The bug is due to the fact that there is no way to generate an array of
> T without explicitly indicate the class of T.
>
> One way to correct the bug is to change the signature of the run method
> to run(List<T> args) or run(Queue<T> args).
> In this case, its perhaps interresting to use a thread safe collection.
>

I think safe coding practices would dictate that the elements be
copied on their way into the AccumulativeRunnable from SwingWorker's
publish(V... chunks) method.

Likewise, I think safe coding practices would dictate that the
elements be copied on their way out of the AccumulativeRunnable into
SwingWorker's process(V... chunks) method.

The still leaves the question of whether AccumulativeRunnable
could/should use a concurrent collection instead of an externally
synchronized collection.

Attempting this in the most straightforward way would require that the
concurrent collection support atomic bulk operations such as
addAll(list) and drainTo(list), but the addAll method is not atomic
(AFAIK) and there is no drainTo method...

--Joe

On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
> Joe Bowbeer a ?crit :
>
> >On 6/2/06, R?mi Forax <forax at univ-mlv.fr> wrote:
> >
> >
> >>The question is what is the best concurrent data structure
> >>for this job.
> >>
> >>
> >>
> >
> >I'm looking at the source at https://swingworker.dev.java.net/
> >
> >
> it seems to be the same code.
>
> >Is this sufficiently current?
> >
> >
> >If so, SwingWorker enqueues AccumulativeRunnable instances on the AWT
> >EventQueue by way of the SwingUtilities.invokeLater() method.
> >
> >AccumulativeRunnable holds the accumulated arguments in an
> >ArrayList<T> and synchronizes internally.  So there's no need to pass
> >a thread-safe data structure to the process() method -- because
> >thread-safety is already handled by the SwingWorker internals.
> >
> >I interpret the details as:
> >
> >When the submitted runnable is executed on the event thread, it grabs
> >the existing elements from the internal ArrayList and calls the
> >run(T... args) method.  These elements are grabbed by the flush()
> >method.  The elements were added by the add() method.  Both methods
> >are synchronized.  In this way one or more process(V... chunks) calls
> >on the worker thread translate into a single run(T... args) call on
> >the event thread.
> >
> >
> yes
>
> >Are you proposing removing the synchronization from
> >AccumulativeRunnable and replacing it with some kind of thread-safe
> >collection?
> >
> >
> Yes.
> The bug is due to the fact that there is no way to generate an array of
> T without
> explicitly indicate the class of T.
>
> One way to correct the bug is to change the signature of the run method
> to run(List<T> args) or run(Queue<T> args).
> In this case, its perhaps interresting to use a thread safe collection.
>
> In perhaps it's a bad idea, i don't know, that why i ask for experts.
>
> R?mi Forax
>


From gluck at gregluck.com  Fri Jun  2 17:02:59 2006
From: gluck at gregluck.com (Greg Luck)
Date: Sat, 3 Jun 2006 07:02:59 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of Mutex
	lock objects
Message-ID: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>

Hi

(I mailed this initially to Doug Lea. He is travelling at present and  
suggested I post it here for a quicker response).

I am the maintainer of ehcache, a leading open source project, and  
probably the most used Java cache. I have also just joined JSR-107  
and am working towards making ehcache an implementation of this spec.  
I also have a copy of Concurrent Programming in Java, Second Edition.

A few years ago we had a serious  problem with scalability caused by  
extreme contention on synchronized methods on BlockingCache. We  
redesigned it to use fined grained Mutex objects, from your  
concurrency package, in a Map of locks, keyed by possible cache keys.  
The class is listed below. The scalability went up by an order of  
magnitude. Problem solved.

However, some very careful users have discovered a problem. Once a  
Mutex object is placed in the Map it stays there forever. It is  
technically a slow memory leak unless the keyset is bounded so that  
at some time it stops growing.
Users are also complaining of slow garbage collection times because  
of the millions of Mutex objects they end up with.

I am not sure what the solution here is. I don't think I can simply  
remove them because I don't know if they are in use, or more subtly,  
whether a caller is holding a reference waiting to acquire a lock and  
put the Mutex into use. If I remove one from the lock Map a new  
caller will put a new one in the Map with the same key. I could have  
the situation where more than one thread things it has the same lock.

I am thinking perhaps a pool of locks but I need to work out how to  
safely reuse the pool. Something close to the Pool discussed in  
Section 3.4.1.2 is probably what I need.

Any thoughts you have on this would be most appreciated by myself and  
my user community.

/**
* A blocking cache, backed by {@link Ehcache}.
* <p/>
* It allows concurrent read access to elements already in the cache.  
If the element is null, other
* reads will block until an element with the same key is put into the  
cache.
* <p/>
* This is useful for constructing read-through or self-populating  
caches.
* <p/>
* This implementation uses the {@link Mutex} class from Doug Lea's  
concurrency package. If you wish to use
* this class, you will need the concurrent package in your class path.
* <p/>
* It features:
* <ul>
* <li>Excellent liveness.
* <li>Fine-grained locking on each element, rather than the cache as  
a whole.
* <li>Scalability to a large number of threads.
* </ul>
* <p/>
* A version of this class is planned which will dynamically use  
JDK5's concurrency package, which is
* based on Doug Lea's, so as to avoid a dependency on his package for  
JDK5 systems. This will not
* be implemented until JDK5 is released on MacOSX and Linux, as JDK5  
will be required to compile
* it, though any version from JDK1.2 up will be able to run the code,  
falling back to Doug
* Lea's concurrency package, if the JDK5 package is not found in the  
classpath.
* <p/>
* The <code>Mutex</code> class does not appear in the JDK5  
concurrency package. Doug Lea has
* generously offered the following advice:
* <p/>
* <pre>
* You should just be able to use ReentrantLock here.  We supply
* ReentrantLock, but not Mutex because the number of cases where a
* non-reentrant mutex is preferable is small, and most people are more
* familiar with reentrant seamantics. If you really need a non-reentrant
* one, the javadocs for class AbstractQueuedSynchronizer include sample
* code for them.
* <p/>
* -Doug
* </pre>
* <p/>
*
* @author Greg Luck
* @version $Id: BlockingCache.java 94 2006-05-25 09:06:30Z gregluck $
*/
public class BlockingCache {

     private static final Log LOG = LogFactory.getLog 
(BlockingCache.class.getName());

     /**
      * The backing Cache
      */
     private final Ehcache cache;


     private final int timeoutMillis;

     /**
      * A map of cache entry locks, one per key, if present
      */
     private final Map locks = new HashMap();

     /**
      * Creates a BlockingCache with the given name.
      *
      * @param name the name to give the cache
      * @throws CacheException
      */
     public BlockingCache(final String name) throws CacheException {
         this(name, 0);
     }

     /**
      * Creates a BlockingCache with the given name.
      *
      * @param name          the name to give the cache
      * @param timeoutMillis the amount of time, in milliseconds, to  
block for
      * @throws CacheException
      * @since 1.2
      */
     public BlockingCache(final String name, int timeoutMillis)  
throws CacheException {
         CacheManager manager = null;
         try {
             manager = CacheManager.create();
         } catch (net.sf.ehcache.CacheException e) {
             LOG.fatal("CacheManager cannot be created. Cause was: "  
+ e.getMessage() + e);
             throw new CacheException("CacheManager cannot be  
created", e);
         }
         cache = manager.getCache(name);
         if (cache == null || !cache.getName().equals(name)) {
             throw new CacheException("Cache " + name + " cannot be  
retrieved. Please check ehcache.xml");
         }
         this.timeoutMillis = timeoutMillis;
     }

     /**
      * Creates a BlockingCache with the given name and
      * uses the given cache manager to create the cache
      *
      * @param name    the name to give the cache
      * @param manager the EHCache CacheManager used to create the  
backing cache
      * @throws CacheException
      */
     public BlockingCache(final String name, final CacheManager  
manager) throws CacheException {
         this(name, manager, 0);
     }

     /**
      * Creates a BlockingCache with the given name and
      * uses the given cache manager to create the cache
      *
      * @param name          the name to give the cache
      * @param manager       the EHCache CacheManager used to create  
the backing cache
      * @param timeoutMillis the amount of time, in milliseconds, to  
block for
      * @throws CacheException
      * @since 1.2
      */
     public BlockingCache(final String name, final CacheManager  
manager, int timeoutMillis) throws CacheException {
         if (manager == null) {
             throw new CacheException("CacheManager cannot be null");
         }
         cache = manager.getCache(name);
         if (cache == null || !cache.getName().equals(name)) {
             throw new CacheException("Cache " + name + " cannot be  
retrieved. Please check ehcache.xml");
         }
         this.timeoutMillis = timeoutMillis;
     }

     /**
      * Retrieve the EHCache backing cache
      */
     protected net.sf.ehcache.Ehcache getCache() {
         return cache;
     }

     /**
      * Returns this cache's name
      */
     public String getName() {
         return cache.getName();
     }

     /**
      * Looks up an entry.  Blocks if the entry is null.
      * Relies on the first thread putting an entry in, which  
releases the lock
      * If a put is not done, the lock is never released
      */
     public Serializable get(final Serializable key) throws  
BlockingCacheException {
         Mutex lock = checkLockExistsForKey(key);
         try {
             if (timeoutMillis == 0) {
                 lock.acquire();
             } else {
                 boolean acquired = lock.attempt(timeoutMillis);
                 if (!acquired) {
                     StringBuffer message = new StringBuffer("lock  
timeout attempting to acquire lock for key ")
                             .append(key).append(" on cache ").append 
(cache.getName());
                     throw new BlockingCacheException(message.toString 
());
                 }
             }
             final Element element = cache.get(key);
             if (element != null) {
                 //ok let the other threads in
                 lock.release();
                 return element.getValue();
             } else {
                 //don't release the read lock until we write
                 return null;
             }
         } catch (InterruptedException e) {
             throw new CacheException("Interrupted. Message was: " +  
e.getMessage());
         }
     }

     private synchronized Mutex checkLockExistsForKey(final  
Serializable key) {
         Mutex lock;
         lock = (Mutex) locks.get(key);
         if (lock == null) {
             lock = new Mutex();
             locks.put(key, lock);
         }
         return lock;
     }

     /**
      * Adds an entry and unlocks it
      */
     public void put(final Serializable key, final Serializable value) {
         Mutex lock = checkLockExistsForKey(key);
         try {
             if (value != null) {
                 final Element element = new Element(key, value);
                 cache.put(element);
             } else {
                 cache.remove(key);
             }
         } finally {
             //Release the readlock here. This will have been  
acquired in the get, where the element was null
             lock.release();
         }
     }

     /**
      * Returns the keys for this cache.
      *
      * @return The keys of this cache.  This is not a live set, so  
it will not track changes to the key set.
      */
     public Collection getKeys() throws CacheException {
         return cache.getKeys();
     }

     /**
      * Drops the contents of this cache.
      */
     public void clear() throws CacheException {
         if (LOG.isDebugEnabled()) {
             LOG.debug("Cache " + cache.getName() + ": removing all  
entries");
         }
         cache.removeAll();
     }

     /**
      * Synchronized version of getName to test liveness of the  
object lock.
      * <p/>
      * The time taken for this method to return is a useful measure  
of runtime contention on the cache.
      */
     public synchronized String liveness() {
         return getName();
     }

     /**
      * Gets all entries from a blocking cache. Cache is not  
serializable. This
      * method provides a way of accessing the keys and values of a  
Cache in a Serializable way e.g.
      * to return from a Remote call.
      * <p/>
      * This method may take a long time to return. It does not lock  
the cache. The list of entries is based
      * on a copy. The actual cache may have changed in the time  
between getting the list and gathering the
      * KeyValuePairs.
      * <p/>
      * This method can potentially return an extremely large object,  
roughly matching the memory taken by the cache
      * itself. Care should be taken before using this method.
      * <p/>
      * By getting all of the entries at once this method can  
transfer a whole cache with a single method call, which
      * is important for Remote calls across a network.
      *
      * @return a Serializable {@link java.util.List} of {@link  
KeyValuePair}s, which implement the Map.Entry interface
      * @throws CacheException where there is an error in the  
underlying cache
      */
     public List getEntries() throws CacheException {
         if (LOG.isDebugEnabled()) {
             LOG.debug("Getting entries for the " + cache.getName() +  
" cache");
         }
         Collection keys = cache.getKeys();
         List keyValuePairs = new ArrayList(keys.size());
         for (Iterator iterator = keys.iterator(); iterator.hasNext 
();) {
             Serializable key = (Serializable) iterator.next();
             Element element = cache.get(key);
             keyValuePairs.add(new KeyValuePair(key, element.getValue 
()));
         }
         return keyValuePairs;
     }
}



Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/55b307a3/attachment-0001.html 

From brian at quiotix.com  Fri Jun  2 17:52:06 2006
From: brian at quiotix.com (Brian Goetz)
Date: Fri, 02 Jun 2006 17:52:06 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
 Mutex	lock objects
In-Reply-To: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
Message-ID: <4480B306.2050905@quiotix.com>

> I am thinking perhaps a pool of locks but I need to work out how to 
> safely reuse the pool. Something close to the Pool discussed in Section 
> 3.4.1.2 is probably what I need.

Look at lock striping (JCiP 11.4.3), which is also used by 
ConcurrentHashMap.  It creates an array of locks (say, 16), and uses 
hashCode() % 16 to partition the keys across the set of locks.

From gluck at gregluck.com  Fri Jun  2 18:18:10 2006
From: gluck at gregluck.com (Greg Luck)
Date: Sat, 3 Jun 2006 08:18:10 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex	lock objects
In-Reply-To: <4480B306.2050905@quiotix.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
Message-ID: <D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>

Brian

That sounds good. I don't have a copy of JCiP so I bought one :) from  
Amazon. It will arrive between June 21 and July 3. I would appreciate  
any online or email stuff on lock striping in the meantime.
On 03/06/2006, at 7:52 AM, Brian Goetz wrote:

>> I am thinking perhaps a pool of locks but I need to work out how  
>> to safely reuse the pool. Something close to the Pool discussed in  
>> Section 3.4.1.2 is probably what I need.
>
> Look at lock striping (JCiP 11.4.3), which is also used by  
> ConcurrentHashMap.  It creates an array of locks (say, 16), and  
> uses hashCode() % 16 to partition the keys across the set of locks.
>



Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/40c063d3/attachment.html 

From brian at quiotix.com  Fri Jun  2 18:31:32 2006
From: brian at quiotix.com (Brian Goetz)
Date: Fri, 02 Jun 2006 18:31:32 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
 Mutex	lock objects
In-Reply-To: <D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
Message-ID: <4480BC44.7080700@quiotix.com>

> That sounds good. I don't have a copy of JCiP so I bought one :) from 
> Amazon. 

Guess all that "Jedi mind trick" practice is paying off :)

> It will arrive between June 21 and July 3. I would appreciate 
> any online or email stuff on lock striping in the meantime. 

Hashtable / synchronizedMap uses the "one big fat lock" approach to 
guard the mutable state of the map.  That works, but is a big 
concurrency bottleneck, as you've observed.  You went to the opposite 
extreme, one lock per key.  That works (as long as you've got sufficient 
synchronization in the cache itself to protect its own data structures.)

Lock striping is a middle ground, partitioning keys into a fixed number 
of subsets, like the trick used at large theaters for will-call ticket 
pickup -- there are separate lines for "A-F, G-M, N-R, and S-Z".  This 
way, there are a fixed number of locks, each guarding (hopefully) 1/Nth 
of the keys.

You could use striping in your example:

   Lock[] locks = new Lock[N];
   /* intializer block */ {
     for (i=0; i<N; i++)
         locks[i] = new ReentrantLock();
   }

and

private synchronized Mutex getLockForKey(final Serializable key) {
     int h = key.hashCode() % N;
     if (h < 0)
         h += N;
     return locks[h];
}

This way, 1/Nth of the keys are guarded by locks[0], 1/Nth by locks[1], 
etc.  Concurrency can be tuned by choosing N; we found 16 works well on 
systems with fewer than a few dozen processors.

From mattocks at mac.com  Fri Jun  2 22:11:59 2006
From: mattocks at mac.com (Craig Mattocks)
Date: Fri, 2 Jun 2006 22:11:59 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex	lock objects
In-Reply-To: <mailman.99.1149282229.11515.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.99.1149282229.11515.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <a82e687fa0a9b347c6996cb2030135b1@mac.com>

On  Sat, 3 Jun 2006 07:02:59 +1000 Greg Luck <gluck at gregluck.com> wrote:

> Once a Mutex object is placed in the Map it stays there forever. It is
> technically a slow memory leak unless the keyset is bounded so that
> at some time it stops growing.

Use a WeakHashMap?

http://www-128.ibm.com/developerworks/java/library/j-jtp11225/


From dawidk at mathcs.emory.edu  Fri Jun  2 23:53:30 2006
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Fri, 02 Jun 2006 23:53:30 -0400
Subject: [concurrency-interest] Problem with using an unbounded map
	ofMutexlock objects
In-Reply-To: <a82e687fa0a9b347c6996cb2030135b1@mac.com>
References: <mailman.99.1149282229.11515.concurrency-interest@altair.cs.oswe
	go.edu> <a82e687fa0a9b347c6996cb2030135b1@mac.com>
Message-ID: <448107BA.20207@mathcs.emory.edu>

Craig Mattocks wrote:
> On  Sat, 3 Jun 2006 07:02:59 +1000 Greg Luck <gluck at gregluck.com> wrote:
>
>   
>> Once a Mutex object is placed in the Map it stays there forever. It is
>> technically a slow memory leak unless the keyset is bounded so that
>> at some time it stops growing.
>>     
>
> Use a WeakHashMap?
>
>   

Nah; the keys are compared using equals() so you don't want to tie locks 
to particular object instances.

Here is a "named lock" class that may just do the trick (it is called 
"named", but in reality, the "name" of the lock can be an arbitrary 
object, with equals() comparison semantics):

http://dcl.mathcs.emory.edu/cgi-bin/viewcvs.cgi/software/util/src/edu/emory/mathcs/util/concurrent/ReentrantNamedLock.java

It does use a form of a weak map (weak _value_ map to be precise) to 
allow locks that are (1) unused and (2) unlocked to be garbage 
collected, and later re-created if needed again.

I do think, however, that lock striping may work out better b/c of 
allocation considerations.

Regards,
Dawid


From dhanji at gmail.com  Sat Jun  3 00:08:03 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sat, 3 Jun 2006 14:08:03 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <4480BC44.7080700@quiotix.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
Message-ID: <aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>

The lock striping idea is a very interesting. I wonder what your cache
key distribution would like and if it would always have a high enough
entropy to make lock striping effective (versus pooling).

As I see it, the benefits of pooling are:
- no bottleneck until all pool elements are simultaneously in use,
- no overhead of instantiation/gc of new locks for cache keys (this is
also true of striping)

However with lock striping and a sufficiently high entropy of cache
keys (I assume this depends entirely on the target business domain)
you could end up with the same bottleneck on one heavily used stripe,
while the other locks sit idle. I would definitely suggest if the
entropy of cache keys cannot be guaranteed beforehand, that lock
pooling is a better solution (even with the same number of locks).

On 6/3/06, Brian Goetz <brian at quiotix.com> wrote:
> > That sounds good. I don't have a copy of JCiP so I bought one :) from
> > Amazon.
>
> Guess all that "Jedi mind trick" practice is paying off :)
>
> > It will arrive between June 21 and July 3. I would appreciate
> > any online or email stuff on lock striping in the meantime.
>
> Hashtable / synchronizedMap uses the "one big fat lock" approach to
> guard the mutable state of the map.  That works, but is a big
> concurrency bottleneck, as you've observed.  You went to the opposite
> extreme, one lock per key.  That works (as long as you've got sufficient
> synchronization in the cache itself to protect its own data structures.)
>
> Lock striping is a middle ground, partitioning keys into a fixed number
> of subsets, like the trick used at large theaters for will-call ticket
> pickup -- there are separate lines for "A-F, G-M, N-R, and S-Z".  This
> way, there are a fixed number of locks, each guarding (hopefully) 1/Nth
> of the keys.
>
> You could use striping in your example:
>
>    Lock[] locks = new Lock[N];
>    /* intializer block */ {
>      for (i=0; i<N; i++)
>          locks[i] = new ReentrantLock();
>    }
>
> and
>
> private synchronized Mutex getLockForKey(final Serializable key) {
>      int h = key.hashCode() % N;
>      if (h < 0)
>          h += N;
>      return locks[h];
> }
>
> This way, 1/Nth of the keys are guarded by locks[0], 1/Nth by locks[1],
> etc.  Concurrency can be tuned by choosing N; we found 16 works well on
> systems with fewer than a few dozen processors.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dhanji at gmail.com  Sat Jun  3 00:09:10 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sat, 3 Jun 2006 14:09:10 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
Message-ID: <aa067ea10606022109j7af6cf05lb8bfe5ba1a755b2f@mail.gmail.com>

a minor correction:

> However with lock striping and a sufficiently high entropy of cache
> keys (I assume this depends entirely on the target business domain)

should read "sufficiently *low* entropy"

On 6/3/06, Dhanji R. Prasanna <dhanji at gmail.com> wrote:
> The lock striping idea is a very interesting. I wonder what your cache
> key distribution would like and if it would always have a high enough
> entropy to make lock striping effective (versus pooling).
>
> As I see it, the benefits of pooling are:
> - no bottleneck until all pool elements are simultaneously in use,
> - no overhead of instantiation/gc of new locks for cache keys (this is
> also true of striping)
>
> However with lock striping and a sufficiently high entropy of cache
> keys (I assume this depends entirely on the target business domain)
> you could end up with the same bottleneck on one heavily used stripe,
> while the other locks sit idle. I would definitely suggest if the
> entropy of cache keys cannot be guaranteed beforehand, that lock
> pooling is a better solution (even with the same number of locks).
>
> On 6/3/06, Brian Goetz <brian at quiotix.com> wrote:
> > > That sounds good. I don't have a copy of JCiP so I bought one :) from
> > > Amazon.
> >
> > Guess all that "Jedi mind trick" practice is paying off :)
> >
> > > It will arrive between June 21 and July 3. I would appreciate
> > > any online or email stuff on lock striping in the meantime.
> >
> > Hashtable / synchronizedMap uses the "one big fat lock" approach to
> > guard the mutable state of the map.  That works, but is a big
> > concurrency bottleneck, as you've observed.  You went to the opposite
> > extreme, one lock per key.  That works (as long as you've got sufficient
> > synchronization in the cache itself to protect its own data structures.)
> >
> > Lock striping is a middle ground, partitioning keys into a fixed number
> > of subsets, like the trick used at large theaters for will-call ticket
> > pickup -- there are separate lines for "A-F, G-M, N-R, and S-Z".  This
> > way, there are a fixed number of locks, each guarding (hopefully) 1/Nth
> > of the keys.
> >
> > You could use striping in your example:
> >
> >    Lock[] locks = new Lock[N];
> >    /* intializer block */ {
> >      for (i=0; i<N; i++)
> >          locks[i] = new ReentrantLock();
> >    }
> >
> > and
> >
> > private synchronized Mutex getLockForKey(final Serializable key) {
> >      int h = key.hashCode() % N;
> >      if (h < 0)
> >          h += N;
> >      return locks[h];
> > }
> >
> > This way, 1/Nth of the keys are guarded by locks[0], 1/Nth by locks[1],
> > etc.  Concurrency can be tuned by choosing N; we found 16 works well on
> > systems with fewer than a few dozen processors.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>

From brian at quiotix.com  Sat Jun  3 00:12:22 2006
From: brian at quiotix.com (Brian Goetz)
Date: Sat, 03 Jun 2006 00:12:22 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
 Mutex lock objects
In-Reply-To: <aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	
	<4480B306.2050905@quiotix.com>	
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
Message-ID: <44810C26.9050803@quiotix.com>

> However with lock striping and a sufficiently high entropy of cache
> keys (I assume this depends entirely on the target business domain)
> you could end up with the same bottleneck on one heavily used stripe,

This is true of any hash-based collection.  If you have a poor hash 
function, performance suffers.  In the worst case:

   public int hashCode() { return 0; }

is a valid hash function, but it turns a hashmap into a linked list.

I'm not quite sure what you have in mind for pooling locks, but I think 
it was a requirement that all operations for key K use the same lock, 
which eliminates pooling as an option.

From gluck at gregluck.com  Sat Jun  3 00:57:16 2006
From: gluck at gregluck.com (Greg Luck)
Date: Sat, 3 Jun 2006 14:57:16 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <44810C26.9050803@quiotix.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	
	<4480B306.2050905@quiotix.com>	
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
Message-ID: <5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>

Yes,

It is a requirement that all operations for key K use the same lock.


On 03/06/2006, at 2:12 PM, Brian Goetz wrote:

>> However with lock striping and a sufficiently high entropy of cache
>> keys (I assume this depends entirely on the target business domain)
>> you could end up with the same bottleneck on one heavily used stripe,
>
> This is true of any hash-based collection.  If you have a poor hash  
> function, performance suffers.  In the worst case:
>
>   public int hashCode() { return 0; }
>
> is a valid hash function, but it turns a hashmap into a linked list.
>
> I'm not quite sure what you have in mind for pooling locks, but I  
> think it was a requirement that all operations for key K use the  
> same lock, which eliminates pooling as an option.
>

Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/d9901375/attachment-0001.html 

From dhanji at gmail.com  Sat Jun  3 01:04:25 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sat, 3 Jun 2006 15:04:25 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <44810C26.9050803@quiotix.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
Message-ID: <aa067ea10606022204x7d9df42pce2bb4c18ffae9d@mail.gmail.com>

>
> I'm not quite sure what you have in mind for pooling locks, but I think
> it was a requirement that all operations for key K use the same lock,
> which eliminates pooling as an option.
>

I wasnt very clear before: pool the locks and then rotate them behind
the stripes (making sure the same hashcode is not in use). That way an
idle stripe doesnt (always) equal an idle lock. It's a bit complex to
track in-use hashkeys, but..

private synchronized Mutex getLockForKey(final Serializable key) {
    int h = key.hashCode() % N;

    if (h < 0)
        h += N;

    Mutex m = stripes[h].getLockInUse(key.hashCode());
    if (null != m)
       return m;

    stripes[h].use(pool.pop(), key.hashCode());
    return stripes[h].getLockInUse(key.hashCode());
}

private synchronized void releaseLock(final Serializable key) {
    int h = key.hashCode() % N;

    if (h < 0)
        h += N;

    try {
       pool.push(stripes[h].getLockInUse(key.hashCode()));
       stripes[h].unuse(key.hashCode());
    } catch (NPE) {
        throw new LockWasNotInUseException();
    }
}

does this seem viable?
purely pooling locks (without the stripes) for each key sets up a
chicken and egg condition with 'how do we get synchronized access to
the in-use locks', I agree, it's not even near feasible.  =)

From tim at peierls.net  Sat Jun  3 01:05:30 2006
From: tim at peierls.net (Tim Peierls)
Date: Sat, 3 Jun 2006 01:05:30 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
Message-ID: <63b4e4050606022205t10d86adfw4721d28e9ea4dabe@mail.gmail.com>

On 6/2/06, Greg Luck <gluck at gregluck.com> wrote:
>
> * A version of this class is planned which will dynamically use JDK5's
> concurrency package, which is
> * based on Doug Lea's, so as to avoid a dependency on his package for JDK5
> systems. This will not
> * be implemented until JDK5 is released on MacOSX and Linux, as JDK5 will
> be required to compile
> * it, though any version from JDK1.2 up will be able to run the code,
> falling back to Doug
> * Lea's concurrency package, if the JDK5 package is not found in the
> classpath.
>

Nothing to do with the locking question you asked, but consider using Dawid
Kurzyniec's backport of the java.util.concurrent package instead of falling
back to Doug Lea's util.concurrent library -- it might make it easier to
maintain the two versions of the class in parallel.

http://dcl.mathcs.emory.edu/util/backport-util-concurrent/


--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/974cef31/attachment.html 

From tim at peierls.net  Sat Jun  3 02:39:18 2006
From: tim at peierls.net (Tim Peierls)
Date: Sat, 3 Jun 2006 02:39:18 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
	<5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
Message-ID: <63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>

On second thought, this looks like another job for FutureTask. It's similar
to the Memoizer example in chapter 5 of JCiP.

I was expecting Joe Bowbeer to have chimed in by now, but I'll have to do it
for him. :-)

The approach is to cache a Future for each value rather than the value
itself. The get method finds the Future for the given key, adding it
atomically to the cache if it doesn't exist, and then waits for its result
to become available. The timed get method waits for up to a given time limit
before returning null. The put method sets the value of the Future
associated with the key (creating and adding if necessary); if the value has
already been set, it removes the Future from the cache and tries again.

Here's an illustration using ConcurrentHashMap as the underlying cache. It
uses generics to make the roles of variables clear, but that's not a
necessary part of the approach.

This code compiles and runs on a small test (not shown here).

public class BlockingCache<K, V> {
    private final ConcurrentMap<K, Result<V>> cache = new
ConcurrentHashMap<K, Result<V>>();

    public V get(K key) throws InterruptedException {
        try {
            return futureFor(key).get();
        } catch (ExecutionException e) {
            throw new IllegalStateException(e.getCause()); // shouldn't
happen
        }
    }

    public V get(K key, long timeout, TimeUnit unit) throws
InterruptedException {
        try {
            return futureFor(key).get(timeout, unit);
        } catch (TimeoutException e) {
            return null;
        } catch (ExecutionException e) {
            throw new IllegalStateException(e.getCause()); // shouldn't
happen
        }
    }

    public void put(K key, V value) {
        while (true) {
            Result<V> f = futureFor(key);
            if (!f.isDone()) {
                f.set(value);
                break;
            }
            cache.remove(key, f);
        }
    }

    private Result<V> futureFor(K key) {
        Result<V> f = cache.get(key);
        if (f == null) {
            Result<V> ft = new Result<V>();
            f = cache.putIfAbsent(key, ft);
            if (f == null) return ft;
        }
        return f;
    }

    static class Result<V> extends FutureTask<V> {
        Result() { super(new Runnable() { public void run() {} }, null); }
        public synchronized void set(V value) { super.set(value); }
    }
}

You'd definitely want to use the concurrency utilities backport if you go
with this approach.

--tim

On 6/3/06, Greg Luck <gluck at gregluck.com> wrote:
>
> Yes,
>
> It is a requirement that all operations for key K use the same lock.
>
>
> On 03/06/2006, at 2:12 PM, Brian Goetz wrote:
>
> However with lock striping and a sufficiently high entropy of cache
> keys (I assume this depends entirely on the target business domain)
> you could end up with the same bottleneck on one heavily used stripe,
>
>
> This is true of any hash-based collection.  If you have a poor hash
> function, performance suffers.  In the worst case:
>
>   public int hashCode() { return 0; }
>
> is a valid hash function, but it turns a hashmap into a linked list.
>
> I'm not quite sure what you have in mind for pooling locks, but I think it
> was a requirement that all operations for key K use the same lock, which
> eliminates pooling as an option.
>
>
> Regards
>
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluckyahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/a6dd6fee/attachment.html 

From tim at peierls.net  Sat Jun  3 12:32:14 2006
From: tim at peierls.net (Tim Peierls)
Date: Sat, 3 Jun 2006 12:32:14 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
	<5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
	<63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>
Message-ID: <63b4e4050606030932p47e97f68vb465b72aed4f8c81@mail.gmail.com>

On 6/3/06, Tim Peierls <tim at peierls.net> wrote:
>
> I was expecting Joe Bowbeer to have chimed in by now, but I'll have to do
> it for him. :-)
>

Joe pointed out (offline) some weaknesses in my posted code. Here is an
improved version that adds a remove method: waiting gets return null if the
key they are waiting for is removed. Benign races are possible, e.g.,
simultaneous puts from different threads, simultaneous put and remove.

The two part message is "Design with the standard library interfaces; use
the standard library implementations where conveniently possible". Future
makes the waiting and interrupt handling logic easy and consistent.
ConcurrentMap provides a thread-safe map with atomic put-if-absent and
remove-only-given-value. FutureTask and ConcurrentHashMap are performant and
well-tested implementations.

I believe the approach will scale very well. For ehcache, you have
serialization concerns that are not addressed in the code below, but this
should be independent of the blocking get issue.

public class BlockingCache<K, V> {

    public V get(K key) throws InterruptedException {
        try {
            return futureFor(key).get();
        } catch (CancellationException e) {
            return null;
        } catch (ExecutionException e) {
            throw new IllegalStateException(e.getCause()); // shouldn't
happen
        }
    }

    public V get(K key, long timeout, TimeUnit unit) throws
InterruptedException {
        try {
            return futureFor(key).get(timeout, unit);
        } catch (TimeoutException e) {
            return null;
        } catch (CancellationException e) {
            return null;
        } catch (ExecutionException e) {
            throw new IllegalStateException(e.getCause()); // shouldn't
happen
        }
    }

    public void put(K key, V value) {
        while (true) {
            FutureResult<V> f = futureFor(key);
            if (!f.isDone() || !cache.remove(key, f)) {
                f.set(value); // first set succeeds, subsequent calls
ignored
                break;
            }
        }
    }

    public void remove(K key) {
        if (cache.containsKey(key)) { // try to avoid creating future
unnecessarily
            FutureResult<V> f = futureFor(key);
            f.cancel(false);
            cache.remove(key, f);
        }
    }


    private FutureResult<V> futureFor(K key) {
        FutureResult<V> f = cache.get(key);
        if (f == null) {
            FutureResult<V> newf = new FutureResult<V>();
            f = cache.putIfAbsent(key, newf);
            if (f == null) return newf;
        }
        return f;
    }

    private final ConcurrentMap<K, FutureResult<V>> cache =
        new ConcurrentHashMap<K, FutureResult<V>>();


    private static class FutureResult<V> extends FutureTask<V> {
        FutureResult() { super(UNUSED, null); }
        public void set(V value) { super.set(value); }
    }

    private static final Runnable UNUSED = new Runnable() { public void
run() {} };
}


--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/de3be3c4/attachment.html 

From tim at peierls.net  Sat Jun  3 12:43:49 2006
From: tim at peierls.net (Tim Peierls)
Date: Sat, 3 Jun 2006 12:43:49 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <63b4e4050606030932p47e97f68vb465b72aed4f8c81@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
	<5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
	<63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>
	<63b4e4050606030932p47e97f68vb465b72aed4f8c81@mail.gmail.com>
Message-ID: <63b4e4050606030943s1b53f294g4290b5f2d2c165f2@mail.gmail.com>

And in case it wasn't clear, you will still want to pursue the lock striping
approach that Brian described to get ConcurrentMap-like behavior.

--tim

On 6/3/06, Tim Peierls <tim at peierls.net> wrote:
>
> I believe the approach will scale very well. For ehcache, you have
> serialization concerns that are not addressed in the code below, but this
> should be independent of the blocking get issue.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060603/08b838f6/attachment.html 

From gluck at gregluck.com  Sun Jun  4 04:32:05 2006
From: gluck at gregluck.com (Greg Luck)
Date: Sun, 4 Jun 2006 18:32:05 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <63b4e4050606030943s1b53f294g4290b5f2d2c165f2@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
	<5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
	<63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>
	<63b4e4050606030932p47e97f68vb465b72aed4f8c81@mail.gmail.com>
	<63b4e4050606030943s1b53f294g4290b5f2d2c165f2@mail.gmail.com>
Message-ID: <CA8E93CD-FB90-4258-9E07-0F4F931A106C@gregluck.com>

Tim

Is your code example a complete solution? Do you mean that the lock- 
striping is an alternative to your implementation?

In any case  I will run your solution over my mult-threaded torture  
tests this week.

On 04/06/2006, at 2:43 AM, Tim Peierls wrote:

> And in case it wasn't clear, you will still want to pursue the lock  
> striping approach that Brian described to get ConcurrentMap-like  
> behavior.
>
> --tim
>
> On 6/3/06, Tim Peierls <tim at peierls.net> wrote:
> I believe the approach will scale very well. For ehcache, you have  
> serialization concerns that are not addressed in the code below,  
> but this should be independent of the blocking get issue.
>



Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060604/b30b255a/attachment.html 

From tim at peierls.net  Sun Jun  4 08:39:20 2006
From: tim at peierls.net (Tim Peierls)
Date: Sun, 4 Jun 2006 08:39:20 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <CA8E93CD-FB90-4258-9E07-0F4F931A106C@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<aa067ea10606022108v79a165e7wdb3351585bab7c92@mail.gmail.com>
	<44810C26.9050803@quiotix.com>
	<5917AC87-A51C-4048-83FE-FC3419114316@gregluck.com>
	<63b4e4050606022339p7ef5f272j120e338a2c42996f@mail.gmail.com>
	<63b4e4050606030932p47e97f68vb465b72aed4f8c81@mail.gmail.com>
	<63b4e4050606030943s1b53f294g4290b5f2d2c165f2@mail.gmail.com>
	<CA8E93CD-FB90-4258-9E07-0F4F931A106C@gregluck.com>
Message-ID: <63b4e4050606040539k6383a11gc253078016c54d9e@mail.gmail.com>

I mean that the underlying caching mechanism needs to be thread-safe and to
provide atomic put-if-absent and remove-with-given-value operations in order
to use the blocking get approach I sketched. ConcurrentHashMap has those
properties, but if you run into trouble implementing your Cache class on top
of it, you can still use the lock-striping approach used internally by CHM
to build your own ConcurrentMap-like mechanism.

I should mention that I have a vested interest in the performance and
scalability of ehcache, because I am one of your users (via Hibernate)! :-)

--tim

On 6/4/06, Greg Luck <gluck at gregluck.com> wrote:
>
> Tim
> Is your code example a complete solution? Do you mean that the
> lock-striping is an alternative to your implementation?
>
> In any case  I will run your solution over my mult-threaded torture tests
> this week.
>
> On 04/06/2006, at 2:43 AM, Tim Peierls wrote:
>
> And in case it wasn't clear, you will still want to pursue the lock
> striping approach that Brian described to get ConcurrentMap-like behavior.
>
> --tim
>
> On 6/3/06, Tim Peierls <tim at peierls.net> wrote:
> >
> > I believe the approach will scale very well. For ehcache, you have
> > serialization concerns that are not addressed in the code below, but this
> > should be independent of the blocking get issue.
> >
>
>
>
>
> Regards
>
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluckyahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060604/2a4c3cfa/attachment-0001.html 

From dawidk at mathcs.emory.edu  Sun Jun  4 15:20:58 2006
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sun, 04 Jun 2006 15:20:58 -0400
Subject: [concurrency-interest] backport: version 2.2 available
Message-ID: <4483329A.7000502@mathcs.emory.edu>

Hello all,

The backport-util-concurrent, version 2.2, is now available:

http://dcl.mathcs.emory.edu/util/backport-util-concurrent/

It adds atomic blocking multi-acquires for fair semaphores, it is 
reconciled with latest JSR 166 sources (recent changes in navigable 
interfaces etc.), and it includes a few minor fixes.

Enjoy,
Dawid Kurzyniec

From steve at jofti.com  Mon Jun  5 15:49:24 2006
From: steve at jofti.com (steve at jofti.com)
Date: Mon, 5 Jun 2006 20:49:24 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 17,
	Issue 4
In-Reply-To: <mailman.99.1149282229.11515.concurrency-interest@altair.cs.oswego.edu>
References: <mailman.99.1149282229.11515.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <D630AD82-D74E-4549-BB5F-73DE03353FB0@jofti.com>

Hi Greg,
Have you thought about a compromise (sort of like the concurrent  
hashmap) and
have something like an array of locks (or open hashing table) which  
you choose by the hashcode of the key mod the number of elements in  
the array

This would give a reasonable fine grained locking (but would depend  
on the hash collision and the number of slots) - maybe a large enough  
prime would give you a tradeoff you could live with

Assuming that the locks are pretty short lived you should get  
reasonable performance - if not you might get bottleneck areas

any thoughts?

steve


On 2 Jun 2006, at 22:03, concurrency-interest-request at cs.oswego.edu  
wrote:

> Send Concurrency-interest mailing list submissions to
> 	concurrency-interest at altair.cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
> 	concurrency-interest-request at altair.cs.oswego.edu
>
> You can reach the person managing the list at
> 	concurrency-interest-owner at altair.cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
>    1. Problem with using an unbounded map of Mutex	lock objects
>       (Greg Luck)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 3 Jun 2006 07:02:59 +1000
> From: Greg Luck <gluck at gregluck.com>
> Subject: [concurrency-interest] Problem with using an unbounded map of
> 	Mutex	lock objects
> To: concurrency-interest at cs.oswego.edu
> Message-ID: <A397B776-BE4D-4F79-B053-F16654D354A5 at gregluck.com>
> Content-Type: text/plain; charset="us-ascii"
>
> Hi
>
> (I mailed this initially to Doug Lea. He is travelling at present and
> suggested I post it here for a quicker response).
>
> I am the maintainer of ehcache, a leading open source project, and
> probably the most used Java cache. I have also just joined JSR-107
> and am working towards making ehcache an implementation of this spec.
> I also have a copy of Concurrent Programming in Java, Second Edition.
>
> A few years ago we had a serious  problem with scalability caused by
> extreme contention on synchronized methods on BlockingCache. We
> redesigned it to use fined grained Mutex objects, from your
> concurrency package, in a Map of locks, keyed by possible cache keys.
> The class is listed below. The scalability went up by an order of
> magnitude. Problem solved.
>
> However, some very careful users have discovered a problem. Once a
> Mutex object is placed in the Map it stays there forever. It is
> technically a slow memory leak unless the keyset is bounded so that
> at some time it stops growing.
> Users are also complaining of slow garbage collection times because
> of the millions of Mutex objects they end up with.
>
> I am not sure what the solution here is. I don't think I can simply
> remove them because I don't know if they are in use, or more subtly,
> whether a caller is holding a reference waiting to acquire a lock and
> put the Mutex into use. If I remove one from the lock Map a new
> caller will put a new one in the Map with the same key. I could have
> the situation where more than one thread things it has the same lock.
>
> I am thinking perhaps a pool of locks but I need to work out how to
> safely reuse the pool. Something close to the Pool discussed in
> Section 3.4.1.2 is probably what I need.
>
> Any thoughts you have on this would be most appreciated by myself and
> my user community.
>
> /**
> * A blocking cache, backed by {@link Ehcache}.
> * <p/>
> * It allows concurrent read access to elements already in the cache.
> If the element is null, other
> * reads will block until an element with the same key is put into the
> cache.
> * <p/>
> * This is useful for constructing read-through or self-populating
> caches.
> * <p/>
> * This implementation uses the {@link Mutex} class from Doug Lea's
> concurrency package. If you wish to use
> * this class, you will need the concurrent package in your class path.
> * <p/>
> * It features:
> * <ul>
> * <li>Excellent liveness.
> * <li>Fine-grained locking on each element, rather than the cache as
> a whole.
> * <li>Scalability to a large number of threads.
> * </ul>
> * <p/>
> * A version of this class is planned which will dynamically use
> JDK5's concurrency package, which is
> * based on Doug Lea's, so as to avoid a dependency on his package for
> JDK5 systems. This will not
> * be implemented until JDK5 is released on MacOSX and Linux, as JDK5
> will be required to compile
> * it, though any version from JDK1.2 up will be able to run the code,
> falling back to Doug
> * Lea's concurrency package, if the JDK5 package is not found in the
> classpath.
> * <p/>
> * The <code>Mutex</code> class does not appear in the JDK5
> concurrency package. Doug Lea has
> * generously offered the following advice:
> * <p/>
> * <pre>
> * You should just be able to use ReentrantLock here.  We supply
> * ReentrantLock, but not Mutex because the number of cases where a
> * non-reentrant mutex is preferable is small, and most people are more
> * familiar with reentrant seamantics. If you really need a non- 
> reentrant
> * one, the javadocs for class AbstractQueuedSynchronizer include  
> sample
> * code for them.
> * <p/>
> * -Doug
> * </pre>
> * <p/>
> *
> * @author Greg Luck
> * @version $Id: BlockingCache.java 94 2006-05-25 09:06:30Z gregluck $
> */
> public class BlockingCache {
>
>      private static final Log LOG = LogFactory.getLog
> (BlockingCache.class.getName());
>
>      /**
>       * The backing Cache
>       */
>      private final Ehcache cache;
>
>
>      private final int timeoutMillis;
>
>      /**
>       * A map of cache entry locks, one per key, if present
>       */
>      private final Map locks = new HashMap();
>
>      /**
>       * Creates a BlockingCache with the given name.
>       *
>       * @param name the name to give the cache
>       * @throws CacheException
>       */
>      public BlockingCache(final String name) throws CacheException {
>          this(name, 0);
>      }
>
>      /**
>       * Creates a BlockingCache with the given name.
>       *
>       * @param name          the name to give the cache
>       * @param timeoutMillis the amount of time, in milliseconds, to
> block for
>       * @throws CacheException
>       * @since 1.2
>       */
>      public BlockingCache(final String name, int timeoutMillis)
> throws CacheException {
>          CacheManager manager = null;
>          try {
>              manager = CacheManager.create();
>          } catch (net.sf.ehcache.CacheException e) {
>              LOG.fatal("CacheManager cannot be created. Cause was: "
> + e.getMessage() + e);
>              throw new CacheException("CacheManager cannot be
> created", e);
>          }
>          cache = manager.getCache(name);
>          if (cache == null || !cache.getName().equals(name)) {
>              throw new CacheException("Cache " + name + " cannot be
> retrieved. Please check ehcache.xml");
>          }
>          this.timeoutMillis = timeoutMillis;
>      }
>
>      /**
>       * Creates a BlockingCache with the given name and
>       * uses the given cache manager to create the cache
>       *
>       * @param name    the name to give the cache
>       * @param manager the EHCache CacheManager used to create the
> backing cache
>       * @throws CacheException
>       */
>      public BlockingCache(final String name, final CacheManager
> manager) throws CacheException {
>          this(name, manager, 0);
>      }
>
>      /**
>       * Creates a BlockingCache with the given name and
>       * uses the given cache manager to create the cache
>       *
>       * @param name          the name to give the cache
>       * @param manager       the EHCache CacheManager used to create
> the backing cache
>       * @param timeoutMillis the amount of time, in milliseconds, to
> block for
>       * @throws CacheException
>       * @since 1.2
>       */
>      public BlockingCache(final String name, final CacheManager
> manager, int timeoutMillis) throws CacheException {
>          if (manager == null) {
>              throw new CacheException("CacheManager cannot be null");
>          }
>          cache = manager.getCache(name);
>          if (cache == null || !cache.getName().equals(name)) {
>              throw new CacheException("Cache " + name + " cannot be
> retrieved. Please check ehcache.xml");
>          }
>          this.timeoutMillis = timeoutMillis;
>      }
>
>      /**
>       * Retrieve the EHCache backing cache
>       */
>      protected net.sf.ehcache.Ehcache getCache() {
>          return cache;
>      }
>
>      /**
>       * Returns this cache's name
>       */
>      public String getName() {
>          return cache.getName();
>      }
>
>      /**
>       * Looks up an entry.  Blocks if the entry is null.
>       * Relies on the first thread putting an entry in, which
> releases the lock
>       * If a put is not done, the lock is never released
>       */
>      public Serializable get(final Serializable key) throws
> BlockingCacheException {
>          Mutex lock = checkLockExistsForKey(key);
>          try {
>              if (timeoutMillis == 0) {
>                  lock.acquire();
>              } else {
>                  boolean acquired = lock.attempt(timeoutMillis);
>                  if (!acquired) {
>                      StringBuffer message = new StringBuffer("lock
> timeout attempting to acquire lock for key ")
>                              .append(key).append(" on cache ").append
> (cache.getName());
>                      throw new BlockingCacheException(message.toString
> ());
>                  }
>              }
>              final Element element = cache.get(key);
>              if (element != null) {
>                  //ok let the other threads in
>                  lock.release();
>                  return element.getValue();
>              } else {
>                  //don't release the read lock until we write
>                  return null;
>              }
>          } catch (InterruptedException e) {
>              throw new CacheException("Interrupted. Message was: " +
> e.getMessage());
>          }
>      }
>
>      private synchronized Mutex checkLockExistsForKey(final
> Serializable key) {
>          Mutex lock;
>          lock = (Mutex) locks.get(key);
>          if (lock == null) {
>              lock = new Mutex();
>              locks.put(key, lock);
>          }
>          return lock;
>      }
>
>      /**
>       * Adds an entry and unlocks it
>       */
>      public void put(final Serializable key, final Serializable  
> value) {
>          Mutex lock = checkLockExistsForKey(key);
>          try {
>              if (value != null) {
>                  final Element element = new Element(key, value);
>                  cache.put(element);
>              } else {
>                  cache.remove(key);
>              }
>          } finally {
>              //Release the readlock here. This will have been
> acquired in the get, where the element was null
>              lock.release();
>          }
>      }
>
>      /**
>       * Returns the keys for this cache.
>       *
>       * @return The keys of this cache.  This is not a live set, so
> it will not track changes to the key set.
>       */
>      public Collection getKeys() throws CacheException {
>          return cache.getKeys();
>      }
>
>      /**
>       * Drops the contents of this cache.
>       */
>      public void clear() throws CacheException {
>          if (LOG.isDebugEnabled()) {
>              LOG.debug("Cache " + cache.getName() + ": removing all
> entries");
>          }
>          cache.removeAll();
>      }
>
>      /**
>       * Synchronized version of getName to test liveness of the
> object lock.
>       * <p/>
>       * The time taken for this method to return is a useful measure
> of runtime contention on the cache.
>       */
>      public synchronized String liveness() {
>          return getName();
>      }
>
>      /**
>       * Gets all entries from a blocking cache. Cache is not
> serializable. This
>       * method provides a way of accessing the keys and values of a
> Cache in a Serializable way e.g.
>       * to return from a Remote call.
>       * <p/>
>       * This method may take a long time to return. It does not lock
> the cache. The list of entries is based
>       * on a copy. The actual cache may have changed in the time
> between getting the list and gathering the
>       * KeyValuePairs.
>       * <p/>
>       * This method can potentially return an extremely large object,
> roughly matching the memory taken by the cache
>       * itself. Care should be taken before using this method.
>       * <p/>
>       * By getting all of the entries at once this method can
> transfer a whole cache with a single method call, which
>       * is important for Remote calls across a network.
>       *
>       * @return a Serializable {@link java.util.List} of {@link
> KeyValuePair}s, which implement the Map.Entry interface
>       * @throws CacheException where there is an error in the
> underlying cache
>       */
>      public List getEntries() throws CacheException {
>          if (LOG.isDebugEnabled()) {
>              LOG.debug("Getting entries for the " + cache.getName() +
> " cache");
>          }
>          Collection keys = cache.getKeys();
>          List keyValuePairs = new ArrayList(keys.size());
>          for (Iterator iterator = keys.iterator(); iterator.hasNext
> ();) {
>              Serializable key = (Serializable) iterator.next();
>              Element element = cache.get(key);
>              keyValuePairs.add(new KeyValuePair(key, element.getValue
> ()));
>          }
>          return keyValuePairs;
>      }
> }
>
>
>
> Regards
>
> Greg Luck
>
> web: http://gregluck.com
> skype: gregrluck
> yahoo: gregrluck
> mobile: +61 408 061 622
>
>
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: /pipermail/attachments/20060603/55b307a3/attachment.html
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> End of Concurrency-interest Digest, Vol 17, Issue 4
> ***************************************************


From gluck at gregluck.com  Tue Jun  6 04:20:13 2006
From: gluck at gregluck.com (Greg Luck)
Date: Tue, 6 Jun 2006 18:20:13 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex	lock objects
In-Reply-To: <4480BC44.7080700@quiotix.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
Message-ID: <19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>

Brian et al

Thanks so much for everyone's contributions.

I tested out Brian's lock striping with my suite of concurrency tests  
(BlockingCacheTest in ehcache) which hammer BlockingCache with 100  
threads. It seems to work very well.

Mutex objects use 24 bytes so I opted to go for 100. That is 2400  
bytes in total, way down from the tens of MBs that is common now in  
ehcache for large systems.

I also looked into the  allocation of locks for different keys. In  
the tests I did for lock selection, locks were evenly selected +- 20%.

In all this looks to be an excellent solution with minimal change to  
the BlockingCache. The newly revised blocking cache is reproduced  
below. I would appreciate anyone letting me know if there are any  
shortcomings in it.

One point to note. In Brian's implementation, getLockForKey 
(Serializable key) was synchronized. I think this is unncecessary and  
potentially harmful to scalability. Mine is not synchronized.

Finally thanks to Tim Peieris and others for alternate solutions. I  
don't want to bring another lib at this time. One of the attractions  
of ehcache, which I would like to preserve,  is the minimal  
dependencies.

Brian's Recommendation
===================


Hashtable / synchronizedMap uses the "one big fat lock" approach to  
guard the mutable state of the map.  That works, but is a big  
concurrency bottleneck, as you've observed.  You went to the opposite  
extreme, one lock per key.  That works (as long as you've got  
sufficient synchronization in the cache itself to protect its own  
data structures.)

Lock striping is a middle ground, partitioning keys into a fixed  
number of subsets, like the trick used at large theaters for will- 
call ticket pickup -- there are separate lines for "A-F, G-M, N-R,  
and S-Z".  This way, there are a fixed number of locks, each guarding  
(hopefully) 1/Nth of the keys.

You could use striping in your example:

   Lock[] locks = new Lock[N];
   /* intializer block */ {
     for (i=0; i<N; i++)
         locks[i] = new ReentrantLock();
   }

and

private synchronized Mutex getLockForKey(final Serializable key) {
     int h = key.hashCode() % N;
     if (h < 0)
         h += N;
     return locks[h];
}

This way, 1/Nth of the keys are guarded by locks[0], 1/Nth by locks 
[1], etc.  Concurrency can be tuned by choosing N; we found 16 works  
well on systems with fewer than a few dozen processors.



The completed BlockingCache
========================



public class BlockingCache {

     /**
      * The default number of locks to use. 16 is recommended by  
Brian Goetz
      */
     protected static final int LOCK_NUMBER = 100;

     private static final Log LOG = LogFactory.getLog 
(BlockingCache.class.getName());


     /**
      * Based on the lock striping concept from Brian Goetz. See Java  
Concurrency in Practice 11.4.3
      */
     private Mutex[] locks = new Mutex[LOCK_NUMBER];

     {
         for (int i = 0; i < LOCK_NUMBER; i++) {
             locks[i] = new Mutex();
         }
     }

     /**
      * The backing Cache
      */
     private final Ehcache cache;


     private final int timeoutMillis;
     /**
      * A map of cache entry locks, one per key, if present
      */
     //private final Map locks = new HashMap();

     /**
      * Creates a BlockingCache with the given name.
      *
      * @param name the name to give the cache
      * @throws CacheException
      */
     public BlockingCache(final String name) throws CacheException {
         this(name, 0);
     }

     /**
      * Creates a BlockingCache with the given name.
      *
      * @param name          the name to give the cache
      * @param timeoutMillis the amount of time, in milliseconds, to  
block for
      * @throws CacheException
      * @since 1.2
      */
     public BlockingCache(final String name, int timeoutMillis)  
throws CacheException {
         CacheManager manager = null;
         try {
             manager = CacheManager.create();
         } catch (net.sf.ehcache.CacheException e) {
             LOG.fatal("CacheManager cannot be created. Cause was: "  
+ e.getMessage() + e);
             throw new CacheException("CacheManager cannot be  
created", e);
         }
         cache = manager.getCache(name);
         if (cache == null || !cache.getName().equals(name)) {
             throw new CacheException("Cache " + name + " cannot be  
retrieved. Please check ehcache.xml");
         }
         this.timeoutMillis = timeoutMillis;
     }

     /**
      * Creates a BlockingCache with the given name and
      * uses the given cache manager to create the cache
      *
      * @param name    the name to give the cache
      * @param manager the EHCache CacheManager used to create the  
backing cache
      * @throws CacheException
      */
     public BlockingCache(final String name, final CacheManager  
manager) throws CacheException {
         this(name, manager, 0);
     }

     /**
      * Creates a BlockingCache with the given name and
      * uses the given cache manager to create the cache
      *
      * @param name          the name to give the cache
      * @param manager       the EHCache CacheManager used to create  
the backing cache
      * @param timeoutMillis the amount of time, in milliseconds, to  
block for
      * @throws CacheException
      * @since 1.2
      */
     public BlockingCache(final String name, final CacheManager  
manager, int timeoutMillis) throws CacheException {
         if (manager == null) {
             throw new CacheException("CacheManager cannot be null");
         }
         cache = manager.getCache(name);
         if (cache == null || !cache.getName().equals(name)) {
             throw new CacheException("Cache " + name + " cannot be  
retrieved. Please check ehcache.xml");
         }
         this.timeoutMillis = timeoutMillis;
     }

     /**
      * Retrieve the EHCache backing cache
      */
     protected net.sf.ehcache.Ehcache getCache() {
         return cache;
     }

     /**
      * Returns this cache's name
      */
     public String getName() {
         return cache.getName();
     }

     /**
      * Looks up an entry.  Blocks if the entry is null.
      * Relies on the first thread putting an entry in, which  
releases the lock
      * If a put is not done, the lock is never released
      */
     public Serializable get(final Serializable key) throws  
BlockingCacheException {
         Mutex lock = getLockForKey(key);
         try {
             if (timeoutMillis == 0) {
                 lock.acquire();
             } else {
                 boolean acquired = lock.attempt(timeoutMillis);
                 if (!acquired) {
                     StringBuffer message = new StringBuffer("lock  
timeout attempting to acquire lock for key ")
                             .append(key).append(" on cache ").append 
(cache.getName());
                     throw new BlockingCacheException(message.toString 
());
                 }
             }
             final Element element = cache.get(key);
             if (element != null) {
                 //ok let the other threads in
                 lock.release();
                 return element.getValue();
             } else {
                 //don't release the read lock until we write
                 return null;
             }
         } catch (InterruptedException e) {
             throw new CacheException("Interrupted. Message was: " +  
e.getMessage());
         }
     }

     private Mutex getLockForKey(final Serializable key) {
         if (key == null) {
             return locks[0];
         }
         int h = key.hashCode() % LOCK_NUMBER;
         if (h < 0) {
             h += LOCK_NUMBER;
         }
         return locks[h];
     }

     /**
      * Adds an entry and unlocks it
      */
     public void put(final Serializable key, final Serializable value) {
         Mutex lock = getLockForKey(key);
         try {
             if (value != null) {
                 final Element element = new Element(key, value);
                 cache.put(element);
             } else {
                 cache.remove(key);
             }
         } finally {
             //Release the readlock here. This will have been  
acquired in the get, where the element was null
             lock.release();
         }
     }

     /**
      * Returns the keys for this cache.
      *
      * @return The keys of this cache.  This is not a live set, so  
it will not track changes to the key set.
      */
     public Collection getKeys() throws CacheException {
         return cache.getKeys();
     }

     /**
      * Drops the contents of this cache.
      */
     public void clear() throws CacheException {
         if (LOG.isDebugEnabled()) {
             LOG.debug("Cache " + cache.getName() + ": removing all  
entries");
         }
         cache.removeAll();
     }

     /**
      * Synchronized version of getName to test liveness of the  
object lock.
      * <p/>
      * The time taken for this method to return is a useful measure  
of runtime contention on the cache.
      */
     public synchronized String liveness() {
         return getName();
     }

     /**
      * Gets all entries from a blocking cache. Cache is not  
serializable. This
      * method provides a way of accessing the keys and values of a  
Cache in a Serializable way e.g.
      * to return from a Remote call.
      * <p/>
      * This method may take a long time to return. It does not lock  
the cache. The list of entries is based
      * on a copy. The actual cache may have changed in the time  
between getting the list and gathering the
      * KeyValuePairs.
      * <p/>
      * This method can potentially return an extremely large object,  
roughly matching the memory taken by the cache
      * itself. Care should be taken before using this method.
      * <p/>
      * By getting all of the entries at once this method can  
transfer a whole cache with a single method call, which
      * is important for Remote calls across a network.
      *
      * @return a Serializable {@link java.util.List} of {@link  
KeyValuePair}s, which implement the Map.Entry interface
      * @throws CacheException where there is an error in the  
underlying cache
      */
     public List getEntries() throws CacheException {
         if (LOG.isDebugEnabled()) {
             LOG.debug("Getting entries for the " + cache.getName() +  
" cache");
         }
         Collection keys = cache.getKeys();
         List keyValuePairs = new ArrayList(keys.size());
         for (Iterator iterator = keys.iterator(); iterator.hasNext 
();) {
             Serializable key = (Serializable) iterator.next();
             Element element = cache.get(key);
             keyValuePairs.add(new KeyValuePair(key, element.getValue 
()));
         }
         return keyValuePairs;
     }
}


Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/fcd0d59e/attachment-0001.html 

From joe.bowbeer at gmail.com  Tue Jun  6 06:36:21 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 6 Jun 2006 03:36:21 -0700
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
Message-ID: <31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>

Greg,

I'm disappointed you're not using the Future-based approach.  I was
hoping you'd benchmark it and report back.  I'm interested to know how
it performs :-)

However, I can suggest a couple optimizations for your striping implementation.

1. Spread the bits in the hash code.

ConcurrentHashMap spreads the hash with the following:

    /**
     * Returns a hash code for non-null Object x.
     * Uses the same hash code spreader as most other java.util hash tables.
     * @param x the object serving as a key
     * @return the hash code
     */
    static int hash(Object x) {
        int h = x.hashCode();
        h += ~(h << 9);
        h ^=  (h >>> 14);
        h +=  (h << 4);
        h ^=  (h >>> 10);
        return h;
    }

Rationale: Hashcodes are generally unique, but they are not random.
The method above disperses the bits, producing a more random
distribution after division.


2. Require LOCK_NUMBER to be a power of two, such as 128.

In this way, a binary AND (&) can replace division (/).


Applying both of these to getLockForKey:

   /**
    * The default number of locks to use. Must be a power of 2.
    */
   protected static final int LOCK_NUMBER = 128;

   private Mutex getLockForKey(final Serializable key) {
       if (key == null)
           return locks[0];
       assert (LOCK_NUMBER & (LOCK_NUMBER-1)) == 0; // power of 2
       int h = hash(key) & (LOCK_NUMBER-1);
       return locks[h];
   }

--
Joe ~ joebowbeer.thruhere.net


On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
>
> Brian et al
>
> Thanks so much for everyone's contributions.
>
> I tested out Brian's lock striping with my suite of concurrency tests
> (BlockingCacheTest in ehcache) which hammer BlockingCache with 100 threads.
> It seems to work very well.
>
> Mutex objects use 24 bytes so I opted to go for 100. That is 2400 bytes in
> total, way down from the tens of MBs that is common now in ehcache for large
> systems.
>
> I also looked into the  allocation of locks for different keys. In the tests
> I did for lock selection, locks were evenly selected +- 20%.
>
> In all this looks to be an excellent solution with minimal change to the
> BlockingCache. The newly revised blocking cache is reproduced below. I would
> appreciate anyone letting me know if there are any shortcomings in it.
>
> One point to note. In Brian's implementation, getLockForKey(Serializable
> key) was synchronized. I think this is unncecessary and potentially harmful
> to scalability. Mine is not synchronized.
>
> Finally thanks to Tim Peieris and others for alternate solutions. I don't
> want to bring another lib at this time. One of the attractions of ehcache,
> which I would like to preserve,  is the minimal dependencies.
>

From dl at cs.oswego.edu  Tue Jun  6 07:41:39 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 06 Jun 2006 07:41:39 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
 Mutex lock objects
In-Reply-To: <31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	<4480B306.2050905@quiotix.com>	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	<4480BC44.7080700@quiotix.com>	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
Message-ID: <448569F3.8050800@cs.oswego.edu>

Joe Bowbeer wrote:
> 
> However, I can suggest a couple optimizations for your striping implementation.
> 
> 1. Spread the bits in the hash code.
> 

Joe - thanks for the implicit reminder to update this. Last month
we did some analysis of java.util.HashMap and found that the hash
bit scrambling function could be improved, and did so for HashMap.
(I think this version might now be in Mustang builds.)
But hadn't gotten around to ConcurrentHashMap. This is not
quite black magic but close to it. You can analytically determine
general properties, but then use brute-force testing of candidate
functions to find best in a family, Doing this led to:

     static int hash(Object x) {
         // This function ensures that hashCodes that differ only by
         // constant multiples at each bit position have a bounded
         // number of collisions.
         int h = x.hashCode();
         h ^= (h >>> 20) ^ (h >>> 12);
         return h ^ (h >>> 7) ^ (h >>> 4);
     }

> 
> 2. Require LOCK_NUMBER to be a power of two, such as 128.
> 
> In this way, a binary AND (&) can replace division (/).
> 

Absolutely. If (and only if) you use a decent bit spreader like
above, this should give a very noticeable speedup. The mod (%)
operator is very slow on most processors, and especially so in
Java, where there is sign-based adjustment on top of the hardware
instruction.

-Doug

From gluck at gregluck.com  Tue Jun  6 08:51:50 2006
From: gluck at gregluck.com (Greg Luck)
Date: Tue, 6 Jun 2006 22:51:50 +1000
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
Message-ID: <25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>

Joe

I have tested the hash code spreader.  It performs noticeably poorer  
than using key.hashCode(), which spread evenly with the full  
distribution within +- 20%.
This new one is +- 49%.

See the following test. I have tried a couple different ways of  
generating keys which give much the same result. Note that  
BlockingCache is overwhelmingly used with
database IDs which are number in similar ranges to the ones I am  
generating.

    /**
      * Tests that stripes are evently distributed
      */
     public void testStripingDistribution() {
         int[] lockIndexes = new int[128];
         for (int i = 0; i < 5000; i++) {
             String key = new String("" + i * 3 / 2 + i);
             key += key.hashCode();
             int lock = blockingCache.selectLock(key);
             lockIndexes[lock]++;
         }

         for (int i = 0; i < 128; i++) {
             assertTrue("Lock index " + i + " outside of range: " +  
lockIndexes[i], 20 <= lockIndexes[i] && lockIndexes[i] <= 55);
         }
     }


     /**
      * Selects a lock for a key. The same lock is always used for a  
given key.
      * @param key
      * @return the selected lock index
      */
     int selectLock(final Object key) {
         if (key == null) {
             return 0;
         } else {
             int hash = hash(key) & (LOCK_NUMBER - 1);
             return hash;
         }

     }


     /**
      * Returns a hash code for non-null Object x.
      * Uses the same hash code spreader as most other java.util hash  
tables.
      *
      * @param object the object serving as a key
      * @return the hash code
      */
     private int hash(Object object) {
         int hashcode = object.hashCode();
         hashcode += ~(hashcode << 9);
         hashcode ^= (hashcode >>> 14);
         hashcode += (hashcode << 4);
         hashcode ^= (hashcode >>> 10);
         return hashcode;
     }





On 06/06/2006, at 8:36 PM, Joe Bowbeer wrote:

> Greg,
>
> I'm disappointed you're not using the Future-based approach.  I was
> hoping you'd benchmark it and report back.  I'm interested to know how
> it performs :-)
>
> However, I can suggest a couple optimizations for your striping  
> implementation.
>
> 1. Spread the bits in the hash code.
>
> ConcurrentHashMap spreads the hash with the following:
>
>     /**
>      * Returns a hash code for non-null Object x.
>      * Uses the same hash code spreader as most other java.util  
> hash tables.
>      * @param x the object serving as a key
>      * @return the hash code
>      */
>     static int hash(Object x) {
>         int h = x.hashCode();
>         h += ~(h << 9);
>         h ^=  (h >>> 14);
>         h +=  (h << 4);
>         h ^=  (h >>> 10);
>         return h;
>     }
>
> Rationale: Hashcodes are generally unique, but they are not random.
> The method above disperses the bits, producing a more random
> distribution after division.
>
>
> 2. Require LOCK_NUMBER to be a power of two, such as 128.
>
> In this way, a binary AND (&) can replace division (/).
>
>
> Applying both of these to getLockForKey:
>
>    /**
>     * The default number of locks to use. Must be a power of 2.
>     */
>    protected static final int LOCK_NUMBER = 128;
>
>    private Mutex getLockForKey(final Serializable key) {
>        if (key == null)
>            return locks[0];
>        assert (LOCK_NUMBER & (LOCK_NUMBER-1)) == 0; // power of 2
>        int h = hash(key) & (LOCK_NUMBER-1);
>        return locks[h];
>    }
>
> --
> Joe ~ joebowbeer.thruhere.net
>
>
> On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
>>
>> Brian et al
>>
>> Thanks so much for everyone's contributions.
>>
>> I tested out Brian's lock striping with my suite of concurrency tests
>> (BlockingCacheTest in ehcache) which hammer BlockingCache with 100  
>> threads.
>> It seems to work very well.
>>
>> Mutex objects use 24 bytes so I opted to go for 100. That is 2400  
>> bytes in
>> total, way down from the tens of MBs that is common now in ehcache  
>> for large
>> systems.
>>
>> I also looked into the  allocation of locks for different keys. In  
>> the tests
>> I did for lock selection, locks were evenly selected +- 20%.
>>
>> In all this looks to be an excellent solution with minimal change  
>> to the
>> BlockingCache. The newly revised blocking cache is reproduced  
>> below. I would
>> appreciate anyone letting me know if there are any shortcomings in  
>> it.
>>
>> One point to note. In Brian's implementation, getLockForKey 
>> (Serializable
>> key) was synchronized. I think this is unncecessary and  
>> potentially harmful
>> to scalability. Mine is not synchronized.
>>
>> Finally thanks to Tim Peieris and others for alternate solutions.  
>> I don't
>> want to bring another lib at this time. One of the attractions of  
>> ehcache,
>> which I would like to preserve,  is the minimal dependencies.
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



Regards

Greg Luck

web: http://gregluck.com
skype: gregrluck
yahoo: gregrluck
mobile: +61 408 061 622



-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/f3b518cd/attachment-0001.html 

From tim at peierls.net  Tue Jun  6 09:58:30 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 6 Jun 2006 09:58:30 -0400
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
Message-ID: <63b4e4050606060658x2fa7d910n76b524000e806f0d@mail.gmail.com>

On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
>
> One point to note. In Brian's implementation, getLockForKey(Serializable
> key) was synchronized. I think this is unncecessary and potentially harmful
> to scalability. Mine is not synchronized.
>

You need to make the locks field final for this to be safe. See, for
example, 16.3 of Java Concurrency in Practice .

You can remove the final keywords from the 2-arg constructor parameters.

One concern I have about the current API is that it doesn't observe the
rule/convention that blocking methods throw InterruptedException. This makes
it harder, for example, to write cancellable tasks for the Executor
framework if they call BlockingCache.get. Not a showstopper, but more work
for the user.

Another concern is that the public API requires client threads to follow
failed gets by puts to release the mutex. It's not flat-out wrong, but it
means observing a special protocol on the client side. Wouldn't it be safer
to have a get method that takes a value-producing object that can be used to
return a value for a key if the cache doesn't contain one? Then users can't
fail to observe the protocol.

Quick sketch:

interface Function<A, V> {
    V compute(A key);
}

// BlockingCache method
public V get(K key, Function<K, V> f) throws InterruptedException {...}

Function<BigInteger, BigInteger[]> factor = new Function<BigInteger,
BigInteger[]>() {
    public BigInteger[] call(BigInteger n) { return computeFactors(n); }
};

BlockingCache<BigInteger, BigInteger[]> cache = new
BlockingCache<BigInteger, BigInteger[]>();

BigInteger[] getFactors(BigInteger n) throws InterruptedException {
    return cache.get(n, factor);
}

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/46ad416b/attachment.html 

From joe.bowbeer at gmail.com  Tue Jun  6 10:08:30 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 6 Jun 2006 07:08:30 -0700
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
Message-ID: <31f2a7bd0606060708k3de18659k15f2a97dcdbd14b5@mail.gmail.com>

On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
>
> I have tested the hash code spreader.  It performs noticeably poorer than
> using key.hashCode(), which spread evenly with the full distribution within
> +- 20%.
> This new one is +- 49%.
>

Are you sure the hash spreader isn't increasing randomness, resulting
in more bumps?  In other words, is smoother really better?

Plan B:

The hashcode for Strings is computed as:

  s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]

For numeric keys, each s[i] will contain a digit '0' .. '9'

That is: 48 <= s[i] <= 57

So maybe this hash function already works well with a table size of 128?

Given the comments in HashMap and ConcurrentHashMap, however, I would
hesitate to use 2^N locks without using a hash spreader (or performing
further analysis on the hashcodes).


On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
>
> Joe
>
> I have tested the hash code spreader.  It performs noticeably poorer than
> using key.hashCode(), which spread evenly with the full distribution within
> +- 20%.
> This new one is +- 49%.
>
> See the following test. I have tried a couple different ways of generating
> keys which give much the same result. Note that BlockingCache is
> overwhelmingly used with
> database IDs which are number in similar ranges to the ones I am generating.
>
>    /**
>      * Tests that stripes are evently distributed
>      */
>     public void testStripingDistribution() {
>         int[] lockIndexes = new int[128];
>         for (int i = 0; i < 5000; i++) {
>             String key = new String("" + i * 3 / 2 + i);
>             key += key.hashCode();
>             int lock = blockingCache.selectLock(key);
>             lockIndexes[lock]++;
>         }
>
>         for (int i = 0; i < 128; i++) {
>             assertTrue("Lock index " + i + " outside of range: " +
> lockIndexes[i], 20 <= lockIndexes[i] && lockIndexes[i] <= 55);
>         }
>     }
>
>
>     /**
>      * Selects a lock for a key. The same lock is always used for a given
> key.
>      * @param key
>      * @return the selected lock index
>      */
>     int selectLock(final Object key) {
>         if (key == null) {
>             return 0;
>         } else {
>             int hash = hash(key) & (LOCK_NUMBER - 1);
>             return hash;
>         }
>
>     }
>
>
>     /**
>      * Returns a hash code for non-null Object x.
>      * Uses the same hash code spreader as most other java.util hash tables.
>      *
>      * @param object the object serving as a key
>      * @return the hash code
>      */
>     private int hash(Object object) {
>         int hashcode = object.hashCode();
>         hashcode += ~(hashcode << 9);
>         hashcode ^= (hashcode >>> 14);
>         hashcode += (hashcode << 4);
>         hashcode ^= (hashcode >>> 10);
>         return hashcode;
>     }
>
>
>
>
>
>
> On 06/06/2006, at 8:36 PM, Joe Bowbeer wrote:
>
>
> Greg,
>
> I'm disappointed you're not using the Future-based approach.  I was
> hoping you'd benchmark it and report back.  I'm interested to know how
> it performs :-)
>
> However, I can suggest a couple optimizations for your striping
> implementation.
>
> 1. Spread the bits in the hash code.
>
> ConcurrentHashMap spreads the hash with the following:
>
>     /**
>      * Returns a hash code for non-null Object x.
>      * Uses the same hash code spreader as most other java.util hash tables.
>      * @param x the object serving as a key
>      * @return the hash code
>      */
>     static int hash(Object x) {
>         int h = x.hashCode();
>         h += ~(h << 9);
>         h ^=  (h >>> 14);
>         h +=  (h << 4);
>         h ^=  (h >>> 10);
>         return h;
>     }
>
> Rationale: Hashcodes are generally unique, but they are not random.
> The method above disperses the bits, producing a more random
> distribution after division.
>
>
> 2. Require LOCK_NUMBER to be a power of two, such as 128.
>
> In this way, a binary AND (&) can replace division (/).
>
>
> Applying both of these to getLockForKey:
>
>    /**
>     * The default number of locks to use. Must be a power of 2.
>     */
>    protected static final int LOCK_NUMBER = 128;
>
>    private Mutex getLockForKey(final Serializable key) {
>        if (key == null)
>            return locks[0];
>        assert (LOCK_NUMBER & (LOCK_NUMBER-1)) == 0; // power of 2
>        int h = hash(key) & (LOCK_NUMBER-1);
>        return locks[h];
>    }
>
> --
> Joe ~ joebowbeer.thruhere.net
>

From forax at univ-mlv.fr  Tue Jun  6 10:08:27 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 06 Jun 2006 16:08:27 +0200
Subject: [concurrency-interest] ConcurrentNavigableMap has two keySet
In-Reply-To: <25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	<4480B306.2050905@quiotix.com>	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	<4480BC44.7080700@quiotix.com>	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
Message-ID: <44858C5B.70503@univ-mlv.fr>

It seems that during the last changes (perhaps corresponding to bug 6415641)
two different methods to obtain a NavigableSet
in ConcurrentNavigableMap was introduced.

|*keySet 
<http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html#keySet%28%29>*()| 

          Returns a |NavigableSet| 
<http://download.java.net/jdk6/docs/api/java/util/NavigableSet.html> 
view of the keys contained in this map.
|*navigableKeySet 
<http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html#navigableKeySet%28%29>*()| 

          Returns a |NavigableSet| 
<http://download.java.net/jdk6/docs/api/java/util/NavigableSet.html> 
view of the keys contained in this map.


see 
http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html

I think that navigableKeySet() can be removed from 
ConcurrentNavigableMap and
its implementation ConcurrentSkipListMap.

R?mi Forax





From dl at cs.oswego.edu  Tue Jun  6 11:03:05 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 06 Jun 2006 11:03:05 -0400
Subject: [concurrency-interest] ConcurrentNavigableMap has two keySet
In-Reply-To: <44858C5B.70503@univ-mlv.fr>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	<4480B306.2050905@quiotix.com>	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	<4480BC44.7080700@quiotix.com>	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
	<44858C5B.70503@univ-mlv.fr>
Message-ID: <44859929.4070003@cs.oswego.edu>

R?mi Forax wrote:
> 
> I think that navigableKeySet() can be removed from 
> ConcurrentNavigableMap and
> its implementation ConcurrentSkipListMap.
> 

Method navigableKeySet is needed in (nonconcurrent) NavigableMap to
conservatively maintain backward compatibility with SortedMap etc.
So it is also needed in subinterface ConcurrentNavigableMap, even though, as
specified, there's no reason to call it rather than just calling keySet.

-Doug



From josh at bloch.us  Tue Jun  6 11:13:09 2006
From: josh at bloch.us (Joshua Bloch)
Date: Tue, 6 Jun 2006 08:13:09 -0700
Subject: [concurrency-interest] ConcurrentNavigableMap has two keySet
In-Reply-To: <44858C5B.70503@univ-mlv.fr>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
	<44858C5B.70503@univ-mlv.fr>
Message-ID: <b097ac510606060813i56e30270va63ea504c440f450@mail.gmail.com>

R?mi,

Ah, would that it were.  ConcurrentNavigableMap extends NavigableMap.
NavigableMap needs both of these methods, as they have different return
types in NavigableMap.  We were unable to refine the return type of keySet
in NavigableMap for historical reasons: TreeMap was retrofitted to implement
NavigableMap.  TreeMap was non-final, so people have already extended it and
overridden keySet with a method that returns a Map rather than a
NavigableMap.  Had we refined the return type of NavigableMap.keySet(), we
would have broken those subclasses.  The reason that we were able to refine
the return type of ConcurrentNavigableMap is because there are no existing
implementations to break: there is no ConcurrentSortedMap, and
ConcurrentSkipListMap is brand new.

         Josh

P.S.  The reason that SortedMap did not refine the return type of keySet is
that covariant returns were not yet part of the language when I wrote it;
SortedMap has existed since 1.2 (1998), and covariant return types were
added in Tiger (2004).

On 6/6/06, R?mi Forax <forax at univ-mlv.fr> wrote:
>
> It seems that during the last changes (perhaps corresponding to bug
> 6415641)
> two different methods to obtain a NavigableSet
> in ConcurrentNavigableMap was introduced.
>
> |*keySet
> <
> http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html#keySet%28%29
> >*()|
>
>           Returns a |NavigableSet|
> <http://download.java.net/jdk6/docs/api/java/util/NavigableSet.html>
> view of the keys contained in this map.
> |*navigableKeySet
> <
> http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html#navigableKeySet%28%29
> >*()|
>
>           Returns a |NavigableSet|
> <http://download.java.net/jdk6/docs/api/java/util/NavigableSet.html>
> view of the keys contained in this map.
>
>
> see
>
> http://download.java.net/jdk6/docs/api/java/util/concurrent/ConcurrentNavigableMap.html
>
> I think that navigableKeySet() can be removed from
> ConcurrentNavigableMap and
> its implementation ConcurrentSkipListMap.
>
> R?mi Forax
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/7ddbfae5/attachment.html 

From mike.quilleash at azuresolutions.com  Tue Jun  6 14:24:20 2006
From: mike.quilleash at azuresolutions.com (Mike Quilleash)
Date: Tue, 6 Jun 2006 19:24:20 +0100
Subject: [concurrency-interest] Cancellation convention
Message-ID: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>

Quick question about cancelling things and the usual way of doing it.
 
Is it the convention to use Thread.interrupt() to do cancellation of a
task in another thread?  Presumably the Thread being run must either be
calling API code that is interruptible or check itself for the
interrupted state regularly.
 
Specifically I'm interested in being able to cancel long running JDBC
calls (using PreparedStatement.cancel()).  Would a sensible way be to
fork off the PreparedStatement execution in another thread and have the
main thread wait for the second thread to complete, but if it is
interrupted then call the PreparedStatement.cancel() and throw an
exception out to indicate the cancellation succeeded?  Just after some
best practice advice.
 
Cheers.
 
Mike.
 

______________________________________________________________________
This email has been scanned by the MessageLabs Email Security System.
For more information please visit http://www.messagelabs.com/email 
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/0abde2b8/attachment.html 

From tim at peierls.net  Tue Jun  6 15:05:15 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 6 Jun 2006 15:05:15 -0400
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
Message-ID: <63b4e4050606061205r26f47dax2d73ca1960694de4@mail.gmail.com>

Is it safe to share PreparedStatement instances between threads? If not,
then there's nothing you can do, since you can't have one thread in
PreparedStatement.execute() and another in PreparedStatement.cancel().

If you can guarantee thread-safety of PreparedStatement, then you can use a
technique described in Section 7.1.6 of Java Concurrency in Practice: Create
a Thread with a custom interruption policy by overriding interrupt() to call
PreparedStatement.cancel() in addition to super.interrupt () -- be sure to
use a finally block for the latter. (Even better would be to use the
CancellableTask technique in Section 7.1.7; the particular implementation
described there relies on a feature only available in Java 6, but you can
work around that.)

--tim

On 6/6/06, Mike Quilleash < mike.quilleash at azuresolutions.com> wrote:
>
>  Quick question about cancelling things and the usual way of doing it.
>
> Is it the convention to use Thread.interrupt() to do cancellation of a
> task in another thread?  Presumably the Thread being run must either be
> calling API code that is interruptible or check itself for the interrupted
> state regularly.
>
> Specifically I'm interested in being able to cancel long running JDBC
> calls (using PreparedStatement.cancel()).  Would a sensible way be to fork
> off the PreparedStatement execution in another thread and have the main
> thread wait for the second thread to complete, but if it is interrupted then
> call the PreparedStatement.cancel() and throw an exception out to indicate
> the cancellation succeeded?  Just after some best practice advice.
>
> Cheers.
>
> Mike.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/18cc76c4/attachment.html 

From brian at quiotix.com  Tue Jun  6 16:16:48 2006
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 06 Jun 2006 16:16:48 -0400
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
Message-ID: <4485E2B0.4040909@quiotix.com>

> Is it the convention to use Thread.interrupt() to do cancellation of a 
> task in another thread?  Presumably the Thread being run must either be 
> calling API code that is interruptible or check itself for the 
> interrupted state regularly.

Interrupting a thread when you do not know (a) exactly what code is 
running in it and (b) how it will react to interruption is ill-advised. 
  Better to use the cancel() feature of Future (to avoid problem (a)) 
and code your tasks to deal properly with IE (to avoid (b)).

You can then run such tasks in a standard thread pool, which is usually 
preferable to forking off a separate thread.

(This material is covered fairly extensively in Ch7 of JCiP.)

> Specifically I'm interested in being able to cancel long running JDBC 
> calls (using PreparedStatement.cancel()).  Would a sensible way be to 
> fork off the PreparedStatement execution in another thread and have the 
> main thread wait for the second thread to complete, but if it is 
> interrupted then call the PreparedStatement.cancel() and throw an 
> exception out to indicate the cancellation succeeded?  Just after some 
> best practice advice.

From brian at quiotix.com  Tue Jun  6 16:19:04 2006
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 06 Jun 2006 16:19:04 -0400
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <63b4e4050606061205r26f47dax2d73ca1960694de4@mail.gmail.com>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<63b4e4050606061205r26f47dax2d73ca1960694de4@mail.gmail.com>
Message-ID: <4485E338.6050107@quiotix.com>

> Is it safe to share PreparedStatement instances between threads? If not, 
> then there's nothing you can do, since you can't have one thread in 
> PreparedStatement.execute() and another in PreparedStatement.cancel().

We don't know.  The specification is absolutely silent on the subject of 
the thread-safety of JDBC objects.  However, serial thread confinement 
can be applied to the entire family of related JDBC objects (Connection 
/ PS / ResultSet), and in the absence of a truly whacked out 
interpretation of the spec, should probably be OK.

Some vendors try to make their JDBC drivers safe (like Oracle.) 
Sometimes they succeed, though the Oracle driver has had well-known 
deadlock problems in the past (can't say about hte current version.)


From tim at peierls.net  Tue Jun  6 17:07:05 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 6 Jun 2006 17:07:05 -0400
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <4485E338.6050107@quiotix.com>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<63b4e4050606061205r26f47dax2d73ca1960694de4@mail.gmail.com>
	<4485E338.6050107@quiotix.com>
Message-ID: <63b4e4050606061407g6c643a4fk133a5778fdeb3d0a@mail.gmail.com>

On 6/6/06, Brian Goetz <brian at quiotix.com> wrote:
>
> > Is it safe to share PreparedStatement instances between threads?
>
> We don't know.  The specification is absolutely silent on the subject of
> the thread-safety of JDBC objects.  However, serial thread confinement
> can be applied to the entire family of related JDBC objects (Connection
> / PS / ResultSet), and in the absence of a truly whacked out
> interpretation of the spec, should probably be OK.


Mike seemed to be proposing something outside of serial thread confinement:
PS.execute in one thread, and PS.cancel in another. But your argument (here
and in JCiP 4.5.1) is that providing a cancel method in the API makes no
sense if you can't use it in this way.


Some vendors try to make their JDBC drivers safe (like Oracle.)
> Sometimes they succeed, though the Oracle driver has had well-known
> deadlock problems in the past (can't say about the current version.)


It's quite possible that some driver implementations work by accident.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060606/5972a73c/attachment.html 

From dhanji at gmail.com  Tue Jun  6 20:16:43 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 7 Jun 2006 10:16:43 +1000
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
Message-ID: <aa067ea10606061716u2476e45aic68b229795772498@mail.gmail.com>

On 6/7/06, Mike Quilleash <mike.quilleash at azuresolutions.com> wrote:
>

>
> Specifically I'm interested in being able to cancel long running JDBC calls
> (using PreparedStatement.cancel()).

JDBC provides a setQueryTimeout which will throw a SQLException if the
PS runs past the timeout limit?
This should be the preferred way of timing out long-running queries,
as the semantics of concurrency with JDBC are obscure at best--unless
Im very much mistaken and have misunderstood your problem.

From mike.quilleash at azuresolutions.com  Wed Jun  7 03:14:07 2006
From: mike.quilleash at azuresolutions.com (Mike Quilleash)
Date: Wed, 7 Jun 2006 08:14:07 +0100
Subject: [concurrency-interest] Cancellation convention
Message-ID: <F1689FB09456E347A6E38343B99E680D0219ED61@THHS2EXBE2X.hostedservice2.net>

Thanks for your replies guys.

My problem isn't really a timeout problem it's a user cancellation
problem.  Some of our queries can be extremely long running
(minutes-hours) and it would be nice for the user to be able to cancel
them mid-process for whatever reason, they might spot a problem in the
configuration etc.

The problem is when the execution goes into either
PreparedStatement.executeQuery/executeUpdate.  Both of these are
blocking until some rows are available or the update has completed,
respectively.  For a query involving group by/order by executeQuery
can't return until all the aggregation and ordering logic has been done
in the database.

During this potentially-prolonged period the user would like to cancel
the execution, which would involve calling PreparedStatement.cancel.  I
have tested this between two threads, one executing the other calling
cancel, with a limited number of JDBC drivers (jtds for SQLServer and
Oracle's own driver) and it seems to work ok.

The issue is slightly compounded by the query could be one of several
that executes in sequence which I may want to cancel at any time.  I
could just add cancel hooks at each "depth" of my libraries down to the
JDBC level so if a user cancels the overall process it would work it's
way down through the executing process until the current JDBC call gets
cancelled.  I just wondered if there was a more elegant/preferred way of
doing it using interrupt().  I am mildly concerned that it could
interrupt nio channel traffic and close the channel as a consequence but
assuming I can avoid that is this a sensible approach?

Cheers.

Mike.

-----Original Message-----
From: Dhanji R. Prasanna [mailto:dhanji at gmail.com] 
Sent: 07 June 2006 01:17
To: Mike Quilleash
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Cancellation convention

On 6/7/06, Mike Quilleash <mike.quilleash at azuresolutions.com> wrote:
>

>
> Specifically I'm interested in being able to cancel long running JDBC 
> calls (using PreparedStatement.cancel()).

JDBC provides a setQueryTimeout which will throw a SQLException if the
PS runs past the timeout limit?
This should be the preferred way of timing out long-running queries, as
the semantics of concurrency with JDBC are obscure at best--unless Im
very much mistaken and have misunderstood your problem.

______________________________________________________________________
This email has been scanned by the MessageLabs Email Security System.
For more information please visit http://www.messagelabs.com/email 
______________________________________________________________________


From joe.bowbeer at gmail.com  Wed Jun  7 04:11:17 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 7 Jun 2006 01:11:17 -0700
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <F1689FB09456E347A6E38343B99E680D0219ED61@THHS2EXBE2X.hostedservice2.net>
References: <F1689FB09456E347A6E38343B99E680D0219ED61@THHS2EXBE2X.hostedservice2.net>
Message-ID: <31f2a7bd0606070111kd9492e9mb289e3bdd223b205@mail.gmail.com>

Mike Quilleash <mike.quilleash at azuresolutions.com> wrote:
>
> Specifically I'm interested in being able to cancel long running
> JDBC calls (using PreparedStatement.cancel()).  Would a sensible
> way be to fork off the PreparedStatement execution in another thread
> and have the main thread wait for the second thread to complete, but
> if it is interrupted then call the PreparedStatement.cancel() and throw
> an exception out to indicate the cancellation succeeded?  Just after
> some best practice advice.

Assuming you've scheduled the request as a FutureTask, I would call
task.cancel(false) to cancel it.  This will void the task -- without
sending an interrupt into JDBC land.

Then, assuming it's reliable(*), I would override the protected done()
method in your FutureTask so that it will cancel the prepared
statement if the task was cancelled.

  protected void done() {
    if (isCancelled()) {
      try {
        preparedStatement.cancel();
      } catch (SQLException ex) {
        // oops!
      }
    }
  }

(*) The spec says Statement.cancel() will:

"Cancels this Statement object if both the DBMS and driver support
aborting an SQL statement. This method can be used by one thread to
cancel a statement that is being executed by another thread."

-- 
Joe Bowbeer ~ joebowbeer.thruhere.net

From morisil at ncdc.pl  Wed Jun  7 11:48:37 2006
From: morisil at ncdc.pl (Kazimierz Pogoda)
Date: Wed, 07 Jun 2006 17:48:37 +0200
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
Message-ID: <1149695317.4886.25.camel@localhost.localdomain>

On Tue, 2006-06-06 at 19:24 +0100, Mike Quilleash wrote:

> Specifically I'm interested in being able to cancel long running JDBC
> calls (using PreparedStatement.cancel()).  Would a sensible way be to
> fork off the PreparedStatement execution in another thread and have
> the main thread wait for the second thread to complete, but if it is
> interrupted then call the PreparedStatement.cancel() and throw an
> exception out to indicate the cancellation succeeded?  Just after some
> best practice advice.

Cancellation of PreparedStatement (CallableStatement in fact) that was
executed by another thread works for me, but there is one issue. It
looks like oracle jdbc driver implementations react to cancel() method
on PreparedStatement only in case when it is hanging on the network
socket. So if we call cancel() on statement before executing thread is
"deep enough" in the execution, cancellation simply doesn't work. To
workaround this i wrote the code that analyzes stack trace of the
statement executor thread:

    private boolean isAwaitingEvent() {
        final StackTraceElement[] stackTrace = getStatementExecutorThread().getStackTrace();
        if (stackTrace.length < 2) {   //it is probably impossible, but maybe is thread is just started, so let's check
            return false;
        }
        final String recentClass = stackTrace[0].getClassName();
        final String recentMethod = stackTrace[0].getMethodName();

        if (!"java.net.SocketInputStream".equals(recentClass) && "socketRead0".equals(recentMethod)) {   //make sure we are hanging on socket
            return false;
        }

        boolean foundCallable = false;
        final String thisClass = getClass().getName();
        for (int i = 1; i < stackTrace.length; i++) {
            final String className = stackTrace[i].getClassName();
            final String methodName = stackTrace[i].getMethodName();
            if ((!foundCallable) && "oracle.jdbc.driver.OracleCallableStatement".equals(className) && "execute".equals(methodName)) {
                foundCallable = true;
                continue;
            } else if (thisClass.equals(className) && "awaitEvent".equals(methodName)) {
                return true;
            }
        }
        return false;
    }


And I'm waiting for this method to return true before I call cancel() on
the statement. Has anyone idea for better workaround?

-- 
"the spirit can only withdraw into a corner. And yet, it is not at all 
 worn out or superfluous, but, like an (eternal) witness, floats above 
 the rubble of culture - almost like an  avenger of God.  As though it 
 awaited a new incarnation."
                                        -- Ludwig Wittgenstein --
Kazimierz Pogoda
mailto:morisil at ncdc.pl


From Pete.Soper at Sun.COM  Wed Jun  7 17:13:38 2006
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Wed, 07 Jun 2006 17:13:38 -0400
Subject: [concurrency-interest] new SerialNum example for ThreadLocal class
	doc
Message-ID: <44874182.4000000@Sun.COM>

Recently the "SerialNum" example class in the java.lang.ThreadLocal doc 
was upgraded to use autoboxing and generics and to avoid unclear use of 
"synchronized." We (some JSR166 expert group members and I) thought this 
new version looked pretty good, but Tom Hawtin thought otherwise, 
pointing out the value of using @Overload, "final" and 
getAndIncrement(). That he found three ways to improve this was a bit of 
a surprise and suggests the more eyes the better, so I'm asking for any 
additional comments for the new version listed below. This is the raw 
text and the escape sequences of course display as "<" and "@" as HTML. 
Note also the two long lines format fine despite the autowrap your mail 
client might show below.

-Pete

----
  * <pre>
  * import java.util.concurrent.atomic.AtomicInteger;
  *
  * public class SerialNum {
  *
  *     // The next serial number to be assigned. Starts at zero.
  *     private static final AtomicInteger nextSerialNum = new 
AtomicInteger();
  *
  *     private static final ThreadLocal&lt;Integer> serialNum = new 
ThreadLocal&lt;Integer>() {
  *         &#64;Override
  *         protected Integer initialValue() {
  *             return nextSerialNum.getAndIncrement();
  *         }
  *     };
  *
  *     public static int get() {
  *         return serialNum.get();
  *     }
  * }</pre>




From dhanji at gmail.com  Wed Jun  7 20:52:14 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 8 Jun 2006 10:52:14 +1000
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <1149695317.4886.25.camel@localhost.localdomain>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<1149695317.4886.25.camel@localhost.localdomain>
Message-ID: <aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>

Hi, interesting solution. I cant really think of a better one but equally messy:

When the user cancels the request, go into a thread that keeps calling
cancel on the connection until a flag is set by the canceled thread:

//elsewhere in the class
Semaphore s = new Semaphore(1);

//this is the statement being executed
{
s.acquire();
ps.execute();
s.release();
}

//canceling thread
while (s.availablePermits() < 1) {
ps.cancel();
}

Im quite sure a more elegant synchronization solution can be found
with Futures or Locks. In any case I wouldn't be encouraged to use
this method without knowing exactly what the underlying JDBC driver
does on a Statement.cancel().

An unrelated comment: for efficiency and type safety in your
stacktrace analyzer solution you might want to compare:

java.net.SocketStream.class.equals(stackTrace[i])
//etc.

instead of comparing strings.


On 6/8/06, Kazimierz Pogoda <morisil at ncdc.pl> wrote:
> On Tue, 2006-06-06 at 19:24 +0100, Mike Quilleash wrote:
>
> > Specifically I'm interested in being able to cancel long running JDBC
> > calls (using PreparedStatement.cancel()).  Would a sensible way be to
> > fork off the PreparedStatement execution in another thread and have
> > the main thread wait for the second thread to complete, but if it is
> > interrupted then call the PreparedStatement.cancel() and throw an
> > exception out to indicate the cancellation succeeded?  Just after some
> > best practice advice.
>
> Cancellation of PreparedStatement (CallableStatement in fact) that was
> executed by another thread works for me, but there is one issue. It
> looks like oracle jdbc driver implementations react to cancel() method
> on PreparedStatement only in case when it is hanging on the network
> socket. So if we call cancel() on statement before executing thread is
> "deep enough" in the execution, cancellation simply doesn't work. To
> workaround this i wrote the code that analyzes stack trace of the
> statement executor thread:
>
>     private boolean isAwaitingEvent() {
>         final StackTraceElement[] stackTrace = getStatementExecutorThread().getStackTrace();
>         if (stackTrace.length < 2) {   //it is probably impossible, but maybe is thread is just started, so let's check
>             return false;
>         }
>         final String recentClass = stackTrace[0].getClassName();
>         final String recentMethod = stackTrace[0].getMethodName();
>
>         if (!"java.net.SocketInputStream".equals(recentClass) && "socketRead0".equals(recentMethod)) {   //make sure we are hanging on socket
>             return false;
>         }
>
>         boolean foundCallable = false;
>         final String thisClass = getClass().getName();
>         for (int i = 1; i < stackTrace.length; i++) {
>             final String className = stackTrace[i].getClassName();
>             final String methodName = stackTrace[i].getMethodName();
>             if ((!foundCallable) && "oracle.jdbc.driver.OracleCallableStatement".equals(className) && "execute".equals(methodName)) {
>                 foundCallable = true;
>                 continue;
>             } else if (thisClass.equals(className) && "awaitEvent".equals(methodName)) {
>                 return true;
>             }
>         }
>         return false;
>     }
>
>
> And I'm waiting for this method to return true before I call cancel() on
> the statement. Has anyone idea for better workaround?
>
> --
> "the spirit can only withdraw into a corner. And yet, it is not at all
>  worn out or superfluous, but, like an (eternal) witness, floats above
>  the rubble of culture - almost like an  avenger of God.  As though it
>  awaited a new incarnation."
>                                         -- Ludwig Wittgenstein --
> Kazimierz Pogoda
> mailto:morisil at ncdc.pl
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From morisil at ncdc.pl  Thu Jun  8 06:56:48 2006
From: morisil at ncdc.pl (Kazimierz Pogoda)
Date: Thu, 08 Jun 2006 12:56:48 +0200
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<1149695317.4886.25.camel@localhost.localdomain>
	<aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>
Message-ID: <1149764208.4439.25.camel@localhost.localdomain>

On Thu, 2006-06-08 at 10:52 +1000, Dhanji R. Prasanna wrote:

> ... Im quite sure a more elegant synchronization solution can be found
> with Futures or Locks. In any case I wouldn't be encouraged to use
> this method without knowing exactly what the underlying JDBC driver
> does on a Statement.cancel().

Thanks for your hints. I must check if it is possible to make several
cancellations on the same statement. My code is strongly bind to oracle,
thus I have only one jdbc driver to check. :)

> An unrelated comment: for efficiency and type safety in your
> stacktrace analyzer solution you might want to compare:
> 
> java.net.SocketStream.class.equals(stackTrace[i])

I don't grasp the idea? StackTraceElement is not an instance of Class?
Do you suggest me to make:

Class.forName(stackTrace[i].getClassName())

every time my metod is called?

-- 
"the spirit can only withdraw into a corner. And yet, it is not at all 
 worn out or superfluous, but, like an (eternal) witness, floats above 
 the rubble of culture - almost like an  avenger of God.  As though it 
 awaited a new incarnation."
                                        -- Ludwig Wittgenstein --
Kazimierz Pogoda
mailto:morisil at ncdc.pl


From Pete.Soper at Sun.COM  Thu Jun  8 12:25:41 2006
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Thu, 08 Jun 2006 12:25:41 -0400
Subject: [concurrency-interest] Need one more reviewer,
 please Re:  new SerialNum example for ThreadLocal class	doc
In-Reply-To: <44874182.4000000@Sun.COM>
References: <44874182.4000000@Sun.COM>
Message-ID: <44884F85.4020306@Sun.COM>

I need one more name (email address fine) of somebody who has carefully 
examined this example and judged it to be the right thing for Mustang. 
Send this directly to me, not to the list, please. If there's anything 
to report back I'll be sure to do that.

Thanks,
Pete

Pete Soper wrote:
> Recently the "SerialNum" example class in the java.lang.ThreadLocal doc 
> was upgraded to use autoboxing and generics and to avoid unclear use of 
> "synchronized." We (some JSR166 expert group members and I) thought this 
> new version looked pretty good, but Tom Hawtin thought otherwise, 
> pointing out the value of using @Overload, "final" and 
> getAndIncrement(). That he found three ways to improve this was a bit of 
> a surprise and suggests the more eyes the better, so I'm asking for any 
> additional comments for the new version listed below. This is the raw 
> text and the escape sequences of course display as "<" and "@" as HTML. 
> Note also the two long lines format fine despite the autowrap your mail 
> client might show below.
> 
> -Pete
> 
> ----
>   * <pre>
>   * import java.util.concurrent.atomic.AtomicInteger;
>   *
>   * public class SerialNum {
>   *
>   *     // The next serial number to be assigned. Starts at zero.
>   *     private static final AtomicInteger nextSerialNum = new 
> AtomicInteger();
>   *
>   *     private static final ThreadLocal&lt;Integer> serialNum = new 
> ThreadLocal&lt;Integer>() {
>   *         &#64;Override
>   *         protected Integer initialValue() {
>   *             return nextSerialNum.getAndIncrement();
>   *         }
>   *     };
>   *
>   *     public static int get() {
>   *         return serialNum.get();
>   *     }
>   * }</pre>
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From Pete.Soper at Sun.COM  Thu Jun  8 12:45:34 2006
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Thu, 08 Jun 2006 12:45:34 -0400
Subject: [concurrency-interest] Need one more reviewer,
 please Re:  new SerialNum example for ThreadLocal class	doc
Message-ID: <4488542E.2010703@Sun.COM>

tim at peierls.net suggested "Why not remove 'Starts at zero' and give an 
explicit 0 argument to the AtomicInteger constructor?" and I said I 
think this is a good idea. It's incorporated below. Any more comments 
(direct to me, please)?

-Pete

----
   * <pre>
   * import java.util.concurrent.atomic.AtomicInteger;
   *
   * public class SerialNum {
   *
   *     private static final AtomicInteger nextSerialNum = new 
AtomicInteger(0);
   *
   *     private static final ThreadLocal&lt;Integer> serialNum = new 
ThreadLocal&lt;Integer>() {
   *         &#64;Override
   *         protected Integer initialValue() {
   *             return nextSerialNum.getAndIncrement();
   *         }
   *     };
   *
   *     public static int get() {
   *         return serialNum.get();
   *     }
   * }</pre>




From dhanji at gmail.com  Thu Jun  8 19:38:57 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Fri, 9 Jun 2006 09:38:57 +1000
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <1149764208.4439.25.camel@localhost.localdomain>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<1149695317.4886.25.camel@localhost.localdomain>
	<aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>
	<1149764208.4439.25.camel@localhost.localdomain>
Message-ID: <aa067ea10606081638u7808ed87se23b25beac06564@mail.gmail.com>

> > java.net.SocketStream.class.equals(stackTrace[i])
>
> I don't grasp the idea? StackTraceElement is not an instance of Class?
> Do you suggest me to make:
>
> Class.forName(stackTrace[i].getClassName())
>
> every time my metod is called?
>

oops my bad, it should have read:

java.net.SocketStream.class.getName().equals(stackTrace[i].getClassName())

this way there is *some* type safety instead of directly comparing
strings/literals.
Dhanji

From morisil at ncdc.pl  Fri Jun  9 05:15:16 2006
From: morisil at ncdc.pl (Kazimierz Pogoda)
Date: Fri, 09 Jun 2006 11:15:16 +0200
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <aa067ea10606081638u7808ed87se23b25beac06564@mail.gmail.com>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<1149695317.4886.25.camel@localhost.localdomain>
	<aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>
	<1149764208.4439.25.camel@localhost.localdomain>
	<aa067ea10606081638u7808ed87se23b25beac06564@mail.gmail.com>
Message-ID: <1149844516.4439.2.camel@localhost.localdomain>

On Fri, 2006-06-09 at 09:38 +1000, Dhanji R. Prasanna wrote:
> > > java.net.SocketStream.class.equals(stackTrace[i])
> >
> > I don't grasp the idea? StackTraceElement is not an instance of Class?
> > Do you suggest me to make:
> >
> > Class.forName(stackTrace[i].getClassName())
> >
> > every time my metod is called?
> >
> 
> oops my bad, it should have read:
> 
> java.net.SocketStream.class.getName().equals(stackTrace[i].getClassName())

Unfortunately java.net.SocketInputStream is a friendly class (default
class modifier) :(

-- 
"the spirit can only withdraw into a corner. And yet, it is not at all 
 worn out or superfluous, but, like an (eternal) witness, floats above 
 the rubble of culture - almost like an  avenger of God.  As though it 
 awaited a new incarnation."
                                        -- Ludwig Wittgenstein --
Kazimierz Pogoda
mailto:morisil at ncdc.pl


From dhanji at gmail.com  Fri Jun  9 05:41:23 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Fri, 9 Jun 2006 19:41:23 +1000
Subject: [concurrency-interest] Cancellation convention
In-Reply-To: <1149844516.4439.2.camel@localhost.localdomain>
References: <F1689FB09456E347A6E38343B99E680D0219EB6F@THHS2EXBE2X.hostedservice2.net>
	<1149695317.4886.25.camel@localhost.localdomain>
	<aa067ea10606071752v1574a8b2yff18342fc280744f@mail.gmail.com>
	<1149764208.4439.25.camel@localhost.localdomain>
	<aa067ea10606081638u7808ed87se23b25beac06564@mail.gmail.com>
	<1149844516.4439.2.camel@localhost.localdomain>
Message-ID: <aa067ea10606090241k1f589ab9sb195e3d100f7daf@mail.gmail.com>

> Unfortunately java.net.SocketInputStream is a friendly class (default
> class modifier) :(
>

doh =(

From kris at dotech.com  Fri Jun  9 10:31:18 2006
From: kris at dotech.com (Kris Schneider)
Date: Fri, 09 Jun 2006 10:31:18 -0400
Subject: [concurrency-interest] Ensure Callable.call is invoked from
	constructing thread?
Message-ID: <44898636.6020501@dotech.com>

I need to ensure that a Callable is called from the same thread within 
which it was constructed:

public class Processor implements Callable {
   private Object ctx;

   public Processor(Object threadSensitiveContext) {
     if (threadSensitiveContext == null) {
       throw new NullPointerException("threadSensitiveContext cannot be null");
     }
     this.ctx = threadSensitiveContext;
     // Store id/ref of current thread
   }

   public Object call() throws Exception {
     if (this.ctx == null) {
       throw new IllegalStateException("ctx has already been processed - 
this Callable can only be called once");
     }

     // Ensure id/ref of current thread is the same as stored id/ref

     Object result = null;
     try {
       // Use this.ctx to produce result
     } finally {
       this.ctx = null;
     }
     return result;
   }
}

The two approaches that immediately came to mind were to use a reference 
object or System.identityHashCode(Thread.currentThread()). Any thoughts on 
which might be better or if there are other approaches that are better 
still? Thanks.

-- 
Kris Schneider <mailto:kris at dotech.com>
D.O.Tech       <http://www.dotech.com/>

From tim at peierls.net  Fri Jun  9 11:14:29 2006
From: tim at peierls.net (Tim Peierls)
Date: Fri, 9 Jun 2006 11:14:29 -0400
Subject: [concurrency-interest] Ensure Callable.call is invoked from
	constructing thread?
In-Reply-To: <44898636.6020501@dotech.com>
References: <44898636.6020501@dotech.com>
Message-ID: <63b4e4050606090814s22037acbq8d8e3c94d2362421@mail.gmail.com>

You could store the thread-sensitive context in a ThreadLocal, set by the
constructor, checked and used in call().

For different approaches to dealing with execution policies like this, see
chapters 6 and 8 of Java Concurrency in Practice (http://jcip.net).

--tim

On 6/9/06, Kris Schneider <kris at dotech.com> wrote:
>
> I need to ensure that a Callable is called from the same thread within
> which it was constructed:
>
> public class Processor implements Callable {
>    private Object ctx;
>
>    public Processor(Object threadSensitiveContext) {
>      if (threadSensitiveContext == null) {
>        throw new NullPointerException("threadSensitiveContext cannot be
> null");
>      }
>      this.ctx = threadSensitiveContext;
>      // Store id/ref of current thread
>    }
>
>    public Object call() throws Exception {
>      if (this.ctx == null) {
>        throw new IllegalStateException("ctx has already been processed -
> this Callable can only be called once");
>      }
>
>      // Ensure id/ref of current thread is the same as stored id/ref
>
>      Object result = null;
>      try {
>        // Use this.ctx to produce result
>      } finally {
>        this.ctx = null;
>      }
>      return result;
>    }
> }
>
> The two approaches that immediately came to mind were to use a reference
> object or System.identityHashCode(Thread.currentThread()). Any thoughts on
> which might be better or if there are other approaches that are better
> still? Thanks.
>
> --
> Kris Schneider <mailto:kris at dotech.com>
> D.O.Tech       <http://www.dotech.com/>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060609/f6fc343e/attachment.html 

From tackline at tackline.plus.com  Fri Jun  9 12:31:54 2006
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 09 Jun 2006 17:31:54 +0100
Subject: [concurrency-interest] Ensure Callable.call is invoked
 fromconstructing thread?
In-Reply-To: <44898636.6020501@dotech.com>
References: <44898636.6020501@dotech.com>
Message-ID: <4489A27A.6090403@tackline.plus.com>

Kris Schneider wrote:
> I need to ensure that a Callable is called from the same thread within 
> which it was constructed:

> The two approaches that immediately came to mind were to use a reference 
> object or System.identityHashCode(Thread.currentThread()). Any thoughts on 
> which might be better or if there are other approaches that are better 
> still? Thanks.

System.identityHashCode does not produce unique values. A very common 
mistake - the documentation is a bit poor.

I guess Thread.currentThread().getId() should work (since 1.5), as 
should new WeakReference<Thread>(Thread.currentThread()).

Tom Hawtin


From kris at dotech.com  Fri Jun  9 14:46:22 2006
From: kris at dotech.com (Kris Schneider)
Date: Fri, 09 Jun 2006 14:46:22 -0400
Subject: [concurrency-interest] Ensure Callable.call is invoked
 fromconstructing thread?
In-Reply-To: <4489A27A.6090403@tackline.plus.com>
References: <44898636.6020501@dotech.com> <4489A27A.6090403@tackline.plus.com>
Message-ID: <4489C1FE.7030308@dotech.com>

Thomas Hawtin wrote:
> Kris Schneider wrote:
> 
>>I need to ensure that a Callable is called from the same thread within 
>>which it was constructed:
> 
> 
>>The two approaches that immediately came to mind were to use a reference 
>>object or System.identityHashCode(Thread.currentThread()). Any thoughts on 
>>which might be better or if there are other approaches that are better 
>>still? Thanks.
> 
> 
> System.identityHashCode does not produce unique values. A very common 
> mistake - the documentation is a bit poor.

Nice. Good to know.

> I guess Thread.currentThread().getId() should work (since 1.5), as 
> should new WeakReference<Thread>(Thread.currentThread()).

This has to work on 1.4.2, so no go with getId. It looks like the ID of a 
terminated thread can be reused, so I'd probably steer clear of that even 
for 1.5. So, that leaves ref object and ThreadLocal (per Tim). Thanks to 
both of you for the feedback so far.

> Tom Hawtin

-- 
Kris Schneider <mailto:kris at dotech.com>
D.O.Tech       <http://www.dotech.com/>

From Jan.Nielsen at sungardhe.com  Fri Jun  9 15:37:58 2006
From: Jan.Nielsen at sungardhe.com (Jan Nielsen)
Date: Fri, 9 Jun 2006 13:37:58 -0600
Subject: [concurrency-interest] Ensure Callable.call is invoked
 fromconstructing thread?
In-Reply-To: <4489C1FE.7030308@dotech.com>
Message-ID: <OF48E57B47.AF6AF280-ON87257188.006AE6E0-87257188.006BD8E9@sungardhe.com>

Kris,

For what it's worth, I use a ThreadLocal for this type of problem in 
several areas of my code; I don't see any performance problems with 
ThreadLocal in my use-cases.


-Jan


Jan Nielsen * System Architect * SunGard Higher Education * Tel +1 801 257 
4155 * Fax +1 801 485 6606 * jan.nielsen at sungardhe.com * www.sungardhe.com 
* 90 South 400 West, Suite 500, Salt Lake City, UT USA

CONFIDENTIALITY: This email (including any attachments) may contain 
confidential, proprietary and privileged information, and unauthorized 
disclosure or use is prohibited.  If you received this email in error, 
please notify the sender and delete this email from your system. Thank 
you.



Kris Schneider <kris at dotech.com> 
Sent by: concurrency-interest-bounces at cs.oswego.edu
06/09/2006 12:46 PM

To
concurrency-interest at cs.oswego.edu
cc

Subject
Re: [concurrency-interest] Ensure Callable.call is invoked 
fromconstructing thread?






Thomas Hawtin wrote:
> Kris Schneider wrote:
> 
>>I need to ensure that a Callable is called from the same thread within 
>>which it was constructed:
> 
> 
>>The two approaches that immediately came to mind were to use a reference 

>>object or System.identityHashCode(Thread.currentThread()). Any thoughts 
on 
>>which might be better or if there are other approaches that are better 
>>still? Thanks.
> 
> 
> System.identityHashCode does not produce unique values. A very common 
> mistake - the documentation is a bit poor.

Nice. Good to know.

> I guess Thread.currentThread().getId() should work (since 1.5), as 
> should new WeakReference<Thread>(Thread.currentThread()).

This has to work on 1.4.2, so no go with getId. It looks like the ID of a 
terminated thread can be reused, so I'd probably steer clear of that even 
for 1.5. So, that leaves ref object and ThreadLocal (per Tim). Thanks to 
both of you for the feedback so far.

> Tom Hawtin

-- 
Kris Schneider <mailto:kris at dotech.com>
D.O.Tech       <http://www.dotech.com/>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest



From Pete.Soper at Sun.COM  Fri Jun  9 16:46:25 2006
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Fri, 09 Jun 2006 16:46:25 -0400
Subject: [concurrency-interest] Need one more reviewer,
 please Re:  new SerialNum example for ThreadLocal class	doc
In-Reply-To: <4488542E.2010703@Sun.COM>
References: <4488542E.2010703@Sun.COM>
Message-ID: <4489DE21.6010601@Sun.COM>

Thanks for all the high quality input. I will send a 'final' version for 
review but I have to finish the unit test and I picked a bad time to 
come up to speed on NetBeans (but it is *absolutely fabulous* and I 
haven't had such a cool tool as this in a long time).

But here's the "current" version sans "*" and HTML escapes.
Josh: I'm using latest jstyle and will get that sorted if this version 
isn't right yet. Thanks for the gentle feedback.
Brian: I will get back to that other example with you soonest.

(again, comments directly to me, please)

I should also note that because the example starting this review was a 
"suggested fix" for a bug I'm not constrained by Sun licensing 
restrictions. It would not be wise to cut and paste source out of the 
JDk and do this kind of thing (at least not yet!).

-Pete
--------------
import java.util.concurrent.atomic.AtomicInteger;

public class UniqueThreadIdGenerator {

     private static final AtomicInteger i = new AtomicInteger(0);

     private static final ThreadLocal<Integer> uniqueNum =
         new ThreadLocal<Integer>() {
             @Override protected Integer initialValue() {
                 return i.getAndIncrement();
             }
     };

     public static int getCurrentThreadId() {
         return i.get();
     }
} // UniqueThreadIdGenerator

From dhanji at gmail.com  Fri Jun  9 22:36:58 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Sat, 10 Jun 2006 12:36:58 +1000
Subject: [concurrency-interest] Ensure Callable.call is invoked
	fromconstructing thread?
In-Reply-To: <4489A27A.6090403@tackline.plus.com>
References: <44898636.6020501@dotech.com> <4489A27A.6090403@tackline.plus.com>
Message-ID: <aa067ea10606091936o73c087c9je8c8eb9ad71081a1@mail.gmail.com>

On 6/10/06, Thomas Hawtin <tackline at tackline.plus.com> wrote:
>
> System.identityHashCode does not produce unique values. A very common
> mistake - the documentation is a bit poor.
>
This is very interesting, identifying transient instances uniquely is
quite a common design problem for me. One good solution I find is
using IoC to instantiate/register your objects and store a unique id
for each, then query the container for the id. I'd venture that using
a thread pool similarly (with a unique checkout id) would be a good
solution if your architecture allows for it. just a thought.

> I guess Thread.currentThread().getId() should work (since 1.5), as
> should new WeakReference<Thread>(Thread.currentThread()).
>
> Tom Hawtin
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From joe.bowbeer at gmail.com  Mon Jun 12 20:55:42 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 12 Jun 2006 17:55:42 -0700
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <31f2a7bd0606060708k3de18659k15f2a97dcdbd14b5@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
	<31f2a7bd0606060708k3de18659k15f2a97dcdbd14b5@mail.gmail.com>
Message-ID: <31f2a7bd0606121755o11340c27ua506f20f9bd16013@mail.gmail.com>

On 6/6/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> On 6/6/06, Greg Luck <gluck at gregluck.com> wrote:
> >
> > I have tested the hash code spreader.  It performs noticeably poorer than
> > using key.hashCode(), which spread evenly with the full distribution within
> > +- 20%.
> > This new one is +- 49%.
> >
>
> Are you sure the hash spreader isn't increasing randomness, resulting
> in more bumps?  In other words, is smoother really better?
>

Follow-up:

I ran your test using a pseudo random number generator in place of a
hash function and found that ranges of +/- 50% or more are not
uncommon.  (I observed 19 <= count <= 61.)

This suggests that the hash-spreader *is* producing more random
assignments, as desired.

If the hash function is random, then I think the sums should be
normally distributed, in which case a fairly wide distribution is
likely.  (How unlikely is is that the sums all lie within +/- 20% of
the mean?)

The less normal the distribution, the less random the hash function,
and the more likely it is that certain sets of data will amplify
patterns inherent in the hash function, resulting in undesirable lock
contention.

    public static final int NUM_BUCKETS = 128;
    public static final int NUM_TRIALS = 5000;

    public static void main(String[] args) {
        Random rnd = new Random();
        int[] bucket = new int[NUM_BUCKETS];
        for (int n = NUM_TRIALS; --n >= 0; )
            bucket[rnd.nextInt(bucket.length)]++;
        int[] sum = new int[bucket.length];
        for (int i : bucket)
            sum[i]++;
        SortedMap<Integer,Integer> map =
                new TreeMap<Integer,Integer>();
        for (int i = 0; i < sum.length; i++)
            if (sum[i] != 0)
                map.put(i, sum[i]);
        System.out.println(map);
    }

--Joe

From joe.bowbeer at gmail.com  Tue Jun 13 03:22:04 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 13 Jun 2006 00:22:04 -0700
Subject: [concurrency-interest] Problem with using an unbounded map of
	Mutex lock objects
In-Reply-To: <31f2a7bd0606121755o11340c27ua506f20f9bd16013@mail.gmail.com>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>
	<4480B306.2050905@quiotix.com>
	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>
	<4480BC44.7080700@quiotix.com>
	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<25CBE125-17F7-497C-8BFD-1D09632EA597@gregluck.com>
	<31f2a7bd0606060708k3de18659k15f2a97dcdbd14b5@mail.gmail.com>
	<31f2a7bd0606121755o11340c27ua506f20f9bd16013@mail.gmail.com>
Message-ID: <31f2a7bd0606130022t62b7ece2qd8a4732a5282d6ea@mail.gmail.com>

Correction:

I wrote:

> If the hash function is random, then I think the sums should be
> normally distributed, in which case a fairly wide distribution is
> likely.  (How unlikely is it that the sums all lie within +/- 20% of
> the mean?)
>
> The less normal the distribution, the less random the hash function,
> and the more likely it is that certain sets of data will amplify
> patterns inherent in the hash function, resulting in undesirable lock
> contention.
>

Scratch the bit about "normal distribution".  It's probably not true
and it just confuses the issue anyway.

The point I'm trying to make is that a random number generator will
not typically produce hit counts within +/- 20% of the mean in only
5000 trials, so I think it's unreasonable to expect a hash function to
do that well.

(Is there a statistician in the house?  With 128 buckets and 5000
random trials, how unlikely is it that the hit counts all lie within
+/- 20% of the mean?)

I corrected a bug in my code and added more info to the printout:

import java.security.SecureRandom;
import java.util.Random;
import java.util.SortedMap;
import java.util.TreeMap;

public class BucketTest {

    public static final int NUM_BUCKETS = 128;
    public static final int NUM_TRIALS = 5000;

    public static void main(String[] args) {
        Random rnd = new SecureRandom();
        int[] bucket = new int[NUM_BUCKETS];
        for (int n = NUM_TRIALS; --n >= 0; )
            bucket[rnd.nextInt(bucket.length)]++;
        int[] sum = new int[NUM_TRIALS];
        for (int i = 0; i < bucket.length; i++)
            sum[bucket[i]]++;
        SortedMap<Integer, Integer> map =
                new TreeMap<Integer, Integer>();
        for (int i = 0; i < sum.length; i++)
            if (sum[i] != 0)
                map.put(i, sum[i]);
        System.out.println(map);
        double mean = (double) NUM_TRIALS / NUM_BUCKETS;
        System.out.println(
            ((mean - map.firstKey()) * 100.0 / mean) + "% - " +
            ((map.lastKey() - mean)  * 100.0 / mean) + "%");
    }
}

run:

hit counts: {20=1, 27=4, ... , 53=1, 56=1}

range: 48.8% - 43.36%

--Joe

From dl at cs.oswego.edu  Fri Jun 16 15:27:55 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 16 Jun 2006 15:27:55 -0400
Subject: [concurrency-interest] Improving ThreadPoolExecutor.shutdownNow
	guarantees
Message-ID: <4493063B.6090502@cs.oswego.edu>


The return value of ThreadPoolExecutor.shutdownNow was not very
well-defined, either in spec or implementation. This method claimed
to return a list of tasks that had not run. But:
   1. What about tasks that are in the midst of being entered DURING
      the call to shutdownNow?
   2. Are those tasks deleted from the task queue upon return?

There were no official answers, but the unofficial
answer to the first question was: no answer -- they might
be dropped, rejected, returned in list, or sit in queue.
And the answer to the second was no, which because of the
first issue, meant that you could not rely on queue state.

There's probably not any code out there that depends on these
details, but we still want to get them right after noticing
how crummy this situation is. So, we improved
this to guarantee that ALL tasks (even those in the midst of
being entered) are run, rejected or returned in list (exactly one
of these), and remove them from queue upon return from shutdownNow,
which guarantees that traversals of results from multiple calls
won't encounter them multiple times.

This change probably won't make Mustang (which means that it might
be a while before they get into any Sun release) but we'd welcome
any comments or suggestions about them. You can find details in
CVS versions of code base.

-Doug




From ben at hf.webex.com  Sat Jun 17 12:14:49 2006
From: ben at hf.webex.com (Ben)
Date: Sun, 18 Jun 2006 00:14:49 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606180014.AA21576@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From yechielf at gigaspaces.com  Sun Jun 18 07:42:16 2006
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Sun, 18 Jun 2006 13:42:16 +0200
Subject: [concurrency-interest] a question regarding the double-checked
	locking
Message-ID: <D166C96F43D1D611B8E3000255A0C48C6BE9A8@OFFICESRV>

Hi all
will the following double-checked locking code work ?
note that when instance   is assigned a ref to the object, its after the
assigning thread have exited the inner synchronized block,
so the ref dummy_instance must contain a completly initialized object image.
If it works, will replacing the inner synchronized by a  dummy_instance
which is volatile do the job too ?
Are there compiler optimizations which "unify" nested lockes ?
  
 
 
private static Something instance = null;
private  Something dummy_instance = null;


public Something getInstance() {
  if (instance == null) {
    synchronized (some object A) {
        synchronized (some object B) {
          if (instance == null)
            dummy_instance = new Something();
        }
        instance = dummy_instance;
            }
    }
  }
  return instance;
}

Regrds,
Yechiel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060618/bd663bf0/attachment.html 

From dcholmes at optusnet.com.au  Sun Jun 18 07:20:11 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sun, 18 Jun 2006 21:20:11 +1000
Subject: [concurrency-interest] a question regarding the
	double-checkedlocking
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BE9A8@OFFICESRV>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEGAGPAA.dcholmes@optusnet.com.au>

I don't quite understand the static versus non-static parts of this. What
are "some object a" and "some object b" ?  A happens-before relationship
only occurs between an unlock and subsequent lock of a monitor on the same
object.

But why would you bother even trying this when a single lock and making the
static instance volatile will work. Or even better use static
initialization, whether direct or via the static nested class idiom.

You have to ensure there is a happens-before relationship between the
construction of the instance, the writing of the instanace field ref and the
subsequent reading of it. I just described the minimal solution. There are
probably an unlimited number of strange things you could do to get the same
effect.

Don't know what you mean by "unify" nested locks. The compiler can't do
anything you could detect in the program as being incorrect.

Cheers,
David Holmes

 -----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
Sent: Sunday, 18 June 2006 9:42 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] a question regarding the
double-checkedlocking


  Hi all
  will the following double-checked locking code work ?
  note that when instance   is assigned a ref to the object, its after the
assigning thread have exited the inner synchronized block,
  so the ref dummy_instance must contain a completly initialized object
image.
  If it works, will replacing the inner synchronized by a  dummy_instance
which is volatile do the job too ?
  Are there compiler optimizations which "unify" nested lockes ?



  private static Something instance = null;
  private  Something dummy_instance = null;


  public Something getInstance() {
    if (instance == null) {
      synchronized (some object A) {
          synchronized (some object B) {
            if (instance == null)
              dummy_instance = new Something();
          }
          instance = dummy_instance;
              }
      }
    }
    return instance;
  }

  Regrds,
  Yechiel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060618/2147e27f/attachment.html 

From yechielf at gigaspaces.com  Sun Jun 18 09:15:25 2006
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Sun, 18 Jun 2006 15:15:25 +0200
Subject: [concurrency-interest] a question regarding the
	double-checke	dlocking
Message-ID: <D166C96F43D1D611B8E3000255A0C48C6BE9AB@OFFICESRV>

Thanks.
Lets ignore the static, my mistake.
I want to avoid declaring the instance ref as volatile and pay the price
volatile-check in every instance check.
I was referring to the example of double-checked locking from jsr133 FAQ
http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl
<http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl> 
 
which I altered a little. Object A and Object B are just 2 objects
constructed when the main object was created.
Since , upon monitor release, the cache is flushed to main memory, and since
the "instance" ref is updated only after the inner monitor is exited and the
"Something" object created
inside it, would it ensure a consistent view of the instance pointed-to
object ? 
 
 

-----Original Message-----
From: David Holmes [mailto:dcholmes at optusnet.com.au]
Sent: Sunday, June 18, 2006 13:20
To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] a question regarding the
double-checkedlocking


I don't quite understand the static versus non-static parts of this. What
are "some object a" and "some object b" ?  A happens-before relationship
only occurs between an unlock and subsequent lock of a monitor on the same
object.
 
But why would you bother even trying this when a single lock and making the
static instance volatile will work. Or even better use static
initialization, whether direct or via the static nested class idiom.
 
You have to ensure there is a happens-before relationship between the
construction of the instance, the writing of the instanace field ref and the
subsequent reading of it. I just described the minimal solution. There are
probably an unlimited number of strange things you could do to get the same
effect.
 
Don't know what you mean by "unify" nested locks. The compiler can't do
anything you could detect in the program as being incorrect.
 
Cheers,
David Holmes
 
 -----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
Sent: Sunday, 18 June 2006 9:42 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] a question regarding the
double-checkedlocking



Hi all
will the following double-checked locking code work ?
note that when instance   is assigned a ref to the object, its after the
assigning thread have exited the inner synchronized block,
so the ref dummy_instance must contain a completly initialized object image.
If it works, will replacing the inner synchronized by a  dummy_instance
which is volatile do the job too ?
Are there compiler optimizations which "unify" nested lockes ?
  
 
 
private static Something instance = null;

private  Something dummy_instance = null;


public Something getInstance() {
  if (instance == null) {
    synchronized (some object A) {
        synchronized (some object B) {
          if (instance == null)
            dummy_instance = new Something();
        }
        instance = dummy_instance;
            }
    }
  }
  return instance;
}

Regrds,
Yechiel

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060618/a72602b5/attachment-0001.html 

From ben at hf.webex.com  Sun Jun 18 08:13:00 2006
From: ben at hf.webex.com (Ben)
Date: Sun, 18 Jun 2006 20:13:00 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606182013.AA55481@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From chris.purcell.39 at gmail.com  Sun Jun 18 09:38:37 2006
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Sun, 18 Jun 2006 14:38:37 +0100
Subject: [concurrency-interest] a question regarding the double-checke
	dlocking
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BE9AB@OFFICESRV>
References: <D166C96F43D1D611B8E3000255A0C48C6BE9AB@OFFICESRV>
Message-ID: <4856e16d0606180638l59066fd0n91e04ddef7834810@mail.gmail.com>

> Since , upon monitor release, the cache is flushed to main memory, and since
> the "instance" ref is updated only after the inner monitor is exited and the
> "Something" object created
> inside it, would it ensure a consistent view of the instance pointed-to
> object ?

IIRC, writes can be pulled up before monitor exits. Or, to put it
another way, there's a happens-before between your `new something()`
and the atomic updates ending the synchronized block around it, but no
happen-before between your `new something()` and your `instance =
dummy_instance`.

Also, there's no happens-before between your reading the reference and
your reading the instance it refers to. I'm not sure where Java sits
on the issue of dependencies, but you might luck out there too.

In conclusion, to the best of my recollection, it won't work. Can you
just use the Initialization On Demand idiom, which is known to work?

Cheers,
Chris

From ben at hf.webex.com  Sun Jun 18 12:10:17 2006
From: ben at hf.webex.com (Ben)
Date: Mon, 19 Jun 2006 00:10:17 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606190010.AA62717@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From dcholmes at optusnet.com.au  Sun Jun 18 19:19:22 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 19 Jun 2006 09:19:22 +1000
Subject: [concurrency-interest] a question regarding
	thedouble-checke	dlocking
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BE9AB@OFFICESRV>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEGCGPAA.dcholmes@optusnet.com.au>

Thinking of this in terms of "cache flushing" is guaranteed to get you into
trouble. On mainstream PC hardware for example, the cache never needs to be
flushed. The memory model establishes happens-before orderings between
operations and, in simple terms, that means the reader that sees ref as
non-null and the writer that creates the object and sets the ref non-null
*must* either lock/unlock the same monitor or read/write the same volatile
field. Neither of which occurs in your code and so the requisite
happens-before ordering is not present.

Reading a volatile field is almost free on many systems. What platform are
you concerned with?

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
  Sent: Sunday, 18 June 2006 11:15 PM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] a question regarding thedouble-checke
dlocking


  Thanks.
  Lets ignore the static, my mistake.
  I want to avoid declaring the instance ref as volatile and pay the price
volatile-check in every instance check.
  I was referring to the example of double-checked locking from jsr133 FAQ
  http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl

  which I altered a little. Object A and Object B are just 2 objects
constructed when the main object was created.
  Since , upon monitor release, the cache is flushed to main memory, and
since the "instance" ref is updated only after the inner monitor is exited
and the "Something" object created
  inside it, would it ensure a consistent view of the instance pointed-to
object ?


    -----Original Message-----
    From: David Holmes [mailto:dcholmes at optusnet.com.au]
    Sent: Sunday, June 18, 2006 13:20
    To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] a question regarding the
double-checkedlocking


    I don't quite understand the static versus non-static parts of this.
What are "some object a" and "some object b" ?  A happens-before
relationship only occurs between an unlock and subsequent lock of a monitor
on the same object.

    But why would you bother even trying this when a single lock and making
the static instance volatile will work. Or even better use static
initialization, whether direct or via the static nested class idiom.

    You have to ensure there is a happens-before relationship between the
construction of the instance, the writing of the instanace field ref and the
subsequent reading of it. I just described the minimal solution. There are
probably an unlimited number of strange things you could do to get the same
effect.

    Don't know what you mean by "unify" nested locks. The compiler can't do
anything you could detect in the program as being incorrect.

    Cheers,
    David Holmes

     -----Original Message-----
    From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
    Sent: Sunday, 18 June 2006 9:42 PM
    To: concurrency-interest at cs.oswego.edu
    Subject: [concurrency-interest] a question regarding the
double-checkedlocking


      Hi all
      will the following double-checked locking code work ?
      note that when instance   is assigned a ref to the object, its after
the assigning thread have exited the inner synchronized block,
      so the ref dummy_instance must contain a completly initialized object
image.
      If it works, will replacing the inner synchronized by a
dummy_instance which is volatile do the job too ?
      Are there compiler optimizations which "unify" nested lockes ?



      private static Something instance = null;
      private  Something dummy_instance = null;


      public Something getInstance() {
        if (instance == null) {
          synchronized (some object A) {
              synchronized (some object B) {
                if (instance == null)
                  dummy_instance = new Something();
              }
              instance = dummy_instance;
                  }
          }
        }
        return instance;
      }

      Regrds,
      Yechiel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060619/b875fe9f/attachment.html 

From yechielf at gigaspaces.com  Mon Jun 19 05:29:08 2006
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Mon, 19 Jun 2006 11:29:08 +0200
Subject: [concurrency-interest] a question regarding
	thedouble-checke		dlocking
Message-ID: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>

I am concerned with general correctness of my code,
want to avoid the price of volatile, here is a quote from jsr133 FAQ
"However, for fans of double-checked locking (and we really hope there are
none left), the news is still not good. The whole point of double-checked
locking was to avoid the performance overhead of synchronization. Not only
has brief synchronization gotten a LOT less expensive since the Java 1.0
days, but under the new memory model, the performance cost of using volatile
goes up, almost to the level of the cost of synchronization. So there's
still no good reason to use double-checked-locking"
 
 
 

-----Original Message-----
From: David Holmes [mailto:dcholmes at optusnet.com.au]
Sent: Monday, June 19, 2006 01:19
To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] a question regarding thedouble-checke
dlocking


Thinking of this in terms of "cache flushing" is guaranteed to get you into
trouble. On mainstream PC hardware for example, the cache never needs to be
flushed. The memory model establishes happens-before orderings between
operations and, in simple terms, that means the reader that sees ref as
non-null and the writer that creates the object and sets the ref non-null
*must* either lock/unlock the same monitor or read/write the same volatile
field. Neither of which occurs in your code and so the requisite
happens-before ordering is not present.
 
Reading a volatile field is almost free on many systems. What platform are
you concerned with?
 
Cheers,
David Holmes

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
Sent: Sunday, 18 June 2006 11:15 PM
To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] a question regarding thedouble-checke
dlocking


Thanks.
Lets ignore the static, my mistake.
I want to avoid declaring the instance ref as volatile and pay the price
volatile-check in every instance check.
I was referring to the example of double-checked locking from jsr133 FAQ
http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl
<http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl> 
 
which I altered a little. Object A and Object B are just 2 objects
constructed when the main object was created.
Since , upon monitor release, the cache is flushed to main memory, and since
the "instance" ref is updated only after the inner monitor is exited and the
"Something" object created
inside it, would it ensure a consistent view of the instance pointed-to
object ? 
 
 

-----Original Message-----
From: David Holmes [mailto:dcholmes at optusnet.com.au]
Sent: Sunday, June 18, 2006 13:20
To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
Subject: RE: [concurrency-interest] a question regarding the
double-checkedlocking


I don't quite understand the static versus non-static parts of this. What
are "some object a" and "some object b" ?  A happens-before relationship
only occurs between an unlock and subsequent lock of a monitor on the same
object.
 
But why would you bother even trying this when a single lock and making the
static instance volatile will work. Or even better use static
initialization, whether direct or via the static nested class idiom.
 
You have to ensure there is a happens-before relationship between the
construction of the instance, the writing of the instanace field ref and the
subsequent reading of it. I just described the minimal solution. There are
probably an unlimited number of strange things you could do to get the same
effect.
 
Don't know what you mean by "unify" nested locks. The compiler can't do
anything you could detect in the program as being incorrect.
 
Cheers,
David Holmes
 
 -----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
Sent: Sunday, 18 June 2006 9:42 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] a question regarding the
double-checkedlocking



Hi all
will the following double-checked locking code work ?
note that when instance   is assigned a ref to the object, its after the
assigning thread have exited the inner synchronized block,
so the ref dummy_instance must contain a completly initialized object image.
If it works, will replacing the inner synchronized by a  dummy_instance
which is volatile do the job too ?
Are there compiler optimizations which "unify" nested lockes ?
  
 
 
private static Something instance = null;

private  Something dummy_instance = null;


public Something getInstance() {
  if (instance == null) {
    synchronized (some object A) {
        synchronized (some object B) {
          if (instance == null)
            dummy_instance = new Something();
        }
        instance = dummy_instance;
            }
    }
  }
  return instance;
}

Regrds,
Yechiel

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060619/797a9003/attachment-0001.html 

From kaa at pax.priv.no  Mon Jun 19 04:17:58 2006
From: kaa at pax.priv.no (=?ISO-8859-1?Q?Kolbj=F8rn_Aamb=F8?=)
Date: Mon, 19 Jun 2006 10:17:58 +0200
Subject: [concurrency-interest] problem with ReentrantReadWriteLock to
	implement atomic function
In-Reply-To: <448569F3.8050800@cs.oswego.edu>
References: <A397B776-BE4D-4F79-B053-F16654D354A5@gregluck.com>	<4480B306.2050905@quiotix.com>	<D6A86189-6D2F-4EB3-9D0B-9A15360151B8@gregluck.com>	<4480BC44.7080700@quiotix.com>	<19271BC7-B11A-4F67-996B-FEF5FDCD61CF@gregluck.com>
	<31f2a7bd0606060336jc976dd6r8d737ee667967876@mail.gmail.com>
	<448569F3.8050800@cs.oswego.edu>
Message-ID: <F6729585-C377-49D3-9719-35E9A269B7BB@pax.priv.no>

In the code below I try to make an atomic put function. I suspect  
that my implementation that divide the function
into to try blocks, one for reading and then one for writing will not  
be atomic since there are two try blocks.

I have tried to implement the function with one try block first but  
stumpled as seen below. Can you give me some
advice?

Best wishes

Kolbj?rn Aamb?, Oslo



//
//  Unique.java
//  JT1
//
//  Created by Kolbj?rn Aamb? on 2/1/06.
//  Copyright 2006 __MyCompanyName__. All rights reserved.
//
import java.util.concurrent.*;
import java.util.concurrent.locks.*;
import java.util.*;

public class Unique<K extends Comparable<K>, V extends Comparable<V>> {
	private ConcurrentHashMap<K, V> K_V = new ConcurrentHashMap<K, V>();
	private ConcurrentHashMap<V, K> V_K = new ConcurrentHashMap<V, K>();
	//private Map<V, K> V_K_Text = new TreeMap<V, K>();
	private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock 
();
	private final Lock r = rwl.readLock();
     private final Lock w = rwl.writeLock();
	
	public Unique () {}
	
	public V put(K key, V value){
	// Tested to be lock robust for upt to 300K Objects 060608
		boolean hasValue = V_K.containsKey(value);
		boolean hasKey = K_V.containsKey(key);
		V value2 = null;
		
		r.lock();
		try {
			hasValue = V_K.containsKey(value);
			hasKey = K_V.containsKey(key);
		} finally {
			r.unlock();
		}

		if (!hasValue){// No preexisting occurrence of value
			w.lock();
			try {
				if (hasKey) V_K.remove(K_V.get(key));
				V_K.put(value, key);
				value2 = K_V.put(key, value);
			} finally {
				w.unlock();
			}
		}
		
		/* The code above works (I think) but the code below, that I  
thought was the
		   the more appropriate  way of doing locking to get atomic  
functionality stops like
		   this at about 65K inserts...:
		
		:
		64000.0/640000.0  10 insert/ms
		65000.0/650000.0  4 insert/ms
		[LaunchRunner Error] JTally.main(String[]) threw an exception:
		java.lang.IllegalMonitorStateException
			at java.util.concurrent.locks.ReentrantReadWriteLock 
$Sync.tryReleaseShared(ReentrantReadWriteLock.java:275)
			at  
java.util.concurrent.locks.AbstractQueuedSynchronizer.releaseShared 
(AbstractQueuedSynchronizer.java:1180)
			at java.util.concurrent.locks.ReentrantReadWriteLock 
$ReadLock.unlock(ReentrantReadWriteLock.java:576)
			at Unique.put(Unique.java:61)
			at Tally.put(Tally.java:116)
			at tryTally.testCombinedUNIQUE13(tryTally.java:41)
			at JTally.main(JTally.java:272)
			at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
			at sun.reflect.NativeMethodAccessorImpl.invoke 
(NativeMethodAccessorImpl.java:39)
			at sun.reflect.DelegatingMethodAccessorImpl.invoke 
(DelegatingMethodAccessorImpl.java:25)
			at java.lang.reflect.Method.invoke(Method.java:585)
			at apple.launcher.LaunchRunner.run(LaunchRunner.java:88)
			at apple.launcher.LaunchRunner.callMain(LaunchRunner.java:50)
			at apple.launcher.JavaApplicationLauncher.launch 
(JavaApplicationLauncher.java:52)

		JTally has exited with status 0.
	 */
/*
		
		r.lock();
		try {
			hasValue = V_K.containsKey(value);
			hasKey = K_V.containsKey(key);

			if (!hasValue){// No preexisting occurrence of value
				r.unlock();
				w.lock();
				if (hasKey) V_K.remove(K_V.get(key));
				V_K.put(value, key);
				value2 = K_V.put(key, value);
				r.lock(); // Downgrading the lock to read lock
			}
		} finally {
			r.unlock();
		}
*/
		return value2;
	}// put(..)
	
	
	public V get(K key){
		return K_V.get(key);
	}
	
	public K getKey(V value){
		return V_K.get(value);
	}
	
	public boolean containsKey(Object key){
		return K_V.containsKey(key);
	}
	
	public boolean containsValue(Object value){
		return V_K.containsKey(value);
	}
	
	public boolean contains(Object value){// for compatability with  
hashtable
		return V_K.containsKey(value);
	}
	

}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060619/1c3e2c49/attachment-0001.html 

From dcholmes at optusnet.com.au  Mon Jun 19 04:20:44 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 19 Jun 2006 18:20:44 +1000
Subject: [concurrency-interest] a question regarding
	thedouble-checke	dlocking
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEGFGPAA.dcholmes@optusnet.com.au>

That quote is somewhat dated and was deliberately trying to dissuade people
from thinking they need DCL. There were some recent posts concerning the
costs of volatiles, I'll see if I can dig up a specific reference.

Otherwise use the initialization holder idiom to avoid the need for the
volatile.

Cheers,
David Holmes
  -----Original Message-----
  From: Yechiel Feffer [mailto:yechielf at gigaspaces.com]
  Sent: Monday, 19 June 2006 7:29 PM
  To: dholmes at ieee.org; Yechiel Feffer; concurrency-interest at cs.oswego.edu
  Subject: RE: [concurrency-interest] a question regarding thedouble-checke
dlocking


  I am concerned with general correctness of my code,
  want to avoid the price of volatile, here is a quote from jsr133 FAQ
  "However, for fans of double-checked locking (and we really hope there are
none left), the news is still not good. The whole point of double-checked
locking was to avoid the performance overhead of synchronization. Not only
has brief synchronization gotten a LOT less expensive since the Java 1.0
days, but under the new memory model, the performance cost of using volatile
goes up, almost to the level of the cost of synchronization. So there's
still no good reason to use double-checked-locking"



    -----Original Message-----
    From: David Holmes [mailto:dcholmes at optusnet.com.au]
    Sent: Monday, June 19, 2006 01:19
    To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
    Subject: RE: [concurrency-interest] a question regarding
thedouble-checke dlocking


    Thinking of this in terms of "cache flushing" is guaranteed to get you
into trouble. On mainstream PC hardware for example, the cache never needs
to be flushed. The memory model establishes happens-before orderings between
operations and, in simple terms, that means the reader that sees ref as
non-null and the writer that creates the object and sets the ref non-null
*must* either lock/unlock the same monitor or read/write the same volatile
field. Neither of which occurs in your code and so the requisite
happens-before ordering is not present.

    Reading a volatile field is almost free on many systems. What platform
are you concerned with?

    Cheers,
    David Holmes
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
      Sent: Sunday, 18 June 2006 11:15 PM
      To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] a question regarding
thedouble-checke dlocking


      Thanks.
      Lets ignore the static, my mistake.
      I want to avoid declaring the instance ref as volatile and pay the
price volatile-check in every instance check.
      I was referring to the example of double-checked locking from jsr133
FAQ
      http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#dcl

      which I altered a little. Object A and Object B are just 2 objects
constructed when the main object was created.
      Since , upon monitor release, the cache is flushed to main memory, and
since the "instance" ref is updated only after the inner monitor is exited
and the "Something" object created
      inside it, would it ensure a consistent view of the instance
pointed-to object ?


        -----Original Message-----
        From: David Holmes [mailto:dcholmes at optusnet.com.au]
        Sent: Sunday, June 18, 2006 13:20
        To: Yechiel Feffer; concurrency-interest at cs.oswego.edu
        Subject: RE: [concurrency-interest] a question regarding the
double-checkedlocking


        I don't quite understand the static versus non-static parts of this.
What are "some object a" and "some object b" ?  A happens-before
relationship only occurs between an unlock and subsequent lock of a monitor
on the same object.

        But why would you bother even trying this when a single lock and
making the static instance volatile will work. Or even better use static
initialization, whether direct or via the static nested class idiom.

        You have to ensure there is a happens-before relationship between
the construction of the instance, the writing of the instanace field ref and
the subsequent reading of it. I just described the minimal solution. There
are probably an unlimited number of strange things you could do to get the
same effect.

        Don't know what you mean by "unify" nested locks. The compiler can't
do anything you could detect in the program as being incorrect.

        Cheers,
        David Holmes

         -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yechiel
Feffer
        Sent: Sunday, 18 June 2006 9:42 PM
        To: concurrency-interest at cs.oswego.edu
        Subject: [concurrency-interest] a question regarding the
double-checkedlocking


          Hi all
          will the following double-checked locking code work ?
          note that when instance   is assigned a ref to the object, its
after the assigning thread have exited the inner synchronized block,
          so the ref dummy_instance must contain a completly initialized
object image.
          If it works, will replacing the inner synchronized by a
dummy_instance which is volatile do the job too ?
          Are there compiler optimizations which "unify" nested lockes ?



          private static Something instance = null;
          private  Something dummy_instance = null;


          public Something getInstance() {
            if (instance == null) {
              synchronized (some object A) {
                  synchronized (some object B) {
                    if (instance == null)
                      dummy_instance = new Something();
                  }
                  instance = dummy_instance;
                      }
              }
            }
            return instance;
          }

          Regrds,
          Yechiel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060619/a96f3920/attachment.html 

From ben at hf.webex.com  Mon Jun 19 04:33:07 2006
From: ben at hf.webex.com (Ben)
Date: Mon, 19 Jun 2006 16:33:07 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606191633.AA27339@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From ben at hf.webex.com  Mon Jun 19 04:33:19 2006
From: ben at hf.webex.com (Ben)
Date: Mon, 19 Jun 2006 16:33:19 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606191633.AA27346@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From dcholmes at optusnet.com.au  Mon Jun 19 09:18:39 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Mon, 19 Jun 2006 23:18:39 +1000
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <F6729585-C377-49D3-9719-35E9A269B7BB@pax.priv.no>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>

Brief comment: I think the IllegalMonitorStateException may be masking an
OutOfMemoryError. If you look at the problematic code it assumes no
exceptions occur.

  r.unlock();
  w.lock();
  if (hasKey) V_K.remove(K_V.get(key));
  V_K.put(value, key);
  value2 = K_V.put(key, value);
  r.lock(); // Downgrading the lock to read lock
  }
  } finally {
    r.unlock();
  }

Any exception at either put() will cause the finally to unlock the read
lock, which isn't locked.

David Holmes

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Kolbj?rn
Aamb?
Sent: Monday, 19 June 2006 6:18 PM
To: Doug Lea
Cc: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
toimplement atomic function


In the code below I try to make an atomic put function. I suspect that my
implementation that divide the function
into to try blocks, one for reading and then one for writing will not be
atomic since there are two try blocks.


I have tried to implement the function with one try block first but stumpled
as seen below. Can you give me some
advice?


Best wishes


Kolbj?rn Aamb?, Oslo






//
//  Unique.java
//  JT1
//
//  Created by Kolbj?rn Aamb? on 2/1/06.
//  Copyright 2006 __MyCompanyName__. All rights reserved.
//
import java.util.concurrent.*;
import java.util.concurrent.locks.*;
import java.util.*;


public class Unique<K extends Comparable<K>, V extends Comparable<V>> {
private ConcurrentHashMap<K, V> K_V = new ConcurrentHashMap<K, V>();
private ConcurrentHashMap<V, K> V_K = new ConcurrentHashMap<V, K>();
//private Map<V, K> V_K_Text = new TreeMap<V, K>();
private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
private final Lock r = rwl.readLock();
    private final Lock w = rwl.writeLock();


public Unique () {}


public V put(K key, V value){
// Tested to be lock robust for upt to 300K Objects 060608
boolean hasValue = V_K.containsKey(value);
boolean hasKey = K_V.containsKey(key);
V value2 = null;


r.lock();
try {
hasValue = V_K.containsKey(value);
hasKey = K_V.containsKey(key);
} finally {
r.unlock();
}


if (!hasValue){// No preexisting occurrence of value
w.lock();
try {
if (hasKey) V_K.remove(K_V.get(key));
V_K.put(value, key);
value2 = K_V.put(key, value);
} finally {
w.unlock();
}
}


/* The code above works (I think) but the code below, that I thought was the
  the more appropriate  way of doing locking to get atomic functionality
stops like
  this at about 65K inserts...:


:
64000.0/640000.0  10 insert/ms
65000.0/650000.0  4 insert/ms
[LaunchRunner Error] JTally.main(String[]) threw an exception:
java.lang.IllegalMonitorStateException
at
java.util.concurrent.locks.ReentrantReadWriteLock$Sync.tryReleaseShared(Reen
trantReadWriteLock.java:275)
at
java.util.concurrent.locks.AbstractQueuedSynchronizer.releaseShared(Abstract
QueuedSynchronizer.java:1180)
at
java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.unlock(ReentrantR
eadWriteLock.java:576)
at Unique.put(Unique.java:61)
at Tally.put(Tally.java:116)
at tryTally.testCombinedUNIQUE13(tryTally.java:41)
at JTally.main(JTally.java:272)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39
)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl
.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at apple.launcher.LaunchRunner.run(LaunchRunner.java:88)
at apple.launcher.LaunchRunner.callMain(LaunchRunner.java:50)
at
apple.launcher.JavaApplicationLauncher.launch(JavaApplicationLauncher.java:5
2)


JTally has exited with status 0.
 */
/*


r.lock();
try {
hasValue = V_K.containsKey(value);
hasKey = K_V.containsKey(key);


if (!hasValue){// No preexisting occurrence of value
r.unlock();
w.lock();
if (hasKey) V_K.remove(K_V.get(key));
V_K.put(value, key);
value2 = K_V.put(key, value);
r.lock(); // Downgrading the lock to read lock
}
} finally {
r.unlock();
}
*/
return value2;
}// put(..)




public V get(K key){
return K_V.get(key);
}


public K getKey(V value){
return V_K.get(value);
}


public boolean containsKey(Object key){
return K_V.containsKey(key);
}


public boolean containsValue(Object value){
return V_K.containsKey(value);
}


public boolean contains(Object value){// for compatability with hashtable
return V_K.containsKey(value);
}


}



From ben at hf.webex.com  Mon Jun 19 09:45:45 2006
From: ben at hf.webex.com (Ben)
Date: Mon, 19 Jun 2006 21:45:45 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606192145.AA37520@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From pugh at cs.umd.edu  Mon Jun 19 10:26:51 2006
From: pugh at cs.umd.edu (Bill Pugh)
Date: Mon, 19 Jun 2006 10:26:51 -0400
Subject: [concurrency-interest] a question regarding
	thedouble-checke		dlocking
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>
References: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>
Message-ID: <28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>


On Jun 19, 2006, at 5:29 AM, Yechiel Feffer wrote:

> I am concerned with general correctness of my code,
> want to avoid the price of volatile, here is a quote from jsr133 FAQ
> "However, for fans of double-checked locking (and we really hope  
> there are none left), the news is still not good. The whole point  
> of double-checked locking was to avoid the performance overhead of  
> synchronization. Not only has brief synchronization gotten a LOT  
> less expensive since the Java 1.0 days, but under the new memory  
> model, the performance cost of using volatile goes up, almost to  
> the level of the cost of synchronization. So there's still no good  
> reason to use double-checked-locking"
>


That is not from the JSR 133 FAQ.

The person who wrote that doesn't know what they are talking about.

The cost of a volatile read is significantly less than synchronization.
In fact, you would be hard pressed to find an increase over the cost of
a normal read in a double checked locking usage.

	Bill

From forax at univ-mlv.fr  Mon Jun 19 11:09:32 2006
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 19 Jun 2006 17:09:32 +0200
Subject: [concurrency-interest] a question regarding	thedouble-checke
 dlocking
In-Reply-To: <28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>
References: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>
	<28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>
Message-ID: <4496BE2C.1030003@univ-mlv.fr>

Bill Pugh a ?crit :
> On Jun 19, 2006, at 5:29 AM, Yechiel Feffer wrote:
>
>   
>> I am concerned with general correctness of my code,
>> want to avoid the price of volatile, here is a quote from jsr133 FAQ
>> "However, for fans of double-checked locking (and we really hope  
>> there are none left), the news is still not good. The whole point  
>> of double-checked locking was to avoid the performance overhead of  
>> synchronization. Not only has brief synchronization gotten a LOT  
>> less expensive since the Java 1.0 days, but under the new memory  
>> model, the performance cost of using volatile goes up, almost to  
>> the level of the cost of synchronization. So there's still no good  
>> reason to use double-checked-locking"
>>
>>     
>
>
> That is not from the JSR 133 FAQ.
>   
using google the quote seems issued from this thread :
http://www.theserverside.com/patterns/thread.tss?thread_id=39606#206141
not from the FAQ.
> The person who wrote that doesn't know what they are talking about.
>
> The cost of a volatile read is significantly less than synchronization.
> In fact, you would be hard pressed to find an increase over the cost of
> a normal read in a double checked locking usage.
>
> 	Bill
R?mi Forax


From pugh at cs.umd.edu  Mon Jun 19 11:49:42 2006
From: pugh at cs.umd.edu (Bill Pugh)
Date: Mon, 19 Jun 2006 11:49:42 -0400
Subject: [concurrency-interest] a question regarding
	thedouble-checke		dlocking
In-Reply-To: <28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>
References: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>
	<28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>
Message-ID: <1BD4FAE5-7348-4385-99A5-990654CA5CDD@cs.umd.edu>

Oops. Doug observed that it is actually on the JMM FAQ web page.

I believe that will be updated shortly.

	Bill

On Jun 19, 2006, at 10:26 AM, Bill Pugh wrote:

>
> On Jun 19, 2006, at 5:29 AM, Yechiel Feffer wrote:
>
>> I am concerned with general correctness of my code,
>> want to avoid the price of volatile, here is a quote from jsr133 FAQ
>> "However, for fans of double-checked locking (and we really hope  
>> there are none left), the news is still not good. The whole point  
>> of double-checked locking was to avoid the performance overhead of  
>> synchronization. Not only has brief synchronization gotten a LOT  
>> less expensive since the Java 1.0 days, but under the new memory  
>> model, the performance cost of using volatile goes up, almost to  
>> the level of the cost of synchronization. So there's still no good  
>> reason to use double-checked-locking"
>>
>
>
> That is not from the JSR 133 FAQ.
>
> The person who wrote that doesn't know what they are talking about.
>
> The cost of a volatile read is significantly less than  
> synchronization.
> In fact, you would be hard pressed to find an increase over the  
> cost of
> a normal read in a double checked locking usage.
>
> 	Bill


From gergg at cox.net  Mon Jun 19 11:56:35 2006
From: gergg at cox.net (Gregg Wonderly)
Date: Mon, 19 Jun 2006 10:56:35 -0500
Subject: [concurrency-interest] a question regarding	thedouble-checke
 dlocking
In-Reply-To: <4496BE2C.1030003@univ-mlv.fr>
References: <D166C96F43D1D611B8E3000255A0C48C6BE9AC@OFFICESRV>	<28C1E614-7029-4762-9BAB-4E9D6876EC10@cs.umd.edu>
	<4496BE2C.1030003@univ-mlv.fr>
Message-ID: <4496C933.2020606@cox.net>

R?mi Forax wrote:
> Bill Pugh a ?crit :
>>On Jun 19, 2006, at 5:29 AM, Yechiel Feffer wrote:
>>>I am concerned with general correctness of my code,
>>>want to avoid the price of volatile, here is a quote from jsr133 FAQ
>>>"However, for fans of double-checked locking (and we really hope  
>>>there are none left), the news is still not good. The whole point  
>>>of double-checked locking was to avoid the performance overhead of  
>>>synchronization. Not only has brief synchronization gotten a LOT  
>>>less expensive since the Java 1.0 days, but under the new memory  
>>>model, the performance cost of using volatile goes up, almost to  
>>>the level of the cost of synchronization. So there's still no good  
>>>reason to use double-checked-locking"
>>
>>That is not from the JSR 133 FAQ.
>>  
> 
> using google the quote seems issued from this thread :
> http://www.theserverside.com/patterns/thread.tss?thread_id=39606#206141
> not from the FAQ.
> 
>>The person who wrote that doesn't know what they are talking about.
>>
>>The cost of a volatile read is significantly less than synchronization.
>>In fact, you would be hard pressed to find an increase over the cost of
>>a normal read in a double checked locking usage.

http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html

Does in fact contain the text:

     However, for fans of double-checked locking (and we really hope
     there are none left), the news is still not good. The whole
     point of double-checked locking was to avoid the performance
     overhead of synchronization. Not only has brief synchronization
     gotten a LOT less expensive since the Java 1.0 days, but under
     the new memory model, the performance cost of using volatile
     goes up, almost to the level of the cost of synchronization.
     So there's still no good reason to use double-checked-locking.

     Instead, use the Initialization On Demand Holder idiom, which
     is thread-safe and a lot easier to understand:

So, it would appear that there is some kind of disparity in thoughts and words here.

Gregg Wonderly

From ben at hf.webex.com  Mon Jun 19 12:18:34 2006
From: ben at hf.webex.com (Ben)
Date: Tue, 20 Jun 2006 00:18:34 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606200018.AA42854@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From jmanson at cs.purdue.edu  Mon Jun 19 13:23:37 2006
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Mon, 19 Jun 2006 13:23:37 -0400
Subject: [concurrency-interest] a question regarding	thedouble-checke
 dlocking
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEGFGPAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCCEGFGPAA.dcholmes@optusnet.com.au>
Message-ID: <4496DD99.1050004@cs.purdue.edu>

Apologies - as David says, the quotation is dated.  It has been removed 
from the document.

					Jeremy

David Holmes wrote:
> That quote is somewhat dated and was deliberately trying to dissuade people
> from thinking they need DCL. There were some recent posts concerning the
> costs of volatiles, I'll see if I can dig up a specific reference.
> 
> Otherwise use the initialization holder idiom to avoid the need for the
> volatile.
> 
> Cheers,
> David Holmes
>   -----Original Message-----
>   From: Yechiel Feffer [mailto:yechielf at gigaspaces.com]
>   Sent: Monday, 19 June 2006 7:29 PM
>   To: dholmes at ieee.org; Yechiel Feffer; concurrency-interest at cs.oswego.edu
>   Subject: RE: [concurrency-interest] a question regarding thedouble-checke
> dlocking
> 
> 
>   I am concerned with general correctness of my code,
>   want to avoid the price of volatile, here is a quote from jsr133 FAQ
>   "However, for fans of double-checked locking (and we really hope there are
> none left), the news is still not good. The whole point of double-checked
> locking was to avoid the performance overhead of synchronization. Not only
> has brief synchronization gotten a LOT less expensive since the Java 1.0
> days, but under the new memory model, the performance cost of using volatile
> goes up, almost to the level of the cost of synchronization. So there's
> still no good reason to use double-checked-locking"

From kaa at pax.priv.no  Tue Jun 20 03:57:12 2006
From: kaa at pax.priv.no (=?ISO-8859-1?Q?Kolbj=F8rn_Aamb=F8?=)
Date: Tue, 20 Jun 2006 09:57:12 +0200
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
Message-ID: <E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>

No there are no OutOfMemory issues as far as I can understand:

The code is made to implement 1:1 relations where accessing values to  
get
keys will happen as efficient as retrieving keys to get their values.

I suspect that the maximum number of locks (65536 recursive write  
locks and 65536 read locks) happen to be the problem here. I'm trying  
to find out how to make  an atomic put function using  
ReentrantReadWriteLock without getting problems with this limitation.

public V put(K key, V value){
	// Tested to be lock robust for upt to 300K Objects 060608
		boolean hasValue = V_K.containsKey(value);
		boolean hasKey = K_V.containsKey(key);
		V value2 = null;
		
		r.lock();
		try {
			hasValue = V_K.containsKey(value);
			hasKey = K_V.containsKey(key);

			if (!hasValue){// No preexisting occurrence of value
				r.unlock();
				w.lock();
				if (hasKey) V_K.remove(K_V.get(key));
				V_K.put(value, key);
				value2 = K_V.put(key, value);
				r.lock(); // Downgrading the lock to read lock
			}
		} finally {
			r.unlock();
		}		
		return value2;
	}// put(..)


The following implementation don't have this limitation and will go  
on working until RAM becomes a problem:
The question is will this implementation work as an atomic put function?

	
	public V put(K key, V value){
	// Tested to be lock robust for up to 300K Objects
		boolean hasValue = V_K.containsKey(value);
		boolean hasKey = K_V.containsKey(key);
		V value2 = null;
		
		r.lock();
		try {
			hasValue = V_K.containsKey(value);
			hasKey = K_V.containsKey(key);
		} finally {
			r.unlock();
		}

		if (!hasValue){// No preexisting occurrence of value
			w.lock();
			try {
				if (hasKey) V_K.remove(K_V.get(key));
				V_K.put(value, key);
				value2 = K_V.put(key, value);
			} finally {
				w.unlock();
			}
		} 		
		return value2;
	}// put(..)
	


	
	







On Jun 19, 2006, at 3:18 PM, David Holmes wrote:

> Brief comment: I think the IllegalMonitorStateException may be  
> masking an
> OutOfMemoryError. If you look at the problematic code it assumes no
> exceptions occur.
>
>   r.unlock();
>   w.lock();
>   if (hasKey) V_K.remove(K_V.get(key));
>   V_K.put(value, key);
>   value2 = K_V.put(key, value);
>   r.lock(); // Downgrading the lock to read lock
>   }
>   } finally {
>     r.unlock();
>   }
>
> Any exception at either put() will cause the finally to unlock the  
> read
> lock, which isn't locked.
>
> David Holmes
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of  
> Kolbj?rn
> Aamb?
> Sent: Monday, 19 June 2006 6:18 PM
> To: Doug Lea
> Cc: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] problem with ReentrantReadWriteLock
> toimplement atomic function
>
>
> In the code below I try to make an atomic put function. I suspect  
> that my
> implementation that divide the function
> into to try blocks, one for reading and then one for writing will  
> not be
> atomic since there are two try blocks.
>
>
> I have tried to implement the function with one try block first but  
> stumpled
> as seen below. Can you give me some
> advice?
>
>
> Best wishes
>
>
> Kolbj?rn Aamb?, Oslo
>
>
>
>
>
>
> //
> //  Unique.java
> //  JT1
> //
> //  Created by Kolbj?rn Aamb? on 2/1/06.
> //  Copyright 2006 __MyCompanyName__. All rights reserved.
> //
> import java.util.concurrent.*;
> import java.util.concurrent.locks.*;
> import java.util.*;
>
>
> public class Unique<K extends Comparable<K>, V extends  
> Comparable<V>> {
> private ConcurrentHashMap<K, V> K_V = new ConcurrentHashMap<K, V>();
> private ConcurrentHashMap<V, K> V_K = new ConcurrentHashMap<V, K>();
> //private Map<V, K> V_K_Text = new TreeMap<V, K>();
> private final ReentrantReadWriteLock rwl = new  
> ReentrantReadWriteLock();
> private final Lock r = rwl.readLock();
>     private final Lock w = rwl.writeLock();
>
>
> public Unique () {}
>
>
> public V put(K key, V value){
> // Tested to be lock robust for upt to 300K Objects 060608
> boolean hasValue = V_K.containsKey(value);
> boolean hasKey = K_V.containsKey(key);
> V value2 = null;
>
>
> r.lock();
> try {
> hasValue = V_K.containsKey(value);
> hasKey = K_V.containsKey(key);
> } finally {
> r.unlock();
> }
>
>
> if (!hasValue){// No preexisting occurrence of value
> w.lock();
> try {
> if (hasKey) V_K.remove(K_V.get(key));
> V_K.put(value, key);
> value2 = K_V.put(key, value);
> } finally {
> w.unlock();
> }
> }
>
>
> /* The code above works (I think) but the code below, that I  
> thought was the
>   the more appropriate  way of doing locking to get atomic  
> functionality
> stops like
>   this at about 65K inserts...:
>
>
> :
> 64000.0/640000.0  10 insert/ms
> 65000.0/650000.0  4 insert/ms
> [LaunchRunner Error] JTally.main(String[]) threw an exception:
> java.lang.IllegalMonitorStateException
> at
> java.util.concurrent.locks.ReentrantReadWriteLock 
> $Sync.tryReleaseShared(Reen
> trantReadWriteLock.java:275)
> at
> java.util.concurrent.locks.AbstractQueuedSynchronizer.releaseShared 
> (Abstract
> QueuedSynchronizer.java:1180)
> at
> java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.unlock 
> (ReentrantR
> eadWriteLock.java:576)
> at Unique.put(Unique.java:61)
> at Tally.put(Tally.java:116)
> at tryTally.testCombinedUNIQUE13(tryTally.java:41)
> at JTally.main(JTally.java:272)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
> sun.reflect.NativeMethodAccessorImpl.invoke 
> (NativeMethodAccessorImpl.java:39
> )
> at
> sun.reflect.DelegatingMethodAccessorImpl.invoke 
> (DelegatingMethodAccessorImpl
> .java:25)
> at java.lang.reflect.Method.invoke(Method.java:585)
> at apple.launcher.LaunchRunner.run(LaunchRunner.java:88)
> at apple.launcher.LaunchRunner.callMain(LaunchRunner.java:50)
> at
> apple.launcher.JavaApplicationLauncher.launch 
> (JavaApplicationLauncher.java:5
> 2)
>
>
> JTally has exited with status 0.
>  */
> /*
>
>
> r.lock();
> try {
> hasValue = V_K.containsKey(value);
> hasKey = K_V.containsKey(key);
>
>
> if (!hasValue){// No preexisting occurrence of value
> r.unlock();
> w.lock();
> if (hasKey) V_K.remove(K_V.get(key));
> V_K.put(value, key);
> value2 = K_V.put(key, value);
> r.lock(); // Downgrading the lock to read lock
> }
> } finally {
> r.unlock();
> }
> */
> return value2;
> }// put(..)
>
>
>
>
> public V get(K key){
> return K_V.get(key);
> }
>
>
> public K getKey(V value){
> return V_K.get(value);
> }
>
>
> public boolean containsKey(Object key){
> return K_V.containsKey(key);
> }
>
>
> public boolean containsValue(Object value){
> return V_K.containsKey(value);
> }
>
>
> public boolean contains(Object value){// for compatability with  
> hashtable
> return V_K.containsKey(value);
> }
>
>
> }
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060620/65398812/attachment-0001.html 

From ben at hf.webex.com  Tue Jun 20 04:28:11 2006
From: ben at hf.webex.com (Ben)
Date: Tue, 20 Jun 2006 16:28:11 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606201628.AA15323@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From joe.bowbeer at gmail.com  Tue Jun 20 04:57:59 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 20 Jun 2006 01:57:59 -0700
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
	<E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
Message-ID: <31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>

On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
>
> I suspect that the maximum number of locks (65536 recursive write locks and
> 65536 read locks) happen to be the problem here. I'm trying to find out how
> to make  an atomic put function using ReentrantReadWriteLock without getting
> problems with this limitation.
>

That seems likely.  The exception was probably thrown from r.unlock()
inside a finally block -- after w.lock() or r.lock() threw an Error.

(If you were to retain this code I'd suggest adding a "locked" flag
and/or more try-finally nesting in order to disambiguate this
condition. This would also protect against "put" failures, as David
points out.)

--Joe


From joe.bowbeer at gmail.com  Tue Jun 20 05:50:37 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 20 Jun 2006 02:50:37 -0700
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
	<E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
	<31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
Message-ID: <31f2a7bd0606200250t4d0fdb6fxe036874b3443f963@mail.gmail.com>

On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
> >
> > I suspect that the maximum number of locks (65536 recursive write locks
> > and 65536 read locks) happen to be the problem here.
> >
>
> That seems likely.  The exception was probably thrown from r.unlock()
> inside a finally block -- after w.lock() or r.lock() threw an Error.
>
> (If you were to retain this code I'd suggest adding a "locked" flag
> and/or more try-finally nesting in order to disambiguate this
> condition. This would also protect against "put" failures, as David
> points out.)
>

More:

Was the write lock getting downgraded correctly?

  if (!hasValue) {
      r.unlock();
      w.lock();
      if (hasKey) V_K.remove(K_V.get(key));
      V_K.put(value, key);
      value2 = K_V.put(key, value);
      r.lock(); // Downgrading the lock to read lock
  }

Isn't the above missing a final write unlock?

    w.unlock(); // unlock write, still hold read

The following is from ReentrantReadWriteLock javadoc:

    // downgrade lock
    rwl.readLock().lock(); // reacquire read without giving up write lock
    rwl.writeLock().unlock(); // unlock write, still hold read

--Joe


From joe.bowbeer at gmail.com  Tue Jun 20 07:28:50 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 20 Jun 2006 04:28:50 -0700
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <31f2a7bd0606200250t4d0fdb6fxe036874b3443f963@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
	<E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
	<31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
	<31f2a7bd0606200250t4d0fdb6fxe036874b3443f963@mail.gmail.com>
Message-ID: <31f2a7bd0606200428l26db884t95476cd68f64f137@mail.gmail.com>

Conclusion:

I believe the missing writeLock.unlock is the root cause, resulting in
64K recursive write locks and ultimate failure.

I also wanted to mention that you don't need to use concurrent maps if
you're using your own locks.  Unsynch'd HashMap is fine.

On the other hand, ConcurrentMap provides some conditional put/remove
methods that you *might* be able to leverage.

Consider the following:

  V value2 = null;
  if (V_K.putIfAbsent(value, key)) {
      if ((value2 = K_V.put(key, value)) != null)
          V_K.remove(value2, key);
  }
  return value2;


On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
> > >
> > > I suspect that the maximum number of locks (65536 recursive
> > > write locks and 65536 read locks) happen to be the problem here.
> > >
> >
> > That seems likely.  The exception was probably thrown from r.unlock()
> > inside a finally block -- after w.lock() or r.lock() threw an Error.
> >
> > (If you were to retain this code I'd suggest adding a "locked" flag
> > and/or more try-finally nesting in order to disambiguate this
> > condition. This would also protect against "put" failures, as David
> > points out.)
> >
>
> More:
>
> Was the write lock getting downgraded correctly?
>
>   if (!hasValue) {
>       r.unlock();
>       w.lock();
>       if (hasKey) V_K.remove(K_V.get(key));
>       V_K.put(value, key);
>       value2 = K_V.put(key, value);
>       r.lock(); // Downgrading the lock to read lock
>   }
>
> Isn't the above missing a final write unlock?
>
>     w.unlock(); // unlock write, still hold read
>
> The following is from ReentrantReadWriteLock javadoc:
>
>     // downgrade lock
>     rwl.readLock().lock(); // reacquire read without giving up write lock
>     rwl.writeLock().unlock(); // unlock write, still hold read
>


From kaa at pax.priv.no  Tue Jun 20 07:34:05 2006
From: kaa at pax.priv.no (=?ISO-8859-1?Q?Kolbj=F8rn_Aamb=F8?=)
Date: Tue, 20 Jun 2006 13:34:05 +0200
Subject: [concurrency-interest] problem with ReentrantReadWriteLock
	toimplement atomic function
In-Reply-To: <31f2a7bd0606200250t4d0fdb6fxe036874b3443f963@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>
	<E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
	<31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
	<31f2a7bd0606200250t4d0fdb6fxe036874b3443f963@mail.gmail.com>
Message-ID: <2A456C23-97FF-4372-8A4E-31B876245724@pax.priv.no>

Thanks! You have pointed out what solved the problem:

	public V put(K key, V value)
		throws NullPointerException{
	// Tested to be lock robust for upt to 300K Objects 060608
		boolean hasValue = V_K.containsKey(value);
		boolean hasKey = K_V.containsKey(key);
		V value2 = null;
		
		r.lock();
		try {
			hasValue = V_K.containsKey(value);
			hasKey = K_V.containsKey(key);

			if (!hasValue){// No preexisting occurrence of value
				r.unlock();// Upgrading the lock to write lock
				w.lock();
				if (hasKey) V_K.remove(K_V.get(key));
				
				V_K.put(value, key);
				value2 = K_V.put(key, value);
				
				r.lock();	// Downgrading the lock to read lock
				w.unlock(); //
			}
		} finally {
			r.unlock();
		}		
		return value2;
	}// put(..)


To reiterate on Davids point on OutOfMemoryError - Since put(..)  
throws  NullPointerException which is an extension of  
RunTimeException I would like to compleat both puts or none of them,  
for instance... So I would have to try doing one of them and if  
necessary reversing with the risk of that not working.... Any comments?

Thank you for all help!

Kolbj?rn Aamb?, Oslo





On Jun 20, 2006, at 11:50 AM, Joe Bowbeer wrote:

> On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
>> On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
>> >
>> > I suspect that the maximum number of locks (65536 recursive  
>> write locks
>> > and 65536 read locks) happen to be the problem here.
>> >
>>
>> That seems likely.  The exception was probably thrown from r.unlock()
>> inside a finally block -- after w.lock() or r.lock() threw an Error.
>>
>> (If you were to retain this code I'd suggest adding a "locked" flag
>> and/or more try-finally nesting in order to disambiguate this
>> condition. This would also protect against "put" failures, as David
>> points out.)
>>
>
> More:
>
> Was the write lock getting downgraded correctly?
>
>  if (!hasValue) {
>      r.unlock();
>      w.lock();
>      if (hasKey) V_K.remove(K_V.get(key));
>      V_K.put(value, key);
>      value2 = K_V.put(key, value);
>      r.lock(); // Downgrading the lock to read lock
>  }
>
> Isn't the above missing a final write unlock?
>
>    w.unlock(); // unlock write, still hold read
>
> The following is from ReentrantReadWriteLock javadoc:
>
>    // downgrade lock
>    rwl.readLock().lock(); // reacquire read without giving up write  
> lock
>    rwl.writeLock().unlock(); // unlock write, still hold read
>
> --Joe

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060620/dc8e6b7f/attachment-0001.html 

From dcholmes at optusnet.com.au  Tue Jun 20 07:53:54 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Tue, 20 Jun 2006 21:53:54 +1000
Subject: [concurrency-interest] problem with
	ReentrantReadWriteLocktoimplement atomic function
In-Reply-To: <31f2a7bd0606200428l26db884t95476cd68f64f137@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEHBGPAA.dcholmes@optusnet.com.au>

And now that you've resolved the problem take a good look at where you need
to place try/catch/finally to ensure you won't attempt to unlock locks that
aren't locked if exceptions are thrown.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Joe
> Bowbeer
> Sent: Tuesday, 20 June 2006 9:29 PM
> To: Kolbj?rn Aamb?
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] problem with
> ReentrantReadWriteLocktoimplement atomic function
>
>
> Conclusion:
>
> I believe the missing writeLock.unlock is the root cause, resulting in
> 64K recursive write locks and ultimate failure.
>
> I also wanted to mention that you don't need to use concurrent maps if
> you're using your own locks.  Unsynch'd HashMap is fine.
>
> On the other hand, ConcurrentMap provides some conditional put/remove
> methods that you *might* be able to leverage.
>
> Consider the following:
>
>   V value2 = null;
>   if (V_K.putIfAbsent(value, key)) {
>       if ((value2 = K_V.put(key, value)) != null)
>           V_K.remove(value2, key);
>   }
>   return value2;
>
>
> On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > On 6/20/06, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> > > On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
> > > >
> > > > I suspect that the maximum number of locks (65536 recursive
> > > > write locks and 65536 read locks) happen to be the problem here.
> > > >
> > >
> > > That seems likely.  The exception was probably thrown from r.unlock()
> > > inside a finally block -- after w.lock() or r.lock() threw an Error.
> > >
> > > (If you were to retain this code I'd suggest adding a "locked" flag
> > > and/or more try-finally nesting in order to disambiguate this
> > > condition. This would also protect against "put" failures, as David
> > > points out.)
> > >
> >
> > More:
> >
> > Was the write lock getting downgraded correctly?
> >
> >   if (!hasValue) {
> >       r.unlock();
> >       w.lock();
> >       if (hasKey) V_K.remove(K_V.get(key));
> >       V_K.put(value, key);
> >       value2 = K_V.put(key, value);
> >       r.lock(); // Downgrading the lock to read lock
> >   }
> >
> > Isn't the above missing a final write unlock?
> >
> >     w.unlock(); // unlock write, still hold read
> >
> > The following is from ReentrantReadWriteLock javadoc:
> >
> >     // downgrade lock
> >     rwl.readLock().lock(); // reacquire read without giving up
> write lock
> >     rwl.writeLock().unlock(); // unlock write, still hold read
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From gergg at cox.net  Tue Jun 20 07:55:13 2006
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 20 Jun 2006 06:55:13 -0500
Subject: [concurrency-interest] problem with
 ReentrantReadWriteLock	toimplement atomic function
In-Reply-To: <31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEGHGPAA.dcholmes@optusnet.com.au>	<E370E76D-4B27-4511-A7F9-5B8FFDC8926E@pax.priv.no>
	<31f2a7bd0606200157k75e664b3veb37940a80a282fc@mail.gmail.com>
Message-ID: <4497E221.7040104@cox.net>

Joe Bowbeer wrote:
> On 6/20/06, Kolbj?rn Aamb? <kaa at pax.priv.no> wrote:
> 
>>I suspect that the maximum number of locks (65536 recursive write locks and
>>65536 read locks) happen to be the problem here. I'm trying to find out how
>>to make  an atomic put function using ReentrantReadWriteLock without getting
>>problems with this limitation.
>
> (If you were to retain this code I'd suggest adding a "locked" flag
> and/or more try-finally nesting in order to disambiguate this
> condition. This would also protect against "put" failures, as David
> points out.)

Anytime that I have code structure like this, I use the following pattern to 
make sure I see the Exceptions which can be thrown:

try {
	... do work which throws exceptions
} catch( SomeExceptionMethodThrows ex ) {
	log.log( Level.APPROPRIATE, ex.toString(), ex );
	throw ex;
} catch( RuntimeException ex ) {
	log.log( Level.APPROPRIATE, ex.toString(), ex );
	throw ex;
} finally {
	... cleanup which can also throw method declared exceptions ...
}

Making sure that the 'throws' declared exceptions are caught, logged,
and rethrown is helpful in tracking down these kinds of issues.  You can use 
some of the other log methods, or a different level to reduce duplicates in a 
block/method which can routinely abort.

Gregg Wonderly

From ben at hf.webex.com  Tue Jun 20 07:56:48 2006
From: ben at hf.webex.com (Ben)
Date: Tue, 20 Jun 2006 19:56:48 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606201956.AA23068@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From serkandemir007 at gmail.com  Tue Jun 20 10:07:55 2006
From: serkandemir007 at gmail.com (Serkan Demir)
Date: Tue, 20 Jun 2006 17:07:55 +0300
Subject: [concurrency-interest] A quiz or evaulation questions for
	java.util.concurrent package
Message-ID: <c060a6cb0606200707p526976bao9e0ad6c48479dcc5@mail.gmail.com>

Hi guys,

Nowadays, I have been preparing for a presentation about new
concurrent package. At the end of the presentation, i decide to make a
short quiz about this topic.
Do you prefer some thought-proviking questions for me? Any links,
example questions, or advices ?
Is there any puzzles in Joshua Bloch's puzzlers related to this new
concurrent package?

thanks lot,

Serkan

http://serkandemir.blogspot.com
www.oksijen.com

From josh at bloch.us  Tue Jun 20 10:41:27 2006
From: josh at bloch.us (Joshua Bloch)
Date: Tue, 20 Jun 2006 08:41:27 -0600
Subject: [concurrency-interest] A quiz or evaulation questions for
	java.util.concurrent package
In-Reply-To: <c060a6cb0606200707p526976bao9e0ad6c48479dcc5@mail.gmail.com>
References: <c060a6cb0606200707p526976bao9e0ad6c48479dcc5@mail.gmail.com>
Message-ID: <b097ac510606200741r292e8565na4118fc49f7896ae@mail.gmail.com>

Serkan,

Sorry to say, I have no j.u.c puzzlers yet.

      Josh

On 6/20/06, Serkan Demir <serkandemir007 at gmail.com> wrote:
> Hi guys,
>
> Nowadays, I have been preparing for a presentation about new
> concurrent package. At the end of the presentation, i decide to make a
> short quiz about this topic.
> Do you prefer some thought-proviking questions for me? Any links,
> example questions, or advices ?
> Is there any puzzles in Joshua Bloch's puzzlers related to this new
> concurrent package?
>
> thanks lot,
>
> Serkan
>
> http://serkandemir.blogspot.com
> www.oksijen.com
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From ben at hf.webex.com  Tue Jun 20 12:15:49 2006
From: ben at hf.webex.com (Ben)
Date: Wed, 21 Jun 2006 00:15:49 +0800
Subject: [concurrency-interest] I will not be in office from 6/19 to 6/30.
	And I even couldn't check mail in these days.
Message-ID: <10606210015.AA31663@hf.webex.com>

I will not be in office from 6/19 to 6/30. And I even couldn't check mail in these days.
Please contact Paul or Drong for Reminder issues. Thanks.

From doron at rajwan.org  Wed Jun 21 06:32:32 2006
From: doron at rajwan.org (Doron Rajwan)
Date: Wed, 21 Jun 2006 03:32:32 -0700 (PDT)
Subject: [concurrency-interest] A quiz or evaulation questions for
	java.util.concurrent package
In-Reply-To: <mailman.1.1150819201.17712.concurrency-interest@altair.cs.oswego.edu>
Message-ID: <20060621103232.75819.qmail@web52606.mail.yahoo.com>


ConcurrentHashMap<String,String> map = ...

Thread 1:
  map.put("A","A");
  map.put("B","B");

Thread 2:
  String b = map.get("B");
  String a = map.get("A");

Thread 3:
  Iterator<String> itr = map.keySet().iterator();
  ... check if A/B exists in itr.

Questions:
1. Can Thread2 see B but see A as null?
   Answer: no.
2. Can Thread3 see B but not A?
   Answer: yes.

Doron


______________________________________________________
Doron Rajwan, doron at rajwan.org, http://www.rajwan.org


From mark at talios.com  Sat Jun 24 21:37:19 2006
From: mark at talios.com (Mark Derricutt)
Date: Sun, 25 Jun 2006 13:37:19 +1200
Subject: [concurrency-interest] TimeUnit.HOURS in backport but not JDK5
Message-ID: <5184347f0606241837l12c433e5h7d9e57d4806a0acd@mail.gmail.com>

Hi all,

Was just converting some code from using the backported concurrency library
to the actual JD5 code and found that TimeUnit.HOURS which was used in the
code doesn't exist in the JDK5 codebase.

Should it be there? Or not be there?  Just curious...

Mark

-- 
i like my video games - mamma said they are gonna melt my brains
i like my video games - i don't care what daddy said; they're my reality
  - henning pauly
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060625/985dcf4c/attachment.html 

From dcholmes at optusnet.com.au  Sun Jun 25 06:20:21 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Sun, 25 Jun 2006 20:20:21 +1000
Subject: [concurrency-interest] TimeUnit.HOURS in backport but not JDK5
In-Reply-To: <5184347f0606241837l12c433e5h7d9e57d4806a0acd@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEJBGPAA.dcholmes@optusnet.com.au>

That's a Java 6 update the backport has picked up (MINUTES, HOURS and DAYS).
I think Dawid has mentioned making a seperate Java 5 backport and Java 6
backport at some stage.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Mark
Derricutt
  Sent: Sunday, 25 June 2006 11:37 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] TimeUnit.HOURS in backport but not JDK5


  Hi all,

  Was just converting some code from using the backported concurrency
library to the actual JD5 code and found that TimeUnit.HOURS which was used
in the code doesn't exist in the JDK5 codebase.

  Should it be there? Or not be there?  Just curious...

  Mark

  --
  i like my video games - mamma said they are gonna melt my brains
  i like my video games - i don't care what daddy said; they're my reality
    - henning pauly
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060625/e40c13c1/attachment.html 

From Ryan.LeCompte at pangonetworks.com  Tue Jun 27 16:51:29 2006
From: Ryan.LeCompte at pangonetworks.com (Ryan LeCompte)
Date: Tue, 27 Jun 2006 16:51:29 -0400
Subject: [concurrency-interest] Synchronization question
Message-ID: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>

Hello all,
 
I have a question regarding thread synchronization and referencing variables. Here's the rough description:
 
I have a class that has a non-volatile, private member variable. The class has a default no-arg constructor which doesn't do anything of importance. There is a synchronized method which gets invoked by the main thread, which assigns a value to the private member variable (non-primitive), among other things.
 
Then, I have another non-synchronized method which simply returns a reference to the private member variable (that's all it does). Multiple threads will ultimately invoke this non-synchronized method to get access to the variable. My question is this: is it possible that these other threads will not see the assignment made to the private member variable by the synchronized method? The system is written such that these other threads will NOT invoke the non-synchronized accessor method until the synchronized method is invoked. Do I want to make this private member variable volatile? Hopefully not.
 
Thanks!
 
Ryan
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/6f79e81e/attachment.html 

From jmanson at cs.purdue.edu  Tue Jun 27 17:01:51 2006
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Tue, 27 Jun 2006 17:01:51 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
Message-ID: <44A19CBF.8010906@cs.purdue.edu>

Hi Ryan,

There has to be a happens-before relationship between the assignment to 
the variable and any read of it.  This means that, when you say:

> The system is written such that these other threads will NOT invoke the
> non-synchronized accessor method until the synchronized method is
> invoked.

Then if there is a happens-before relationship making this guarantee, 
then you are fine.

The happens-before guarantee can be made by, for example, a write to a 
volatile in the writer thread after the write, and a read of the same 
variable in the reader thread before the read. Alternatively, you can 
have an unlock in the writer thread after the write, followed by a lock 
on the same monitor in a reader thread before the read.  Alternatively, 
you can have the writer thread start the reader threads after it 
performs the write.

					Jeremy

From tim at peierls.net  Tue Jun 27 17:24:23 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 27 Jun 2006 17:24:23 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A19CBF.8010906@cs.purdue.edu>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
Message-ID: <63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>

Jeremy answered the question, but there's another important point: Code that
relies on complicated happens-before reasoning is bound to be harder to
understand and maintain than code with a straightforward synchronization
policy.

Volatile access is not expensive. Unless there is a demonstrable performance
disadvantage in this particular case, you should either make the field
volatile or synchronize the accessor method. Don't make future maintainers
of your code read through a justification of why non-volatile,
non-synchronized access is OK, even if it is. (And definitely don't leave
out such a justification if you are relying on it!)

Chapters 2-4 of Java Concurrency in Practice make this point much more
compellingly than I can here. :-)

--tim

On 6/27/06, Jeremy Manson <jmanson at cs.purdue.edu> wrote:
>
> Hi Ryan,
>
> There has to be a happens-before relationship between the assignment to
> the variable and any read of it.  This means that, when you say:
>
> > The system is written such that these other threads will NOT invoke the
> > non-synchronized accessor method until the synchronized method is
> > invoked.
>
> Then if there is a happens-before relationship making this guarantee,
> then you are fine.
>
> The happens-before guarantee can be made by, for example, a write to a
> volatile in the writer thread after the write, and a read of the same
> variable in the reader thread before the read. Alternatively, you can
> have an unlock in the writer thread after the write, followed by a lock
> on the same monitor in a reader thread before the read.  Alternatively,
> you can have the writer thread start the reader threads after it
> performs the write.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/64c3da6c/attachment.html 

From Ryan.LeCompte at pangonetworks.com  Tue Jun 27 17:43:07 2006
From: Ryan.LeCompte at pangonetworks.com (Ryan LeCompte)
Date: Tue, 27 Jun 2006 17:43:07 -0400
Subject: [concurrency-interest] Synchronization question
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com><44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
Message-ID: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>

Thanks! I'll make the field volatile then. There is absolutely no harm in making a field volatile and using it inside of another synchronized method/block, correct? No potential deadlocks simply due to the variable being made volatile?
 
Thanks,
Ryan

________________________________

From: tpeierls at gmail.com on behalf of Tim Peierls
Sent: Tue 6/27/2006 5:24 PM
To: Ryan LeCompte
Cc: Jeremy Manson; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Synchronization question


Jeremy answered the question, but there's another important point: Code that relies on complicated happens-before reasoning is bound to be harder to understand and maintain than code with a straightforward synchronization policy.

Volatile access is not expensive. Unless there is a demonstrable performance disadvantage in this particular case, you should either make the field volatile or synchronize the accessor method. Don't make future maintainers of your code read through a justification of why non-volatile, non-synchronized access is OK, even if it is. (And definitely don't leave out such a justification if you are relying on it!)

Chapters 2-4 of Java Concurrency in Practice make this point much more compellingly than I can here. :-)

--tim

On 6/27/06, Jeremy Manson <jmanson at cs.purdue.edu> wrote: 

	Hi Ryan,
	
	There has to be a happens-before relationship between the assignment to
	the variable and any read of it.  This means that, when you say:
	
	> The system is written such that these other threads will NOT invoke the 
	> non-synchronized accessor method until the synchronized method is
	> invoked.
	
	Then if there is a happens-before relationship making this guarantee,
	then you are fine.
	
	The happens-before guarantee can be made by, for example, a write to a 
	volatile in the writer thread after the write, and a read of the same
	variable in the reader thread before the read. Alternatively, you can
	have an unlock in the writer thread after the write, followed by a lock 
	on the same monitor in a reader thread before the read.  Alternatively,
	you can have the writer thread start the reader threads after it
	performs the write.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/43bf9fb5/attachment.html 

From tim at peierls.net  Tue Jun 27 17:51:53 2006
From: tim at peierls.net (Tim Peierls)
Date: Tue, 27 Jun 2006 17:51:53 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
Message-ID: <63b4e4050606271451j4e3a5252i4f6ca2be333e7d0@mail.gmail.com>

No harm and no potential deadlocks.

--tim

On 6/27/06, Ryan LeCompte <Ryan.LeCompte at pangonetworks.com> wrote:
>
>  Thanks! I'll make the field volatile then. There is absolutely no harm in
> making a field volatile and using it inside of another synchronized
> method/block, correct? No potential deadlocks simply due to the variable
> being made volatile?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/5725755a/attachment.html 

From jmanson at cs.purdue.edu  Tue Jun 27 17:59:29 2006
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Tue, 27 Jun 2006 17:59:29 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com><44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
Message-ID: <44A1AA41.1030708@cs.purdue.edu>

Ryan LeCompte wrote:
> Thanks! I'll make the field volatile then. There is absolutely no
> harm in making a field volatile and using it inside of another
> synchronized method/block, correct? No potential deadlocks simply due
> to the variable being made volatile?
> 
> Thanks, Ryan


I was going to mention volatile, but I realized that annotating the
variable volatile doesn't actually guarantee that the initialization
will happens-before the reads.  It only guarantees that the
intialization happens-before the reads /if the reads actually see the
initialization/.

That's circular in this case, and seems to miss the point.

So you still need the happens-before relationship.

HOWEVER, as Tim pointed out, volatile is cheap, and is a good annotation
to have on shared variables that are not GuardedBy some lock.  So you
might as well still use it.

					Jeremy

From Ryan.LeCompte at pangonetworks.com  Tue Jun 27 18:05:31 2006
From: Ryan.LeCompte at pangonetworks.com (Ryan LeCompte)
Date: Tue, 27 Jun 2006 18:05:31 -0400
Subject: [concurrency-interest] Synchronization question
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com><44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
	<44A1AA41.1030708@cs.purdue.edu>
Message-ID: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C4@pangomail2k3.pangonetworks.com>

Sounds great. I will make the field volatile. The fact that I ensure that the variable is initialized before other threads get a chance to read it satisfies the happens-before relationship, correct?

________________________________

From: Jeremy Manson [mailto:jmanson at cs.purdue.edu]
Sent: Tue 6/27/2006 5:59 PM
To: Ryan LeCompte
Cc: Tim Peierls; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Synchronization question



Ryan LeCompte wrote:
> Thanks! I'll make the field volatile then. There is absolutely no
> harm in making a field volatile and using it inside of another
> synchronized method/block, correct? No potential deadlocks simply due
> to the variable being made volatile?
>
> Thanks, Ryan


I was going to mention volatile, but I realized that annotating the
variable volatile doesn't actually guarantee that the initialization
will happens-before the reads.  It only guarantees that the
intialization happens-before the reads /if the reads actually see the
initialization/.

That's circular in this case, and seems to miss the point.

So you still need the happens-before relationship.

HOWEVER, as Tim pointed out, volatile is cheap, and is a good annotation
to have on shared variables that are not GuardedBy some lock.  So you
might as well still use it.

                                        Jeremy


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/f4100b0a/attachment-0001.html 

From brian at quiotix.com  Tue Jun 27 18:18:44 2006
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 27 Jun 2006 18:18:44 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
Message-ID: <44A1AEC4.6000907@quiotix.com>

And, just for completeness: synchronized write + nonsynchronized read 
doesn't create the required happens-before, so it doesn't work.  The 
getter in such a case isn't required to ever return anything other than 
the default (zero) value.

Tim Peierls wrote:
> Jeremy answered the question, but there's another important point: Code 
> that relies on complicated happens-before reasoning is bound to be 
> harder to understand and maintain than code with a straightforward 
> synchronization policy.
> 
> Volatile access is not expensive. Unless there is a demonstrable 
> performance disadvantage in this particular case, you should either make 
> the field volatile or synchronize the accessor method. Don't make future 
> maintainers of your code read through a justification of why 
> non-volatile, non-synchronized access is OK, even if it is. (And 
> definitely don't leave out such a justification if you are relying on it!)
> 
> Chapters 2-4 of Java Concurrency in Practice make this point much more 
> compellingly than I can here. :-)

From Ryan.LeCompte at pangonetworks.com  Tue Jun 27 18:22:43 2006
From: Ryan.LeCompte at pangonetworks.com (Ryan LeCompte)
Date: Tue, 27 Jun 2006 18:22:43 -0400
Subject: [concurrency-interest] Synchronization question
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com>
Message-ID: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C5@pangomail2k3.pangonetworks.com>

Phew, now I'm getting confused... :) So what would make my code correct then? Is it sufficient to just mark it volatile in the scenario that I described? 

________________________________

From: Brian Goetz [mailto:brian at quiotix.com]
Sent: Tue 6/27/2006 6:18 PM
To: Tim Peierls
Cc: Ryan LeCompte; concurrency-interest at cs.oswego.edu; Jeremy Manson
Subject: Re: [concurrency-interest] Synchronization question



And, just for completeness: synchronized write + nonsynchronized read
doesn't create the required happens-before, so it doesn't work.  The
getter in such a case isn't required to ever return anything other than
the default (zero) value.

Tim Peierls wrote:
> Jeremy answered the question, but there's another important point: Code
> that relies on complicated happens-before reasoning is bound to be
> harder to understand and maintain than code with a straightforward
> synchronization policy.
>
> Volatile access is not expensive. Unless there is a demonstrable
> performance disadvantage in this particular case, you should either make
> the field volatile or synchronize the accessor method. Don't make future
> maintainers of your code read through a justification of why
> non-volatile, non-synchronized access is OK, even if it is. (And
> definitely don't leave out such a justification if you are relying on it!)
>
> Chapters 2-4 of Java Concurrency in Practice make this point much more
> compellingly than I can here. :-)


-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060627/2374d3bd/attachment.html 

From jmanson at cs.purdue.edu  Tue Jun 27 18:44:54 2006
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Tue, 27 Jun 2006 18:44:54 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C4@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com><44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C3@pangomail2k3.pangonetworks.com>
	<44A1AA41.1030708@cs.purdue.edu>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C4@pangomail2k3.pangonetworks.com>
Message-ID: <44A1B4E6.8070101@cs.purdue.edu>

Ryan LeCompte wrote:
> Sounds great. I will make the field volatile. The fact that I ensure
> that the variable is initialized before other threads get a chance to
> read it satisfies the happens-before relationship, correct?
> 

Brian was just saying what I was saying.  As long as you use a
happens-before relationship to make sure the variable is initialized 
before other threads get a chance to read it, you will be okay.

That is, if the variable is x, and there is a volatile boolean variable v:

Writer thread

x = 1;
v = true;

Reader thread:

if (v)
   r1 = x;

The fact that the reader thread won't read x unless v has been set to 
true, plus the fact that the write to x happens-before v is set to true, 
implies that the write to x must happen-before the read of x.

Alternatively:

Writer thread:

x = 1;
new Thread(new ReaderThread());

Reader thread:

r1 = x;

The reader thread will not execute until the writer thread has 
initialized x, so the initialization must happen-before the read.

That's the kind of (very obvious) thing you have to do -- you just have 
to use something that is labeled as "this creates happens-before 
relationships" to do it.  So, for example, if v were /not/ volatile in 
the first example, then that wouldn't work, because writes and reads of 
non-volatile variables don't create happens-before relationships.

					Jeremy

From joe.bowbeer at gmail.com  Tue Jun 27 18:54:49 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 27 Jun 2006 15:54:49 -0700
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
Message-ID: <31f2a7bd0606271554s4ccb756rdb35b8cc31f7599f@mail.gmail.com>

On 6/27/06, Ryan LeCompte <Ryan.LeCompte at pangonetworks.com> wrote:
>
> I have a question regarding thread synchronization and referencing
> variables. Here's the rough description:
>
> I have a class that has a non-volatile, private member variable. The class
> has a default no-arg constructor which doesn't do anything of importance.
> There is a synchronized method which gets invoked by the main thread, which
> assigns a value to the private member variable (non-primitive), among other
> things.
>
> Then, I have another non-synchronized method which simply returns a
> reference to the private member variable (that's all it does). Multiple
> threads will ultimately invoke this non-synchronized method to get access to
> the variable. My question is this: is it possible that these other threads
> will not see the assignment made to the private member variable by the
> synchronized method? The system is written such that these other threads
> will NOT invoke the non-synchronized accessor method until the synchronized
> method is invoked. Do I want to make this private member variable volatile?
> Hopefully not.
>
> Thanks!
>
> Ryan
>

Here's how I view your choices:

If it is true that only one thread will initialize the variable, and
that is guaranteed to happen before any other threads access the
variable (because of synchronization external to this class, e.g.,
Swing event dispatch thread), then neither initializer nor accessor
need to be synchronized and the variable doesn't need to be volatile.
BUT in that case you should definitely document that this class
depends on these conditions.

Otherwise, you should synchronize both initializer and accessor
methods, and you don't need to make the variable volatile.  This is my
recommendation.

You could also just make the variable volatile and not synchronize the
methods -- IF the initializer is only doing simple assignment (that
is, nothing that requires an atomic block).  But this is kind of
fragile.  Leave volatile to the experts is my advice.

The worst thing to do is to synchronize one method and not the other.
This is a sure sign  to others that something is messed up :-)
Half-synchronization doesn't do any good at all.

-- 
Joe Bowbeer ~ joebowbeer.thruhere.net

From brian at quiotix.com  Tue Jun 27 23:29:25 2006
From: brian at quiotix.com (Brian Goetz)
Date: Tue, 27 Jun 2006 23:29:25 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C5@pangomail2k3.pangonetworks.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>	<44A1AEC4.6000907@quiotix.com>
	<73C466B3EAAF504987DBF8E6EAC7E8CF0733C5@pangomail2k3.pangonetworks.com>
Message-ID: <44A1F795.7000603@quiotix.com>

> Phew, now I'm getting confused... :) So what would make my code correct 
> then? Is it sufficient to just mark it volatile in the scenario that I 
> described?

Quoting from JCiP 3.5.3 (Safe Publication Idioms), p52:

To publish an object safely, both the reference to the object and the 
object's state must be made visible to other threads at the same time. 
A properly constructed object can be safely published by:

  - Initializing an object reference from a static initializer;
  - Storing a reference to it into a volatile field or AtomicReference;
  - Storing a reference to it into a final field of a properly 
constructed object;
  - Storing a reference to it into a field that is properly guarded by a 
lock.

The last one, properly guarded by a lock, means all accesses (read and 
write) to the field synchronize on a common lock.

If you want more, buy the book :)


From holger at wizards.de  Wed Jun 28 05:32:18 2006
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Wed, 28 Jun 2006 11:32:18 +0200
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A1AEC4.6000907@quiotix.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com>
Message-ID: <44A24CA2.1010005@wizards.de>

Brian Goetz wrote:
> And, just for completeness: synchronized write + nonsynchronized read 
> doesn't create the required happens-before, so it doesn't work.  The 
> getter in such a case isn't required to ever return anything other than 
> the default (zero) value.

This made me curious. While "strictly speaking" the above behaviour might
be correct according to the spec/revised memory model, in practice (as in
stuff I can buy/run today) the unsynchronized read *will* succeed - maybe
later than one might expect but it still does, simply because most people
don't yet have transactional or distributed shared memory, and the VM is
still pretty conservative about its write-back. So how exactly will the
above behaviour ever come into play? Is it caused by:
- the VM and its *implemented* cross-thread memory sync policy
- the physical memory as implemented by the OS
- both or something else?

Are there any actual CPUs that are really that picky? T1, Azul?

Somehow I get the feeling that a VM/CPU that would strictly implement the
above behaviour - always returning the initial null for an unsynchronized
read when done from another thread - would be less than successful on the
market with existing Java applications. It would mean that all methods
returning an instance variable would have to be declared as synchronized
or the variable as volatile, effectively making both keywords (or at least
volatile) redundant since the 'safe' behaviour might as well be the
default. Somehow I get the feeling that this would be a second Y2K in the
making.

Another question - what exactly causes the delayed visibility of
references or variables across threads? I'd like to learn more about the
internals.

thanks
Holger

PS: Yes, I have the book and recommend it everywhere. :)


From dhanji at gmail.com  Wed Jun 28 08:14:55 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Wed, 28 Jun 2006 22:14:55 +1000
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A24CA2.1010005@wizards.de>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
Message-ID: <aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>

On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
> Brian Goetz wrote:
> > And, just for completeness: synchronized write + nonsynchronized read
> > doesn't create the required happens-before, so it doesn't work.  The
> > getter in such a case isn't required to ever return anything other than
> > the default (zero) value.
>
> This made me curious. While "strictly speaking" the above behaviour might
> be correct according to the spec/revised memory model, in practice (as in
> stuff I can buy/run today) the unsynchronized read *will* succeed - maybe

I believe with regard to the original question, the unsynchronized
read is not expected to be deterministic because there isnt a
happens-before edge forcing the 2 threads into a write/read sequence.
Im not sure what you mean by "succeed", but for the required behavior
(i.e. write prior to read) one cannot guarantee that a synchronized
write + unsynchronized read will suffice.

Declaring the variable as volatile forces both threads to deal with
the same memory but still does not solve the issue of sequencing the
write/read. This is how I read Brian's and the others' responses.


From joe.bowbeer at gmail.com  Wed Jun 28 08:44:24 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 28 Jun 2006 05:44:24 -0700
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A24CA2.1010005@wizards.de>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
Message-ID: <31f2a7bd0606280544t7be0acc5o3cc87baa14737608@mail.gmail.com>

On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
> Brian Goetz wrote:
> > And, just for completeness: synchronized write + nonsynchronized read
> > doesn't create the required happens-before, so it doesn't work.  The
> > getter in such a case isn't required to ever return anything other than
> > the default (zero) value.
>
> This made me curious. While "strictly speaking" the above behaviour might
> be correct according to the spec/revised memory model, in practice (as in
> stuff I can buy/run today) the unsynchronized read *will* succeed - maybe
> later than one might expect but it still does, simply because most people
> don't yet have transactional or distributed shared memory, and the VM is
> still pretty conservative about its write-back. So how exactly will the
> above behaviour ever come into play? Is it caused by:
> - the VM and its *implemented* cross-thread memory sync policy
> - the physical memory as implemented by the OS
> - both or something else?
>
> Are there any actual CPUs that are really that picky? T1, Azul?
>
> Somehow I get the feeling that a VM/CPU that would strictly implement the
> above behaviour - always returning the initial null for an unsynchronized
> read when done from another thread - would be less than successful on the
> market with existing Java applications. It would mean that all methods
> returning an instance variable would have to be declared as synchronized
> or the variable as volatile, effectively making both keywords (or at least
> volatile) redundant since the 'safe' behaviour might as well be the
> default. Somehow I get the feeling that this would be a second Y2K in the
> making.
>
> Another question - what exactly causes the delayed visibility of
> references or variables across threads? I'd like to learn more about the
> internals.
>
> thanks
> Holger
>
> PS: Yes, I have the book and recommend it everywhere. :)
>

AFAIK, unsynched reads can be hoisted out of loops today in the
adaptive/JIT stage.

    while (getFoo() == null)
        Thread.yield();

=>

    if (getFoo() == null)
        while(true) Thread.yield();

> Somehow I get the feeling that a VM/CPU that would strictly implement the
> above behaviour - always returning the initial null for an unsynchronized
> read when done from another thread - would be less than successful on the
> market with existing Java applications.

Just so you know, there's lengthy discussion and background
information in the JMM archives:

http://mailman.cs.umd.edu/mailman/options/javamemorymodel-discussion

--Joe


From holger at wizards.de  Wed Jun 28 09:16:28 2006
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Wed, 28 Jun 2006 15:16:28 +0200
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	
	<44A19CBF.8010906@cs.purdue.edu>	
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>	
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>
Message-ID: <44A2812C.3080008@wizards.de>

Dhanji R. Prasanna wrote:
> On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
>> Brian Goetz wrote:
>> > And, just for completeness: synchronized write + nonsynchronized read
>> > doesn't create the required happens-before, so it doesn't work.  The
>> > getter in such a case isn't required to ever return anything other than
>> > the default (zero) value.
>>
>> This made me curious. While "strictly speaking" the above behaviour might
>> be correct according to the spec/revised memory model, in practice (as in
>> stuff I can buy/run today) the unsynchronized read *will* succeed - maybe
> 
> I believe with regard to the original question, the unsynchronized
> read is not expected to be deterministic because there isnt a
> happens-before edge forcing the 2 threads into a write/read sequence.

The original poster assured that the setting (== exit of the synchronized
method body) was guaranteed to happen before the read. I don't think
anybody would expect the read to return a non-null value even though no
value has ever been set yet. Not even Futures can do that. ;)

> Im not sure what you mean by "succeed", but for the required behavior
> (i.e. write prior to read) one cannot guarantee that a synchronized
> write + unsynchronized read will suffice.

I'm mainly interested in unambiguous clarification of the apparently (?)
possible time window that may or may not exist after the synchronized set
method has returned. The size of that window (if it exists?) constitutes a
"visibility race" and if it is ever allowed to be "forever" - as per
Brian's comment above - then many applications will produce "interesting"
results.

> Declaring the variable as volatile forces both threads to deal with
> the same memory but still does not solve the issue of sequencing the
> write/read. This is how I read Brian's and the others' responses.

Brian qouted: "Storing a reference to [the published object] into a field
that is properly guarded by a lock." but then added "all accesses (read
and write)". The former would allow for an unspecified window where the
change is not-quite-visible-yet, but eventually will (MEM_AUTO_COMMIT :).
The latter would mean that *all* references to *all* fields of a compound
object that is shared between threads *must* be accessed from inside a
synchronized method or at least in a synchronized block to ensure
visibility. We can only guess how many lines of Java code don't do that;
that's why I was wondering about the possible fallout.

Sorry if I'm being dense or overly picky here - if I'm missing something
fundamental please set me straight. All this should be put into a FAQ that
every random Java dude can understand!

cheers
Holger


From tim at peierls.net  Wed Jun 28 09:49:50 2006
From: tim at peierls.net (Tim Peierls)
Date: Wed, 28 Jun 2006 09:49:50 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A2812C.3080008@wizards.de>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>
	<44A2812C.3080008@wizards.de>
Message-ID: <63b4e4050606280649y454d1aa3pee3aaa4fb7f2236f@mail.gmail.com>

On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
>
> Brian quoted: "Storing a reference to [the published object] into a field
> that is properly guarded by a lock." but then added "all accesses (read
> and write)". The former would allow for an unspecified window where the
> change is not-quite-visible-yet, but eventually will (MEM_AUTO_COMMIT :).
> The latter would mean that *all* references to *all* fields of a compound
> object that is shared between threads *must* be accessed from inside a
> synchronized method or at least in a synchronized block to ensure
> visibility. We can only guess how many lines of Java code don't do that;
> that's why I was wondering about the possible fallout.


The fallout is potentially huge.

Here is another JCiP quote: "If multiple threads access the same mutable
state variable without appropriate synchronization, <em>your program is
broken</em>. (p.16)"  (The term "access" refers to both reads and writes.)

There are probably a lot of broken programs out there.

--tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060628/a6e47375/attachment.html 

From studdugie at gmail.com  Wed Jun 28 10:11:58 2006
From: studdugie at gmail.com (studdugie)
Date: Wed, 28 Jun 2006 10:11:58 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A2812C.3080008@wizards.de>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>
	<44A2812C.3080008@wizards.de>
Message-ID: <5a59ce530606280711p5286c060ncf23c0464fd20336@mail.gmail.com>

I agree w/ the spirit of Holger's questions 100% because it deals w/
what is happening on the ground now, not what is theoritically
supposed to happen.  Since I use Sun JVMs almost exclusively I would
love to hear back from Sun engineers about what is going on under the
covers today in regards to this discussion.

Regards,

Dane

On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
> Dhanji R. Prasanna wrote:
> > On 6/28/06, Holger Hoffst?tte <holger at wizards.de> wrote:
> >> Brian Goetz wrote:
> >> > And, just for completeness: synchronized write + nonsynchronized read
> >> > doesn't create the required happens-before, so it doesn't work.  The
> >> > getter in such a case isn't required to ever return anything other than
> >> > the default (zero) value.
> >>
> >> This made me curious. While "strictly speaking" the above behaviour might
> >> be correct according to the spec/revised memory model, in practice (as in
> >> stuff I can buy/run today) the unsynchronized read *will* succeed - maybe
> >
> > I believe with regard to the original question, the unsynchronized
> > read is not expected to be deterministic because there isnt a
> > happens-before edge forcing the 2 threads into a write/read sequence.
>
> The original poster assured that the setting (== exit of the synchronized
> method body) was guaranteed to happen before the read. I don't think
> anybody would expect the read to return a non-null value even though no
> value has ever been set yet. Not even Futures can do that. ;)
>
> > Im not sure what you mean by "succeed", but for the required behavior
> > (i.e. write prior to read) one cannot guarantee that a synchronized
> > write + unsynchronized read will suffice.
>
> I'm mainly interested in unambiguous clarification of the apparently (?)
> possible time window that may or may not exist after the synchronized set
> method has returned. The size of that window (if it exists?) constitutes a
> "visibility race" and if it is ever allowed to be "forever" - as per
> Brian's comment above - then many applications will produce "interesting"
> results.
>
> > Declaring the variable as volatile forces both threads to deal with
> > the same memory but still does not solve the issue of sequencing the
> > write/read. This is how I read Brian's and the others' responses.
>
> Brian qouted: "Storing a reference to [the published object] into a field
> that is properly guarded by a lock." but then added "all accesses (read
> and write)". The former would allow for an unspecified window where the
> change is not-quite-visible-yet, but eventually will (MEM_AUTO_COMMIT :).
> The latter would mean that *all* references to *all* fields of a compound
> object that is shared between threads *must* be accessed from inside a
> synchronized method or at least in a synchronized block to ensure
> visibility. We can only guess how many lines of Java code don't do that;
> that's why I was wondering about the possible fallout.
>
> Sorry if I'm being dense or overly picky here - if I'm missing something
> fundamental please set me straight. All this should be put into a FAQ that
> every random Java dude can understand!
>
> cheers
> Holger
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From brian at quiotix.com  Wed Jun 28 11:52:32 2006
From: brian at quiotix.com (Brian Goetz)
Date: Wed, 28 Jun 2006 11:52:32 -0400
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <5a59ce530606280711p5286c060ncf23c0464fd20336@mail.gmail.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>	<44A1AEC4.6000907@quiotix.com>
	<44A24CA2.1010005@wizards.de>	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>	<44A2812C.3080008@wizards.de>
	<5a59ce530606280711p5286c060ncf23c0464fd20336@mail.gmail.com>
Message-ID: <44A2A5C0.5020609@quiotix.com>

> I agree w/ the spirit of Holger's questions 100% because it deals w/
> what is happening on the ground now, not what is theoritically
> supposed to happen.  Since I use Sun JVMs almost exclusively I would
> love to hear back from Sun engineers about what is going on under the
> covers today in regards to this discussion.

To some degree, Holger's question is analogous to when your kid says 
"but I ran with the scissors every day last week and I didn't put my eye 
out!"  Just because one can engage in risky behavior "a lot of times" 
and not suffer negative consequences doesn't mean that you are not 
asking for trouble.

Most popular CPUs (Intel, Sparc) offer a stronger memory model than 
required by the JMM.  That means that _some_ of the bad things that can 
happen in broken code won't actually happen on these CPUs.  Similarly, 
_some_ of the bad things that can happen don't on single-CPU systems.

I've taken the position of deliberately not enumerating or explaining 
them, because I know that at some point, someone will incorrectly say 
(probably just leaving off the "In X and Y cases" qualification) in an 
embarassingly public forum "Brian says its OK to do Z" based on that. 
Besides, any advice along those lines would be dangerously CPU- and 
JVM-specific.

As to the duration of the visibility race -- I've seen evidence that it 
can be at least minutes on real systems.  (That's basically forever, 
isn't it?)  But the JMM does allow it to be forever, and Joe's example 
of a compiler optimization shows one when it will be forever because the 
compiler has hoisted the fetch out of the loop.  (This one really 
happens too.)


From dhanji at gmail.com  Wed Jun 28 19:05:40 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 29 Jun 2006 09:05:40 +1000
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <44A2A5C0.5020609@quiotix.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>
	<44A19CBF.8010906@cs.purdue.edu>
	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>
	<44A1AEC4.6000907@quiotix.com> <44A24CA2.1010005@wizards.de>
	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>
	<44A2812C.3080008@wizards.de>
	<5a59ce530606280711p5286c060ncf23c0464fd20336@mail.gmail.com>
	<44A2A5C0.5020609@quiotix.com>
Message-ID: <aa067ea10606281605v25c7937fx80547a955c921228@mail.gmail.com>

On 6/29/06, Brian Goetz <brian at quiotix.com> wrote:
> > I agree w/ the spirit of Holger's questions 100% because it deals w/
> > what is happening on the ground now, not what is theoritically
> > supposed to happen.
>
> To some degree, Holger's question is analogous to when your kid says
> "but I ran with the scissors every day last week and I didn't put my eye
> out!"  Just because one can engage in risky behavior "a lot of times"
> and not suffer negative consequences doesn't mean that you are not
> asking for trouble.
>

I agree that there isnt much merit to discussing what may happen on a
specific architecture/CPU, as we can only ever guarantee behavior according
to the language specification. Most apps are intended to run on any JVM
(even ones for CPUs not built yet) anyway, and cannot be deterministic if
there is a presumption of a specific CPU architecture (you're better off
compiling to native in that case).


I'm mainly interested in unambiguous clarification of the apparently (?)
> possible time window that may or may not exist after the synchronized set
> method has returned.


Afaics, there is no way to unambiguously clarify this without a
machine-specific answer.

The size of that window (if it exists?) constitutes a
"visibility race" and if it is ever allowed to be "forever" - as per
Brian's comment above - then many applications will produce "interesting"
results.


Im not clear how this is a race condition, if the reader acts after the
happens-before edge, there won't be a competition for shared memory--unless
I am missing something (quite possible)? Do you just mean that there is an
(potential) undefined delay?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060629/0aa861bc/attachment.html 

From dhanji at gmail.com  Wed Jun 28 19:36:18 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 29 Jun 2006 09:36:18 +1000
Subject: [concurrency-interest] wikipedia article
Message-ID: <aa067ea10606281636w7fe7d60u9f74c8f87c0dd8c2@mail.gmail.com>

I came across this article on wikipedia:
http://en.wikipedia.org/wiki/Real-Time_Java

Although I am generally wary of anything wikipedia says, it's often ok for
minor technical definitions and such. But I was bothered when I read the
following points:

It was not immediately suitable for Real
time<http://en.wikipedia.org/wiki/Real_time>systems for two reasons:
>
>    - The threading behavior was largely unspecified. This, reputedly,
>    was a concession to Microsoft<http://en.wikipedia.org/wiki/Microsoft>to allow for the weak threading models underlying the Microsoft
>    Windows <http://en.wikipedia.org/wiki/Microsoft_Windows> operating
>    system at the time.
>
>
>    - Still, there is only one synchronization primitive available for Lock
>    (software engineering)<http://en.wikipedia.org/wiki/Lock_%28software_engineering%29>,
>    the Monitor (synchronization)<http://en.wikipedia.org/wiki/Monitor_%28synchronization%29>pattern, meaning that only code sections can be guarded, not data.
>
>
Obviously the article is quite out of date, but was it true that the poor
threading model in early java was a concession to Microsoft?

Also, data can be guarded directly with j.u.c.atomic--if I'm not mistaken,
obviating the second point?

Dhanji.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060629/85e65c11/attachment.html 

From dcholmes at optusnet.com.au  Wed Jun 28 20:00:45 2006
From: dcholmes at optusnet.com.au (David Holmes)
Date: Thu, 29 Jun 2006 10:00:45 +1000
Subject: [concurrency-interest] wikipedia article
In-Reply-To: <aa067ea10606281636w7fe7d60u9f74c8f87c0dd8c2@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKNGPAA.dcholmes@optusnet.com.au>

The reference re Microsoft is completely incorrect. There was a very early
Java Threads whitepaper that defined a strict priority-based scheduling
model. That model was not implementable on Solaris or Windows at the time,
without involving the real-time scheduling classes of the OS. The spec was
subsequently relaxed.

Second any reference to "protecting code" versus "protecting data" is very
misleading and confusing. You protect data by controlling the code that
accesses that data. The level of abstraction at which you do this then lends
some people to characterise as "protecting data" or "protecting code". An
abstraction involving shared objects that can't be accessed in anything but
a thread-safe manner would be classified as "data protection". Java doesn't
provide that directly but allows you build this by applying "code
protection" in the right way.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Dhanji R.
Prasanna
  Sent: Thursday, 29 June 2006 9:36 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] wikipedia article


  I came across this article on wikipedia:
  http://en.wikipedia.org/wiki/Real-Time_Java

  Although I am generally wary of anything wikipedia says, it's often ok for
minor technical definitions and such. But I was bothered when I read the
following points:


    It was not immediately suitable for Real time systems for two reasons:

      a.. The threading behavior was largely unspecified. This, reputedly,
was a concession to Microsoft to allow for the weak threading models
underlying the Microsoft Windows operating system at the time.
      a.. Still, there is only one synchronization primitive available for
Lock (software engineering), the Monitor (synchronization) pattern, meaning
that only code sections can be guarded, not data.

  Obviously the article is quite out of date, but was it true that the poor
threading model in early java was a concession to Microsoft?

  Also, data can be guarded directly with j.u.c.atomic--if I'm not mistaken,
obviating the second point?

  Dhanji.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060629/553b58b6/attachment.html 

From dhanji at gmail.com  Wed Jun 28 23:21:42 2006
From: dhanji at gmail.com (Dhanji R. Prasanna)
Date: Thu, 29 Jun 2006 13:21:42 +1000
Subject: [concurrency-interest] wikipedia article
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKNGPAA.dcholmes@optusnet.com.au>
References: <aa067ea10606281636w7fe7d60u9f74c8f87c0dd8c2@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEKNGPAA.dcholmes@optusnet.com.au>
Message-ID: <aa067ea10606282021w6a2bc32fucb54a7f49f76497c@mail.gmail.com>

On 6/29/06, David Holmes <dcholmes at optusnet.com.au> wrote:
>
>  The reference re Microsoft is completely incorrect. There was a very
> early Java Threads whitepaper that defined a strict priority-based
> scheduling model. That model was not implementable on Solaris or Windows at
> the time, without involving the real-time scheduling classes of the OS. The
> spec was subsequently relaxed.
>

Good to know!

Second any reference to "protecting code" versus "protecting data" is very
> misleading and confusing. You protect data by controlling the code that
> accesses that data. The level of abstraction at which you do this then lends
> some people to characterise as "protecting data" or "protecting code". An
> abstraction involving shared objects that can't be accessed in anything but
> a thread-safe manner would be classified as "data protection". Java doesn't
> provide that directly but allows you build this by applying "code
> protection" in the right way.
>

I agree strongly about the wording. In any case at a core-API level of
abstraction java provides this "data protection" with atomic references.
Thanks very much for clearing that up viz MS.

Cheers,
> David Holmes
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060629/ea45be37/attachment.html 

From holger at wizards.de  Thu Jun 29 04:34:36 2006
From: holger at wizards.de (=?ISO-8859-1?Q?Holger_Hoffst=E4tte?=)
Date: Thu, 29 Jun 2006 10:34:36 +0200
Subject: [concurrency-interest] Synchronization question
In-Reply-To: <aa067ea10606281605v25c7937fx80547a955c921228@mail.gmail.com>
References: <73C466B3EAAF504987DBF8E6EAC7E8CF0733C2@pangomail2k3.pangonetworks.com>	<44A19CBF.8010906@cs.purdue.edu>	<63b4e4050606271424m5804856y9540e149ddfe1567@mail.gmail.com>	<44A1AEC4.6000907@quiotix.com>
	<44A24CA2.1010005@wizards.de>	<aa067ea10606280514le9a4392mbc50718ba71cbb84@mail.gmail.com>	<44A2812C.3080008@wizards.de>	<5a59ce530606280711p5286c060ncf23c0464fd20336@mail.gmail.com>	<44A2A5C0.5020609@quiotix.com>
	<aa067ea10606281605v25c7937fx80547a955c921228@mail.gmail.com>
Message-ID: <44A3909C.8020308@wizards.de>

Dhanji R. Prasanna wrote:
>> I'm mainly interested in unambiguous clarification of the apparently (?)
>> possible time window that may or may not exist after the
>> synchronized set method has returned. 
> 
> Afaics, there is no way to unambiguously clarify this without a
> machine-specific answer.

That would have been fine, I was merely curious. Too many years of lurking
in comp.arch, I guess..

> Im not clear how this is a race condition, if the reader acts after the
> happens-before edge, there won't be a competition for shared
> memory--unless I am missing something (quite possible)? Do you just mean
> that there is an (potential) undefined delay?

Yes (the latter), and as Brian has commented it not only exists but is
also irrelevant to know from an external point of view - since the spec
says it can be forever. I understand his reluctance to give concrete
examples since that would indeed only lead to even more misguided
folklore, and Java already has enough of that.

Holger

From qweries at gmail.com  Fri Jun 30 04:16:43 2006
From: qweries at gmail.com (Raj)
Date: Fri, 30 Jun 2006 13:46:43 +0530
Subject: [concurrency-interest] NullPointerException in
	ThreadLocal$ThreadLocalMap.replaceStaleEntry
Message-ID: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>

Hi we have been facing an NPE on an off. The stack trace looks like:

java.lang.NullPointerException
	at java.lang.ThreadLocal$ThreadLocalMap$Entry.access$502(ThreadLocal.java:229)
	at java.lang.ThreadLocal$ThreadLocalMap.replaceStaleEntry(ThreadLocal.java:509)
	at java.lang.ThreadLocal$ThreadLocalMap.getAfterMiss(ThreadLocal.java:362)
	at java.lang.ThreadLocal$ThreadLocalMap.get(ThreadLocal.java:341)
	at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:219)
	at java.lang.ThreadLocal.get(ThreadLocal.java:121)
*snip*

This issue has been reported by some elsewhere:
http://www-128.ibm.com/developerworks/forums/dw_thread.jsp?message=13741787&cat=10&thread=90185&treeDisplayType=threadmode1&forum=176#13741787.
However, no solution/analysis of the cause has been posted.

The problem occurs sporadicaly and we are having trouble to simulate
the problem. Would appreciate any help in trying to narrow down the
problem.

Thanks,
Raj

From joe.bowbeer at gmail.com  Fri Jun 30 06:41:12 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 30 Jun 2006 03:41:12 -0700
Subject: [concurrency-interest] NullPointerException in
	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
Message-ID: <31f2a7bd0606300341g6597058ay7640f1e9f0750bff@mail.gmail.com>

On 6/30/06, Raj <qweries at gmail.com> wrote:
> Hi we have been facing an NPE on an off. The stack trace looks like:
>
> java.lang.NullPointerException
>         at java.lang.ThreadLocal$ThreadLocalMap$Entry.access$502(ThreadLocal.java:229)
>         at java.lang.ThreadLocal$ThreadLocalMap.replaceStaleEntry(ThreadLocal.java:509)
>         at java.lang.ThreadLocal$ThreadLocalMap.getAfterMiss(ThreadLocal.java:362)
>         at java.lang.ThreadLocal$ThreadLocalMap.get(ThreadLocal.java:341)
>         at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:219)
>         at java.lang.ThreadLocal.get(ThreadLocal.java:121)
> *snip*
>
> This issue has been reported by some elsewhere:
> http://www-128.ibm.com/developerworks/forums/dw_thread.jsp?message=13741787&cat=10&thread=90185&treeDisplayType=threadmode1&forum=176#13741787.
> However, no solution/analysis of the cause has been posted.
>
> The problem occurs sporadicaly and we are having trouble to simulate
> the problem. Would appreciate any help in trying to narrow down the
> problem.
>
> Thanks,
> Raj


Which version and build of the VM are you using?  (java -version)

From bharath at pramati.com  Fri Jun 30 07:23:38 2006
From: bharath at pramati.com (Bharath Ganesh)
Date: Fri, 30 Jun 2006 16:53:38 +0530
Subject: [concurrency-interest] NullPointerException
	inThreadLocal$ThreadLocalMap.replaceStaleEntry
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
	<31f2a7bd0606300341g6597058ay7640f1e9f0750bff@mail.gmail.com>
Message-ID: <049301c69c37$bce13d10$c001a8c0@bharathg>

The java version used was 

java version "1.4.2_11"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.4.2_11-b06)
Java HotSpot(TM) Client VM (build 1.4.2_11-b06, mixed mode)


  ----- Original Message ----- 
  From: Joe Bowbeer 
  To: concurrency-interest at cs.oswego.edu 
  Sent: Friday, June 30, 2006 4:11 PM
  Subject: Re: [concurrency-interest] NullPointerException inThreadLocal$ThreadLocalMap.replaceStaleEntry


  On 6/30/06, Raj <qweries at gmail.com> wrote:
  > Hi we have been facing an NPE on an off. The stack trace looks like:
  >
  > java.lang.NullPointerException
  >         at java.lang.ThreadLocal$ThreadLocalMap$Entry.access$502(ThreadLocal.java:229)
  >         at java.lang.ThreadLocal$ThreadLocalMap.replaceStaleEntry(ThreadLocal.java:509)
  >         at java.lang.ThreadLocal$ThreadLocalMap.getAfterMiss(ThreadLocal.java:362)
  >         at java.lang.ThreadLocal$ThreadLocalMap.get(ThreadLocal.java:341)
  >         at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:219)
  >         at java.lang.ThreadLocal.get(ThreadLocal.java:121)
  > *snip*
  >
  > This issue has been reported by some elsewhere:
  > http://www-128.ibm.com/developerworks/forums/dw_thread.jsp?message=13741787&cat=10&thread=90185&treeDisplayType=threadmode1&forum=176#13741787.
  > However, no solution/analysis of the cause has been posted.
  >
  > The problem occurs sporadicaly and we are having trouble to simulate
  > the problem. Would appreciate any help in trying to narrow down the
  > problem.
  >
  > Thanks,
  > Raj


  Which version and build of the VM are you using?  (java -version)
  _______________________________________________
  Concurrency-interest mailing list
  Concurrency-interest at altair.cs.oswego.edu
  http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060630/af6f7f8d/attachment.html 

From joe.bowbeer at gmail.com  Fri Jun 30 08:18:57 2006
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 30 Jun 2006 05:18:57 -0700
Subject: [concurrency-interest] NullPointerException
	inThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <049301c69c37$bce13d10$c001a8c0@bharathg>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
	<31f2a7bd0606300341g6597058ay7640f1e9f0750bff@mail.gmail.com>
	<049301c69c37$bce13d10$c001a8c0@bharathg>
Message-ID: <31f2a7bd0606300518t4b3014dhf40d9e61e75c0c13@mail.gmail.com>

On 6/30/06, Bharath Ganesh <bharath at pramati.com> wrote:
>
> The java version used was 1.4.2_11-b06
>

But that was before java.util.concurrent..

Unless someone else has a clue, I would suggest you upgrade to 1.5 and
retry.  A few bugs have been fixed since 1.4, such as:

5025230R (thread) Creating thread local variables from within
ThreadLocal.initialValue()

--Joe

From dl at cs.oswego.edu  Fri Jun 30 08:31:22 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 30 Jun 2006 08:31:22 -0400
Subject: [concurrency-interest] NullPointerException
	in	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
Message-ID: <44A5199A.3030807@cs.oswego.edu>

Raj wrote:
> Hi we have been facing an NPE on an off. The stack trace looks like:
> 
> java.lang.NullPointerException
> 	at java.lang.ThreadLocal$ThreadLocalMap$Entry.access$502(ThreadLocal.java:229)
> 	at java.lang.ThreadLocal$ThreadLocalMap.replaceStaleEntry(ThreadLocal.java:509)
> 	at java.lang.ThreadLocal$ThreadLocalMap.getAfterMiss(ThreadLocal.java:362)
> 	at java.lang.ThreadLocal$ThreadLocalMap.get(ThreadLocal.java:341)
> 	at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:219)
> 	at java.lang.ThreadLocal.get(ThreadLocal.java:121)
> *snip*
> 
> This issue has been reported by some elsewhere:
> http://www-128.ibm.com/developerworks/forums/dw_thread.jsp?message=13741787&cat=10&thread=90185&treeDisplayType=threadmode1&forum=176#13741787.
> However, no solution/analysis of the cause has been posted.
> 

Which probably stems from no one having taken the time to
file a replicatable bug report so someone can diagnose it!
Could you please do so?

As Joe just mentioned, there was an unsupported usage (that
was not clearly documented as unsupported) of initialValue
methods recursively creating other ThreadLocals, that was
addressed for Mustang, and which might conceivably cause this.
It might not be too hard to look in your code to see if
there are any cases of this. Otherwise, offhand, this looks
like it might be a GC bug, but no one will be able to figure
it out unless they can replicate.

-Doug

From qweries at gmail.com  Fri Jun 30 09:04:01 2006
From: qweries at gmail.com (Raj)
Date: Fri, 30 Jun 2006 18:34:01 +0530
Subject: [concurrency-interest] NullPointerException in
	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5199A.3030807@cs.oswego.edu>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
	<44A5199A.3030807@cs.oswego.edu>
Message-ID: <f6e4b9950606300604w27500561g10aefc034d83af15@mail.gmail.com>

Thanks for pointing out the initialValue bug. It is a good start to
narrow down the problem. It is not easy for us to do a code walk
through and find out if we are facing the same issue as we use some
third party libraries and the thread locals are being created in our
code, the libraries and presumably in the jdk code.

I will attempt checking the StackTraceElements in the ThreadLocal
constructor to see if the ThreadLocal.initialValue() is in the stack.
Figuring out how it would cause this NPE would be another thing. :)

Since it is not very easily reproducible, there would not be any quick
way to confirm if JDK 5 has the fix even if we do not face the issue
with JDK 5.

Thanks,
Raj

On 6/30/06, Doug Lea <dl at cs.oswego.edu> wrote:
> Raj wrote:
> > Hi we have been facing an NPE on an off. The stack trace looks like:
> >
> > java.lang.NullPointerException
> >       at java.lang.ThreadLocal$ThreadLocalMap$Entry.access$502(ThreadLocal.java:229)
> >       at java.lang.ThreadLocal$ThreadLocalMap.replaceStaleEntry(ThreadLocal.java:509)
> >       at java.lang.ThreadLocal$ThreadLocalMap.getAfterMiss(ThreadLocal.java:362)
> >       at java.lang.ThreadLocal$ThreadLocalMap.get(ThreadLocal.java:341)
> >       at java.lang.ThreadLocal$ThreadLocalMap.access$000(ThreadLocal.java:219)
> >       at java.lang.ThreadLocal.get(ThreadLocal.java:121)
> > *snip*
> >
> > This issue has been reported by some elsewhere:
> > http://www-128.ibm.com/developerworks/forums/dw_thread.jsp?message=13741787&cat=10&thread=90185&treeDisplayType=threadmode1&forum=176#13741787.
> > However, no solution/analysis of the cause has been posted.
> >
>
> Which probably stems from no one having taken the time to
> file a replicatable bug report so someone can diagnose it!
> Could you please do so?
>
> As Joe just mentioned, there was an unsupported usage (that
> was not clearly documented as unsupported) of initialValue
> methods recursively creating other ThreadLocals, that was
> addressed for Mustang, and which might conceivably cause this.
> It might not be too hard to look in your code to see if
> there are any cases of this. Otherwise, offhand, this looks
> like it might be a GC bug, but no one will be able to figure
> it out unless they can replicate.
>
> -Doug
>

From tackline at tackline.plus.com  Fri Jun 30 10:58:10 2006
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 30 Jun 2006 15:58:10 +0100
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5199A.3030807@cs.oswego.edu>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>
	<44A5199A.3030807@cs.oswego.edu>
Message-ID: <44A53C02.60207@tackline.plus.com>

Doug Lea wrote:
> 
> As Joe just mentioned, there was an unsupported usage (that
> was not clearly documented as unsupported) of initialValue
> methods recursively creating other ThreadLocals, that was
> addressed for Mustang, and which might conceivably cause this.
> It might not be too hard to look in your code to see if
> there are any cases of this. Otherwise, offhand, this looks
> like it might be a GC bug, but no one will be able to figure
> it out unless they can replicate.

Looking through the source, it does appear to be Bug 5025230 [1] as Joe 
says. However, this case is a bit more subtle than the scenario in the 
report. It appears that the nested thread-local initialisation causes 
some tidying of stale entries, which clears the slot about to be filled 
(probably on a complete rehash of the thread's table).

Anyway, the result is the same. Initialising ThreadLocals within 
initialValue doesn't work in both 1.4.2_11 and 1.5.0_07. Currently you 
need mustang for it to work (or patch your own JRE - I believe there is 
a license to do this for internal use (IANAL)).

Avoiding nested initialisation may be more difficult than it would first 
appear. As well as your own code in initialValue, you need to avoid 
using anyone else's code that might initiliase ThreadLocals. For 
instance, loading classes can cause ThreadLocals to initialise (that 
confused me briefly).

You could try flushing out any ThreadLocals in every thread before using 
initialValue. However, the obvious safe approach is to override get in 
place of initialValue. Something like:

public abstract class SaferThreadLocal/*<T>*/
extends ThreadLocal/*<T>*/
{
     private static final Object UNINITIALIZED = new Object();

     //@Override
     protected final Object/*T*/ initialValue() {
         return UNINITIALIZED;
     }

     protected abstract Object/*T*/ initialValueOverride();

     //@SuppressWarnings("unchecked")
     //@Override
     protected final Object/*T*/ get() {
         Object obj = super.get();
         if (obj == UNINITIALIZED) {
             obj = initialValueOverride();
             super.set(obj);
         }
         return /*(T)*/obj;
     }
}

(Disclaimer: code not tested, or even compiled.)

Tom Hawtin

[1] http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5025230


From mailinglist.taras.tielkes at gmail.com  Fri Jun 30 11:28:42 2006
From: mailinglist.taras.tielkes at gmail.com (Taras Tielkes)
Date: Fri, 30 Jun 2006 17:28:42 +0200
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A53C02.60207@tackline.plus.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>
	<44A53C02.60207@tackline.plus.com>
Message-ID: <44A5432A.90901@gmail.com>

Thomas Hawtin wrote:
> Doug Lea wrote:
>   
>> As Joe just mentioned, there was an unsupported usage (that
>> was not clearly documented as unsupported) of initialValue
>> methods recursively creating other ThreadLocals, that was
>> addressed for Mustang, and which might conceivably cause this.
>> It might not be too hard to look in your code to see if
>> there are any cases of this. Otherwise, offhand, this looks
>> like it might be a GC bug, but no one will be able to figure
>> it out unless they can replicate.
>>     
>
> Looking through the source, it does appear to be Bug 5025230 [1] as Joe 
> says. However, this case is a bit more subtle than the scenario in the 
> report. It appears that the nested thread-local initialisation causes 
> some tidying of stale entries, which clears the slot about to be filled 
> (probably on a complete rehash of the thread's table).
>
>   
That would certainly make it very non-deterministic and hard to reproduce.

Now for a bit off-topic...I heard that a new implementation of 
ThreadLocal will make it into Dolphin, eliminating both the lingering 
stale entries, and the value->key reference path limitation. Any thuth 
to this, or better, details?

-tt
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20060630/b7fc6b30/attachment-0001.html 

From dl at cs.oswego.edu  Fri Jun 30 12:46:51 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 30 Jun 2006 12:46:51 -0400
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5432A.90901@gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com>
	<44A5432A.90901@gmail.com>
Message-ID: <44A5557B.9060002@cs.oswego.edu>

Taras Tielkes wrote:
> T
> Now for a bit off-topic...I heard that a new implementation of 
> ThreadLocal will make it into Dolphin, eliminating both the lingering 
> stale entries, and the value->key reference path limitation. Any thuth 
> to this, or better, details?
> 

I think that's the plan.

Here's how I see some of the story behind it.

1. ThreadLocals were originally designed as a way to maintain
very fast access (mainly by avoiding synchronization) to little
bits of context needed mainly in infrastructure/middleware stuff.
As an example, ReentrantReadWriteLock uses one to track reader
recursion. The main design goals here are to make the common
fast path very fast (usually less than a dozen simple instructions).
And implicit limitations of not dealing well with cyclic garbage
never even arose.

2. Web frameworks, especially, discovered that you could use
ThreadLocals to maintain full session state more cheaply than
any other way, basically by making everything a ThreadLocal.
By not having programmers think about what would even make
sense as a ThreadLocal, and instead using them for everything,
ThreadLocal itself turns into a mini-garbage-collector. Which
it will never do as well as platform-level GC. Even doing it
as well as it does costs the "classic" uses a bit of performance,
and doing it better will cost more.

So the fun algorithmic issue here is how to make life better
for both styles of use. Not knowing any better compromise, it
may be that there is an additional SlowerButBetterAtGCThreadLocal
class people can use when applicable.

-Doug


From tackline at tackline.plus.com  Fri Jun 30 13:18:42 2006
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 30 Jun 2006 18:18:42 +0100
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5432A.90901@gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu><44A53C02.60207@tackline.plus.com>
	<44A5432A.90901@gmail.com>
Message-ID: <44A55CF2.3060705@tackline.plus.com>

Taras Tielkes wrote:
> 
> Now for a bit off-topic...I heard that a new implementation of 
> ThreadLocal will make it into Dolphin, eliminating both the lingering 
> stale entries, and the value->key reference path limitation. Any thuth 
> to this, or better, details?

I believe the current thinking is that an early dolphin build will have 
clearer documentation[1]. A java.lang.ReclaimableThreadLocal[2] (extends 
ThreadLocal) will provide a better behaved implementation (of some 
description). It's difficult to come up with a well behaved 
implementation that performs as well as the current implementation on 
multiprocessor machines (particularly without making changes deep within 
the JVM).

Tom Hawtin

[1] "(spec thread) ThreadLocal.remove documentation needs improvement 
wrt reclaiming objects"
         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6422556

[2] "(thread) Provide reclaimable thread local values without Thread 
termination"
         http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6254531

From taras.tielkes at gmail.com  Fri Jun 30 13:30:16 2006
From: taras.tielkes at gmail.com (Taras Tielkes)
Date: Fri, 30 Jun 2006 19:30:16 +0200
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5557B.9060002@cs.oswego.edu>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com>
	<44A5432A.90901@gmail.com> <44A5557B.9060002@cs.oswego.edu>
Message-ID: <44A55FA8.7080903@gmail.com>

Doug Lea wrote:
> Taras Tielkes wrote:
>> T
>> Now for a bit off-topic...I heard that a new implementation of 
>> ThreadLocal will make it into Dolphin, eliminating both the lingering 
>> stale entries, and the value->key reference path limitation. Any 
>> thuth to this, or better, details?
>>
>
> I think that's the plan.
>
> Here's how I see some of the story behind it.
>
> 1. ThreadLocals were originally designed as a way to maintain
> very fast access (mainly by avoiding synchronization) to little
> bits of context needed mainly in infrastructure/middleware stuff.
> As an example, ReentrantReadWriteLock uses one to track reader
> recursion. The main design goals here are to make the common
> fast path very fast (usually less than a dozen simple instructions).
> And implicit limitations of not dealing well with cyclic garbage
> never even arose.
Were such consideration there at the beginning (1.1?), long before 
ReentrantReadWriteLock?

I've always been surprised (hearing about) such strong performance 
considerations, since the typical uses of ThreadLocal that I've seen 
(transacion, auth, causality contexts) aren't that demanding. Usually 
set at entry, removed at exit, with limited mutations in between (nested 
tx, role delegation, etc).
>
> 2. Web frameworks, especially, discovered that you could use
> ThreadLocals to maintain full session state more cheaply than
> any other way, basically by making everything a ThreadLocal.
> By not having programmers think about what would even make
> sense as a ThreadLocal, and instead using them for everything,
> ThreadLocal itself turns into a mini-garbage-collector. Which
> it will never do as well as platform-level GC. Even doing it
> as well as it does costs the "classic" uses a bit of performance,
> and doing it better will cost more.
>
There's something worse too: InheritableThreadLocal: There are 
components that set InheritableThreadLocals, and there are components 
creating threads, blissfully unaware of each other and a mix for 
disaster. The result is almost always an unGCable reference keeping a 
(perhaps huge) object graph in memory. The code setting the ITL just 
can't know when and where a new thread will be created.

A good example is a servlet that generates images (thus 
lazy-initializing the Java2D headless subsystem, to be specific, the 
sun.java2d.Disposer thread).
The first webapp to do this will leak a reference to any 
currently-for-that-thread ITL to the Disposer thread (which only shuts 
down when the JVM shuts down.

What about a method to forcefully clean the ThreadLocals for the current 
thread (and the CCL to) ?

> So the fun algorithmic issue here is how to make life better
> for both styles of use. Not knowing any better compromise, it
> may be that there is an additional SlowerButBetterAtGCThreadLocal
> class people can use when applicable.
>
Or a method to force cleanup. Frameworks usually know when a request is 
at the end of it's lifecycle.
Just curious, what is the pre-Thread amount of ThreadLocals you're 
optimizing for?

-tt

From dl at cs.oswego.edu  Fri Jun 30 14:08:14 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 30 Jun 2006 14:08:14 -0400
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A55FA8.7080903@gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com>	<44A5432A.90901@gmail.com>
	<44A5557B.9060002@cs.oswego.edu> <44A55FA8.7080903@gmail.com>
Message-ID: <44A5688E.5080404@cs.oswego.edu>

Taras Tielkes wrote:
> The main design goals here are to make the common
>> fast path very fast (usually less than a dozen simple instructions).
>> And implicit limitations of not dealing well with cyclic garbage
>> never even arose.
> Were such consideration there at the beginning (1.1?), long before 
> ReentrantReadWriteLock?

Performance of ThreadLocals has been an issue just about forever.
See for example some of the old JMM postings about it more than 5 years ago.
(http://www.cs.umd.edu/~pugh/java/memoryModel/)

(Without care, nearly every class in java.lang, java.util, and
java.util.concurrent is likely to be the performance bottleneck
in many real applications. It keeps life interesting for library
developers.)

> 
> What about a method to forcefully clean the ThreadLocals for the current 
> thread (and the CCL to) ?
> 

This has been proposed many times, and each time it is argued that
no one piece of code will ever know enough to kill exactly all
the right ThreadLocals, since some are buried in unknown subsystems,
including some that may be critical in security code.

A better bet would be to establish some new scoping construct
such that you could declare ThreadLocals to be in particular
scopes, and then support a method that would kill all in that
scope. I don't believe anyone has ever made a concrete proposal
along those lines though.


> Or a method to force cleanup. Frameworks usually know when a request is 
> at the end of it's lifecycle.
> Just curious, what is the pre-Thread amount of ThreadLocals you're 
> optimizing for?
> 

They default to only 16 but resizing is quick and not usually the issue
here.

-Doug


From tackline at tackline.plus.com  Fri Jun 30 14:39:46 2006
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 30 Jun 2006 19:39:46 +0100
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A5557B.9060002@cs.oswego.edu>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com><44A5432A.90901@gmail.com>
	<44A5557B.9060002@cs.oswego.edu>
Message-ID: <44A56FF2.9000809@tackline.plus.com>

Doug Lea wrote:
> 
> 1. ThreadLocals were originally designed as a way to maintain
> very fast access (mainly by avoiding synchronization) to little
> bits of context needed mainly in infrastructure/middleware stuff.

Didn't the original version (prior to 1.3/1.2.2_13) use synchronisation, 
with a pre-ThreadLocal map from Thread to value instead of a per-Thread 
map from ThreadLocal to value?

Tom Hawtin


From dl at cs.oswego.edu  Fri Jun 30 14:43:55 2006
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 30 Jun 2006 14:43:55 -0400
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A56FF2.9000809@tackline.plus.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com><44A5432A.90901@gmail.com>
	<44A5557B.9060002@cs.oswego.edu>
	<44A56FF2.9000809@tackline.plus.com>
Message-ID: <44A570EB.4060209@cs.oswego.edu>

Thomas Hawtin wrote:
> 
> Didn't the original version (prior to 1.3/1.2.2_13) use synchronisation, 
> with a pre-ThreadLocal map from Thread to value instead of a per-Thread 
> map from ThreadLocal to value?
> 

Until the API originator reimplemented it to meet original intent :-)
All thread-local constructions in all languages and systems I know use
the vastly more efficient variable-as-key approach.

-Doug


From tackline at tackline.plus.com  Fri Jun 30 15:42:20 2006
From: tackline at tackline.plus.com (Thomas Hawtin)
Date: Fri, 30 Jun 2006 20:42:20 +0100
Subject: [concurrency-interest]
	NullPointerExceptionin	ThreadLocal$ThreadLocalMap.replaceStaleEntry
In-Reply-To: <44A55FA8.7080903@gmail.com>
References: <f6e4b9950606300116u20040447l12889617cb90e2a@mail.gmail.com>	<44A5199A.3030807@cs.oswego.edu>	<44A53C02.60207@tackline.plus.com><44A5432A.90901@gmail.com>
	<44A5557B.9060002@cs.oswego.edu> <44A55FA8.7080903@gmail.com>
Message-ID: <44A57E9C.9060903@tackline.plus.com>

Taras Tielkes wrote:
> 
> A good example is a servlet that generates images (thus 
> lazy-initializing the Java2D headless subsystem, to be specific, the 
> sun.java2d.Disposer thread).
> The first webapp to do this will leak a reference to any 
> currently-for-that-thread ITL to the Disposer thread (which only shuts 
> down when the JVM shuts down.

Yup, you can end up with system threads having, say, an Applet's 
TimeZone. Most such thread creation code fix the ThreadGroup but not 
InheritableThreadLocals.

Rather than making Thread even more baroque, perhaps a better way around 
the problem would be to have a system thread responsible for creating 
other system threads. Likewise containers should not spawn their own 
threads from a thread accessible to user code.

Tom Hawtin


