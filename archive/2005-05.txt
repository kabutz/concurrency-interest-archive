From gergg at cox.net  Mon May  2 11:26:53 2005
From: gergg at cox.net (Gregg Wonderly)
Date: Mon May  2 11:27:13 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <20050430172552.19217.qmail@home19.riedel.org>
References: <20050430172552.19217.qmail@home19.riedel.org>
Message-ID: <427646BD.9010808@cox.net>

Larry Riedel wrote:
> It seems to me plainly reasonable to ask to be able
> to iterate through all the ThreadLocals associated
> with a particular Thread, as well as to be able to
> clear each one found via iteration, regardless of
> whether there is a provided method which promises
> to clear all the ThreadLocals, or whether clearing
> them would (not) put the Thread in a pristine state.

This creates a security hole in applications that host multiple remotely 
downloaded codebases which utilize threadlocal data for security 
information such as password/key caching etc.  Open it up for general 
inspection and any thread from another codebase has access to stuff 
inside of another codebases security context.

I don't use threadlocals myself because it is just as easy to use a
Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
control access to and manage clearing etc on my own.

Gregg Wonderly
From tim at peierls.net  Mon May  2 11:41:56 2005
From: tim at peierls.net (Tim Peierls)
Date: Mon May  2 11:42:05 2005
Subject: [concurrency-interest] proposal for AES and STPE (long)
Message-ID: <42764A44.8080902@peierls.net>

C-I folks:

Can anyone see any problem with the following proposal? Do you see any way 
that it could break existing code? Can you think of an easier way to 
achieve the same effect?

-----

The use of FutureTask is hardwired into the submit, invokeAll, and
invokeAny methods of AbstractExecutorService, so if you want your
ExecutorService to use a custom Runnable and Future implementation other
than FutureTask, you end up having to implement the ExecutorService 
interface directly rather than extend AES.

When would you want to use a custom runnable future? Some examples:

- To identify the Runnable or Callable associated with a Future (without 
having to maintain the relationship externally).

- To detect if a submitted Runnable is already a Future, avoiding further 
wrapping.

- To add the ability to reprioritize tasks when the input queue is a 
PriorityBlockingQueue.

These are all things I've wanted to do at one time or another.


Here's a proposal to add this capability:

- Add interface j.u.c.RunnableFuture<V> implementing Runnable and Future<V>.

- Change FutureTask<V> to implement RunnableFuture<V>.

- Add to AES: protected methods
     newTaskFor(Runnable r, V v) and
     newTaskFor(Callable c),
both returning RunnableFuture<V> and implemented to return new 
FutureTask<V>(r, v) or new FutureTask<V>(c).

- Change AES submit, invokeAll, and invokeAny methods to use newTaskFor and 
RunnableFuture<V> wherever they currently have new FutureTask<V>(...) and 
FutureTask<V>.

Now if you want to provide a custom RunnableFuture, just override the 
newTaskFor methods. If you don't override them, you get the current 
behavior: FutureTask.

For example:

   public class MyCustomRunnableFuture<V> implements RunnableFuture<V> {...}

   public class MyThreadPool extends ThreadPoolExecutor {
       <V> protected RunnableFuture<V> newTaskFor(Callable<V> c) {
           return new MyCustomRunnableFuture<V>(c);
       }
       ...
   }

   ExecutorService myPool = new MyThreadPool(...);
   ...
   Future<String> f = myPool.submit(new Callable<String>() {...});
   assert f instanceof MyCustomRunnableFuture;


It would also be nice to do the same thing for scheduled tasks, but the 
situation is different; there is no AbstractScheduledExecutorService and no 
public ScheduledFutureTask<V>. Instead the following changes would allow 
one to "decorate" the internally generated runnable ScheduledFuture by 
wrapping it with another:

- Add interface j.u.c.RunnableScheduledFuture<V> implementing Runnable and 
ScheduledFuture<V>.

- Change private STPE.ScheduledFutureTask<V> to implement 
RunnableScheduledFuture<V>.

- Add to STPE: protected methods
     decorateTask(Runnable r, RunnableScheduledFuture<V> task) and
     decorateTask(Callable<V> c, RunnableScheduledFuture<V> task),
both returning RunnableScheduledFuture<V> and implemented to return their 
second arguments directly.

- Change STPE.scheduleXXX methods to wrap calls to new ScheduledFutureTask 
with decorateTask, passing the original Runnable or Callable as the first 
argument, and use the RunnableScheduleFuture type instead of 
ScheduledFutureTask where needed.

Now to decorate a RunnableScheduledFuture<V> with your own, override the 
decorateTask methods to do something other than return their second 
arguments directly -- probably by creating a delegating wrapper around the 
second argument that keeps a reference to the original Runnable or Callable.

For example:

   public class MyScheduleTask<V> implements RunnableScheduledFuture<V> {
     ...
   }

   public class MyScheduledThreadPool extends ScheduledThreadPoolExecutor {
       <V> protected RunnableScheduledFuture<V> decorateTask(
           Runnable r, RunnableScheduledFuture<V> rsf) {

           return new MyScheduledTask<V>(r, rsf);
       }
       ...
   }

   ScheduledExecutorService mySkd = new MyScheduledThreadPool(...);
   ScheduledFuture<String> f = mySkd.schedule(2, MINUTES, runnableTask);
   assert f instanceof MyScheduledTask;

-----

--tim

From unmesh_joshi at hotmail.com  Mon May  2 20:59:47 2005
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Mon May  2 20:59:56 2005
Subject: [concurrency-interest] How seriously should we take broken double
	checked idiom
In-Reply-To: <200504301600.j3UG03n2021088@altair.cs.oswego.edu>
Message-ID: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>

hi,

Double checked idiom is not guaranteed to work in Java. How seriously should 
we take it? In my current project, there are lot of stateless service 
classes, which are designed to be singletons. My tech lead says, "We have to 
use double checked idiom, even if it is not guaranteed to work. It will work 
most of the times and not many concurrent users are going to access the 
system".
What I understand as broken with the idiom is.
1. Our of order writes can write reference to the singleton instance field 
before calling constructor.
2. "Constructor" in java does following.
    1. It sets up object layout with TypeIno pointer.
    2. Sets up HashCode field in object layout.
    3. Sets up Lock related structures in object.
    4. Sets up and Initializes instance fields (which can be ignored in my 
case, as objects are stateless)

Constructor not being called, means none of the above takes place. If any 
other thread thinks object as constructed and tries to call any method on 
the object can show unpredictable behaviour.

Is my understanding right?

Thanks,
Unmesh

_________________________________________________________________
Bought a New Cellphone? 
http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-265?ck=Register Sell your 
old one for a Great Price in eBay!

From jmanson at cs.purdue.edu  Mon May  2 21:21:26 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Mon May  2 21:21:37 2005
Subject: [concurrency-interest] How seriously should we take broken double
	checked idiom
In-Reply-To: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
References: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
Message-ID: <4276D216.2030002@cs.purdue.edu>

Unmesh joshi wrote:

> Is my understanding right?
> 

This is, in fact, one of the things that can happen when double-checked 
initialization is not written correctly.  For a full discussion, consult 
this web page:

http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html

The fix is pretty easy, so you may want to implement it anyway.  If you 
have this:

class Foo {
   private Helper helper = null;
   public Helper getHelper() {
     if (helper == null)
       synchronized(this) {
         if (helper == null)
           helper = new Helper();
       }
     return helper;
     }
}

All you have to do in Java 5.0 and later is declare helper as 
"volatile", and the problem is fixed.

If you are stuck with an earlier version of Java, (or even if you 
aren't) strongly consider using the Initialization On Demand Holder Idiom:

private static class LazySomethingHolder {
   public static Something something = new Something();
}

public static Something getInstance() {
   return LazySomethingHolder.something;
}

It has the virtue of being simple, clean and having good performance.

					Jeremy
From dholmes at dltech.com.au  Mon May  2 21:44:01 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Mon May  2 21:44:15 2005
Subject: [concurrency-interest] How seriously should we take broken
	doublechecked idiom
In-Reply-To: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJJFKAA.dholmes@dltech.com.au>

Unmesh,

It may be that in this particular case no harm may befall the users of your
singletons. But why take the chance and promote a generally unsafe
programming practice? Who is going to take responsibility for saying "this
will be fine in our case" ?

Double-checked locking *does* work in Java 5.0 if the field is volatile.

But in your case why are you bothering with double-checked locking anyway?
Your classes are statess singletons so just use a normal static
initialization pattern:

  class Service {
    private static final Service theInstance = new Service();

    public static Service instance() { return theInstance; }

    ...
  }

There are no synchronization issues here at all - class loading and
initialization takes care of it. Plus class-initialization only occurs on
active use, and presumably the only active use of your class is to get the
singleton and use it. Hence there should not be any issue about over-eager
construction of the singletons. (There's a holder pattern for cases where
the "main " class is used in different ways and you need to avoid
unnecessary construction of the singleton.)

David Holmes
> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu
> [mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of Unmesh
> joshi
> Sent: Tuesday, 3 May 2005 11:00 AM
> To: concurrency-interest@altair.cs.oswego.edu
> Subject: [concurrency-interest] How seriously should we take broken
> doublechecked idiom
>
>
> hi,
>
> Double checked idiom is not guaranteed to work in Java. How
> seriously should
> we take it? In my current project, there are lot of stateless service
> classes, which are designed to be singletons. My tech lead says,
> "We have to
> use double checked idiom, even if it is not guaranteed to work.
> It will work
> most of the times and not many concurrent users are going to access the
> system".
> What I understand as broken with the idiom is.
> 1. Our of order writes can write reference to the singleton
> instance field
> before calling constructor.
> 2. "Constructor" in java does following.
>     1. It sets up object layout with TypeIno pointer.
>     2. Sets up HashCode field in object layout.
>     3. Sets up Lock related structures in object.
>     4. Sets up and Initializes instance fields (which can be
> ignored in my
> case, as objects are stateless)
>
> Constructor not being called, means none of the above takes place. If any
> other thread thinks object as constructed and tries to call any method on
> the object can show unpredictable behaviour.
>
> Is my understanding right?
>
> Thanks,
> Unmesh
>
> _________________________________________________________________
> Bought a New Cellphone?
> http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-265?ck=Register
>  Sell your
> old one for a Great Price in eBay!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From brian at quiotix.com  Mon May  2 23:30:03 2005
From: brian at quiotix.com (Brian Goetz)
Date: Mon May  2 23:30:15 2005
Subject: [concurrency-interest] How seriously should we take broken double
	checked idiom
In-Reply-To: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
References: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
Message-ID: <4276F03B.6050307@quiotix.com>

> Double checked idiom is not guaranteed to work in Java. How seriously 
> should we take it? 

Your program is broken.  Is that serious?

> In my current project, there are lot of stateless 
> service classes, which are designed to be singletons. My tech lead says, 
> "We have to use double checked idiom, even if it is not guaranteed to 
> work. It will work most of the times and not many concurrent users are 
> going to access the system".

Oh my god.  Are you serious?

If this is really the totality of his thoughts on the subject, then your 
tech lead really ought to be fired.  This is wrong on more than three 
levels, but I'll restrict myself to the three I'm sure about:

  - Error: lazy initialization is necessary.  This is very often false. 
  While it _may_ be true in your case, his questionable logic in the 
other two points casts considerable doubt on this.

  - Error: double checked locking is the only way to achieve lazy 
initialization.  Dead wrong.  The "Initialization On Demand Holder 
Idiom" (see Jeremy's response, or Effective Java #48.) This idiom beats 
DCL on all fronts -- simplicity, performance, and correctness.

  - Error: It is good enough for a production program to work "most of 
the time" or "as long as there are not too many users."

I might go so far as to say that if your quote is accurate, I would be 
disinclined to believe anything this person says.


Your characterization of the problem is correct -- basically, a thread 
can observe an object to be incompletely constructed, which could cause 
any number of problems -- null pointer exception or similar exception 
being the best possible outcome (because at least then you would find 
out you had a problem.)

As Jeremy points out, DCL instances can be "fixed" by making the 
instance field volatile, _IF_ you are on JDK 5.0 or later.

From pugh at cs.umd.edu  Tue May  3 11:42:45 2005
From: pugh at cs.umd.edu (Bill Pugh)
Date: Tue May  3 11:43:55 2005
Subject: [concurrency-interest] How seriously should we take broken double
	checked idiom
In-Reply-To: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
References: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
Message-ID: <CFA1BED2-15D3-49E4-A9B1-DF565F30F8B3@cs.umd.edu>

Please tell me what project you work on so I can avoid it, or what  
company you work for so I can short your stock.

Like others, I am appalled at your tech lead's attitude towards  
software reliability.

There is essentially no cost to performing thread-safe lazy  
initialization in a correct way, and several
possible correct ways to accomplish it.

If it really is that case that your objects have no instance fields  
at all, they you can get away with the non-thread-safe form
of double checked locking. But that is very much a corner case, and  
would break if you ever added fields to those objects.
Also, if the objects truely have no state, I can't see that you are  
saving much of anything by initializing them in a lazy fashion.

     Bill Pugh

On May 2, 2005, at 8:59 PM, Unmesh joshi wrote:

> hi,
>
> Double checked idiom is not guaranteed to work in Java. How  
> seriously should we take it? In my current project, there are lot  
> of stateless service classes, which are designed to be singletons.  
> My tech lead says, "We have to use double checked idiom, even if it  
> is not guaranteed to work. It will work most of the times and not  
> many concurrent users are going to access the system".
> What I understand as broken with the idiom is.
> 1. Our of order writes can write reference to the singleton  
> instance field before calling constructor.
> 2. "Constructor" in java does following.
>    1. It sets up object layout with TypeIno pointer.
>    2. Sets up HashCode field in object layout.
>    3. Sets up Lock related structures in object.
>    4. Sets up and Initializes instance fields (which can be ignored  
> in my case, as objects are stateless)
>
> Constructor not being called, means none of the above takes place.  
> If any other thread thinks object as constructed and tries to call  
> any method on the object can show unpredictable behaviour.
>
> Is my understanding right?
>
> Thanks,
> Unmesh
>
> _________________________________________________________________
> Bought a New Cellphone? http://adfarm.mediaplex.com/ad/ck/ 
> 4686-26272-10936-265?ck=Register Sell your old one for a Great  
> Price in eBay!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dawidk at mathcs.emory.edu  Tue May  3 14:45:47 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Tue May  3 14:46:07 2005
Subject: [concurrency-interest] How seriously should we take broken
	doublechecked idiom
In-Reply-To: <CFA1BED2-15D3-49E4-A9B1-DF565F30F8B3@cs.umd.edu>
References: <BAY21-F192F3428D44BD3910CEEF4EF180@phx.gbl>
	<CFA1BED2-15D3-49E4-A9B1-DF565F30F8B3@cs.umd.edu>
Message-ID: <4277C6DB.8060202@mathcs.emory.edu>

Bill Pugh wrote:

> Please tell me what project you work on so I can avoid it, or what  
> company you work for so I can short your stock.
>
> Like others, I am appalled at your tech lead's attitude towards  
> software reliability.
>
> There is essentially no cost to performing thread-safe lazy  
> initialization in a correct way, and several
> possible correct ways to accomplish it.
>
Not trying to argue with what you guys say and suggest as alternatives, 
I think you might be a bit too harsh in reacting to the question. After 
all, "double checked locking" idiom was once blessed and recommended, 
and, correct me if I am wrong, but I think I have seen several uses of 
it in core Java classes. It will take time and patience to educate 
people that it is not correct; also, I can understand that people may 
count that the idiom will work on SUN JVMs even though not guaranteed by 
the spec, just because SUN once was using it in its own code. Even 
though this expectation may be unjustified, especially on SMP machines, 
still - educating (and especially un-educating) people always takes time 
and patience. Also, after all, the fact that this question was asked on 
this forum suggests that the company might actually be quite sane :)

Just my 2c,
Regards,
Dawid Kurzyniec

From sergemasse1 at yahoo.com  Tue May  3 16:13:36 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Tue May  3 16:13:48 2005
Subject: [concurrency-interest] How seriously should we take broken
	doublechecked idiom
In-Reply-To: 6667
Message-ID: <20050503201336.44076.qmail@web51404.mail.yahoo.com>

I agree with Dawid. 

Finally a person on this thread with .edu in his
address who appears to be average iq or above.

serge

--- Dawid Kurzyniec <dawidk@mathcs.emory.edu> wrote:
> Bill Pugh wrote:
> 
> > Please tell me what project you work on so I can
> avoid it, or what  
> > company you work for so I can short your stock.
> >
> > Like others, I am appalled at your tech lead's
> attitude towards  
> > software reliability.
> >
> > There is essentially no cost to performing
> thread-safe lazy  
> > initialization in a correct way, and several
> > possible correct ways to accomplish it.
> >
> Not trying to argue with what you guys say and
> suggest as alternatives, 
> I think you might be a bit too harsh in reacting to
> the question. After 
> all, "double checked locking" idiom was once blessed
> and recommended, 
> and, correct me if I am wrong, but I think I have
> seen several uses of 
> it in core Java classes. It will take time and
> patience to educate 
> people that it is not correct; also, I can
> understand that people may 
> count that the idiom will work on SUN JVMs even
> though not guaranteed by 
> the spec, just because SUN once was using it in its
> own code. Even 
> though this expectation may be unjustified,
> especially on SMP machines, 
> still - educating (and especially un-educating)
> people always takes time 
> and patience. Also, after all, the fact that this
> question was asked on 
> this forum suggests that the company might actually
> be quite sane :)
> 
> Just my 2c,
> Regards,
> Dawid Kurzyniec
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
>
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
From dawidk at mathcs.emory.edu  Tue May  3 16:30:24 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Tue May  3 16:30:47 2005
Subject: [concurrency-interest] How seriously should we take
	brokendoublechecked idiom
In-Reply-To: <20050503201336.44076.qmail@web51404.mail.yahoo.com>
References: <20050503201336.44076.qmail@web51404.mail.yahoo.com>
Message-ID: <4277DF60.9070105@mathcs.emory.edu>

serge masse wrote:

>I agree with Dawid. 
>
>Finally a person on this thread with .edu in his
>address who appears to be average iq or above.
>
>  
>
Oops... I hope you know that people who answered before me on this 
thread are probably the most qualified in the world to address this sort 
of questions, and I wouldn't doubt their IQ:

http://www.cs.umd.edu/~pugh/java/
http://www.briangoetz.com/pubs.html
http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html

Regards,
Dawid Kurzyniec

From dawidk at mathcs.emory.edu  Tue May  3 16:41:05 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Tue May  3 16:41:22 2005
Subject: [concurrency-interest] How seriously should we
	takebrokendoublechecked idiom
In-Reply-To: <4277DF60.9070105@mathcs.emory.edu>
References: <20050503201336.44076.qmail@web51404.mail.yahoo.com>
	<4277DF60.9070105@mathcs.emory.edu>
Message-ID: <4277E1E1.4040208@mathcs.emory.edu>

Dawid Kurzyniec wrote:

> serge masse wrote:
>
>> I agree with Dawid.
>> Finally a person on this thread with .edu in his
>> address who appears to be average iq or above.
>>
>>  
>>
> Oops... I hope you know that people who answered before me on this 
> thread are probably the most qualified in the world to address this 
> sort of questions, and I wouldn't doubt their IQ:
>
> http://www.cs.umd.edu/~pugh/java/
> http://www.briangoetz.com/pubs.html
> http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html
>
I forgot one more :)

http://www.cs.umd.edu/users/jmanson/java/thesis.pdf

Regards,
Dawid

From sergemasse1 at yahoo.com  Tue May  3 16:46:26 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Tue May  3 16:46:34 2005
Subject: [concurrency-interest] How seriously should we
	takebrokendoublechecked idiom
In-Reply-To: 6667
Message-ID: <20050503204626.3452.qmail@web51405.mail.yahoo.com>

Thanks Dawid,
I was not aware of this thesis. Will read it, or try
to. I downloaded it.

serge

--- Dawid Kurzyniec <dawidk@mathcs.emory.edu> wrote:
> Dawid Kurzyniec wrote:
> 
> > serge masse wrote:
> >
> >> I agree with Dawid.
> >> Finally a person on this thread with .edu in his
> >> address who appears to be average iq or above.
> >>
> >>  
> >>
> > Oops... I hope you know that people who answered
> before me on this 
> > thread are probably the most qualified in the
> world to address this 
> > sort of questions, and I wouldn't doubt their IQ:
> >
> > http://www.cs.umd.edu/~pugh/java/
> > http://www.briangoetz.com/pubs.html
> >
>
http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html
> >
> I forgot one more :)
> 
> http://www.cs.umd.edu/users/jmanson/java/thesis.pdf
> 
> Regards,
> Dawid
> 
> 
From jmanson at cs.purdue.edu  Tue May  3 17:18:51 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Tue May  3 17:19:05 2005
Subject: [concurrency-interest] How seriously should
	we	takebrokendoublechecked idiom
In-Reply-To: <20050503204626.3452.qmail@web51405.mail.yahoo.com>
References: <20050503204626.3452.qmail@web51405.mail.yahoo.com>
Message-ID: <4277EABB.6080108@cs.purdue.edu>

serge masse wrote:
> Thanks Dawid,
> I was not aware of this thesis. Will read it, or try
> to. I downloaded it.
> 
> serge
> 

Well, I suppose that at this point, I might as well chime in with a 
reading list.  I'm pretty sure that although these things have been 
announced on this list, there has never been a roundup.

Depending on your level of interest in the memory model (and depending 
on your level of expertise), you may be better off starting with one of 
Brian's articles:

http://www-106.ibm.com/developerworks/java/library/j-jtp02244.html
http://www-106.ibm.com/developerworks/java/library/j-jtp03304/

Or the FAQ that he and I wrote:

http://www.cs.umd.edu/users/pugh/java/memoryModel/jsr-133-faq.html

For a more technical / academic version of this stuff, the paper that 
Bill, Sarita Adve and I wrote for this year's POPL might be a good bet.

http://www.cs.umd.edu/~jmanson/java/popl05.pdf

JSR-133 itself is also a good place to go:

http://www.jcp.org/en/jsr/detail?id=133

Mind you, I'm not trying to dissuade anyone from reading my 
dissertation.  I think (with no modesty whatsoever) I did a pretty good 
job of laying out the issues.  It is the only place to go (currently) 
for a full explanation of all our decisions.  But it may be more than a 
lot of people want to plow through.

					Jeremy
From sergemasse1 at yahoo.com  Tue May  3 18:36:15 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Tue May  3 18:36:23 2005
Subject: [concurrency-interest] Java 5 memory model - a nice lit roundup
	from Jeremy
In-Reply-To: 6667
Message-ID: <20050503223616.34818.qmail@web51409.mail.yahoo.com>

Great literature round up Jeremy. Thanks.

As for your dissertation being *more than a 
lot of people want to plow through*, I had a quick
look and it looks like the prose is as easy to read as
a novel (maybe a Le Carre) compared to the
specifications, which I read last year. So I do
recommend it highly for any serious Java dev.

serge

--- Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> serge masse wrote:
> > Thanks Dawid,
> > I was not aware of this thesis. Will read it, or
> try
> > to. I downloaded it.
> > 
> > serge
> > 
> 
> Well, I suppose that at this point, I might as well
> chime in with a 
> reading list.  I'm pretty sure that although these
> things have been 
> announced on this list, there has never been a
> roundup.
> 
> Depending on your level of interest in the memory
> model (and depending 
> on your level of expertise), you may be better off
> starting with one of 
> Brian's articles:
> 
>
http://www-106.ibm.com/developerworks/java/library/j-jtp02244.html
>
http://www-106.ibm.com/developerworks/java/library/j-jtp03304/
> 
> Or the FAQ that he and I wrote:
> 
>
http://www.cs.umd.edu/users/pugh/java/memoryModel/jsr-133-faq.html
> 
> For a more technical / academic version of this
> stuff, the paper that 
> Bill, Sarita Adve and I wrote for this year's POPL
> might be a good bet.
> 
> http://www.cs.umd.edu/~jmanson/java/popl05.pdf
> 
> JSR-133 itself is also a good place to go:
> 
> http://www.jcp.org/en/jsr/detail?id=133
> 
> Mind you, I'm not trying to dissuade anyone from
> reading my 
> dissertation.  I think (with no modesty whatsoever)
> I did a pretty good 
> job of laying out the issues.  It is the only place
> to go (currently) 
> for a full explanation of all our decisions.  But it
> may be more than a 
> lot of people want to plow through.
> 
> 					Jeremy
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
>
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
From hans.boehm at hp.com  Tue May  3 17:27:38 2005
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue May  3 18:41:44 2005
Subject: [concurrency-interest] How seriously should we take
	brokendoublechecked idiom
Message-ID: <65953E8166311641A685BDF71D8658262B6F12@cacexc12.americas.cpqcorp.net>

A lot of my concern in ignoring such correctness issues
would be that once you go down that road at all, you
no longer know whether a given failure is expected or not,
making it much harder to diagnose even the unrelated ones.
When you see a highly intermittent failure, it's hard enough
to try to reason backwards about what might have caused it,
without also considering the impact of intentional
"low probability" bugs.

It's much harder to reason about failure "probabilities"
than to argue that something is correct.  Especially when
these aren't real probabilities.  Something that fails 1
in a zillion times now during testing, may fail every other
time next time somebody releases a new OS kernel with a
different thread scheduler, or when someone releases a
new machine with different timing characteristics.

You really don't want to go there intentionally.
Concurrent systems tend to have more than enough of these
problems without intentionally adding more.  Especially
when it's cheap to avoid.

Once you stop aiming for 100% correctness, things get very
complicated.

As you suggest, on hardware with weak memory ordering, there
is no practical way for a JVM to ensure that double-checked
locking works without the volatile declaration.  VMs
will not support it for backward compatibility because they
can't, at least not on platforms like PowerPC or Itanium.  

Hans

> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu 
> [mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf 
> Of Dawid Kurzyniec
> Sent: Tuesday, May 03, 2005 11:46 AM
> Cc: concurrency-interest@altair.cs.oswego.edu
> Subject: Re: [concurrency-interest] How seriously should we 
> take brokendoublechecked idiom
> 
> 
> Bill Pugh wrote:
> 
> > Please tell me what project you work on so I can avoid it, or what
> > company you work for so I can short your stock.
> >
> > Like others, I am appalled at your tech lead's attitude towards
> > software reliability.
> >
> > There is essentially no cost to performing thread-safe lazy
> > initialization in a correct way, and several
> > possible correct ways to accomplish it.
> >
> Not trying to argue with what you guys say and suggest as 
> alternatives, 
> I think you might be a bit too harsh in reacting to the 
> question. After 
> all, "double checked locking" idiom was once blessed and recommended, 
> and, correct me if I am wrong, but I think I have seen 
> several uses of 
> it in core Java classes. It will take time and patience to educate 
> people that it is not correct; also, I can understand that people may 
> count that the idiom will work on SUN JVMs even though not 
> guaranteed by 
> the spec, just because SUN once was using it in its own code. Even 
> though this expectation may be unjustified, especially on SMP 
> machines, 
> still - educating (and especially un-educating) people always 
> takes time 
> and patience. Also, after all, the fact that this question 
> was asked on 
> this forum suggests that the company might actually be quite sane :)
> 
> Just my 2c,
> Regards,
> Dawid Kurzyniec
> 
> _______________________________________________
> Concurrency-interest mailing list 
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From dawidk at mathcs.emory.edu  Wed May  4 01:09:28 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed May  4 01:09:45 2005
Subject: [concurrency-interest] How seriously should we
	takebrokendoublechecked idiom
In-Reply-To: <65953E8166311641A685BDF71D8658262B6F12@cacexc12.americas.cpqcorp.net>
References: <65953E8166311641A685BDF71D8658262B6F12@cacexc12.americas.cpqcorp.net>
Message-ID: <42785908.3050404@mathcs.emory.edu>

Boehm, Hans wrote:

>A lot of my concern in ignoring such correctness issues (...)
>  
>
Just to clarify: I never meant to imply that it is OK to use DCL. In 
postings preceding mine, and in yours, it was clearly demonstrated that 
there is no technical reason to use it. I only commented the form, not 
the technical merit.

Cheers,
Dawid


From osvaldo at visionnaire.com.br  Wed May  4 07:30:46 2005
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Wed May  4 07:50:32 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <427646BD.9010808@cox.net>
References: <20050430172552.19217.qmail@home19.riedel.org>
	<427646BD.9010808@cox.net>
Message-ID: <4278B266.3050405@visionnaire.com.br>

Hi,

Gregg Wonderly wrote:
> Larry Riedel wrote:
> I don't use threadlocals myself because it is just as easy to use a
> Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
> control access to and manage clearing etc on my own.

Humm... I always assumed that ThreadLocal is more efficient and it
should play better with thread deaths.  I see in the source that it's
indeed highly customized an optimized, using its own implementation of
Map, private variables from Thread etc.  Not to mention quoting Donald
Knuth's algorithms, so I feel better using it ;)

A+
Osvaldo

-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo@visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

From mike.skells at ebizz-consulting.com  Wed May  4 15:19:18 2005
From: mike.skells at ebizz-consulting.com (Mike Skells)
Date: Wed May  4 15:19:33 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <4278B266.3050405@visionnaire.com.br>
Message-ID: <!~!AAAAAOA01SqLMP9LnkmIo2Z58BvEeioA@ebizz-consulting.com>



> Larry Riedel wrote:
> I don't use threadlocals myself because it is just as easy to use a
> Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
> control access to and manage clearing etc on my own.

[Mike Skells] 
Interesting to know how you manage the cleanup, as you now have a strong
reference to a Thread in you HashMap, so the Thread cannot be GC until every
one of your explicit cleanups completes

Also all of the ThreadLocals that are created in that thread are not GCed
either (fixed in JDK1.5).

If this is run in an environment that manages Threads (outside you control)
such as an appserver then the cleanup is complicated further.  

Looks to me as if you have created your own personal memory leak!

----

BTW
Should the ThreadLocals be cleared from the Thread when the Thread completes
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 1906 bytes
Desc: not available
Url : /pipermail/attachments/20050504/47267b18/winmail.bin
From dawidk at mathcs.emory.edu  Wed May  4 18:03:58 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed May  4 18:04:10 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <!~!AAAAAOA01SqLMP9LnkmIo2Z58BvEeioA@ebizz-consulting.com>
References: <!~!AAAAAOA01SqLMP9LnkmIo2Z58BvEeioA@ebizz-consulting.com>
Message-ID: <427946CE.8040103@mathcs.emory.edu>

Mike Skells wrote:

>  
>
>>I don't use threadlocals myself because it is just as easy to use a
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.
>>    
>>
>
>[Mike Skells] 
>Interesting to know how you manage the cleanup, as you now have a strong
>reference to a Thread in you HashMap, so the Thread cannot be GC until every
>one of your explicit cleanups completes
>
>  
>
I guess WeakHashMap should do the trick.

There exists an alternative that actually uses thread locals, with 
support for delegating them to worker threads. See 
http://www.mathcs.emory.edu/dcl/util/#concurrent, paragraph on 
delegatable thread locals.

The idea is that you can take immutable snapshot of the current thread's 
state, including delegatable thread locals (user-level subclass of 
InheritableThreadLocal), and later temporarily revert to that state, 
usually in other (worker) threads:

ThreadContext cxt = ThreadContext.getContext(); // takes current 
snapshot, including values of delegatable thread locals

...
// later, usually in a different thread
cxt.perform(Runnable);

during the execution of the runnable, the state (e.g. values of 
delegatable thread locals) of the thread in which "perform" was invoked 
is set to the snapshot represented by the cxt. After returning from 
"perform", state is fully restored to the original value.

This technique can be used in particular to run worker tasks in a 
"pristine" environment, as was postulated (by using "empty" snapshots) 
without violating encapsulation, without introducing race conditions, 
and without resorting to explicit "clear" operation on thread locals. 
Also, it can be used to propagate thread locals through executors from 
invoking thread to the worker thread - the executor needs basically to 
take thread snapshot on "execute" and use it during task execution. 
Alternatively, it can be used to achieve state persistency between tasks 
- all you need to do is to re-take the snapshot at the end of each task 
and hand it in to the next task.

Of course it does not work for ordinary ThreadLocals and 
InheritableThreadLocals - this can't be done without changing the JVM. 
To make your thread locals delegatable you need to explicitly use 
DelegatableThreadLocal class when you create them.

Regards,
Dawid


From donnie at haleonline.net  Wed May  4 18:46:25 2005
From: donnie at haleonline.net (Donnie Hale)
Date: Wed May  4 18:46:25 2005
Subject: [concurrency-interest] Please comment on this approach
In-Reply-To: <4277EABB.6080108@cs.purdue.edu>
Message-ID: <200505042246.j44MkLn0027041@altair.cs.oswego.edu>

I'll try to make this as brief as possible. I have an app where the main
thread will do all file I/O, generating some items that need processed. The
result of that processing will be some other items that will be posted to a
message queue using JMS (another somewhat I/O intensive operation). I want
those two processing stages to be handled each in their own dedicated thread
reading from a LinkedBlockingQueue. The reason for a dedicated thread to
handle queued items is due to the high overhead of creating the resources
needed to process the queued items (e.g. a JMS connection) - I don't want to
either recreate those every time or create lots of them for all the threads
in a pool. BTW, I'm using the backport library, as I must use JDK 1.4.

Below is a (hopefully :) reusable approach I've come up with. My main
questions are:

1) Am I missing something in the library that already does this?
2) If not, does my approach have any fundamental design or implementation
flaws?

// fairly obvious interface for handling items pulled from queue
public interface GenericThreadQueueHandler {
	void initialize(GenericThreadQueue q);
	void itemDequeued(Object o);
	void cleanup();
}

/**
 * The envisioned usage is in situations where long-lived, relatively high-
 * overhead, possibly thread-specific resources are required to process the
 * items as they are dequeued (e.g. a JMS connection). In those situations,
the
 * resources can't (or shouldn't) be recreated for every item that is
dequeued. 
 */
public abstract class GenericThreadQueue {

	public GenericThreadQueue(GenericThreadQueueHandler h) {
		queue_ = new LinkedBlockingQueue();
		handler_ = h;
	}
	
	public void start() {
		Runnable r = new GenericRunnable(this, handler_);
		thread_ = Executors.defaultThreadFactory().newThread(r);
		thread_.setDaemon(true);
		thread_.start();
	}
	
	public void stop() {
		thread_.interrupt();
		try {
			thread_.join();
		}
		catch (InterruptedException xcpt) {
			// do nothing
		}
	}
	
	private static class GenericRunnable implements Runnable {
		public GenericRunnable(GenericThreadQueue q,
GenericThreadQueueHandler h) {
			queue_ = q;
			handler_ = h;
		}
		
		public void run() {
			handler_.initialize(queue_);

			try {
				while (true) {
					
					// get next item from queue
					Object o;
					
					try {
						o = queue_.dequeue();
					}
					catch (InterruptedException xcpt) {
						// signal to end thread
						break;
					}
					
					// process item
					handler_.itemDequeued(o);
				}
			}
			finally {
				handler_.cleanup();
			}
		}
		
		GenericThreadQueue queue_;
		private GenericThreadQueueHandler handler_;
	}
	
	protected final void enqueue(Object o) throws InterruptedException {
		queue_.put(o);
	}
	
	protected final Object dequeue() throws InterruptedException {
		return queue_.take();
	}
	
	private LinkedBlockingQueue queue_;
	private Thread thread_;
	private GenericThreadQueueHandler handler_;
}

Thanks, and sorry for the length.

Donnie

From unmesh_joshi at hotmail.com  Wed May  4 19:14:04 2005
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed May  4 19:14:05 2005
Subject: [concurrency-interest] RE: Concurrency-interest Digest, Vol 4,
	Issue 4
Message-ID: <BAY21-F301618F0A22BAEA6880EDDEF190@phx.gbl>

Thank you for all your replies. With all these,  I guess, I will be able 
convince my tech lead.
I have a question though, about On Demand Holder Idiom. If the constructor 
of Singleton is throwing exception, we will not be able to use it?
public class Cache {


  private static class OnDemandHelher {
       static Cache instance = new Cache(); ///
  }

  private Cache() throws InitializationException {
    //load data...
  }

}

Thanks,
Unmesh

>From: concurrency-interest-request@cs.oswego.edu
>Reply-To: concurrency-interest@cs.oswego.edu
>To: concurrency-interest@altair.cs.oswego.edu
>Subject: Concurrency-interest Digest, Vol 4, Issue 4
>Date: Wed, 4 May 2005 07:52:49 -0400 (EDT)
>
>Send Concurrency-interest mailing list submissions to
>	concurrency-interest@altair.cs.oswego.edu
>
>To subscribe or unsubscribe via the World Wide Web, visit
>	http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>or, via email, send a message with subject or body 'help' to
>	concurrency-interest-request@altair.cs.oswego.edu
>
>You can reach the person managing the list at
>	concurrency-interest-owner@altair.cs.oswego.edu
>
>When replying, please edit your Subject line so it is more specific
>than "Re: Contents of Concurrency-interest digest..."
>
>
>Today's Topics:
>
>    1. Re: How seriously should we take broken	doublechecked idiom
>       (Dawid Kurzyniec)
>    2. Re: How seriously should we take broken	doublechecked idiom
>       (serge masse)
>    3. Re: How seriously should we take	brokendoublechecked idiom
>       (Dawid Kurzyniec)
>    4. Re: How seriously should we	takebrokendoublechecked idiom
>       (Dawid Kurzyniec)
>    5. Re: How seriously should we	takebrokendoublechecked idiom
>       (serge masse)
>    6. Re: How seriously should	we	takebrokendoublechecked idiom
>       (Jeremy Manson)
>    7. Java 5 memory model - a nice lit roundup	from Jeremy (serge masse)
>    8. RE: How seriously should we take	brokendoublechecked idiom
>       (Boehm, Hans)
>    9. Re: How seriously should we	takebrokendoublechecked idiom
>       (Dawid Kurzyniec)
>   10. Re: reusing threads and thread local state
>       (Osvaldo Pinali Doederlein)
>
>
>----------------------------------------------------------------------
>
>Message: 1
>Date: Tue, 03 May 2005 14:45:47 -0400
>From: Dawid Kurzyniec <dawidk@mathcs.emory.edu>
>Subject: Re: [concurrency-interest] How seriously should we take
>	broken	doublechecked idiom
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <4277C6DB.8060202@mathcs.emory.edu>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>Bill Pugh wrote:
>
> > Please tell me what project you work on so I can avoid it, or what
> > company you work for so I can short your stock.
> >
> > Like others, I am appalled at your tech lead's attitude towards
> > software reliability.
> >
> > There is essentially no cost to performing thread-safe lazy
> > initialization in a correct way, and several
> > possible correct ways to accomplish it.
> >
>Not trying to argue with what you guys say and suggest as alternatives,
>I think you might be a bit too harsh in reacting to the question. After
>all, "double checked locking" idiom was once blessed and recommended,
>and, correct me if I am wrong, but I think I have seen several uses of
>it in core Java classes. It will take time and patience to educate
>people that it is not correct; also, I can understand that people may
>count that the idiom will work on SUN JVMs even though not guaranteed by
>the spec, just because SUN once was using it in its own code. Even
>though this expectation may be unjustified, especially on SMP machines,
>still - educating (and especially un-educating) people always takes time
>and patience. Also, after all, the fact that this question was asked on
>this forum suggests that the company might actually be quite sane :)
>
>Just my 2c,
>Regards,
>Dawid Kurzyniec
>
>
>
>------------------------------
>
>Message: 2
>Date: Tue, 3 May 2005 13:13:36 -0700 (PDT)
>From: serge masse <sergemasse1@yahoo.com>
>Subject: Re: [concurrency-interest] How seriously should we take
>	broken	doublechecked idiom
>To: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <20050503201336.44076.qmail@web51404.mail.yahoo.com>
>Content-Type: text/plain; charset=us-ascii
>
>I agree with Dawid.
>
>Finally a person on this thread with .edu in his
>address who appears to be average iq or above.
>
>serge
>
>--- Dawid Kurzyniec <dawidk@mathcs.emory.edu> wrote:
> > Bill Pugh wrote:
> >
> > > Please tell me what project you work on so I can
> > avoid it, or what
> > > company you work for so I can short your stock.
> > >
> > > Like others, I am appalled at your tech lead's
> > attitude towards
> > > software reliability.
> > >
> > > There is essentially no cost to performing
> > thread-safe lazy
> > > initialization in a correct way, and several
> > > possible correct ways to accomplish it.
> > >
> > Not trying to argue with what you guys say and
> > suggest as alternatives,
> > I think you might be a bit too harsh in reacting to
> > the question. After
> > all, "double checked locking" idiom was once blessed
> > and recommended,
> > and, correct me if I am wrong, but I think I have
> > seen several uses of
> > it in core Java classes. It will take time and
> > patience to educate
> > people that it is not correct; also, I can
> > understand that people may
> > count that the idiom will work on SUN JVMs even
> > though not guaranteed by
> > the spec, just because SUN once was using it in its
> > own code. Even
> > though this expectation may be unjustified,
> > especially on SMP machines,
> > still - educating (and especially un-educating)
> > people always takes time
> > and patience. Also, after all, the fact that this
> > question was asked on
> > this forum suggests that the company might actually
> > be quite sane :)
> >
> > Just my 2c,
> > Regards,
> > Dawid Kurzyniec
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@altair.cs.oswego.edu
> >
>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>------------------------------
>
>Message: 3
>Date: Tue, 03 May 2005 16:30:24 -0400
>From: Dawid Kurzyniec <dawidk@mathcs.emory.edu>
>Subject: Re: [concurrency-interest] How seriously should we take
>	brokendoublechecked idiom
>To: serge masse <sergemasse1@yahoo.com>
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <4277DF60.9070105@mathcs.emory.edu>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>serge masse wrote:
>
> >I agree with Dawid.
> >
> >Finally a person on this thread with .edu in his
> >address who appears to be average iq or above.
> >
> >
> >
>Oops... I hope you know that people who answered before me on this
>thread are probably the most qualified in the world to address this sort
>of questions, and I wouldn't doubt their IQ:
>
>http://www.cs.umd.edu/~pugh/java/
>http://www.briangoetz.com/pubs.html
>http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html
>
>Regards,
>Dawid Kurzyniec
>
>
>
>------------------------------
>
>Message: 4
>Date: Tue, 03 May 2005 16:41:05 -0400
>From: Dawid Kurzyniec <dawidk@mathcs.emory.edu>
>Subject: Re: [concurrency-interest] How seriously should we
>	takebrokendoublechecked idiom
>To: serge masse <sergemasse1@yahoo.com>
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <4277E1E1.4040208@mathcs.emory.edu>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>Dawid Kurzyniec wrote:
>
> > serge masse wrote:
> >
> >> I agree with Dawid.
> >> Finally a person on this thread with .edu in his
> >> address who appears to be average iq or above.
> >>
> >>
> >>
> > Oops... I hope you know that people who answered before me on this
> > thread are probably the most qualified in the world to address this
> > sort of questions, and I wouldn't doubt their IQ:
> >
> > http://www.cs.umd.edu/~pugh/java/
> > http://www.briangoetz.com/pubs.html
> > http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html
> >
>I forgot one more :)
>
>http://www.cs.umd.edu/users/jmanson/java/thesis.pdf
>
>Regards,
>Dawid
>
>
>
>------------------------------
>
>Message: 5
>Date: Tue, 3 May 2005 13:46:26 -0700 (PDT)
>From: serge masse <sergemasse1@yahoo.com>
>Subject: Re: [concurrency-interest] How seriously should we
>	takebrokendoublechecked idiom
>To: Dawid Kurzyniec <dawidk@mathcs.emory.edu>
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <20050503204626.3452.qmail@web51405.mail.yahoo.com>
>Content-Type: text/plain; charset=us-ascii
>
>Thanks Dawid,
>I was not aware of this thesis. Will read it, or try
>to. I downloaded it.
>
>serge
>
>--- Dawid Kurzyniec <dawidk@mathcs.emory.edu> wrote:
> > Dawid Kurzyniec wrote:
> >
> > > serge masse wrote:
> > >
> > >> I agree with Dawid.
> > >> Finally a person on this thread with .edu in his
> > >> address who appears to be average iq or above.
> > >>
> > >>
> > >>
> > > Oops... I hope you know that people who answered
> > before me on this
> > > thread are probably the most qualified in the
> > world to address this
> > > sort of questions, and I wouldn't doubt their IQ:
> > >
> > > http://www.cs.umd.edu/~pugh/java/
> > > http://www.briangoetz.com/pubs.html
> > >
> >
>http://www.jaoo.org/jaoo2000/conference/speakers/holmes.html
> > >
> > I forgot one more :)
> >
> > http://www.cs.umd.edu/users/jmanson/java/thesis.pdf
> >
> > Regards,
> > Dawid
> >
> >
>
>
>------------------------------
>
>Message: 6
>Date: Tue, 03 May 2005 16:18:51 -0500
>From: Jeremy Manson <jmanson@cs.purdue.edu>
>Subject: Re: [concurrency-interest] How seriously should	we
>	takebrokendoublechecked idiom
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <4277EABB.6080108@cs.purdue.edu>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>serge masse wrote:
> > Thanks Dawid,
> > I was not aware of this thesis. Will read it, or try
> > to. I downloaded it.
> >
> > serge
> >
>
>Well, I suppose that at this point, I might as well chime in with a
>reading list.  I'm pretty sure that although these things have been
>announced on this list, there has never been a roundup.
>
>Depending on your level of interest in the memory model (and depending
>on your level of expertise), you may be better off starting with one of
>Brian's articles:
>
>http://www-106.ibm.com/developerworks/java/library/j-jtp02244.html
>http://www-106.ibm.com/developerworks/java/library/j-jtp03304/
>
>Or the FAQ that he and I wrote:
>
>http://www.cs.umd.edu/users/pugh/java/memoryModel/jsr-133-faq.html
>
>For a more technical / academic version of this stuff, the paper that
>Bill, Sarita Adve and I wrote for this year's POPL might be a good bet.
>
>http://www.cs.umd.edu/~jmanson/java/popl05.pdf
>
>JSR-133 itself is also a good place to go:
>
>http://www.jcp.org/en/jsr/detail?id=133
>
>Mind you, I'm not trying to dissuade anyone from reading my
>dissertation.  I think (with no modesty whatsoever) I did a pretty good
>job of laying out the issues.  It is the only place to go (currently)
>for a full explanation of all our decisions.  But it may be more than a
>lot of people want to plow through.
>
>					Jeremy
>
>
>------------------------------
>
>Message: 7
>Date: Tue, 3 May 2005 15:36:15 -0700 (PDT)
>From: serge masse <sergemasse1@yahoo.com>
>Subject: [concurrency-interest] Java 5 memory model - a nice lit
>	roundup	from Jeremy
>To: Jeremy Manson <jmanson@cs.purdue.edu>
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID: <20050503223616.34818.qmail@web51409.mail.yahoo.com>
>Content-Type: text/plain; charset=us-ascii
>
>Great literature round up Jeremy. Thanks.
>
>As for your dissertation being *more than a
>lot of people want to plow through*, I had a quick
>look and it looks like the prose is as easy to read as
>a novel (maybe a Le Carre) compared to the
>specifications, which I read last year. So I do
>recommend it highly for any serious Java dev.
>
>serge
>
>--- Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> > serge masse wrote:
> > > Thanks Dawid,
> > > I was not aware of this thesis. Will read it, or
> > try
> > > to. I downloaded it.
> > >
> > > serge
> > >
> >
> > Well, I suppose that at this point, I might as well
> > chime in with a
> > reading list.  I'm pretty sure that although these
> > things have been
> > announced on this list, there has never been a
> > roundup.
> >
> > Depending on your level of interest in the memory
> > model (and depending
> > on your level of expertise), you may be better off
> > starting with one of
> > Brian's articles:
> >
> >
>http://www-106.ibm.com/developerworks/java/library/j-jtp02244.html
> >
>http://www-106.ibm.com/developerworks/java/library/j-jtp03304/
> >
> > Or the FAQ that he and I wrote:
> >
> >
>http://www.cs.umd.edu/users/pugh/java/memoryModel/jsr-133-faq.html
> >
> > For a more technical / academic version of this
> > stuff, the paper that
> > Bill, Sarita Adve and I wrote for this year's POPL
> > might be a good bet.
> >
> > http://www.cs.umd.edu/~jmanson/java/popl05.pdf
> >
> > JSR-133 itself is also a good place to go:
> >
> > http://www.jcp.org/en/jsr/detail?id=133
> >
> > Mind you, I'm not trying to dissuade anyone from
> > reading my
> > dissertation.  I think (with no modesty whatsoever)
> > I did a pretty good
> > job of laying out the issues.  It is the only place
> > to go (currently)
> > for a full explanation of all our decisions.  But it
> > may be more than a
> > lot of people want to plow through.
> >
> > 					Jeremy
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@altair.cs.oswego.edu
> >
>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>------------------------------
>
>Message: 8
>Date: Tue, 3 May 2005 14:27:38 -0700
>From: "Boehm, Hans" <hans.boehm@hp.com>
>Subject: RE: [concurrency-interest] How seriously should we take
>	brokendoublechecked idiom
>To: "Dawid Kurzyniec" <dawidk@mathcs.emory.edu>
>Cc: concurrency-interest@altair.cs.oswego.edu
>Message-ID:
>	<65953E8166311641A685BDF71D8658262B6F12@cacexc12.americas.cpqcorp.net>
>Content-Type: text/plain;	charset="us-ascii"
>
>A lot of my concern in ignoring such correctness issues
>would be that once you go down that road at all, you
>no longer know whether a given failure is expected or not,
>making it much harder to diagnose even the unrelated ones.
>When you see a highly intermittent failure, it's hard enough
>to try to reason backwards about what might have caused it,
>without also considering the impact of intentional
>"low probability" bugs.
>
>It's much harder to reason about failure "probabilities"
>than to argue that something is correct.  Especially when
>these aren't real probabilities.  Something that fails 1
>in a zillion times now during testing, may fail every other
>time next time somebody releases a new OS kernel with a
>different thread scheduler, or when someone releases a
>new machine with different timing characteristics.
>
>You really don't want to go there intentionally.
>Concurrent systems tend to have more than enough of these
>problems without intentionally adding more.  Especially
>when it's cheap to avoid.
>
>Once you stop aiming for 100% correctness, things get very
>complicated.
>
>As you suggest, on hardware with weak memory ordering, there
>is no practical way for a JVM to ensure that double-checked
>locking works without the volatile declaration.  VMs
>will not support it for backward compatibility because they
>can't, at least not on platforms like PowerPC or Itanium.
>
>Hans
>
> > -----Original Message-----
> > From: concurrency-interest-bounces@cs.oswego.edu
> > [mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf
> > Of Dawid Kurzyniec
> > Sent: Tuesday, May 03, 2005 11:46 AM
> > Cc: concurrency-interest@altair.cs.oswego.edu
> > Subject: Re: [concurrency-interest] How seriously should we
> > take brokendoublechecked idiom
> >
> >
> > Bill Pugh wrote:
> >
> > > Please tell me what project you work on so I can avoid it, or what
> > > company you work for so I can short your stock.
> > >
> > > Like others, I am appalled at your tech lead's attitude towards
> > > software reliability.
> > >
> > > There is essentially no cost to performing thread-safe lazy
> > > initialization in a correct way, and several
> > > possible correct ways to accomplish it.
> > >
> > Not trying to argue with what you guys say and suggest as
> > alternatives,
> > I think you might be a bit too harsh in reacting to the
> > question. After
> > all, "double checked locking" idiom was once blessed and recommended,
> > and, correct me if I am wrong, but I think I have seen
> > several uses of
> > it in core Java classes. It will take time and patience to educate
> > people that it is not correct; also, I can understand that people may
> > count that the idiom will work on SUN JVMs even though not
> > guaranteed by
> > the spec, just because SUN once was using it in its own code. Even
> > though this expectation may be unjustified, especially on SMP
> > machines,
> > still - educating (and especially un-educating) people always
> > takes time
> > and patience. Also, after all, the fact that this question
> > was asked on
> > this forum suggests that the company might actually be quite sane :)
> >
> > Just my 2c,
> > Regards,
> > Dawid Kurzyniec
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest@altair.cs.oswego.edu
> > http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
>------------------------------
>
>Message: 9
>Date: Wed, 04 May 2005 01:09:28 -0400
>From: Dawid Kurzyniec <dawidk@mathcs.emory.edu>
>Subject: Re: [concurrency-interest] How seriously should we
>	takebrokendoublechecked idiom
>To: "Boehm, Hans" <hans.boehm@hp.com>,
>	concurrency-interest@altair.cs.oswego.edu
>Message-ID: <42785908.3050404@mathcs.emory.edu>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>Boehm, Hans wrote:
>
> >A lot of my concern in ignoring such correctness issues (...)
> >
> >
>Just to clarify: I never meant to imply that it is OK to use DCL. In
>postings preceding mine, and in yours, it was clearly demonstrated that
>there is no technical reason to use it. I only commented the form, not
>the technical merit.
>
>Cheers,
>Dawid
>
>
>
>
>------------------------------
>
>Message: 10
>Date: Wed, 04 May 2005 08:30:46 -0300
>From: Osvaldo Pinali Doederlein <osvaldo@visionnaire.com.br>
>Subject: Re: [concurrency-interest] reusing threads and thread local
>	state
>To: Gregg Wonderly <gergg@cox.net>
>Cc: larryr@saturn.sdsu.edu, Pete Soper <Pete.Soper@sun.com>,
>	concurrency-interest@altair.cs.oswego.edu
>Message-ID: <4278B266.3050405@visionnaire.com.br>
>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
>Hi,
>
>Gregg Wonderly wrote:
> > Larry Riedel wrote:
> > I don't use threadlocals myself because it is just as easy to use a
> > Hashtable<Thread,Hashtable<String,?>> via a static factory which I can
> > control access to and manage clearing etc on my own.
>
>Humm... I always assumed that ThreadLocal is more efficient and it
>should play better with thread deaths.  I see in the source that it's
>indeed highly customized an optimized, using its own implementation of
>Map, private variables from Thread etc.  Not to mention quoting Donald
>Knuth's algorithms, so I feel better using it ;)
>
>A+
>Osvaldo
>
>--
>-----------------------------------------------------------------------
>Osvaldo Pinali Doederlein                   Visionnaire Informtica S/A
>osvaldo@visionnaire.com.br                http://www.visionnaire.com.br
>Arquiteto de Tecnologia                          +55 (41) 337-1000 #223
>
>
>
>------------------------------
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest@altair.cs.oswego.edu
>http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>End of Concurrency-interest Digest, Vol 4, Issue 4
>**************************************************

_________________________________________________________________
Bought a New Cellphone? 
http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-265?ck=Register Sell your 
old one for a Great Price in eBay!

From dholmes at dltech.com.au  Wed May  4 19:36:32 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Wed May  4 19:36:41 2005
Subject: [concurrency-interest] RE: Concurrency-interest Digest, Vol 4,
	Issue 4
In-Reply-To: <BAY21-F301618F0A22BAEA6880EDDEF190@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCOELNFKAA.dholmes@dltech.com.au>

> Thank you for all your replies. With all these,  I guess, I will be able
> convince my tech lead.
> I have a question though, about On Demand Holder Idiom. If the
> constructor of Singleton is throwing exception, we will not be able to
> use it?
> public class Cache {
>
>
>   private static class OnDemandHelher {
>        static Cache instance = new Cache(); ///
>   }
>
>   private Cache() throws InitializationException {
>     //load data...
>   }
>
> }

Presuming that is a checked-exception, you would have to catch and convert
to an unchecked exception:

    private static class OnDemandHelper {
        static Cache instance;

        static {
           try {
               instance = new Cache();
           }
           catch (InitializationException e) {
              throw (RuntimeException) new RuntimeException().initCause(e);
           }
        }
    }

Or you could create your own subclass of RuntimeException to handle this
directly. Of course you would have to adapt the handling of the exception in
the client code.

You could also account for the exception in the helper another way:

    private static class OnDemandHelper {
        static Cache instance;
	 InitializationException exception;

        static {
           try {
               instance = new Cache();
           }
           catch (InitializationException e) {
              exception = e;
           }
        }

        static Cache instance() throws InitializationException {
           if (instance != null)
              return instance;
           throw exception;
        }
    }

This way client code still uses an instance() method that can throw, but
that method is no longer responsible for initialization.

Cheers,
David Holmes

From unmesh_joshi at hotmail.com  Wed May  4 20:07:12 2005
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Wed May  4 20:07:31 2005
Subject: [concurrency-interest] RE: Concurrency-interest Digest, Vol 4,
	Issue 4
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOELNFKAA.dholmes@dltech.com.au>
Message-ID: <BAY21-F150D9893F55F784B6DFD95EF1A0@phx.gbl>

Thanks a lot. I like the second approach more. I am going to implement it 
immidiately.

>From: "David Holmes" <dholmes@dltech.com.au>
>To: "Unmesh joshi" 
><unmesh_joshi@hotmail.com>,<concurrency-interest@altair.cs.oswego.edu>
>Subject: RE: [concurrency-interest] RE: Concurrency-interest Digest, Vol 
>4,Issue 4
>Date: Thu, 5 May 2005 09:36:32 +1000
>
> > Thank you for all your replies. With all these,  I guess, I will be able
> > convince my tech lead.
> > I have a question though, about On Demand Holder Idiom. If the
> > constructor of Singleton is throwing exception, we will not be able to
> > use it?
> > public class Cache {
> >
> >
> >   private static class OnDemandHelher {
> >        static Cache instance = new Cache(); ///
> >   }
> >
> >   private Cache() throws InitializationException {
> >     //load data...
> >   }
> >
> > }
>
>Presuming that is a checked-exception, you would have to catch and convert
>to an unchecked exception:
>
>     private static class OnDemandHelper {
>         static Cache instance;
>
>         static {
>            try {
>                instance = new Cache();
>            }
>            catch (InitializationException e) {
>               throw (RuntimeException) new 
>RuntimeException().initCause(e);
>            }
>         }
>     }
>
>Or you could create your own subclass of RuntimeException to handle this
>directly. Of course you would have to adapt the handling of the exception 
>in
>the client code.
>
>You could also account for the exception in the helper another way:
>
>     private static class OnDemandHelper {
>         static Cache instance;
>	 InitializationException exception;
>
>         static {
>            try {
>                instance = new Cache();
>            }
>            catch (InitializationException e) {
>               exception = e;
>            }
>         }
>
>         static Cache instance() throws InitializationException {
>            if (instance != null)
>               return instance;
>            throw exception;
>         }
>     }
>
>This way client code still uses an instance() method that can throw, but
>that method is no longer responsible for initialization.
>
>Cheers,
>David Holmes
>

_________________________________________________________________
NRIs open a savings a/c with just INR 10,000 
http://creative.mediaturf.net/creatives/icicibank/TOL210405.htm FREE money 
transfers.

From gregg at cytetech.com  Wed May  4 22:36:30 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed May  4 22:36:36 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <4278B266.3050405@visionnaire.com.br>
References: <20050430172552.19217.qmail@home19.riedel.org>	<427646BD.9010808@cox.net>
	<4278B266.3050405@visionnaire.com.br>
Message-ID: <427986AE.7040607@cytetech.com>

Osvaldo Pinali Doederlein wrote:
> Humm... I always assumed that ThreadLocal is more efficient and it
> should play better with thread deaths.  I see in the source that it's
> indeed highly customized an optimized, using its own implementation of
> Map, private variables from Thread etc.  Not to mention quoting Donald
> Knuth's algorithms, so I feel better using it ;)

The explicit interaction with Thread creates certain bindings which are 
part of what started this discussion.  Different applications will 
require different behaviors.  Supporting all needs in a single class is 
a hard bargain.  I think Josh is concervative about how extensible 
things should be.  I am torn between the view that ThreadLocal is way 
too focused on a particular application type to be in the jdk, and 
ThreadLocal is just one way to accomodate thread private data.

A different design would have been to use a wrapper around ThreadLocal 
that provided the controlling key.  The wrapper could use an Object key 
to identify the context.  Where ThreadLocal uses a Thread as the map 
key, you'd instead see keys.get(Thread) used.  Each time that you wanted 
to use ThreadLocals, you might do something like:

	Runnable r = ...;
	ThreadLocalContext c = new ThreadLocalContext ( r );
	c.start();

ThreadLocalContext would use a package private interface to ThreadLocal 
to do

	ThreadLocal.bindThread(this,key)

bindThread would do

	Object tkey = keys.remove( Thread.currentThread() );
	ValueMap map = new ValueMap();
	maps.put( key, map );
	c.setMap( map );
	keys.put( Thread.currentThread(), key );

Now you have access to ThreadContext in the creating context, and you'd 
have a path from ThreadContext to the ThreadLocal map for that 
ThreadContext.  There would be a direct object graph without a static 
reference or other exposure that would sacrifice the isolation portion 
of the implementation.  Just a thought...

Gregg Wonderly
From gregg at cytetech.com  Wed May  4 22:45:45 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed May  4 22:45:51 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <!~!AAAAAOA01SqLMP9LnkmIo2Z58BvEeioA@ebizz-consulting.com>
References: <!~!AAAAAOA01SqLMP9LnkmIo2Z58BvEeioA@ebizz-consulting.com>
Message-ID: <427988D9.1020001@cytetech.com>



Mike Skells wrote:

>>I don't use threadlocals myself because it is just as easy to use a
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.

This is my statement, not Larry's.

> Interesting to know how you manage the cleanup, as you now have a strong
> reference to a Thread in you HashMap, so the Thread cannot be GC until every
> one of your explicit cleanups completes

I use explicit thread management to handle this issue.  And also, I use 
an periodic thread that asks if the thread is still running and remove 
entries for any such threads.

> Also all of the ThreadLocals that are created in that thread are not GCed
> either (fixed in JDK1.5).
> 
> If this is run in an environment that manages Threads (outside you control)
> such as an appserver then the cleanup is complicated further.  

I don't use J2EE.  I just use J2SE and Jini for my enterprise 
applications.  Keeps me in control of the things that matter to me.

> Looks to me as if you have created your own personal memory leak!

Only if you don't understand all the issues and ways out.  There are a 
lot more "appliance programmers" who don't understand computer science, 
so these things will largely work for them.  But, these memory leak bugs 
are getting to be way to common (java.util.Timer cancelled tasks), so 
I've learned to just role my own rather than depending on bug free JDK 
code, which historically has not been available.

Gregg Wonderly
From donnie at haleonline.net  Wed May  4 22:50:36 2005
From: donnie at haleonline.net (Donnie Hale)
Date: Wed May  4 22:50:41 2005
Subject: [concurrency-interest] Please comment on this approach
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEMCFKAA.dholmes@dltech.com.au>
Message-ID: <200505050250.j452obn0001438@altair.cs.oswego.edu>

David,

Thanks for the comments. Follow-ups:

1. The docs for defaultThreadFactory and the ThreadFactory interface read as
though they are available general purpose usage. That's why I picked it.
I'll look into SingleThreadExecutor to see how that would alter what I've
put together.

2. Back in my native Win32 days, I'd use a sentinel Event and
WaitForMultipleObjects to be notified that I should fall out the bottom of a
thread. There's probably something like that in the concurrent API, but I'm
just getting familiar with it and have likely missed the "canonical" way to
do that, so to speak. Perhaps you can point me a little further in the right
direction.

Thanks again,

Donnie
 

-----Original Message-----
From: David Holmes [mailto:dholmes@dltech.com.au] 
Sent: Wednesday, May 04, 2005 9:11 PM
To: Donnie Hale
Cc: concurrency-jsr
Subject: RE: [concurrency-interest] Please comment on this approach

Your basic approach seems sound enough. Basically the main thread pushes the
objects to be processed into a LinkedBlockingQueue and you create a thread
that pulls them from the queue and processes them and pushes them out to
JMS.

If you intend to use this a lot then encapsulating the thread and queue
together makes good sense, but for one-off usage it isn't necessary to make
it so complicated.

Two minor points:

1.  thread_ = Executors.defaultThreadFactory().newThread(r);

The default thread factory wasn't intended for general purpose thread
construction outside of the pool. As this is your thread, that you control,
just construct it. It won't do any harm, but it is an odd usage in my view
and your thread will get an odd name. :)

That said, you might consider using a SingleThreadExecutor just in case you
want to crank up the concurrency at a later stage.

2. Rather than stopping the thread by interupting it, consider just putting
a sentinel object into the queue. You can clear the queue before inserting
the sentinel if you want to stop the current contents from being cleared. Of
course if you want to terminate the currently processing object then
interrupt is your only chance - assuming the processing code checks for
interrupts. The interrupt isn't wrong, I just prefer a sentinel for this
kind of situation, and interrupts always require you know how all the code
you will execute responds to interruption.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu
> [mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of Donnie 
> Hale
> Sent: Thursday, 5 May 2005 8:46 AM
> To: concurrency-interest@altair.cs.oswego.edu
> Subject: [concurrency-interest] Please comment on this approach
>
>
> I'll try to make this as brief as possible. I have an app where the 
> main thread will do all file I/O, generating some items that need 
> processed. The result of that processing will be some other items that 
> will be posted to a message queue using JMS (another somewhat I/O 
> intensive operation). I want those two processing stages to be handled 
> each in their own dedicated thread reading from a LinkedBlockingQueue. 
> The reason for a dedicated thread to handle queued items is due to the 
> high overhead of creating the resources needed to process the queued 
> items (e.g. a JMS connection) - I don't want to either recreate those 
> every time or create lots of them for all the threads in a pool. BTW, 
> I'm using the backport library, as I must use JDK 1.4.
>
> Below is a (hopefully :) reusable approach I've come up with. My main 
> questions are:
>
> 1) Am I missing something in the library that already does this?
> 2) If not, does my approach have any fundamental design or 
> implementation flaws?
>
> // fairly obvious interface for handling items pulled from queue 
> public interface GenericThreadQueueHandler {
> 	void initialize(GenericThreadQueue q);
> 	void itemDequeued(Object o);
> 	void cleanup();
> }
>
> /**
>  * The envisioned usage is in situations where long-lived, relatively 
> high-
>  * overhead, possibly thread-specific resources are required to 
> process the
>  * items as they are dequeued (e.g. a JMS connection). In those 
> situations, the
>  * resources can't (or shouldn't) be recreated for every item that is 
> dequeued.
>  */
> public abstract class GenericThreadQueue {
>
> 	public GenericThreadQueue(GenericThreadQueueHandler h) {
> 		queue_ = new LinkedBlockingQueue();
> 		handler_ = h;
> 	}
>
> 	public void start() {
> 		Runnable r = new GenericRunnable(this, handler_);
> 		thread_ = Executors.defaultThreadFactory().newThread(r);
> 		thread_.setDaemon(true);
> 		thread_.start();
> 	}
>
> 	public void stop() {
> 		thread_.interrupt();
> 		try {
> 			thread_.join();
> 		}
> 		catch (InterruptedException xcpt) {
> 			// do nothing
> 		}
> 	}
>
> 	private static class GenericRunnable implements Runnable {
> 		public GenericRunnable(GenericThreadQueue q, 
> GenericThreadQueueHandler h) {
> 			queue_ = q;
> 			handler_ = h;
> 		}
>
> 		public void run() {
> 			handler_.initialize(queue_);
>
> 			try {
> 				while (true) {
>
> 					// get next item from queue
> 					Object o;
>
> 					try {
> 						o = queue_.dequeue();
> 					}
> 					catch (InterruptedException xcpt) {
> 						// signal to end thread
> 						break;
> 					}
>
> 					// process item
> 					handler_.itemDequeued(o);
> 				}
> 			}
> 			finally {
> 				handler_.cleanup();
> 			}
> 		}
>
> 		GenericThreadQueue queue_;
> 		private GenericThreadQueueHandler handler_;
> 	}
>
> 	protected final void enqueue(Object o) throws InterruptedException {
> 		queue_.put(o);
> 	}
>
> 	protected final Object dequeue() throws InterruptedException {
> 		return queue_.take();
> 	}
>
> 	private LinkedBlockingQueue queue_;
> 	private Thread thread_;
> 	private GenericThreadQueueHandler handler_; }
>
> Thanks, and sorry for the length.
>
> Donnie
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From dholmes at dltech.com.au  Wed May  4 23:10:57 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Wed May  4 23:11:03 2005
Subject: [concurrency-interest] Please comment on thisapproach
Message-ID: <NFBBKALFDCPFIDBNKAPCMEMGFKAA.dholmes@dltech.com.au>

> 2. Back in my native Win32 days, I'd use a sentinel Event and
> WaitForMultipleObjects to be notified that I should fall out the
> bottom of a thread. There's probably something like that in the
> concurrent API,

No there is nothing like that in the concurrent API - neither a sentinel
event nor waitForMultipleObjects :)
 
I was referring to simply defining a special Object that you use as a
marker:

   static final Object STOP = new Object();


   public void stop() {
          q.add(STOP);
          thread.join(); // if you really need this
          ...
  }

  public void run() {
    Object obj;
    while ((obj = queue.take()) != STOP) {
      // process obj
   }
  }
 
Cheers,
David Holmes

From mike.skells at ebizz-consulting.com  Thu May  5 05:00:30 2005
From: mike.skells at ebizz-consulting.com (Mike Skells)
Date: Thu May  5 05:00:35 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <427988D9.1020001@cytetech.com>
Message-ID: <200505050900.j4590Vn0005328@altair.cs.oswego.edu>

The point is that the approach that you propose is not suitable for the
general case.
1. It doesn't work in J2EE
2. It doesn't work when you are writing reusable code (ie not the app)
3. It stops the application being swapped

Given the above it does not seen to be a good idea to post is as the
solution to the problem that was described.

BTW WeakHashMap is _not_ a same management mechanism for the problem below.
You are assuming that there in no reference to the Thread in any of the
values that you maintain, or anywhere else in any system you ever write.
This is precisely the problem that causes memory leaks

Mike 


-----Original Message-----
From: concurrency-interest-bounces@cs.oswego.edu
[mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf Of Gregg
Wonderly
Sent: 05 May 2005 03:46
To: Mike Skells
Cc: 'Gregg Wonderly'; larryr@saturn.sdsu.edu;
concurrency-interest@altair.cs.oswego.edu; 'Osvaldo Pinali Doederlein';
'Pete Soper'
Subject: Re: [concurrency-interest] reusing threads and thread local state



Mike Skells wrote:

>>I don't use threadlocals myself because it is just as easy to use a
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.

This is my statement, not Larry's.

> Interesting to know how you manage the cleanup, as you now have a strong
> reference to a Thread in you HashMap, so the Thread cannot be GC until
every
> one of your explicit cleanups completes

I use explicit thread management to handle this issue.  And also, I use 
an periodic thread that asks if the thread is still running and remove 
entries for any such threads.

> Also all of the ThreadLocals that are created in that thread are not GCed
> either (fixed in JDK1.5).
> 
> If this is run in an environment that manages Threads (outside you
control)
> such as an appserver then the cleanup is complicated further.  

I don't use J2EE.  I just use J2SE and Jini for my enterprise 
applications.  Keeps me in control of the things that matter to me.

> Looks to me as if you have created your own personal memory leak!

Only if you don't understand all the issues and ways out.  There are a 
lot more "appliance programmers" who don't understand computer science, 
so these things will largely work for them.  But, these memory leak bugs 
are getting to be way to common (java.util.Timer cancelled tasks), so 
I've learned to just role my own rather than depending on bug free JDK 
code, which historically has not been available.

Gregg Wonderly
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dawidk at mathcs.emory.edu  Thu May  5 12:24:06 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu May  5 12:24:34 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <200505050900.j4590Vn0005328@altair.cs.oswego.edu>
References: <200505050900.j4590Vn0005328@altair.cs.oswego.edu>
Message-ID: <427A48A6.6010400@mathcs.emory.edu>

Mike,

Mike Skells wrote:

>The point is that the approach that you propose is not suitable for the
>general case.
>1. It doesn't work in J2EE
>  
>
That's a strong claim, I haven't seen you demonstrated this; all you 
said is that "cleanup is complicated"

>2. It doesn't work when you are writing reusable code (ie not the app)
>  
>
If you are writing the library, you can specify how you handle 
thread-specific data as a matter of your library API.

>3. It stops the application being swapped
>  
>
?

>Given the above it does not seen to be a good idea to post is as the
>solution to the problem that was described.
>
>  
>
I don't think Gregg posted it as a general solution - it seemed rather 
as a possible approach that may be useful in some cases. Same with my 
DelegatableThreadLocal proposal. But frankly, first of all, what is the 
problem that was described, exactly? I think that the main reason why 
the EG does not want to hear about thread locals is that nobody so far 
have shown a valid use case in which their 
cleanup/propagation/management was really needed. Everyone is speeking 
in general terms, and speculating "what the world needs", but noone 
managed to provided example like: "I wrote an application/library X, it 
does Y and Z, and I need it to be able to do W, which is not possible 
with existing API because Q".

>BTW WeakHashMap is _not_ a same management mechanism for the problem below.
>You are assuming that there in no reference to the Thread in any of the
>values that you maintain, or anywhere else in any system you ever write.
>This is precisely the problem that causes memory leaks
>  
>
If you have references to the thread anywhere else in the system, your 
thread locals will not be freed in any case. Yes, back-references from 
values would also keep thread local map alive, but often you know that 
your application does not have them. But, in fact, it can be fixed by 
changing the outer map into an ordinary thread local:

new ThreadLocal(new HashMap<String, ?>)


In fact, this is a strategy I used in my ThreadContext class to 
implement DelegatableThreadLocals.

I agree that memory leaks may be a serious problem in Java apps. 
Fortunately, with existing profilers, they are usually quite easy to 
identify and fix.

Regards,
Dawid


From gregg at cytetech.com  Thu May  5 12:34:34 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu May  5 12:34:47 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <20050505144531.4D544F0C53@integer.pobox.com>
References: <20050505144531.4D544F0C53@integer.pobox.com>
Message-ID: <427A4B1A.5010409@cytetech.com>



Mike Skells wrote:
> The point is that the approach that you propose is not suitable for the
> general case.
> 1. It doesn't work in J2EE
> 2. It doesn't work when you are writing reusable code (ie not the app)
> 3. It stops the application being swapped
> 
> Given the above it does not seen to be a good idea to post is as the
> solution to the problem that was described.

The whole world is not J2EE powered.  The fact that J2EE isolates you 
from some of the capabilities of the J2SE platform is a completely 
different issue.  Regarding #2, I don't think I provided any concrete 
code that what I wrote which showed that I was not creating reusable 
code.  If you interpreted it that way, I'm sorry for confusing you.  I 
do create reusable code where that makes sense.  In some cases it's not, 
because the application has some very specific needs.

I'm not sure what #3 refers to.  The application is J2SE compatible and 
can thus be run on any J2SE complient JVM.

> BTW WeakHashMap is _not_ a same management mechanism for the problem below.
> You are assuming that there in no reference to the Thread in any of the
> values that you maintain, or anywhere else in any system you ever write.
> This is precisely the problem that causes memory leaks

I didn't suggest WeakHashMap as a 'same management mechanism'. 
WeakHashMap is a useful mechanism only where the key can not be 
referenced by external, uncontrolled sources.  Global objects, such as 
Thread are in fact, poor choices.  The mechanism that I posted about in 
an earlier note uses a separate object as the key.  This eliminates the 
global data view conflict as long as accessibility to that object is 
managed effectively/correctly.

Gregg Wonderly
From mike.skells at ebizz-consulting.com  Thu May  5 16:28:29 2005
From: mike.skells at ebizz-consulting.com (Mike Skells)
Date: Thu May  5 16:28:36 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <427A48A6.6010400@mathcs.emory.edu>
Message-ID: <200505052028.j45KSVn0019775@altair.cs.oswego.edu>



-----Original Message-----
From: concurrency-interest-bounces@cs.oswego.edu
[mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf Of Dawid
Kurzyniec
Sent: 05 May 2005 17:24
To: Mike Skells; concurrency-interest@altair.cs.oswego.edu
Cc: 'Gregg Wonderly'; larryr@saturn.sdsu.edu; 'Pete Soper'; 'Osvaldo Pinali
Doederlein'; gregg.wonderly@pobox.com
Subject: Re: [concurrency-interest] reusing threads and thread local state

Mike,

Mike Skells wrote:

>The point is that the approach that you propose is not suitable for the
>general case.
>1. It doesn't work in J2EE
>  
>
That's a strong claim, I haven't seen you demonstrated this; all you 
said is that "cleanup is complicated"
[Mike Skells] 
When your classes are unloaded, and not reloadable, then this is complicates
to the level of being impossible

>2. It doesn't work when you are writing reusable code (ie not the app)
>  
>
If you are writing the library, you can specify how you handle 
thread-specific data as a matter of your library API.
[Mike Skells] 
Again this is more complexity, for no purpose. Do you believe that the
library will manage the threads for you.

The point is that the start of this email chain was looking to define/refine
a simple pattern to make life easier, and less error prone

>3. It stops the application being swapped
>  
>
?
[Mike Skells] 
What does ? mean

Does it mean that you don't understand that the application cannot be
swapped, or that you don't think that this is an important ussue,
considering that you consider that this can be used and reused as a standard
pattern

>Given the above it does not seen to be a good idea to post is as the
>solution to the problem that was described.
>
>  
>
I don't think Gregg posted it as a general solution - it seemed rather 
as a possible approach that may be useful in some cases.
[Mike Skells] 
Sorry, maybe I am reading too much into the comment
--
> I don't use threadlocals myself because it is just as easy to use a 
> Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
> control access to and manage clearing etc on my own.
--
Sounds like this is a easy to use general solution. I didn't see any careats
in the comment, hence my response


 Same with my 
DelegatableThreadLocal proposal. But frankly, first of all, what is the 
problem that was described, exactly? I think that the main reason why 
the EG does not want to hear about thread locals is that nobody so far 
have shown a valid use case in which their 
cleanup/propagation/management was really needed. Everyone is speeking 
in general terms, and speculating "what the world needs", but noone 
managed to provided example like: "I wrote an application/library X, it 
does Y and Z, and I need it to be able to do W, which is not possible 
with existing API because Q".
[Mike Skells] 
Agreed. The use case here is important. My usage pattern for threadLocals is
not looking for any enhancements here, I tend to use then for callbacks only
and the mechanism that I use cleanup on exit [not proposing this pattern!]

>BTW WeakHashMap is _not_ a same management mechanism for the problem below.
>You are assuming that there in no reference to the Thread in any of the
>values that you maintain, or anywhere else in any system you ever write.
>This is precisely the problem that causes memory leaks
>  
>
If you have references to the thread anywhere else in the system, your 
thread locals will not be freed in any case. 
[Mike Skells] 
After 1.5 they arefreed up when the thread exits

See Thread.exit()

[Mike Skells] 
Yes, back-references from values would also keep thread local map alive, but
often you know that 
your application does not have them. But, in fact, it can be fixed by 
changing the outer map into an ordinary thread local:

new ThreadLocal(new HashMap<String, ?>)
[Mike Skells] 
I think that one of us has missed the point here. The proposal was to
provide an alternative to ThreadLocal. So what do you need the HashMap for?

And of course this will _not_ work prior to JDK 1.5
[Mike Skells] 


In fact, this is a strategy I used in my ThreadContext class to 
implement DelegatableThreadLocals.

I agree that memory leaks may be a serious problem in Java apps. 
Fortunately, with existing profilers, they are usually quite easy to 
identify and fix.

Regards,
Dawid


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From mike.skells at ebizz-consulting.com  Thu May  5 16:44:59 2005
From: mike.skells at ebizz-consulting.com (Mike Skells)
Date: Thu May  5 16:45:06 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <427A4B1A.5010409@cytetech.com>
Message-ID: <200505052045.j45Kj3n0020056@altair.cs.oswego.edu>



-----Original Message-----
From: Gregg Wonderly [mailto:gregg@cytetech.com] 
Sent: 05 May 2005 17:35
To: Mike Skells
Cc: gregg.wonderly@pobox.com; 'Gregg Wonderly'; larryr@saturn.sdsu.edu;
concurrency-interest@altair.cs.oswego.edu; 'Osvaldo Pinali Doederlein';
'Pete Soper'
Subject: Re: [concurrency-interest] reusing threads and thread local state



Mike Skells wrote:
> The point is that the approach that you propose is not suitable for the
> general case.
> 1. It doesn't work in J2EE
> 2. It doesn't work when you are writing reusable code (ie not the app)
> 3. It stops the application being swapped
> 
> Given the above it does not seen to be a good idea to post is as the
> solution to the problem that was described.

The whole world is not J2EE powered.  The fact that J2EE isolates you 
from some of the capabilities of the J2SE platform is a completely 
different issue.  
[Mike Skells] 
But the point remains - this pattern does not work in this case, so it in
not general. This is the point that I was making ie " not suitable for the
general case."


Regarding #2, I don't think I provided any concrete 
code that what I wrote which showed that I was not creating reusable 
code.  If you interpreted it that way, I'm sorry for confusing you.  I 
do create reusable code where that makes sense.  In some cases it's not, 
because the application has some very specific needs.
[Mike Skells] 
Please see other email thread

I'm not sure what #3 refers to.  The application is J2SE compatible and 
can thus be run on any J2SE complient JVM.
[Mike Skells] 
Swapped not ported. Ie swapped out as a process from memory when the
application is quiet, and the OS has other demands on the system resources

> BTW WeakHashMap is _not_ a same management mechanism for the problem
below.
> You are assuming that there in no reference to the Thread in any of the
> values that you maintain, or anywhere else in any system you ever write.
> This is precisely the problem that causes memory leaks

I didn't suggest WeakHashMap as a 'same management mechanism'. 
WeakHashMap is a useful mechanism only where the key can not be 
referenced by external, uncontrolled sources.  Global objects, such as 
Thread are in fact, poor choices.  The mechanism that I posted about in 
an earlier note uses a separate object as the key.  This eliminates the 
global data view conflict as long as accessibility to that object is 
managed effectively/correctly.
[Mike Skells] 
Agreed, my comment relates only to the comment
 ----
>>I don't use threadlocals myself because it is just as easy to use a 
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.
...
I guess WeakHashMap should do the trick.
----

Gregg Wonderly


From dawidk at mathcs.emory.edu  Thu May  5 19:00:39 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu May  5 19:00:54 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <200505052028.j45KSVn0019775@altair.cs.oswego.edu>
References: <200505052028.j45KSVn0019775@altair.cs.oswego.edu>
Message-ID: <427AA597.3060801@mathcs.emory.edu>

Mike Skells wrote:

>-----Original Message-----
>From: concurrency-interest-bounces@cs.oswego.edu
>[mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf Of Dawid
>Kurzyniec
>Sent: 05 May 2005 17:24
>To: Mike Skells; concurrency-interest@altair.cs.oswego.edu
>Cc: 'Gregg Wonderly'; larryr@saturn.sdsu.edu; 'Pete Soper'; 'Osvaldo Pinali
>Doederlein'; gregg.wonderly@pobox.com
>Subject: Re: [concurrency-interest] reusing threads and thread local state
>
>Mike,
>
>Mike Skells wrote:
>
>  
>
>>The point is that the approach that you propose is not suitable for the
>>general case.
>>1. It doesn't work in J2EE
>> 
>>
>>    
>>
>That's a strong claim, I haven't seen you demonstrated this; all you 
>said is that "cleanup is complicated"
>[Mike Skells] 
>When your classes are unloaded, and not reloadable, then this is complicates
>to the level of being impossible
>
>  
>
I guess you are implying that memory leaks are nearly impossible to 
avoid when using the technique described by Gregg in J2EE.

>>3. It stops the application being swapped
>>    
>>
>?
>[Mike Skells] 
>What does ? mean
>  
>
I meant that I did not understand the sentence, because "swapped" is too 
ambigious. From the other thread, I understand that you meant swapping 
from memory to disk. I still do not see obvious connection between this 
and what Gregg suggested, other than hidden assumption that there must 
be some sort of a memory leak, but even then, I guess I can hardly see 
how it prevents swapping to disk. It may be my ignorance of J2EE though 
- perhaps you mean some J2EE-level swapping, not the OS-level swapping.

>>Given the above it does not seen to be a good idea to post is as the
>>solution to the problem that was described.
>>    
>>
>I don't think Gregg posted it as a general solution - it seemed rather 
>as a possible approach that may be useful in some cases.
>[Mike Skells] 
>Sorry, maybe I am reading too much into the comment
>--
>  
>
>>I don't use threadlocals myself because it is just as easy to use a 
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.
>>    
>>
>--
>Sounds like this is a easy to use general solution. I didn't see any careats
>in the comment, hence my response
>  
>
OK, I think (hope?) we may all agree that the pattern proposed by Gregg 
is not a general-purpose replacement for thread locals; there are 
contexts where they are definitely more natural to use, e.g. since they 
provide better encapsulation, they avoid naming clashes, and they are 
faster. IMHO, though, that pattern can be useful in some situations, 
e.g. when you need named locals, when you need some sharing between 
threads, and when you need more dynamic creation patterns. In yet other 
cases, a hybrid solution (e.g. new ThreadLocal(new HashMap()) may be the 
most beneficial, since it preserves thread isolation while allowing 
dynamic instantiation.

I would like to read Gregg's posting as "in fact, we still could live 
even without normal thread locals; hence, we can live without JSR166 API 
extensions to clear them etc.", which does not imply that we should 
abandon thread locals, as in many contexts they are very nice and useful.

>  
>
>>BTW WeakHashMap is _not_ a same management mechanism for the problem below.
>>You are assuming that there in no reference to the Thread in any of the
>>values that you maintain, or anywhere else in any system you ever write.
>>This is precisely the problem that causes memory leaks
>>    
>>
>If you have references to the thread anywhere else in the system, your 
>thread locals will not be freed in any case. 
>[Mike Skells] 
>After 1.5 they arefreed up when the thread exits
>
>See Thread.exit()
>  
>
Acknowledged.

Regards,
Dawid


From mike.skells at ebizz-consulting.com  Fri May  6 11:19:24 2005
From: mike.skells at ebizz-consulting.com (Mike Skells)
Date: Fri May  6 11:19:29 2005
Subject: [concurrency-interest] reusing threads and thread local state
In-Reply-To: <427AA597.3060801@mathcs.emory.edu>
Message-ID: <200505061519.j46FJPn0002516@altair.cs.oswego.edu>



-----Original Message-----
From: Dawid Kurzyniec [mailto:dawidk@mathcs.emory.edu] 
Sent: 06 May 2005 00:01
To: Mike Skells
Cc: concurrency-interest@altair.cs.oswego.edu
Subject: Re: [concurrency-interest] reusing threads and thread local state

Mike Skells wrote:

>-----Original Message-----
>From: concurrency-interest-bounces@cs.oswego.edu
>[mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf Of Dawid
>Kurzyniec
>Sent: 05 May 2005 17:24
>To: Mike Skells; concurrency-interest@altair.cs.oswego.edu
>Cc: 'Gregg Wonderly'; larryr@saturn.sdsu.edu; 'Pete Soper'; 'Osvaldo Pinali
>Doederlein'; gregg.wonderly@pobox.com
>Subject: Re: [concurrency-interest] reusing threads and thread local state
>
>Mike,
>
>Mike Skells wrote:
>
>  
>
>>The point is that the approach that you propose is not suitable for the
>>general case.
>>1. It doesn't work in J2EE
>> 
>>
>>    
>>
>That's a strong claim, I haven't seen you demonstrated this; all you 
>said is that "cleanup is complicated"
>[Mike Skells] 
>When your classes are unloaded, and not reloadable, then this is
complicates
>to the level of being impossible
>
>  
>
I guess you are implying that memory leaks are nearly impossible to 
avoid when using the technique described by Gregg in J2EE.
[Mike Skells] 
Yes - put better than I did

>>3. It stops the application being swapped
>>    
>>
>?
>[Mike Skells] 
>What does ? mean
>  
>
I meant that I did not understand the sentence, because "swapped" is too 
ambigious. From the other thread, I understand that you meant swapping 
from memory to disk. I still do not see obvious connection between this 
and what Gregg suggested, other than hidden assumption that there must 
be some sort of a memory leak, but even then, I guess I can hardly see 
how it prevents swapping to disk. It may be my ignorance of J2EE though 
- perhaps you mean some J2EE-level swapping, not the OS-level swapping.

[Mike Skells] 
In other replies an indication that the cleanup task operates as a periodic
event, thus the application is activates to do the tidyup. If this is too
long then memory is tied up, if not then to OS cannot swap the task as it
keeps waking up



>>Given the above it does not seen to be a good idea to post is as the
>>solution to the problem that was described.
>>    
>>
>I don't think Gregg posted it as a general solution - it seemed rather 
>as a possible approach that may be useful in some cases.
>[Mike Skells] 
>Sorry, maybe I am reading too much into the comment
>--
>  
>
>>I don't use threadlocals myself because it is just as easy to use a 
>>Hashtable<Thread,Hashtable<String,?>> via a static factory which I can 
>>control access to and manage clearing etc on my own.
>>    
>>
>--
>Sounds like this is a easy to use general solution. I didn't see any
careats
>in the comment, hence my response
>  
>
OK, I think (hope?) we may all agree that the pattern proposed by Gregg 
is not a general-purpose replacement for thread locals; there are 
contexts where they are definitely more natural to use, e.g. since they 
provide better encapsulation, they avoid naming clashes, and they are 
faster. IMHO, though, that pattern can be useful in some situations, 
e.g. when you need named locals, when you need some sharing between 
threads, and when you need more dynamic creation patterns. In yet other 
cases, a hybrid solution (e.g. new ThreadLocal(new HashMap()) may be the 
most beneficial, since it preserves thread isolation while allowing 
dynamic instantiation.

I would like to read Gregg's posting as "in fact, we still could live 
even without normal thread locals; hence, we can live without JSR166 API 
extensions to clear them etc.", which does not imply that we should 
abandon thread locals, as in many contexts they are very nice and useful.

[Mike Skells] 
Agreed
>  
>
>>BTW WeakHashMap is _not_ a same management mechanism for the problem
below.
>>You are assuming that there in no reference to the Thread in any of the
>>values that you maintain, or anywhere else in any system you ever write.
>>This is precisely the problem that causes memory leaks
>>    
>>
>If you have references to the thread anywhere else in the system, your 
>thread locals will not be freed in any case. 
>[Mike Skells] 
>After 1.5 they arefreed up when the thread exits
>
>See Thread.exit()
>  
>
Acknowledged.

Regards,
Dawid




From Philip.Lee at logicacmg.com  Mon May  9 10:31:42 2005
From: Philip.Lee at logicacmg.com (Lee, Phil)
Date: Mon May  9 10:32:17 2005
Subject: [concurrency-interest] Pooled executor and data visibility
Message-ID: <6216396AEBE36247BF62B505A88ADA0A047A084E@uk-ex002.groupinfra.com>

Hi,

I am using a PooledExecutor to handle events arriving for a large number
of session objects. If all Runnables passed to the PooledExecutor invoke
Session::work() then can I get away with just making Session::work()
synchronized to ensure that all data modifications are visibile to any
other thread than handles a subsequent event for a that session. Put
another way, do the cache flush/invalidate effects of synchronized
extend to all data fields of all objects touched by calls made within
the synchronized block or are they limited to the object upon which
synchronized is operating. (I'm guessing it's the latter and hoping it's
the former but I haven't seen it spelt out anywhere :).

TIA,

	Phil.


This e-mail and any attachment is for authorised use by the intended recipient(s) only. It may contain proprietary material, confidential information and/or be subject to legal privilege. It should not be copied, disclosed to, retained or used by, any other party. If you are not an intended recipient then please promptly delete this e-mail and any attachment and all copies and inform the sender. Thank you.

From dholmes at dltech.com.au  Mon May  9 20:09:11 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Mon May  9 20:09:23 2005
Subject: [concurrency-interest] Pooled executor and data visibility
In-Reply-To: <6216396AEBE36247BF62B505A88ADA0A047A084E@uk-ex002.groupinfra.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEBAFLAA.dholmes@dltech.com.au>

Phil,

When thread-B acquires a monitor that was released by thread-A then ALL
writes performed by thread-A before releasing the monitor are visible to
thread-B when it acquires the monitor.

In terms of the memory-model, everything that happens-before the release of
a monitor in one thread, happens before a subsequent acquire of the same
monitor in another thread. This is spelt out in the Java Memory Model spec
which is in chapter 17 of the Java Language Specification, 3rd edition.

http://java.sun.com/docs/books/jls/index.html

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu
> [mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of Lee,
> Phil
> Sent: Tuesday, 10 May 2005 12:32 AM
> To: concurrency-interest@altair.cs.oswego.edu
> Subject: [concurrency-interest] Pooled executor and data visibility
>
>
> Hi,
>
> I am using a PooledExecutor to handle events arriving for a large number
> of session objects. If all Runnables passed to the PooledExecutor invoke
> Session::work() then can I get away with just making Session::work()
> synchronized to ensure that all data modifications are visibile to any
> other thread than handles a subsequent event for a that session. Put
> another way, do the cache flush/invalidate effects of synchronized
> extend to all data fields of all objects touched by calls made within
> the synchronized block or are they limited to the object upon which
> synchronized is operating. (I'm guessing it's the latter and hoping it's
> the former but I haven't seen it spelt out anywhere :).
>
> TIA,
>
> 	Phil.
>
>
> This e-mail and any attachment is for authorised use by the
> intended recipient(s) only. It may contain proprietary material,
> confidential information and/or be subject to legal privilege. It
> should not be copied, disclosed to, retained or used by, any
> other party. If you are not an intended recipient then please
> promptly delete this e-mail and any attachment and all copies and
> inform the sender. Thank you.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From Philip.Lee at logicacmg.com  Tue May 10 15:43:07 2005
From: Philip.Lee at logicacmg.com (Lee, Phil)
Date: Tue May 10 15:43:33 2005
Subject: [concurrency-interest] Pooled executor and data visibility
Message-ID: <6216396AEBE36247BF62B505A88ADA0A0488800C@uk-ex002.groupinfra.com>

David,

Thanks, that's very helpful. We're currently targeting JRE 1.4.2_06 and
I understand some of the JSR133 recommendation were incorporated into
pre-Java 5.0 releases but I have found it very difficult to find any
specific information. Any pointers would be much appreciated!

Cheers,

	Phil.

-----Original Message-----
From: David Holmes [mailto:dholmes@dltech.com.au] 
Sent: 10 May 2005 01:09
To: Lee, Phil; concurrency-interest@altair.cs.oswego.edu
Subject: RE: [concurrency-interest] Pooled executor and data visibility

Phil,

When thread-B acquires a monitor that was released by thread-A then ALL
writes performed by thread-A before releasing the monitor are visible to
thread-B when it acquires the monitor.

In terms of the memory-model, everything that happens-before the release
of a monitor in one thread, happens before a subsequent acquire of the
same monitor in another thread. This is spelt out in the Java Memory
Model spec which is in chapter 17 of the Java Language Specification,
3rd edition.

http://java.sun.com/docs/books/jls/index.html

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu
> [mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of Lee, 
> Phil
> Sent: Tuesday, 10 May 2005 12:32 AM
> To: concurrency-interest@altair.cs.oswego.edu
> Subject: [concurrency-interest] Pooled executor and data visibility
>
>
> Hi,
>
> I am using a PooledExecutor to handle events arriving for a large 
> number of session objects. If all Runnables passed to the 
> PooledExecutor invoke
> Session::work() then can I get away with just making Session::work() 
> synchronized to ensure that all data modifications are visibile to any

> other thread than handles a subsequent event for a that session. Put 
> another way, do the cache flush/invalidate effects of synchronized 
> extend to all data fields of all objects touched by calls made within 
> the synchronized block or are they limited to the object upon which 
> synchronized is operating. (I'm guessing it's the latter and hoping 
> it's the former but I haven't seen it spelt out anywhere :).
>
> TIA,
>
> 	Phil.
>
>
> This e-mail and any attachment is for authorised use by the intended 
> recipient(s) only. It may contain proprietary material, confidential 
> information and/or be subject to legal privilege. It should not be 
> copied, disclosed to, retained or used by, any other party. If you are

> not an intended recipient then please promptly delete this e-mail and 
> any attachment and all copies and inform the sender. Thank you.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>


This e-mail and any attachment is for authorised use by the intended recipient(s) only. It may contain proprietary material, confidential information and/or be subject to legal privilege. It should not be copied, disclosed to, retained or used by, any other party. If you are not an intended recipient then please promptly delete this e-mail and any attachment and all copies and inform the sender. Thank you.

From dl at cs.oswego.edu  Tue May 10 19:32:28 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 10 19:32:31 2005
Subject: [concurrency-interest] Pooled executor and data visibility
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEBAFLAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCAEBAFLAA.dholmes@dltech.com.au>
Message-ID: <4281448C.5030805@cs.oswego.edu>

> Thanks, that's very helpful. We're currently targeting JRE 1.4.2_06 and
> I understand some of the JSR133 recommendation were incorporated into
> pre-Java 5.0 releases but I have found it very difficult to find any
> specific information. Any pointers would be much appreciated!
> 

So long as you are relying only on visibility and ordering
properties surrounding locks, you are surely OK.
There were a few small but important adjustments in J2SE5 surrounding
final fields and volatiles, but memory properties of locks
remained the same because hotspot locks conform
equally well to old and new memory model.

I'm sure that you will not be able to find anyone or anything to
officially tell you this though.

-Doug
From mark.kralj-taylor at zen.co.uk  Wed May 11 04:42:44 2005
From: mark.kralj-taylor at zen.co.uk (mark.kralj-taylor)
Date: Wed May 11 04:42:51 2005
Subject: [concurrency-interest] backport: Is there a forward port of
 backport.util.concurrent to Java 5.0
Message-ID: <4281C584.5070100@zen.co.uk>

Hi,
Is there a forward port to Java 5 of the backport.util.concurrent libraries?

At first this might sound a strange requrest, if running a Java 5 JVM, 
why not just use java.util.concurrent directly?

I want to use java.util.concurrent style APIs in my libraries, but I 
don't control the level of JVM the code will eventually be run in.
This is typical for large systems that are composed to a mixture of open 
source and in-house Jars from several project teams.
I have to write to the minimum JVM level that we support (Java 1.4), 
then other projects will choose to deploy to either a Java 1.4 or 5.0 JVM.
I don't have cycles to maintain seperate Java 1.4 and 5.0 sources or 
libraries I work on.
It would be great if I could code to backport.util.concurrent API, then 
projects could choose between a Java 1.4 and Java 5.0 implementation Jar 
of  backport.util.concurrent, to match their JVM.

The benefits of a Java 5 forward port of java.util.concurrent, is that 
it lets people take advantace of an implementation optimised for Java 5 
atomic operations, if they are running a Java 5.0 JVM, without needing 
them to make any code changes.
Right now my libraries are leading projects to use 
backport.util.concurrent APIs, which is a performance compromise on Java 
5.0 JVMs.

Ideally a forward port would allow interoperability between 
java.util.concurrent and backport.util.concurrent.

What is the backport.util.concurrent project's thoughts on this?
Are there any plans to Java 5 produce a forward port?

Thanks,
Mark
From radhakrishnan.mohan at gmail.com  Wed May 11 07:07:38 2005
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed May 11 07:49:03 2005
Subject: [concurrency-interest] Thread pools
Message-ID: <loom.20050511T125145-561@post.gmane.org>

Hi,

     We have a web application that integrates with web services. The web 
service responses actually decided what web page is shown to the user.
We could to have a thread pool and one thread for each webservice call. We 
could also use java.nio.

     So inorder to avoid context switching overhead we have decided to use nio 
with WSIF( Web service invocation framework ). I am looking for some design 
advice regarding this.

Thanks,
Mohan

From hanson.char at gmail.com  Wed May 11 08:02:17 2005
From: hanson.char at gmail.com (Hanson Char)
Date: Wed May 11 08:02:25 2005
Subject: [concurrency-interest] backport: Is there a forward port of
	backport.util.concurrent to Java 5.0
In-Reply-To: <4281C584.5070100@zen.co.uk>
References: <4281C584.5070100@zen.co.uk>
Message-ID: <ca53c8f805051105025585d523@mail.gmail.com>

Sounds like it should belong to a separate project, analogous to the
Apache commons logging which acts like a facade to the actual
underlying implementation.  So kind of a "commons concurrent" package
which provides an API that allows either the backport or jdk1.5 to be
used, depending on the actual JVM being run.

Hanson

On 5/11/05, mark.kralj-taylor <mark.kralj-taylor@zen.co.uk> wrote:
> Hi,
> Is there a forward port to Java 5 of the backport.util.concurrent libraries?
> 
> At first this might sound a strange requrest, if running a Java 5 JVM,
> why not just use java.util.concurrent directly?
> 
> I want to use java.util.concurrent style APIs in my libraries, but I
> don't control the level of JVM the code will eventually be run in.
> This is typical for large systems that are composed to a mixture of open
> source and in-house Jars from several project teams.
> I have to write to the minimum JVM level that we support (Java 1.4),
> then other projects will choose to deploy to either a Java 1.4 or 5.0 JVM.
> I don't have cycles to maintain seperate Java 1.4 and 5.0 sources or
> libraries I work on.
> It would be great if I could code to backport.util.concurrent API, then
> projects could choose between a Java 1.4 and Java 5.0 implementation Jar
> of  backport.util.concurrent, to match their JVM.
> 
> The benefits of a Java 5 forward port of java.util.concurrent, is that
> it lets people take advantace of an implementation optimised for Java 5
> atomic operations, if they are running a Java 5.0 JVM, without needing
> them to make any code changes.
> Right now my libraries are leading projects to use
> backport.util.concurrent APIs, which is a performance compromise on Java
> 5.0 JVMs.
> 
> Ideally a forward port would allow interoperability between
> java.util.concurrent and backport.util.concurrent.
> 
> What is the backport.util.concurrent project's thoughts on this?
> Are there any plans to Java 5 produce a forward port?
> 
> Thanks,
> Mark
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dl at cs.oswego.edu  Wed May 11 08:37:53 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed May 11 08:37:55 2005
Subject: [concurrency-interest] backport: Is there a forward port of
	backport.util.concurrent to Java 5.0
In-Reply-To: <4281C584.5070100@zen.co.uk>
References: <4281C584.5070100@zen.co.uk>
Message-ID: <4281FCA1.6010802@cs.oswego.edu>

> Is there a forward port to Java 5 of the backport.util.concurrent libraries?

So long as your application used only those classes and methods
that are in the backport (very few commonly useful ones aren't),
a "forward port" would not actually
consist of different code, but just different import statements.
I would think that there would be configuration tools
out there that could help arrange this.

The only things to be careful about are those few methods
like System.nanoTime and Thread uncaught exception handlers
that couldn't be backported to be in compatible classes
(because they are outside java.util.concurrent). It would
be easiest if your code never used such methods. If you do need
them, you can make little some ad-hoc adaptors.

-Doug
From etienne.laverdiere at vmd.desjardins.com  Wed May 11 10:39:38 2005
From: etienne.laverdiere at vmd.desjardins.com (etienne.laverdiere@vmd.desjardins.com)
Date: Wed May 11 10:39:51 2005
Subject: [concurrency-interest] which util-concurrent  to use for JDK1.3.1
Message-ID: <OF3685E7F0.7EAA6A31-ON85256FFE.004FFCD6-85256FFE.005088A6@vmd.desjardins.com>






Hi,

what is latest version of the Concurrent package for (IBM)JDK 1.3.1?

The backport-util-concurrent-1.1_01 found at
http://www.mathcs.emory.edu/dcl/util/ doesn't seems top be compatible, I
get this error:

10:25 AMjava.lang.UnsupportedClassVersionError:
edu/emory/mathcs/backport/java/util/concurrent/Executors (Unsupported
major.minor version 48.0)

Should I use the older version "util.concurrent Release 1.3.4." found at
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html

(EDU.oswego.cs.dl.util.concurrent.*)

Thanks.

Etienne Laverdi?re
Concepteur
D?veloppement informatique
Valeurs mobili?res Desjardins
(514) 281-2244 poste 3852
etienne.laverdiere@vmd.desjardins.com

- L'int?grit? des informations transmises dans ce courriel n?est pas
garantie par Valeurs mobili?res Desjardins qui d?cline toute responsabilit?
quant aux dommages caus?s par leur modification frauduleuse. - Ce courriel
est confidentiel et est ? l?usage exclusif de son destinataire. Toute
personne qui re?oit celui-ci par erreur doit en informer imm?diatement son
exp?diteur et le d?truire sur-le-champ. Toute autre  utilisation des
informations qu?il contient est strictement interdite. - Le pr?sent
avertissement ne limite aucunement tout autre avertissement plus restrictif
qui vous aurait ?t? transmis par Valeurs mobili?res Desjardins.
- The integrity of the transmitted information in this E-mail is not
guaranteed by Desjardins Securities which accepts no liability for any
damage caused by its fraudulent alteration.  - This E-mail is confidential
and is intended for the sole use of the recipient or authorized
representative of the recipient. Any person who receives this E-mail by
mistake shall immediately notify the sender and destroy it. Any other use
of the information therein is strictly prohibited. - In no manner does this
notice limit other more restrictive warnings which may have been
transmitted to you by Desjardins Securities.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20050511/a315df73/attachment.htm
From dawidk at mathcs.emory.edu  Wed May 11 10:58:52 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed May 11 10:59:07 2005
Subject: [concurrency-interest] which util-concurrent to use for JDK1.3.1
In-Reply-To: <OF3685E7F0.7EAA6A31-ON85256FFE.004FFCD6-85256FFE.005088A6@vmd.desjardins.com>
References: <OF3685E7F0.7EAA6A31-ON85256FFE.004FFCD6-85256FFE.005088A6@vmd.desjardins.com>
Message-ID: <42821DAC.90401@mathcs.emory.edu>

etienne.laverdiere@vmd.desjardins.com wrote:

> Hi,
>
> what is latest version of the Concurrent package for (IBM)JDK 1.3.1?
>
> The backport-util-concurrent-1.1_01 found at 
> http://www.mathcs.emory.edu/dcl/util/ doesn't seems top be compatible, 
> I get this error:
>
> 10:25 AMjava.lang.UnsupportedClassVersionError: 
> edu/emory/mathcs/backport/java/util/concurrent/Executors (Unsupported 
> major.minor version 48.0)
>
> Should I use the older version "util.concurrent Release 1.3.4." found 
> at 
> http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
>
backport-util-concurrent is written to support 1.4, but it is quite easy 
to compile it on 1.3 if you need to. Download the source distribution 
and try to compile; you will get a few errors that will necessitate 
minor changes in about 6 classes. Namely, you need to remove "assert" 
statements, modify some exception classes to ignore the "cause" 
parameter, and in one place, change Boolean.valueOf(b) to "b ? 
Boolean.TRUE : boolean.FALSE".

Maybe one day I will provide explicit support for 1.2+, but so far, the 
interest was low...


Of course you can also use dl.util.concurrent 1.3.4, but it predates JSR 
166 and the APIs are a bit different.

Regards,
Dawid Kurzyniec



From jean.morissette666 at videotron.ca  Wed May 11 12:40:07 2005
From: jean.morissette666 at videotron.ca (Jean Morissette)
Date: Wed May 11 11:40:04 2005
Subject: [concurrency-interest] Thread pools
In-Reply-To: <loom.20050511T125145-561@post.gmane.org>
References: <loom.20050511T125145-561@post.gmane.org>
Message-ID: <200505111240.07724.jean.morissette666@videotron.ca>

Hi Mohan,
	You should take a look at SEDA (Staged Event-Driven Architecture) 
http://www.eecs.harvard.edu/~mdw/proj/seda/

It provide a really performant solution for highly concurrent applications.  
The last version of the SEDA project can be found here 
http://www.jcyclone.org/

Hope this help,
-Jean


Le 11 Mai 2005 07:07, Mohan Radhakrishnan a ?crit?:
> Hi,
>
>      We have a web application that integrates with web services. The web
> service responses actually decided what web page is shown to the user.
> We could to have a thread pool and one thread for each webservice call. We
> could also use java.nio.
>
>      So inorder to avoid context switching overhead we have decided to use
> nio with WSIF( Web service invocation framework ). I am looking for some
> design advice regarding this.
>
> Thanks,
> Mohan

From dawidk at mathcs.emory.edu  Wed May 11 12:34:34 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed May 11 12:34:40 2005
Subject: [concurrency-interest] backport: Is there a forward port
	ofbackport.util.concurrent to Java 5.0
In-Reply-To: <ca53c8f805051105025585d523@mail.gmail.com>
References: <4281C584.5070100@zen.co.uk>
	<ca53c8f805051105025585d523@mail.gmail.com>
Message-ID: <4282341A.1030005@mathcs.emory.edu>

Hanson Char wrote:

>Sounds like it should belong to a separate project, analogous to the
>Apache commons logging which acts like a facade to the actual
>underlying implementation.  So kind of a "commons concurrent" package
>which provides an API that allows either the backport or jdk1.5 to be
>used, depending on the actual JVM being run.
>
>  
>
That sounds right. My suggestion would be that you create your own 
facade API, with the stuff that you use, in versions for 1) backport and 
2) j.u.c., differing by import statements. An alternative is to try to 
recompile backport with changed package names, e.g. removing 
"edu.emory.mathcs.backport", and add the JAR to the _boot_ class path on 
1.4 JVMs (although I am not even sure if this will work, e.g. JVM may 
complain about forbidden definition of java.* packages). If this works, 
you could use j.u.c. APIs in 1.4, with the exception for things like 
nanoTime(), as Doug mentioned.

The "forward-port" of the backport is another interesting alternative, 
but I am not sure how happy people would be to code against backport 
packages (funny package names, no generics etc) when targetting mainly 
5.0. Also, this potentially could add overheads (as could, as the matter 
of fact, the facade API) - e.g. if delegation is used, calls would go 
through wrapper classes, and also the number of instance counts would 
double, which could be non-negligible for lock classes and atomic 
variables. Possible solution would be to use inheritance, rather than 
delegation. I might consider something like this at some point, but the 
priority for me is to complete the backport (e.g. add skip-list maps).

BTW. I am happy to see such a wide interest - people are asking for the 
backport to be available on all Java versions between 1.3 and 5.0 :) I 
will try to do my best to accomodate the requests, with priorities 
depending on the relative level of interest.

Regards,
Dawid Kurzyniec

>Hanson
>
>On 5/11/05, mark.kralj-taylor <mark.kralj-taylor@zen.co.uk> wrote:
>  
>
>>Hi,
>>Is there a forward port to Java 5 of the backport.util.concurrent libraries?
>>
>>At first this might sound a strange requrest, if running a Java 5 JVM,
>>why not just use java.util.concurrent directly?
>>
>>I want to use java.util.concurrent style APIs in my libraries, but I
>>don't control the level of JVM the code will eventually be run in.
>>This is typical for large systems that are composed to a mixture of open
>>source and in-house Jars from several project teams.
>>I have to write to the minimum JVM level that we support (Java 1.4),
>>then other projects will choose to deploy to either a Java 1.4 or 5.0 JVM.
>>I don't have cycles to maintain seperate Java 1.4 and 5.0 sources or
>>libraries I work on.
>>It would be great if I could code to backport.util.concurrent API, then
>>projects could choose between a Java 1.4 and Java 5.0 implementation Jar
>>of  backport.util.concurrent, to match their JVM.
>>
>>The benefits of a Java 5 forward port of java.util.concurrent, is that
>>it lets people take advantace of an implementation optimised for Java 5
>>atomic operations, if they are running a Java 5.0 JVM, without needing
>>them to make any code changes.
>>Right now my libraries are leading projects to use
>>backport.util.concurrent APIs, which is a performance compromise on Java
>>5.0 JVMs.
>>
>>Ideally a forward port would allow interoperability between
>>java.util.concurrent and backport.util.concurrent.
>>
>>What is the backport.util.concurrent project's thoughts on this?
>>Are there any plans to Java 5 produce a forward port?
>>    
>>


From david at walend.net  Wed May 11 14:02:49 2005
From: david at walend.net (David Walend)
Date: Wed May 11 14:03:15 2005
Subject: [concurrency-interest] backport: Is there a forward port of
	backport.util.concurrent to Java 5.0
In-Reply-To: <200505111501.j4BF1Cn1014659@altair.cs.oswego.edu>
References: <200505111501.j4BF1Cn1014659@altair.cs.oswego.edu>
Message-ID: <125C9650-43EB-40D2-96F7-F7C35C561B0E@walend.net>

On May 11, 2005, at 11:01 AM, concurrency-interest- 
request@cs.oswego.edu wrote:

>
> Hi,
> Is there a forward port to Java 5 of the backport.util.concurrent  
> libraries?
>
> Ideally a forward port would allow interoperability between
> java.util.concurrent and backport.util.concurrent.
>
> What is the backport.util.concurrent project's thoughts on this?
> Are there any plans to Java 5 produce a forward port?
>
>

Mark,

For SomnifugiJMS, I was able to use an interface/driver pattern to  
separate out a backport version and a juc version of the code base. I  
stopped there to wait for retroweaver.

If you can wait, or want to help out, Toby plans to use the backport  
in retroweaver. That's what stopped me from branching the Somnifugi  
properly into 1.4 and 5.0 versions. Helping retroweaver use the  
backport is at least a more interesting option than adding another  
layer of abstraction.

Hope that helps,

Dave


From Sai.Kumar at ca.com  Wed May 11 17:49:59 2005
From: Sai.Kumar at ca.com (Pollachi, Saikumar)
Date: Wed May 11 17:50:04 2005
Subject: [concurrency-interest] backport: Is there a forward port
	ofbackport.util.concurrent to Java 5.0
Message-ID: <B80488675062364A909EE60F4A66603806303D74@usilms23.ca.com>


Hi!

I would like to know if I can have a persistent queue that employs memory mapped i/o and uses LinkedBlockingQueue<> ..

Saikumar

-----Original Message-----
From: concurrency-interest-bounces@cs.oswego.edu
[mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of David
Walend
Sent: Wednesday, May 11, 2005 2:03 PM
To: concurrency-interest@altair.cs.oswego.edu
Subject: [concurrency-interest] backport: Is there a forward port
ofbackport.util.concurrent to Java 5.0


On May 11, 2005, at 11:01 AM, concurrency-interest- 
request@cs.oswego.edu wrote:

>
> Hi,
> Is there a forward port to Java 5 of the backport.util.concurrent  
> libraries?
>
> Ideally a forward port would allow interoperability between
> java.util.concurrent and backport.util.concurrent.
>
> What is the backport.util.concurrent project's thoughts on this?
> Are there any plans to Java 5 produce a forward port?
>
>

Mark,

For SomnifugiJMS, I was able to use an interface/driver pattern to  
separate out a backport version and a juc version of the code base. I  
stopped there to wait for retroweaver.

If you can wait, or want to help out, Toby plans to use the backport  
in retroweaver. That's what stopped me from branching the Somnifugi  
properly into 1.4 and 5.0 versions. Helping retroweaver use the  
backport is at least a more interesting option than adding another  
layer of abstraction.

Hope that helps,

Dave


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From mark.kralj-taylor at zen.co.uk  Wed May 11 19:01:46 2005
From: mark.kralj-taylor at zen.co.uk (mark.kralj-taylor)
Date: Wed May 11 19:01:53 2005
Subject: [concurrency-interest] backport: Is there a forward port
	ofbackport.util.concurrent to Java 5.0
In-Reply-To: <4282341A.1030005@mathcs.emory.edu>
References: <4281C584.5070100@zen.co.uk>
	<ca53c8f805051105025585d523@mail.gmail.com>
	<4282341A.1030005@mathcs.emory.edu>
Message-ID: <42828EDA.7020904@zen.co.uk>

I understand that porting from backport.util.concurrent to 
java.util.concurrent means replacing import statements, but this is not 
practical for us, let me try and elaborate...

Also my users want to avoid runtime and learning overhead of that an 
abstraction API would introduce:
- java.util.concurrent classes defines the API.
-- We definitley don't want a 'Jakarta Commons Concurrent' API that 
detects if you are using Java 5 at runtime - we are happy to make 
decision at deployment time, just not design (coding) time.
- backport.util.concurrent provides a way to use java.util.concurrent 
API with Java 1.4, tahts great, ok it uses different packages because 
java.* is special, thats fine.
--  I'm ok with import statement translation when we upgrade to require  
upgrade to Java 5, but we are not ready for that yet .....

Our situation today is of many in-house aplications owned by seperate 
teams that will each make their own decision on which JVM they run with: 
is it Java 1.4 or 5.0 and which  JVM vendor: SUN, IBM, BEA....
There are many shared libraries owned by seperate teams again, and some 
of these want to use java.util.concurrent constructs (previously we used 
oswego).
Some library APIs use low level concurrency constructs, exposing them to 
higher levels - esp. Futures, Executors etc. we don't want to write 
custom abstraction APIs and Java 1.4/5.0 integrations for these.

End result is that an app is a stack of 10+ libs (many in-house).
At an application groups level, projects want to chose which JVM to run 
with and if Java 5.0, to get performance advantages of JVM support for 
atomic operations (i.e true non-blocking data structures in 
java.util.concurrent on Java 5.0 - we have seen performance benefits 
from using atomic-operations CAS etc in C++)

A forward port of backport-util-concurrent.jar would enable projects to 
take advantage of Java 5.0 by changing a single JAR on their classpath, 
this is do-able and control of each application group.

However maintaining and deploying an entire stack of library Jars with 
different import statements is not something we see as manageable.
When we can require minimum of Java 5.0, updating imports will be fine, 
but this is some time off, probably more than a year given we will be 
moving to require Java 1.4 (rather than 1.3) in the NEXT few months - 
and some see that as being aggressive!

I hope tis helps explian why we are interested in a forward port of 
backport-util-concurrent.jar, and why we don't see replacing import 
statements as a solution for us in the medium term.

Mark

Dawid Kurzyniec wrote:

> Hanson Char wrote:
>
>> Sounds like it should belong to a separate project, analogous to the
>> Apache commons logging which acts like a facade to the actual
>> underlying implementation.  So kind of a "commons concurrent" package
>> which provides an API that allows either the backport or jdk1.5 to be
>> used, depending on the actual JVM being run.
>>
>>  
>>
> That sounds right. My suggestion would be that you create your own 
> facade API, with the stuff that you use, in versions for 1) backport 
> and 2) j.u.c., differing by import statements. An alternative is to 
> try to recompile backport with changed package names, e.g. removing 
> "edu.emory.mathcs.backport", and add the JAR to the _boot_ class path 
> on 1.4 JVMs (although I am not even sure if this will work, e.g. JVM 
> may complain about forbidden definition of java.* packages). If this 
> works, you could use j.u.c. APIs in 1.4, with the exception for things 
> like nanoTime(), as Doug mentioned.
>
> The "forward-port" of the backport is another interesting alternative, 
> but I am not sure how happy people would be to code against backport 
> packages (funny package names, no generics etc) when targetting mainly 
> 5.0. Also, this potentially could add overheads (as could, as the 
> matter of fact, the facade API) - e.g. if delegation is used, calls 
> would go through wrapper classes, and also the number of instance 
> counts would double, which could be non-negligible for lock classes 
> and atomic variables. Possible solution would be to use inheritance, 
> rather than delegation. I might consider something like this at some 
> point, but the priority for me is to complete the backport (e.g. add 
> skip-list maps).
>
> BTW. I am happy to see such a wide interest - people are asking for 
> the backport to be available on all Java versions between 1.3 and 5.0 
> :) I will try to do my best to accomodate the requests, with 
> priorities depending on the relative level of interest.
>
> Regards,
> Dawid Kurzyniec
>
>> Hanson
>>
>> On 5/11/05, mark.kralj-taylor <mark.kralj-taylor@zen.co.uk> wrote:
>>  
>>
>>> Hi,
>>> Is there a forward port to Java 5 of the backport.util.concurrent 
>>> libraries?
>>>
>>> At first this might sound a strange requrest, if running a Java 5 JVM,
>>> why not just use java.util.concurrent directly?
>>>
>>> I want to use java.util.concurrent style APIs in my libraries, but I
>>> don't control the level of JVM the code will eventually be run in.
>>> This is typical for large systems that are composed to a mixture of 
>>> open
>>> source and in-house Jars from several project teams.
>>> I have to write to the minimum JVM level that we support (Java 1.4),
>>> then other projects will choose to deploy to either a Java 1.4 or 
>>> 5.0 JVM.
>>> I don't have cycles to maintain seperate Java 1.4 and 5.0 sources or
>>> libraries I work on.
>>> It would be great if I could code to backport.util.concurrent API, then
>>> projects could choose between a Java 1.4 and Java 5.0 implementation 
>>> Jar
>>> of  backport.util.concurrent, to match their JVM.
>>>
>>> The benefits of a Java 5 forward port of java.util.concurrent, is that
>>> it lets people take advantace of an implementation optimised for Java 5
>>> atomic operations, if they are running a Java 5.0 JVM, without needing
>>> them to make any code changes.
>>> Right now my libraries are leading projects to use
>>> backport.util.concurrent APIs, which is a performance compromise on 
>>> Java
>>> 5.0 JVMs.
>>>
>>> Ideally a forward port would allow interoperability between
>>> java.util.concurrent and backport.util.concurrent.
>>>
>>> What is the backport.util.concurrent project's thoughts on this?
>>> Are there any plans to Java 5 produce a forward port?
>>>   
>>
>
>
>

From dholmes at dltech.com.au  Wed May 11 19:29:24 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Wed May 11 19:29:36 2005
Subject: [concurrency-interest] backport: Is there a forward
	portofbackport.util.concurrent to Java 5.0
In-Reply-To: <42828EDA.7020904@zen.co.uk>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEDLFLAA.dholmes@dltech.com.au>

mark kralj-taylor writes:
> we are happy to make decision at deployment time, just not
> design (coding) time.

Import statement translation is a build-time decision, not a design time
one. Whenever a project wants to use your library they build it specifying
which import to use (you could even define an Annotation for this and write
your own annotation pre-processor). Or you simply build two different jars
for your library. Managing two jars should not be a burden - and you'd need
to manage either the back-port jar of forward-port jar anyway. Actually
producing the jars needs a pre-processing phase in your compilation system.

Given the complexity of the systems you describe, managing this "switch" in
the build process should not be a major concern. Besides what alternative do
you actually have? A forward-port does not yet exist.

Cheers,
David Holmes

From Shyamal.Mehta at trilogy.com  Thu May 12 01:56:05 2005
From: Shyamal.Mehta at trilogy.com (Shyamal.Mehta@trilogy.com)
Date: Thu May 12 01:58:10 2005
Subject: [concurrency-interest] Iterator does not work after removal of last
	element
Message-ID: <OFEE4EC603.602B120C-ON65256FFF.001F5E4A@trilogy.com>

While using the LinkedBlockingQueue, I found the following behavior:

Once the remove method is called on the queue when only one element is 
present in it, the iterator returned by any subsequent calls to iterator() 
method (even after we have filled more elements in the queue), returns an 
iterator that behaves that the queue is empty.

I have attached the test program I wrote to verify this. Is it a bug or am 
I missing something?

The same behavior is shown when using JDK 1.5 too.

Thanks,
Shyamal




import edu.emory.mathcs.backport.java.util.concurrent.LinkedBlockingQueue;
import java.util.Iterator;

public class TestConcurrent 
{
        public static void main(String[] args) 
        {
        try
        {
            LinkedBlockingQueue q = new LinkedBlockingQueue();
            Integer data;
            Iterator iter;
            for (int i = 1; i <= 100 ; i++ )
            {

                data = new Integer(i);
                q.add(data);

                System.out.print("Inserted " + i + " th element. Queue 
size is " + q.size() + ". ");
                iter = q.iterator();
                int count = 0;
                while ( iter.hasNext() )
                {
                    iter.next();
                    count++;
                }
                System.out.println("Iterator found " + count + " elements. 
");
 
                /*
                Removing the element by either of the two ways (by the 
queue's 
                remove method or the iterator's remove method) results in 
an 
                iterator being returned (on the next call of iterator() 
method)
                that always behaves as if the queue is empty.
                If we use the queue's take method to remove elements, that 
works.
                */
                q.remove(data);

                /*iter = q.iterator();
                count = 0;
                while ( iter.hasNext() )
                {
                    iter.next();
                    iter.remove();
                    count++;
                }
                System.out.println(" Removed "+count+" elements.");*/
 
                //q.take();
 
            }
        }
        catch(Exception e)
        {
            e.printStackTrace();
        }
        }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20050512/b8d39e49/attachment-0001.htm
From dholmes at dltech.com.au  Thu May 12 02:41:55 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Thu May 12 02:42:06 2005
Subject: [concurrency-interest] Iterator does not work after removal of
	lastelement
In-Reply-To: <OFEE4EC603.602B120C-ON65256FFF.001F5E4A@trilogy.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEEDFLAA.dholmes@dltech.com.au>

This is a known bug. See the first listed item at:

http://gee.cs.oswego.edu/dl/concurrency-interest/post-tiger.html

and
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6215625

Unfortunately this is not yet fixed in 1.5 and we don't know yet whether it
will be.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces@cs.oswego.edu
[mailto:concurrency-interest-bounces@cs.oswego.edu]On Behalf Of
Shyamal.Mehta@trilogy.com
  Sent: Thursday, 12 May 2005 3:56 PM
  To: concurrency-interest@altair.cs.oswego.edu
  Subject: [concurrency-interest] Iterator does not work after removal of
lastelement



  While using the LinkedBlockingQueue, I found the following behavior:

  Once the remove method is called on the queue when only one element is
present in it, the iterator returned by any subsequent calls to iterator()
method (even after we have filled more elements in the queue), returns an
iterator that behaves that the queue is empty.

  I have attached the test program I wrote to verify this. Is it a bug or am
I missing something?

  The same behavior is shown when using JDK 1.5 too.

  Thanks,
  Shyamal




  import edu.emory.mathcs.backport.java.util.concurrent.LinkedBlockingQueue;
  import java.util.Iterator;

  public class TestConcurrent
  {
          public static void main(String[] args)
          {
          try
          {
              LinkedBlockingQueue q = new LinkedBlockingQueue();
              Integer data;
              Iterator iter;
              for (int i = 1; i <= 100 ; i++ )
              {

                  data = new Integer(i);
                  q.add(data);

                  System.out.print("Inserted " + i + " th element. Queue
size is " + q.size() + ". ");
                  iter = q.iterator();
                  int count = 0;
                  while ( iter.hasNext() )
                  {
                      iter.next();
                      count++;
                  }
                  System.out.println("Iterator found " + count + " elements.
");

                  /*
                  Removing the element by either of the two ways (by the
queue's
                  remove method or the iterator's remove method) results in
an
                  iterator being returned (on the next call of iterator()
method)
                  that always behaves as if the queue is empty.
                  If we use the queue's take method to remove elements, that
works.
                  */
                  q.remove(data);

                  /*iter = q.iterator();
                  count = 0;
                  while ( iter.hasNext() )
                  {
                      iter.next();
                      iter.remove();
                      count++;
                  }
                  System.out.println(" Removed "+count+" elements.");*/

                  //q.take();

              }
          }
          catch(Exception e)
          {
              e.printStackTrace();
          }
          }
  }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20050512/26cfa9c0/attachment.htm
From david at walend.net  Tue May 17 09:34:20 2005
From: david at walend.net (David Walend)
Date: Tue May 17 09:34:28 2005
Subject: [concurrency-interest] Backport in Retroweaver
Message-ID: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net>

I took some time last night to add support for the concurrency  
backport in retroweaver last night. It was pretty straightforward.  
(diff to RetroWeaver.java added to the end of this email.)

Any advice on testing? Is there a body of tests for JSR-166 that I  
can just grab, retroweave and run?

Thanks,

Dave

----

diff -r src/com/rc/retroweaver/RetroWeaver.java src.orig/com/rc/ 
retroweaver/Retr
oWeaver.java
179,185d178
<     // Change references from  "java/util/concurrent" to "edu/emory/ 
mathcs/bac
kport/java/util/concurrent"
<     //only replace java/util/concurrent if it is not already part  
of the backp
ort's string.
<     //
<     if ( (newName.indexOf( "java/util/concurrent" ) != -1 ) &&  
( newName.index
Of("edu/emory/mathcs/backport/java/util/concurrent") == -1)) {
<       newName = newName.replace( "java/util/concurrent", "edu/emory/ 
mathcs/bac
kport/java/util/concurrent" );
<     }
<
253,259d245
<
<     //only replace java/util/concurrent if it is not already in the  
backport's
string.
<     if ( (newClassName.indexOf( "java/util/concurrent" ) != -1 )
<         && ( newClassName.indexOf("edu/emory/mathcs/backport/java/ 
util/concurr
ent") == -1)) {
<         newClassName = newClassName.replace( "java/util/ 
concurrent", "edu/emor
y/mathcs/backport/java/util/concurrent" );
<     }
<
Only in src/com/rc/retroweaver: RetroWeaver.java~



David Walend
david@walend.net
http://walend.net

From dl at cs.oswego.edu  Tue May 17 09:42:12 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 17 09:42:15 2005
Subject: [concurrency-interest] Backport in Retroweaver
In-Reply-To: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net>
References: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net>
Message-ID: <4289F4B4.80508@cs.oswego.edu>

David Walend wrote:
> I took some time last night to add support for the concurrency  
> backport in retroweaver last night. It was pretty straightforward.  
> (diff to RetroWeaver.java added to the end of this email.)
> 
> Any advice on testing? Is there a body of tests for JSR-166 that I  
> can just grab, retroweave and run?
> 

All of the TCK tests are available in CVS (src/test/tck)
as are most of our random undocumented micro-benchmark-style tests
(src/test/loops), and also some tests in a form compatible with
Sun regression testing (src/test/jtreg)

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/

Warning: At the moment, most of our CVS is in a state
preparing for Mustang integration, so you will need to
make a lot of minor ad-hoc adjustments to suppress or
avoid 1.6-specific classes and functionality.

-Doug

From david at walend.net  Tue May 17 12:33:19 2005
From: david at walend.net (David Walend)
Date: Tue May 17 12:33:49 2005
Subject: [concurrency-interest] Backport in Retroweaver
In-Reply-To: <4289F4B4.80508@cs.oswego.edu>
References: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net>
	<4289F4B4.80508@cs.oswego.edu>
Message-ID: <72D59F0A-D7C3-475B-9D94-AF0FE75DBE19@walend.net>


On May 17, 2005, at 9:42 AM, Doug Lea wrote:

> David Walend wrote:
>
>> Any advice on testing? Is there a body of tests for JSR-166 that  
>> I  can just grab, retroweave and run?
>>
>
> Warning: At the moment, most of our CVS is in a state
> preparing for Mustang integration, so you will need to
> make a lot of minor ad-hoc adjustments to suppress or
> avoid 1.6-specific classes and functionality.
>

Thanks for the warning, Doug.

Someone didn't just happen to drop a tag in CVS before cutting over  
to Mustang?

How about the backport? Would it be a fair test to turn the eembjuc  
imports into juc imports, then retroweave them?

What's the best way to incorporate the tests in the retroweaver code?  
If I just copy them into retroweaver's code base, it'd be a fork.

Thanks,

Dave
From dl at cs.oswego.edu  Tue May 17 12:55:18 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 17 12:55:20 2005
Subject: [concurrency-interest] Backport in Retroweaver
In-Reply-To: <72D59F0A-D7C3-475B-9D94-AF0FE75DBE19@walend.net>
References: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net>
	<4289F4B4.80508@cs.oswego.edu>
	<72D59F0A-D7C3-475B-9D94-AF0FE75DBE19@walend.net>
Message-ID: <428A21F6.7050206@cs.oswego.edu>

David Walend wrote:

> Someone didn't just happen to drop a tag in CVS before cutting over  
> to Mustang?

Yes, but it doesn't help too much because the backport also includes
versions of bugfixes we've made since 1.5.0, and tests that were added
to cover them. It also includes backports of some 1.6 code.


-Doug
From jbaxter at panscient.com  Tue May 17 17:39:47 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Tue May 17 17:40:36 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <423A72D4.5040108@peierls.net>
References: <200503181619.58814.jbaxter@panscient.com>
	<423A72D4.5040108@peierls.net>
Message-ID: <200505180709.47821.jbaxter@panscient.com>

On Friday 18 March 2005 16:49, Tim Peierls wrote:
> Jonathan Baxter wrote:
> > Used to be really easy to create a bounded, blocking thread pool:
> >
> > PooledExecutor pe = new PooledExecutor(10);
> > pe.waitWhenBlocked();
> >
> > Was also easy to increase and decrease the maximum number of threads
> > available, via setMaximumPoolSize and createThreads.
> >
> > How do you get the same behaviour under java.util.concurrent?
>
>   ExecutorService exec = new ThreadPoolExecutor(1, 10, 1, TimeUnit.MINUTES,
>                                           new
> SynchronousQueue<Runnable>());
>
> Doesn't seem too hard. setMaximumPoolSize() is still there, and you can
> prestartAllCoreThreads() instead of createThreads().

But does this block when the pool is full? Doesn't the 
RejectedExecutionHandler get called instead? Seems that ThreadPoolExecutor 
uses BlockingQueue.offer rather than BlockingQueue.put, or am I missing 
something?

Thanks,

Jonathan 

>
> --tim
From tim at peierls.net  Tue May 17 19:04:46 2005
From: tim at peierls.net (Tim Peierls)
Date: Tue May 17 19:05:01 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <200505180709.47821.jbaxter@panscient.com>
References: <200503181619.58814.jbaxter@panscient.com>
	<423A72D4.5040108@peierls.net>
	<200505180709.47821.jbaxter@panscient.com>
Message-ID: <428A788E.3050009@peierls.net>

Jonathan Baxter wrote:
>>>Used to be really easy to create a bounded, blocking thread pool:
>>>
>>>PooledExecutor pe = new PooledExecutor(10);
>>>pe.waitWhenBlocked();
>>>
>>>Was also easy to increase and decrease the maximum number of threads
>>>available, via setMaximumPoolSize and createThreads.
>>>
>>>How do you get the same behaviour under java.util.concurrent?
>>
>> [Tim Peierls]
>>  ExecutorService exec = new ThreadPoolExecutor(1, 10, 1, TimeUnit.MINUTES,
>>                                          new SynchronousQueue<Runnable>());
>>
>>Doesn't seem too hard. setMaximumPoolSize() is still there, and you can
>>prestartAllCoreThreads() instead of createThreads().
>
> [Jonathan Baxter]
> But does this block when the pool is full? Doesn't the 
> RejectedExecutionHandler get called instead? Seems that ThreadPoolExecutor 
> uses BlockingQueue.offer rather than BlockingQueue.put, or am I missing 
> something?

 From the SynchronousQueue javadocs:

"You cannot peek at a synchronous queue because an element is only present 
when you try to take it; you cannot add an element (using any method) 
unless another thread is trying to remove it; you cannot iterate as there 
is nothing to iterate."

SynchronousQueue is a strange beast, but it's what you want here.

--tim

From jbaxter at panscient.com  Tue May 17 19:46:38 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Tue May 17 19:47:28 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <428A788E.3050009@peierls.net>
References: <200503181619.58814.jbaxter@panscient.com>
	<200505180709.47821.jbaxter@panscient.com>
	<428A788E.3050009@peierls.net>
Message-ID: <200505180916.38426.jbaxter@panscient.com>

On Wednesday 18 May 2005 08:34, Tim Peierls wrote:
> Jonathan Baxter wrote:
> >>>Used to be really easy to create a bounded, blocking thread pool:
> >>>
> >>>PooledExecutor pe = new PooledExecutor(10);
> >>>pe.waitWhenBlocked();
> >>>
> >>>Was also easy to increase and decrease the maximum number of threads
> >>>available, via setMaximumPoolSize and createThreads.
> >>>
> >>>How do you get the same behaviour under java.util.concurrent?
> >>
> >> [Tim Peierls]
> >>  ExecutorService exec = new ThreadPoolExecutor(1, 10, 1,
> >> TimeUnit.MINUTES, new SynchronousQueue<Runnable>());
> >>
> >>Doesn't seem too hard. setMaximumPoolSize() is still there, and you can
> >>prestartAllCoreThreads() instead of createThreads().
> >
> > [Jonathan Baxter]
> > But does this block when the pool is full? Doesn't the
> > RejectedExecutionHandler get called instead? Seems that
> > ThreadPoolExecutor uses BlockingQueue.offer rather than
> > BlockingQueue.put, or am I missing something?
>
>  From the SynchronousQueue javadocs:
>
> "You cannot peek at a synchronous queue because an element is only present
> when you try to take it; you cannot add an element (using any method)
> unless another thread is trying to remove it; you cannot iterate as there
> is nothing to iterate."
>
> SynchronousQueue is a strange beast, but it's what you want here.

But ThreadPoolExecutor uses the the offer method not the put method of the 
BlockingQueue, and according to the BlockingQueue documentation, offer 
returns immediately if an element cannot be added to the queue. So it doesn't 
seem to matter what kind of BlockingQueue you specify (Synchronous or 
otherwise), you're never going to get blocking behaviour. 

Looking at the source of the old PooledExecutor, the waitWhenBlocked method 
installed a BlockedExecutionHandler that explicitly invokes the put method on 
the queue. So to get the same behaviour from ThreadPoolExecutor I guess one 
could install a RejectedExecutionHandler that does the same thing, but 
explicitly accessing the BlockingQueue in the RejectedExecutionHandler seems 
dangerous. 

- Jonathan 


>
> --tim
From tim at peierls.net  Tue May 17 20:31:03 2005
From: tim at peierls.net (Tim Peierls)
Date: Tue May 17 20:31:13 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <200505180916.38426.jbaxter@panscient.com>
References: <200503181619.58814.jbaxter@panscient.com>
	<200505180709.47821.jbaxter@panscient.com>
	<428A788E.3050009@peierls.net>
	<200505180916.38426.jbaxter@panscient.com>
Message-ID: <428A8CC7.4080006@peierls.net>

Jonathan Baxter wrote:
>>>> ExecutorService exec = new ThreadPoolExecutor(1, 10, 1,
>>>>          TimeUnit.MINUTES, new SynchronousQueue<Runnable>());
> 
> But ThreadPoolExecutor uses the the offer method not the put method of the 
> BlockingQueue, and according to the BlockingQueue documentation, offer 
> returns immediately if an element cannot be added to the queue. So it doesn't 
> seem to matter what kind of BlockingQueue you specify (Synchronous or 
> otherwise), you're never going to get blocking behaviour. 

Yup, ignore my previous mail. As you say, while pool is at max, it will 
reject further tasks.

I suppose you could extend SynchronousQueue with an offer method that does 
block. But I don't understand why you *want* to block the calling thread. 
You could use CallerRunsPolicy to run the rejected task in the calling 
thread, which would be like blocking, except it would get some work done. 
You could use the default policy and catch RejectedExcutionException, do 
some work, and try again. Both of these seem preferable to just sitting 
there indefinitely waiting for the pool to open up.

--tim

From jbaxter at panscient.com  Tue May 17 20:43:52 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Tue May 17 20:44:36 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <428A8CC7.4080006@peierls.net>
References: <200503181619.58814.jbaxter@panscient.com>
	<200505180916.38426.jbaxter@panscient.com>
	<428A8CC7.4080006@peierls.net>
Message-ID: <200505181013.52698.jbaxter@panscient.com>

> Yup, ignore my previous mail. As you say, while pool is at max, it will
> reject further tasks.
>
> I suppose you could extend SynchronousQueue with an offer method that does
> block. But I don't understand why you *want* to block the calling thread.
> You could use CallerRunsPolicy to run the rejected task in the calling
> thread, which would be like blocking, except it would get some work done.
> You could use the default policy and catch RejectedExcutionException, do
> some work, and try again. Both of these seem preferable to just sitting
> there indefinitely waiting for the pool to open up.


Blocking behaviour can be very useful if you have interacting thread pools 
doing different kinds of work. Eg, thread pool a does work A, and then hands 
off to thread pool B that does work B. If the resource consumption patterns 
of work A and work B are very different (eg A waits on the network while B is 
computationally intensive), then it can be handy to have the workers in A 
block when handing off to a worker in B, so that the B work doesn't keep 
growing and chew up all the resources. 

Suffice it to say there are plenty of use cases, and that the old concurrent 
code supported this easily. It is somewhat surprising that that the new 
package makes this almost impossible to do in an elegant way. 


- Jonathan 

>
> --tim
From dholmes at dltech.com.au  Tue May 17 21:22:20 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Tue May 17 21:22:28 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <200505181013.52698.jbaxter@panscient.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>

Jonathan Baxter wrote:
> Suffice it to say there are plenty of use cases, and that the old
> concurrent
> code supported this easily. It is somewhat surprising that that the new
> package makes this almost impossible to do in an elegant way.

I have to agree. Using blocking for flow control is extremely reasonable.
I'm quite surprised that this has turned out to be so difficult.

Defining a RejectedExecutionHandler that interacts with the queue to do a
blocking put seems like a reasonable approach in principle, but there are no
guarantees it will work as you don't know what the pool does with a command
before submitting to the queue (ie wrapping in some internal housekeeping
class).

David Holmes

From brian at quiotix.com  Tue May 17 22:10:37 2005
From: brian at quiotix.com (Brian Goetz)
Date: Tue May 17 22:10:45 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
Message-ID: <428AA41D.5040104@quiotix.com>

> I have to agree. Using blocking for flow control is extremely reasonable.
> I'm quite surprised that this has turned out to be so difficult.
> 
> Defining a RejectedExecutionHandler that interacts with the queue to do a
> blocking put seems like a reasonable approach in principle, but there are no
> guarantees it will work as you don't know what the pool does with a command
> before submitting to the queue (ie wrapping in some internal housekeeping
> class).

We had this discussion a few weeks ago on the -jsr list, where I also 
asked why there was no way to effectively execute() block, which would 
provide both throttling (the same way that caller-runs does) and 
preserve in-order execution (which caller-runs does not.)  Doug 
responded that in practice, this policy was not as sound as it, well, 
sounds.
From jbaxter at panscient.com  Wed May 18 02:51:17 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Wed May 18 02:52:17 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <428AA41D.5040104@quiotix.com>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
	<428AA41D.5040104@quiotix.com>
Message-ID: <200505181621.17304.jbaxter@panscient.com>

On Wednesday 18 May 2005 11:40, Brian Goetz wrote:
> We had this discussion a few weeks ago on the -jsr list, where I also
> asked why there was no way to effectively execute() block, which would
> provide both throttling (the same way that caller-runs does) and
> preserve in-order execution (which caller-runs does not.)  Doug
> responded that in practice, this policy was not as sound as it, well,
> sounds.

Is that list public? Can you cross post Doug's reasoning here? If the problem 
is primarily one of guaranteeing in-order execution, I'd happy to give that 
away in return for some kind of approximate guarantee modulo starvation. IMO, 
Blocked execution for flow control is way too useful a baby to throw out with 
the bathwater. 
From brian at quiotix.com  Wed May 18 03:27:17 2005
From: brian at quiotix.com (Brian Goetz)
Date: Wed May 18 03:27:24 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <200505181621.17304.jbaxter@panscient.com>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
	<428AA41D.5040104@quiotix.com>
	<200505181621.17304.jbaxter@panscient.com>
Message-ID: <428AEE55.8080708@quiotix.com>

> Is that list public? Can you cross post Doug's reasoning here? If the problem 
> is primarily one of guaranteeing in-order execution, I'd happy to give that 
> away in return for some kind of approximate guarantee modulo starvation. IMO, 
> Blocked execution for flow control is way too useful a baby to throw out with 
> the bathwater. 

If you don't care about in-order execution, then you can simply use the 
"caller runs" rejected execution handler.  The result is that the new 
task will be execute in the thread of the submitter, which has the 
effect of throttling that thread's ability to generate more load, giving 
the pool some time to catch up.
From jbaxter at panscient.com  Wed May 18 05:04:27 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Wed May 18 05:04:35 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <428AEE55.8080708@quiotix.com>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
	<200505181621.17304.jbaxter@panscient.com>
	<428AEE55.8080708@quiotix.com>
Message-ID: <200505181834.27620.jbaxter@panscient.com>

> If you don't care about in-order execution, then you can simply use the
> "caller runs" rejected execution handler.  The result is that the new
> task will be execute in the thread of the submitter, which has the
> effect of throttling that thread's ability to generate more load, giving
> the pool some time to catch up.

This doesn't work for the use case in my original post: two separate thread 
pools with different resource usage characteristics. Eg, threads in pool A 
run a low-cpu task that spends most of its time waiting on the network - say 
100 threads. Threads in pool B run a high-cpu task, and is deliberately set 
small so as not to overwhelm the jvm - say 5 threads. If the threads in pool 
A implement "caller runs" as they hand-off to thread pool B, you can end up 
starving the rest of the threads in pool A: eg 80 threads in A executing 
their work, 20 executing thread pool B work as "caller runs", and another 5 
in pool B executing their work. Instead of bounding the resources consumed by 
pool B you have 5 times as many threads executing B work as you tuned for. 

More abstractly, it seems to me that "caller runs" isn't necessarily the right 
thing to do if there is an "impedance mismatch" between the two worker pools. 
Whereas if thread pool B blocks on handoff, you might end up with 20 pool A 
threads waiting to submit work to pool B, but that is preferable to 
potentially killing the jvm by overloading on pool B work.  
From A.Solofnenko at mdl.com  Tue May 17 21:15:46 2005
From: A.Solofnenko at mdl.com (Alexey N. Solofnenko)
Date: Wed May 18 09:34:20 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <428A8CC7.4080006@peierls.net>
References: <200503181619.58814.jbaxter@panscient.com>
	<200505180709.47821.jbaxter@panscient.com>
	<428A788E.3050009@peierls.net>
	<200505180916.38426.jbaxter@panscient.com>
	<428A8CC7.4080006@peierls.net>
Message-ID: <428A9742.6040304@mdl.com>



Tim Peierls wrote:

> I suppose you could extend SynchronousQueue with an offer method that 
> does block. But I don't understand why you *want* to block the calling 
> thread. You could use CallerRunsPolicy to run the rejected task in the 
> calling thread, which would be like blocking, except it would get some 
> work done. You could use the default policy and catch 
> RejectedExcutionException, do some work, and try again. Both of these 
> seem preferable to just sitting there indefinitely waiting for the 
> pool to open up.
>
One would not want to do that to limit a number of concurrently executed 
tasks.

- Alexey.

> --tim
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


-- 
------------------------------------------------------------------------
/ Alexey N. Solofnenko
home: http://trelony.cjb.net/
/
From dl at cs.oswego.edu  Wed May 18 09:50:07 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed May 18 09:56:22 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <200505181621.17304.jbaxter@panscient.com>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
	<428AA41D.5040104@quiotix.com>
	<200505181621.17304.jbaxter@panscient.com>
Message-ID: <1116424207.4765.18.camel@localhost.localdomain>

On Wed, 2005-05-18 at 16:21 +0930, Jonathan Baxter wrote:

> Is that list public? Can you cross post Doug's reasoning here? If the problem 
> is primarily one of guaranteeing in-order execution, I'd happy to give that 
> away in return for some kind of approximate guarantee modulo starvation. IMO, 
> Blocked execution for flow control is way too useful a baby to throw out with 
> the bathwater. 


I'm away at some meetings (greetings from Dublin) so can't dig them
out easily at the moment, but the reasons for omitting waitWhenBlocked
were: 

(1) It was the single biggest source of bug-reports in
dl.util.concurrent because its range of correct operation is
very small -- you have to use just the right combinations of
other parameters, and even so there are inherent races you need
to be aware of. (For example, some common utility in JBoss had
consequential problems along these lines until they changed it.)  

(2) As Tim mentioned, a version supporting it really ought to
be able to cancel out on interruption, which the new API doesn't
support (for good reasons).

So my main conclusion here was that if you are smart enough to
know exactly how you'd like this to work, you don't need
us to build it for you :-)

-Doug


From dawidk at mathcs.emory.edu  Wed May 18 13:49:58 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed May 18 13:50:12 2005
Subject: [concurrency-interest] Backport in Retroweaver
In-Reply-To: <72D59F0A-D7C3-475B-9D94-AF0FE75DBE19@walend.net>
References: <36BD202B-ABC3-408F-99BD-C267E6CB0459@walend.net><4289F4B4.80508	@cs.oswego.edu>
	<72D59F0A-D7C3-475B-9D94-AF0FE75DBE19@walend.net>
Message-ID: <428B8046.3000307@mathcs.emory.edu>

David Walend wrote:

>
> On May 17, 2005, at 9:42 AM, Doug Lea wrote:
>
>> David Walend wrote:
>>
>>> Any advice on testing? Is there a body of tests for JSR-166 that  I  
>>> can just grab, retroweave and run?
>>>
>>
>> Warning: At the moment, most of our CVS is in a state
>> preparing for Mustang integration, so you will need to
>> make a lot of minor ad-hoc adjustments to suppress or
>> avoid 1.6-specific classes and functionality.
>>
>
You also need to keep in mind that the backport is actually somewhere in 
the middle between Java 5.0 and Mustang. I incorporated fixes and tests 
to bugs found before Feb 7, and I've put in new features which are not 
available in Java 5.0. The "since" tags indicate whether a given piece 
of functionality is in 5.0. (Except for some TimeUnits, which I need to 
fix).

> How about the backport? Would it be a fair test to turn the eembjuc  
> imports into juc imports, then retroweave them?

You could, but I would be careful, since the API mapping is not 100% 
one-one:
1) eembjuc tests have all generics stuff removed,
2) System.nanoTime() is moved to helpers.Utils,
3) Thread.UncaughtExceptionHandler is emulated by helpers.ThreadHelpers

>
> What's the best way to incorporate the tests in the retroweaver code?  
> If I just copy them into retroweaver's code base, it'd be a fork.
>
I took the sources from Doug and made the necessary changes; I bring it 
up-to-date by applying CVS diffs from JSR 166 repository. So far, 
maintaining it was not terribly problematic.

Hope this helps,
Dawid


BTW. I think I will implement the "forward-backport" that was asked for 
some time ago, i.e. port to 5.0 that maintains binary and source 
compatibility with applications written against eembjuc, but attaining 
native speeds on 5.0. It seems simple enough, and useful enough. One of 
the main motivations is the observation that sometimes you may not have 
access to the source code, so you can't change package names and 
recompile, but you'd still like to take advantage of native j.u.c. support.


From jbaxter at panscient.com  Wed May 18 19:52:54 2005
From: jbaxter at panscient.com (Jonathan Baxter)
Date: Wed May 18 19:53:09 2005
Subject: [concurrency-interest] PooledExecutor vs java.util.concurrent
In-Reply-To: <1116424207.4765.18.camel@localhost.localdomain>
References: <NFBBKALFDCPFIDBNKAPCAEJPFLAA.dholmes@dltech.com.au>
	<200505181621.17304.jbaxter@panscient.com>
	<1116424207.4765.18.camel@localhost.localdomain>
Message-ID: <200505190922.54160.jbaxter@panscient.com>

On Wednesday 18 May 2005 23:20, Doug Lea wrote:
> I'm away at some meetings (greetings from Dublin) so can't dig them
> out easily at the moment, but the reasons for omitting waitWhenBlocked
> were:
>
> (1) It was the single biggest source of bug-reports in
> dl.util.concurrent because its range of correct operation is
> very small -- you have to use just the right combinations of
> other parameters, and even so there are inherent races you need
> to be aware of. (For example, some common utility in JBoss had
> consequential problems along these lines until they changed it.)
>
> (2) As Tim mentioned, a version supporting it really ought to
> be able to cancel out on interruption, which the new API doesn't
> support (for good reasons).
>
> So my main conclusion here was that if you are smart enough to
> know exactly how you'd like this to work, you don't need
> us to build it for you :-)

Well, that's something you could say of _any_ higher-level API functionality. 
Eg, I'm smart enough to know exactly how I'd like a HashSet to work, but that 
doesn't mean I want to roll my own :-)

Anyway, the old code does the trick for me so I am happy to continue using it. 

- Jonathan 

From Pete.Soper at Sun.COM  Thu May 19 12:07:50 2005
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Thu May 19 12:08:01 2005
Subject: [concurrency-interest] juc book now or later & Tiger cheat sheet?
Message-ID: <428CB9D6.1050808@Sun.COM>


A friend leading a reading group wonders about the value of reading 
Doug's concurrency book now vs waiting for the update that syncs it with 
the Tiger APIs. Has anybody made a "translation table" to relate APIs in 
the book to Tiger APIs where there are name or other differences?

-Pete
From brian at quiotix.com  Thu May 19 13:33:04 2005
From: brian at quiotix.com (Brian Goetz)
Date: Thu May 19 13:33:01 2005
Subject: [concurrency-interest] juc book now or later & Tiger cheat sheet?
In-Reply-To: <428CB9D6.1050808@Sun.COM>
References: <428CB9D6.1050808@Sun.COM>
Message-ID: <428CCDD0.6020508@quiotix.com>

Short answer: You should read Doug's book now, and later, and then again 
a few times.

You should also look for Java Concurrency in Practice, coming in Q4/2005 
from the people that brought you java.util.concurrent.

> A friend leading a reading group wonders about the value of reading 
> Doug's concurrency book now vs waiting for the update that syncs it with 
> the Tiger APIs. Has anybody made a "translation table" to relate APIs in 
> the book to Tiger APIs where there are name or other differences?
From jozart at blarg.net  Sun May 22 13:51:53 2005
From: jozart at blarg.net (Joe Bowbeer)
Date: Sun May 22 13:52:09 2005
Subject: [concurrency-interest] Swing Threads article updated
Message-ID: <98cf1af15b7fb5ebcc8c895a1102afb5@blargmail.com>

Now featured at javadesktop.org:

Proving that "the last word" never really is, Joseph Bowbeer has just updated this Swing Connection article to reflect the java.util.concurrent package that debuted in JDK 5.0. The article features SwingWorker, a form of which will be included in JDK 6.0 if RFE 4681682 is approved.

Links:

The Last Word in Swing Threads [updated]
http://java.sun.com/products/jfc/tsc/articles/threads/threads3.html

RFE: Include SwingWorker with the JDK
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4681682


From gregg at cytetech.com  Sun May 22 21:59:50 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Sun May 22 22:00:06 2005
Subject: [concurrency-interest] Swing Threads article updated
In-Reply-To: <98cf1af15b7fb5ebcc8c895a1102afb5@blargmail.com>
References: <98cf1af15b7fb5ebcc8c895a1102afb5@blargmail.com>
Message-ID: <42913916.7010109@cytetech.com>

Joe Bowbeer wrote:
> Now featured at javadesktop.org:
> 
> Proving that "the last word" never really is, Joseph Bowbeer has just updated this Swing Connection article to reflect the java.util.concurrent package that debuted in JDK 5.0. The article features SwingWorker, a form of which will be included in JDK 6.0 if RFE 4681682 is approved.

Please have a look at the ComponentUpdateThread class in 
swingutil.dev.java.net for an expansion of SwingWorker that includes 
some helpful, additional features for UIs dealing with remote or long 
running operations.

Gregg Wonderly
From jean.morissette666 at videotron.ca  Mon May 23 13:09:38 2005
From: jean.morissette666 at videotron.ca (Jean Morissette)
Date: Mon May 23 13:09:30 2005
Subject: [concurrency-interest] synchronized vs ReentrantLock semantic
Message-ID: <200505231309.39189.jean.morissette666@videotron.ca>

Hi all,
	I would like to know whether replacing "synchronized" statement by 
ReentrantLock instances has the same semantic and meaning for the jvm?  By 
exemple, I'm wondering whether ReentrantLock would allow reliable 
transmission of values or sets of values from one thread to another through 
shared variables?

Thanks,
-Jean
From dl at cs.oswego.edu  Mon May 23 13:23:45 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon May 23 13:23:47 2005
Subject: [concurrency-interest] synchronized vs ReentrantLock semantic
In-Reply-To: <200505231309.39189.jean.morissette666@videotron.ca>
References: <200505231309.39189.jean.morissette666@videotron.ca>
Message-ID: <429211A1.707@cs.oswego.edu>

Jean Morissette wrote:
> Hi all,
> 	I would like to know whether replacing "synchronized" statement by 
> ReentrantLock instances has the same semantic and meaning for the jvm?  By 
> exemple, I'm wondering whether ReentrantLock would allow reliable 
> transmission of values or sets of values from one thread to another through 
> shared variables?
>

yes. See the javadoc for the Lock interface, that says:

Memory Synchronization

All Lock implementations must enforce the same memory synchronization 
semantics as provided by the built-in monitor lock:

     * A successful lock operation acts like a successful monitorEnter 
action
     * A successful unlock operation acts like a successful monitorExit 
action



...

-Doug
From dl at cs.oswego.edu  Tue May 24 09:31:30 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 24 09:31:32 2005
Subject: [concurrency-interest] AtomicX.lazySet
Message-ID: <42932CB2.4030603@cs.oswego.edu>


As probably the last little JSR166 follow-up for Mustang,
we added a "lazySet" method to the Atomic classes
(AtomicInteger, AtomicReference, etc). This is a niche
method that is sometimes useful when fine-tuning code using
non-blocking data structures. The semantics are
that the write is guaranteed not to be re-ordered with any
previous write, but may be reordered with subsequent operations
(or equivalently, might not be visible to other threads) until
some other volatile write or synchronizing action occurs).

The main use case is for nulling out fields of nodes in
non-blocking data structures solely for the sake of avoiding
long-term garbage retention; it applies when it is harmless
if other threads see non-null values for a while, but you'd
like to ensure that structures are eventually GCable. In such
cases, you can get better performance by avoiding
the costs of the null volatile-write. There are a few
other use cases along these lines for non-reference-based
atomics as well, so the method is supported across all of the
AtomicX classes.

For people who like to think of these operations in terms of
machine-level barriers on common multiprocessors, lazySet
provides a preceeding store-store barrier (which is either
a no-op or very cheap on current platforms), but no
store-load barrier (which is usually the expensive part
of a volatile-write).

-Doug





From TAlison at ameritrade.com  Tue May 24 16:12:36 2005
From: TAlison at ameritrade.com (TAlison@ameritrade.com)
Date: Tue May 24 16:12:59 2005
Subject: [concurrency-interest] ScheduledThreadPoolExecutor lost exception?
Message-ID: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>

I'm extending ScheduledThreadPoolExecutor to implement the afterExecute
method so that I can log any runtime exceptions thrown by scheduled
tasks. However, I've found that runtime exceptions do not actually make
it to afterExecute. It appears the Sync used by the FutureTask that
wraps the scheduled task catches the exception and calls setException
but does not rethrow it. Thus, the runTask method of
ThreadPoolExecutor$Worker never passes it to to afterExecute. 
 
So, even if an exception is thrown, it is masked by the FutureTask
wrapper and the Worker class thinks the task ran successfully. Is this a
bug or am I interpreting the usage of afterExecute incorrectly? I'm
running JDK 5.0 Update 3.
 
Example:
 
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
 
public class SchedulerExample extends ScheduledThreadPoolExecutor
{
 
    public SchedulerExample(int threads)
    {
        super(threads);
    }
 
    /**
     * @param args
     */
    public static void main(String[] args)
    {
        ScheduledExecutorService executor = new SchedulerExample(5);
        executor.schedule(new ExceptionRunnable(), 1, TimeUnit.SECONDS);
    }
 
    static class ExceptionRunnable implements Runnable
    {
        public void run()
        {
            System.out.println("Throwing a runtime exception.");
            String npe = null;
            System.out.println(npe.toString() + ": Null pointer
exception should have been thrown.");
        }
    }
 
    @Override
    protected void afterExecute(Runnable r, Throwable t)
    {
        super.afterExecute(r, t);
 
        System.out.println("Executing afterExecute. Throwable is " + t);
        if (t != null)
            t.printStackTrace();
    }
}


From dl at cs.oswego.edu  Tue May 24 16:38:07 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 24 16:38:10 2005
Subject: [concurrency-interest] ScheduledThreadPoolExecutor lost exception?
In-Reply-To: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>
References: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>
Message-ID: <429390AF.1090605@cs.oswego.edu>

TAlison@ameritrade.com wrote:
> I'm extending ScheduledThreadPoolExecutor to implement the afterExecute
> method so that I can log any runtime exceptions thrown by scheduled
> tasks. However, I've found that runtime exceptions do not actually make
> it to afterExecute. It appears the Sync used by the FutureTask that
> wraps the scheduled task catches the exception and calls setException
> but does not rethrow it. Thus, the runTask method of
> ThreadPoolExecutor$Worker never passes it to to afterExecute. 


A periodic task is not considered to have completed until
it is cancelled -- its run() method is repeatedly called until then.
So, afterExecute is only called after the final re-running.

The spec is not the least bit clear about this though.
Sorry, and thanks for reporting it!

Additionally, it would be equally sensible to do this
the way you expected it to work.

We'll discuss whether we should clarify or change the spec and/or
the code.

-Doug
From dl at cs.oswego.edu  Tue May 24 16:43:44 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 24 16:43:46 2005
Subject: [concurrency-interest] ScheduledThreadPoolExecutor lost exception?
In-Reply-To: <429390AF.1090605@cs.oswego.edu>
References: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>
	<429390AF.1090605@cs.oswego.edu>
Message-ID: <42939200.4080203@cs.oswego.edu>

I mis-wrote...

> TAlison@ameritrade.com wrote:

> A periodic task is not considered to have completed until
> it is cancelled -- its run() method is repeatedly called until then.
> So, afterExecute is only called after the final re-running.

Sorry, afterExecute is called, but the return value and exception
are suppressed/ignored until completion. Which the spec doesn't say will
happen , so is very arguably a bug, that should be fixed.

-Doug
From dl at cs.oswego.edu  Tue May 24 19:46:50 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue May 24 19:46:54 2005
Subject: [concurrency-interest] ScheduledThreadPoolExecutor lost exception?
In-Reply-To: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>
References: <3578F9EC5CB8D447A840B64145AFEB7E030CF9@scsdcmail1.prod-am.ameritrade.com>
Message-ID: <4293BCEA.6050600@cs.oswego.edu>

TAlison@ameritrade.com wrote:
> I'm extending ScheduledThreadPoolExecutor to implement the afterExecute
> method so that I can log any runtime exceptions thrown by scheduled
> tasks. However, I've found that runtime exceptions do not actually make
> it to afterExecute. It appears the Sync used by the FutureTask that
> wraps the scheduled task catches the exception and calls setException
> but does not rethrow it. Thus, the runTask method of
> ThreadPoolExecutor$Worker never passes it to to afterExecute. 
>  
> So, even if an exception is thrown, it is masked by the FutureTask
> wrapper and the Worker class thinks the task ran successfully. Is this a
> bug or am I interpreting the usage of afterExecute incorrectly? I'm
> running JDK 5.0 Update 3.
>  


Ignore my previous responses. Sorry.

The current behavior is correct. It is however confusing
(even to me!) and should/will be clarified.

Submitted actions in ScheduledThreadPoolExecutors are
maintained as tasks (of type ScheduledFuture) that are returned from the
various schedule methods. These tasks contain computations and report
back status and results. Thus, if an inner computation throws
an exception, the task's get() method will in turn throw it if
probed via get().

Because these kinds of exceptions are contained, the executor should not
and does not see them -- afterExecute should/does see only any
exceptions that the containing task itself throws.

So, if you'd like to trap/log internal exceptions, the supported way
to do it is:

   ScheduledFuture<?> task =
     executor.schedule(new ExceptionRunnable(), 1, TimeUnit.SECONDS);
   try {
     task.get();
   } catch(ExecutionException ex) {
     ... do something with ex.getCause() ...
   }

Note: as of Mustang you will be able to override
the concrete task class (using ScheduledThreadPoolExecutor.decorateTask)
which would allow you to create one that rethrows an inner exception
so that afterExecute will see it, if that's what you really want to do.

Sorry again for the confusion.

(Note to self. Impose a one-hour minimum before replying
to bug report mail :-)


-Doug


From cnmaclean at hotmail.com  Mon May 30 07:22:30 2005
From: cnmaclean at hotmail.com (Calum MacLean)
Date: Mon May 30 07:32:35 2005
Subject: [concurrency-interest] Use of blocked queues
Message-ID: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>

Hi

I'm wanting to use a blocked queue.

In my particular usage, when adding to the queue, I want to check if there 
are any readers which are blocked, waiting for something to arrive on the 
queue.  This is so that, if no readers are waiting, I fire off an event.

Is this possible using any of the java.util.concurrency blocking queues? I 
currently can't see a way to do this using the existing classes.  I want to 
avoid reinventing the wheel if necessary!

Thanks,
Calum


From dl at cs.oswego.edu  Mon May 30 08:27:29 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon May 30 08:27:32 2005
Subject: [concurrency-interest] Use of blocked queues
In-Reply-To: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
References: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
Message-ID: <429B06B1.4050908@cs.oswego.edu>

Calum MacLean wrote:
> Hi
> 
> I'm wanting to use a blocked queue.
> 
> In my particular usage, when adding to the queue, I want to check if there 
> are any readers which are blocked, waiting for something to arrive on the 
> queue.  This is so that, if no readers are waiting, I fire off an event.
> 
> Is this possible using any of the java.util.concurrency blocking queues? I 
> currently can't see a way to do this using the existing classes.  I want to 
> avoid reinventing the wheel if necessary!
> 

First, be aware that this sort of design has an intrinsic race.
Even if it looks like there are no threads waiting when you
check, by the time you issue the event, there may be some.
So your overall design must be able to accommodate false alarms.

Given this, from what I understand of your intent,
I think you can do something like:
   if (!q.offer(data)) {
     fireEvent();
     q.put(data);
   }

-Doug
From matthias.ernst at coremedia.com  Mon May 30 08:41:26 2005
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Mon May 30 08:41:31 2005
Subject: AW: [concurrency-interest] Use of blocked queues
Message-ID: <F34C8A704C489B46B9E9FBDBD1B91D5FC04508@MARS.coremedia.com>

> In my particular usage, when adding to the queue, I want to 
> check if there are any readers which are blocked, waiting for 
> something to arrive on the queue.  This is so that, if no 
> readers are waiting, I fire off an event.

> I want to avoid reinventing the wheel 
> if necessary!

Just wondering: are you maybe reinventing a thread pool? If fireEvent()
causes a new reader to be created
that sounds a lot like it.

Matthias

From yechielf at gigaspaces.com  Mon May 30 09:48:19 2005
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Mon May 30 08:44:52 2005
Subject: [concurrency-interest] increment()/decrement() methods on
	atomicInteger ?
Message-ID: <D166C96F43D1D611B8E3000255A0C48C6BDF02@OFFICESRV>

Hi
In some cases it is desirable to increment/decrement an atomic integer,
without getting the result (for example- in a set implementation when you
add/remove an element (updating an atomic "size" which is just a
"recommendation").  Would'nt it be helpful to add
increment/decrement methods, which donot return a value ?  Assuming  that an
atomic increment can be delegated to the 
processor level (at least for volatile) - this can save the CAS retry cycle

Regards,
Yechiel Fefer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20050530/13b48c42/attachment.htm
From dl at cs.oswego.edu  Mon May 30 08:49:46 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon May 30 08:49:48 2005
Subject: [concurrency-interest] Use of blocked queues
In-Reply-To: <429B06B1.4050908@cs.oswego.edu>
References: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
	<429B06B1.4050908@cs.oswego.edu>
Message-ID: <429B0BEA.5000807@cs.oswego.edu>

I wrote:
> 
> Given this, from what I understand of your intent,
> I think you can do something like:
>    if (!q.offer(data)) {
>      fireEvent();
>      q.put(data);
>    }
> 
>

I should have noted that this snippet is only reliable for
SynchronousQueues, which may or may not be best for you here.
If you use a queue with storage (LinkedBlockingQueue etc),
you probably want to always fire an event, because offer() cannot
distinguish queuing from taking by another thread.
While you might be able to heuristically cut down on the number of
events by first putting the item, and then checking of the queue
is still empty, this won't do a lot of good because even if
there is a waiting taker, it usually will not have completely taken the
item by the time you check.

-Doug

From dl at cs.oswego.edu  Mon May 30 08:59:31 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon May 30 08:59:32 2005
Subject: [concurrency-interest] increment()/decrement() methods
	on	atomicInteger ?
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BDF02@OFFICESRV>
References: <D166C96F43D1D611B8E3000255A0C48C6BDF02@OFFICESRV>
Message-ID: <429B0E33.2030701@cs.oswego.edu>

Yechiel Feffer wrote:
> Hi
> In some cases it is desirable to increment/decrement an atomic integer, 
> without getting the result (for example- in a set implementation when 
> you add/remove an element (updating an atomic "size" which is just a 
> "recommendation").  Would'nt it be helpful to add
> 
> increment/decrement methods, which donot return a value ?  Assuming  
> that an atomic increment can be delegated to the
> processor level (at least for volatile) - this can save the CAS retry cycle
> 

Consider using the weakCompareAndSet method for this sort of thing.

   void maybeIncrement(AtomicInteger k) {
      int oldValue = k.get();
      k.weakCompareAndSet(oldValue, oldValue+1);
   }

Disclaimer: On x86, amd64, and sparc in hotspot, weakCompareAndSet and 
compareAndSet
map to the same instruction, so you won't see much difference.

-Doug
From cnmaclean at hotmail.com  Mon May 30 09:22:24 2005
From: cnmaclean at hotmail.com (Calum MacLean)
Date: Mon May 30 09:43:29 2005
Subject: [concurrency-interest] Use of blocked queues
References: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
	<429B06B1.4050908@cs.oswego.edu> <429B0BEA.5000807@cs.oswego.edu>
Message-ID: <BAY101-DAV11B08C773E617989E6B47BAB030@phx.gbl>

You're correct - I was planning using a LinkedBlockingQueue, so offer() 
wouldn't work.

I'll step back to explain my purpose.
My application is getting "messages" sent from a socket.  What I want to do 
is provide a generic interface for receiving these messages, which allow 
clients to choose whether to read them (and therefore block if there are 
none available) or to poll them (i.e. non-blocking).
For the clients which are using polling, I additionally want to provide a 
notification mechanism for when events arrive in and have not (immediately) 
been read by a waiting reader.
So it looks something like this (simplifying a little):
    interface MessageSource
    {
        Message read();
        Message poll();
        addMessageAvailableListener(MessageAvailableListener listener);
        removeMessageAvailableListener(MessageAvailableListener listener);
    }

I'd also say that the listener is intended to indicate that a new message 
has come in, which hasn't been read immediately, but there's no guarantee 
intended of whether it will still be there when you poll.  So the race 
condition you mentioned is OK.  Also, in most situations there would be a 
single client, choosing to use either reading or polling; so typically the 
occurrence of the race condition would be avoided because the client would 
just be using a single mechanism for reading.

I can achieve this relatively easily directly, by using a common object for 
synchronising around, and keeping a note of the number of readers.  But I 
thought that part of the raison-d'etre of java.util.concurrency was so that 
most uses of concurrency could use the higher level constructs (queues 
etc.), and not have to worry about using locks etc. directly.  So I was 
wondering if I was missing something in how I could achieve what I wanted to 
do.

I'd also note that, if I synchronise around e.g. a LinkedList, then I can 
synchronise around it for things other than putting/taking.  But I can't get 
a handle on the internal locks within (e.g.) LinedBlockingQueue to do 
something similar there.

Thanks for your help,
Calum


>I wrote:
>>
>> Given this, from what I understand of your intent,
>> I think you can do something like:
>>    if (!q.offer(data)) {
>>      fireEvent();
>>      q.put(data);
>>    }
>>
>
> I should have noted that this snippet is only reliable for
> SynchronousQueues, which may or may not be best for you here.
> If you use a queue with storage (LinkedBlockingQueue etc),
> you probably want to always fire an event, because offer() cannot
> distinguish queuing from taking by another thread.
> While you might be able to heuristically cut down on the number of
> events by first putting the item, and then checking of the queue
> is still empty, this won't do a lot of good because even if
> there is a waiting taker, it usually will not have completely taken the
> item by the time you check.
>
> -Doug
>
> 
From dl at cs.oswego.edu  Mon May 30 09:43:47 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon May 30 09:43:50 2005
Subject: [concurrency-interest] Use of blocked queues
In-Reply-To: <BAY101-DAV11B08C773E617989E6B47BAB030@phx.gbl>
References: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
	<429B06B1.4050908@cs.oswego.edu> <429B0BEA.5000807@cs.oswego.edu>
	<BAY101-DAV11B08C773E617989E6B47BAB030@phx.gbl>
Message-ID: <429B1893.2030004@cs.oswego.edu>

Calum MacLean wrote:

> I can achieve this relatively easily directly, by using a common object for 
> synchronising around, and keeping a note of the number of readers.  

Except that the reader count will not include any thread currently
blocked on that lock waiting to get in while you are checking, which is
exactly the race condition you'd have otherwise. So, while you might
be able to reduce unnecessary events using something like this,
you can't eliminate them, and if this lock becomes highly contended,
you might find that it is faster overall to just unconditionally
issue events. Or maybe not. But I don't see anything that adding
any capability to java.util.concurrent would help with here.


-Doug







From brian at quiotix.com  Mon May 30 14:49:00 2005
From: brian at quiotix.com (Brian Goetz)
Date: Mon May 30 14:56:56 2005
Subject: [concurrency-interest] increment()/decrement() methods
	on	atomicInteger ?
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BDF02@OFFICESRV>
References: <D166C96F43D1D611B8E3000255A0C48C6BDF02@OFFICESRV>
Message-ID: <429B601C.3050304@quiotix.com>

  In some cases it is desirable to increment/decrement an atomic integer,
> without getting the result (for example- in a set implementation when 
> you add/remove an element (updating an atomic "size" which is just a 
> "recommendation").  Would'nt it be helpful to add
> 
> increment/decrement methods, which donot return a value ?  Assuming  
> that an atomic increment can be delegated to the
> processor level (at least for volatile) - this can save the CAS retry cycle

This does not save the CAS retry cycle.  Increment looks like this:

while (true) {
   int i = get();
   if (cas(i, i+1))
     return i+1;
}

To implement a non-value-returning increment, you'd still have to do this:

while (true) {
   int i = get();
   if (cas(i, i+1))
     break;
}

So there's no performance advantage to having a non-value-returning 
increment operation.  I agree it might save you a little typing, but 
that's not really a great reason to add a method (and three increment 
methods might be more confusing than two.)

From cnmaclean at hotmail.com  Mon May 30 16:17:58 2005
From: cnmaclean at hotmail.com (Calum MacLean)
Date: Mon May 30 16:27:57 2005
Subject: [concurrency-interest] Use of blocked queues
References: <BAY101-F33BE09444F917AD7EB9615AB030@phx.gbl>
	<429B06B1.4050908@cs.oswego.edu> <429B0BEA.5000807@cs.oswego.edu>
	<BAY101-DAV11B08C773E617989E6B47BAB030@phx.gbl>
	<429B1893.2030004@cs.oswego.edu>
Message-ID: <BAY101-DAV16E977421D3322EC150945AB030@phx.gbl>

Hi Doug

OK, I understand that there still might be that race condition.  In my case 
it's OK - the event is, in effect, just an indication that the message 
wasn't read instantly (i.e. there wasn't a reader which was waiting for it), 
but without any guarantee that it wasn't read pretty soon after that, and 
possibly even before the notification was sent out.  So it's a conservative 
policy.

So, regarding being able to check how many readers are blocked waiting on a 
queue, you're basically saying that I can't do that using 
java.util.concurrent, and I will have to do it myself?

Thanks,
Calum

----- Original Message ----- 
From: "Doug Lea" <dl@cs.oswego.edu>
To: "Calum MacLean" <cnmaclean@hotmail.com>
Cc: <concurrency-interest@altair.cs.oswego.edu>
Sent: Monday, May 30, 2005 2:43 PM
Subject: Re: [concurrency-interest] Use of blocked queues


> Calum MacLean wrote:
>
>> I can achieve this relatively easily directly, by using a common object 
>> for synchronising around, and keeping a note of the number of readers.
>
> Except that the reader count will not include any thread currently
> blocked on that lock waiting to get in while you are checking, which is
> exactly the race condition you'd have otherwise. So, while you might
> be able to reduce unnecessary events using something like this,
> you can't eliminate them, and if this lock becomes highly contended,
> you might find that it is faster overall to just unconditionally
> issue events. Or maybe not. But I don't see anything that adding
> any capability to java.util.concurrent would help with here.
>
>
> -Doug
>
>
>
>
>
>
>
> 
From dholmes at dltech.com.au  Mon May 30 18:19:00 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Mon May 30 18:19:11 2005
Subject: [concurrency-interest] increment()/decrement()
	methodson	atomicInteger ?
In-Reply-To: <429B601C.3050304@quiotix.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEIMFMAA.dholmes@dltech.com.au>

Brian Goetz wrote:
> This does not save the CAS retry cycle.  Increment looks like this:
>
> while (true) {
>    int i = get();
>    if (cas(i, i+1))
>      return i+1;
> }
>
> To implement a non-value-returning increment, you'd still have to do this:
>
> while (true) {
>    int i = get();
>    if (cas(i, i+1))
>      break;
> }
>
> So there's no performance advantage to having a non-value-returning
> increment operation.

I think Brian and Doug have missed Yechiel's point. If I understand
correctly Yechiel is presuming that increment() et al use a CAS-loop only
because they want to return the old value. Therefore if you don't need the
return value you could implement those methods without using CAS at all.
This is true in principle. On X86 there are explicit instructions that can
be used to do atomic increments and decrements. However - and Doug is the
expert on this - I recall being told that there is no significant
performance gain in using such instructions over using a CAS loop. So all
the atomic ops were written using the CAS-loop, which not only simplifies
the Java code, it also makes life easier for the JIT/VM as it only has to
intrinsify one atomic instruction.

Cheers,
David Holmes

From dholmes at dltech.com.au  Mon May 30 18:41:29 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Mon May 30 18:41:35 2005
Subject: [concurrency-interest] Use of blocked queues
In-Reply-To: <BAY101-DAV11B08C773E617989E6B47BAB030@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEIOFMAA.dholmes@dltech.com.au>

Calum MacLean writes:
> I can achieve this relatively easily directly, by using a common
> object for synchronising around, and keeping a note of the number of
readers.
> But I thought that part of the raison-d'etre of java.util.concurrency
> was so that most uses of concurrency could use the higher level constructs
(queues
> etc.), and not have to worry about using locks etc. directly.

j.u.c provides a toolkit for a wide range of uses - some things higher-level
than others, but ultimately it comes down to application needs: you use the
tools that do the job best.

I still can't quite grasp exactly what you need, but based on the statement
above would it suffice to simply have your readers increment an
AtomicInteger before taking from the queue and decrement it after - the
count then tracks very approximately how many reads are in progress?

Cheers,
David Holmes

From yechielf at gigaspaces.com  Tue May 31 05:55:31 2005
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Tue May 31 04:51:59 2005
Subject: [concurrency-interest] increment()/decrement() methodson	atom
	icInteger ?
Message-ID: <D166C96F43D1D611B8E3000255A0C48C6BDF09@OFFICESRV>

Yes, thanks David, this was my point,delegation of the increment op to the
processor by the JVM,
but I disagree with you that there is no real diff' between cas and atomic
incrementation. This is true for a single threaded env' but in a "packed"
multi-threaded env' the cas retry loop may iterate several times, rejecting
the op'. This can be avoided by a delegated incrementation, and is not
needed in this case since I dont want to know the result after.

Regrds, Yechiel 

-----Original Message-----
From: David Holmes [mailto:dholmes@dltech.com.au]
Sent: Tuesday, May 31, 2005 00:19
To: Brian Goetz; Yechiel Feffer
Cc: concurrency-interest@altair.cs.oswego.edu
Subject: RE: [concurrency-interest] increment()/decrement() methodson
atomicInteger ?


Brian Goetz wrote:
> This does not save the CAS retry cycle.  Increment looks like this:
>
> while (true) {
>    int i = get();
>    if (cas(i, i+1))
>      return i+1;
> }
>
> To implement a non-value-returning increment, you'd still have to do this:
>
> while (true) {
>    int i = get();
>    if (cas(i, i+1))
>      break;
> }
>
> So there's no performance advantage to having a non-value-returning
> increment operation.

I think Brian and Doug have missed Yechiel's point. If I understand
correctly Yechiel is presuming that increment() et al use a CAS-loop only
because they want to return the old value. Therefore if you don't need the
return value you could implement those methods without using CAS at all.
This is true in principle. On X86 there are explicit instructions that can
be used to do atomic increments and decrements. However - and Doug is the
expert on this - I recall being told that there is no significant
performance gain in using such instructions over using a CAS loop. So all
the atomic ops were written using the CAS-loop, which not only simplifies
the Java code, it also makes life easier for the JIT/VM as it only has to
intrinsify one atomic instruction.

Cheers,
David Holmes
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20050531/c216b603/attachment.htm
From dholmes at dltech.com.au  Tue May 31 23:48:55 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Tue May 31 23:49:12 2005
Subject: [concurrency-interest] increment()/decrement()
	methodson	atomicInteger ?
In-Reply-To: <D166C96F43D1D611B8E3000255A0C48C6BDF09@OFFICESRV>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEKPFMAA.dholmes@dltech.com.au>

Yechiel Feffer writes:
> Yes, thanks David, this was my point,delegation of the increment op to the
processor
> by the JVM, but I disagree with you that there is no real diff' between
cas and
> atomic incrementation. This is true for a single threaded env' but in a
"packed"
> multi-threaded env' the cas retry loop may iterate several times,
rejecting the op'.
> This can be avoided by a delegated incrementation, and is not needed in
this case
> since I dont want to know the result after.

Yes it is possible that a highly contended atomic variable could require
several CAS retries. Is it likely? I think not, though of course you could
construct a scenario that exercises this aspect.

If anyone were to encounter such an occurrence in practice then it would be
reasonable grounds for submitting an RFE to specialise those actions to
avoid the use of CAS. As I said the current scheme makes life a lot simpler
at both the Java and JVM level.

Cheers,
David Holmes

