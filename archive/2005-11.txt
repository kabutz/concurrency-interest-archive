From unmesh_joshi at hotmail.com  Tue Nov  1 06:25:38 2005
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue Nov  1 06:26:11 2005
Subject: [concurrency-interest] Task framework demo programs in JDK 5.0
In-Reply-To: <200510311700.j9VH096q020432@altair.cs.oswego.edu>
Message-ID: <BAY21-F51D7EE45A96C6465D80C1EF6F0@phx.gbl>

Hi,

I was going through Fork/Join demo programs in util.concurrent. Are these 
samples available for JDK 5.0 version of util.concurrent?

Thanks,
Unmesh


From unmesh_joshi at hotmail.com  Tue Nov  1 06:25:38 2005
From: unmesh_joshi at hotmail.com (Unmesh joshi)
Date: Tue Nov  1 06:26:15 2005
Subject: [concurrency-interest] Task framework demo programs in JDK 5.0
In-Reply-To: <200510311700.j9VH096q020432@altair.cs.oswego.edu>
Message-ID: <BAY21-F51D7EE45A96C6465D80C1EF6F0@phx.gbl>

Hi,

I was going through Fork/Join demo programs in util.concurrent. Are these 
samples available for JDK 5.0 version of util.concurrent?

Thanks,
Unmesh


From dl at cs.oswego.edu  Tue Nov  1 07:47:09 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue Nov  1 07:49:00 2005
Subject: [concurrency-interest] Task framework demo programs in JDK 5.0
In-Reply-To: <BAY21-F51D7EE45A96C6465D80C1EF6F0@phx.gbl>
References: <BAY21-F51D7EE45A96C6465D80C1EF6F0@phx.gbl>
Message-ID: <436763CD.6080404@cs.oswego.edu>

Unmesh joshi wrote:
> Hi,
> 
> I was going through Fork/Join demo programs in util.concurrent. Are 
> these samples available for JDK 5.0 version of util.concurrent?
> 

This still runs on Java SE5, but creating a nicer version that is
integrated with j.u.c.Executors etc and takes advantage
of lower-level support to run faster is still on the todo list.

(I'm trying to get usd to the new naming conventions
"JDK1.5" -> "J2SE5.0" -> "Java SE5".)

-Doug

From jason_mehrens at hotmail.com  Tue Nov  1 17:29:09 2005
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Tue Nov  1 17:29:46 2005
Subject: [concurrency-interest] Object.wait(long) not returning the time
	remaining.
Message-ID: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>

This might be off topic but, can someone clarify the evaluation of RFE 
6176773 to me? Here is the link: 
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6176773

The evaluator states: "The actual signature of Object.wait can never be 
changed, because of binary
compatibility."  I don't see how changing the return type of a final void 
method can break binary compatibility (adding a new method to Object is a 
different story).  The method has a void return type so no caller is looking 
at the return value, there is none.  The method is final so no subclass or 
interface has to deal with return type change because it can't override 
method.  Existing code does care what the return type because it doesn't 
access it.

Reflection is the only thing I can think of that might break if the code is 
explicitly checking the return type of Object.wait(long) and taking a 
different code path if it is not void.  Since everything is an "Object" why 
would use reflection to call wait?  Maybe an introspection tool would look 
at the return type but I doubt it would cause tool from working.

Jason Mehrens


From joe.bowbeer at gmail.com  Tue Nov  1 18:32:39 2005
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue Nov  1 18:33:06 2005
Subject: [concurrency-interest] Object.wait(long) not returning the time
	remaining.
In-Reply-To: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>
References: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>
Message-ID: <31f2a7bd0511011532y5742b530x40371968f40c2905@mail.gmail.com>

Adding a return type to a void method would create two incompatibilities:

1. Existing callers of Object.wait would not pop the newly returned value.

2. Existing importers of Object.wait would fail to locate the method.

See Method Descriptors and Return Descriptors in the class file doc:

http://java.sun.com/docs/books/vmspec/2nd-edition/html/ClassFile.doc.html
*
*
On 11/1/05, Jason Mehrens <jason_mehrens@hotmail.com> wrote:
>
> This might be off topic but, can someone clarify the evaluation of RFE
> 6176773 to me? Here is the link:
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6176773
>
> The evaluator states: "The actual signature of Object.wait can never be
> changed, because of binary
> compatibility." I don't see how changing the return type of a final void
> method can break binary compatibility (adding a new method to Object is a
> different story). The method has a void return type so no caller is
> looking
> at the return value, there is none. The method is final so no subclass or
> interface has to deal with return type change because it can't override
> method. Existing code does care what the return type because it doesn't
> access it.
>
> Reflection is the only thing I can think of that might break if the code
> is
> explicitly checking the return type of Object.wait(long) and taking a
> different code path if it is not void. Since everything is an "Object" why
> would use reflection to call wait? Maybe an introspection tool would look
> at the return type but I doubt it would cause tool from working.
>
> Jason Mehrens
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20051101/aa0d2213/attachment.htm
From dholmes at dltech.com.au  Tue Nov  1 18:33:46 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Tue Nov  1 18:34:23 2005
Subject: [concurrency-interest] Object.wait(long) not returning the
	timeremaining.
In-Reply-To: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEKAGHAA.dholmes@dltech.com.au>

Jason,

> This might be off topic but, can someone clarify the evaluation of RFE
> 6176773 to me? Here is the link:
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6176773
>

I'm surprised they even accepted the above as a RFE. This was killed off
long long ago - see:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4027382

This could have been fixed in 1997 one way or another but they didn't see
that. Ancient history now.

> The evaluator states: "The actual signature of Object.wait can never be
> changed, because of binary
> compatibility."  I don't see how changing the return type of a final void
> method can break binary compatibility

It breaks binary compatibility because the JLS (Chapter 13) says that it
does. Changing the return type of a method has the effect of deleting the
old method and adding a new one. The former change is not binary compatible
if a method with the same signature and return type does not exist in a
superclass of the class being changed. While at the language level it would
seem a harmless change, at the JVM level the return type is part of the
method descriptor used by the bytecode - hence changing the return type
would result in a runtime error due to a missing method.

Unless you are trying to use wait() for doing explicit timing (which you
should not be doing) then this lack of information is not critical. The
important thing is whether or not the condition you were waiting on is now
valid.

If you really need to know then use the new Condition objects and their
awaitNanos method.

Cheers,
David Holmes

From brian at quiotix.com  Tue Nov  1 19:05:24 2005
From: brian at quiotix.com (Brian Goetz)
Date: Tue Nov  1 19:05:59 2005
Subject: [concurrency-interest] Object.wait(long) not returning the time
	remaining.
In-Reply-To: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>
References: <BAY105-F36493AE3255D78354C09C9836F0@phx.gbl>
Message-ID: <436802C4.9040205@quiotix.com>

What you describe is source compatibility, not binary compatibility. 
Changing the return type from void to non-void will not break any 
_source_ code that uses it.  But it will break bytecode, since the 
return value has to be popped off the stack if it is ignored.

Example:

class Foo {
   int i;
   public void setI(int arg) { i = arg; }
   public int setAndGetI(int arg) { i = arg; return i; }

   public static void main() {
     Foo f = new foo();
     f.setI(1);
     f.setAndGetI(1);
   }
}

Look at the bytecode below.  Notice the extra 'pop' in the call to 
setAndGetI where the return value is ignored.  Existing bytecode which 
calls Object.wait() would not have that, so it is not a binary compatble 
change.

public void setI(int);
   Code:
    0:	aload_0
    1:	iload_1
    2:	putfield	#2; //Field i:I
    5:	return

public int setAndGetI(int);
   Code:
    0:	aload_0
    1:	iload_1
    2:	putfield	#2; //Field i:I
    5:	aload_0
    6:	getfield	#2; //Field i:I
    9:	ireturn

public static void main();
   Code:
    0:	new	#3; //class Foo
    3:	dup
    4:	invokespecial	#4; //Method "<init>":()V
    7:	astore_0
    8:	aload_0
    9:	iconst_1
    10:	invokevirtual	#5; //Method setI:(I)V
    13:	aload_0
    14:	iconst_1
    15:	invokevirtual	#6; //Method setAndGetI:(I)I
    18:	pop
    19:	return

}


Jason Mehrens wrote:
> This might be off topic but, can someone clarify the evaluation of RFE 
> 6176773 to me? Here is the link: 
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6176773
> 
> The evaluator states: "The actual signature of Object.wait can never be 
> changed, because of binary
> compatibility."  I don't see how changing the return type of a final 
> void method can break binary compatibility (adding a new method to 
> Object is a different story).  The method has a void return type so no 
> caller is looking at the return value, there is none.  The method is 
> final so no subclass or interface has to deal with return type change 
> because it can't override method.  Existing code does care what the 
> return type because it doesn't access it.
> 
> Reflection is the only thing I can think of that might break if the code 
> is explicitly checking the return type of Object.wait(long) and taking a 
> different code path if it is not void.  Since everything is an "Object" 
> why would use reflection to call wait?  Maybe an introspection tool 
> would look at the return type but I doubt it would cause tool from working.
> 
> Jason Mehrens

From ryan.lecompte at pangonetworks.com  Wed Nov  2 08:51:40 2005
From: ryan.lecompte at pangonetworks.com (Ryan LeCompte)
Date: Wed Nov  2 08:52:25 2005
Subject: [concurrency-interest] Volatiles & deadlock
Message-ID: <PANGOSERVERgQkdzgXO0000055c@pangonetworks.com>

Hello all,

 

Is there any possible way for variables that are declared as "volatile" to
possibly get in a deadlock by the JVM? I know that if access to a particular
shared mutable variable is protected by methods that are "synchronized",
that it's still possible for a deadlock to occur depending on the
implementations of these synchronized methods. However, if there is nothing
to worry about when declaring a variable as volatile and not using the
"synchronized" approach to ensure correctness, right?

 

Thanks,

Ryan

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20051102/61ce5427/attachment.htm
From P.H.Welch at kent.ac.uk  Wed Nov  2 09:49:51 2005
From: P.H.Welch at kent.ac.uk (P.H.Welch)
Date: Wed Nov  2 09:50:47 2005
Subject: [concurrency-interest] spurious wakeups semantics
Message-ID: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>


Hi,

Seeing the discussion on these spurious wakeups alarms (maybe depresses)
me, :( ...

The idea of a spurious wakeup was (surely?) never part of the conceived
design for Java threads ... just something that crept in because of
some dodgy threading libraries on which early implementations depended??

There was never such a thing in Hoare monitors, from which the Java ones
are slightly descended.

As a design concept, it makes no sense.  If spurious unblocking from
"wait()" invocations are legal, then JVMs could all simplify their
implementations by implementing wait/notify/notifyAll as no-ops.  That
looks perfectly legal!  In such JVMs, all "wait()"s are immediately
spuriously notified and all "notify()"s have nothing to do - easy, :).

Humm ... maybe the "wait()" can't be a no-op since it must release
the monitor?  But it could be implemented as a release-monitor-lock
then "Thread.yield()" them spurious-wakeup then acquire-monitor-lock.
Actually, I think that's optimisable back to a no-op!  Either way ...

... all those waits-inside-while-condition loops become busy-polling,

:(,

which is actually what they really are anyway ... with no guarantees
of exit.  I suspect that many real systems running on many real JVMs
(even without spurious wakeups) are at risk from never exiting such
loops.  Isn't the *only* technical reason for programming such loops
... to cope with spurious wakeups?  The other reasons for them being
lazy (or erroneous) logic ... that's a conjecture ... suspect true.

Isn't it time that spurious wakeups were removed from Java semantics?

Peter.
From jmanson at cs.purdue.edu  Wed Nov  2 09:53:17 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Wed Nov  2 09:53:58 2005
Subject: [concurrency-interest] Volatiles & deadlock
In-Reply-To: <PANGOSERVERgQkdzgXO0000055c@pangonetworks.com>
References: <PANGOSERVERgQkdzgXO0000055c@pangonetworks.com>
Message-ID: <4368D2DD.9070000@cs.purdue.edu>

Ryan LeCompte wrote:
> Is there any possible way for variables that are declared as "volatile" to
> possibly get in a deadlock by the JVM? I know that if access to a particular
> shared mutable variable is protected by methods that are "synchronized",
> that it's still possible for a deadlock to occur depending on the
> implementations of these synchronized methods. However, if there is nothing
> to worry about when declaring a variable as volatile and not using the
> "synchronized" approach to ensure correctness, right?

volatile boolean a = false;
volatile boolean b = false;

Thread 1:

1: while (!a);
2: b = true;

Thread 2:

3: while (!b);
4: a = true;

Statement 1 waits for statement 4 waits for statement 3 waits for 
statement 2 waits for statement 1: a cycle.

Of course, in this case, regular, non-volatile variables would be just 
as likely to deadlock.  Is there a case where volatiles would and normal 
variables wouldn't?  No, because volatiles are just like regular 
variables, except they have memory consistency guarantees.

					Jeremy
From P.H.Welch at kent.ac.uk  Wed Nov  2 10:15:48 2005
From: P.H.Welch at kent.ac.uk (P.H.Welch)
Date: Wed Nov  2 10:16:30 2005
Subject: [concurrency-interest] Volatiles & deadlock
Message-ID: <E1EXKL6-00043m-EG@myrtle.ukc.ac.uk>


Jeremy Manson wrote:
> > Ryan LeCompte wrote:
> > Is there any possible way for variables that are declared as "volatile" to
> > possibly get in a deadlock by the JVM? I know that if access to a particular
> > shared mutable variable is protected by methods that are "synchronized",
> > that it's still possible for a deadlock to occur depending on the
> > implementations of these synchronized methods. However, if there is nothing
> > to worry about when declaring a variable as volatile and not using the
> > "synchronized" approach to ensure correctness, right?
>
> volatile boolean a = false;
> volatile boolean b = false;
>
> Thread 1:
>
> 1: while (!a);
> 2: b = true;
>
> Thread 2:
>
> 3: while (!b);
> 4: a = true;
>
> Statement 1 waits for statement 4 waits for statement 3 waits for
> statement 2 waits for statement 1: a cycle.

Nice example!

Technically, this is livelock though - an even nastier condition than
deadlock.  If theads 1 and 2 were deadlocked, they wouldn't trouble
the processor any more and their inactivity might become obvious (and
debuggable).  In this case, threads 1 and 2 continually trouble the
processor and that unproductive busyness (in a more complex embedding)
might be very un-obvious.  Volatiles scare me ...

Peter.
From matthias.ernst at coremedia.com  Wed Nov  2 10:22:15 2005
From: matthias.ernst at coremedia.com (Ernst, Matthias)
Date: Wed Nov  2 10:23:31 2005
Subject: AW: [concurrency-interest] spurious wakeups semantics
Message-ID: <F34C8A704C489B46B9E9FBDBD1B91D5F01926CA3@MARS.coremedia.com>


> As a design concept, it makes no sense.  If spurious 
> unblocking from "wait()" invocations are legal, then JVMs 
> could all simplify their implementations by implementing 
> wait/notify/notifyAll as no-ops.  

A trivial implementation of a concept does not render the concept
nonsensical.
The implementation is just not useful then.

I'm sure spurious wakeups have a raison d'etre (which would be
interesting to know the cause for).

But even if there were no spurious wakeups, the while loop is necessary
anyway in most cases
because the condition might have already changed back to false between
wakeup and the actual
acquisition of the monitor. Take the example of a threadpool thread:

...
  synchronized(jobs) {
    if(jobs.isEmpty()) wait();
    job = jobs.take();
  }
  job.run();
...

When this thread is woken up, but before it can actually re-acquire the
monitor, another
threadpool thread might have finished its work and grabbed the next job.
So it's necessary
to change 'if' to 'while'.

I've always explained spurious wakeups to myself as follows: "The while
loop is necessary
anyway because wait cannot atomically wakeup and acquire. So why pay a
penalty for removing
spurious wakeups in the threading library?"

Matthias

From tim at peierls.net  Wed Nov  2 10:35:39 2005
From: tim at peierls.net (Tim Peierls)
Date: Wed Nov  2 10:36:36 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
References: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
Message-ID: <4368DCCB.90100@peierls.net>

P.H.Welch wrote:
> Isn't it time that spurious wakeups were removed from Java semantics?

Who would benefit?

Not JVM designers, since they would have to work around the possibility of spurious wakeups at the 
OS level, with a consequent cost in performance.

Not programmers: The only burden imposed on the programmer by the possibility of spurious wakeups 
is the need to recheck a condition predicate. But this is such a good practice in any case that it 
doesn't really count as a burden.

Imagine what would happen if spurious wakeups were disallowed. First, programmers (those who never 
really bought into the idea that premature optimization is evil) would rush to turn this:

   synchronized (this) {
       while (!condition) wait();
       // do things that need condition to hold
   }

into this (to avoid a condition test that they "just know" is unnecessary):

   synchronized (this) {
       if (!condition) wait();
       // assert condition;  // "commented out to save cycles" (would be the claim)
       // do things that need condition to hold
   }

and then the notifying methods would change subtly so that the condition would *not* necessarily 
hold while you are doing things that require it to be true. The resulting bugs would manifest 
years later and not in a way that is obviously connected to the wait() call.


--tim

From gergg at cox.net  Wed Nov  2 10:45:11 2005
From: gergg at cox.net (Gregg Wonderly)
Date: Wed Nov  2 10:45:51 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
References: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
Message-ID: <4368DF07.8000509@cox.net>

P.H.Welch wrote:
> which is actually what they really are anyway ... with no guarantees
> of exit.  I suspect that many real systems running on many real JVMs
> (even without spurious wakeups) are at risk from never exiting such
> loops.  Isn't the *only* technical reason for programming such loops
> ... to cope with spurious wakeups?  The other reasons for them being
> lazy (or erroneous) logic ... that's a conjecture ... suspect true.
> 
> Isn't it time that spurious wakeups were removed from Java semantics?

I regularly code

	synchronized(lock) {
		while(!cond) {
			lock.wait(10000);
			log.fine("lock wakeup, cond: "+cond );
		}
	}

to make sure that if I see a no-progress situation, I can check to see which 
threads are stuck with conditions not changing (see my http://logman.jini.org 
project that lets you use jini to remotely manage and monitor logging streams). 
  This is a good debugging aid, and it helps me to manage all the interactions 
that I expect to see during testing.  I can turn this debugging on, and see that 
things are flowing as expected.  One can specify an even shorter sleep time, and 
get more log messages which can help alert you to longer than expected waiting.

Gregg Wonderly
From brian at quiotix.com  Wed Nov  2 11:00:01 2005
From: brian at quiotix.com (Brian Goetz)
Date: Wed Nov  2 11:00:41 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
References: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
Message-ID: <4368E281.6010405@quiotix.com>

> Seeing the discussion on these spurious wakeups alarms (maybe depresses)
> me, :( ...

Short answer: Don't worry about it so much.

> There was never such a thing in Hoare monitors, from which the Java ones
> are slightly descended.

Hoare monitors are a mathematical abstraction.  Spurious wakeups are 
permitted in recognition of the fact that real life is messy.  You can 
build an OS / thread package that NEVER delivers spurious wakeups, but 
there is a real engineering cost.  It is far more practical and 
efficient to allow the odd spurious wakeup.

Its like the difference between fair and barging locks.  Nonfair locks 
seem disturbing to everyone at first, until they realize the true cost 
of fairness (~2 orders of magnitude performance cost), and then they 
realize that statistical fairness is a better deal.  Same with SW; 
allowing an OS to deliver a spurious wakeup once in a while (and it is 
infrequent) allows for other optimizations and engineering improvements 
in the implementation.

> As a design concept, it makes no sense.  If spurious unblocking from
> "wait()" invocations are legal, then JVMs could all simplify their
> implementations by implementing wait/notify/notifyAll as no-ops.  That
> looks perfectly legal!  In such JVMs, all "wait()"s are immediately
> spuriously notified and all "notify()"s have nothing to do - easy, :).

Yes, but no reasonable JVM would do this.  JVMs could also implement 
sleep() with spin-waits.  There is a market here -- and such a JVM would 
be rejected by the market.

> Isn't it time that spurious wakeups were removed from Java semantics?

 From the perspective of a software developer, spurious wakeups are 
totally irrelevant.  Why?  To deal with spurious wakeups, you need to 
wait in a loop and re-test the condition every time.  But a program 
which uses wait() must do this anyway in order to be correct!  So, if 
spurious wakeups were disallowed, it would have zero effect on program 
code.

Short answer: Don't worry about it so much.

From David.Biesack at sas.com  Wed Nov  2 11:19:12 2005
From: David.Biesack at sas.com (David J. Biesack)
Date: Wed Nov  2 11:19:55 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk> (P.H.Welch@kent.ac.uk)
References: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
Message-ID: <200511021619.jA2GJCQ20902@mozart.unx.sas.com>

> From: "P.H.Welch" <P.H.Welch@kent.ac.uk>
> Date: Wed, 02 Nov 2005 14:49:51 +0000
> 
> Hi,
> 
> Seeing the discussion on these spurious wakeups alarms (maybe depresses)
> me, :( ...

David Holmes' comments clarified the topic for me. (I think the Javadoc should be corrected so that it is clearer.)

When a thread gets a spurious wakeup, it does not simply resume. It merely exits the wait set for the lock. It must still request/obtain the lock, which means it is still blocked, waiting for the lock. IOW, "spurious wakeup" does not mean "return from wait()" and therefore calamity.

The reason the loop/condition test is necessary is that, because of a spurious wakeup, the thread can run even if notify{All}() was not called; i.e. if the second thread calls wait(), but only once it obtains the lock. Further, the thread may resume BEFORE the second thread changes the wait condition to true. Hence the loop is necessary. But it was always a good idea/necessary to begin with:. when notifyAll() is called, another thread may run first and reset the condition to false.

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513

From P.H.Welch at kent.ac.uk  Wed Nov  2 12:09:12 2005
From: P.H.Welch at kent.ac.uk (P.H.Welch)
Date: Wed Nov  2 12:09:50 2005
Subject: [concurrency-interest] spurious wakeups semantics
Message-ID: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>


Matthias and Tim both raise the defence for while-not-condition-wait-loops
with the classical argument that something might have unset the waited-for
condition between the notifyer setting it up and the waiter reacquiring
the monitor.  Of course that may happen ... but only if the logic in the
programmed system is sloppy (I used the term "lazy" last time).

I come from a different school.  With Hoare monitors, a waiting process
atomically reacquires the monitor from a "notifying" process that has
set up the condition being awaited - the term "signal" is used rather
than "notify".  That allows proofs of liveness - that a waiting process
will eventually proceed if enough signals happen.

The Java "notify" retains the monitor, allowing silly things to be done
- like unsetting the condition about which you just notified.  Worse -
because it's more complex - entirely different threads can acquire the
monitor between notification and reacquisition by the waiting thread and,
as you say, they can unset the condition.  So, we "have" to put our
wait()s inside a while-not-condition loop.  But ... only because of
sloppy design ... conjecture again!

Why does the Java "notify" retain the monitor?  Probably to reduce context
switching (and consequent cache missing) - I guess??

But the cost is busy - possibly infinite - waiting to get out of that
while-not-condition-wait-loop.  It's easy to create an example of a system
that's 99% of its time asleep - waiting for things to happen - with all
the wait()s protected by while-loops waiting for the right condition and
with all the notifying processes doing "notifyAll()"s ... and yet some
threads never progress out of their while-not-condition-wait-loops ...
all the rules in the text book have been followed!  Not good.

Matthias noted:
> A trivial implementation of a concept does not render the concept
> nonsensical.  The implementation is just not useful then.

But our programs must survive being executed on such a useless, but legal,
implementation.  I suspect most would not?  The fact that a trivial
implementation of a concept might exist means that our use of the concept
must cope with that implementation ... and if it can't, that renders
the concept (or at least our use of it) useless.

Tim noted:
> Who would benefit?
> 
> Not JVM designers, since they would have to work around the possibility
> of spurious wakeups at the OS level, with a consequent cost in performance.

It's surely much better for the JVM to protect the Java system from broken
OS threading mechanisms.  Allowing the spurious wakeups through has an
effect of performance as well -- pulling the woken thread off the wait-set
and into the acquire-the-monitor-set, scheduling that woken thread,
executing its code to test (folornly) its while-condition, and finally
putting that woken thread back in the wait-set and scheduling another
thread.  That doesn't look too attractive.

Better: don't build your JVM on a broken threading mechanism ... it is
possible to have unbroken ones that don't do things when they shouldn't.

> Imagine what would happen if spurious wakeups were disallowed. First,
> programmers (those who never really bought into the idea that premature
> optimization is evil) would rush to turn this ... <description of
> while-wait-loop turned into if-wait>.

It sounds like you're threatening us with spurious wakeups just to make
us keep the while-wait-loop, :).

I would hope that - alongside converting while-wait-loop to if-wait -
they would look very carefully at the logic of their monitor methods
to ensure that the condition can't be unset between notification and
re-acquisition.  Getting that wrong is as bad as the spurious wakeup
and as costly for performance (perhaps infinitely so).  Of course,
the same duty must be imposed on maintainers of the system.

And, of course, this might be very difficult ... but that's a problem with
working with monitors ...  and, indeed, with most kinds of object locking.

Just seen ...

Brian wrote:
> Hoare monitors are a mathematical abstraction.  Spurious wakeups are
> permitted in recognition of the fact that real life is messy.  You can
> build an OS / thread package that NEVER delivers spurious wakeups, but
> there is a real engineering cost.  It is far more practical and
> efficient to allow the odd spurious wakeup.

Clean mathematical abstractions are *necessary* (though not sufficient)
for clean - and, hence, fast, simple and efficient - systems.  Hoare's
mathematical abstractions have proved pretty successful in guiding some
really spectacular engineering developments that deal with real messy
life.

It's the absence of clean mathematical abstractions that leads to real
engineering costs (that you mention).  I just don't believe that never
delivering a spurious wakeup should impose such a cost (assuming we're
not trying to guard against hardware corruption).

Peter (who must get back to his day job!).
From josh at bloch.us  Wed Nov  2 12:49:24 2005
From: josh at bloch.us (Joshua Bloch)
Date: Wed Nov  2 12:49:59 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
Message-ID: <b097ac510511020949o5414afdp9f4d705b29c43fb3@mail.gmail.com>

I agree wholeheartedly with Tim's original statement.  As an
interesting aside, I have it on reasonably good authority that the
"spurious wakeup" clause was put into the spec because one of the spec
authors felt that it encourage good coding habits, along the lines
discussed by Tim.

         Josh

From Pete.Soper at Sun.COM  Wed Nov  2 12:51:00 2005
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Wed Nov  2 12:54:57 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <200511021619.jA2GJCQ20902@mozart.unx.sas.com>
References: <E1EXJvz-0005uI-FM@myrtle.ukc.ac.uk>
	<200511021619.jA2GJCQ20902@mozart.unx.sas.com>
Message-ID: <4368FC84.6000306@Sun.COM>

Hi David,

You wrote:

>>
>>Seeing the discussion on these spurious wakeups alarms (maybe depresses)
>>me, :( ...
> 
> 
> David Holmes' comments clarified the topic for me. 

>(I think the Javadoc should be corrected so that it is clearer.)
> 

This went on the "todo list" when David Holmes flagged it. It is Sun bug
6344935.

-Pete
From tim at peierls.net  Wed Nov  2 13:16:37 2005
From: tim at peierls.net (Tim Peierls)
Date: Wed Nov  2 13:17:47 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
Message-ID: <43690285.70106@peierls.net>

P.H.Welch wrote:
>> [Tim:] Imagine what would happen if spurious wakeups were disallowed. First, programmers
>> (those who never really bought into the idea that premature optimization is evil) would rush
>> to turn this ... <description of while-wait-loop turned into if-wait>.
> 
> It sounds like you're threatening us with spurious wakeups just to make us keep the 
> while-wait-loop, :).

Whatever works! :-)


> I would hope that - alongside converting while-wait-loop to if-wait - they would look very 
> carefully at the logic of their monitor methods to ensure that the condition can't be unset 
> between notification and re-acquisition.

This asks too much of the programmer, and it precludes practical designs that don't fit the 
theoretical ideal.

For example, until JDK 5.0, you were limited to one wait-set per monitor, so rechecking the 
condition was sometimes essential even you disregarded the possibility of spurious wakeups.


> It's the absence of clean mathematical abstractions that leads to real engineering costs (that 
> you mention).

There's also a cost if you pick an abstraction that is too restrictive or that doesn't map well to
engineering realities.


> I just don't believe that never delivering a spurious wakeup should impose such a cost 
> (assuming we're not trying to guard against hardware corruption).

Let me turn that around: Is there a realistic example of a setting where the cost of a single 
superfluous condition evaluation dominates the context switch overhead in an essential way?  If 
not, then there is no reason to avoid the "while (!cond) wait()" pattern and thus no reason to 
force JVM designers to do handstands to hide spurious wakeups from us.  (If there is such an 
example, then there's more to debate.)

--tim

From brian at quiotix.com  Wed Nov  2 13:27:57 2005
From: brian at quiotix.com (Brian Goetz)
Date: Wed Nov  2 13:28:39 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
Message-ID: <4369052D.6070800@quiotix.com>

Your argument is mostly an "aesthetic" one, and you are contorting the 
world to fit your sense of aesthetic.  Spurious wakeups were not 
invented because we like ugliness; they were a real-world engineering 
compromise.  I presume you posted here because you wanted to understand 
the issue.  But using words like "broken" (incorrectly, I might add) 
does little to enlist the aid of those here.

> Matthias and Tim both raise the defence for while-not-condition-wait-loops
> with the classical argument that something might have unset the waited-for
> condition between the notifyer setting it up and the waiter reacquiring
> the monitor.  Of course that may happen ... but only if the logic in the
> programmed system is sloppy (I used the term "lazy" last time).

BZZZT.

- This can happen whenever a single wait set is used for multiple 
conditions.  Until Java 5, this was the _only_ way to get multiple 
conditions on a single condition queue, and you still can't with 
intrinsic condition queues.  So what should we do?  Outlaw bounded 
buffers, and other concurrent objects which require more than one 
condition?

- This can happen whenever notifyAll is used to wake up more than one 
thread, even if all threads are waiting for the same condition.  There 
are good engineering reasons why you might prefer notifyAll to single 
notify.

These cases don't describe "sloppiness", they describe sensible 
practices for common real-world problems.

>>A trivial implementation of a concept does not render the concept
>>nonsensical.  The implementation is just not useful then.
> 
> But our programs must survive being executed on such a useless, but legal,
> implementation.  I suspect most would not?  The fact that a trivial
> implementation of a concept might exist means that our use of the concept
> must cope with that implementation ... and if it can't, that renders
> the concept (or at least our use of it) useless.

The standard idioms cope with that quite well.   Such an implementation 
would just perform poorly.  Which is one reason why it would be a poor, 
albeit valid, implementation.

   synchronized (lock) {
     while (!conditionPredicate())
        lock.wait();
   }

will work fine if wait() is simply an unlock^n-lock^n sequence.  And the 
JLS requires it to release the lock as part of a wait, so the 
unlock^n-lock^n cannot be optimized away.  See JLS/3e 17.8.1.  (You 
might consider looking at the spec before making claims like "X would be 
a valid implementation, but that would break real programs" when the 
spec very clearly outlaws X.)

> It's surely much better for the JVM to protect the Java system from broken
> OS threading mechanisms.  

You have done nothing to support your claim of brokenness.  As far as I 
can tell, all you've said is that you personally find it ugly.  You may 
be right, but that doesn't mean its broken.

> Allowing the spurious wakeups through has an
> effect of performance as well -- pulling the woken thread off the wait-set
> and into the acquire-the-monitor-set, scheduling that woken thread,
> executing its code to test (folornly) its while-condition, and finally
> putting that woken thread back in the wait-set and scheduling another
> thread.  That doesn't look too attractive.

OS'es which permit spurious wakeups may do so because by doing so 
because they can improve overall performance.  Again, I refer you to the 
fair/nonfair issue with locks.  Sure, fairness is prettier, but 
starvation-free nonfair locks can be implemented a lot more efficiently. 
    To make a performance argument, you'd have to analyze the 
performance costs of rewriting the OS as you suggest.

> I would hope that - alongside converting while-wait-loop to if-wait -
> they would look very carefully at the logic of their monitor methods
> to ensure that the condition can't be unset between notification and
> re-acquisition.  

I share your hopes, but I've met enough real programmers to know that 
this is in the same category as hoping to wake up taller tomorrow.

> Clean mathematical abstractions are *necessary* (though not sufficient)
> for clean - and, hence, fast, simple and efficient - systems.  Hoare's
> mathematical abstractions have proved pretty successful in guiding some
> really spectacular engineering developments that deal with real messy
> life.

Except that a monitor-based design for a system of even moderate 
complexity will almost certainly deadlock.  This is (one reason) why the 
monitor-like approach that Java uses was taken over "real" monitors.

> It's the absence of clean mathematical abstractions that leads to real
> engineering costs (that you mention).  I just don't believe that never
> delivering a spurious wakeup should impose such a cost (assuming we're
> not trying to guard against hardware corruption).

This one I buy.  But the abstractions need to be consistent with the 
reality of hardware and OSs of the day.

From dl at cs.oswego.edu  Wed Nov  2 14:33:21 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed Nov  2 14:35:16 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
Message-ID: <43691481.3090601@cs.oswego.edu>

Hi Peter,

It's nice (honestly!) to get your usual balance on the perennial
spurious wakeup issue.

A couple of notes on it:

1. As it turns out, the current implementation 
locks.ReentrantLock.Condition.await() do not spuriously
wake up. We don't document or promise this though, for the kinds
of reasons Tim and Josh mentioned.

2. Conversely though, the underlying "primitive" operation
locks.LockSupport.park() is intentionally(!) very "leaky"
and will sometimes fail to block at all. Notice that if threads do
spuriously wake up on modern OSes, then it performance-neutral whether
the OS or the monitor implementation or application code puts
them back to sleep when necessary. However, because
blocking threads on modern multiprocessors and their operating
systems are relatively much more expensive in throughput cost
than, say, the uniprocessors of a decade ago, opportunistically
trying to proceed when you are awake anyway is often faster.

3. We hope that people will increasingly use the more convenient,
semantically cleaner,  and often significantly more efficient
medium/higher level constructs that java.util.concurrent offers
rather use monitor/condition operations at all. In fact, whenever people
post on this list that they are using them, I often wonder to myself
what higher-level construct we might put in j.u.c. that they could use
instead.

-Doug
From forax at univ-mlv.fr  Wed Nov  2 14:34:39 2005
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Wed Nov  2 14:35:18 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <4369052D.6070800@quiotix.com>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk> <4369052D.6070800@quiotix.com>
Message-ID: <436914CF.5050202@univ-mlv.fr>

Brian Goetz a ?crit :
...
> 
> - This can happen whenever a single wait set is used for multiple 
> conditions.  Until Java 5, this was the _only_ way to get multiple 
> conditions on a single condition queue, and you still can't with 
> intrinsic condition queues.  So what should we do?  Outlaw bounded 
> buffers, and other concurrent objects which require more than one 
> condition?
> 
> - This can happen whenever notifyAll is used to wake up more than one 
> thread, even if all threads are waiting for the same condition.  There 
> are good engineering reasons why you might prefer notifyAll to single 
> notify.

what are these good engineering reasons ?
and are these reasons can be applied to Condition.signal/signalAll too
in case of fair Lock ?

> 
> These cases don't describe "sloppiness", they describe sensible 
> practices for common real-world problems.

...

> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

R?mi Forax

From brian at quiotix.com  Wed Nov  2 14:52:26 2005
From: brian at quiotix.com (Brian Goetz)
Date: Wed Nov  2 14:53:08 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <436914CF.5050202@univ-mlv.fr>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk>
	<4369052D.6070800@quiotix.com> <436914CF.5050202@univ-mlv.fr>
Message-ID: <436918FA.9080306@quiotix.com>

>> - This can happen whenever notifyAll is used to wake up more than one 
>> thread, even if all threads are waiting for the same condition.  There 
>> are good engineering reasons why you might prefer notifyAll to single 
>> notify.
> 
> what are these good engineering reasons ?
> and are these reasons can be applied to Condition.signal/signalAll too
> in case of fair Lock ?

In order for a design to be a candidate for notify() instead of 
notifyAll(), three conditions need to hold:

  - Uniform waiters.  All waiters must be waiting for the same 
condition.  This rules out a bounded buffer design which uses an 
intrinsic condition queue, because there are separate "notEmpty" and 
"notFull" conditions.

  - One in, one-out.  A notification must release exactly one waiter. 
This rules out blocking classes like latches and barriers, which must 
use notifyAll().

  - Subclass safety.  This one is a little trickier.  The class must be 
structured so that if the class is subclassed, the above requirements 
still hold.  It is very difficult to design a blocking class so that it 
can be subclassed arbitrarily.


Any class which uses an intrinsic condition queue / lock object and the 
queue/lock object is not hidden cannot meet the first requirement, 
because any old code could wait() on the condition queue and violate the 
uniform waiters requirement.  So the monitor-like pattern encouraged by 
Java does not play nicely with single notify.


From dawidk at mathcs.emory.edu  Wed Nov  2 17:58:12 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed Nov  2 17:58:48 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <43691481.3090601@cs.oswego.edu>
References: <E1EXM6q-00022E-2C@myrtle.ukc.ac.uk> 
	<43691481.3090601@cs.oswego.edu>
Message-ID: <43694484.9060502@mathcs.emory.edu>

Doug Lea wrote:

> Hi Peter,
>
> It's nice (honestly!) to get your usual balance on the perennial
> spurious wakeup issue.
>
> A couple of notes on it:
>
> 1. As it turns out, the current implementation 
> locks.ReentrantLock.Condition.await() do not spuriously
> wake up. We don't document or promise this though, for the kinds
> of reasons Tim and Josh mentioned.
>
In the 1.4 backport, spurious wakeups are possible when using unfair 
conditions, and in fact I have seen them happening (on MS Windows). They 
won't occur when using fair conditions, although - as Doug says - this 
is undocumented and not promised to hold in the future.

Regards,
Dawid Kurzyniec

From sergemasse1 at yahoo.com  Wed Nov  2 18:29:01 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Wed Nov  2 18:29:39 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet Memory Model
Message-ID: <20051102232902.88095.qmail@web51413.mail.yahoo.com>

Hi all,
Can someone give us a brief comparison (or a link)
between Java Memory Model and .NET Memory Model?

I am also more specifically interested in the
capabilities of a well constructed multithreaded
application in Java 5 and dotnet for working properly
on a multicore cpu. 

For example, is it true that dotnet cannot guarantee
proper behavior of a multithreaded application on a
multicore chip? 

And is it true that older version of Java, such as
Java 1.3 and older, cannot guarantee proper behavior
of a multithreaded application on a multicore chip?

thanks,
serge masse
From jmanson at cs.purdue.edu  Wed Nov  2 19:18:01 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Wed Nov  2 19:18:42 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet Memory
	Model
In-Reply-To: <20051102232902.88095.qmail@web51413.mail.yahoo.com>
References: <20051102232902.88095.qmail@web51413.mail.yahoo.com>
Message-ID: <43695739.2000000@cs.purdue.edu>

Gnah.  CLI stuff...

We have been back and forth with the .NET people about this a few times. 
  My understanding is that .NET ignores the ECMA CLI specification 
memory model.  This is no bad thing, because although it learned some of 
the lessons of the JMM, it didn't learn all of them.  It was quite 
vague.  However, this means that we are somewhat light on documentation 
on what .NET actually does.

I note that Vance Morrison has recently posted an article on the new 
model in the .NET Framework 2.0:

http://msdn.microsoft.com/msdnmag/issues/05/10/MemoryModels/default.aspx

It is a fairly weak (in the memory consistency sense) model.  From a 
quick glance, it looks as if it doesn't deal with a lot of the subtle 
issues that we dealt with in the JMM.  This is of more interest to 
compiler writers than the people on this list, though.

As for the relative correctness of your code on .NET and in earlier 
versions of Java, that depends on your code.

In JDK1.4 and earlier, and, I suspect, in .NET, if you use locks 
correctly, then your code will behave correctly.  By use locks 
correctly, I mean that all accesses to shared memory should be ordered 
by locking and mutual exclusion (more accurately, the locks in your 
program should ensure that there should be no data races).

If you don't follow this locking protocol (using volatiles, for 
example), you can get into trouble in earlier JDKs.  .NET has a volatile 
modifier which, I believe, is intended to work like Java's.

					Jeremy
From osvaldo at visionnaire.com.br  Thu Nov  3 12:13:09 2005
From: osvaldo at visionnaire.com.br (Osvaldo Pinali Doederlein)
Date: Thu Nov  3 11:40:07 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet Memory
	Model
In-Reply-To: <43695739.2000000@cs.purdue.edu>
References: <20051102232902.88095.qmail@web51413.mail.yahoo.com>
	<43695739.2000000@cs.purdue.edu>
Message-ID: <436A4525.2080507@visionnaire.com.br>

Hi,

This excellent post (from Microsoft's JIT program manager) is a very
good overview of this issue:

http://discuss.develop.com/archives/wa.exe?A2=ind0203B&L=DOTNET&P=R375

Go straight to "CAVEATS for V1" in the end.  Basically, it seems that
Microsoft gets away with a weak MM and implementation, because they
support mostly the P5/P6 platform which hardware MM is very strong.
So they can use all compiler optimizations they want without issues.
But IIRC the Intanium is not as nice as the Pentium, so I'd expect
MS to have improved this in .NET 2.0 which supports 64-bit platforms.

A+
Osvaldo

Jeremy Manson wrote:
> Gnah.  CLI stuff...
> 
> We have been back and forth with the .NET people about this a few times. 
>  My understanding is that .NET ignores the ECMA CLI specification memory 
> model.  This is no bad thing, because although it learned some of the 
> lessons of the JMM, it didn't learn all of them.  It was quite vague.  
> However, this means that we are somewhat light on documentation on what 
> .NET actually does.
> 
> I note that Vance Morrison has recently posted an article on the new 
> model in the .NET Framework 2.0:
> 
> http://msdn.microsoft.com/msdnmag/issues/05/10/MemoryModels/default.aspx
> 
> It is a fairly weak (in the memory consistency sense) model.  From a 
> quick glance, it looks as if it doesn't deal with a lot of the subtle 
> issues that we dealt with in the JMM.  This is of more interest to 
> compiler writers than the people on this list, though.
> 
> As for the relative correctness of your code on .NET and in earlier 
> versions of Java, that depends on your code.
> 
> In JDK1.4 and earlier, and, I suspect, in .NET, if you use locks 
> correctly, then your code will behave correctly.  By use locks 
> correctly, I mean that all accesses to shared memory should be ordered 
> by locking and mutual exclusion (more accurately, the locks in your 
> program should ensure that there should be no data races).
> 
> If you don't follow this locking protocol (using volatiles, for 
> example), you can get into trouble in earlier JDKs.  .NET has a volatile 
> modifier which, I believe, is intended to work like Java's.
> 
>                     Jeremy
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


-- 
-----------------------------------------------------------------------
Osvaldo Pinali Doederlein                   Visionnaire Inform?tica S/A
osvaldo@visionnaire.com.br                http://www.visionnaire.com.br
Arquiteto de Tecnologia                          +55 (41) 337-1000 #223

From jmanson at cs.purdue.edu  Thu Nov  3 11:57:23 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov  3 11:58:03 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet Memory
	Model
In-Reply-To: <436A4525.2080507@visionnaire.com.br>
References: <20051102232902.88095.qmail@web51413.mail.yahoo.com>	<43695739.2000000@cs.purdue.edu>
	<436A4525.2080507@visionnaire.com.br>
Message-ID: <436A4173.6030207@cs.purdue.edu>

Osvaldo Pinali Doederlein wrote:
> Hi,
> 
> This excellent post (from Microsoft's JIT program manager) is a very
> good overview of this issue:
> 
> http://discuss.develop.com/archives/wa.exe?A2=ind0203B&L=DOTNET&P=R375
> 
> Go straight to "CAVEATS for V1" in the end.  Basically, it seems that
> Microsoft gets away with a weak MM and implementation, because they
> support mostly the P5/P6 platform which hardware MM is very strong.
> So they can use all compiler optimizations they want without issues.
> But IIRC the Intanium is not as nice as the Pentium, so I'd expect
> MS to have improved this in .NET 2.0 which supports 64-bit platforms.
> 
> A+
> Osvaldo
> 

I'm not sure how excellent this article is.  For example, his LazyInit 
example ignores reordering by the reader.  Even with the rules he 
states, you would really need a memory barrier before the first read of 
the singleton.

Having said that, the post is 3 years old and describes the ECMA 
standard, which we know they are ignoring.  So it may not be all that 
useful in understanding what they are doing now.

					Jeremy
From P.H.Welch at kent.ac.uk  Thu Nov  3 15:59:26 2005
From: P.H.Welch at kent.ac.uk (P.H.Welch)
Date: Thu Nov  3 16:00:07 2005
Subject: [concurrency-interest] spurious wakeups semantics
Message-ID: <E1EXmBC-0000Qg-Ce@myrtle.ukc.ac.uk>


Apologies!  Maybe I was trying to stir things up a bit ... I expected
to get bitten back.  :)

Thank you to all who responded (some privately).  I'll try to respond
carefully and briefly!

Re. the thought-JVM in which wait/notify/notifyAll were implemented as no-ops,
Brian Goetz wrote:
> the JLS requires it to release the lock as part of a wait, so the
> unlock^n-lock^n cannot be optimized away.  See JLS/3e 17.8.1.  (You
> might consider looking at the spec before making claims like "X would be
> a valid implementation, but that would break real programs" when the
> spec very clearly outlaws X.)`

In my defence, I did (partly) withdraw the wait-as-a-no-op idea:
> Humm ... maybe the "wait()" can't be a no-op since it must release
> the monitor?  But it could be implemented as a release-monitor-lock
> then "Thread.yield()" them spurious-wakeup then acquire-monitor-lock.

Before blowing it with the incorrect:
> Actually, I think that's optimisable back to a no-op!

Though then proceeding that, even if wait can only reduce to release-acquire:
> all those waits-inside-while-condition loops become busy-polling, :(,

When we need polling, we do it.  Doing it as the default way of design
just feels wrong.

Maybe some of this is bound up with another complaint from Brian:
> > It's surely much better for the JVM to protect the Java system from broken
> > OS threading mechanisms.
> 
> You have done nothing to support your claim of brokenness.  As far as I
> can tell, all you've said is that you personally find it ugly.  You may
> be right, but that doesn't mean its broken.

If I say to Fred: "wake me up when Jim's made the porridge" ... and Fred goes
and wakes me up before Jim's made the porridge ... and Fred is a computer
programmed to do that task ... then I'd say Fred is broken.

I want to commit the sin of *sometimes* (maybe quite often) doing a wait()
without surrounding it with a while-not-condition loop ... something I just
can't do in the context of spurious wakeups.  The reason for not wanting
the loop is not to do with saving the cost of rechecking the condition ...
it's to do with semantic clarity ... not cluttering the system with stuff
we don't need ... "Ockham's Razor" ... :).

Doug Lea wrote:
>                                         Notice that if threads do
> spuriously wake up on modern OSes, then it (is) performance-neutral whether
> the OS or the monitor implementation or application code puts
> them back to sleep when necessary.

Great!  So let's get the OS or the monitor implementation to do it and
not impose a logic-non-neutral complexity burden on the application code.
The OS or monitor implementation only has to be made right once.

Getting back to my reasons for sin ...

Sometimes, a thread has grabbed a monitor lock and finds that it simply
has to wait().  This is in one branch of its logic.  Now, just because
of spurious wakeups, I either must distort that logic into a loop ...
or leave the simple branch, invent an extra boolean field and expand
the simple wait() into one governed by a loop ... and modify the notifier
to set that extra boolean.  Extra engineering like this is bad, simply
because it is there.  And it doesn't have to be there ... were it not
for those spurious wakeups.

Of course, as Brian points out in a later posting discussing notify()
versus notifyAll(), for the above to work the monitor object must be
hidden from the rest of the system.  It also helps if only one thread
can be doing that wait()ing at any time.

Various replies mention that we need the while-not-condition-wait loop
when different monitor methods of the same object are waiting for
different conditions - e.g. a bounded buffer where the pusher needs
some room and the puller needs something to be there.  [This is with
classical Java monitors, before Java 5.]

The above is true, of course.  Even so, it is possible to design bounded
buffers with loop-free logic.  One way uses 3 monitor objects: one on
which the pushers must first lock, another for the pullers and the third
to sort out contention between an (at most) single puller and (at most)
single pusher for the actual buffer (and on which the wait/notifying
gets done).  We don't need notifyAll because there is (at most) one
party to notify.  We don't need a loop round the wait because there
is only you waiting for that notification (except for that darn spurious
wakeup).

But you probably won't like that approach because of the performance hit
from the extra lock that needs to be acquired?  Humm ... maybe that hit
should be reduced a couple of orders of magnitude ...

Mis-quoting Brian (apologies):
> I share your hopes, but ... <snip> ... this is in the same category
> as hoping to wake up taller tomorrow.

Nevertheless, it can be done ... though maybe we need a fresh start.

A comment on performance was made:
> OS'es which permit spurious wakeups may do so because by doing so
> because they can improve overall performance.  Again, I refer you to the
> fair/nonfair issue with locks.  Sure, fairness is prettier, but
> starvation-free nonfair locks can be implemented a lot more efficiently.

and, earlier, someone mentioned that imposing "fairness" cost 2 orders
of magnitude extra overhead?  But low cost "fair" algorithms -- for example
for concurrent-read-exclusive-write (CREW) locks have long been around.
One is given and documented in the JCSP library:

  http://www.cs.kent.ac.uk/projects/ofa/jcsp/jcsp1-0-rc4/jcsp-docs/jcsp/lang/Crew.html

(though please read the "Cautionary Note" in the above).

Another comment on Hoare's "real" monitors:
> > Clean mathematical abstractions are *necessary* (though not sufficient)
> > for clean - and, hence, fast, simple and efficient - systems.  Hoare's
> > mathematical abstractions have proved pretty successful in guiding some
> > really spectacular engineering developments that deal with real messy
> > life.
> 
> Except that a monitor-based design for a system of even moderate
> complexity will almost certainly deadlock.  This is (one reason) why the
> monitor-like approach that Java uses was taken over "real" monitors.

The "Except ..." sentence is way too strong and unsupported by evidence
or explanation.

Also, Java monitors may be less prone to deadlock -- but they are still
very prone to it -- but are, in consequence, more prone to livelock ...
which may be worse ("will I ever get out of this wait-loop?").

Finally, Doug wrote:
> 3. We hope that people will increasingly use the more convenient,
> semantically cleaner,  and often significantly more efficient
> medium/higher level constructs that java.util.concurrent offers
> rather use monitor/condition operations at all. In fact, whenever people
> post on this list that they are using them, I often wonder to myself
> what higher-level construct we might put in j.u.c. that they could use
> instead.

Yes.  The original Java monitor design is specialised for certain
kinds of threading logic and works well if that's what you want.  But
it's not really a "low-level" concurrency primitive on which you can
build what-you-really-want-to-do, get-it-right and get-it-efficient.

Rebuilding from a highly efficient lower set of primitives -- and,
thank you, offering those primitives -- seems a much better bet.

My interest is building concurrency mechanisms on top of CSP (and,
recently, pi-calculus) primitives.  These are not so far from Doug's
set, :).

If any are still reading and were curious:

  http://www-128.ibm.com/developerworks/java/library/j-csp2/
  http://www.cs.kent.ac.uk/projects/ofa/jcsp/

Really must update the latter!

Peter.
From Pete.Soper at Sun.COM  Thu Nov  3 17:38:05 2005
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Thu Nov  3 17:41:57 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <E1EXmBC-0000Qg-Ce@myrtle.ukc.ac.uk>
References: <E1EXmBC-0000Qg-Ce@myrtle.ukc.ac.uk>
Message-ID: <436A914D.3040403@Sun.COM>

P.H.Welch wrote:

> 
> If I say to Fred: "wake me up when Jim's made the porridge" ... and Fred goes
> and wakes me up before Jim's made the porridge ... and Fred is a computer
> programmed to do that task ... then I'd say Fred is broken.
> 

Fred is a very human-like computer with bare feet in a house with loose
carpet tacks and very occasionally screams at the top of his lungs.
Neither you or Jim are willing to pay for the carpet man to come around,
to make Fred shoes, string a metal detector around his neck and give him
some extra code, etc. You are periodically annoyed but finally accept
that noise happens. And you never, ever dip your spoon into an empty
bowl of porridge anyway.

:-)

-Pete

From sergemasse1 at yahoo.com  Thu Nov  3 19:26:27 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Thu Nov  3 19:27:12 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet Memory
	Model
In-Reply-To: <43695739.2000000@cs.purdue.edu>
Message-ID: <20051104002627.19765.qmail@web51405.mail.yahoo.com>

Jeremy,
Thank you very much for the link and info that you
provided in your reply. They were very useful and also
guided me in further search and some refinement of my
previous statements.

I would appreciate if you or someone else could
correct, confirm, or invalidate the following 2
statements.

1) In order to come up with a well constructed
multithreaded Java app guaranteed to work properly on
any multicore chips when using Java 1.4 down, one must
consider as invalid certain idioms and advices from
Sun and others, and use the old Ada and Modula3
technique of synchronizing all accesses to shared
variables, including those qualified as final and
including those of type String. (The situation is
better, i.e., less restrictive and allowing better
performance, when using Java 5.)

2) Dotnet cannot guarantee proper behavior of a
multithreaded application on all multicore chips and
can only be safely used on the multicore chips that
are officially supported by Microsoft. 

thanks
serge

--- Jeremy Manson <jmanson@cs.purdue.edu> wrote:

> Gnah.  CLI stuff...
> 
> We have been back and forth with the .NET people
> about this a few times. 
>   My understanding is that .NET ignores the ECMA CLI
> specification 
> memory model.  This is no bad thing, because
> although it learned some of 
> the lessons of the JMM, it didn't learn all of them.
>  It was quite 
> vague.  However, this means that we are somewhat
> light on documentation 
> on what .NET actually does.
> 
> I note that Vance Morrison has recently posted an
> article on the new 
> model in the .NET Framework 2.0:
> 
>
http://msdn.microsoft.com/msdnmag/issues/05/10/MemoryModels/default.aspx
> 
> It is a fairly weak (in the memory consistency
> sense) model.  From a 
> quick glance, it looks as if it doesn't deal with a
> lot of the subtle 
> issues that we dealt with in the JMM.  This is of
> more interest to 
> compiler writers than the people on this list,
> though.
> 
> As for the relative correctness of your code on .NET
> and in earlier 
> versions of Java, that depends on your code.
> 
> In JDK1.4 and earlier, and, I suspect, in .NET, if
> you use locks 
> correctly, then your code will behave correctly.  By
> use locks 
> correctly, I mean that all accesses to shared memory
> should be ordered 
> by locking and mutual exclusion (more accurately,
> the locks in your 
> program should ensure that there should be no data
> races).
> 
> If you don't follow this locking protocol (using
> volatiles, for 
> example), you can get into trouble in earlier JDKs. 
> .NET has a volatile 
> modifier which, I believe, is intended to work like
> Java's.
> 
> 					Jeremy
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
>
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
From dholmes at dltech.com.au  Thu Nov  3 19:38:08 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Thu Nov  3 19:38:49 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <436A914D.3040403@Sun.COM>
Message-ID: <NFBBKALFDCPFIDBNKAPCGENOGHAA.dholmes@dltech.com.au>

I know I should just sit back and keep quiet but ... :)

Peter is right (as another Peter (Buhr uC++) not on this list would
strenuously agree) in the absence of spurious wakeups it is possible to
write code that need not wait() in a loop, and in some cases (much fewer)
not even check a condition before waiting.

However it is far more common for people to write code that will be
incorrect in the absence of the loop (even people that should know better).
So the mantra has always been "always test your condition in a loop" - with
a footnote: unless you can prove it is safe to do otherwise. Spurious
wakeups reinforce this and help to avoid errors that would otherwise occur.
(This is a similar argument Dave Butenhof makes for the POSIX pthreads
semantics for condition variables - which Java essentially borrowed from).

Spurious wakeups have a history steeped in myth and mystery. No one is
really sure where they came from. The POSIX rationale shows a piece of
broken code and uses that to justify the possibility of spurious wakeups.
Legend has it that some early multi-processor (Firefly is often named but
I've never seen any supporting documentation) might mistakenly wakeup more
than one thread that was waiting - hence they were woken spuriously (this is
somewhat supported by POSIX's pthread_cond_signal semantics that state that
it
"unblocks at least one thread" - at least Java didn't copy to that
extent.)**

Peter is also right that the VM could shield the runtime and the application
from these obscure possibilities. But as Tim pointed out the cost-to-benefit
ration just doesn't justify it. Language purists will no doubt disagree, but
offending one's aesthetic and engineering sensibilities by needing to use a
while loop, is hardly a significant matter***. Java isn't going to change so
just grin-and-bear it.

** By the way. Another aspect of this is whether, considering POSIX, a
spurious wakeup was only meant to account for a signal waking more than one
thread, or whether it could occur even in the absence of any signals.
(Unless you use waiting as a sleep mechanism, I don't think there is any
practical difference between the two.)

*** I do understand however that it makes formal modelling more difficult
due to the need to establish that the loop terminates. As long as such
models don't assume that spurious wakeups can occur infinitely often, their
only affect is a time delay. You still need to establish that any waiting
thread will eventually have its reason for waiting satisfied.

Probably best to stop there. :-)

Cheers,
David Holmes

From dholmes at dltech.com.au  Thu Nov  3 19:57:44 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Thu Nov  3 19:58:19 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet MemoryModel
In-Reply-To: <20051104002627.19765.qmail@web51405.mail.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEOAGHAA.dholmes@dltech.com.au>

> 1) In order to come up with a well constructed
> multithreaded Java app guaranteed to work properly on
> any multicore chips when using Java 1.4 down, one must
> consider as invalid certain idioms and advices from
> Sun and others, and use the old Ada and Modula3
> technique of synchronizing all accesses to shared
> variables, including those qualified as final and
> including those of type String. (The situation is
> better, i.e., less restrictive and allowing better
> performance, when using Java 5.)

There are two kinds of guarantee here:

a) what does the Java platform guarantee
b) what does a specific implementation of Java provide on a given platform

For (a) then pre Java 5 - yes certain idioms and coding practices are
technically incorrect and not guaranteed to work by the rules of the
platform.

However for (b) a given implementation is always more constrained than the
spec and actually provides tighter behaviour. For example, I believe that
Sun's JDK 1.4.2 implements volatile semantics in a way that is consistent
with the Java 5 memory model.

Depending on what kind of "guarantee" you are after, you may be able to use
pre Java 5 software in its existing form.

Given that multi-core chips are supposed to be transparent to the software
(ie the software can't tell if it is running on multi-core or SMP) then I
don't expect to suddenly see problems with software that ran on a SMP before
and is now run on multi-core. Of course, software that has only run on a
single processor before may well exhibit previously undetected concurrency
bugs when run with multiple processors and/or cores.

David Holmes

From andrejnavodnik at yahoo.com  Fri Nov  4 01:39:04 2005
From: andrejnavodnik at yahoo.com (Andrej Navodnik)
Date: Fri Nov  4 01:39:43 2005
Subject: [concurrency-interest] Help, how to design a pool of executors
Message-ID: <20051104063904.57128.qmail@web50604.mail.yahoo.com>

Hello all,

I would kindly ask someone for a gentle hand to guide
me through the 
problems related to the concurrent programming.

My problem is the following. I'd like to design a
special structure/pool of 
executors which gives a priority to the task that
testing element satisfies 
a special intermediate condition. If an algorithm
could verify that the 
testing element is appropriate for further use then
the task that has 
found this element is allowed to cancel all other
tasks in pool and calculate 
the final result based on this "optimal element".

Let's say that I have a set of elements from which I
want to find  an optimal
element. During testing whether an element is
appropriate or not an element must 
satisfy some kind of an intermediate condition. If an
intermediate condition is 
not satisfied then the pool select another element for
testing. If this 
intermediate condition is satisfied then the task that
has found this element:
  - is allowed to cancel all other tasks in the pool;
  - is allowed to disable that the pool could to
accept new elements for testing;
  - is the only one that is allowed to continue and
calculate the final result.
Structure should either return null (there are no
elements that could satisfy 
an intermediate condition) or final result based on
input "optimal element".

The behavior of the tasks in the pool could be
explained with the following 
picture:

0----5------x
 1-----7----x
  2---6-----x
   3-----9-!-------------->
    4---8---x

Legend:
0, 1, 2, 3, 4: ... finished tasks/elements which could
not satisfy 
                   intermediate condition;
5, 7, 6, 8: ...... canceled tasks by task testing
element number 9;
9: ............... task that has found that an element
that satisfies intermediate 
                   condition, has canceled all other
currently running tasks 
                   in the pool and is allowed to
calculate the final result;
!: ............... time when the task has found out
that the element number 9
                   satisfies an intermediate
condition; from that time on the task 
                   with element number 9 is the only
one executing in the pool;

Is it wise to design such kind of structure? I'm
prepared to do some homework 
but I don't know where to start (which objects to put
together). Is it possible 
that the costs using this kind of structure could be
higher than the benefits?
I'm aware of the examples in class
ExecutorCompletionService but are not 
behaving the way I want.

Best regards,
Andrei



	
		
__________________________________ 
Yahoo! Mail - PC Magazine Editors' Choice 2005 
http://mail.yahoo.com
From joe.bowbeer at gmail.com  Fri Nov  4 02:36:24 2005
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri Nov  4 02:36:57 2005
Subject: [concurrency-interest] Help, how to design a pool of executors
In-Reply-To: <20051104063904.57128.qmail@web50604.mail.yahoo.com>
References: <20051104063904.57128.qmail@web50604.mail.yahoo.com>
Message-ID: <31f2a7bd0511032336k349f960epcdd5270c38ba9a80@mail.gmail.com>

I believe the cancellation mechanism you desire can be implemented by
hooking the done() method of FutureTask.

For some executor service,

ExecutorService service = Executors.newFixedThreadPool(n);

You can create and execute your tasks roughly as follows:

Runnable task = new FutureTask(callable) {
  protected void done() {
    try {
      System.out.println("Answer is " + get());
      // succeeded - shutdown service
      service.shutdownNow();
    } catch (Exception ex) { }
  }
};

service.execute(task);


Note that in our terminology, a ThreadPool executor maintains a "pool"
of threads and a queue of tasks.


On 11/3/05, Andrej Navodnik <andrejnavodnik@yahoo.com> wrote:
> Hello all,
>
> I would kindly ask someone for a gentle hand to guide
> me through the
> problems related to the concurrent programming.
>
> My problem is the following. I'd like to design a
> special structure/pool of
> executors which gives a priority to the task that
> testing element satisfies
> a special intermediate condition. If an algorithm
> could verify that the
> testing element is appropriate for further use then
> the task that has
> found this element is allowed to cancel all other
> tasks in pool and calculate
> the final result based on this "optimal element".
>
> Let's say that I have a set of elements from which I
> want to find  an optimal
> element. During testing whether an element is
> appropriate or not an element must
> satisfy some kind of an intermediate condition. If an
> intermediate condition is
> not satisfied then the pool select another element for
> testing. If this
> intermediate condition is satisfied then the task that
> has found this element:
>   - is allowed to cancel all other tasks in the pool;
>   - is allowed to disable that the pool could to
> accept new elements for testing;
>   - is the only one that is allowed to continue and
> calculate the final result.
> Structure should either return null (there are no
> elements that could satisfy
> an intermediate condition) or final result based on
> input "optimal element".
>
> The behavior of the tasks in the pool could be
> explained with the following
> picture:
>
> 0----5------x
>  1-----7----x
>   2---6-----x
>    3-----9-!-------------->
>     4---8---x
>
> Legend:
> 0, 1, 2, 3, 4: ... finished tasks/elements which could
> not satisfy
>                    intermediate condition;
> 5, 7, 6, 8: ...... canceled tasks by task testing
> element number 9;
> 9: ............... task that has found that an element
> that satisfies intermediate
>                    condition, has canceled all other
> currently running tasks
>                    in the pool and is allowed to
> calculate the final result;
> !: ............... time when the task has found out
> that the element number 9
>                    satisfies an intermediate
> condition; from that time on the task
>                    with element number 9 is the only
> one executing in the pool;
>
> Is it wise to design such kind of structure? I'm
> prepared to do some homework
> but I don't know where to start (which objects to put
> together). Is it possible
> that the costs using this kind of structure could be
> higher than the benefits?
> I'm aware of the examples in class
> ExecutorCompletionService but are not
> behaving the way I want.
>
> Best regards,
> Andrei
>

From TEREKHOV at de.ibm.com  Fri Nov  4 06:44:37 2005
From: TEREKHOV at de.ibm.com (Alexander Terekhov)
Date: Fri Nov  4 06:45:30 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGENOGHAA.dholmes@dltech.com.au>
Message-ID: <OFF7B4BC5C.EA3BD2C7-ONC12570AF.004075B5-C12570AF.003FD4BE@de.ibm.com>



> No one is really sure where they came from.

http://citeseer.ist.psu.edu/birrell87synchronization.html

regards,
alexander.

From David.Biesack at sas.com  Fri Nov  4 08:20:14 2005
From: David.Biesack at sas.com (David J. Biesack)
Date: Fri Nov  4 08:20:51 2005
Subject: [concurrency-interest] Re: spurious wakeups semantics
In-Reply-To: <200511040738.jA47c36q016042@altair.cs.oswego.edu>
	(concurrency-interest-request@cs.oswego.edu)
References: <200511040738.jA47c36q016042@altair.cs.oswego.edu>
Message-ID: <200511041320.jA4DKEQ09238@mozart.unx.sas.com>


Another question: Are spurious wakeups allowed in Java 1.4, or is it only in 1.5 that they are allowed? The 1.4.2 javadoc for java.lang.Object does not mention spurious wakeups, nor does Chapter 17 of JLS 2.0. Or do 1.4 JVMs disallow them and incur the performance penalties mentioned in this thread?

I assume they may occur in 1.4 (and earlier VMs) but just have not been documented. See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4974934 which may have come from a FindBugs analysis of 1.4 source.

thanks

-- 
David J. Biesack     SAS Institute Inc.
(919) 531-7771       SAS Campus Drive
http://www.sas.com   Cary, NC 27513

From josh at bloch.us  Fri Nov  4 10:22:23 2005
From: josh at bloch.us (Joshua Bloch)
Date: Fri Nov  4 10:23:27 2005
Subject: [concurrency-interest] Re: spurious wakeups semantics
In-Reply-To: <200511041320.jA4DKEQ09238@mozart.unx.sas.com>
References: <200511040738.jA47c36q016042@altair.cs.oswego.edu>
	<200511041320.jA4DKEQ09238@mozart.unx.sas.com>
Message-ID: <b097ac510511040722m773bd3dem419ec972eae07f6e@mail.gmail.com>

David,

As a practical matter, they were allowed from  JDK 1.1 at least.  The
specs were not up to snuff, and I am (partly) to blame for this.  When
I arrived at JavaSoft ('96), spurious wakeups could occur, but were
not documented.  For whatever reason, it took us years to document
this authoritatively.

             Josh

On 11/4/05, David J. Biesack <David.Biesack@sas.com> wrote:
>
> Another question: Are spurious wakeups allowed in Java 1.4, or is it only in 1.5 that they are allowed? The 1.4.2 javadoc for java.lang.Object does not mention spurious wakeups, nor does Chapter 17 of JLS 2.0. Or do 1.4 JVMs disallow them and incur the performance penalties mentioned in this thread?
>
> I assume they may occur in 1.4 (and earlier VMs) but just have not been documented. See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4974934 which may have come from a FindBugs analysis of 1.4 source.
>
> thanks
>
> --
> David J. Biesack     SAS Institute Inc.
> (919) 531-7771       SAS Campus Drive
> http://www.sas.com   Cary, NC 27513
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From Pete.Soper at Sun.COM  Fri Nov  4 11:35:39 2005
From: Pete.Soper at Sun.COM (Pete Soper)
Date: Fri Nov  4 11:39:33 2005
Subject: [concurrency-interest] Re: spurious wakeups semantics (more
	history & refs)
In-Reply-To: <200511041320.jA4DKEQ09238@mozart.unx.sas.com>
References: <200511040738.jA47c36q016042@altair.cs.oswego.edu>
	<200511041320.jA4DKEQ09238@mozart.unx.sas.com>
Message-ID: <436B8DDB.2070807@Sun.COM>

Here are some details to go along with Josh's msg about this.

David J. Biesack wrote:
> Another question: Are spurious wakeups allowed in Java 1.4, or is it only in 1.5 that they are allowed? 

The 1.4.2 javadoc for java.lang.Object does not mention spurious
wakeups, nor does Chapter 17 of JLS 2.0.

 Or do 1.4 JVMs disallow them and incur the performance penalties
mentioned in this thread?
> 
> I assume they may occur in 1.4 (and earlier VMs) but just have not been documented.

 See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4974934 which
may have come

 from a FindBugs analysis of 1.4 source.
> 

The bug of interest is 4308396 "Java wait/notify should require
condition variable, allow spurious wakeups" filed against 1.4.0. Here is
the description:

"The current Java Language Specification definition of wait, notify,
   and notifyAll does not require that they be done within a "condition
   variable" paradigm.  The requested change would be to require that
   wait be called from within a loop that tests for a logical condition
   variable, and that notify and notifyAll change the value of that
   condition variable, and that when wait returns the value of the
condition
   variable must be checked to see that it has changed, otherwise the
   loop continues and the wait is reentered.  A corollary of the requested
   change is that waits may return due to spurious wakeups, meaning
operating
   system events unconnected to any action within the Java program."



And the eval:

"The spec should and will be clarified to indicate that spurious wakeups
can occur.  This is one of the many reasons that wait should *always* be
used inside a loop (See Item 50 in Bloch's "Effective Java.")

Note that this does not affect the JLS, which no longer contains the
specifications for the core libraries.  It will affect only the
documentation of the Object.wait method.

--- 2003-01-21


I applaud the proposed change to the specification, but HotSpot JVM
implementors should be aware that for compatibility reaons our
_implementation_  is not permitted to return spuriously from wait().

--- 2003-10-07"

This change was delivered into Java SE 5 ("Tiger") and went into JLS 3.0
as well as the lib javadoc despite the remark above.

The end result is typified by the Object.wait() doc shown here:

 http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html#wait()

Bug 4777391 "unexpected behaviour of Object.wait method" came before the
spec update but shows an extreme case of not having a condition ("test
should be hung !!!" is printed due to a notify by the system).

public class hang extends Thread {
    public static void main(String argv[]) {
        Thread thread = new hang();

        System.out.println("prepare to hang !!");
        try {
            synchronized (thread) {
                thread.start();  /*1*/
    	        thread.wait();   /*2*/
            }

            System.out.println("test should be hung !!!");
        } catch (InterruptedException e) {
            System.out.println("InterruptedException" + e);
        }
    }
}


-Pete
From jmanson at cs.purdue.edu  Fri Nov  4 12:14:16 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Fri Nov  4 12:15:16 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <OFF7B4BC5C.EA3BD2C7-ONC12570AF.004075B5-C12570AF.003FD4BE@de.ibm.com>
References: <OFF7B4BC5C.EA3BD2C7-ONC12570AF.004075B5-C12570AF.003FD4BE@de.ibm.com>
Message-ID: <436B96E8.2040302@cs.purdue.edu>

Alexander Terekhov wrote:
> 
>>No one is really sure where they came from.
> 
> 
> http://citeseer.ist.psu.edu/birrell87synchronization.html
> 

This paper gives the same implementation that David describes as broken 
in the POSIX rationale, no?

					Jeremy
From TEREKHOV at de.ibm.com  Fri Nov  4 13:16:00 2005
From: TEREKHOV at de.ibm.com (Alexander Terekhov)
Date: Fri Nov  4 13:10:01 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <436B96E8.2040302@cs.purdue.edu>
Message-ID: <OFE480EF35.68B58139-ONC12570AF.0062596B-C12570AF.0063A9BD@de.ibm.com>

Jeremy Manson <jmanson@cs.purdue.edu> wrote:
>
> Alexander Terekhov wrote:
> >
> >>No one is really sure where they came from.
> >
> >
> > http://citeseer.ist.psu.edu/birrell87synchronization.html
> >
>
> This paper gives the same implementation that David describes as broken
> in the POSIX rationale, no?

Uhmm, he said:

: The POSIX rationale shows a piece of broken code and uses that to
: justify the possibility of spurious wakeups.

I have no idea what piece of broken code in the POSIX rationale David
was talking about.

regards,
alexander.

From ggagne at westminstercollege.edu  Fri Nov  4 13:48:39 2005
From: ggagne at westminstercollege.edu (Greg Gagne)
Date: Fri Nov  4 13:49:22 2005
Subject: [concurrency-interest] spurious wakeups semantics
Message-ID: <s36b4a9e.058@MAIL.westminstercollege.edu>

>From Butenhof's "Programming with POSIX Threads" p. 80

"Spurious Wakeups : This means that when you wait on a condition variable, the wait may (occasionally) return when no thread specifically broadcast or signaled that condition variable. Spurious wakeups may sound strange, but on some multiprocessor systems, making condition variable wakeup completely predictable might substantially slow all condition variable operations. The race conditions that cause spurious wakeups should be considered rare."

//greg



>>> Alexander Terekhov <TEREKHOV@de.ibm.com> 11/04/05 11:16 AM >>>
Jeremy Manson <jmanson@cs.purdue.edu> wrote:
>
> Alexander Terekhov wrote:
> >
> >>No one is really sure where they came from.
> >
> >
> > http://citeseer.ist.psu.edu/birrell87synchronization.html
> >
>
> This paper gives the same implementation that David describes as broken
> in the POSIX rationale, no?

Uhmm, he said:

: The POSIX rationale shows a piece of broken code and uses that to
: justify the possibility of spurious wakeups.

I have no idea what piece of broken code in the POSIX rationale David
was talking about.

regards,
alexander.

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From jmanson at cs.purdue.edu  Fri Nov  4 13:52:53 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Fri Nov  4 13:53:47 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <OFE480EF35.68B58139-ONC12570AF.0062596B-C12570AF.0063A9BD@de.ibm.com>
References: <OFE480EF35.68B58139-ONC12570AF.0062596B-C12570AF.0063A9BD@de.ibm.com>
Message-ID: <436BAE05.1030307@cs.purdue.edu>

Alexander Terekhov wrote:
> Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> 
>>Alexander Terekhov wrote:
>>
>>>>No one is really sure where they came from.
>>>
>>>
>>>http://citeseer.ist.psu.edu/birrell87synchronization.html
>>>
>>
>>This paper gives the same implementation that David describes as broken
>>in the POSIX rationale, no?
> 
> 
> Uhmm, he said:
> 
> : The POSIX rationale shows a piece of broken code and uses that to
> : justify the possibility of spurious wakeups.
> 
> I have no idea what piece of broken code in the POSIX rationale David
> was talking about.
> 

Okay.  I was specifically thinking of the one on this page:

http://www.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html

					Jeremy
From TEREKHOV at de.ibm.com  Fri Nov  4 14:47:04 2005
From: TEREKHOV at de.ibm.com (Alexander Terekhov)
Date: Fri Nov  4 14:41:01 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <436BAE05.1030307@cs.purdue.edu>
Message-ID: <OF67A6FA72.D801702C-ONC12570AF.006B8AB1-C12570AF.006C0061@de.ibm.com>

Jeremy Manson <jmanson@cs.purdue.edu> wrote:
[...]
> > : The POSIX rationale shows a piece of broken code and uses that to
> > : justify the possibility of spurious wakeups.
> >
> > I have no idea what piece of broken code in the POSIX rationale David
> > was talking about.
> >
>
> Okay.  I was specifically thinking of the one on this page:
>
>
http://www.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html

Ah that. Well, do you see anything truly broken in

http://www.terekhov.de/DESIGN-futex-CV.cpp
http://www.terekhov.de/DESIGN-futex-CV-with-async.cancelable-wait.txt

then? ;-)

regards,
alexander.

From jmanson at cs.purdue.edu  Fri Nov  4 15:02:51 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Fri Nov  4 15:03:32 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <OF67A6FA72.D801702C-ONC12570AF.006B8AB1-C12570AF.006C0061@de.ibm.com>
References: <OF67A6FA72.D801702C-ONC12570AF.006B8AB1-C12570AF.006C0061@de.ibm.com>
Message-ID: <436BBE6B.6020503@cs.purdue.edu>

Alexander Terekhov wrote:
> Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> [...]
> 
>>>: The POSIX rationale shows a piece of broken code and uses that to
>>>: justify the possibility of spurious wakeups.
>>>
>>>I have no idea what piece of broken code in the POSIX rationale David
>>>was talking about.
>>>
>>
>>Okay.  I was specifically thinking of the one on this page:
>>
>> http://www.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html
> 
> Ah that. Well, do you see anything truly broken in
> 
> http://www.terekhov.de/DESIGN-futex-CV.cpp
> http://www.terekhov.de/DESIGN-futex-CV-with-async.cancelable-wait.txt
> 
> then? ;-)
> 

Actually, I was just using the word "broken" to quote David.  As far as 
I am concerned, code that is "broken" is code that does not work 
according to spec.  It is therefore impossible for code that is 
specifically listed in the spec to be broken.

It is, of course, possible for a spec to be broken, but that is a 
different issue.

I was just re-asking the original question - what was the original 
rationale for spurious wakeups?  The code described in the paper that 
you indicated was the same as the code on the POSIX page.  David implied 
there was something mysterious and ancient which required spurious 
wakeups, and existed prior to the POSIX spec.  Anyone know what it was?

					Jeremy
From josh at bloch.us  Fri Nov  4 16:19:51 2005
From: josh at bloch.us (Joshua Bloch)
Date: Fri Nov  4 16:20:24 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <436BBE6B.6020503@cs.purdue.edu>
References: <OF67A6FA72.D801702C-ONC12570AF.006B8AB1-C12570AF.006C0061@de.ibm.com>
	<436BBE6B.6020503@cs.purdue.edu>
Message-ID: <b097ac510511041319r30710066x560f8329430deaeb@mail.gmail.com>

As I understand it, the wording was due to Butehof, and he knew full
well what he was doing.  He simply thought the API led to better
client code.  But you can check with Butenhof, and get the answer
straight from the horse's mouth.

       Josh

On 11/4/05, Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> Alexander Terekhov wrote:
> > Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> > [...]
> >
> >>>: The POSIX rationale shows a piece of broken code and uses that to
> >>>: justify the possibility of spurious wakeups.
> >>>
> >>>I have no idea what piece of broken code in the POSIX rationale David
> >>>was talking about.
> >>>
> >>
> >>Okay.  I was specifically thinking of the one on this page:
> >>
> >> http://www.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html
> >
> > Ah that. Well, do you see anything truly broken in
> >
> > http://www.terekhov.de/DESIGN-futex-CV.cpp
> > http://www.terekhov.de/DESIGN-futex-CV-with-async.cancelable-wait.txt
> >
> > then? ;-)
> >
>
> Actually, I was just using the word "broken" to quote David.  As far as
> I am concerned, code that is "broken" is code that does not work
> according to spec.  It is therefore impossible for code that is
> specifically listed in the spec to be broken.
>
> It is, of course, possible for a spec to be broken, but that is a
> different issue.
>
> I was just re-asking the original question - what was the original
> rationale for spurious wakeups?  The code described in the paper that
> you indicated was the same as the code on the POSIX page.  David implied
> there was something mysterious and ancient which required spurious
> wakeups, and existed prior to the POSIX spec.  Anyone know what it was?
>
>                                         Jeremy
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From levmatta at uol.com.br  Fri Nov  4 20:02:28 2005
From: levmatta at uol.com.br (=?ISO-8859-1?Q?Lu=EDs_Matta?=)
Date: Fri Nov  4 20:03:02 2005
Subject: [concurrency-interest] Class variables and concurrency
Message-ID: <436C04A4.3030501@uol.com.br>

Hello all,
    today I found a very poor code in a webapp that I am helping to develop:
(Obvious buggy)
class Foo {
    public static String CONST_SQL;
    public static String CONST_SQL1 = "select * from a where b = ";
    public static String getA(String param) {
       CONST_SQL = CONST_SQL1 + param;
        ...run query and return result
    }
}
(corrected to)
class Foo {
    //speed is the priority not code beauty
    public static String CONST_SQL1 = "select * from a where b = ";
    //reentrant code
    public static String getA(String param) {
       String CONST_SQL = CONST_SQL1 + param;
        ...run query and return result
    }
}
    Since this method can be run by multiple threads, and we are using 
class variables, this is a theoretical bug. But is it a actual one, is 
there a pratical situation where this bug will manifest itself?
    I ask because since the variable is not synchronized, it appears to 
me that it will get cached and will never be refreshed in any pratical 
situation.

What are the rules for concurrent access to class variables, and what 
how would the Sun JVM (version 1.4.3) behave?

Thanks,
Lu?s

PS: This will run on a powerfull machine (I just know it is new and runs 
solaris) ontop of websphere.
PS2: I know that caching is system dependent and not especified, but I 
am interest in the pratical side of things

From dawidk at mathcs.emory.edu  Sat Nov  5 02:56:50 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sat Nov  5 02:57:25 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436C04A4.3030501@uol.com.br>
References: <436C04A4.3030501@uol.com.br>
Message-ID: <436C65C2.6070303@mathcs.emory.edu>

Lu?s Matta wrote:

> (corrected to)
> class Foo {
>    //speed is the priority not code beauty
>    public static String CONST_SQL1 = "select * from a where b = ";
>    //reentrant code
>    public static String getA(String param) {
>       String CONST_SQL = CONST_SQL1 + param;
>        ...run query and return result
>    }
> }

Make CONST_SQL1 final (and perhaps private), rename CONST_SQL to 
something more sensible (e.g. query), remove the comment about speed, 
and you're fine. Final fields and local variables are thread-safe (do 
not need synchronization).

>    Since this method can be run by multiple threads, and we are using 
> class variables, this is a theoretical bug. 

There is no such thing as theoretical bug. Especially when concurrency 
is involved.

>
> PS: This will run on a powerfull machine (I just know it is new and 
> runs solaris) ontop of websphere.
> PS2: I know that caching is system dependent and not especified, but I 
> am interest in the pratical side of things
>
It is very dangerous to take concurrency so lightly. It can cost your 
company a lot of money. The most subtle concurrency bugs usually do not 
appear until the application is deployed and under heavy load [I'm 
shamelessly borrowing from JCiP here]. And that is usually the worst 
possible moment to have a system failure, resulting in your clients or 
your boss wanting to hurt you and your family. It is *crucial* to design 
the code carefully and to code defensively to eliminate concurrency 
problems at the design level. Testing is simply not good enough. Even 
more so because it seems that you are unable to run tests on the target 
machine. Concurrency problems can often go unnoticed on uniprocessor 
developer machines, but come to light on powerful, multiprocessor 
application servers.

Regards,
Dawid Kurzyniec

From andrejnavodnik at yahoo.com  Sat Nov  5 09:58:48 2005
From: andrejnavodnik at yahoo.com (Andrej Navodnik)
Date: Sat Nov  5 09:59:26 2005
Subject: [concurrency-interest] Re: Help, how to design a pool of threads
Message-ID: <20051105145848.4677.qmail@web50605.mail.yahoo.com>

Hi all,

let's say that I did some homework ;-) Here is my
code:

import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Random;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

public class Test {
  public static void main(String... args) {
    int N = 100;
    FindOptimalElement s = new FindOptimalElement(
        prepareTestData(N));
    System.out.println(
        "Waiting for optimal element...");
    Result r = s.get();
    System.out.println("Result: " + r);
    System.exit(0);
  }
  
  static List<Pair> prepareTestData(int n) {
    Random r = new Random();
    List<Pair> testData = new ArrayList<Pair>();
    for (int i = 0; i < n; i++) {
      double a = r.nextDouble();
      double b = r.nextDouble();
      testData.add(new Pair(a, b));
    }
    return testData;
  }
}

interface OptimalElement<E> {
  boolean isOptimalElement(E e);
}

class FindOptimalElement {
  private static final int NUMBER_WORKERS = 10;
  private final AtomicBoolean optimalElementFound;
  private final AtomicInteger testedData;
  private final int numberOfData;
  private final BlockingQueue<Future<Result>> workers;
  private final ReentrantLock dataLock;
  private volatile Result result;
  private volatile Condition resultPrepared;
  private boolean resultDefined;
  private final ThreadPoolExecutor service;
  
  FindOptimalElement(List<Pair> data) {
    this.numberOfData = data.size();
    this.optimalElementFound = 
        new AtomicBoolean(false);
    this.testedData = new AtomicInteger(0);
    this.dataLock = new ReentrantLock();
    this.resultPrepared = dataLock.newCondition();
    this.workers = 
        new ArrayBlockingQueue<Future<Result>>(
        NUMBER_WORKERS);
    
    int corePoolSize = NUMBER_WORKERS;
    int maximumPoolSize = NUMBER_WORKERS;
    long keepAliveTime = 1;
    BlockingQueue<Runnable> workQueue =
        new LinkedBlockingQueue<Runnable>();
    service = new ThreadPoolExecutor(corePoolSize,
        maximumPoolSize, keepAliveTime,
        TimeUnit.SECONDS, workQueue);
    service.prestartAllCoreThreads();
    
    service.execute(new Producer(data));
    service.execute(new Consumer());
  }
  
  // how should I cancel/stop other threads, 
  // is this possible??
  private void cancelRunnables(
      Runnable excludeRunnable) {
    BlockingQueue<Runnable> queue=service.getQueue();
    Runnable[] runnables = (Runnable[]) Array
        .newInstance(Runnable.class, NUMBER_WORKERS);
    queue.toArray(runnables);
    for (Runnable r : runnables) {
      System.out.println("Task: " + r);
      if (r != null && !r.equals(excludeRunnable)) {
        System.out.println("Removed task: " + r);
        service.remove(r);
      }
    }
    service.purge();
    System.out.println("Other threads in the pool " +
        "should be canceled/removed, are they?");
  }
  
  class Producer implements Runnable {
    private final List<Pair> testData;
    Producer(List<Pair> testData) {
      this.testData = testData;
    }
    public void run() {
      try {
        for (Pair p : testData) {
          Callable<Result> c = new Worker(p);
          Future<Result> task = service.submit(c);
          workers.put(task);
        }
      } catch (InterruptedException ie) {
        ie.printStackTrace();
      }
    }
  }
  
  class Consumer implements Runnable {
    public void run() {
      for (;;) {
        try {
          final Future<Result> f = workers.take();
          Runnable task = new PrepareResult(f);
          service.execute(task);
        } catch (InterruptedException ie) {
          ie.printStackTrace();
          return ;
        }
      }
    }
    
    class PrepareResult implements Runnable {
      private final Future<Result> f;
      PrepareResult(Future<Result> f) {
        this.f = f;
      }
      public void run() {
        try {
          Result r = f.get();
          dataLock.lock();
          try {
            if (r != null) {
              result = r;
              resultDefined = true;
              resultPrepared.signal();
            }
            if (!resultDefined) {
              int n = testedData.incrementAndGet();
              if (n==numberOfData) {
                System.out.println(
                    "All data tested, " +
                    "no optimal element found...");
                resultDefined = true;
                resultPrepared.signal();
              }
            }
          } finally {
            dataLock.unlock();
          }
          
        } catch (ExecutionException ee) {
          ee.printStackTrace();
        } catch (InterruptedException ie) {
          ie.printStackTrace();
        }
      }
    }
  }
  
  public Result get() {
    dataLock.lock();
    try {
      while (resultDefined == false)
        resultPrepared.await();
    } catch (InterruptedException ex) {
      ex.printStackTrace();
    } finally {
      dataLock.unlock();
    }
    return result;
  }
  
  private class Worker implements Callable<Result>,
      OptimalElement<Pair> {
    private final Pair p;
    
    Worker(Pair p) {
      this.p = p;
    }
    
    public Result call() {
      if (optimalElementFound.get()) {
        return null;
      }
      System.out.println(
        "Seaching for optimal element...");
      try {
        Thread.sleep(1000);
      } catch (InterruptedException ex) {
        ex.printStackTrace();
      }
      
      // check if the element satisfies intermediate
      // condition
      if (isOptimalElement(p)) {
        System.out.println(
          "Optimal element is found...");
        for(;;) {
          if (!optimalElementFound.get()) {
            optimalElementFound.compareAndSet(
              false, true);
            if (optimalElementFound.get()) {
              break;
            }
          } else
            return null;
        }
        
        // if proper element is found then 
        // cancel other tasks, 
        // actually this does not work
        System.out.println("Cancel other threads...");
        Thread currentThread = Thread.currentThread();
        cancelRunnables(currentThread);
        
        try {
          // simulate hard work, to find solution
          Thread.sleep(10000);
        } catch (InterruptedException ex) {
          ex.printStackTrace();
        }
        
        // final phase, prepare result
        System.out.println(Thread.currentThread() +
            ": Returning optimal element...");
        return new Result(p, p.a+p.b);
      } else {
        try {
          // simulate useless job that should
          // not be executed
          Thread.sleep(2000);
        } catch (InterruptedException ex) {
          ex.printStackTrace();
        }
        if (optimalElementFound.get()) {
          System.out.println(Thread.currentThread() +
              ": Task is still doing useless " + 
              "things...");
        }
        return null;
      }
    }
    
    public boolean isOptimalElement(Pair p) {
      return  p.a > 0.8 && p.b > 0.8;
      // simulate hard to find optimal element, result

      // should be null;
      //return  p.a > 0.99 && p.b > 0.99;
    }
  }
}


class Result {
  public final double sum;
  public final Pair p;
  Result(Pair p, double sum) {
    this.p = p;
    this.sum = sum;
  }
  public String toString() {
    return "Input: " + p + " ==> result: " + sum;
  }
}

class Pair {
  public final double a;
  public final double b;
  Pair(double a, double b) {
    this.a = a;
    this.b = b;
  }
  public String toString() {
    return "[a: " + a + ", b: " + b + "]";
  }
}


If the input data set contains optimal data then the 
output of the program is the following:

Waiting for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Seaching for optimal element...
Optimal element is found...
Cancel other threads...
Task: null
Task: null
Task: null
Task: null
Task: null
Task: null
Task: null
Task: null
Task: null
Task: null
Other threads in the pool should be canceled/removed,
are they?
Thread[pool-1-thread-6,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-5,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-1,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-3,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-4,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-10,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-9,5,main]: Task is still doing   
             useless things...
Thread[pool-1-thread-7,5,main]: Task is still doing
useless things...
Thread[pool-1-thread-8,5,main]: Returning optimal
element...
Result: Input: [a: 0.9554837437185378, b:
0.8581452336165145] ==> result: 1.8136289773350525

My questions are:
- how should I design my application so that the tasks

in the pool would be canceled/stopped after the 
optimal element is found except for the task 
that has found that ?optimal element? - I wouldn't 
like to see the message ?Task is still doing useless
things? because it's actually using resources that
should be used fior preparing the final result;
- should I concern about this problem or not?
- are there any other constructs that I could 
use and achieve the same result?

Best regards,
Andrei

P.S.: Please don't laugh at my code, I'm still 
beginner as far as concurrent programming is
concerned...


		




		
__________________________________ 
Yahoo! FareChase: Search multiple travel sites in one click.
http://farechase.yahoo.com
From dl at cs.oswego.edu  Sat Nov  5 10:20:58 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat Nov  5 10:22:51 2005
Subject: [concurrency-interest] Re: Help, how to design a pool of threads
In-Reply-To: <20051105145848.4677.qmail@web50605.mail.yahoo.com>
References: <20051105145848.4677.qmail@web50605.mail.yahoo.com>
Message-ID: <436CCDDA.6000408@cs.oswego.edu>

Andrej Navodnik wrote:
> 
> My questions are:
> - how should I design my application so that the tasks
> 
> in the pool would be canceled/stopped after the 
> optimal element is found except for the task 
> that has found that ?optimal element? - I wouldn't 
> like to see the message ?Task is still doing useless
> things? because it's actually using resources that
> should be used fior preparing the final result;
> - should I concern about this problem or not?
> - are there any other constructs that I could 
> use and achieve the same result?
> 

You might find the second code example in the ExecutorCompletionService
javadoc helpful. See

http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/ExecutorCompletionService.html

-Doug


From joe.bowbeer at gmail.com  Sat Nov  5 10:55:15 2005
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat Nov  5 10:55:51 2005
Subject: [concurrency-interest] Re: Help, how to design a pool of threads
In-Reply-To: <20051105145848.4677.qmail@web50605.mail.yahoo.com>
References: <20051105145848.4677.qmail@web50605.mail.yahoo.com>
Message-ID: <31f2a7bd0511050755v7c6e6cfdr1203f8f9627f6d1e@mail.gmail.com>

First, I'm trying to understand the threading scheme.  It looks likethere is a producer that submits worker tasks to the pool and aconsumer that processes the results.  I suggest you move the producerand consumer into the same thread.  Perhaps this could be the mainthread.  That is, after you create the service, do the producer thingin the main thread next, submitting the worker tasks to the service;then do the consumer thing, processing the results.  If the mainthread won't do, move the producer and consumer to a single backgroundthread.
Moving the producer and consumer into a single thread leaves thethread pool dedicated to the worker tasks.  Easier to manage thatway...
> My questions are:
> - how should I design my application so that the tasks> in the pool would be canceled/stopped after the> optimal element is found except for the task> that has found that ?optimal element? - I wouldn't> like to see the message ?Task is still doing useless> things? because it's actually using resources that> should be used fior preparing the final result;
FutureTasks are cancelled by calling task.cancel(true);
If the task is still in the queue, this will prevent the task fromever running.  If the task is already actively running, this will alsointerrupt the thread that's running the task.
But the task must be responsive to interrupts.  That is, wheninterrupted, the task should promptly quit.  If the task could bewaiting on a lock when it is interrupted, I recommend usinglockInterruptibly().  If the task sleeps, then don't catch theInterruptedException, just let the task (ie, Callable.call) throwInterruptedException.  Finally, if the task is looping withoutblocking then it can check isCancelled() to see if it's beencancelled.
Your cancelRunnables method removes tasks from the service's queue butdoes not attempt to cancel running tasks.  Would it work better tocancel all the tasks in the workers list?  If the service is dedicatedto workers, though, then service.shutdownNow will do this for you.  Itcancels all active tasks.
> - should I concern about this problem or not?
Yes.
> - are there any other constructs that I could> use and achieve the same result?>
Use a completion service work for the consumer thing?
Joe.

On 11/5/05, Andrej Navodnik <andrejnavodnik@yahoo.com> wrote:> Hi all,>> let's say that I did some homework ;-) Here is my> code:>> import java.lang.reflect.Array;> import java.util.ArrayList;> import java.util.Iterator;> import java.util.List;> import java.util.Random;> import java.util.concurrent.ArrayBlockingQueue;> import java.util.concurrent.BlockingQueue;> import java.util.concurrent.Callable;> import java.util.concurrent.ExecutionException;> import java.util.concurrent.ExecutorService;> import java.util.concurrent.Executors;> import java.util.concurrent.Future;> import java.util.concurrent.LinkedBlockingQueue;> import java.util.concurrent.ThreadPoolExecutor;> import java.util.concurrent.TimeUnit;> import java.util.concurrent.atomic.AtomicBoolean;> import java.util.concurrent.atomic.AtomicInteger;> import java.util.concurrent.locks.Condition;> import java.util.concurrent.locks.ReentrantLock;>> public class Test {>   public static void main(String... args) {>     int N = 100;>     FindOptimalElement s = new FindOptimalElement(>         prepareTestData(N));>     System.out.println(>         "Waiting for optimal element...");>     Result r = s.get();>     System.out.println("Result: " + r);>     System.exit(0);>   }>>   static List<Pair> prepareTestData(int n) {>     Random r = new Random();>     List<Pair> testData = new ArrayList<Pair>();>     for (int i = 0; i < n; i++) {>       double a = r.nextDouble();>       double b = r.nextDouble();>       testData.add(new Pair(a, b));>     }>     return testData;>   }> }>> interface OptimalElement<E> {>   boolean isOptimalElement(E e);> }>> class FindOptimalElement {>   private static final int NUMBER_WORKERS = 10;>   private final AtomicBoolean optimalElementFound;>   private final AtomicInteger testedData;>   private final int numberOfData;>   private final BlockingQueue<Future<Result>> workers;>   private final ReentrantLock dataLock;>   private volatile Result result;>   private volatile Condition resultPrepared;>   private boolean resultDefined;>   private final ThreadPoolExecutor service;>>   FindOptimalElement(List<Pair> data) {>     this.numberOfData = data.size();>     this.optimalElementFound =>         new AtomicBoolean(false);>     this.testedData = new AtomicInteger(0);>     this.dataLock = new ReentrantLock();>     this.resultPrepared = dataLock.newCondition();>     this.workers =>         new ArrayBlockingQueue<Future<Result>>(>         NUMBER_WORKERS);>>     int corePoolSize = NUMBER_WORKERS;>     int maximumPoolSize = NUMBER_WORKERS;>     long keepAliveTime = 1;>     BlockingQueue<Runnable> workQueue =>         new LinkedBlockingQueue<Runnable>();>     service = new ThreadPoolExecutor(corePoolSize,>         maximumPoolSize, keepAliveTime,>         TimeUnit.SECONDS, workQueue);>     service.prestartAllCoreThreads();>>     service.execute(new Producer(data));>     service.execute(new Consumer());>   }>>   // how should I cancel/stop other threads,>   // is this possible??>   private void cancelRunnables(>       Runnable excludeRunnable) {>     BlockingQueue<Runnable> queue=service.getQueue();>     Runnable[] runnables = (Runnable[]) Array>         .newInstance(Runnable.class, NUMBER_WORKERS);>     queue.toArray(runnables);>     for (Runnable r : runnables) {>       System.out.println("Task: " + r);>       if (r != null && !r.equals(excludeRunnable)) {>         System.out.println("Removed task: " + r);>         service.remove(r);>       }>     }>     service.purge();>     System.out.println("Other threads in the pool " +>         "should be canceled/removed, are they?");>   }>>   class Producer implements Runnable {>     private final List<Pair> testData;>     Producer(List<Pair> testData) {>       this.testData = testData;>     }>     public void run() {>       try {>         for (Pair p : testData) {>           Callable<Result> c = new Worker(p);>           Future<Result> task = service.submit(c);>           workers.put(task);>         }>       } catch (InterruptedException ie) {>         ie.printStackTrace();>       }>     }>   }>>   class Consumer implements Runnable {>     public void run() {>       for (;;) {>         try {>           final Future<Result> f = workers.take();>           Runnable task = new PrepareResult(f);>           service.execute(task);>         } catch (InterruptedException ie) {>           ie.printStackTrace();>           return ;>         }>       }>     }>>     class PrepareResult implements Runnable {>       private final Future<Result> f;>       PrepareResult(Future<Result> f) {>         this.f = f;>       }>       public void run() {>         try {>           Result r = f.get();>           dataLock.lock();>           try {>             if (r != null) {>               result = r;>               resultDefined = true;>               resultPrepared.signal();>             }>             if (!resultDefined) {>               int n = testedData.incrementAndGet();>               if (n==numberOfData) {>                 System.out.println(>                     "All data tested, " +>                     "no optimal element found...");>                 resultDefined = true;>                 resultPrepared.signal();>               }>             }>           } finally {>             dataLock.unlock();>           }>>         } catch (ExecutionException ee) {>           ee.printStackTrace();>         } catch (InterruptedException ie) {>           ie.printStackTrace();>         }>       }>     }>   }>>   public Result get() {>     dataLock.lock();>     try {>       while (resultDefined == false)>         resultPrepared.await();>     } catch (InterruptedException ex) {>       ex.printStackTrace();>     } finally {>       dataLock.unlock();>     }>     return result;>   }>>   private class Worker implements Callable<Result>,>       OptimalElement<Pair> {>     private final Pair p;>>     Worker(Pair p) {>       this.p = p;>     }>>     public Result call() {>       if (optimalElementFound.get()) {>         return null;>       }>       System.out.println(>         "Seaching for optimal element...");>       try {>         Thread.sleep(1000);>       } catch (InterruptedException ex) {>         ex.printStackTrace();>       }>>       // check if the element satisfies intermediate>       // condition>       if (isOptimalElement(p)) {>         System.out.println(>           "Optimal element is found...");>         for(;;) {>           if (!optimalElementFound.get()) {>             optimalElementFound.compareAndSet(>               false, true);>             if (optimalElementFound.get()) {>               break;>             }>           } else>             return null;>         }>>         // if proper element is found then>         // cancel other tasks,>         // actually this does not work>         System.out.println("Cancel other threads...");>         Thread currentThread = Thread.currentThread();>         cancelRunnables(currentThread);>>         try {>           // simulate hard work, to find solution>           Thread.sleep(10000);>         } catch (InterruptedException ex) {>           ex.printStackTrace();>         }>>         // final phase, prepare result>         System.out.println(Thread.currentThread() +>             ": Returning optimal element...");>         return new Result(p, p.a+p.b);>       } else {>         try {>           // simulate useless job that should>           // not be executed>           Thread.sleep(2000);>         } catch (InterruptedException ex) {>           ex.printStackTrace();>         }>         if (optimalElementFound.get()) {>           System.out.println(Thread.currentThread() +>               ": Task is still doing useless " +>               "things...");>         }>         return null;>       }>     }>>     public boolean isOptimalElement(Pair p) {>       return  p.a > 0.8 && p.b > 0.8;>       // simulate hard to find optimal element, result>>       // should be null;>       //return  p.a > 0.99 && p.b > 0.99;>     }>   }> }>>> class Result {>   public final double sum;>   public final Pair p;>   Result(Pair p, double sum) {>     this.p = p;>     this.sum = sum;>   }>   public String toString() {>     return "Input: " + p + " ==> result: " + sum;>   }> }>> class Pair {>   public final double a;>   public final double b;>   Pair(double a, double b) {>     this.a = a;>     this.b = b;>   }>   public String toString() {>     return "[a: " + a + ", b: " + b + "]";>   }> }>>> If the input data set contains optimal data then the> output of the program is the following:>> Waiting for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Seaching for optimal element...> Optimal element is found...> Cancel other threads...> Task: null> Task: null> Task: null> Task: null> Task: null> Task: null> Task: null> Task: null> Task: null> Task: null> Other threads in the pool should be canceled/removed,> are they?> Thread[pool-1-thread-6,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-5,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-1,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-3,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-4,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-10,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-9,5,main]: Task is still doing>              useless things...> Thread[pool-1-thread-7,5,main]: Task is still doing> useless things...> Thread[pool-1-thread-8,5,main]: Returning optimal> element...> Result: Input: [a: 0.9554837437185378, b:> 0.8581452336165145] ==> result: 1.8136289773350525>> My questions are:> - how should I design my application so that the tasks>> in the pool would be canceled/stopped after the> optimal element is found except for the task> that has found that ?optimal element? - I wouldn't> like to see the message ?Task is still doing useless> things? because it's actually using resources that> should be used fior preparing the final result;> - should I concern about this problem or not?> - are there any other constructs that I could> use and achieve the same result?>> Best regards,> Andrei>> P.S.: Please don't laugh at my code, I'm still> beginner as far as concurrent programming is> concerned...>
From andrejnavodnik at yahoo.com  Sat Nov  5 11:52:20 2005
From: andrejnavodnik at yahoo.com (Andrej Navodnik)
Date: Sat Nov  5 11:52:57 2005
Subject: [concurrency-interest] Re: Help, how to design a pool of threads
In-Reply-To: <436CCDDA.6000408@cs.oswego.edu>
Message-ID: <20051105165220.22908.qmail@web50606.mail.yahoo.com>

Hi Doug,

thank you very much for your quick response. 

I have already studied the example program you have
suggested but if I understand it correctly the threads
in the pool are canceled/stopped AFTER the final
result is found/prepared. Actually, I'd like to have a
pool where threads could be canceled/stopped BEFORE
one the threads prepares final result. 

Suppose that the algorithm is testing different
variants for the next  step and that this phase must
also produce some data for the next  step. Suppose
also, that during this step, let's say approximately
about at 1/3 to 1/5 of the total work, it must decide
whether the input data would produce useful results or
not. If the input data could not produce useful result
then the algorithm should try with another parameters.
But in case that the algorithm could predict that the
result could be useful then I'd like to stop other
threads because they are using valuable resources
(CPU) and I'd like to give priority only to the thread
that is one the right path. So, I'd like to test some
kind of an intermediate condition and AFTER this
condition there would be only one working thread in
the pool which would produce result. I'd like to
implement a strategy where only an owner of the right
token is given the right to run in the final. 

Best regards,
Andrei


--- Doug Lea <dl@cs.oswego.edu> wrote:

> Andrej Navodnik wrote:
> > 
> > My questions are:
> > - how should I design my application so that the
> tasks
> > 
> > in the pool would be canceled/stopped after the 
> > optimal element is found except for the task 
> > that has found that ?optimal element? - I wouldn't
> 
> > like to see the message ?Task is still doing
> useless
> > things? because it's actually using resources that
> > should be used fior preparing the final result;
> > - should I concern about this problem or not?
> > - are there any other constructs that I could 
> > use and achieve the same result?
> > 
> 
> You might find the second code example in the
> ExecutorCompletionService
> javadoc helpful. See
> 
>
http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/ExecutorCompletionService.html
> 
> -Doug
> 
> 



	
		
__________________________________ 
Yahoo! Mail - PC Magazine Editors' Choice 2005 
http://mail.yahoo.com
From andrejnavodnik at yahoo.com  Sat Nov  5 12:01:15 2005
From: andrejnavodnik at yahoo.com (Andrej Navodnik)
Date: Sat Nov  5 12:01:54 2005
Subject: [concurrency-interest] Re: Help, how to design a pool of threads
In-Reply-To: <31f2a7bd0511050755v7c6e6cfdr1203f8f9627f6d1e@mail.gmail.com>
Message-ID: <20051105170116.10134.qmail@web50611.mail.yahoo.com>

Hello Joe,

thank you very much for your reply. I will carefuly
consider all your suggestions.

Back to my homework...
Andrei

--- Joe Bowbeer <joe.bowbeer@gmail.com> wrote:

> First, I'm trying to understand the threading
> scheme.  It looks like
> there is a producer that submits worker tasks to the
> pool and a
> consumer that processes the results.  I suggest you
> move the producer
> and consumer into the same thread.  Perhaps this
> could be the main
> thread.  That is, after you create the service, do
> the producer thing
> in the main thread next, submitting the worker tasks
> to the service;
> then do the consumer thing, processing the results. 
> If the main
> thread won't do, move the producer and consumer to a
> single background
> thread.
> 
> Moving the producer and consumer into a single
> thread leaves the
> thread pool dedicated to the worker tasks.  Easier
> to manage that
> way...
> 
> > My questions are:
> 
> > - how should I design my application so that the
> tasks
> > in the pool would be canceled/stopped after the
> > optimal element is found except for the task
> > that has found that "optimal element" - I
> wouldn't
> > like to see the message ???Task is still doing
> useless
> > things??? because it's actually using resources
> that
> > should be used fior preparing the final result;
> 
> FutureTasks are cancelled by calling
> task.cancel(true);
> 
> If the task is still in the queue, this will prevent
> the task from
> ever running.  If the task is already actively
> running, this will also
> interrupt the thread that's running the task.
> 
> But the task must be responsive to interrupts.  That
> is, when
> interrupted, the task should promptly quit.  If the
> task could be
> waiting on a lock when it is interrupted, I
> recommend using
> lockInterruptibly().  If the task sleeps, then don't
> catch the
> InterruptedException, just let the task (ie,
> Callable.call) throw
> InterruptedException.  Finally, if the task is
> looping without
> blocking then it can check isCancelled() to see if
> it's been
> cancelled.
> 
> Your cancelRunnables method removes tasks from the
> service's queue but
> does not attempt to cancel running tasks.  Would it
> work better to
> cancel all the tasks in the workers list?  If the
> service is dedicated
> to workers, though, then service.shutdownNow will do
> this for you.  It
> cancels all active tasks.
> 
> > - should I concern about this problem or not?
> 
> Yes.
> 
> > - are there any other constructs that I could
> > use and achieve the same result?
> >
> 
> Use a completion service work for the consumer
> thing?
> 
> Joe.



	
		
__________________________________ 
Yahoo! Mail - PC Magazine Editors' Choice 2005 
http://mail.yahoo.com
From sergemasse1 at yahoo.com  Sat Nov  5 13:32:16 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Sat Nov  5 13:32:51 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436C65C2.6070303@mathcs.emory.edu>
Message-ID: <20051105183216.30566.qmail@web51402.mail.yahoo.com>

Dawid,
I thought that William Pugh
(http://www.cs.umd.edu/~pugh/papers/jmm2.pdf), Jeremy
Manson (recently in this list
http://altair.cs.oswego.edu/pipermail/concurrency-interest/2005-November/002084.html)
and with Brian Goetz
(http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html),
stated something to the effect that *final* fields
(which includes String's) were not threadsafe in Java
1.4 down and thus require explicit synchronization
constructs to be added by programmers, like all
non-final shared fields (*final* fields are threadsafe
in Java 5 without additional code). 

Is this correct about *final* fields requiring
synchronization in 1.4 down?

If this is the case, then ladies and gentlemen, we are
about to have real problem with these new multi-core
chips, aren't we? Probably much bigger than the Y2K
problem because soon most of our software is going to
migrate from single cpu chips to multiprocessor chips
and possibly much new defects will occur in
multithreaded apps. And I tend to agree with David
Homes that apps that have run correctly on SMP
(symmetric multiprocessors) are less likely to show
defects when run on multi-core chips, although the
chance is probably not zero. 

Are there estimates of the risks of migrating
multithreaded apps to multi-core chips from single
processor and from SMP, and to SMP from single
processor? It would be very important to see a
percentage of new problems observed in apps that have
been ported from single to SMP (which have been in
widespread use for a while now).

I'm getting very nervous about this. For example, I
migrated my open source projects to Java 5 back in
2004 but I may still have to painfully re-test them
for multi-core chips because the Java 5 versions were
only tested on single processor systems. I also have
to give some very bad news to my clients who are
mostly still at 1.3 and 1.4.

I predict that if multithreaded Java apps show a
significant percentage of new defects when ported to
multi-core chips and dotnet apps don't (or show a
lower percentage), then virtually the only such chips
that will sell will be those that are supported by
dotnet and Java development will become a memory,
unless this issue is addressed now.

JSRs 133 and 166 are great but not sufficient for the
current average programmer.

For example, the Java community could develop a new
language or design tool that would:
- make it very easy to develop safe multithreaded apps
(new apps);
- automatically transform and render threadsafe
existing Java apps (old apps).

Are there such projects now? Is Fortress one of these
(http://research.sun.com/sunlabsday/talks.php?id=55)?
Are there others? 

serge


--- Dawid Kurzyniec <dawidk@mathcs.emory.edu> wrote:

> Lu?s Matta wrote:
> 
> > (corrected to)
> > class Foo {
> >    //speed is the priority not code beauty
> >    public static String CONST_SQL1 = "select *
> from a where b = ";
> >    //reentrant code
> >    public static String getA(String param) {
> >       String CONST_SQL = CONST_SQL1 + param;
> >        ...run query and return result
> >    }
> > }
> 
> Make CONST_SQL1 final (and perhaps private), rename
> CONST_SQL to 
> something more sensible (e.g. query), remove the
> comment about speed, 
> and you're fine. Final fields and local variables
> are thread-safe (do 
> not need synchronization).
> 
> >    Since this method can be run by multiple
> threads, and we are using 
> > class variables, this is a theoretical bug. 
> 
> There is no such thing as theoretical bug.
> Especially when concurrency 
> is involved.
> 
> >
> > PS: This will run on a powerfull machine (I just
> know it is new and 
> > runs solaris) ontop of websphere.
> > PS2: I know that caching is system dependent and
> not especified, but I 
> > am interest in the pratical side of things
> >
> It is very dangerous to take concurrency so lightly.
> It can cost your 
> company a lot of money. The most subtle concurrency
> bugs usually do not 
> appear until the application is deployed and under
> heavy load [I'm 
> shamelessly borrowing from JCiP here]. And that is
> usually the worst 
> possible moment to have a system failure, resulting
> in your clients or 
> your boss wanting to hurt you and your family. It is
> *crucial* to design 
> the code carefully and to code defensively to
> eliminate concurrency 
> problems at the design level. Testing is simply not
> good enough. Even 
> more so because it seems that you are unable to run
> tests on the target 
> machine. Concurrency problems can often go unnoticed
> on uniprocessor 
> developer machines, but come to light on powerful,
> multiprocessor 
> application servers.
> 
> Regards,
> Dawid Kurzyniec
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
>
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From levmatta at uol.com.br  Sat Nov  5 17:05:31 2005
From: levmatta at uol.com.br (=?ISO-8859-1?Q?Lu=EDs_Matta?=)
Date: Sat Nov  5 17:06:09 2005
Subject: [concurrency-interest] Class variables and concurrency
Message-ID: <436D2CAB.5070203@uol.com.br>

Thanks Dawid Kurzyniec,
    just to clarify some things (and ask another)...

When I sad "theoretical bug" , and I realy missed on the words there, what I meant was: it is a coding bug, but will is it one that will manifest itself (actual bug). Sorry.

OK, so I got of my lazy butt and I have created a simple test attached below and the bug _*DID*_ manifest itself.
Any comments on it?.

Results on a machine running Windows XP Sp2 on a P4 with HT (aproximate maximuns):
jvm  runs threads iterations result
5_05 5    50      |10000      0.008%
6b54 5    50      10000      0.05%
5-05 3    2       100        2.5%

I believe that 2 threads is my systems maximum concurrent capability, so I tested it.
Note that the jvm 6b54 gives a much higher result. How come?|

Thanks,
Lu?s Matta

|import java.util.concurrent.atomic.AtomicInteger;
public class Main {
    private static String CONST;
    private static final String CONST1 = "1+";
    
    protected static AtomicInteger atomic = new AtomicInteger(0);
    
    public Main() {
    }
    
    public static String doIt(char param) {
         CONST =  CONST1  + param;
         return CONST;
    }
    public static void main(String[] args) {
        char [] params = new char[50];//number of runs
        for (int i=0; i<params.length; i++){
            params[i] = (char) i;
        }
        
        for (char param: params) {
            Thread t = new Thread(new ThreadTest(param));
            t.start();            
        }
    }
    
    private static class ThreadTest implements Runnable {
        public ThreadTest(char param) {
            this.param = param;
        }
        protected char param;

        public void run() {
            for (int i =0; i<10000; i++){//number of iterations
                String res = Main.doIt(param);
                if (res.charAt(2)!=param){
                    atomic.incrementAndGet();
                }
            }
            System.out.println("Atomic value:"+Integer.toString(atomic.get()));
        }
    }
}
|
PS: Thanks for the "final" modifier I did miss it in the code. Much better now.
PS: When I mentioned speed, I was refering to coding one. The app MUST be released by the end of the month.||


From dawidk at mathcs.emory.edu  Sat Nov  5 18:51:29 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sat Nov  5 18:52:17 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436D2CAB.5070203@uol.com.br>
References: <436D2CAB.5070203@uol.com.br>
Message-ID: <436D4581.5000407@mathcs.emory.edu>

Lu?s Matta wrote:

> OK, so I got of my lazy butt and I have created a simple test attached 
> below and the bug _*DID*_ manifest itself.
> Any comments on it?.
>
I may have misunderstood your first post. Were you asking if the bug in 
the *original* code will manifest itself? Well, you've just found out 
yourself that yes, very much so. Now, I was responding to your fix: for 
it to be 100% correct, you need that "final". To my understanding 
(experts correct me if I'm wrong), you may otherwise see this field 
uninitialized (i.e. null) in some threads. The simplest way to avoid 
worrying about it is to use that "final".

Because of the race condition, the code you were testing is 
undeterministic, which means in practice that it depends on so many 
things that differences between JVMs come at no surprise.

Regards,
Dawid


From sergemasse1 at yahoo.com  Sun Nov  6 10:26:35 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Sun Nov  6 10:27:17 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet MemoryModel
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEOAGHAA.dholmes@dltech.com.au>
Message-ID: <20051106152635.24828.qmail@web51402.mail.yahoo.com>

David Holmes wrote: "Given that multi-core chips are
supposed to be transparent to the software (ie the
software can't tell if it is running on multi-core or
SMP) then I don't expect to suddenly see problems with
software that ran on a SMP before and is now run on
multi-core. Of course, software that has only run on a
single processor before may well exhibit previously
undetected concurrency bugs when run with multiple
processors and/or cores."

Thank you David.

Should we worry about multicores soon to be
ubiquitous?

Let's just consider servlets (and jsps) for example.

There are millions of them currently running.

A large portion of them are currently running on
uniprocessors and probably most of these are slated to
be ported to multicore systems over the next few
years.

What is the expected percentage of these that will
show new defects when ported to multicore?

I am worried by this but maybe I shouldn't be.
Nevertheless, there are quite a few signals raising
alarms about the issue of concurrent Java code ported
from uniprocessors to multicore and I hope that this
mailing list will be helpful about it, as I think it
is part of its purpose.

Thank you for all who make this list so informative
and useful.

serge

From tim at peierls.net  Sun Nov  6 11:53:09 2005
From: tim at peierls.net (Tim Peierls)
Date: Sun Nov  6 11:51:50 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet MemoryModel
In-Reply-To: <20051106152635.24828.qmail@web51402.mail.yahoo.com>
References: <20051106152635.24828.qmail@web51402.mail.yahoo.com>
Message-ID: <436E34F5.2050107@peierls.net>

serge masse wrote:
> Let's just consider servlets (and jsps) for example.
> 
> There are millions of them currently running.
> 
> A large portion of them are currently running on uniprocessors and probably most of these are
> slated to be ported to multicore systems over the next few years.
> 
> What is the expected percentage of these that will show new defects when ported to multicore?
> 
> I am worried by this but maybe I shouldn't be.


I'm more worried about the ones that have defects but don't show them. These are the buffer
overruns of the Java world.

You can try to provide tools to increase confidence in the correctness of a program, but
programmers have to know enough to use these tools (and often have to get approval to use them).
So education is needed, and that's a long process.

--tim

From sergemasse1 at yahoo.com  Sun Nov  6 12:42:10 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Sun Nov  6 12:42:46 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet MemoryModel
In-Reply-To: <436E34F5.2050107@peierls.net>
Message-ID: <20051106174210.19471.qmail@web51409.mail.yahoo.com>

Thanks Tim.

--- Tim Peierls <tim@peierls.net> wrote:
> 
> I'm more worried about the ones that have defects
> but don't show them. These are the buffer
> overruns of the Java world.

Indeed, I was implying that my understanding of
David's comment was when a multithreaded app is ported
from uniprocessor to a multicore, the new defects that
will manifest themselves should be virtuall all from
pre-existing defects in the original versions that had
not shown up on uniprocessor.

> 
> You can try to provide tools to increase confidence
> in the correctness of a program, but
> programmers have to know enough to use these tools
> (and often have to get approval to use them).
> So education is needed, and that's a long process.
> 
> --tim
> 
 
I agree and like most Java consultants, a significant
percentage of my income is derived from such
educational work and this is also why I need to get
this issue straight, so that I can continue to do a
decent job advising my clients, as well as to continue
writing better code myself. A *train the
trainer-programmer* situation.

Do you have any specific tools to suggest for this
potential problem of porting concurrent apps from
uniprocessors to multicore?

thanks again,
serge
From brian at quiotix.com  Sun Nov  6 13:00:35 2005
From: brian at quiotix.com (Brian Goetz)
Date: Sun Nov  6 13:01:16 2005
Subject: [concurrency-interest] Java Memory Model versus dotnet MemoryModel
In-Reply-To: <20051106152635.24828.qmail@web51402.mail.yahoo.com>
References: <20051106152635.24828.qmail@web51402.mail.yahoo.com>
Message-ID: <436E44C3.20303@quiotix.com>

> Should we worry about multicores soon to be
> ubiquitous?

I think what Serge is getting at here is that the fact that 
single-processor machines have been the norm in a lot of environments, 
especially on desktops, has masked a lot of bugs, which may soon be 
unmasked as the MP machines become cheaper and more widespread.

This is true, but I think a bigger masking factor is the dominance of 
IA32 in the low-end multiprocessor world, whose stronger memory model 
also masks a lot of real concurrency bugs.

> There are millions of them currently running.

And most are stateless, another masking factor.  The servlets that are 
most likely to show thread-safety problems are also those that are most 
likely to show other logic errors, such as those that implicitly assume 
that the user will never hit the "back" button.  These are the ones that 
carry state from request to request.

In other words, yes, the increased chance that a program will be 
deployed on an MP system will disclose more bugs.  But there is a lot of 
"noise" that may continue to mask these bugs, so I doubt it will be the 
flood that some predict.  It might be better if it were a flood, because 
then people would take it seriously (and some of us on this list could 
make a fortune cashing in on the "next Y2K panic".)

> A large portion of them are currently running on
> uniprocessors and probably most of these are slated to
> be ported to multicore systems over the next few
> years.

Except that there will be no "porting", just redeploying.  Porting 
involves a managed effort to audit, modify, and test.  More likely, 
people will buy new systems and slap them in their racks.

> 
> What is the expected percentage of these that will
> show new defects when ported to multicore?
> 
> I am worried by this but maybe I shouldn't be.
> Nevertheless, there are quite a few signals raising
> alarms about the issue of concurrent Java code ported
> from uniprocessors to multicore and I hope that this
> mailing list will be helpful about it, as I think it
> is part of its purpose.
> 
> Thank you for all who make this list so informative
> and useful.
> 
> serge
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From dholmes at dltech.com.au  Sun Nov  6 19:08:00 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Sun Nov  6 19:08:34 2005
Subject: [concurrency-interest] spurious wakeups semantics
In-Reply-To: <OFF7B4BC5C.EA3BD2C7-ONC12570AF.004075B5-C12570AF.003FD4BE@de.ibm.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBIGIAA.dholmes@dltech.com.au>

Alexander Terekhov wrote:
> David Holmes wrote:
> > No one is really sure where they came from.
>
> http://citeseer.ist.psu.edu/birrell87synchronization.html
>

Thanks for the reference Alex - that is a paper that would be of general
reading interest to everyone on the list. They were aware of so many issues
that Java was later to stumble over (eg. interrupt/alert and signal
interaction). And they also (because they followed mesa) diverged from the
semantics of Hoare monitors. (People mistakenly think Java broke new ground
here when in fact it pretty much borrowed everything from elsewhere.)

Is this the source of spurious wakeups? I have no idea and in previous
discussions on comp.programming.threads I don't recall this paper being
discussed - but at least Firefly is mentioned :) The paper obviously allows
"spurious wakeups" by allowing a signal to release more than one thread -
which they seemed to allow for efficiency/performance reasons that aren't
elaborated on in that paper. But see also the referenced paper by Pike et
al:

http://citeseer.ist.psu.edu/55102.html

"Process Sleep and Wakeup on a Shared-memory Multiprocessor  "

which shows how hard SMP programming can be if all you have is a
test-and-set instruction.

Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> Alexander Terekhov wrote:
> > Jeremy Manson <jmanson@cs.purdue.edu> wrote:
> >>This paper gives the same implementation that David describes as broken
> >>in the POSIX rationale, no?
> >
> > I have no idea what piece of broken code in the POSIX rationale David
> > was talking about.
>
> Okay.  I was specifically thinking of the one on this page:
>
> http://www.opengroup.org/onlinepubs/009695399/functions/pthread_co
nd_signal.html

The code Jeremy links to is the "broken" code I was referring to. The key
requirement for the condition wait is that it atomically releases the lock
and suspends the thread (as per the Birrell formal specs) but this code
fails to do that as the two actions are not atomic - hence I claim it is
broken. Whether this relates to the system described in the Birrell paper I
can't say - the paper contains no code listing - maybe the POSIX folk
figured if Birrell had to do that way then it should be allowed to happen by
the spec. I wasn't around then so I don't know the timeline.

Anyway time to put this debate to bed again - till next time of course. :)

Cheers,
David Holmes

From dholmes at dltech.com.au  Sun Nov  6 19:35:02 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Sun Nov  6 19:35:37 2005
Subject: [concurrency-interest] Re: spurious wakeups semantics
	(morehistory & refs)
In-Reply-To: <436B8DDB.2070807@Sun.COM>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEBJGIAA.dholmes@dltech.com.au>

Pete Soper wrote:
> Bug 4777391 "unexpected behaviour of Object.wait method" came before the
> spec update but shows an extreme case of not having a condition ("test
> should be hung !!!" is printed due to a notify by the system).
>
> public class hang extends Thread {
>     public static void main(String argv[]) {
>         Thread thread = new hang();
>
>         System.out.println("prepare to hang !!");
>         try {
>             synchronized (thread) {
>                 thread.start();  /*1*/
>     	        thread.wait();   /*2*/
>             }
>
>             System.out.println("test should be hung !!!");
>         } catch (InterruptedException e) {
>             System.out.println("InterruptedException" + e);
>         }
>     }
> }

It is a pity that the evaluator of that bug didn't clearly state what was
happening: the JDK has always used synchronization on the Thread object
itself to control concurrent access, and this includes the use of wait() in
the implementation of the join() method. Consequently, as a thread
terminates (logically by the code that causes run() to execute) a
notifyAll() is done on the Thread object to wake up any joiners.

Use of the Thread object is a bad idea from an encapsulation perspective and
is not required by the spec. In the tutorials that Doug Lea and I have given
since 1996 we have always warned people away from using Thread objects in
their own synchronization protocols due to their use by the runtime
libraries.

Cheers,
David Holmes

From dholmes at dltech.com.au  Sun Nov  6 20:02:04 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Sun Nov  6 20:02:56 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436C04A4.3030501@uol.com.br>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBKGIAA.dholmes@dltech.com.au>

Not withstanding Dawid's responses I'd just like to address a couple of
points.

Lu?s Matta writes:
> (Obvious buggy)
> class Foo {
>     public static String CONST_SQL;
>     public static String CONST_SQL1 = "select * from a where b = ";
>     public static String getA(String param) {
>        CONST_SQL = CONST_SQL1 + param;
>         ...run query and return result
>     }
> }
> ...
>     Since this method can be run by multiple threads, and we are using
> class variables, this is a theoretical bug. But is it a actual one, is
> there a pratical situation where this bug will manifest itself?
>     I ask because since the variable is not synchronized, it appears to
> me that it will get cached and will never be refreshed in any pratical
> situation.

It would be possible for the value written to CONST_SQL to be maintained as
a local or on the stack and so if a second thread changed CONST_SQL the
first thread need not notice it. But it is just as possible that the static
field will be reloaded when used to run the actual query - in which case it
could see someone else's value for CONST_SQL and so execute the wrong query.

There are many factors at play here including the source code compiler, and
the JIT. Bottom line is this code has a serious bug.

> What are the rules for concurrent access to class variables, and what
> how would the Sun JVM (version 1.4.3) behave?

The rules for accessing statics is no different to accessing instance
fields. The source compiler will issue as many or as few GETSTATIC/PUTSTATIC
bytecodes as is needed to implement the program semantics and required by
the specification. Source code compilers tend to make very conservative
assumptions about what might happen in method calls so it is likely that use
of a static field before and after a method call would result in two
GETSTATIC uses. The JIT will again do whatever it needs to implement the
program semantics but this time with more of a view on performance and
optimization. That may or may not require that the GETSTATIC bytecodes
remain as explicit loads from memory - it depends on what analysis the
compiler does of any methods called in between the accesses.

Bottom line: don't think about these things as you have no idea what will
occur at runtime. Write the code correctly as per the language
specification.


Cheers,
David Holmes

From dholmes at dltech.com.au  Sun Nov  6 20:23:32 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Sun Nov  6 20:24:06 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436D4581.5000407@mathcs.emory.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBLGIAA.dholmes@dltech.com.au>

> Dawid Kurzyniec writes:
> Now, I was responding to your fix: for it to be 100% correct, you need
> that "final". To my understanding (experts correct me if I'm wrong), you
> may otherwise see this field uninitialized (i.e. null) in some threads.

You will never see a static final field with its default initialized value.
The synchronization that occurs as part of the class initialization process
make this impossible. The lock of the Class object is held during static
initialization of the class, and any use of the class that requires that it
be initialized also must acquire that lock. So no thread can use the class
without having gained the lock, which is only released after initialization
is complete. The release of the lock by the initializing thread (and thus
all initialization code) happens-before the lock acquisition by another
thread.

The reason you need the final here is if the field remains non-private,
otherwise some other thread could change the value.

Cheers,
David Holmes

From dawidk at mathcs.emory.edu  Sun Nov  6 21:20:21 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Sun Nov  6 21:21:17 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEBLGIAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCEEBLGIAA.dholmes@dltech.com.au>
Message-ID: <436EB9E5.2060102@mathcs.emory.edu>

David Holmes wrote:

>>Dawid Kurzyniec writes:
>>Now, I was responding to your fix: for it to be 100% correct, you need
>>that "final". To my understanding (experts correct me if I'm wrong), you
>>may otherwise see this field uninitialized (i.e. null) in some threads.
>>    
>>
>
>You will never see a static final field with its default initialized value.
>The synchronization that occurs as part of the class initialization process
>make this impossible. The lock of the Class object is held during static
>initialization of the class, and any use of the class that requires that it
>be initialized also must acquire that lock. So no thread can use the class
>without having gained the lock, which is only released after initialization
>is complete. The release of the lock by the initializing thread (and thus
>all initialization code) happens-before the lock acquisition by another
>thread.
>  
>
Is the same guaranteed if the field is non-final?

Does this mean that every access to any class variable involves locking? 
Or is there some kind of a thread-local cache so that each thread locks 
on any class at most once? What does the specification say about it?

Regards,
Dawid


From dholmes at dltech.com.au  Sun Nov  6 21:35:00 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Sun Nov  6 21:35:36 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <436EB9E5.2060102@mathcs.emory.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEBPGIAA.dholmes@dltech.com.au>

Dawid Kurzyniec writes:
> Is the same guaranteed if the field is non-final?

Yes. The initialization of a static field (via an initialization expression
or static initializer block) is guaranteed to be seen. Of course if the
field is non-final and changed after initialization that is a different
matter.

> Does this mean that every access to any class variable involves locking?
> Or is there some kind of a thread-local cache so that each thread locks
> on any class at most once? What does the specification say about it?

The specification requires that before any action that requires a class to
be initialized is performed, the class must be determined to be initialized
by acquiring the class lock as I described. See JVMS Section 2.17.5.
Logically this means that every thread must appear to acquire the Class
object lock of every Class/Interface it uses (where such use requires
initialization) at least once. The VM will do the best it can to try and
ensure it is at most once. For example, the JIT can see if a class to be
used by a jitted method has been initialized or not, and if so generate code
that skips the initialization check; otherwise it puts in the initialization
check on the first use. There are various ways the VM can optimise this.

Cheers,
David Holmes

From eross at m-Qube.com  Mon Nov  7 18:25:10 2005
From: eross at m-Qube.com (Elias Ross)
Date: Mon Nov  7 18:25:57 2005
Subject: [concurrency-interest] util.concurrent 1.3.4
Message-ID: <1131405910.5612.34.camel@momo.m-qube.com>


I know there is an existing bug with 

ConcurrentReaderHashMap.keySet().toArray()

but one interesting way I've come across this is with this sort of code:

ConcurrentReaderHashMap cr;
List l = new ArrayList();

  l.addAll(cr.keySet());

What ends up happening is "null" entries end up getting added to the
ArrayList.  This is because, despite what the JavaDoc says:
        
        Appends all of the elements in the specified Collection to the
        end of this list, in the order that they are returned by the
        specified Collection's Iterator.
        
The code for ArrayList calls "toArray" on the set and ignores the
iterator.

    public boolean addAll(Collection<? extends E> c) {
        Object[] a = c.toArray();
        ...
    }


From hans.boehm at hp.com  Fri Nov  4 19:00:49 2005
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon Nov  7 18:44:08 2005
Subject: [concurrency-interest] spurious wakeups semantics
Message-ID: <65953E8166311641A685BDF71D8658266C1A1A@cacexc12.americas.cpqcorp.net>

This seems to credit earlier systems, e.g. Mesa.

They cite Lampson and Redell, CACM 80, 2
(http://portal.acm.org/citation.cfm?doid=358818.358824), which already
contains some discussion of this.

Hans

> -----Original Message-----
> From: concurrency-interest-bounces@cs.oswego.edu 
> [mailto:concurrency-interest-bounces@cs.oswego.edu] On Behalf 
> Of Alexander Terekhov
> Sent: Friday, November 04, 2005 3:45 AM
> To: David Holmes
> Cc: concurrency-interest@altair.cs.oswego.edu
> Subject: RE: [concurrency-interest] spurious wakeups semantics
> 
> 
> 
> 
> > No one is really sure where they came from.
> 
> http://citeseer.ist.psu.edu/birrell87synchronization.html
> 
> regards,
> alexander.
> 
> _______________________________________________
> Concurrency-interest mailing list 
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From sergemasse1 at yahoo.com  Mon Nov  7 19:26:03 2005
From: sergemasse1 at yahoo.com (serge masse)
Date: Mon Nov  7 19:26:40 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEBPGIAA.dholmes@dltech.com.au>
Message-ID: <20051108002604.15163.qmail@web51413.mail.yahoo.com>

David.
Which version of Java are you referring to?
serge
From dholmes at dltech.com.au  Mon Nov  7 19:32:02 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Mon Nov  7 19:32:38 2005
Subject: [concurrency-interest] Class variables and concurrency
In-Reply-To: <20051108002604.15163.qmail@web51413.mail.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEDLGIAA.dholmes@dltech.com.au>

> David.
> Which version of Java are you referring to?
> serge

Probably 1.2 onwards (JLS 2nd edition and JVMS second edition). The actual
initialization protocol is unchanged even as far back as 1.1, as far as I
can recall, but 1.2 put more constraints on exactly when a class/interface
had to be initialized.

David

From gregg at cytetech.com  Mon Nov  7 20:52:32 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon Nov  7 20:53:21 2005
Subject: [concurrency-interest] Named locks with String values
Message-ID: <437004E0.7050301@cytetech.com>

I recently was working on some code where a method had to string values comming 
into it, and these values indicate a SQL database rowset that I want to lock 
access to.  I was trying to decide how I wanted to the locking and then it 
dawned on me that I could do the following.

	public void getEntries( String use, String key, ... ) {
		synchronized( (use+"/"+key).intern() ) {
			...
		}
	}

I quick check with and without the intern() call validated that the uniqueness 
of intern() appeared to provide the locking that I needed.

I haven't seen String.intern() mentioned here as a way to get named locks and so 
I was curious of others comments about this usage and whether there are other 
interesting exploits of using other JVM caches.

I understand that this can cause some extended memory growth if use and key are 
not reasonably bounded in possible values.

Gregg Wonderly
From mattocks at mac.com  Wed Nov  9 00:43:46 2005
From: mattocks at mac.com (Craig Mattocks)
Date: Wed Nov  9 00:44:27 2005
Subject: [concurrency-interest] Java Concurrency in Practice
Message-ID: <082785adb62ec8af5e9235f662af9e5d@mac.com>

Okay, just pre-ordered:

http://www.amazon.com/exec/obidos/tg/detail/-/0321349601/002-8907356 
-9580856?%5Fencoding=UTF8&v=glance

Although the publishing date is listed as February 10, 2006, Amazon  
estimates a shipping date of January 10, 2006.

Can't wait!
Craig

From brian at quiotix.com  Wed Nov  9 01:50:22 2005
From: brian at quiotix.com (Brian Goetz)
Date: Wed Nov  9 01:51:01 2005
Subject: [concurrency-interest] Java Concurrency in Practice
In-Reply-To: <082785adb62ec8af5e9235f662af9e5d@mac.com>
References: <082785adb62ec8af5e9235f662af9e5d@mac.com>
Message-ID: <43719C2E.1030700@quiotix.com>

> Can't wait!
> Craig

Me neither :)

-Brian

From dawidk at mathcs.emory.edu  Thu Nov 10 02:47:48 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 02:48:54 2005
Subject: [concurrency-interest] Named locks with String values
In-Reply-To: <437004E0.7050301@cytetech.com>
References: <437004E0.7050301@cytetech.com>
Message-ID: <4372FB24.8040206@mathcs.emory.edu>

Gregg Wonderly wrote:

> I recently was working on some code where a method had to string 
> values comming into it, and these values indicate a SQL database 
> rowset that I want to lock access to.  I was trying to decide how I 
> wanted to the locking and then it dawned on me that I could do the 
> following.
>
>     public void getEntries( String use, String key, ... ) {
>         synchronized( (use+"/"+key).intern() ) {
>             ...
>         }
>     }
>
I was hoping that some EG member would comment, but in the absence of that:

This looks reasonably legit to me, although feels a bit risky. One 
possible caveat is that it is "external" synchronization, and some other 
library used by your program might independently have the same idea. 
Then you can possibly get into deadlocks: even if you enforce consistent 
lock ordering, or if your code never obtains more than a single lock, 
when combined with unknown library code, it may result in trying to 
acquire two locks from two threads in a different order.

> I understand that this can cause some extended memory growth if use 
> and key are not reasonably bounded in possible values.

I think that smart enough JVM would make the intern cache weak, but you 
never know.

All in all, I would probably rather implement my own weak named lock 
pool, just to be sure that nothing bad like that can happen.

Regards,
Dawid

From dawidk at mathcs.emory.edu  Thu Nov 10 03:02:34 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 03:03:08 2005
Subject: [concurrency-interest] Language extensions for java.util.concurrent?
Message-ID: <4372FE9A.6030402@mathcs.emory.edu>

Now, as the dust has settled and java.util.concurrent is a core library, 
I am wondering if the next step should be to propose language extensions 
to simplify usage of new tools, particularly locks and atomics? For 
instance:

class A {
  atomic int a;
  final Lock lock = new ReentrantLock();
  void foo() {
    ++a; // -> incrementAndGet()
    a ?= 5, 8; // ->compareAndSet(5, 8)
    lock.lock() { // ->lock(); try { ... } finally { unlock(); }
      // do stuff with the lock held
    }
  }
}

Precedence for interface-based syntax support has been set by the 
Iterable, and atomic is essentially a stronger incarnation of volatile. 
So why not?

Regards,
Dawid

From jmanson at cs.purdue.edu  Thu Nov 10 09:53:59 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov 10 09:54:41 2005
Subject: [concurrency-interest] Language extensions for
	java.util.concurrent?
In-Reply-To: <4372FE9A.6030402@mathcs.emory.edu>
References: <4372FE9A.6030402@mathcs.emory.edu>
Message-ID: <43735F07.1050504@cs.purdue.edu>

Dawid Kurzyniec wrote:
> Now, as the dust has settled and java.util.concurrent is a core library, 
> I am wondering if the next step should be to propose language extensions 
> to simplify usage of new tools, particularly locks and atomics? For 
> instance:
> 
> class A {
>  atomic int a;
>  final Lock lock = new ReentrantLock();
>  void foo() {
>    ++a; // -> incrementAndGet()
>    a ?= 5, 8; // ->compareAndSet(5, 8)
>    lock.lock() { // ->lock(); try { ... } finally { unlock(); }
>      // do stuff with the lock held
>    }
>  }
> }
> 
> Precedence for interface-based syntax support has been set by the 
> Iterable, and atomic is essentially a stronger incarnation of volatile. 
> So why not?
> 

Three things:

First, I don't think you would be able to convince the powers that be to 
introduce new syntax to support an API.  It tends to be something they 
don't like.  Generally, their feeling seems to be that APIs are the 
correct way to extend the language.  Which is why we get APIs that 
require rewrites of the entire system, like RTSJ and Isolates.

Of course, you can argue about the basic correctness of this view.  And 
you can argue about the presence of autoboxing and foreach loops.

Second, I, personally, would be more inclined to want to see a general 
purpose atomic block.  Something like this:

class A {
  int a;
  final Lock lock = new ReentrantLock();
  void foo() {
    atomic {
      ++a;
    }
    atomic {
      if (a == 5) {
        a = 8;
      }
    }
  }
}


Compilers could do the appropriate replacement, changing the first block 
to an increment and the second to something like a CAS.  The syntax 
could also be used to make multiple statements atomic, rather than being 
restricted to a single statement.  There is some momentum for such a 
creature in the academic community.

Third, having said this, it is possible to do some method-level stuff 
with annotations.  For example, I wrote a program that takes classes 
that look like this:

class Foo {

   @reentrant void a() {
      // does stuff
   }

}

and changes them to:

class Foo {

   ReentrantLock rl = new ReentrantLock();

   void a() {
     rl.lock();
     try {
       // does stuff
     } finally {
       rl.unlock();
     }
   }
}

which may suffice for new syntax for locking.  It just took a little bit 
of bytecode munging.

					Jeremy
From gergg at cox.net  Thu Nov 10 10:58:21 2005
From: gergg at cox.net (Gregg Wonderly)
Date: Thu Nov 10 10:59:09 2005
Subject: [concurrency-interest] Named locks with String values
In-Reply-To: <4372FB24.8040206@mathcs.emory.edu>
References: <437004E0.7050301@cytetech.com> <4372FB24.8040206@mathcs.emory.edu>
Message-ID: <43736E1D.20605@cox.net>

Dawid Kurzyniec wrote:
> Gregg Wonderly wrote:
> 
>> I recently was working on some code where a method had to string 
>> values comming into it, and these values indicate a SQL database 
>> rowset that I want to lock access to.  I was trying to decide how I 
>> wanted to the locking and then it dawned on me that I could do the 
>> following.
>>
>>     public void getEntries( String use, String key, ... ) {
>>         synchronized( (use+"/"+key).intern() ) {
>>             ...
>>         }
>>     }
>>
> I was hoping that some EG member would comment, but in the absence of that:
> 
> This looks reasonably legit to me, although feels a bit risky. One 
> possible caveat is that it is "external" synchronization, and some other 
> library used by your program might independently have the same idea. 

What this is controlling is the synchronization of a set of property values in a 
database.  There are multiple threads that are able to delete all and insert all 
of the properties as they encounter information during startup.  What happens is 
that one thread will delete all the properties, and then another, will run a 
query and find them all missing, and say ohh I need to update these.  Both 
threads will then try the inserts, one or more of which will fail with a 
duplicate key error.  This synchronization is only needed briefly, and is, in 
fact isolated to just the threads running in this JVM.  All other users of the 
data are read-only users.

It does feel a bit risky, to me as well, but it was a quick way to see that I 
had in fact found the location of conflicting access.  I can, of course, create 
a real weakhashmap of locks, as I suggested in my other followup.  And, I 
probably will.  But, I just found this to be an interesting quick and easy way 
to create a named locking mechanism.  It's not ultimate, nor, perhaps even 
realistic to use, but just something that came to mind.

Gregg Wonderly
From dawidk at mathcs.emory.edu  Thu Nov 10 13:37:35 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 13:38:28 2005
Subject: [concurrency-interest] Language extensions 	for 
	java.util.concurrent?
In-Reply-To: <43735F07.1050504@cs.purdue.edu>
References: <4372FE9A.6030402@mathcs.emory.edu> 
	<43735F07.1050504@cs.purdue.edu>
Message-ID: <4373936F.9060304@mathcs.emory.edu>

Jeremy Manson wrote:

> Dawid Kurzyniec wrote:
>
>> Now, as the dust has settled and java.util.concurrent is a core 
>> library, I am wondering if the next step should be to propose 
>> language extensions to simplify usage of new tools, particularly 
>> locks and atomics? For instance:
>>
>> class A {
>>  atomic int a;
>>  final Lock lock = new ReentrantLock();
>>  void foo() {
>>    ++a; // -> incrementAndGet()
>>    a ?= 5, 8; // ->compareAndSet(5, 8)
>>    lock.lock() { // ->lock(); try { ... } finally { unlock(); }
>>      // do stuff with the lock held
>>    }
>>  }
>> }
>>
>> Precedence for interface-based syntax support has been set by the 
>> Iterable, and atomic is essentially a stronger incarnation of 
>> volatile. So why not?
>>
>
> Three things:
>
> First, I don't think you would be able to convince the powers that be 
> to introduce new syntax to support an API.  It tends to be something 
> they don't like.  Generally, their feeling seems to be that APIs are 
> the correct way to extend the language.  Which is why we get APIs that 
> require rewrites of the entire system, like RTSJ and Isolates.
>
> Of course, you can argue about the basic correctness of this view.  
> And you can argue about the presence of autoboxing and foreach loops.
>
Sure, they are, and they ought to be, very conservative about the 
language. But nonwithstanding, we see the language evolving, with 
changes nearly every major release. Inner classes, anonymous array 
expressions, class literals, blank finals, final parameters in 1.1, 
strictfp in 1.2, assert in 1.4, generics, autoboxing, foreach loops, 
varargs, concise array literals in 5.0.

Personally I don't have a problem with using j.u.c. merely as the API, 
but the concurrency is already a part of the language anyway, so I think 
that a bit of syntactic sugar for locks and atomics could decrease the 
dichotomy between intrinsic locks and volatiles on one side and explicit 
locks and atomics on the other. After all, this is a very special API, 
requiring explicit JVM support (atomics and park/unpark), and receiving 
special treatment already (deadlock detection for explicit locks). So, 
if there is any API for which I would welcome language support, it would 
be this one.

> Second, I, personally, would be more inclined to want to see a general 
> purpose atomic block.  Something like this:
>
> class A {
>  int a;
>  final Lock lock = new ReentrantLock();
>  void foo() {
>    atomic {
>      ++a;
>    }
>    atomic {
>      if (a == 5) {
>        a = 8;
>      }
>    }
>  }
> }
>
>
> Compilers could do the appropriate replacement, changing the first 
> block to an increment and the second to something like a CAS.  The 
> syntax could also be used to make multiple statements atomic, rather 
> than being restricted to a single statement.  There is some momentum 
> for such a creature in the academic community.

I am not sure how multiple statements could be make atomic without 
introducing mutual exclusion. But if you go there, the boundary between 
blocking and non-blocking statements becomes blurry... I feel a bit 
uneasy about that.

Also, the syntax for CAS is actually longer in this form than 
a.compareAndSet().

Anyway, I am not saying I have all the answers. I am just curious what 
other people may think in general about introducing language extensions 
like this to support this API.

In particular, if I had lock.lock() { ... } (and lock.tryLock() { ... } 
etc.), I would be more inclined to move away from intrinsic locks 
towards explicit locks.

Perhaps the idea could be generalized to allow general constructs of the 
form foo.bar() { ... }, with before- and after- actions for bar() 
defined by the class via annotations, and inserted by the source 
compiler as needed. This would also in some sense generalize the 
constructor invocation syntax for anonymous inner classes. Such a 
general mechanism could benefit other APIs that rely on before/after 
pattern. For instance, I can imagine a version of doPrivileged like this:

AccessController.doPrivileged(acc) {
   // statements here;
   // can read/write local variables from enclosing block
}

The remaining questions are what to do with a returned value (if the 
method is non-null), and how to handle exceptions. One possible solution:

try {
  Socket s = pool.getSocket() {
    // after-action returns the socket to the pool, but only if there 
was no IOException
  }
}
catch (IOException e) {
  // socket could not be obtained, or broken connection
  // handle...
}

Regards,
Dawid

From dawidk at mathcs.emory.edu  Thu Nov 10 14:06:57 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 14:07:43 2005
Subject: [concurrency-interest] Named locks with String values
In-Reply-To: <43736E1D.20605@cox.net>
References: <437004E0.7050301@cytetech.com> 
	<4372FB24.8040206@mathcs.emory.edu> <43736E1D.20605@cox.net>
Message-ID: <43739A51.6040803@mathcs.emory.edu>

Gregg Wonderly wrote:

> Dawid Kurzyniec wrote:
>
>> Gregg Wonderly wrote:
>>
>>> I recently was working on some code where a method had to string 
>>> values comming into it, and these values indicate a SQL database 
>>> rowset that I want to lock access to.  I was trying to decide how I 
>>> wanted to the locking and then it dawned on me that I could do the 
>>> following.
>>>
>>>     public void getEntries( String use, String key, ... ) {
>>>         synchronized( (use+"/"+key).intern() ) {
>>>             ...
>>>         }
>>>     }
>>>
>> I was hoping that some EG member would comment, but in the absence of 
>> that:
>>
>> This looks reasonably legit to me, although feels a bit risky. One 
>> possible caveat is that it is "external" synchronization, and some 
>> other library used by your program might independently have the same 
>> idea. 
>
>
> What this is controlling is the synchronization of a set of property 
> values in a database.  There are multiple threads that are able to 
> delete all and insert all of the properties as they encounter 
> information during startup.  What happens is that one thread will 
> delete all the properties, and then another, will run a query and find 
> them all missing, and say ohh I need to update these.  Both threads 
> will then try the inserts, one or more of which will fail with a 
> duplicate key error.  This synchronization is only needed briefly, and 
> is, in fact isolated to just the threads running in this JVM.  All 
> other users of the data are read-only users.
>
> It does feel a bit risky, to me as well, but it was a quick way to see 
> that I had in fact found the location of conflicting access.  I can, 
> of course, create a real weakhashmap of locks, as I suggested in my 
> other followup.  And, I probably will.  But, I just found this to be 
> an interesting quick and easy way to create a named locking 
> mechanism.  It's not ultimate, nor, perhaps even realistic to use, but 
> just something that came to mind.

You're welcome to use:
http://dcl.mathcs.emory.edu/cgi-bin/viewcvs.cgi/software/util/src/edu/emory/mathcs/util/remote/locks/ReentrantDistributedLock.java?view=markup

To make this work in your scenario, you need either to modify the class 
a bit, or to write a dummy RemoteLock class, ensapsulating String 
instance, implementing equals and hashCode by delegating to that string, 
and otherwise having all operations no-op. Then, you can do:

Lock lock = new ReentrantDistributedLock(new DummyRemoteLock("foo"));
lock.lock();
try { ... } finally { lock.unlock(); }

Or even:

Lock lock = new ReentrantDistributedLock(new DummyRemoteLock("foo"));
lock.lock();
try { ... }
finally {
  lock = new ReentrantDistributedLock(new DummyRemoteLock("foo"));
  lock.unlock();
}

Of course you can write a factory method in DummyRemoteLock to simplify 
the invocation syntax, perhaps like this:

Lock lock = MyClass.lock("foo");
try { ... } finally { lock.unlock(); }

This class was designed for a bit more complex general case, where you 
need a distributed lock accessed by many JVMs and threads. Its purpose 
is to provide reentrancy and resolve local mutual exclusion within the 
JVM, so that threads within a single JVM do not contend on a remote 
lock, but only on the local lock, and so that a thread who obtained the 
lock does not make remote calls to re-enter the lock. We used it, with 
some other helper classes providing generic versions of CAS-based and 
Eisenberg-McGuire algorithms, to implement poor-man's distributed 
locking piggybacking on JNDI.

Regards,
Dawid

From jmanson at cs.purdue.edu  Thu Nov 10 14:15:45 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov 10 14:16:30 2005
Subject: [concurrency-interest] Language extensions for
	java.util.concurrent?
In-Reply-To: <4373936F.9060304@mathcs.emory.edu>
References: <4372FE9A.6030402@mathcs.emory.edu>
	<43735F07.1050504@cs.purdue.edu>
	<4373936F.9060304@mathcs.emory.edu>
Message-ID: <43739C61.6040502@cs.purdue.edu>

Dawid Kurzyniec wrote:
> 
> I am not sure how multiple statements could be make atomic without
> introducing mutual exclusion. But if you go there, the boundary
> between blocking and non-blocking statements becomes blurry... I feel
> a bit uneasy about that.

There are a lot of techniques in the works to do just this - it is a 
common research problem.  The idea is to import optimistic concurrency 
from databases.  The back end would take care of atomicity and 
visibility constraints, so the programmer could be free not to worry 
about that stuff.

I'm not sure why this would make you uneasy, though.  Databases employ 
this sort of concurrency all the time.  Wouldn't it be nice if everyone 
could write non-blocking data structures, instead of just people with 
Ph.D.s?  Also, if you can use atomic blocks instead of locking, many of 
the concerns of locking (deadlock, for example) become simplified 
substantially.

> Also, the syntax for CAS is actually longer in this form than a.compareAndSet(). 

Yes, but it has the virtue of being comprehensible for those who don't 
know what a compareAndSet is, without extra work to go look it up.

I'm not claiming that such a structure would be a panacea, but I think 
it would be a lot nicer than special syntax for each method that could 
be invoked on an AtomicXXX.  I am also concerned that your syntax would 
discourage programmers from thinking about multi-variable invariants - 
i.e., it would make it TOO simple to have a single atomic action that 
doesn't relate to other associated actions correctly.  OTOH, an atomic 
{...} block might encourage programmers to group related actions that 
should be performed atomically.

> Perhaps the idea could be generalized to allow general constructs of
> the form foo.bar() { ... }, with before- and after- actions for bar()
>  defined by the class via annotations, and inserted by the source 
> compiler as needed. This would also in some sense generalize the 
> constructor invocation syntax for anonymous inner classes. Such a 
> general mechanism could benefit other APIs that rely on before/after
>  pattern. For instance, I can imagine a version of doPrivileged like
> this:
> 
> AccessController.doPrivileged(acc) { // statements here; // can
> read/write local variables from enclosing block }
>

This is fairly close to what my annotation tool actually does.  More
specifically, you can define something that looks like this in a special
class:

     public ReentrantLock rl = new ReentrantLock();

     void around() {
	rl.lock();
	try {
	  proceed();
	} finally {
	  rl.unlock();
	}
     }

And you can define the following method:

@reentrant int f() {
   a.x = 1;
   return a.x;
}

And it will transform it (at the bytecode level) into this:

int f() {
   int returnVal;
   rl.lock();
   try {
     returnVal = realF();
   } finally {
     rl.unlock();
   }
   return returnVal;
}

int realF() {
   a.x = 1;
   return a.x;
}

You can adjust the around() method as desired to do pretty much whatever
you want it to do.  The problem is that you can't have it within a 
method scope (because you can't annotate individual statements).

					Jeremy
From dawidk at mathcs.emory.edu  Thu Nov 10 14:59:27 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 15:00:14 2005
Subject: [concurrency-interest] Language extensions 
	forjava.util.concurrent?
In-Reply-To: <43739C61.6040502@cs.purdue.edu>
References: <4372FE9A.6030402@mathcs.emory.edu><43735F07.1050504@cs.purdue.e
	du><4373936F.9060304@mathcs.emory.edu> <43739C61.6040502@cs.purdue.edu>
Message-ID: <4373A69F.7080408@mathcs.emory.edu>

Jeremy Manson wrote:

> Dawid Kurzyniec wrote:
>
>>
>> I am not sure how multiple statements could be make atomic without
>> introducing mutual exclusion. But if you go there, the boundary
>> between blocking and non-blocking statements becomes blurry... I feel
>> a bit uneasy about that.
>
>
> There are a lot of techniques in the works to do just this - it is a 
> common research problem.  The idea is to import optimistic concurrency 
> from databases.  The back end would take care of atomicity and 
> visibility constraints, so the programmer could be free not to worry 
> about that stuff.
>
> I'm not sure why this would make you uneasy, though.  Databases employ 
> this sort of concurrency all the time.  Wouldn't it be nice if 
> everyone could write non-blocking data structures, instead of just 
> people with Ph.D.s?  Also, if you can use atomic blocks instead of 
> locking, many of the concerns of locking (deadlock, for example) 
> become simplified substantially.
>
The "uneasiness" was because I thought that locks would be silently 
inserted to handle more complex atomic blocks. If atomic {} is always 
non-blocking, then I may buy into the idea. But optimistic concurrency 
algorithms must deal with failures and retries. How would that look 
like? And what does the following mean:

atomic {
   if (a == 6) { foo(); b=4; a=5; } else a = 4;
}

Would the compiler have to ensure that a is not changed by other threads 
after it is read in the atomic block? But how to do that without 
blocking that other threads?

From jmanson at cs.purdue.edu  Thu Nov 10 15:22:13 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov 10 15:22:58 2005
Subject: [concurrency-interest] Language extensions
	forjava.util.concurrent?
In-Reply-To: <4373A69F.7080408@mathcs.emory.edu>
References: <4372FE9A.6030402@mathcs.emory.edu><43735F07.1050504@cs.purdue.e		du><4373936F.9060304@mathcs.emory.edu>
	<43739C61.6040502@cs.purdue.edu>
	<4373A69F.7080408@mathcs.emory.edu>
Message-ID: <4373ABF5.1080201@cs.purdue.edu>

Dawid Kurzyniec wrote:

> The "uneasiness" was because I thought that locks would be silently 
> inserted to handle more complex atomic blocks. If atomic {} is always 
> non-blocking, then I may buy into the idea. But optimistic concurrency 
> algorithms must deal with failures and retries. How would that look 
> like? And what does the following mean:
> 
> atomic {
>   if (a == 6) { 
 >     foo();
 >     b=4;
 >     a=5;
 >   } else a = 4;
> }
> 
> Would the compiler have to ensure that a is not changed by other threads 
> after it is read in the atomic block? But how to do that without 
> blocking that other threads?

There are several ways of ensuring this, most of which just take some 
imagination; the "right" one probably depends on what you need from your 
system.  Here's some brief discussion, which is by no means complete.

First, you might say that "atomic" only means atomic if a given variable 
is always accessed in an atomic section.  Otherwise, the multivariable 
invariants don't hold.  So, for example, a thread which accesses b and a 
outside an atomic block might see b == 4, but a == something else.  This 
may seem bad, but it is roughly analogous to writing code with data 
races in it.

That would ensure that atomic blocks only need to be atomic with respect 
to each other.  And this is a significantly easier problem.

One simple solution: record all writes in an atomic block to a log, 
instead of writing them directly to memory.  At the end of the block, if 
the memory that has been accessed has not changed, then briefly block 
(in the same sense that all machine level atomic actions briefly block) 
and perform all updates atomically.  If the memory has been changed, 
then restart.

There are obviously pitfalls and elided details here.  There are also 
more sophisticated solutions out there - like I said, it is a fairly 
active research area.  If you are interested in doing some reading, a 
good place to start might be Harris and Fraser's 2003 OOPSLA paper, 
"Language Support for Lightweight Transactions".

					Jeremy
From dawidk at mathcs.emory.edu  Thu Nov 10 15:37:14 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 15:37:54 2005
Subject: [concurrency-interest] Language 
	extensionsforjava.util.concurrent?
In-Reply-To: <4373ABF5.1080201@cs.purdue.edu>
References: <4372FE9A.6030402@mathcs.emory.edu><43735F07.1050504@cs.purdue.e
	du><4373936F.9060304@mathcs.emory.edu><43739C61.6040502@cs.purdue.edu><4
	3	73A69F.7080408@mathcs.emory.edu> <4373ABF5.1080201@cs.purdue.edu>
Message-ID: <4373AF7A.6060407@mathcs.emory.edu>

Jeremy Manson wrote:

> Dawid Kurzyniec wrote:
>
>> The "uneasiness" was because I thought that locks would be silently 
>> inserted to handle more complex atomic blocks. If atomic {} is always 
>> non-blocking, then I may buy into the idea. But optimistic 
>> concurrency algorithms must deal with failures and retries. How would 
>> that look like? And what does the following mean:
>>
>> atomic {
>>   if (a == 6) { 
>
> >     foo();
> >     b=4;
> >     a=5;
> >   } else a = 4;
>
>> }
>>
>> Would the compiler have to ensure that a is not changed by other 
>> threads after it is read in the atomic block? But how to do that 
>> without blocking that other threads?
>
>
> There are several ways of ensuring this, most of which just take some 
> imagination; the "right" one probably depends on what you need from 
> your system.  Here's some brief discussion, which is by no means 
> complete.
>
> First, you might say that "atomic" only means atomic if a given 
> variable is always accessed in an atomic section.  Otherwise, the 
> multivariable invariants don't hold.  So, for example, a thread which 
> accesses b and a outside an atomic block might see b == 4, but a == 
> something else.  This may seem bad, but it is roughly analogous to 
> writing code with data races in it.
>
> That would ensure that atomic blocks only need to be atomic with 
> respect to each other.  And this is a significantly easier problem.
>
> One simple solution: record all writes in an atomic block to a log, 
> instead of writing them directly to memory.  At the end of the block, 
> if the memory that has been accessed has not changed, then briefly 
> block (in the same sense that all machine level atomic actions briefly 
> block) and perform all updates atomically.  If the memory has been 
> changed, then restart.


Jeremy, thanks for the info and references I find it very interesting.

Restarting would require that all invoked methods are idempotent, but I 
think that invoking a method from an atomic block borders with abuse anyway.

Abuse of atomic blocks would cause livelocks, just like abuse of 
synchronized blocks causes deadlocks. Interesting.

Regards,
Dawid

From eross at m-Qube.com  Thu Nov 10 15:43:47 2005
From: eross at m-Qube.com (Elias Ross)
Date: Thu Nov 10 15:44:56 2005
Subject: [concurrency-interest] Language extensions for
	java.util.concurrent?
In-Reply-To: <43739C61.6040502@cs.purdue.edu>
References: <4372FE9A.6030402@mathcs.emory.edu>
	<43735F07.1050504@cs.purdue.edu> <4373936F.9060304@mathcs.emory.edu>
	<43739C61.6040502@cs.purdue.edu>
Message-ID: <1131655428.4335.27.camel@momo.m-qube.com>

On Thu, 2005-11-10 at 14:15 -0500, Jeremy Manson wrote:

>      public ReentrantLock rl = new ReentrantLock();
> 
>      void around() {
>         rl.lock();
>         try {
>           proceed();
>         } finally {
>           rl.unlock();
>         }
>      }

Too bad Java doesn't have the C# keyword "using", it would be nice to be
able to write

     void around() {
        using (rt) {
          proceed();
        }
     }

It's too easy to accidentally write:

     void around() {
        try {
          rl.lock();
          proceed();
        } finally {
          rl.unlock();
        }
     }


From dawidk at mathcs.emory.edu  Thu Nov 10 15:49:42 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Thu Nov 10 15:50:21 2005
Subject: [concurrency-interest] Language extensions 
	forjava.util.concurrent?
In-Reply-To: <1131655428.4335.27.camel@momo.m-qube.com>
References: <4372FE9A.6030402@mathcs.emory.edu><43735F07.1050504@cs.purdue.e
	du> <4373936F.9060304@mathcs.emory.edu><43739C61.6040502@cs.purdue.edu>
	<1131655428.4335.27.camel@momo.m-qube.com>
Message-ID: <4373B266.5070507@mathcs.emory.edu>

Elias Ross wrote:

>Too bad Java doesn't have the C# keyword "using", it would be nice to be
>able to write
>
>     void around() {
>        using (rt) {
>          proceed();
>        }
>     }
>
>It's too easy to accidentally write:
>
>     void around() {
>        try {
>          rl.lock();
>          proceed();
>        } finally {
>          rl.unlock();
>        }
>     }
>
>  
>
 From this example, "using" seems to me to be just like "synchronized".  
(I don't know C#). The problem with this syntax is that it does not 
allow using tryLock(...), and lockInterruptibly(). That's why I would 
opt for lock.lock() { ... }

Regards,
Dawid

From gregg at cytetech.com  Thu Nov 10 18:43:18 2005
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu Nov 10 18:44:12 2005
Subject: [concurrency-interest] Language extensions
	for	java.util.concurrent?
In-Reply-To: <1131655428.4335.27.camel@momo.m-qube.com>
References: <4372FE9A.6030402@mathcs.emory.edu>	<43735F07.1050504@cs.purdue.edu>
	<4373936F.9060304@mathcs.emory.edu>	<43739C61.6040502@cs.purdue.edu>
	<1131655428.4335.27.camel@momo.m-qube.com>
Message-ID: <4373DB16.5060000@cytetech.com>



Elias Ross wrote:
> Too bad Java doesn't have the C# keyword "using", it would be nice to be
> able to write
> 
>      void around() {
>         using (rt) {
>           proceed();
>         }
>      }

A keyword there would be nice.  But, adding keywords to a language is very hard. 
  I think that about the only choice would be to make it possible for 
annotations to be placed in to code.  Then we'd have a whole new dictionary of 
keywords that we could play with because they'd not conflict with identifier useage.

	void around() {
		@locked( rt ) {
			proceed();
		}
	}

this would also allow for @trylocked etc.

Gregg Wonderly
From dholmes at dltech.com.au  Thu Nov 10 18:55:33 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Thu Nov 10 18:56:10 2005
Subject: [concurrency-interest] Language extensions for
	java.util.concurrent?
In-Reply-To: <4372FE9A.6030402@mathcs.emory.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>

My 2c :-)

Dawid writes:
>   atomic int a;
>     ++a; // -> incrementAndGet()
>     a ?= 5, 8; // ->compareAndSet(5, 8)

Hmm this smacks of operator overloading! :) I don't think this sort of
syntactic shorthand buys you that much, and the messier part is the details
of passing 'a' as an argument or returning 'a' from a method. Personally I
like to see what the code actually does - eg. a.compareAndSet(...) and be
able to see just by looking at a code fragment that 'a' is not a plain old
int. I do like the ?= operator though :)

As for the more general form that Jeremy is discussing:
  atomic { ... }

I just don't buy into this sort of system magic (yet!). Languages have been
trying to sell the "tell us what you want and we'll figure out how to do it"
story on concurrency for many many years. They don't succeed because
basically noone believes they can both do it right and fast. There is no
one-size-fits-all solution for concurrency and synchronization, and until
there is people want control over how these things are done. Maybe we are
edging closer to that but I don't think we are that close yet.

The software transaction stuff is promising for some things (like replacing
synchronized with an optimistic approach that falls back to locking) but the
issue of restarts and side-effects still indicate to me that they are not a
general solution to the problem. They work well in databases but that is an
environment where there are no side-effects other than the actions of the
transaction on the database.

>     lock.lock() { // ->lock(); try { ... } finally { unlock(); }

This is a job for IDE tools, like eclipse (which I think does something like
this). Though if continuations were ever to be added to the language then
something like:
    lock.lock() { ... } -> lock.withLock(new Runnable { ... })
might be reasonable.

Aside: there have been some informal proposals for general before/after
"try" blocks over the years but they never gained enough general support to
be considered worthwhile. As Dawid alluded, exceptions and return values
make things messy.


As for Jeremy's annotation tool ... Egads man! That's not an annotation tool
it is a pre-processor! Shame on you for subverting annotations in that way.
Anyone who has read the JLS should know that annotations are not meant to
affect semantics! ;-)       :-)

Cheers,
David Holmes

From jmanson at cs.purdue.edu  Thu Nov 10 19:44:40 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov 10 19:45:37 2005
Subject: [concurrency-interest] Language extensions
	for	java.util.concurrent?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
Message-ID: <4373E978.8020800@cs.purdue.edu>

David Holmes wrote:
> As for the more general form that Jeremy is discussing:
>   atomic { ... }
> 
> I just don't buy into this sort of system magic (yet!). Languages have been
> trying to sell the "tell us what you want and we'll figure out how to do it"
> story on concurrency for many many years. They don't succeed because
> basically noone believes they can both do it right and fast. There is no
> one-size-fits-all solution for concurrency and synchronization, and until
> there is people want control over how these things are done. Maybe we are
> edging closer to that but I don't think we are that close yet.
> 
> The software transaction stuff is promising for some things (like replacing
> synchronized with an optimistic approach that falls back to locking) but the
> issue of restarts and side-effects still indicate to me that they are not a
> general solution to the problem. They work well in databases but that is an
> environment where there are no side-effects other than the actions of the
> transaction on the database.

I'll go even farther and say that I don't think there will ever be a 
one-size-fits-all solution for concurrency and synchronization, any more 
than there is a one-size-fits-all solution for, say, control flow.  We 
have if statements and do-while loops and while loops and for loops - 
there is no reason that there can't be a range of flavors for 
concurrency.  Given that, the goal is (or should be) to create a set of 
tools that are both comprehensible and usable in a broad range of contexts.

JSRs 133 and 166 do this well, but I would still argue that creating 
(say) non-blocking data structures requires serious concurrency jujitsu. 
  Learning and understanding the correct use of volatile and AtomicXXXX 
is hard!  I think that this is the area that development of atomic 
should focus on.  And given the number of non-blocking algorithm 
implementations that require at least some restart / retry, I think it 
is reasonable to have that be part of it.

> As for Jeremy's annotation tool ... Egads man! That's not an annotation tool
> it is a pre-processor! Shame on you for subverting annotations in that way.
> Anyone who has read the JLS should know that annotations are not meant to
> affect semantics! ;-)       :-)

I'm so ashamed!  I should go back to my original idea, which was to use 
Aspect Oriented Programming!  It is so much simpler and easier to 
understand!  And the resulting code is so much easier to read!

"Annotation Tool", "Pre-processor", "Po-tay-to", "Po-tah-to".  Call it a 
pre-processor if it makes you feel better.  The annotation isn't 
changing the code's behavior, the bytecode rewriter is.  It just happens 
to be using the annotation as a marker to decide when to do it.

					Jeremy
From dl at cs.oswego.edu  Fri Nov 11 09:29:54 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri Nov 11 09:31:51 2005
Subject: [concurrency-interest] Language
	extensions	for	java.util.concurrent?
In-Reply-To: <4373E978.8020800@cs.purdue.edu>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
	<4373E978.8020800@cs.purdue.edu>
Message-ID: <4374AAE2.4090907@cs.oswego.edu>

This is getting increasingly removed from the usual concurrency-interest
topics, but ...

Jeremy Manson wrote:
>   Given that, the goal is (or should be) to create a set of 
> tools that are both comprehensible and usable in a broad range of contexts.

So, to provide transactional alternatives/complements to locking, you'd
want to support lightweight language-based constructions that mirror the
cases in which database-style transactions tend to work best:
   1. They contain well-defined read-sets and write-sets
   2. They do not contain side-effecting actions or IO
   3. They do not contain nested transactions (or only limited forms)
   4. They are short.

Databases normally ensure (1) and (2) "syntactically" (SQL etc).
They usually deal with (3) by either dynamically disallowing nesting or
by requiring additional setup/cost. And either don't deal with (4) at
all (with occasional crummy performance or lots of aborts etc) or
support special long-transaction constructions.

It's a challenge to come up with a combination of syntax and APIs
that captures this well. I do think that this is the right challenge to
undertake though, rather than for example allowing arbitrary "atomic {}"
blocks that just so  happen to be well-behaved when constrained in the
above ways that you can't enforce or even check.

> 
> JSRs 133 and 166 do this well, but I would still argue that creating 
> (say) non-blocking data structures requires serious concurrency jujitsu. 

The main jujitsu is in inventing useful/efficient data-structures that
require only single-location compareAndSet. Until hardware can provide
multi-location transactional updates (coincidentally, in the same sense
as that above :-), and maybe even afterwards, these pointwise
solutions that take a lot of effort to devise and implement
correctly are likely to remain best choices.

But, in the same sense that you don't want application programmers to
bother re-implementing tricky non-concurrent data structures like
red-black trees, but instead use standardized APIs like TreeMap, I think
the most promising focus here is in identifying useful
concurrency-related APIs and providing the best implementations we can
come up with. Which just so happens to be the mission of JSR166 and its
follow-ons :-) And co-exists with longer-term goals like those above of
making  transactional forms more usable and useful for other kinds of
usages.

-Doug
From chris.purcell.39 at gmail.com  Fri Nov 11 10:07:16 2005
From: chris.purcell.39 at gmail.com (Chris Purcell)
Date: Fri Nov 11 10:07:59 2005
Subject: [concurrency-interest] Language
	extensions	for	java.util.concurrent?
In-Reply-To: <4374AAE2.4090907@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
	<4373E978.8020800@cs.purdue.edu> <4374AAE2.4090907@cs.oswego.edu>
Message-ID: <3ce34487824890312adb9b8e07d4da26@gmail.com>

Just to note,

>   1. They contain well-defined read-sets and write-sets

*Dynamically determined* read-sets and write-sets, if you use the 
current state-of-the-art. I'm not sure what you mean by "well-defined".

>   3. They do not contain nested transactions (or only limited forms)

Nested atomic blocks are usually supported.

Chris

From dl at cs.oswego.edu  Fri Nov 11 10:37:55 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri Nov 11 10:39:54 2005
Subject: [concurrency-interest] Language
	extensions	for	java.util.concurrent?
In-Reply-To: <3ce34487824890312adb9b8e07d4da26@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
	<4373E978.8020800@cs.purdue.edu> <4374AAE2.4090907@cs.oswego.edu>
	<3ce34487824890312adb9b8e07d4da26@gmail.com>
Message-ID: <4374BAD3.4090607@cs.oswego.edu>

Chris Purcell wrote:
> Just to note,
> 
>>   1. They contain well-defined read-sets and write-sets
> 
> 
> *Dynamically determined* read-sets and write-sets, if you use the 
> current state-of-the-art. I'm not sure what you mean by "well-defined".

Thanks. To try to stay uncontroversial, I prefaced this with

>> cases in which database-style transactions tend to work best: 

not, "work at all". Stretching this as far as possible in language-based
transactions is a good idea. But the possibilities of say, virtual
calls to objects of non-yet-loaded classes can make it fairly challenging.

-Doug
From jmanson at cs.purdue.edu  Fri Nov 11 11:02:55 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Fri Nov 11 11:03:44 2005
Subject: [concurrency-interest] Language
	extensions	for	java.util.concurrent?
In-Reply-To: <4374AAE2.4090907@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
	<4373E978.8020800@cs.purdue.edu> <4374AAE2.4090907@cs.oswego.edu>
Message-ID: <4374C0AF.7060101@cs.purdue.edu>

Doug Lea wrote:
> This is getting increasingly removed from the usual concurrency-interest
> topics, but ...

It's concurrent, isn't it? ;)

> Jeremy Manson wrote:
> 
>>   Given that, the goal is (or should be) to create a set of tools that 
>> are both comprehensible and usable in a broad range of contexts.
> 
> So, to provide transactional alternatives/complements to locking, you'd
> want to support lightweight language-based constructions that mirror the
> cases in which database-style transactions tend to work best:
>   1. They contain well-defined read-sets and write-sets
>   2. They do not contain side-effecting actions or IO
>   3. They do not contain nested transactions (or only limited forms)
>   4. They are short.
> 
> It's a challenge to come up with a combination of syntax and APIs
> that captures this well. I do think that this is the right challenge to
> undertake though, rather than for example allowing arbitrary "atomic {}"
> blocks that just so  happen to be well-behaved when constrained in the
> above ways that you can't enforce or even check.

My point was that atomic blocks are only one tool in the concurrent 
programmer's toolbox, not that atomic blocks are applicable in every 
context.  Sorry if that was unclear from the message.  It bothers me 
when people try to sell atomic blocks as a panacea.

As far as the specific challenges - well, as I said in my first message, 
I elided lots of detail.  I agree that these are several of the obvious 
challenges / limitations when developing effective atomic sections for a 
programming language.

Chris Purcell took issue with 3, which he says are usually supported:

 >   3. They do not contain nested transactions (or only limited forms)

If there are going to be atomics in use in libraries, it becomes pretty 
important to support nested ones.   From my point of view, support for 
nested transactions depends on what you expect them to do.  Their 
semantics can get arbitrarily hairy.  IMO, it is better to keep them 
simple where they occur (by making them reentrant, for example, in the 
same way as synchronized blocks).

We could exchange messages for months on all four points, though, so it 
might be better not to get too deeply into this.


>> JSRs 133 and 166 do this well, but I would still argue that creating 
>> (say) non-blocking data structures requires serious concurrency jujitsu. 
> 
> The main jujitsu is in inventing useful/efficient data-structures that
> require only single-location compareAndSet.

I agree with this; it was, effectively, my point.  Structuring 
algorithms around this is extremely tricky, as you know.

> Until hardware can provide
> multi-location transactional updates (coincidentally, in the same sense
> as that above :-), and maybe even afterwards, these pointwise
> solutions that take a lot of effort to devise and implement
> correctly are likely to remain best choices.

It may, in fact, take hardware support before atomic sections are useful 
to a broad audience.  As for afterwards - well, if you have it, it makes 
sense to be able to use it.

However, I think it is possible to use atomic sections in the meantime 
for platforms for which you have well-understood constraints that make 
it possible to implement them.  Cooperative systems / user-level thread 
systems make implementation of atomic blocks a bit easier and more 
sensible, for obvious reasons.  But then we are straying away from pure 
Java...

> But, in the same sense that you don't want application programmers to
> bother re-implementing tricky non-concurrent data structures like
> red-black trees, but instead use standardized APIs like TreeMap, I think
> the most promising focus here is in identifying useful
> concurrency-related APIs and providing the best implementations we can
> come up with. Which just so happens to be the mission of JSR166 and its
> follow-ons :-) And co-exists with longer-term goals like those above of
> making  transactional forms more usable and useful for other kinds of
> usages.

I wouldn't disagree.  Obviously, your first line of resort should be to 
see if there is an existing library that will fill your needs.  JSR-166 
provides an excellent array of tools.

It is very easy to get carried away with shoving concurrency extensions 
into the language.  I can think of several languages that suffer from 
this problem.  There is a tendency to shoehorn in every feature that the 
designer thinks is cool.  But I would say that in this case that there 
is a hole in what the language provides (which is the ability to do 
multi-location transactional updates).

					Jeremy
From brian at quiotix.com  Thu Nov 10 23:57:24 2005
From: brian at quiotix.com (Brian Goetz)
Date: Fri Nov 11 21:30:13 2005
Subject: [concurrency-interest] Language extensions
	for	java.util.concurrent?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
Message-ID: <437424B4.6030808@quiotix.com>

> I just don't buy into this sort of system magic (yet!). Languages have been
> trying to sell the "tell us what you want and we'll figure out how to do it"
> story on concurrency for many many years. They don't succeed because
> basically noone believes they can both do it right and fast. 

I'm not sure that it needs to be right and fast for it to be damn useful 
today.  Getting locking right is just too hard for Joe Java. 
Concurrency bugs that make it into the field and fail there are very 
expensive.  So for Joe Java, something that gets it right, and not 
godawful slow, might still be a big improvement.  And it will get 
faster, just like everything else does (synchronization was pretty slow 
in Java 1.0.)


> The software transaction stuff is promising for some things (like replacing
> synchronized with an optimistic approach that falls back to locking) but the
> issue of restarts and side-effects still indicate to me that they are not a
> general solution to the problem. They work well in databases but that is an
> environment where there are no side-effects other than the actions of the
> transaction on the database.

I think the real win in the transactional stuff is that it makes writing 
a concurrent algorithm nearly as easy as writing a sequential one.  The 
performance of a V1.0 system might not be all that much worse than what 
Joe Java cooks up.


And with respect to annotations -- turn away from the dark side, Jeremy...

From dl at cs.oswego.edu  Sat Nov 12 10:27:12 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat Nov 12 10:29:09 2005
Subject: [concurrency-interest] Language
	extensions	for	java.util.concurrent?
In-Reply-To: <437424B4.6030808@quiotix.com>
References: <NFBBKALFDCPFIDBNKAPCAEHKGIAA.dholmes@dltech.com.au>
	<437424B4.6030808@quiotix.com>
Message-ID: <437609D0.8000901@cs.oswego.edu>

Brian Goetz wrote:
> [... transactions ...]
> 
>> I just don't buy into this sort of system magic (yet!). Languages 
>> have been trying to sell the "tell us what you want and we'll 
>> figure out how to do it" story on concurrency for many many years.
>>  They don't succeed because basically noone believes they can both
>>  do it right and fast.
> 
> 
> I'm not sure that it needs to be right and fast for it to be damn 
> useful today.

Millions of J2EE/EJB application programmers apparently agree with you.

Recall that most J2EE application code does (in the most common usages)
behave in a basically transactional manner: Containers
may serialize objects for the sake of roll back on failure,
eliminate ability for application code to perform most IO or create  '
new threads, update most object state only via database operations, and
so on.  There's supposedly no need for these programmers to ever use
"synchronized" or anything in java.util.concurrent, and also no need to
deal with security or distribution. Although, inevitably, there are
some cases where reality leaks through, so it is hard to make
simple uniform semantic guarantees about effects.

All this middleware support has a huge effect on performance, but many
people seem to think it is worth the tradeoffs.

But even J2EE programmers sometimes find that they need or
want to introduce concurrency rather than just maintain safety in
the face of potential underlying concurrency. So, stay tuned for
the JSR236/237 "Managed" versions of the java.util.concurrent Executor
framework that will allow J2EE programmers to use async tasks and
Futures as their main (and practically only) form of concurrency
support. The in-progress JSR236/237 will be standardizing the kinds of
things now non-standardly supported in the Websphere and Weblogic
"commonj" work packages to instead use special forms of j.u.c Executors.

Anyway, my main point is just the usual one: There are lots of
useful styles of (concurrent) programming, none of which are always
best, but all of which might be subject to improvement via combinations
of better language, library, and tool support.

-Doug

From mattocks at mac.com  Tue Nov 15 22:59:09 2005
From: mattocks at mac.com (Craig Mattocks)
Date: Tue Nov 15 22:59:54 2005
Subject: [concurrency-interest] Need advice
Message-ID: <a330cc24759888659ee191e11f6186fa@mac.com>

Hi,

I am an environmental research scientist and I am contemplating porting 
a large computational fluid dynamics (CFD) simulation model from 
Fortran 90/95 to Java. The code currently runs on unix/Linux clusters 
using MPI, distributing "patches" of two-dimensional arrays to separate 
nodes/processors to run concurrently (in parallel).

If I restructure the code to use objects inherent to the problem 
instead of global arrays of data, what is the current state-of-the-art 
framework for distributing these objects to different machines 
(nodes/processors) in a cluster?

Thank you, in advance, for your advice and insights.

Craig
--------------------------------------------------------------------
"We all agree that your theory is crazy, but is it crazy enough?"
- Niels Bohr (1885-1962), Nobel physicist, founder of quantum theory
--------------------------------------------------------------------

From gergg at cox.net  Tue Nov 15 23:42:03 2005
From: gergg at cox.net (Gregg Wonderly)
Date: Tue Nov 15 23:42:43 2005
Subject: [concurrency-interest] Need advice
In-Reply-To: <a330cc24759888659ee191e11f6186fa@mac.com>
References: <a330cc24759888659ee191e11f6186fa@mac.com>
Message-ID: <437AB89B.2060503@cox.net>

Craig Mattocks wrote:
> Hi,
> 
> I am an environmental research scientist and I am contemplating porting 
> a large computational fluid dynamics (CFD) simulation model from Fortran 
> 90/95 to Java. The code currently runs on unix/Linux clusters using MPI, 
> distributing "patches" of two-dimensional arrays to separate 
> nodes/processors to run concurrently (in parallel).
> 
> If I restructure the code to use objects inherent to the problem instead 
> of global arrays of data, what is the current state-of-the-art framework 
> for distributing these objects to different machines (nodes/processors) 
> in a cluster?

Craig, the most predominate Java Centric parallel processing, distributed 
architecture engine is the Javaspaces tuple space that is part of Jini.  It 
provides a very powerful mechanism for easily assembling a compute engine.

If you look over on http://www.jini.org under the projects tab, you'll find a 
number of grid/compute server projects.  The http://computefarm.jini.org project 
might be a good place to look at one example of what has been done.  There are 
other examples including some distributed image processing done for realtime 
satellite data etc.

If you have questions, drop me an email, and/or subscribe to the 
javaspaces-users group visible off of http://www.jini.org.

Gregg Wonderly
From skautz at aonix.com  Wed Nov 16 15:49:27 2005
From: skautz at aonix.com (Steve Kautz)
Date: Wed Nov 16 15:50:08 2005
Subject: [concurrency-interest] Roach motels
Message-ID: <002a01c5eaef$3c961800$6a03a8c0@Longitude>

Reading Brian Goetz's article on synchronization optimizations in Mustang
got me thinking again about Bill Pugh's roach motel analogy (statements can
move into a sync block, but they can't move out...).  Does anyone have any
information about conditions under which statements might be moved into a
preceding sync block (or similarly, whether adjacent synchronized blocks may
be coalesced when there is intervening code)?


E.g. suppose we have something like:

boolean foo()
{
synchronized(this)
{
if (inProgress) return false;
inProgress = true;
}

// make this call without lock
Result result = someOtherObject.bar();

synchronized(this)
{
updateState(result);
inProgress = false;
return true;
}
}

When is the compiler allowed to move the call to bar() into the upper sync
block or to coalesce the two blocks?

I'm just wondering about several situations that have come up recently in
which we need to guarantee that the call to bar() is made without holding
the sync lock. This is generally to avoid a possible deadlock, but it may be
for other liveness-related reasons (call to bar() may block).

For example, in the OSGi framework, calls on the bundle registry must not be
made from synchronized code. (The problem is that any call on the registry
may trigger callbacks on other bundles (listeners) and these callbacks are
always made synchronously, so if two threads call the registry at about the
same time, and they are holding sync locks on bundles that are listening for
registry events, it is easy to get deadlock.)

Thanks in advance for any information or pointers to information.
-- Steve K


From jmanson at cs.purdue.edu  Wed Nov 16 16:36:57 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Wed Nov 16 16:37:58 2005
Subject: [concurrency-interest] Roach motels
In-Reply-To: <002a01c5eaef$3c961800$6a03a8c0@Longitude>
References: <002a01c5eaef$3c961800$6a03a8c0@Longitude>
Message-ID: <437BA679.7080806@cs.purdue.edu>

Steve Kautz wrote:

> boolean foo()
> {
> synchronized(this)
> {
> if (inProgress) return false;
> inProgress = true;
> }
> 
> // make this call without lock
> Result result = someOtherObject.bar();
> 
> synchronized(this)
> {
> updateState(result);
> inProgress = false;
> return true;
> }
> }
> 
> When is the compiler allowed to move the call to bar() into the upper sync
> block or to coalesce the two blocks?
> 
> I'm just wondering about several situations that have come up recently in
> which we need to guarantee that the call to bar() is made without holding
> the sync lock. This is generally to avoid a possible deadlock, but it may be
> for other liveness-related reasons (call to bar() may block).

The system is allowed to introduce fairness issues, but can't introduce 
deadlock.  This is because fairness is considered a quality-of-service 
guarantee, but deadlock is considered a correctness issue.

For example, if you have:

while (true) {
   synchronized (this) {
     // stuff
   }
}

The system could change it to this:

synchronized (this) {
   while (true) {
     // stuff
   }
}

Any other thread that actually wants to acquire the lock on this would 
wait forever, which is legal under the Java spec.  This falls under the 
same category of badness as giving all of the runtime to a single 
thread, and never allowing another thread to run.  It's legal, but a 
well-designed system would probably not do it.

OTOH, a system cannot, in general, take this:

   synchronized (this) {
     // stuff
   }
   synchronized (that) {
     // more stuff
   }
   synchronized (this) {
     // even more stuff
   }

and change it to this:

synchronized (this) {
   // stuff

   synchronized (that) {
     // more stuff
   }

   // even more stuff
}

because this can introduce deadlock, which may introduce errors in your 
program.

Interesting aside: There are caveats to this, but those caveats should 
never be seen to affect the correctness of your program.  An example of 
such a caveat would be if the system can determine that the lock on 
"that" is never acquired by any other thread.  In this case, it can do 
the lock coalescing, because doing so won't introduce deadlock.

					Jeremy
From skautz at aonix.com  Wed Nov 16 17:55:03 2005
From: skautz at aonix.com (Steve Kautz)
Date: Wed Nov 16 17:55:47 2005
Subject: [concurrency-interest] Roach motels
Message-ID: <003e01c5eb00$c8116e00$6a03a8c0@Longitude>

Jeremy, thanks for that quick reply.

> OTOH, a system cannot, in general, take this:
>
>    synchronized (this) {
>      // stuff
>    }
>    synchronized (that) {
>      // more stuff
>    }
>    synchronized (this) {
>      // even more stuff
>    }
>
> and change it to this:
>
> synchronized (this) {
>    // stuff
>
>    synchronized (that) {
>      // more stuff
>    }
>
>    // even more stuff
> }
>
> because this can introduce deadlock, which may introduce errors in your
> program.


Right. So I think the interesting question is then, in which direction does
the burden of proof go?   For example, if instead of literally having
synchronized(that) we again have something like:

  synchronized (this) {
     // stuff
   }

   otherObject.bar();

   }
   synchronized (this) {
     // even more stuff
   }

how far is the system obligated to look before concluding that bar() will,
or won't, enter a block of the form synchronized(that)?

In particular, in the OSGi example mentioned earlier, method bar()
ultimately invokes callback methods for a list of listeners, some of which
may be synchronized, and which are added/removed dynamically at runtime.  So
no amount of static analysis will show whether or not a call to bar() will
end up invoking "synchronized(that)".   Does the system a) assume that a
method call may end up in synchronized code unless it can prove otherwise,
or does it b) assume it's ok to coalesce the blocks unless it can show that
the call includes something like "synchronized(that)"?

-- Steve K

From jmanson at cs.purdue.edu  Thu Nov 17 00:00:58 2005
From: jmanson at cs.purdue.edu (Jeremy Manson)
Date: Thu Nov 17 00:01:40 2005
Subject: [concurrency-interest] Roach motels
In-Reply-To: <003e01c5eb00$c8116e00$6a03a8c0@Longitude>
References: <003e01c5eb00$c8116e00$6a03a8c0@Longitude>
Message-ID: <437C0E8A.3030601@cs.purdue.edu>

Steve Kautz wrote:
> Jeremy, thanks for that quick reply.

No problem.  In answer to your question below, the answer is "a)", the 
system has to ensure that it isn't introducing deadlock.  If it can't do 
so, then it can't perform the transformation.  If it can't analyze 
unknown method calls, then it can't perform the transformation.

[I thought I sent this hours ago!]

					Jeremy

> 
> 
>>OTOH, a system cannot, in general, take this:
>>
>>   synchronized (this) {
>>     // stuff
>>   }
>>   synchronized (that) {
>>     // more stuff
>>   }
>>   synchronized (this) {
>>     // even more stuff
>>   }
>>
>>and change it to this:
>>
>>synchronized (this) {
>>   // stuff
>>
>>   synchronized (that) {
>>     // more stuff
>>   }
>>
>>   // even more stuff
>>}
>>
>>because this can introduce deadlock, which may introduce errors in your
>>program.
> 
> 
> 
> Right. So I think the interesting question is then, in which direction does
> the burden of proof go?   For example, if instead of literally having
> synchronized(that) we again have something like:
> 
>   synchronized (this) {
>      // stuff
>    }
> 
>    otherObject.bar();
> 
>    }
>    synchronized (this) {
>      // even more stuff
>    }
> 
> how far is the system obligated to look before concluding that bar() will,
> or won't, enter a block of the form synchronized(that)?
> 
> In particular, in the OSGi example mentioned earlier, method bar()
> ultimately invokes callback methods for a list of listeners, some of which
> may be synchronized, and which are added/removed dynamically at runtime.  So
> no amount of static analysis will show whether or not a call to bar() will
> end up invoking "synchronized(that)".   Does the system a) assume that a
> method call may end up in synchronized code unless it can prove otherwise,
> or does it b) assume it's ok to coalesce the blocks unless it can show that
> the call includes something like "synchronized(that)"?
> 
> -- Steve K
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest

From jean.morissette666 at videotron.ca  Tue Nov 22 23:05:30 2005
From: jean.morissette666 at videotron.ca (Jean Morissette)
Date: Tue Nov 22 23:06:14 2005
Subject: [concurrency-interest] Bulk put/take queue operations
Message-ID: <4383EA8A.10103@videotron.ca>

Hi,
    Is there any plan to support bulk put/take queue operations?  This 
would be usefull to improve performance by reducing lock overhead.  
Also, this could add a kind of optimistic transactionnal semantic (if 
the queue is bounded), which the current API doesn't support.

Regards,
Jean
From josh at bloch.us  Thu Nov 24 20:20:01 2005
From: josh at bloch.us (Joshua Bloch)
Date: Thu Nov 24 20:20:53 2005
Subject: [concurrency-interest] unit testing concurrency code.
In-Reply-To: <432FD36E.1040402@roke.co.uk>
References: <24CFCE44DCB015489FB96D38BDF4FCAA07CA2E@gerard.anchormen.nl>
	<431DE31B.1020907@quiotix.com> <432FD36E.1040402@roke.co.uk>
Message-ID: <b097ac510511241720h565fdf3bx8403f86bb30f59b6@mail.gmail.com>

Nor can you reliably determine that a program works merely by proving
it correct.  You can only prove correctness with respect to some
model, which may itself be flawed.  Also your proof may be faulty.
Some combination of testing and proof works best.  Also it's important
to show your program to other experts.  Two (or more) heads are better
than one.

        Josh

On 9/20/05, Rick Beton <richard.beton@roke.co.uk> wrote:
> Brian Goetz wrote:
>
>  > Testing concurrent code is an extension of testing regular code.
>  > First, you must have good tests for functionality, and be able to test
>  > as many of your classes invariants as possible.  The trick is then
>  > trying to generate as many random interleavings of operations as you
>  > can, without the test framework introducing timing artifacts that will
>  > prevent certain interleavings from being tested.
>
>
> Surely this overlooks something: there are four kinds of dynamic failure
> (deadlock, livelock, starvation and race) that you cannot prove are
> absent simply by testing alone.  You can prove they are *present* if
> your testing finds them, but you can't prove they are *absent*.
>
> This is quite important if you are writing concurrency classes for other
> people to use.  You cannot write tests with enough coverage to handle
> every end-user's use cases.  Simply covering a certain subset of dynamic
> behaviour and then passing such classes as "tested" may be a bit too
> optimistic and misleading.
>
> I'd like to draw your attention to Peter Welch's posting ("CSP, the
> pi-calculus and CPA-2005") and the work he and others have done using
> CSP as the basis for establishing thread reliability (establishing the
> absence of deadlock, livelock, starvation and race).  My own experience
> is limited to being a JCSP user, rather than having much theoretical
> skill.  There are some straightforward design rules that guarantee
> deadlock freedom for example.  This makes JCSP a simple strategy to
> apply to practical usage.
>
> Regards,
> Rick
>
>
>
>
>
>
>
>
>
> --
>
> Visit our website at www.roke.co.uk
>
> Roke Manor Research Ltd, Roke Manor, Romsey, Hampshire SO51 0ZN, UK.
>
> The information contained in this e-mail and any attachments is proprietary to
> Roke Manor Research Ltd and must not be passed to any third party without
> permission. This communication is for information only and shall not create or
> change any contractual relationship.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest@altair.cs.oswego.edu
> http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From p.veentjer at anchormen.nl  Tue Nov 29 06:15:20 2005
From: p.veentjer at anchormen.nl (Peter Veentjer - Anchor Men)
Date: Tue Nov 29 06:16:31 2005
Subject: [concurrency-interest] when to use lock and when to use
	lockInterruptibly
Message-ID: <24CFCE44DCB015489FB96D38BDF4FCAA1EA11F@gerard.anchormen.nl>

When should a lockInterruptibly be used instead of a lock? I guess it
depends on the lock implementation if it supports interruption. Is this
correct? And wouldn`t it be better to always you the lockInterruptibly
(although you have to deal with an InterruptedException).

Met vriendelijke groet,

Peter Veentjer
Anchor Men Interactive Solutions - duidelijk in zakelijke
internetoplossingen

Praediniussingel 41
9711 AE Groningen

T: 050-3115222
F: 050-5891696
E: p.veentjer@anchormen.nl
I : www.anchormen.nl

From joe.bowbeer at gmail.com  Tue Nov 29 07:06:02 2005
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue Nov 29 07:06:47 2005
Subject: [concurrency-interest] when to use lock and when to use
	lockInterruptibly
In-Reply-To: <24CFCE44DCB015489FB96D38BDF4FCAA1EA11F@gerard.anchormen.nl>
References: <24CFCE44DCB015489FB96D38BDF4FCAA1EA11F@gerard.anchormen.nl>
Message-ID: <31f2a7bd0511290406y600329c0h5c1fa83bf17d5306@mail.gmail.com>

On 11/29/05, Peter Veentjer - Anchor Men <p.veentjer@anchormen.nl> wrote:
> When should a lockInterruptibly be used instead of a lock? I guess it
> depends on the lock implementation if it supports interruption. Is this
> correct? And wouldn`t it be better to always you the lockInterruptibly
> (although you have to deal with an InterruptedException).
>

The non-interruptible lock method is similar to the implicit lock in a
"native" synchronized block, in that neither can be interrupted.  I
believe this is one of the reasons that non-interruptible is the
default for the Lock interface.

(Note that the acquire method was interruptible in the dl.u.c. Sync
interface, Lock's ancestor.)

For other situations, that is, except when replacing native
synchronized blocks or otherwise retrofitting old methods with new
locks, I tend to favor lockInterruptibly and its explicit
InterruptedException.

From p.veentjer at anchormen.nl  Tue Nov 29 08:39:57 2005
From: p.veentjer at anchormen.nl (Peter Veentjer - Anchor Men)
Date: Tue Nov 29 08:40:40 2005
Subject: [concurrency-interest] scheduledthreadpoolexecutor threadsafe?
Message-ID: <24CFCE44DCB015489FB96D38BDF4FCAA1EA120@gerard.anchormen.nl>

I have a question about the thread safety of the
ScheduledThreadPoolExecutor.

eg:

 private void delayedExecute(Runnable command) {
        if (isShutdown()) {
            reject(command);
            return;
        }
        // Prestart a thread if necessary. We cannot prestart it
        // running the task because the task (probably) shouldn't be
        // run yet, so thread will just idle until delay elapses.
        if (getPoolSize() < getCorePoolSize())
            prestartCoreThread();
            
        super.getQueue().add(command);
    }

It could happen that a command is added to the Queue altough the
ExecutorService has just been shutdown. This task will never be
executed. Shouldn`t it be better if the ScheduledThreadPoolExecutor
received a Lock from the ThreadPoolExecutor to make this an atomic
action?

The reason I`m asking this question is that I`m also extending to
ThreadPoolExecutor to getter better control on timout behaviour of the
offering of tasks.

Met vriendelijke groet,

Peter Veentjer
Anchor Men Interactive Solutions - duidelijk in zakelijke
internetoplossingen

Praediniussingel 41
9711 AE Groningen

T: 050-3115222
F: 050-5891696
E: p.veentjer@anchormen.nl
I : www.anchormen.nl

From p.veentjer at anchormen.nl  Tue Nov 29 08:58:32 2005
From: p.veentjer at anchormen.nl (Peter Veentjer - Anchor Men)
Date: Tue Nov 29 08:59:16 2005
Subject: [concurrency-interest] scheduledthreadpoolexecutor threadsafe?
Message-ID: <24CFCE44DCB015489FB96D38BDF4FCAA1EA121@gerard.anchormen.nl>

 Hmm.. maybe I know the answer to my own question. The
ThreadPoolExecutor will execute all remaining tasks if it is shutdown.
So all queued tasks will be processed (unless shutdownNow is called).

-----Oorspronkelijk bericht-----
Van: concurrency-interest-bounces@cs.oswego.edu
[mailto:concurrency-interest-bounces@cs.oswego.edu] Namens Peter
Veentjer - Anchor Men
Verzonden: dinsdag 29 november 2005 14:40
Aan: concurrency-interest@altair.cs.oswego.edu
Onderwerp: [concurrency-interest] scheduledthreadpoolexecutor
threadsafe?

I have a question about the thread safety of the
ScheduledThreadPoolExecutor.

eg:

 private void delayedExecute(Runnable command) {
        if (isShutdown()) {
            reject(command);
            return;
        }
        // Prestart a thread if necessary. We cannot prestart it
        // running the task because the task (probably) shouldn't be
        // run yet, so thread will just idle until delay elapses.
        if (getPoolSize() < getCorePoolSize())
            prestartCoreThread();
            
        super.getQueue().add(command);
    }

It could happen that a command is added to the Queue altough the
ExecutorService has just been shutdown. This task will never be
executed. Shouldn`t it be better if the ScheduledThreadPoolExecutor
received a Lock from the ThreadPoolExecutor to make this an atomic
action?

The reason I`m asking this question is that I`m also extending to
ThreadPoolExecutor to getter better control on timout behaviour of the
offering of tasks.

Met vriendelijke groet,

Peter Veentjer
Anchor Men Interactive Solutions - duidelijk in zakelijke
internetoplossingen

Praediniussingel 41
9711 AE Groningen

T: 050-3115222
F: 050-5891696
E: p.veentjer@anchormen.nl
I : www.anchormen.nl

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest@altair.cs.oswego.edu
http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest


From dholmes at dltech.com.au  Tue Nov 29 18:13:01 2005
From: dholmes at dltech.com.au (David Holmes)
Date: Tue Nov 29 18:13:48 2005
Subject: [concurrency-interest] when to use lock and when to use
	lockInterruptibly
In-Reply-To: <24CFCE44DCB015489FB96D38BDF4FCAA1EA11F@gerard.anchormen.nl>
References: <24CFCE44DCB015489FB96D38BDF4FCAA1EA11F@gerard.anchormen.nl>
Message-ID: <20051129230712.M35661@dltech.com.au>

> When should a lockInterruptibly be used instead of a lock? I guess it
> depends on the lock implementation if it supports interruption. Is this
> correct? And wouldn`t it be better to always you the lockInterruptibly
> (although you have to deal with an InterruptedException).

If you want to be more responsive to interrupts *and* the acquisition of the 
lock is not critical then you might want to always lockInterruptibly. A lot 
of the time though that would force propagating the InterruptedException from 
methods that are not truly "blocking" and hence don't need to be 
interruptible.

One situation where you would not want to use interruptible locking is when 
the action you need the lock for must be performed. eg:

   void somemethod() {
     try {
         // main code
      }
      finally {
         l.lock();
         try { updateState(); } finally {
         lock.unlock(); }
      }
   }

Cheers,
David Holmes
From dl at cs.oswego.edu  Tue Nov 29 20:09:44 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue Nov 29 20:11:49 2005
Subject: [concurrency-interest] Bulk put/take queue operations
In-Reply-To: <4383EA8A.10103@videotron.ca>
References: <4383EA8A.10103@videotron.ca>
Message-ID: <438CFBD8.6050903@cs.oswego.edu>

Jean Morissette wrote:
> Hi,
>    Is there any plan to support bulk put/take queue operations?  


For bulk-removes, there's BlockingQueue,drainTo. For bulk-adds,
there's addAll, although this is useful only for unbounded queues.
(For bounded ones, it will throw an exception if some cannot be
added without blocking.) Do you have something further in mind?

-Doug


From moranor at gmail.com  Wed Nov 30 05:06:18 2005
From: moranor at gmail.com (Moran Or Avigdor)
Date: Wed Nov 30 06:43:36 2005
Subject: [concurrency-interest] backport: AtomicLongFieldUpdater support
Message-ID: <98b337d10511300206k57da377fg7f7e554b40e62844@mail.gmail.com>

Are there any plans to support a backport version of
java.util.concurrent.atomic.AtomicLongFieldUpdater ?
e.g.
edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicLongFieldUpdater

Thank you in advance,
Moran.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: /pipermail/attachments/20051130/fb63338e/attachment.htm
From dl at cs.oswego.edu  Wed Nov 30 07:24:34 2005
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed Nov 30 07:26:38 2005
Subject: [concurrency-interest] backport: AtomicLongFieldUpdater support
In-Reply-To: <98b337d10511300206k57da377fg7f7e554b40e62844@mail.gmail.com>
References: <98b337d10511300206k57da377fg7f7e554b40e62844@mail.gmail.com>
Message-ID: <438D9A02.300@cs.oswego.edu>

Moran Or Avigdor wrote:
> Are there any plans to support a backport version of 
> java.util.concurrent.atomic.AtomicLongFieldUpdater ?
> e.g. 
> edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicLongFieldUpdater
> 

While it would logically be possible to do this without
Java 5 native support, it would be so pathetically slow that
Dawid is doing you a big favor by not including them. :-)

-Doug

From dawidk at mathcs.emory.edu  Wed Nov 30 16:51:51 2005
From: dawidk at mathcs.emory.edu (Dawid Kurzyniec)
Date: Wed Nov 30 16:52:46 2005
Subject: [concurrency-interest] backport: AtomicLongFieldUpdater support
In-Reply-To: <438D9A02.300@cs.oswego.edu>
References: <98b337d10511300206k57da377fg7f7e554b40e62844@mail.gmail.com> 
	<438D9A02.300@cs.oswego.edu>
Message-ID: <438E1EF7.3040306@mathcs.emory.edu>

Doug Lea wrote:

> Moran Or Avigdor wrote:
>
>> Are there any plans to support a backport version of 
>> java.util.concurrent.atomic.AtomicLongFieldUpdater ?
>> e.g. 
>> edu.emory.mathcs.backport.java.util.concurrent.atomic.AtomicLongFieldUpdater 
>>
>>
>
> While it would logically be possible to do this without
> Java 5 native support, it would be so pathetically slow that
> Dawid is doing you a big favor by not including them. :-)
>
Yep. It would have to use reflection combined with synchronization. Even 
despite improvements in reflection performance, this does not seem to be 
a viable option.

Regards,
Dawid

