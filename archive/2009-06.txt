From concurrency-interest at cs.oswego.edu  Mon Jun  1 11:40:52 2009
From: concurrency-interest at cs.oswego.edu (PFIZER.INC)
Date: Mon, 1 Jun 2009 11:40:52 -0400 (EDT)
Subject: [concurrency-interest] DISCOUNT ID38324 70% 0FF on Pfizer !
Message-ID: <200906011540.n51FeqJF001038@cs.oswego.edu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090601/73756949/attachment.html>

From karlthepagan at gmail.com  Wed Jun  3 00:31:02 2009
From: karlthepagan at gmail.com (karlthepagan)
Date: Tue, 2 Jun 2009 21:31:02 -0700
Subject: [concurrency-interest] Collections Connection 10
	(TransferQueue.tryTransfer)
Message-ID: <39008ef30906022131w7afb5309s1b354552cd715ae6@mail.gmail.com>

Does the introduction of TransferQueue.tryTransfer indicate that we may see
the leader-followers scheduling strategy for executors as a part of the
concurrency package? (i.e. http://www.cs.wustl.edu/~schmidt/PDF/lf.pdf)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090602/03afcbfd/attachment.html>

From dl at cs.oswego.edu  Wed Jun  3 06:48:18 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 03 Jun 2009 06:48:18 -0400
Subject: [concurrency-interest] Collections Connection 10
	(TransferQueue.tryTransfer)
In-Reply-To: <39008ef30906022131w7afb5309s1b354552cd715ae6@mail.gmail.com>
References: <39008ef30906022131w7afb5309s1b354552cd715ae6@mail.gmail.com>
Message-ID: <4A2654F2.2020806@cs.oswego.edu>

karlthepagan wrote:
> Does the introduction of TransferQueue.tryTransfer indicate that we may 
> see the leader-followers scheduling strategy for executors as a part of 
> the concurrency package? (i.e. http://www.cs.wustl.edu/~schmidt/PDF/lf.pdf)
> 

Better thread pools are among the use cases for
TransferQueue (one is used internally in ForkJoinPool).
There aren't any immediate plans for a leader-follower
style pool, but we encourage people to experiment with
such designs.

-Doug


From dmytro_sheyko at hotmail.com  Thu Jun  4 04:44:37 2009
From: dmytro_sheyko at hotmail.com (Dmytro Sheyko)
Date: Thu, 4 Jun 2009 15:44:37 +0700
Subject: [concurrency-interest] FW: Cant detect deadlock when thread
 reenters synchronization block in	Object.wait()
In-Reply-To: <4A2690F7.5020507@sun.com>
References: <BLU142-W977EB9CCD0CB39860D7FC8A4A0@phx.gbl>
	<4A2690F7.5020507@sun.com>
Message-ID: <BLU142-W18454432C72B817C7D73ED8A4B0@phx.gbl>


Hi all,

There is a bug related to deadlock detection:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6841139

Fixing this issue requires changes in hotspot (it regards pure monitors only). However I believe that for consistency java.util.concurrent classes need to be modified as well. So I created separate bug report for java part as David Holmes suggested. The general idea is to adjust AbstractOwnableSynchronizer so that it would be able to detect deadlocks even if threads wait on condition.
Details are here:
https://bugs.openjdk.java.net/show_bug.cgi?id=100060

proposed patch (java part only):
diff -r 045743e0eb2d src/share/classes/java/util/concurrent/locks/AbstractOwnableSynchronizer.java
--- a/src/share/classes/java/util/concurrent/locks/AbstractOwnableSynchronizer.java    Thu Jun 04 11:28:03 2009 +0800
+++ b/src/share/classes/java/util/concurrent/locks/AbstractOwnableSynchronizer.java    Thu Jun 04 10:54:58 2009 +0300
@@ -54,9 +54,23 @@
     private static final long serialVersionUID = 3737899427754241961L;
 
     /**
-     * Empty constructor for use by subclasses.
+     * Empty constructor for use by subclasses,
+     * creates <tt>main</tt> ownable synchronizer.
      */
-    protected AbstractOwnableSynchronizer() { }
+    protected AbstractOwnableSynchronizer() {
+        this(null);
+    }
+
+    /**
+     * Facility to create <tt>side</tt> ownable synchronizer, which shares
+     * information about exclusive owner thread with specified parent.
+     *
+     * @param parent - ownable synchronizer, with which exclusive owner thread will be shared,
+     * or <tt>null</tt> to create <tt>main</tt> ownable synchronizer.
+     */
+    protected AbstractOwnableSynchronizer(AbstractOwnableSynchronizer parent) {
+        mainOwnableSynchronizer = (parent == null) ? this : parent.mainOwnableSynchronizer;
+    }
 
     /**
      * The current owner of exclusive mode synchronization.
@@ -64,13 +78,18 @@
     private transient Thread exclusiveOwnerThread;
 
     /**
+     * The <tt>main</tt> ownable synchronizer, which actually maintains owner thread.
+     */
+    private final AbstractOwnableSynchronizer mainOwnableSynchronizer;
+
+    /**
      * Sets the thread that currently owns exclusive access. A
      * <tt>null</tt> argument indicates that no thread owns access.
      * This method does not otherwise impose any synchronization or
      * <tt>volatile</tt> field accesses.
      */
     protected final void setExclusiveOwnerThread(Thread t) {
-        exclusiveOwnerThread = t;
+        mainOwnableSynchronizer.exclusiveOwnerThread = t;
     }
 
     /**
@@ -81,6 +100,6 @@
      * @return the owner thread
      */
     protected final Thread getExclusiveOwnerThread() {
-        return exclusiveOwnerThread;
+        return mainOwnableSynchronizer.exclusiveOwnerThread;
     }
 }
diff -r 045743e0eb2d src/share/classes/java/util/concurrent/locks/AbstractQueuedLongSynchronizer.java
--- a/src/share/classes/java/util/concurrent/locks/AbstractQueuedLongSynchronizer.java    Thu Jun 04 11:28:03 2009 +0800
+++ b/src/share/classes/java/util/concurrent/locks/AbstractQueuedLongSynchronizer.java    Thu Jun 04 10:54:58 2009 +0300
@@ -1452,6 +1452,7 @@
          * attempt to set waitStatus fails, wake up to resync (in which
          * case the waitStatus can be transiently and harmlessly wrong).
          */
+        LockSupport.setBlocker(node.thread, this);
         Node p = enq(node);
         int ws = p.waitStatus;
         if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
@@ -1604,7 +1605,7 @@
      *
      * @since 1.6
      */
-    public class ConditionObject implements Condition, java.io.Serializable {
+    public class ConditionObject extends AbstractOwnableSynchronizer implements Condition, java.io.Serializable {
         private static final long serialVersionUID = 1173984872572414699L;
         /** First node of condition queue. */
         private transient Node firstWaiter;
@@ -1614,7 +1615,9 @@
         /**
          * Creates a new <tt>ConditionObject</tt> instance.
          */
-        public ConditionObject() { }
+        public ConditionObject() {
+            super(AbstractQueuedLongSynchronizer.this);
+        }
 
         // Internal methods
 
diff -r 045743e0eb2d src/share/classes/java/util/concurrent/locks/AbstractQueuedSynchronizer.java
--- a/src/share/classes/java/util/concurrent/locks/AbstractQueuedSynchronizer.java    Thu Jun 04 11:28:03 2009 +0800
+++ b/src/share/classes/java/util/concurrent/locks/AbstractQueuedSynchronizer.java    Thu Jun 04 10:54:58 2009 +0300
@@ -1675,6 +1675,7 @@
          * attempt to set waitStatus fails, wake up to resync (in which
          * case the waitStatus can be transiently and harmlessly wrong).
          */
+        LockSupport.setBlocker(node.thread, this);
         Node p = enq(node);
         int ws = p.waitStatus;
         if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
@@ -1825,7 +1826,7 @@
      * <p>This class is Serializable, but all fields are transient,
      * so deserialized conditions have no waiters.
      */
-    public class ConditionObject implements Condition, java.io.Serializable {
+    public class ConditionObject extends AbstractOwnableSynchronizer implements Condition, java.io.Serializable {
         private static final long serialVersionUID = 1173984872572414699L;
         /** First node of condition queue. */
         private transient Node firstWaiter;
@@ -1835,7 +1836,9 @@
         /**
          * Creates a new <tt>ConditionObject</tt> instance.
          */
-        public ConditionObject() { }
+        public ConditionObject() {
+            super(AbstractQueuedSynchronizer.this);
+        }
 
         // Internal methods
 
diff -r 045743e0eb2d src/share/classes/java/util/concurrent/locks/LockSupport.java
--- a/src/share/classes/java/util/concurrent/locks/LockSupport.java    Thu Jun 04 11:28:03 2009 +0800
+++ b/src/share/classes/java/util/concurrent/locks/LockSupport.java    Thu Jun 04 10:54:58 2009 +0300
@@ -131,7 +131,7 @@
         } catch (Exception ex) { throw new Error(ex); }
     }
 
-    private static void setBlocker(Thread t, Object arg) {
+    static void setBlocker(Thread t, Object arg) {
         // Even though volatile, hotspot doesn't need a write barrier here.
         unsafe.putObject(t, parkBlockerOffset, arg);
     }


> Date: Thu, 4 Jun 2009 01:04:23 +1000
> From: David.Holmes at Sun.COM
> Subject: Re: Cant detect deadlock when thread reenters synchronization block in	Object.wait()
> To: dmytro_sheyko at hotmail.com
> CC: serviceability-dev at openjdk.java.net; hotspot-dev at openjdk.java.net; core-libs-dev at openjdk.java.net
> 
> Hi Dmytro,
> 
> Can you split this into two separate bug reports please. The changes to the 
> VM are quite separate from the changes to the java.util.concurrent classes. 
> The j.u.c changes should then be discussed on the concurrent-interest 
> mailing list:
> 
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> This will let all the JSR-166 EG members, and the genercal c-i community 
> evaluate what you have done.
> 
> At this stage I have not evaluated the actual proposals.
> 
> Thanks,
> David Holmes
> (j.u.c bug evaluator)
> 
> Dmytro Sheyko wrote:
> > Hi,
> > 
> > Could you have a look at following patch regarding deadlock detection:
> > 
> > Cant detect deadlock when thread reenters synchronization block in 
> > Object.wait()
> > https://bugs.openjdk.java.net/show_bug.cgi?id=100058
> > http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6841139
> > 
> > Thank you,
> > Dmytro Sheyko
> > 
> > ------------------------------------------------------------------------
> > See all the ways you can stay connected to friends and family 
> > <http://www.microsoft.com/windows/windowslive/default.aspx>

_________________________________________________________________
Invite your mail contacts to join your friends list with Windows Live Spaces. It's easy!
http://spaces.live.com/spacesapi.aspx?wx_action=create&wx_url=/friends.aspx&mkt=en-us
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090604/fc0f1a8e/attachment.html>

From daveclausen at gmail.com  Mon Jun  8 15:40:36 2009
From: daveclausen at gmail.com (Dave Clausen)
Date: Mon, 8 Jun 2009 15:40:36 -0400
Subject: [concurrency-interest] A question about
	ConcurrentLinkedQueue.remove()
In-Reply-To: <8d51e9a40906081047gd3c4832y96b3b414d2889f80@mail.gmail.com>
References: <8d51e9a40906081047gd3c4832y96b3b414d2889f80@mail.gmail.com>
Message-ID: <8d51e9a40906081240w4762091i9b591bf00acea353@mail.gmail.com>

FYI I filed a bug report with Sun a while back that basically covers
the same ground as this thread:

http://bugs.sun.com/view_bug.do?bug_id=6785442

There's not really any new information there.  I'm only mentioning it
so you can close out the ticket when you make the fix.  I apologize if
you've already got it covered.

Thanks,
Dave Clausen

On Fri, Feb 27, 2009 at 12:35 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> I agree that poll should be coded as:
>
> ? ?if (item != null && first.casItem(item, null)) {
> ? ? ? ?return item;
> ? ?}
>
> That's how I read "equivalently" in the spec.
>
> Note that this remove method is specified by Collection, and the two
> phrasings were equivalent before concurrent collections arrived on the
> scene. ?The object was either present *and* removed, or it wasn't, or there
> was a ConcurrentModificationException.
>
> The proposed implementation is also more testable. ?It should be the case
> that the number of items inserted is equal to the number of successful polls
> plus the number of successful removals.
>
> Joe
>
> On Fri, Feb 27, 2009 at 3:55 AM, Doug Lea wrote:
>
>> James Gan wrote:
>>
>>>
>>> Let's consider following scenario. Assume thread A is removing the element
>>> inside first node and thread B is popping, it seems to me that both of them
>>> can succeed.
>>>
>>
>> This is a byproduct of a spec decision that is worth
>> revisiting. The question is: What should be the return value
>> of remove when the item was present on entry but not on return
>> of the method? The spec is a little vague ...
>>
>> ?Returns true if this queue contained the specified element (or
>> ?equivalently, if this queue changed as a result of the call).
>>
>> ... especially since the "equivalently" clause is not exactly
>> equivalent under most people's interpretations! If the item was in
>> the process of being polled, then you might (and you did!) conclude
>> that the queue did not change as a result of the remove call but
>> of the poll. As David mentioned, your interpretation, which
>> is probably more common, could be ensured by using
>> casItem in poll. We probably ought to do this, and then strengthen
>> and clarify the spec/javadoc.
>>
>> While I'm at it: jsr166y.LinkedTransferQueue, which can be used as
>> a plain ConcurrentLinkedQueue, not only doesn't have this
>> issue, but also includes an internal node cleanup algorithm,
>> which prevents the accumulation of embedded cancelled/removed nodes,
>> so is always preferable if you do this a lot. In fact, for Java7.
>> there is no reason not to replace the internals of CLQ by delegating
>> to LTQ, so we will probably do this.
>>
>> -Doug
>


From martinrb at google.com  Mon Jun  8 17:01:19 2009
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 8 Jun 2009 14:01:19 -0700
Subject: [concurrency-interest] A question about
	ConcurrentLinkedQueue.remove()
In-Reply-To: <8d51e9a40906081240w4762091i9b591bf00acea353@mail.gmail.com>
References: <8d51e9a40906081047gd3c4832y96b3b414d2889f80@mail.gmail.com>
	<8d51e9a40906081240w4762091i9b591bf00acea353@mail.gmail.com>
Message-ID: <1ccfd1c10906081401o5103b3f4t7f2add874714d2e7@mail.gmail.com>

David Holmes:
Please re-categorize bug 6785442 to classes_util_concurrent
and mark the bug FIP - Doug and I are working on it.

Dave Clausen:
Thank you very much for filing this.
I hope a fix will be in OpenJDK7 within a month or so.

Martin


On Mon, Jun 8, 2009 at 12:40, Dave Clausen <daveclausen at gmail.com> wrote:

> FYI I filed a bug report with Sun a while back that basically covers
> the same ground as this thread:
>
> http://bugs.sun.com/view_bug.do?bug_id=6785442
>
> There's not really any new information there.  I'm only mentioning it
> so you can close out the ticket when you make the fix.  I apologize if
> you've already got it covered.
>
> Thanks,
> Dave Clausen
>
> On Fri, Feb 27, 2009 at 12:35 PM, Joe Bowbeer <joe.bowbeer at gmail.com>
> wrote:
> > I agree that poll should be coded as:
> >
> >    if (item != null && first.casItem(item, null)) {
> >        return item;
> >    }
> >
> > That's how I read "equivalently" in the spec.
> >
> > Note that this remove method is specified by Collection, and the two
> > phrasings were equivalent before concurrent collections arrived on the
> > scene.  The object was either present *and* removed, or it wasn't, or
> there
> > was a ConcurrentModificationException.
> >
> > The proposed implementation is also more testable.  It should be the case
> > that the number of items inserted is equal to the number of successful
> polls
> > plus the number of successful removals.
> >
> > Joe
> >
> > On Fri, Feb 27, 2009 at 3:55 AM, Doug Lea wrote:
> >
> >> James Gan wrote:
> >>
> >>>
> >>> Let's consider following scenario. Assume thread A is removing the
> element
> >>> inside first node and thread B is popping, it seems to me that both of
> them
> >>> can succeed.
> >>>
> >>
> >> This is a byproduct of a spec decision that is worth
> >> revisiting. The question is: What should be the return value
> >> of remove when the item was present on entry but not on return
> >> of the method? The spec is a little vague ...
> >>
> >>  Returns true if this queue contained the specified element (or
> >>  equivalently, if this queue changed as a result of the call).
> >>
> >> ... especially since the "equivalently" clause is not exactly
> >> equivalent under most people's interpretations! If the item was in
> >> the process of being polled, then you might (and you did!) conclude
> >> that the queue did not change as a result of the remove call but
> >> of the poll. As David mentioned, your interpretation, which
> >> is probably more common, could be ensured by using
> >> casItem in poll. We probably ought to do this, and then strengthen
> >> and clarify the spec/javadoc.
> >>
> >> While I'm at it: jsr166y.LinkedTransferQueue, which can be used as
> >> a plain ConcurrentLinkedQueue, not only doesn't have this
> >> issue, but also includes an internal node cleanup algorithm,
> >> which prevents the accumulation of embedded cancelled/removed nodes,
> >> so is always preferable if you do this a lot. In fact, for Java7.
> >> there is no reason not to replace the internals of CLQ by delegating
> >> to LTQ, so we will probably do this.
> >>
> >> -Doug
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090608/72e68a86/attachment.html>

From vishal.byakod at gmail.com  Wed Jun 10 12:00:34 2009
From: vishal.byakod at gmail.com (Vishal Byakod)
Date: Wed, 10 Jun 2009 21:30:34 +0530
Subject: [concurrency-interest] Concurrent Queue implementation
Message-ID: <ccb85ce20906100900g31c74fb1we252f3ccb4e294a6@mail.gmail.com>

Hi,
I am working on prototyping an embedded Message server and wanted to
know which queue implementation would suit the best.
The requirement is for a in-memory queue which will allow concurrent
puts and gets from the queue.

Any ideas and suggestions would be appreciated.

Thanks
Vishal

From joe.bowbeer at gmail.com  Wed Jun 10 12:29:20 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 10 Jun 2009 09:29:20 -0700
Subject: [concurrency-interest] Concurrent Queue implementation
In-Reply-To: <ccb85ce20906100900g31c74fb1we252f3ccb4e294a6@mail.gmail.com>
References: <ccb85ce20906100900g31c74fb1we252f3ccb4e294a6@mail.gmail.com>
Message-ID: <31f2a7bd0906100929s707a1fbfh53b0fec1b0c54f5a@mail.gmail.com>

On Wed, Jun 10, 2009 at 9:00 AM, Vishal Byakod wrote:

> Hi,
> I am working on prototyping an embedded Message server and wanted to
> know which queue implementation would suit the best.
> The requirement is for a in-memory queue which will allow concurrent
> puts and gets from the queue.
>
> Any ideas and suggestions would be appreciated.
>
> Thanks
> Vishal


Check out the BlockingQueue implementations, such as ArrayBlockingQueue and
LinkedBlockingQueue:

http://java.sun.com/javase/6/docs/api/java/util/concurrent/BlockingQueue.html

Note that take = get.

Joe
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090610/e5cc5806/attachment.html>

From takeshi10 at gmail.com  Wed Jun 10 12:57:26 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Wed, 10 Jun 2009 13:57:26 -0300
Subject: [concurrency-interest] Concurrent Queue implementation
In-Reply-To: <31f2a7bd0906100929s707a1fbfh53b0fec1b0c54f5a@mail.gmail.com>
References: <ccb85ce20906100900g31c74fb1we252f3ccb4e294a6@mail.gmail.com>
	<31f2a7bd0906100929s707a1fbfh53b0fec1b0c54f5a@mail.gmail.com>
Message-ID: <7288749d0906100957y746112bcn9fb067b5e098189b@mail.gmail.com>

theres also the ConcurrentLinkedQueue which is a lock-free unbounded
queue - although its 'poll' methods returns null in the absense of
elements

On Wed, Jun 10, 2009 at 1:29 PM, Joe Bowbeer<joe.bowbeer at gmail.com> wrote:
> On Wed, Jun 10, 2009 at 9:00 AM, Vishal Byakod wrote:
>>
>> Hi,
>> I am working on prototyping an embedded Message server and wanted to
>> know which queue implementation would suit the best.
>> The requirement is for a in-memory queue which will allow concurrent
>> puts and gets from the queue.
>>
>> Any ideas and suggestions would be appreciated.
>>
>> Thanks
>> Vishal
>
> Check out the BlockingQueue implementations, such as ArrayBlockingQueue and
> LinkedBlockingQueue:
>
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/BlockingQueue.html
>
> Note that take = get.
>
> Joe
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>



-- 
http://mapsdev.blogspot.com/
Marcelo Takeshi Fukushima

From jorge.ortiz at gmail.com  Thu Jun 11 02:15:44 2009
From: jorge.ortiz at gmail.com (Jorge Ortiz)
Date: Wed, 10 Jun 2009 23:15:44 -0700
Subject: [concurrency-interest] Consistency guarantees for ConcurrentHashMap
Message-ID: <22a410d00906102315x4d8ce638jc5b7ed5103bcda10@mail.gmail.com>

Consider the following code:

    ConcurrentHashMap<String, Boolean> map = new ...;

    Thread a = new Thread {
        void run() {
            map.put("first", true);
            map.put("second", true);
        }
    };

    Thread b = new Thread {
        void run() {
            map.clear();
        }
    };

    a.start();
    b.start();
    a.join();
    b.join();

I would expect that one of the following scenarios to be true (for the
contents of the map) after this code runs:

    Map("first" -> true, "second" -> true)
    Map("second" -> true)
    Map()

However, upon inspection of ConcurrentHashMap, it seems to me that the
following scenario might also be true:

    Map("first" -> true) ???

This seems surprising because "first" gets put before "second", so if
"second" is cleared, then surely "first" should be cleared too.

Likewise, consider the following code:

    ConcurrentHashMap<String, Boolean> map = new ...;
    List<String> myKeys = new ...;

    Thread a = new Thread {
        void run() {
            map.put("first", true);

            // more stuff

            map.remove("first");
            map.put("second", true);
        }
    };

    Thread b = new Thread {
        void run() {
            Set<String> keys = map.keySet();
            for (String key : keys) {
                myKeys.add(key);
            }
        }
    };

    a.start();
    b.start();
    a.join();
    b.join();

I would expect one of the following scenarios to be true for the contents of
myKeys after this code has run:

    List()
    List("first")
    List("second")

However, upon closer inspection, it seems that the following scenario might
also be true:

    List("first", "second") ???

This is surprising because "second" is only ever put into the map after
"first" is removed. They should never be in the map simultaneously, but an
iterator might perceive them to be so.

Are these interpretations of ConcurrentHashMap's behavior correct?

I ask because I want to add concurrent collections to Scala's standard
library. Ideally, these could just be wrappers around concurrent Java
collections because 1) it saves me a lot of work and 2) it benefits from the
significant effort (and thought and real-world testing) that have gone into
j.u.concurrent.

However, central to Scala's collections are higher-order functions like
"map" and "filter" that operate on an entire collection and return a new
collection with elements derived from the elements in the old collections.
These methods necessarily operate on an entire collection and are frequently
implemented in terms of iterators. Without strongly consistent iterators or
some other way to provide a consistent "snapshot" of ConcurrentHashMap,
"map" and "filter" are... well, pretty useless.

If my interpretation of ConcurrentHashMap is correct, are there are other
concurrent collections that provide such a "snapshot" view?

Could ConcurrentHashMap be wrapped with a ReadWriteLock, where
single-element operations (get, put, etc) acquire the read lock and
whole-collections operations (map, filter, clear, etc) acquire the write
lock? How badly would this hurt performance in the no-writers case?

Thanks,

--j
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090610/19911177/attachment.html>

From jorge.ortiz at gmail.com  Thu Jun 11 13:55:13 2009
From: jorge.ortiz at gmail.com (Jorge Ortiz)
Date: Thu, 11 Jun 2009 10:55:13 -0700
Subject: [concurrency-interest] Consistency guarantees for
	ConcurrentHashMap
In-Reply-To: <e0563fd80906110221j59bdd521q9b72f793f2215d7d@mail.gmail.com>
References: <22a410d00906102315x4d8ce638jc5b7ed5103bcda10@mail.gmail.com>
	<e0563fd80906110221j59bdd521q9b72f793f2215d7d@mail.gmail.com>
Message-ID: <22a410d00906111055h6882115cn46360b3121392719@mail.gmail.com>

Jim, Erkin, James,

I haven't written any code to test these behaviors. This is all purely a
thought experiment at this point. Perhaps I should provide more details.

For the first case, given the implementation of clear():

    public void clear() {
        for (int i = 0; i < segments.length; ++i)
            segments[i].clear();
    }

It's evident that this behavior is at best atomic per segment. There seem to
be no atomicity guarantees between segments. (I understand this is by
design.) Assume Thread B runs first, gets halfway through clear() (clears
half the segments), then suspends. Now Thread A runs, puts "first" in an
already-cleared segment and "second" in a yet-to-be-cleared segment.
Finally, Thread B resumes and clears the remaining segments, including the
one with "second" (but not the one with "first", as that segment had already
been cleared).

The second case, with iterators, follows similarly. Thread A puts "first".
Thread B creates an iterator, and upon creation the iterator's nextEntry is
set to "first". Thread A removes "first", puts "second". Thread B calls
next() on the iterator, receives "first" (because entries are immutable, and
the iterator already has a pointer to "first"'s entry), the iterator's
nextEntry is set to "second", calls next() again, receives "second".

Again, if my understanding is incorrect, please let me know.

Jim,

Thanks for the article on ReadWriteLocks. This information means they're
pretty unsuitable for the purpose I intended, especially since Scala still
needs to support Java 1.5.

I could write map, filter, etc based on weakly consistent iterators, but
weak consistency seems to be not much of a guarantee at all. In particular,
if my understanding of the second scenario I gave is correct, a weakly
consistent iterator can report the map to be in a state that it was never
actually in.

It's worth noting that my understanding of iterator's behavior is not
inconsistent with the explanation given in the Javadocs for keySet(),
values(), and entrySet():

"The view's iterator is a "weakly consistent" iterator that will never throw
ConcurrentModificationException, and guarantees to traverse elements as they
existed upon construction of the iterator, and may (but is not guaranteed
to) reflect any modifications subsequent to construction."

Notably, the iterator "may" reflect modification put("second"), but "won't
guarantee" that modification remove("first") (which happens-before
put("second"), but after the creation of the iterator) will also be
reflected.

I contrast, the Javadoc explanation for the entire ConcurrentHashMap class
is inaccurate, in my opinion:

"Similarly, Iterators and Enumerations return elements reflecting the state
of the hash table at some point at or since the creation of the
iterator/enumeration."

Thanks,

--j

On Thu, Jun 11, 2009 at 2:21 AM, Erkin <erkin.kanlioglu at googlemail.com>wrote:

> Hi Jorge
>
> Case 1) Map doesn't guarantee the order as it calculates hash and put data
> into appropriate segment. Clear method on the other hand works sequentially
> on segments and locks are on per segments. Please correct if I'm wrong.
>
> Case 2) Is it possible to post a test-code with jdk version to prove the
> case?
>
> Thanks
>
> On Thu, Jun 11, 2009 at 7:15 AM, Jorge Ortiz <jorge.ortiz at gmail.com>wrote:
>
>> Consider the following code:
>>
>>     ConcurrentHashMap<String, Boolean> map = new ...;
>>
>>     Thread a = new Thread {
>>         void run() {
>>             map.put("first", true);
>>             map.put("second", true);
>>         }
>>     };
>>
>>     Thread b = new Thread {
>>         void run() {
>>             map.clear();
>>         }
>>     };
>>
>>     a.start();
>>     b.start();
>>     a.join();
>>     b.join();
>>
>> I would expect that one of the following scenarios to be true (for the
>> contents of the map) after this code runs:
>>
>>     Map("first" -> true, "second" -> true)
>>     Map("second" -> true)
>>     Map()
>>
>> However, upon inspection of ConcurrentHashMap, it seems to me that the
>> following scenario might also be true:
>>
>>     Map("first" -> true) ???
>>
>> This seems surprising because "first" gets put before "second", so if
>> "second" is cleared, then surely "first" should be cleared too.
>>
>> Likewise, consider the following code:
>>
>>     ConcurrentHashMap<String, Boolean> map = new ...;
>>     List<String> myKeys = new ...;
>>
>>     Thread a = new Thread {
>>         void run() {
>>             map.put("first", true);
>>
>>             // more stuff
>>
>>             map.remove("first");
>>             map.put("second", true);
>>         }
>>     };
>>
>>     Thread b = new Thread {
>>         void run() {
>>             Set<String> keys = map.keySet();
>>             for (String key : keys) {
>>                 myKeys.add(key);
>>             }
>>         }
>>     };
>>
>>     a.start();
>>     b.start();
>>     a.join();
>>     b.join();
>>
>> I would expect one of the following scenarios to be true for the contents
>> of myKeys after this code has run:
>>
>>     List()
>>     List("first")
>>     List("second")
>>
>> However, upon closer inspection, it seems that the following scenario
>> might also be true:
>>
>>     List("first", "second") ???
>>
>> This is surprising because "second" is only ever put into the map after
>> "first" is removed. They should never be in the map simultaneously, but an
>> iterator might perceive them to be so.
>>
>> Are these interpretations of ConcurrentHashMap's behavior correct?
>>
>> I ask because I want to add concurrent collections to Scala's standard
>> library. Ideally, these could just be wrappers around concurrent Java
>> collections because 1) it saves me a lot of work and 2) it benefits from the
>> significant effort (and thought and real-world testing) that have gone into
>> j.u.concurrent.
>>
>> However, central to Scala's collections are higher-order functions like
>> "map" and "filter" that operate on an entire collection and return a new
>> collection with elements derived from the elements in the old collections.
>> These methods necessarily operate on an entire collection and are frequently
>> implemented in terms of iterators. Without strongly consistent iterators or
>> some other way to provide a consistent "snapshot" of ConcurrentHashMap,
>> "map" and "filter" are... well, pretty useless.
>>
>> If my interpretation of ConcurrentHashMap is correct, are there are other
>> concurrent collections that provide such a "snapshot" view?
>>
>> Could ConcurrentHashMap be wrapped with a ReadWriteLock, where
>> single-element operations (get, put, etc) acquire the read lock and
>> whole-collections operations (map, filter, clear, etc) acquire the write
>> lock? How badly would this hurt performance in the no-writers case?
>>
>> Thanks,
>>
>> --j
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090611/d6813d61/attachment.html>

From dl at cs.oswego.edu  Thu Jun 11 14:25:49 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 11 Jun 2009 14:25:49 -0400
Subject: [concurrency-interest] Consistency guarantees
	for	ConcurrentHashMap
In-Reply-To: <22a410d00906111055h6882115cn46360b3121392719@mail.gmail.com>
References: <22a410d00906102315x4d8ce638jc5b7ed5103bcda10@mail.gmail.com>	<e0563fd80906110221j59bdd521q9b72f793f2215d7d@mail.gmail.com>
	<22a410d00906111055h6882115cn46360b3121392719@mail.gmail.com>
Message-ID: <4A314C2D.7030203@cs.oswego.edu>

Jorge Ortiz wrote:
> Jim, Erkin, James,
> 
> I haven't written any code to test these behaviors. This is all purely a 
> thought experiment at this point. Perhaps I should provide more details.
> 
> For the first case, given the implementation of clear():
> 
>     public void clear() {
>         for (int i = 0; i < segments.length; ++i)
>             segments[i].clear();
>     }
> 
> It's evident that this behavior is at best atomic per segment. There 
> seem to be no atomicity guarantees between segments. (I understand this 
> is by design.) 

Yes, by design. If you require a global total write ordering
than you give up concurrency on writes, in which case
you might as well use a SynchronizedMap(new HashMap()).
You could alternatively use ReadWriteLocks but they have enough
overhead to make use with a HashMap questionable.
And perhaps someday there may be an efficient optimistic
linearizable hash algorithm for bulk operations based on
transactional memory.

> 
> I could write map, filter, etc based on weakly consistent iterators, but 
> weak consistency seems to be not much of a guarantee at all. 

We leave the tradeoff of consistency-strength versus scalability
as a user decision, so offer both synchronized and concurrent versions
of most collections, as discussed in the j.u.c package docs
http://java.sun.com/javase/6/docs/api/java/util/concurrent/package-summary.html

> 
> I contrast, the Javadoc explanation for the entire ConcurrentHashMap 
> class is inaccurate, in my opinion:
> 
> "Similarly, Iterators and Enumerations return elements reflecting the 
> state of the hash table at some point at or since the creation of the 
> iterator/enumeration."
> 

Thanks! That sentence should be changed to be the same as the
other descriptions of weakly consistent iterators.

-Doug

From cleber at nightcoders.com.br  Thu Jun 11 16:05:11 2009
From: cleber at nightcoders.com.br (Cleber Muramoto)
Date: Thu, 11 Jun 2009 17:05:11 -0300
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 53,
	Issue 5
In-Reply-To: <mailman.1.1244736001.26808.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1244736001.26808.concurrency-interest@cs.oswego.edu>
Message-ID: <668a9da40906111305n52b83387qa052c8a2a33545de@mail.gmail.com>

>
>
> I would expect that one of the following scenarios to be true (for the
> contents of the map) after this code runs:
>
>    Map("first" -> true, "second" -> true)
>    Map("second" -> true)
>    Map()
>
> However, upon inspection of ConcurrentHashMap, it seems to me that the
> following scenario might also be true:
>
>    Map("first" -> true) ???
>
> This seems surprising because "first" gets put before "second", so if
> "second" is cleared, then surely "first" should be cleared too.
>
>
I think this may happen because clear acquires the locks individually, so it
might
first acquire the lock for the segment that would hold "first" before
"first" is put and the lock
for "second" after second is "put".



> If my interpretation of ConcurrentHashMap is correct, are there are other
> concurrent collections that provide such a "snapshot" view?
>
> Could ConcurrentHashMap be wrapped with a ReadWriteLock, where
> single-element operations (get, put, etc) acquire the read lock and
> whole-collections operations (map, filter, clear, etc) acquire the write
> lock? How badly would this hurt performance in the no-writers case?


Cliff's Click nonBlockingHashMap provides snapshot views.

Also, according to the doc it is "fully interoperable with
Hashtable", so you should either view Map() or Map("second" -> true).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090611/b9cfd113/attachment.html>

From normelton at gmail.com  Sun Jun 14 12:37:13 2009
From: normelton at gmail.com (Norman Elton)
Date: Sun, 14 Jun 2009 12:37:13 -0400
Subject: [concurrency-interest] Concurrency Architecture
Message-ID: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>

I've been using the java.util.concurrent classes over the past few
years, they've worked well for every circumstance I could throw at
them. Today, I've stumbled upon a case that I just can't figure out
how best to tackle.

I've got a connection generator which builds and returns connections
to a server. In case of failover, I'm maintaining a list of possible
servers to which it can generate connections. My wrapper
getConnection() method takes this into account by first attempting a
connection to the "current" server. If that times out, it scans the
list for a new "current" server.

Here's some pseudocode:

public Connection getConnection() {
	try {
		return this.generator.getConnection();
	} catch (TimeoutException e) {
	}
	
	synchronized(this.generator) {
		foreach (this.servers as curr_server) {
			try {
				this.generator.server = curr_server;
				return this.generator.getConnection();
			} catch (TimeoutException e) {
			}
		}
	}
	
	throw new Exception("Sorry, couldn't find a server");
}

In this case, if three threads simultaneously call getConnection(),
they will all timeout and hit the synchronized block together. The
first one will identify a new server, but the other two have no way to
know that a new server has been identified. They each will loop
through the possible servers.

I'm looking for some way for all threads to be able to call the first
part of the procedure (attempt a connection to the current server). If
that fails, then the first thread will attempt to find a new server,
while others wait for the result.

I've dug through all the possible types of locks, nothing quite meets
the need. Of course, I could be wrong! Can anyone think of a good way
to tackle these requirements?

Thanks!

Norman

From carfield at carfield.com.hk  Sun Jun 14 12:58:42 2009
From: carfield at carfield.com.hk (Carfield Yim)
Date: Mon, 15 Jun 2009 00:58:42 +0800
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
Message-ID: <b4503c170906140958y3fdf0fb2w689ec444211db287@mail.gmail.com>

Can we do that with
http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/Semaphore.html??
The first thread hold the semaphore and the other wait for the result

On Mon, Jun 15, 2009 at 12:37 AM, Norman Elton <normelton at gmail.com> wrote:

> I've been using the java.util.concurrent classes over the past few
> years, they've worked well for every circumstance I could throw at
> them. Today, I've stumbled upon a case that I just can't figure out
> how best to tackle.
>
> I've got a connection generator which builds and returns connections
> to a server. In case of failover, I'm maintaining a list of possible
> servers to which it can generate connections. My wrapper
> getConnection() method takes this into account by first attempting a
> connection to the "current" server. If that times out, it scans the
> list for a new "current" server.
>
> Here's some pseudocode:
>
> public Connection getConnection() {
>        try {
>                return this.generator.getConnection();
>        } catch (TimeoutException e) {
>        }
>
>        synchronized(this.generator) {
>                foreach (this.servers as curr_server) {
>                        try {
>                                this.generator.server = curr_server;
>                                return this.generator.getConnection();
>                        } catch (TimeoutException e) {
>                        }
>                }
>        }
>
>        throw new Exception("Sorry, couldn't find a server");
> }
>
> In this case, if three threads simultaneously call getConnection(),
> they will all timeout and hit the synchronized block together. The
> first one will identify a new server, but the other two have no way to
> know that a new server has been identified. They each will loop
> through the possible servers.
>
> I'm looking for some way for all threads to be able to call the first
> part of the procedure (attempt a connection to the current server). If
> that fails, then the first thread will attempt to find a new server,
> while others wait for the result.
>
> I've dug through all the possible types of locks, nothing quite meets
> the need. Of course, I could be wrong! Can anyone think of a good way
> to tackle these requirements?
>
> Thanks!
>
> Norman
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/8e8e4c30/attachment.html>

From normelton at gmail.com  Sun Jun 14 13:02:41 2009
From: normelton at gmail.com (Norman Elton)
Date: Sun, 14 Jun 2009 13:02:41 -0400
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <b4503c170906140958y3fdf0fb2w689ec444211db287@mail.gmail.com>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
	<b4503c170906140958y3fdf0fb2w689ec444211db287@mail.gmail.com>
Message-ID: <6b3a7f010906141002p433b3f54j44da2f04cf7f37c8@mail.gmail.com>

Let's say one thread already holds the semaphore. That one is off
looking for a new server. If a new thread comes along, he would
normally block until the semaphore is available. Once it's available,
he would go ahead and look for a new server. In my situation, that
second server needs to realize that another thread has already taken
care of the dirty work.

I'm looking at tryAcquire, since it seems that it will behave
differently if someone else already has the semaphore. That might lead
somewhere!

Norman

On Sun, Jun 14, 2009 at 12:58 PM, Carfield Yim<carfield at carfield.com.hk> wrote:
> Can we do that with
> http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/Semaphore.html
> ?? The first thread hold the semaphore and the other wait for the result

From normelton at gmail.com  Sun Jun 14 13:02:15 2009
From: normelton at gmail.com (Norman Elton)
Date: Sun, 14 Jun 2009 13:02:15 -0400
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <b4503c170906140958y3fdf0fb2w689ec444211db287@mail.gmail.com>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
	<b4503c170906140958y3fdf0fb2w689ec444211db287@mail.gmail.com>
Message-ID: <6b3a7f010906141002t6e8facc3ybe49c116193def0c@mail.gmail.com>

Let's say one thread already holds the semaphore. That one is off
looking for a new server. If a new thread comes along, he would
normally block until the semaphore is available. Once it's available,
he would go ahead and look for a new server. In my situation, that
second server needs to realize that another thread has already taken
care of the dirty work.

I'm looking at tryAcquire, since it seems that it will behave
differently if someone else already has the semaphore. That might lead
somewhere!

Norman



On Sun, Jun 14, 2009 at 12:58 PM, Carfield Yim<carfield at carfield.com.hk> wrote:
> Can we do that with
> http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/Semaphore.html
> ?? The first thread hold the semaphore and the other wait for the result

From bronee at gmail.com  Sun Jun 14 13:10:05 2009
From: bronee at gmail.com (Brian S O'Neill)
Date: Sun, 14 Jun 2009 10:10:05 -0700
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
Message-ID: <4A352EED.8060605@gmail.com>

There's many ways to do this, but a simple solution that works with your 
current design is to include an atomic "generation" counter. The first 
thing getConnection does is copy the counter value, from a shared 
AtomicInteger, to a local variable. When you synchronize on 
this.generator, check the counter value again. If it is the same, then 
the current thread is the "leader" and is responsible for selecting a 
new server. It increments the AtomicInteger when it is done. Other 
threads will see that the value has changed, and they just use the new 
server instead of selecting one.

Norman Elton wrote:
> I've been using the java.util.concurrent classes over the past few
> years, they've worked well for every circumstance I could throw at
> them. Today, I've stumbled upon a case that I just can't figure out
> how best to tackle.
>
> I've got a connection generator which builds and returns connections
> to a server. In case of failover, I'm maintaining a list of possible
> servers to which it can generate connections. My wrapper
> getConnection() method takes this into account by first attempting a
> connection to the "current" server. If that times out, it scans the
> list for a new "current" server.
>
> Here's some pseudocode:
>
> public Connection getConnection() {
> 	try {
> 		return this.generator.getConnection();
> 	} catch (TimeoutException e) {
> 	}
> 	
> 	synchronized(this.generator) {
> 		foreach (this.servers as curr_server) {
> 			try {
> 				this.generator.server = curr_server;
> 				return this.generator.getConnection();
> 			} catch (TimeoutException e) {
> 			}
> 		}
> 	}
> 	
> 	throw new Exception("Sorry, couldn't find a server");
> }
>
> In this case, if three threads simultaneously call getConnection(),
> they will all timeout and hit the synchronized block together. The
> first one will identify a new server, but the other two have no way to
> know that a new server has been identified. They each will loop
> through the possible servers.
>
> I'm looking for some way for all threads to be able to call the first
> part of the procedure (attempt a connection to the current server). If
> that fails, then the first thread will attempt to find a new server,
> while others wait for the result.
>
> I've dug through all the possible types of locks, nothing quite meets
> the need. Of course, I could be wrong! Can anyone think of a good way
> to tackle these requirements?
>
> Thanks!
>
> Norman
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>   

From davidcholmes at aapt.net.au  Sun Jun 14 17:37:08 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 15 Jun 2009 07:37:08 +1000
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEELICAA.davidcholmes@aapt.net.au>

Norman,

There are many many ways to set this up. It could be as simple as checking
if the current server has changed after a timeout - if so then someone did
the change; if not then search for a new server yourself. It all depends on
the exact semantics you want - eg whether the new server has to be known to
be good before anyone else starts using it; and how long a "down" server is
excluded from being used etc. A CountDownLatch used as a simple gate can be
used to make other threads wait while a search is in progress, if you don't
want to use the lock directly for this purposes. (Using a Semaphore seems
tricky because you don't know how many threads may be waiting.)

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Norman
> Elton
> Sent: Monday, 15 June 2009 2:37 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Concurrency Architecture
>
>
>
> I've been using the java.util.concurrent classes over the past few
> years, they've worked well for every circumstance I could throw at
> them. Today, I've stumbled upon a case that I just can't figure out
> how best to tackle.
>
> I've got a connection generator which builds and returns connections
> to a server. In case of failover, I'm maintaining a list of possible
> servers to which it can generate connections. My wrapper
> getConnection() method takes this into account by first attempting a
> connection to the "current" server. If that times out, it scans the
> list for a new "current" server.
>
> Here's some pseudocode:
>
> public Connection getConnection() {
> 	try {
> 		return this.generator.getConnection();
> 	} catch (TimeoutException e) {
> 	}
>
> 	synchronized(this.generator) {
> 		foreach (this.servers as curr_server) {
> 			try {
> 				this.generator.server = curr_server;
> 				return this.generator.getConnection();
> 			} catch (TimeoutException e) {
> 			}
> 		}
> 	}
>
> 	throw new Exception("Sorry, couldn't find a server");
> }
>
> In this case, if three threads simultaneously call getConnection(),
> they will all timeout and hit the synchronized block together. The
> first one will identify a new server, but the other two have no way to
> know that a new server has been identified. They each will loop
> through the possible servers.
>
> I'm looking for some way for all threads to be able to call the first
> part of the procedure (attempt a connection to the current server). If
> that fails, then the first thread will attempt to find a new server,
> while others wait for the result.
>
> I've dug through all the possible types of locks, nothing quite meets
> the need. Of course, I could be wrong! Can anyone think of a good way
> to tackle these requirements?
>
> Thanks!
>
> Norman
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From normelton at gmail.com  Sun Jun 14 23:59:04 2009
From: normelton at gmail.com (Norman Elton)
Date: Sun, 14 Jun 2009 23:59:04 -0400
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEELICAA.davidcholmes@aapt.net.au>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEELICAA.davidcholmes@aapt.net.au>
Message-ID: <6b3a7f010906142059p3aeb1aedjeded9cd403721029@mail.gmail.com>

Thanks all for the responses. I was trying to grapple how a
ReentrantReadWriteLock would solve my problem, completely skipping
over the more simple approaches. Brian's idea of an atomic "generation
identifier" seems to be working like a champ.

Norman

On Sun, Jun 14, 2009 at 5:37 PM, David Holmes<davidcholmes at aapt.net.au> wrote:
> Norman,
>
> There are many many ways to set this up. It could be as simple as checking
> if the current server has changed after a timeout - if so then someone did
> the change; if not then search for a new server yourself. It all depends on
> the exact semantics you want - eg whether the new server has to be known to
> be good before anyone else starts using it; and how long a "down" server is
> excluded from being used etc. A CountDownLatch used as a simple gate can be
> used to make other threads wait while a search is in progress, if you don't
> want to use the lock directly for this purposes. (Using a Semaphore seems
> tricky because you don't know how many threads may be waiting.)
>
> David Holmes
>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Norman
>> Elton
>> Sent: Monday, 15 June 2009 2:37 AM
>> To: concurrency-interest at cs.oswego.edu
>> Subject: [concurrency-interest] Concurrency Architecture
>>
>>
>>
>> I've been using the java.util.concurrent classes over the past few
>> years, they've worked well for every circumstance I could throw at
>> them. Today, I've stumbled upon a case that I just can't figure out
>> how best to tackle.
>>
>> I've got a connection generator which builds and returns connections
>> to a server. In case of failover, I'm maintaining a list of possible
>> servers to which it can generate connections. My wrapper
>> getConnection() method takes this into account by first attempting a
>> connection to the "current" server. If that times out, it scans the
>> list for a new "current" server.
>>
>> Here's some pseudocode:
>>
>> public Connection getConnection() {
>> ? ? ? try {
>> ? ? ? ? ? ? ? return this.generator.getConnection();
>> ? ? ? } catch (TimeoutException e) {
>> ? ? ? }
>>
>> ? ? ? synchronized(this.generator) {
>> ? ? ? ? ? ? ? foreach (this.servers as curr_server) {
>> ? ? ? ? ? ? ? ? ? ? ? try {
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this.generator.server = curr_server;
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? return this.generator.getConnection();
>> ? ? ? ? ? ? ? ? ? ? ? } catch (TimeoutException e) {
>> ? ? ? ? ? ? ? ? ? ? ? }
>> ? ? ? ? ? ? ? }
>> ? ? ? }
>>
>> ? ? ? throw new Exception("Sorry, couldn't find a server");
>> }
>>
>> In this case, if three threads simultaneously call getConnection(),
>> they will all timeout and hit the synchronized block together. The
>> first one will identify a new server, but the other two have no way to
>> know that a new server has been identified. They each will loop
>> through the possible servers.
>>
>> I'm looking for some way for all threads to be able to call the first
>> part of the procedure (attempt a connection to the current server). If
>> that fails, then the first thread will attempt to find a new server,
>> while others wait for the result.
>>
>> I've dug through all the possible types of locks, nothing quite meets
>> the need. Of course, I could be wrong! Can anyone think of a good way
>> to tackle these requirements?
>>
>> Thanks!
>>
>> Norman
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>


From thejo at kote.in  Mon Jun 15 04:56:17 2009
From: thejo at kote.in (Thejo Kote)
Date: Mon, 15 Jun 2009 14:26:17 +0530
Subject: [concurrency-interest] Implementation of a global configuration
	cache
Message-ID: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>

Hi,

I'm trying to improve the design of a global configuration cache which
currently consists of public static variables in a class. Something like -

public final class ConfigCache {

    public static String val1;
    public static Map<Integer, MyObj> val2;

    public static initializeCache() {
        val1 = ....;
    }

}

I use the config values in other parts of the applications as
ConfigCache.val1 etc. The task performed by the application is highly
parallelizable and many threads read the configuration values. Some config
values don't change after initialization at start up and some (like val2)
are periodically (every 15 minutes) read from a database and updated in the
cache from a separate thread. I take advantage of the fact that writes to
and reads of references are always atomic when updating cache values in run
time.

With that background -

- Are the visibility characteristics of static and non-static variables the
same? Is it just sheer luck that the reading threads pick up the last
updated reference, and should they be declared as volatile?
- I'm ensuring that no references escape by initializing the cache before
the application accepts requests, but using public static fields is not
ideal and does not provide the required encapsulation. Is there a standard
pattern for implementing such a configuration cache where many threads
constantly read values with an occasional write. Is a singleton object with
proper use of read write locks on the values that keep changing the right
solution?

Thanks,
Thejo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/7360cc65/attachment.html>

From alarmnummer at gmail.com  Mon Jun 15 05:08:09 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Mon, 15 Jun 2009 11:08:09 +0200
Subject: [concurrency-interest] Implementation of a global configuration
	cache
In-Reply-To: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
References: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
Message-ID: <1466c1d60906150208g57a2d426x286a7d050a2e18f6@mail.gmail.com>

Hi Thejo,

would a COTS (common of the shelf) cache not be easier to use? It
saves you a lot of time compared to writing one yourself.

e.g.

ehcache.

On Mon, Jun 15, 2009 at 10:56 AM, Thejo Kote<thejo at kote.in> wrote:
> Hi,
>
> I'm trying to improve the design of a global configuration cache which
> currently consists of public static variables in a class. Something like -
>
> public final class ConfigCache {
>
> ??? public static String val1;
> ??? public static Map<Integer, MyObj> val2;
>
> ??? public static initializeCache() {
> ??????? val1 = ....;
> ??? }
>
> }
>
> I use the config values in other parts of the applications as
> ConfigCache.val1 etc. The task performed by the application is highly
> parallelizable and many threads read the configuration values. Some config
> values don't change after initialization at start up and some (like val2)
> are periodically (every 15 minutes) read from a database and updated in the
> cache from a separate thread. I take advantage of the fact that writes to
> and reads of references are always atomic when updating cache values in run
> time.
>
> With that background -
>
> - Are the visibility characteristics of static and non-static variables the
> same? Is it just sheer luck that the reading threads pick up the last
> updated reference, and should they be declared as volatile?
> - I'm ensuring that no references escape by initializing the cache before
> the application accepts requests, but using public static fields is not
> ideal and does not provide the required encapsulation. Is there a standard
> pattern for implementing such a configuration cache where many threads
> constantly read values with an occasional write. Is a singleton object with
> proper use of read write locks on the values that keep changing the right
> solution?
>
> Thanks,
> Thejo
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From thejo at kote.in  Mon Jun 15 05:21:31 2009
From: thejo at kote.in (Thejo Kote)
Date: Mon, 15 Jun 2009 14:51:31 +0530
Subject: [concurrency-interest] Implementation of a global configuration
	cache
In-Reply-To: <1466c1d60906150208g57a2d426x286a7d050a2e18f6@mail.gmail.com>
References: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
	<1466c1d60906150208g57a2d426x286a7d050a2e18f6@mail.gmail.com>
Message-ID: <3a5ad2140906150221q6f81a97eq94011f93a06cedb@mail.gmail.com>

Hi Peter,

Off the shelf caches like ehcache and JCS are definitely an option I want to
look into. Since I want to cache only around 10 items, two of which keep
changing, I wanted to know if there is a way to achieve it without using a
full fledged off the shelf cache. I also hope to learn more about the common
design approaches and concurrency issues involved in implementing such a
cache. If the effort is too much, I will use something that is already
available and not succumb to NIH :)

Thejo

On Mon, Jun 15, 2009 at 2:38 PM, Peter Veentjer <alarmnummer at gmail.com>wrote:

> Hi Thejo,
>
> would a COTS (common of the shelf) cache not be easier to use? It
> saves you a lot of time compared to writing one yourself.
>
> e.g.
>
> ehcache.
>
> On Mon, Jun 15, 2009 at 10:56 AM, Thejo Kote<thejo at kote.in> wrote:
> > Hi,
> >
> > I'm trying to improve the design of a global configuration cache which
> > currently consists of public static variables in a class. Something like
> -
> >
> > public final class ConfigCache {
> >
> >     public static String val1;
> >     public static Map<Integer, MyObj> val2;
> >
> >     public static initializeCache() {
> >         val1 = ....;
> >     }
> >
> > }
> >
> > I use the config values in other parts of the applications as
> > ConfigCache.val1 etc. The task performed by the application is highly
> > parallelizable and many threads read the configuration values. Some
> config
> > values don't change after initialization at start up and some (like val2)
> > are periodically (every 15 minutes) read from a database and updated in
> the
> > cache from a separate thread. I take advantage of the fact that writes to
> > and reads of references are always atomic when updating cache values in
> run
> > time.
> >
> > With that background -
> >
> > - Are the visibility characteristics of static and non-static variables
> the
> > same? Is it just sheer luck that the reading threads pick up the last
> > updated reference, and should they be declared as volatile?
> > - I'm ensuring that no references escape by initializing the cache before
> > the application accepts requests, but using public static fields is not
> > ideal and does not provide the required encapsulation. Is there a
> standard
> > pattern for implementing such a configuration cache where many threads
> > constantly read values with an occasional write. Is a singleton object
> with
> > proper use of read write locks on the values that keep changing the right
> > solution?
> >
> > Thanks,
> > Thejo
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/434bb3d0/attachment.html>

From davidcholmes at aapt.net.au  Mon Jun 15 06:52:57 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 15 Jun 2009 20:52:57 +1000
Subject: [concurrency-interest] Implementation of a global
	configurationcache
In-Reply-To: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEEOICAA.davidcholmes@aapt.net.au>

With regards to your visibility concerns either:

- static variables must be statically initialized; or else
- the cache must be initialized before any of the threads that use it are
started and there must be a happens-before relationship between the cache
initialization and the thread start; or else
- the variables must be volatile

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Thejo Kote
  Sent: Monday, 15 June 2009 6:56 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Implementation of a global
configurationcache


  Hi,

  I'm trying to improve the design of a global configuration cache which
currently consists of public static variables in a class. Something like -

  public final class ConfigCache {

      public static String val1;
      public static Map<Integer, MyObj> val2;

      public static initializeCache() {
          val1 = ....;
      }

  }

  I use the config values in other parts of the applications as
ConfigCache.val1 etc. The task performed by the application is highly
parallelizable and many threads read the configuration values. Some config
values don't change after initialization at start up and some (like val2)
are periodically (every 15 minutes) read from a database and updated in the
cache from a separate thread. I take advantage of the fact that writes to
and reads of references are always atomic when updating cache values in run
time.

  With that background -

  - Are the visibility characteristics of static and non-static variables
the same? Is it just sheer luck that the reading threads pick up the last
updated reference, and should they be declared as volatile?
  - I'm ensuring that no references escape by initializing the cache before
the application accepts requests, but using public static fields is not
ideal and does not provide the required encapsulation. Is there a standard
pattern for implementing such a configuration cache where many threads
constantly read values with an occasional write. Is a singleton object with
proper use of read write locks on the values that keep changing the right
solution?

  Thanks,
  Thejo

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/21dca837/attachment.html>

From w.hongjiang at gmail.com  Mon Jun 15 07:37:50 2009
From: w.hongjiang at gmail.com (wang hongjiang)
Date: Mon, 15 Jun 2009 19:37:50 +0800
Subject: [concurrency-interest] Implementation of a global
	configurationcache
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEEOICAA.davidcholmes@aapt.net.au>
References: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEEOICAA.davidcholmes@aapt.net.au>
Message-ID: <d55bdf750906150437r5b508699xf8bcf7d8a817ab90@mail.gmail.com>

>> Are the visibility characteristics of static and non-static variables the
same?
I think static or non-static variables are same. should be declared as
volatile.


-- 
wang hongjiang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/6e2e04c2/attachment.html>

From matthias at mernst.org  Mon Jun 15 08:06:51 2009
From: matthias at mernst.org (Matthias Ernst)
Date: Mon, 15 Jun 2009 14:06:51 +0200
Subject: [concurrency-interest] Implementation of a global configuration
	cache
In-Reply-To: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
References: <3a5ad2140906150156s5a3de888h578c523cfb4948fd@mail.gmail.com>
Message-ID: <22ec15240906150506g1d9759d0w613a11d989924a7e@mail.gmail.com>

To keep things simple and to look at a consistent configuration, I
would introduce only _one_ mutable field:
static final AtomicReference<Configuration> configuration = new
AtomicReference<Configuration>(defaultConfig);
The Configuration itself would be immutable.

This way you avoid all problems related to locking or in-flight
inconsistencies and can even do consitent config updates:

Config newConfig = ...from file...;

Config current;
do {
  current = ref.get();
  if (!new.isCompatibleWith(current)) throw;
} while(!ref.compareAndSet(current, new));

And, to get back to your original question, AtomicReference handles
all visibility problems.

Matthias

On Mon, Jun 15, 2009 at 10:56 AM, Thejo Kote<thejo at kote.in> wrote:
> Hi,
>
> I'm trying to improve the design of a global configuration cache which
> currently consists of public static variables in a class. Something like -
>
> public final class ConfigCache {
>
> ??? public static String val1;
> ??? public static Map<Integer, MyObj> val2;
>
> ??? public static initializeCache() {
> ??????? val1 = ....;
> ??? }
>
> }
>
> I use the config values in other parts of the applications as
> ConfigCache.val1 etc. The task performed by the application is highly
> parallelizable and many threads read the configuration values. Some config
> values don't change after initialization at start up and some (like val2)
> are periodically (every 15 minutes) read from a database and updated in the
> cache from a separate thread. I take advantage of the fact that writes to
> and reads of references are always atomic when updating cache values in run
> time.
>
> With that background -
>
> - Are the visibility characteristics of static and non-static variables the
> same? Is it just sheer luck that the reading threads pick up the last
> updated reference, and should they be declared as volatile?
> - I'm ensuring that no references escape by initializing the cache before
> the application accepts requests, but using public static fields is not
> ideal and does not provide the required encapsulation. Is there a standard
> pattern for implementing such a configuration cache where many threads
> constantly read values with an occasional write. Is a singleton object with
> proper use of read write locks on the values that keep changing the right
> solution?
>
> Thanks,
> Thejo
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From gregg at cytetech.com  Mon Jun 15 12:05:03 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Mon, 15 Jun 2009 11:05:03 -0500
Subject: [concurrency-interest] Concurrency Architecture
In-Reply-To: <6b3a7f010906142059p3aeb1aedjeded9cd403721029@mail.gmail.com>
References: <6b3a7f010906140937q35494e4ida524cc543a20e33@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCEEELICAA.davidcholmes@aapt.net.au>
	<6b3a7f010906142059p3aeb1aedjeded9cd403721029@mail.gmail.com>
Message-ID: <4A36712F.2030809@cytetech.com>

Another way to do this, is with Future.  I have sometimes used something like 
the following class (and the included test class) which uses Proxy to help with 
eliminating any server instance management.

The idea here is that server exceptions have a couple of different outcomes in 
client code, most typically.

1. When an error occurs, the method is known to be idempotent so you just call 
again.
2. The result of the method is unknown and the method is not known to be 
idempotent so you need to regain a view of the services state to make the next 
use of the service.

So, I push failure handling out to the invocation but to try and manage the 
recovery in a simple way.

With all the code below, once you have a ServerAcces<T> instance (acc) and have 
made an initial call to get a server (srv), you can just do

ServerAccess<T> acc;
T srv;

try {
	srv.invokeSomething(...);
} catch( RemoteException ex ) {
	log....
	srv = acc.getServer();
}

As the simple try something and if it fails, get a new server instance for the
next call. Note that this can create a delay in returning failure to outer level 
code because we are getting a new server instance after the failure, not on the 
next call.

If srv is local to the class and not a big concurrency issue, you might do 
something more like

try {
	if( srv == null ) {
		srv = acc.getServer();
	srv.invokeSomething(...);
} catch( RemoteException ex ) {
	log...
	srv = null;
}

There are of course other variations on the code below which can include doing 
the getServer() work inside of the Proxy.  This is one of the primary reasons I 
put a Proxy into most of this, because it makes it trivial to reorganize where 
the actual delay associated with finding the server occurs, so that users of the 
code as shown above, don't have to be altered to make it work in whatever way is 
appropriate as your application expands or contracts in complexity.

Gregg Wonderly

-------------------------------------------------------------------

public abstract class ServerAccess<T> {
	private volatile FutureTask<T> srvFut;
	private Logger log = Logger.getLogger(getClass().getName());
	private final Class[] interfaces;

	public ServerAccess( Class[]intfs ) {
		interfaces = intfs;
	}

	public T getServer() throws InterruptedException, ExecutionException {
		if( srvFut == null ) {
			synchronized( this ) {
				if( srvFut == null ) {
					srvFut = getConnectionCreator();
				}
			}
		}
		return wrapServer( srvFut.get() );
	}
	
	protected abstract FutureTask<T> getConnectionCreator();
	
	protected synchronized void invalidate() {
		srvFut = null;
	}
	
	protected T wrapServer( T srvr ) {
		return (T)Proxy.newProxyInstance( srvr.getClass().getClassLoader(), 
interfaces, new ClassHandler<T>( srvr ) );
	}

	private class ClassHandler<T> implements InvocationHandler {
		private T obj;
		public ClassHandler( T srvr ) {
			this.obj = srvr;
		}
		public Object invoke( Object proxy, Method method, Object[] args ) throws 
Throwable {
			try {
				return method.invoke( obj, args );
			} catch( Throwable ex ) {
				log.log(Level.SEVERE, ex.toString(), ex);
				// if IOException, get new server next call
				if( ex instanceof InvocationTargetException ) {
					InvocationTargetException itex = (InvocationTargetException)ex;
					ex = itex.getTargetException();
				}
				if( ex instanceof IOException )
					invalidate();
				throw ex;
			}
		}
	}
}

-----------------------------------------------------------------------------

public class ServerAccessTest implements Runnable {
	Logger log = Logger.getLogger(getClass().getName());
	public static void main( String args[] ) {
		for( int i = 0; i < 10; ++i ) {
			ServerAccessTest acc = new ServerAccessTest(i);
			acc.init();
			new Thread( acc ).start();
		}
	}
	
	public void run() {
		while( true ) {
			try {
				if( srv.getValue() > 200 ) {
					log.info( this+": stopping at "+srv.getValue());
					return;
				}
				srv.setValue( srv.getValue() + 1 );
				log.info( this+": val now="+srv.getValue() );
			} catch( IOException ex ) {
				log.log(Level.SEVERE, ex.toString()+": getting new server", ex);
				try {
					srv = acc.getServer();
				} catch (InterruptedException ex1) {
					log.log(Level.SEVERE, ex.toString(), ex);
				} catch (ExecutionException ex1) {
					log.log(Level.SEVERE, ex.toString(), ex);
				}
			}
		}
	}
	
	public String toString() {
		return "ServerAccessTest#"+inst;
	}
	private final int inst;
	public ServerAccessTest(int inst) {
		this.inst = inst;
	}
	ServerAccess<MyService> acc;
	MyService srv;
	private class MyAccess extends ServerAccess<MyService>
			implements Callable<MyService> {
		
		public MyAccess() {
			super( new Class[]{ MyService.class } );
		}

		public FutureTask<MyService> getConnectionCreator() {
			FutureTask<MyService> fut = new FutureTask<MyService>( this );
			log.info("Starting thread for future connection");
			new Thread( fut ).start();
			return fut;
		}

		public MyService call() {
			try {
				log.info("getting new MyService");
				// your example logic goes here returning
				// service you find to be live
				Thread.sleep((int) (3000 * Math.random() ));
			} catch (InterruptedException ex) {
				Logger.getLogger(ServerAccessTest.class.getName()).log(Level.SEVERE, null, ex);
			}
			return svc;
		}
	}
	static MySrvImpl svc = new MySrvImpl();
	private static class MySrvImpl implements MyService {
		volatile int val;
		public int getValue() throws IOException {
			if( Math.random() > .94 )
				throw new IOException("Simuated Failure at val="+val );
			return val;
		}

		public void setValue(int val) throws IOException {
			if( Math.random() < .03 )
				throw new IOException("Simuated Failure at val="+val );
			this.val = val;
		}
	}
	public void init() {
		acc = new MyAccess();
		try {
			srv = acc.getServer();
		} catch (InterruptedException ex) {
			log.log(Level.SEVERE, ex.toString(), ex);
		} catch (ExecutionException ex) {
			log.log(Level.SEVERE, ex.toString(), ex);
		}
	}
	
	public interface MyService extends Remote {
		public int getValue() throws IOException;
		public void setValue( int val ) throws IOException;
	}
}
Norman Elton wrote:
> Thanks all for the responses. I was trying to grapple how a
> ReentrantReadWriteLock would solve my problem, completely skipping
> over the more simple approaches. Brian's idea of an atomic "generation
> identifier" seems to be working like a champ.
> 
> Norman
> 
> On Sun, Jun 14, 2009 at 5:37 PM, David Holmes<davidcholmes at aapt.net.au> wrote:
>> Norman,
>>
>> There are many many ways to set this up. It could be as simple as checking
>> if the current server has changed after a timeout - if so then someone did
>> the change; if not then search for a new server yourself. It all depends on
>> the exact semantics you want - eg whether the new server has to be known to
>> be good before anyone else starts using it; and how long a "down" server is
>> excluded from being used etc. A CountDownLatch used as a simple gate can be
>> used to make other threads wait while a search is in progress, if you don't
>> want to use the lock directly for this purposes. (Using a Semaphore seems
>> tricky because you don't know how many threads may be waiting.)
>>
>> David Holmes
>>
>>> -----Original Message-----
>>> From: concurrency-interest-bounces at cs.oswego.edu
>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Norman
>>> Elton
>>> Sent: Monday, 15 June 2009 2:37 AM
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: [concurrency-interest] Concurrency Architecture
>>>
>>>
>>>
>>> I've been using the java.util.concurrent classes over the past few
>>> years, they've worked well for every circumstance I could throw at
>>> them. Today, I've stumbled upon a case that I just can't figure out
>>> how best to tackle.
>>>
>>> I've got a connection generator which builds and returns connections
>>> to a server. In case of failover, I'm maintaining a list of possible
>>> servers to which it can generate connections. My wrapper
>>> getConnection() method takes this into account by first attempting a
>>> connection to the "current" server. If that times out, it scans the
>>> list for a new "current" server.
>>>
>>> Here's some pseudocode:
>>>
>>> public Connection getConnection() {
>>>       try {
>>>               return this.generator.getConnection();
>>>       } catch (TimeoutException e) {
>>>       }
>>>
>>>       synchronized(this.generator) {
>>>               foreach (this.servers as curr_server) {
>>>                       try {
>>>                               this.generator.server = curr_server;
>>>                               return this.generator.getConnection();
>>>                       } catch (TimeoutException e) {
>>>                       }
>>>               }
>>>       }
>>>
>>>       throw new Exception("Sorry, couldn't find a server");
>>> }
>>>
>>> In this case, if three threads simultaneously call getConnection(),
>>> they will all timeout and hit the synchronized block together. The
>>> first one will identify a new server, but the other two have no way to
>>> know that a new server has been identified. They each will loop
>>> through the possible servers.
>>>
>>> I'm looking for some way for all threads to be able to call the first
>>> part of the procedure (attempt a connection to the current server). If
>>> that fails, then the first thread will attempt to find a new server,
>>> while others wait for the result.
>>>
>>> I've dug through all the possible types of locks, nothing quite meets
>>> the need. Of course, I could be wrong! Can anyone think of a good way
>>> to tackle these requirements?
>>>
>>> Thanks!
>>>
>>> Norman
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 


From jorge.ortiz at gmail.com  Mon Jun 15 13:33:13 2009
From: jorge.ortiz at gmail.com (Jorge Ortiz)
Date: Mon, 15 Jun 2009 10:33:13 -0700
Subject: [concurrency-interest] Consistency guarantees for
	ConcurrentHashMap
In-Reply-To: <4A314C2D.7030203@cs.oswego.edu>
References: <22a410d00906102315x4d8ce638jc5b7ed5103bcda10@mail.gmail.com>
	<e0563fd80906110221j59bdd521q9b72f793f2215d7d@mail.gmail.com>
	<22a410d00906111055h6882115cn46360b3121392719@mail.gmail.com>
	<4A314C2D.7030203@cs.oswego.edu>
Message-ID: <22a410d00906151033q7304704eqad5bf02e2856b5c2@mail.gmail.com>

Thanks Doug!

I suspected these behaviors were by-design, but their documentation was
contradictory (in the case of iterator) or unspecified (in the case of
clear).

--j

On Thu, Jun 11, 2009 at 11:25 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> Jorge Ortiz wrote:
>
>> Jim, Erkin, James,
>>
>> I haven't written any code to test these behaviors. This is all purely a
>> thought experiment at this point. Perhaps I should provide more details.
>>
>> For the first case, given the implementation of clear():
>>
>>    public void clear() {
>>        for (int i = 0; i < segments.length; ++i)
>>            segments[i].clear();
>>    }
>>
>> It's evident that this behavior is at best atomic per segment. There seem
>> to be no atomicity guarantees between segments. (I understand this is by
>> design.)
>>
>
> Yes, by design. If you require a global total write ordering
> than you give up concurrency on writes, in which case
> you might as well use a SynchronizedMap(new HashMap()).
> You could alternatively use ReadWriteLocks but they have enough
> overhead to make use with a HashMap questionable.
> And perhaps someday there may be an efficient optimistic
> linearizable hash algorithm for bulk operations based on
> transactional memory.
>
>
>> I could write map, filter, etc based on weakly consistent iterators, but
>> weak consistency seems to be not much of a guarantee at all.
>>
>
> We leave the tradeoff of consistency-strength versus scalability
> as a user decision, so offer both synchronized and concurrent versions
> of most collections, as discussed in the j.u.c package docs
>
> http://java.sun.com/javase/6/docs/api/java/util/concurrent/package-summary.html
>
>
>> I contrast, the Javadoc explanation for the entire ConcurrentHashMap class
>> is inaccurate, in my opinion:
>>
>> "Similarly, Iterators and Enumerations return elements reflecting the
>> state of the hash table at some point at or since the creation of the
>> iterator/enumeration."
>>
>>
> Thanks! That sentence should be changed to be the same as the
> other descriptions of weakly consistent iterators.
>
> -Doug
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/e46289ca/attachment.html>

From stephen.duncan at gmail.com  Mon Jun 15 13:38:29 2009
From: stephen.duncan at gmail.com (Stephen Duncan Jr)
Date: Mon, 15 Jun 2009 13:38:29 -0400
Subject: [concurrency-interest] Creating a Pipeline Using Executor Framework
Message-ID: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com>

I have an existing design & implementation of a sort of pipeline of tasks
that are run for each of a series of items.  Following my understanding of
advice in JCiP, I used the Executor and related classes as the
consumer-producer framework for this pipeline.  During the implementation I
made some decisions that, while they worked for this application, didn't
seem to be going with the grain of the framework.  Since I have several
other similar pipelines to be implemented, I was hoping to get some
feedback/critiquing/suggestions-for-improvement on the design.

I'll try to provide enough detail to be useful without getting in the way,
and would be happy to provide more if necessary.  The primary goal is a
flexible design that scales dynamically where possible, and is easily
configurable to match scaling needs where necessary.  Basically, I want to
use this design repeatedly and be fairly confident that it will be unlikely
that the concurrency mechanism is a bottleneck (and so far that's certainly
true, the actual processing has always been the bottleneck).

In this existing procedure, the pipeline of tasks mirrors a work flow of an
external web-service to call.  Each task is essentially broken up by an I/O
boundary such as a call to a web-service or to a database: AddToQueue,
CheckStatus, GetResults, StoreResults (in future pipelines, the more typical
pipeline will be: check out records, process records, store results).
CheckStatus may be run multiple times for an item until success.

So, the flow of an item through the pipeline is:
AddToQueue->CheckStatus->...->CheckStatus->GetResults->StoreResults

The implementation has a ThreadPoolExecutor for each of these pipeline
stages.  The CheckStatus one is a ScheduledThreadPoolExecutor so that if
CheckStatus comes back with "queued", then it schedules another check after
some delay.  General the executor framework matched up well; scheduling,
using a bounded queue with a CallerRunsPolicy, and the shutdown mechanism.
However, several design questions came up, and my chosen solution didn't
always match up to the features I expected.

The first question was how to get the item from stage to stage in the
pipeline.  In other words, how does each task know about the executor that
it should submit to upon completion of its task.  The path I chose was to
have an ExecutionContext object that had getters for each executor in the
pipeline, and a reference to the executionContext was passed to the
constructor of each task.  So the pseudo-code for a tasks run method would
be:

public void doTask() {
    doProcess();
    this.executionContext.getNextTaskExecutor().submit(new NextTask(data,
this.executionContext);
}

This approach seemed to work well, but I'm not sure if there's other design
alternatives that I didn't think of.

The second question was how to know when everything has either made it
through the pipeline or failed along the way.  This is the part I'm most
concerned with.  My design makes no use of Future objects, nor an
ExecutorCompletionService.  I couldn't figure out a way to use these
effectively.  Instead, as part of the ExecutionContext, I added a
BlockingQueue of finished items, so that upon either a failure along the way
or completion of the last task the item is added to the queue.  Then the
main queue, knowing how many items it submitted, loops and waits to take
each item off this queue:

        for (int i = 0; i < items.size(); i++)
        {
            try
            {
                this.executionContext.getFinishedItems().take();
            }
            catch (final InterruptedException e)
            {
                Thread.currentThread().interrupt();
                throw new RuntimeException(
                    "Interrupted while waiting for items to finish.");
            }
        }

One early alternative I had was to have the main method try to shut down and
then wait for completion of each pipeline stage in succession.  However, the
fact that the CheckStatus stage submits tasks back to itself made it
impossible to safely identify when that stage was completely done.

Also, the fact that failure can happen at any stage along the way, and you
don't want to submit a task to stage 2, then 3, then 4 if it fails at stage
1, prevented me from just having a completion service on the last stage.

So, are there alternate approaches out there that I should look at?  I'm
open to suggestions from small changes to whole new ways of looking at the
problem.  As I said, if you need more detail to be able to answer, just let
me know, and I'd be happy to provide it.

Thanks in advance for your help.

-- 
Stephen Duncan Jr
www.stephenduncanjr.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/48374945/attachment-0001.html>

From i30817 at gmail.com  Mon Jun 15 14:36:50 2009
From: i30817 at gmail.com (Paulo Levi)
Date: Mon, 15 Jun 2009 19:36:50 +0100
Subject: [concurrency-interest] Creating a Pipeline Using Executor
	Framework
In-Reply-To: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com>
References: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com>
Message-ID: <212322090906151136i153ea227w2036c77a3660f60@mail.gmail.com>

Maybe i'm just simplifying your design too much, but when i needed to do
something similar i adapted Callable to be a Chain of Responsibility object.
When i needed to change ThreadPoolExecutor i added a "link" in the "chain"
that submitted it. When a chain failed i returned null and "cut" the chain.
When i needed explicit shutdown i overrided a shutdown method, (i had to
create a custom ThreadPoolExecutor to call this, the only nit on my design)
but this forced me sometimes to put blocking objects in the class state not
the run function (to be cancelled assynchronouly).

Just a few ideas.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/bc2c2f11/attachment.html>

From i30817 at gmail.com  Mon Jun 15 14:38:23 2009
From: i30817 at gmail.com (Paulo Levi)
Date: Mon, 15 Jun 2009 19:38:23 +0100
Subject: [concurrency-interest] Creating a Pipeline Using Executor
	Framework
In-Reply-To: <212322090906151136i153ea227w2036c77a3660f60@mail.gmail.com>
References: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com> 
	<212322090906151136i153ea227w2036c77a3660f60@mail.gmail.com>
Message-ID: <212322090906151138t2ae9c142n531df599a02bbbbf@mail.gmail.com>

Oh, the shutdown method is called recursively for every link on the chain
ofcourse.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/5250ec46/attachment.html>

From thejo at kote.in  Mon Jun 15 15:13:48 2009
From: thejo at kote.in (Thejo Kote)
Date: Tue, 16 Jun 2009 00:43:48 +0530
Subject: [concurrency-interest] Creating a Pipeline Using Executor
	Framework
In-Reply-To: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com>
References: <b20ce4ed0906151038h5c2f499fsb515267a3fc364e7@mail.gmail.com>
Message-ID: <3a5ad2140906151213t225ae0a8r66fab0af5b6afae5@mail.gmail.com>

The Cassandra Project (from Facebook, now in incubation at Apache) has a
nice implementation of SEDA (http://www.eecs.harvard.edu/~mdw/proj/seda/)
which may give you ideas about implementing such a system.

Thejo

On Mon, Jun 15, 2009 at 11:08 PM, Stephen Duncan Jr <
stephen.duncan at gmail.com> wrote:

> I have an existing design & implementation of a sort of pipeline of tasks
> that are run for each of a series of items.  Following my understanding of
> advice in JCiP, I used the Executor and related classes as the
> consumer-producer framework for this pipeline.  During the implementation I
> made some decisions that, while they worked for this application, didn't
> seem to be going with the grain of the framework.  Since I have several
> other similar pipelines to be implemented, I was hoping to get some
> feedback/critiquing/suggestions-for-improvement on the design.
>
> I'll try to provide enough detail to be useful without getting in the way,
> and would be happy to provide more if necessary.  The primary goal is a
> flexible design that scales dynamically where possible, and is easily
> configurable to match scaling needs where necessary.  Basically, I want to
> use this design repeatedly and be fairly confident that it will be unlikely
> that the concurrency mechanism is a bottleneck (and so far that's certainly
> true, the actual processing has always been the bottleneck).
>
> In this existing procedure, the pipeline of tasks mirrors a work flow of an
> external web-service to call.  Each task is essentially broken up by an I/O
> boundary such as a call to a web-service or to a database: AddToQueue,
> CheckStatus, GetResults, StoreResults (in future pipelines, the more typical
> pipeline will be: check out records, process records, store results).
> CheckStatus may be run multiple times for an item until success.
>
> So, the flow of an item through the pipeline is:
> AddToQueue->CheckStatus->...->CheckStatus->GetResults->StoreResults
>
> The implementation has a ThreadPoolExecutor for each of these pipeline
> stages.  The CheckStatus one is a ScheduledThreadPoolExecutor so that if
> CheckStatus comes back with "queued", then it schedules another check after
> some delay.  General the executor framework matched up well; scheduling,
> using a bounded queue with a CallerRunsPolicy, and the shutdown mechanism.
> However, several design questions came up, and my chosen solution didn't
> always match up to the features I expected.
>
> The first question was how to get the item from stage to stage in the
> pipeline.  In other words, how does each task know about the executor that
> it should submit to upon completion of its task.  The path I chose was to
> have an ExecutionContext object that had getters for each executor in the
> pipeline, and a reference to the executionContext was passed to the
> constructor of each task.  So the pseudo-code for a tasks run method would
> be:
>
> public void doTask() {
>     doProcess();
>     this.executionContext.getNextTaskExecutor().submit(new NextTask(data,
> this.executionContext);
> }
>
> This approach seemed to work well, but I'm not sure if there's other design
> alternatives that I didn't think of.
>
> The second question was how to know when everything has either made it
> through the pipeline or failed along the way.  This is the part I'm most
> concerned with.  My design makes no use of Future objects, nor an
> ExecutorCompletionService.  I couldn't figure out a way to use these
> effectively.  Instead, as part of the ExecutionContext, I added a
> BlockingQueue of finished items, so that upon either a failure along the way
> or completion of the last task the item is added to the queue.  Then the
> main queue, knowing how many items it submitted, loops and waits to take
> each item off this queue:
>
>         for (int i = 0; i < items.size(); i++)
>         {
>             try
>             {
>                 this.executionContext.getFinishedItems().take();
>             }
>             catch (final InterruptedException e)
>             {
>                 Thread.currentThread().interrupt();
>                 throw new RuntimeException(
>                     "Interrupted while waiting for items to finish.");
>             }
>         }
>
> One early alternative I had was to have the main method try to shut down
> and then wait for completion of each pipeline stage in succession.  However,
> the fact that the CheckStatus stage submits tasks back to itself made it
> impossible to safely identify when that stage was completely done.
>
> Also, the fact that failure can happen at any stage along the way, and you
> don't want to submit a task to stage 2, then 3, then 4 if it fails at stage
> 1, prevented me from just having a completion service on the last stage.
>
> So, are there alternate approaches out there that I should look at?  I'm
> open to suggestions from small changes to whole new ways of looking at the
> problem.  As I said, if you need more detail to be able to answer, just let
> me know, and I'd be happy to provide it.
>
> Thanks in advance for your help.
>
> --
> Stephen Duncan Jr
> www.stephenduncanjr.com
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090616/118db500/attachment.html>

From victor.grazi at credit-suisse.com  Mon Jun 15 15:28:51 2009
From: victor.grazi at credit-suisse.com (Grazi, Victor)
Date: Mon, 15 Jun 2009 15:28:51 -0400
Subject: [concurrency-interest] Java Concurrent Animated
Message-ID: <9A83E42A5C7F3346932568D660877130074FE659@EPRI17P32003A.csfb.cs-group.com>

I wanted the members of this list to be aware of an instructive Java
application that is designed to educate developers on the use and
functioning of the components in the java concurrent library.
The application hosts a series of interactive animations, one per
component (e.g. CyclicBarrier, ReadWriteLock). The user presses buttons
on the UI corresponding to methods on the component to see how the
threads interact with each other and with some blocking structure. A
code snippet pane highlights the relevant code as the threads do their
thing.

The animations are written in Java and each animation is actually
controlled by the underlying concurrent component it is illustrating.
Therefore it depicts the true run-time behavior of the component.
I invite you to download the application, which is now hosted on
SourceForge as an Open Source project.
http://sourceforge.net/projects/javaconcurrenta/

I am hoping that if users interact with the animations, they will be
more inclined to use the concurrent libraries.
Also, developers could use the animations as a reference when carving
out a concurrent architecture.

I would greatly welcome any feedback from this list.

Much thanks
Victor Grazi


CreditSuisse / HOLT
VP - Application Development
Tel: 212-538-5703
6-5703

> Please follow the attached hyperlink to an important disclosure:
> http://www.credit-suisse.com/legal/marketcommentary
> 
> 

=============================================================================== 
 Please access the attached hyperlink for an important electronic communications disclaimer: 
 http://www.credit-suisse.com/legal/en/disclaimer_email_ib.html 
 =============================================================================== 
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090615/ccb31f33/attachment.html>

From mthornton at optrak.co.uk  Wed Jun 17 09:55:25 2009
From: mthornton at optrak.co.uk (Mark Thornton)
Date: Wed, 17 Jun 2009 14:55:25 +0100
Subject: [concurrency-interest] ImmediateFuture
Message-ID: <4A38F5CD.8020702@optrak.co.uk>

For test purposes I created an ImmediateFuture class which implements 
Future but where the value already exists. Am I the only person to have 
found the need to do this or should something like it be considered for 
more general use?

Mark Thornton


From Joe.Kearney at morganstanley.com  Wed Jun 17 11:12:05 2009
From: Joe.Kearney at morganstanley.com (Joe Kearney)
Date: Wed, 17 Jun 2009 16:12:05 +0100
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <4A38F5CD.8020702@optrak.co.uk>
References: <4A38F5CD.8020702@optrak.co.uk>
Message-ID: <ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>

I had to write one of these, I called it ConstantFuture. Fairly trivial
implementation, but would be nice to have on hand.

2009/6/17 Mark Thornton <mthornton at optrak.co.uk>

> For test purposes I created an ImmediateFuture class which implements
> Future but where the value already exists. Am I the only person to have
> found the need to do this or should something like it be considered for more
> general use?
>
> Mark Thornton
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/f5aeaff9/attachment.html>

From sberlin at gmail.com  Wed Jun 17 11:22:14 2009
From: sberlin at gmail.com (Sam Berlin)
Date: Wed, 17 Jun 2009 11:22:14 -0400
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
Message-ID: <19196d860906170822t7b96d118v1297b7cf804c51ce@mail.gmail.com>

I also have one, called SimpleFuture.  Although now that I think about it,
FuturePast is a better name. :-)

Sam

On Wed, Jun 17, 2009 at 11:12 AM, Joe Kearney <Joe.Kearney at morganstanley.com
> wrote:

> I had to write one of these, I called it ConstantFuture. Fairly trivial
> implementation, but would be nice to have on hand.
>
> 2009/6/17 Mark Thornton <mthornton at optrak.co.uk>
>
> For test purposes I created an ImmediateFuture class which implements
>> Future but where the value already exists. Am I the only person to have
>> found the need to do this or should something like it be considered for more
>> general use?
>>
>> Mark Thornton
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/6f256d66/attachment.html>

From jim.andreou at gmail.com  Wed Jun 17 11:38:13 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Wed, 17 Jun 2009 18:38:13 +0300
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
Message-ID: <7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>

One could use something like this, to avoid introducing a new type:

private static final Runnable emptyRunnable = new Runnable() { public void
run() { } };
public static <T> Future<T> futureFor(T value) {
    return new FutureTask<T>(emptyRunnable, value);
}

2009/6/17 Joe Kearney <Joe.Kearney at morganstanley.com>

> I had to write one of these, I called it ConstantFuture. Fairly trivial
> implementation, but would be nice to have on hand.
>
> 2009/6/17 Mark Thornton <mthornton at optrak.co.uk>
>
>> For test purposes I created an ImmediateFuture class which implements
>> Future but where the value already exists. Am I the only person to have
>> found the need to do this or should something like it be considered for more
>> general use?
>>
>>
>> Mark Thornton
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/bff0fc2c/attachment.html>

From kevinb at google.com  Wed Jun 17 12:14:38 2009
From: kevinb at google.com (Kevin Bourrillion)
Date: Wed, 17 Jun 2009 09:14:38 -0700
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
	<7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
Message-ID: <108fcdeb0906170914m100ad5aah709e3449b5bebf23@mail.gmail.com>

Our own Futures.immediateFuture() utility is fairly popular as well, and not
only in test code.  For example, sometimes an interface wants to only
require a Future to be returned, but an implementation happens to already
have the value.


On Wed, Jun 17, 2009 at 8:38 AM, Jim Andreou <jim.andreou at gmail.com> wrote:

> One could use something like this, to avoid introducing a new type:
>
> private static final Runnable emptyRunnable = new Runnable() { public void
> run() { } };
> public static <T> Future<T> futureFor(T value) {
>     return new FutureTask<T>(emptyRunnable, value);
> }
>
> 2009/6/17 Joe Kearney <Joe.Kearney at morganstanley.com>
>
> I had to write one of these, I called it ConstantFuture. Fairly trivial
>> implementation, but would be nice to have on hand.
>>
>> 2009/6/17 Mark Thornton <mthornton at optrak.co.uk>
>>
>>> For test purposes I created an ImmediateFuture class which implements
>>> Future but where the value already exists. Am I the only person to have
>>> found the need to do this or should something like it be considered for more
>>> general use?
>>>
>>>
>>> Mark Thornton
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Kevin Bourrillion @ Google
internal:  http://go/javalibraries
google-collections.googlecode.com
google-guice.googlecode.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/48c7139e/attachment.html>

From Joe.Kearney at morganstanley.com  Wed Jun 17 12:21:09 2009
From: Joe.Kearney at morganstanley.com (Joe Kearney)
Date: Wed, 17 Jun 2009 17:21:09 +0100
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com> 
	<7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
Message-ID: <ec295ec90906170921u5dd2aa8fo1f91b078aec72dc4@mail.gmail.com>

If you want to avoid a new top-level type you could always create an
anonymous ConstantSimpleImmediateFuturePast (or whatever :) ) implementation
in the futureFor method, rather that than add the runtime cost of the
runnable and AQS sync overhead in the FutureTask.

2009/6/17 Jim Andreou <jim.andreou at gmail.com>

> One could use something like this, to avoid introducing a new type:
>
> private static final Runnable emptyRunnable = new Runnable() { public void
> run() { } };
> public static <T> Future<T> futureFor(T value) {
>     return new FutureTask<T>(emptyRunnable, value);
> }
>
> 2009/6/17 Joe Kearney <Joe.Kearney at morganstanley.com>
>
> I had to write one of these, I called it ConstantFuture. Fairly trivial
>> implementation, but would be nice to have on hand.
>>
>> 2009/6/17 Mark Thornton <mthornton at optrak.co.uk>
>>
>>> For test purposes I created an ImmediateFuture class which implements
>>> Future but where the value already exists. Am I the only person to have
>>> found the need to do this or should something like it be considered for more
>>> general use?
>>>
>>>
>>> Mark Thornton
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/c45930f5/attachment.html>

From gregg at cytetech.com  Wed Jun 17 13:14:09 2009
From: gregg at cytetech.com (Gregg Wonderly)
Date: Wed, 17 Jun 2009 12:14:09 -0500
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
	<7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
Message-ID: <4A392461.3080706@cytetech.com>

Practically, the FutureTask returned below, must be executed as well, or all 
get() request will block and never return.  I find it much better to just do the 
whole job and avoid any synchronization.

public static <T> Future<T> futureFor( final T value ) {
	return new Future<T>() {
		public boolean cancel( boolean intr ) {
			return false;
		}
		public T get() {
			return value;
		}
		public T get( long to, TimeUnit unit ) {
			return get();
		}
		public boolean isCancelled() {
			return false;
		}
		public boolean isDone() {
			return true;
		}
	};
}

And yes, it would be nice to have a class in the JDK that was such an 
implementation of Future.

Gregg Wonderly

Jim Andreou wrote:
> One could use something like this, to avoid introducing a new type:
> 
> private static final Runnable emptyRunnable = new Runnable() { public 
> void run() { } };
> public static <T> Future<T> futureFor(T value) { 
>     return new FutureTask<T>(emptyRunnable, value);
> }
> 
> 2009/6/17 Joe Kearney <Joe.Kearney at morganstanley.com 
> <mailto:Joe.Kearney at morganstanley.com>>
> 
>     I had to write one of these, I called it ConstantFuture. Fairly
>     trivial implementation, but would be nice to have on hand.
> 
>     2009/6/17 Mark Thornton <mthornton at optrak.co.uk
>     <mailto:mthornton at optrak.co.uk>>
> 
>         For test purposes I created an ImmediateFuture class which
>         implements Future but where the value already exists. Am I the
>         only person to have found the need to do this or should
>         something like it be considered for more general use?
> 
> 
>         Mark Thornton
> 
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From karlthepagan at gmail.com  Wed Jun 17 14:50:43 2009
From: karlthepagan at gmail.com (karlthepagan)
Date: Wed, 17 Jun 2009 11:50:43 -0700
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <4A392461.3080706@cytetech.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
	<7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
	<4A392461.3080706@cytetech.com>
Message-ID: <39008ef30906171150n6030421wb4f692e632a8f730@mail.gmail.com>

I have also implemented both CompletedFuture and FailedFuture.

I've not used failed outside test and have only seen a rare practical use
for the completed version. One use was a stand-in for a reference to a
scheduled task. For the general implementation RunnableScheduledFuture or at
lest ScheduledFuture should be considered (where getDelay would always
return 0 and compare would behave accordingly).

-karl


On Wed, Jun 17, 2009 at 10:14 AM, Gregg Wonderly <gregg at cytetech.com> wrote:

> And yes, it would be nice to have a class in the JDK that was such an
> implementation of Future.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/e43bff3f/attachment.html>

From ben_manes at yahoo.com  Wed Jun 17 15:55:17 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Wed, 17 Jun 2009 12:55:17 -0700 (PDT)
Subject: [concurrency-interest] ImmediateFuture
In-Reply-To: <108fcdeb0906170914m100ad5aah709e3449b5bebf23@mail.gmail.com>
References: <4A38F5CD.8020702@optrak.co.uk>
	<ec295ec90906170812o53478caawca5d3b5bd136b3b4@mail.gmail.com>
	<7d7138c10906170838l58847ec4l5ce454158b6805a2@mail.gmail.com>
	<108fcdeb0906170914m100ad5aah709e3449b5bebf23@mail.gmail.com>
Message-ID: <318108.9434.qm@web38802.mail.mud.yahoo.com>

And I am yet another doing this.  I have an "eager" future with immediately computes/takes the value and a "lazy" future which computes it on the first invocation.  The eager future is really handy (e.g. a memoizer-based map) and the lazy future to pass up a lower-level futures with some attached post processing logic (e.g. asynchronous memcached call where deserialize is thepost-processing step).




________________________________
From: Kevin Bourrillion <kevinb at google.com>
To: Jim Andreou <jim.andreou at gmail.com>
Cc: Joe Kearney <Joe.Kearney at morganstanley.com>; concurrency-interest at cs.oswego.edu
Sent: Wednesday, June 17, 2009 9:14:38 AM
Subject: Re: [concurrency-interest] ImmediateFuture

Our own Futures.immediateFuture() utility is fairly popular as well, and not only in test code.  For example, sometimes an interface wants to only require a Future to be returned, but an implementation happens to already have the value.




On Wed, Jun 17, 2009 at 8:38 AM, Jim Andreou <jim.andreou at gmail.com> wrote:

One could use something like this, to avoid introducing a new type:

private static final Runnable emptyRunnable = new Runnable() { public void run() { } };
public static <T> Future<T> futureFor(T value) { 
    return new FutureTask<T>(emptyRunnable, value);
}

2009/6/17 Joe Kearney <Joe.Kearney at morganstanley.com>


I had to write one of these, I called it ConstantFuture. Fairly trivial implementation, but would be nice to have on hand.


2009/6/17 Mark Thornton <mthornton at optrak.co.uk>

For test purposes I created an ImmediateFuture class which implements Future but where the value already exists. Am I the only person to have found the need to do this or should something like it be considered for more general use?


Mark Thornton

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest




-- 
Kevin Bourrillion @ Google
internal:  http://go/javalibraries
google-collections.googlecode.com
google-guice.googlecode.com


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/10b0b2b4/attachment-0001.html>

From tgautier at terracottatech.com  Wed Jun 17 18:27:53 2009
From: tgautier at terracottatech.com (Taylor Gautier)
Date: Wed, 17 Jun 2009 15:27:53 -0700 (PDT)
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
Message-ID: <8715173.2104961245277673144.JavaMail.root@mail01.terracottatech.com>

Just wondering why there is no blocking peek call in the java.util.concurrent.BlockingQueue interface? 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/809189db/attachment.html>

From alarmnummer at gmail.com  Wed Jun 17 18:41:06 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 18 Jun 2009 00:41:06 +0200
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <8715173.2104961245277673144.JavaMail.root@mail01.terracottatech.com>
References: <8715173.2104961245277673144.JavaMail.root@mail01.terracottatech.com>
Message-ID: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>

To idea behind the peek is that it should not block unlike a take.

If you want a non blocking version, you can use the poll(long time,
TimeUnit unit) method. But it is strange that there is no (non
blocking) peek method. Perhaps that is the question you wanted to ask?

On Thu, Jun 18, 2009 at 12:27 AM, Taylor
Gautier<tgautier at terracottatech.com> wrote:
> Just wondering why there is no blocking peek call in the
> java.util.concurrent.BlockingQueue interface?
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From tgautier at terracottatech.com  Wed Jun 17 18:51:42 2009
From: tgautier at terracottatech.com (Taylor Gautier)
Date: Wed, 17 Jun 2009 15:51:42 -0700 (PDT)
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>
Message-ID: <6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>

I think the issue I am thinking of is that there is no way to make a blocking call to be notified when the queue is non-empty, yet take no action - all of the blocking actions also atomically change the queue contents. 


After asking this question, I read this bug report, 


http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412 


Where I think I agree with the reviewers comments - is there a real use case? 


I am asking because someone is asking us (Terracotta) if there is a way to do a blocking peek on a Terracotta(ized) LinkedBlockingQueue. 


I've pushed back on the the original poster why they need this functionality... 



----- Original Message ----- 
From: "Peter Veentjer" <alarmnummer at gmail.com> 
To: "Taylor Gautier" <tgautier at terracottatech.com> 
Cc: concurrency-interest at cs.oswego.edu 
Sent: Wednesday, June 17, 2009 3:41:06 PM GMT -08:00 US/Canada Pacific 
Subject: Re: [concurrency-interest] Why no blocking peek call for j.u.c.BQ? 

To idea behind the peek is that it should not block unlike a take. 

If you want a non blocking version, you can use the poll(long time, 
TimeUnit unit) method. But it is strange that there is no (non 
blocking) peek method. Perhaps that is the question you wanted to ask? 

On Thu, Jun 18, 2009 at 12:27 AM, Taylor 
Gautier<tgautier at terracottatech.com> wrote: 
> Just wondering why there is no blocking peek call in the 
> java.util.concurrent.BlockingQueue interface? 
> _______________________________________________ 
> Concurrency-interest mailing list 
> Concurrency-interest at cs.oswego.edu 
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
> 
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090617/6c517c44/attachment.html>

From alarmnummer at gmail.com  Wed Jun 17 18:59:06 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Thu, 18 Jun 2009 00:59:06 +0200
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
References: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>
	<6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
Message-ID: <1466c1d60906171559k1e48e909q8e1714e2edb0519a@mail.gmail.com>

Since you are experienced with instrumentation, you can always enhance
the bytecode so that the notEmpty condition of the LinkedBlockingQueue
gets exposed. This way it is easy to add the desired listen
functionality. Be careful that no signals are eaten :)

On Thu, Jun 18, 2009 at 12:51 AM, Taylor
Gautier<tgautier at terracottatech.com> wrote:
> I think the issue I am thinking of is that there is no way to make a
> blocking call to be notified when the queue is non-empty, yet take no action
> - all of the blocking actions also atomically change the queue contents.
> After asking this question, I read this bug report,
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412
> Where I think I agree with the reviewers comments - is there a real use
> case?
> I am asking because someone is asking us (Terracotta) if there is a way to
> do a blocking peek on a Terracotta(ized) LinkedBlockingQueue.
> I've pushed back on the the original poster why they need this
> functionality...
>
> ----- Original Message -----
> From: "Peter Veentjer" <alarmnummer at gmail.com>
> To: "Taylor Gautier" <tgautier at terracottatech.com>
> Cc: concurrency-interest at cs.oswego.edu
> Sent: Wednesday, June 17, 2009 3:41:06 PM GMT -08:00 US/Canada Pacific
> Subject: Re: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
>
> To idea behind the peek is that it should not block unlike a take.
>
> If you want a non blocking version, you can use the poll(long time,
> TimeUnit unit) method. But it is strange that there is no (non
> blocking) peek method. Perhaps that is the question you wanted to ask?
>
> On Thu, Jun 18, 2009 at 12:27 AM, Taylor
> Gautier<tgautier at terracottatech.com> wrote:
>> Just wondering why there is no blocking peek call in the
>> java.util.concurrent.BlockingQueue interface?
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>

From paulp at improving.org  Wed Jun 17 19:36:42 2009
From: paulp at improving.org (Paul Phillips)
Date: Wed, 17 Jun 2009 16:36:42 -0700
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
References: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>
	<6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
Message-ID: <20090617233642.GA44430@jon.local>

On Wed, Jun 17, 2009 at 03:51:42PM -0700, Taylor Gautier wrote:
> After asking this question, I read this bug report, 
> 
> http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412
> 
> Where I think I agree with the reviewers comments - is there a real 
> use case?

I certainly noticed the absence of that method when writing this:

http://lampsvn.epfl.ch/svn-repos/scala/scala/trunk/src/library/scala/xml/pull/XMLEventReader.scala

It is an XML pull parser.  It presents an iterator interface to the 
user, but because the underlying data may be coming from an arbitrary 
stream which may be arbitrarily slow, we need a way to distinguish end 
of stream (hasNext returns false) from an empty queue (where hasNext 
needs to block, since it doesn't know if there is will be a next.) So we 
insert a poison object when the producer is done producing.

If there is a blocking peek method, I can write it without having to 
manually implement a one element buffer.  hasNext calls peek and returns 
false if it sees the poison object, true if it sees anything else, and 
blocks as long as necessary on an empty queue.  Lacking a blocking peek 
I have to either poll or implement a buffer, neither of which appeals 
compared to the missing alternative.

So unless I missed some way better way to model this (undoubtedly a 
possibility) there's at least one reason.  And there are more in the 
later comments in that bug report.

-- 
Paul Phillips      | A Sunday school is a prison in which children do
Apatheist          | penance for the evil conscience of their parents. 
Empiricist         |     -- H. L. Mencken
slap pi uphill!    |----------* http://www.improving.org/paulp/ *----------

From alexdmiller at yahoo.com  Thu Jun 18 12:29:55 2009
From: alexdmiller at yahoo.com (Alex Miller)
Date: Thu, 18 Jun 2009 09:29:55 -0700 (PDT)
Subject: [concurrency-interest] Why no blocking peek call for > j.u.c.BQ?
In-Reply-To: <mailman.1.1245340800.139.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1245340800.139.concurrency-interest@cs.oswego.edu>
Message-ID: <457833.40854.qm@web32204.mail.mud.yahoo.com>


Will TransferQueue help with this kind of functionality in JDK 7?  

From jim.andreou at gmail.com  Fri Jun 19 02:48:41 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Fri, 19 Jun 2009 09:48:41 +0300
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <20090617233642.GA44430@jon.local>
References: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>
	<6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
	<20090617233642.GA44430@jon.local>
Message-ID: <7d7138c10906182348t12d75502jefaf700786135dc5@mail.gmail.com>

I don't see this as a compelling use case, which can be summarized: "in
cases where there is only a single consumer, I could use a blocking peek
instead of having a variable". Use a variable already. :) The easiness of
this outweights the cost of having another method (somewhere...), which
people could call, creating race conditions (as mentioned) when someone
decides at some time that "perhaps it would be a good idea to add more
consumers for this queue".
Regards,

Dimitris

2009/6/18 Paul Phillips <paulp at improving.org>

> On Wed, Jun 17, 2009 at 03:51:42PM -0700, Taylor Gautier wrote:
> > After asking this question, I read this bug report,
> >
> > http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412
> >
> > Where I think I agree with the reviewers comments - is there a real
> > use case?
>
> I certainly noticed the absence of that method when writing this:
>
>
> http://lampsvn.epfl.ch/svn-repos/scala/scala/trunk/src/library/scala/xml/pull/XMLEventReader.scala
>
> It is an XML pull parser.  It presents an iterator interface to the
> user, but because the underlying data may be coming from an arbitrary
> stream which may be arbitrarily slow, we need a way to distinguish end
> of stream (hasNext returns false) from an empty queue (where hasNext
> needs to block, since it doesn't know if there is will be a next.) So we
> insert a poison object when the producer is done producing.
>
> If there is a blocking peek method, I can write it without having to
> manually implement a one element buffer.  hasNext calls peek and returns
> false if it sees the poison object, true if it sees anything else, and
> blocks as long as necessary on an empty queue.  Lacking a blocking peek
> I have to either poll or implement a buffer, neither of which appeals
> compared to the missing alternative.
>
> So unless I missed some way better way to model this (undoubtedly a
> possibility) there's at least one reason.  And there are more in the
> later comments in that bug report.
>
> --
> Paul Phillips      | A Sunday school is a prison in which children do
> Apatheist          | penance for the evil conscience of their parents.
> Empiricist         |     -- H. L. Mencken
> slap pi uphill!    |----------* http://www.improving.org/paulp/*----------
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090619/7eae5562/attachment.html>

From ashpublic at mac.com  Mon Jun 22 16:21:23 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Mon, 22 Jun 2009 21:21:23 +0100
Subject: [concurrency-interest] concurrency newbie question
Message-ID: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>

Hi,

After reading java concurrency in practice, I've now realize how  
little I know after all these years so I'm trying to put that
right. So as a first step I would like to make a settings class, which  
is just a bunch of getters and setters, a little more
threadsafe and so I would appreciate any helpful comments.


I think I am right in just using a final reference to an atomic
wrapper for the simple property types, but I'm unsure if I'm  
approaching the map property correctly. In the code below
I've tried to follow these guidelines for the 'machines' field:

1. The getter should always return a copy.

2. The setter should replace the currently held list, rather than  
trying to clear() then putAll() which can cause a race condition
if another thread gets in between the two operations.

3. The accessor getMachine(key) method effectively does a double check  
to decide whether it needs to create the entry. The
first check is against null and the second is an implicit check during  
the call to putIfAbsent().

4. My first attempt didn't wrap the map with an atomic, instead the  
map was declared directly as a field. I rejected this because
the set method involved calling clear() then putAll() which can cause  
a race condition
if another thread gets in between the two operations. Was I right to  
reject this approach?


public final class StandardSettings {
	private final AtomicBoolean statusMessage;

	private final AtomicReference<ConcurrentHashMap<String,  
MachineConfig>> machines;

	public StandardSettings() {
		this.statusMessage = new AtomicBoolean(true);
		this.machines = new AtomicReference<ConcurrentHashMap<String,  
MachineConfig>>(
				new ConcurrentHashMap<String, MachineConfig>());
	}

// getter and setter for a boolean property

	public Boolean getStatusMessage() {
		return statusMessage.get();
	}

	public void setStatusMessage(Boolean statusMessage) {
		this.statusMessage.set(statusMessage);
	}

// getter and setter for map property

	public ConcurrentHashMap<String, MachineConfig> getMachines() {
		return new ConcurrentHashMap<String, MachineConfig>(machines.get());
	}

	public void setMachines(ConcurrentHashMap<String, MachineConfig>  
machines) {
		this.machines.set(machines);
	}

// access to the named map entry that creates that entry if it doesn't  
exist

	public MachineConfig getMachine(String name) {
		MachineConfig config = machines.get().get(name);

		if (config == null) {
			MachineConfig newValue = new MachineConfig(name);
			// another thread may have just added after our null check
			MachineConfig oldValue = machines.get().putIfAbsent(name, newValue);
			config = oldValue != null ? oldValue : newValue;

		}

		return config;
	}

}

Am I on the right track for making this class thread safe and if not  
how should I be approaching the problem?

Many thanks
- Ashley Williams

From takeshi10 at gmail.com  Mon Jun 22 16:49:34 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Mon, 22 Jun 2009 17:49:34 -0300
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
Message-ID: <7288749d0906221349m4bf5b0e4obe18505b5e3a0a9e@mail.gmail.com>

I think your code looks correctly, but for readability i would:
-make the machines field volatile instead of using AtomicReference
(for readability)
-unless creating a MachineConfig is very expensive, i'd drop the null
check and always create a new MachineConfig like this:

public MachineConfig getMachine(String name) {
   MachineConfig newValue = new MachineConfig(name);
   MachineConfig oldValue = machines.putIfAbsent(name, newValue);
   return oldValue != null ? oldValue : newValue;
}

but i suppose they are a matter of taste

On Mon, Jun 22, 2009 at 5:21 PM, Ashley Williams<ashpublic at mac.com> wrote:
> Hi,
>
> After reading java concurrency in practice, I've now realize how little I
> know after all these years so I'm trying to put that
> right. So as a first step I would like to make a settings class, which is
> just a bunch of getters and setters, a little more
> threadsafe and so I would appreciate any helpful comments.
>
>
> I think I am right in just using a final reference to an atomic
> wrapper for the simple property types, but I'm unsure if I'm approaching the
> map property correctly. In the code below
> I've tried to follow these guidelines for the 'machines' field:
>
> 1. The getter should always return a copy.
>
> 2. The setter should replace the currently held list, rather than trying to
> clear() then putAll() which can cause a race condition
> if another thread gets in between the two operations.
>
> 3. The accessor getMachine(key) method effectively does a double check to
> decide whether it needs to create the entry. The
> first check is against null and the second is an implicit check during the
> call to putIfAbsent().
>
> 4. My first attempt didn't wrap the map with an atomic, instead the map was
> declared directly as a field. I rejected this because
> the set method involved calling clear() then putAll() which can cause a race
> condition
> if another thread gets in between the two operations. Was I right to reject
> this approach?
>
>
> public final class StandardSettings {
> ? ? ? ?private final AtomicBoolean statusMessage;
>
> ? ? ? ?private final AtomicReference<ConcurrentHashMap<String,
> MachineConfig>> machines;
>
> ? ? ? ?public StandardSettings() {
> ? ? ? ? ? ? ? ?this.statusMessage = new AtomicBoolean(true);
> ? ? ? ? ? ? ? ?this.machines = new AtomicReference<ConcurrentHashMap<String,
> MachineConfig>>(
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?new ConcurrentHashMap<String,
> MachineConfig>());
> ? ? ? ?}
>
> // getter and setter for a boolean property
>
> ? ? ? ?public Boolean getStatusMessage() {
> ? ? ? ? ? ? ? ?return statusMessage.get();
> ? ? ? ?}
>
> ? ? ? ?public void setStatusMessage(Boolean statusMessage) {
> ? ? ? ? ? ? ? ?this.statusMessage.set(statusMessage);
> ? ? ? ?}
>
> // getter and setter for map property
>
> ? ? ? ?public ConcurrentHashMap<String, MachineConfig> getMachines() {
> ? ? ? ? ? ? ? ?return new ConcurrentHashMap<String,
> MachineConfig>(machines.get());
> ? ? ? ?}
>
> ? ? ? ?public void setMachines(ConcurrentHashMap<String, MachineConfig>
> machines) {
> ? ? ? ? ? ? ? ?this.machines.set(machines);
> ? ? ? ?}
>
> // access to the named map entry that creates that entry if it doesn't exist
>
> ? ? ? ?public MachineConfig getMachine(String name) {
> ? ? ? ? ? ? ? ?MachineConfig config = machines.get().get(name);
>
> ? ? ? ? ? ? ? ?if (config == null) {
> ? ? ? ? ? ? ? ? ? ? ? ?MachineConfig newValue = new MachineConfig(name);
> ? ? ? ? ? ? ? ? ? ? ? ?// another thread may have just added after our null
> check
> ? ? ? ? ? ? ? ? ? ? ? ?MachineConfig oldValue =
> machines.get().putIfAbsent(name, newValue);
> ? ? ? ? ? ? ? ? ? ? ? ?config = oldValue != null ? oldValue : newValue;
>
> ? ? ? ? ? ? ? ?}
>
> ? ? ? ? ? ? ? ?return config;
> ? ? ? ?}
>
> }
>
> Am I on the right track for making this class thread safe and if not how
> should I be approaching the problem?
>
> Many thanks
> - Ashley Williams
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
http://mapsdev.blogspot.com/
Marcelo Takeshi Fukushima


From ashpublic at mac.com  Mon Jun 22 17:11:39 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Mon, 22 Jun 2009 22:11:39 +0100
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <7288749d0906221349m4bf5b0e4obe18505b5e3a0a9e@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<7288749d0906221349m4bf5b0e4obe18505b5e3a0a9e@mail.gmail.com>
Message-ID: <85FE1BAE-C21B-430F-B23D-85B4B8A088E3@mac.com>

Great, somebody has verified the code which is a good start. Thanks.

Ok I've had another look at the book and I think you are right that I
can just use volatiles if I don't need any of the CAS features of  
atomics.
I guess I have it in my mind to use the final modifier at all costs when
declaring fields.

On 22 Jun 2009, at 21:49, Marcelo Fukushima wrote:

> I think your code looks correctly, but for readability i would:
> -make the machines field volatile instead of using AtomicReference
> (for readability)
> -unless creating a MachineConfig is very expensive, i'd drop the null
> check and always create a new MachineConfig like this:
>
> public MachineConfig getMachine(String name) {
>   MachineConfig newValue = new MachineConfig(name);
>   MachineConfig oldValue = machines.putIfAbsent(name, newValue);
>   return oldValue != null ? oldValue : newValue;
> }
>
> but i suppose they are a matter of taste
>
> On Mon, Jun 22, 2009 at 5:21 PM, Ashley Williams<ashpublic at mac.com>  
> wrote:
>> Hi,
>>
>> After reading java concurrency in practice, I've now realize how  
>> little I
>> know after all these years so I'm trying to put that
>> right. So as a first step I would like to make a settings class,  
>> which is
>> just a bunch of getters and setters, a little more
>> threadsafe and so I would appreciate any helpful comments.
>>
>>
>> I think I am right in just using a final reference to an atomic
>> wrapper for the simple property types, but I'm unsure if I'm  
>> approaching the
>> map property correctly. In the code below
>> I've tried to follow these guidelines for the 'machines' field:
>>
>> 1. The getter should always return a copy.
>>
>> 2. The setter should replace the currently held list, rather than  
>> trying to
>> clear() then putAll() which can cause a race condition
>> if another thread gets in between the two operations.
>>
>> 3. The accessor getMachine(key) method effectively does a double  
>> check to
>> decide whether it needs to create the entry. The
>> first check is against null and the second is an implicit check  
>> during the
>> call to putIfAbsent().
>>
>> 4. My first attempt didn't wrap the map with an atomic, instead the  
>> map was
>> declared directly as a field. I rejected this because
>> the set method involved calling clear() then putAll() which can  
>> cause a race
>> condition
>> if another thread gets in between the two operations. Was I right  
>> to reject
>> this approach?
>>
>>
>> public final class StandardSettings {
>>        private final AtomicBoolean statusMessage;
>>
>>        private final AtomicReference<ConcurrentHashMap<String,
>> MachineConfig>> machines;
>>
>>        public StandardSettings() {
>>                this.statusMessage = new AtomicBoolean(true);
>>                this.machines = new  
>> AtomicReference<ConcurrentHashMap<String,
>> MachineConfig>>(
>>                                new ConcurrentHashMap<String,
>> MachineConfig>());
>>        }
>>
>> // getter and setter for a boolean property
>>
>>        public Boolean getStatusMessage() {
>>                return statusMessage.get();
>>        }
>>
>>        public void setStatusMessage(Boolean statusMessage) {
>>                this.statusMessage.set(statusMessage);
>>        }
>>
>> // getter and setter for map property
>>
>>        public ConcurrentHashMap<String, MachineConfig>  
>> getMachines() {
>>                return new ConcurrentHashMap<String,
>> MachineConfig>(machines.get());
>>        }
>>
>>        public void setMachines(ConcurrentHashMap<String,  
>> MachineConfig>
>> machines) {
>>                this.machines.set(machines);
>>        }
>>
>> // access to the named map entry that creates that entry if it  
>> doesn't exist
>>
>>        public MachineConfig getMachine(String name) {
>>                MachineConfig config = machines.get().get(name);
>>
>>                if (config == null) {
>>                        MachineConfig newValue = new  
>> MachineConfig(name);
>>                        // another thread may have just added after  
>> our null
>> check
>>                        MachineConfig oldValue =
>> machines.get().putIfAbsent(name, newValue);
>>                        config = oldValue != null ? oldValue :  
>> newValue;
>>
>>                }
>>
>>                return config;
>>        }
>>
>> }
>>
>> Am I on the right track for making this class thread safe and if  
>> not how
>> should I be approaching the problem?
>>
>> Many thanks
>> - Ashley Williams
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> -- 
> http://mapsdev.blogspot.com/
> Marcelo Takeshi Fukushima


From tim at peierls.net  Mon Jun 22 19:36:50 2009
From: tim at peierls.net (Tim Peierls)
Date: Mon, 22 Jun 2009 19:36:50 -0400
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
Message-ID: <63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>

Maybe we didn't emphasize this enough in JCiP, but it's almost always best
to start with something simple and correct and then move to more complex
designs only if it's clear that you really need to.
Your example looks somewhat artificial, but if I were to take it literally,
I would start with something like this.

public interface StandardSettings {
    boolean isStatusMessage();
    void setStatusMessage(boolean statusMessage);
    ConcurrentMap<String, MachineConfig> getMachines();
    MachineConfig get(String name);
}

@ThreadSafe
public final class StandardSettingsImpl implements StandardSettings {

       @GuardedBy("this") private boolean statusMessage = true;

       private final ConcurrentMap<String, MachineConfig>> machines =
           new ConcurrentHashMap<String, MachineConfig>();


       public synchronized boolean isStatusMessage() {
           return statusMessage;
       }

       public synchronized void setStatusMessage(boolean statusMessage) {
           this.statusMessage = statusMessage;
       }

       public ConcurrentMap<String, MachineConfig> getMachines() {
           return machines;
       }

       public MachineConfig getMachine(String name) {
           return machines.get(name);
       }
}

Prefer the interface type ConcurrentMap (or just Map) in APIs, only using
concrete types like ConcurrentHashMap in initializers.

If you're willing to expose the map from machine name to machine config, you
don't need a setMachines method at all. See chapter 4 of JCiP for variations
on this theme.

Use the JCiP annotations (or similar comments) to document your concurrency
policy.

Don't be shy about using simple synchronization.

--tim



On Mon, Jun 22, 2009 at 4:21 PM, Ashley Williams <ashpublic at mac.com> wrote:

> Hi,
>
> After reading java concurrency in practice, I've now realize how little I
> know after all these years so I'm trying to put that
> right. So as a first step I would like to make a settings class, which is
> just a bunch of getters and setters, a little more
> threadsafe and so I would appreciate any helpful comments.
>
>
> I think I am right in just using a final reference to an atomic
> wrapper for the simple property types, but I'm unsure if I'm approaching
> the map property correctly. In the code below
> I've tried to follow these guidelines for the 'machines' field:
>
> 1. The getter should always return a copy.
>
> 2. The setter should replace the currently held list, rather than trying to
> clear() then putAll() which can cause a race condition
> if another thread gets in between the two operations.
>
> 3. The accessor getMachine(key) method effectively does a double check to
> decide whether it needs to create the entry. The
> first check is against null and the second is an implicit check during the
> call to putIfAbsent().
>
> 4. My first attempt didn't wrap the map with an atomic, instead the map was
> declared directly as a field. I rejected this because
> the set method involved calling clear() then putAll() which can cause a
> race condition
> if another thread gets in between the two operations. Was I right to reject
> this approach?
>
>
> public final class StandardSettings {
>        private final AtomicBoolean statusMessage;
>
>        private final AtomicReference<ConcurrentHashMap<String,
> MachineConfig>> machines;
>
>        public StandardSettings() {
>                this.statusMessage = new AtomicBoolean(true);
>                this.machines = new
> AtomicReference<ConcurrentHashMap<String, MachineConfig>>(
>                                new ConcurrentHashMap<String,
> MachineConfig>());
>        }
>
> // getter and setter for a boolean property
>
>        public Boolean getStatusMessage() {
>                return statusMessage.get();
>        }
>
>        public void setStatusMessage(Boolean statusMessage) {
>                this.statusMessage.set(statusMessage);
>        }
>
> // getter and setter for map property
>
>        public ConcurrentHashMap<String, MachineConfig> getMachines() {
>                return new ConcurrentHashMap<String,
> MachineConfig>(machines.get());
>        }
>
>        public void setMachines(ConcurrentHashMap<String, MachineConfig>
> machines) {
>                this.machines.set(machines);
>        }
>
> // access to the named map entry that creates that entry if it doesn't
> exist
>
>        public MachineConfig getMachine(String name) {
>                MachineConfig config = machines.get().get(name);
>
>                if (config == null) {
>                        MachineConfig newValue = new MachineConfig(name);
>                        // another thread may have just added after our null
> check
>                        MachineConfig oldValue =
> machines.get().putIfAbsent(name, newValue);
>                        config = oldValue != null ? oldValue : newValue;
>
>                }
>
>                return config;
>        }
>
> }
>
> Am I on the right track for making this class thread safe and if not how
> should I be approaching the problem?
>
> Many thanks
> - Ashley Williams
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090622/3016d0fd/attachment-0001.html>

From chriskessel at verizon.net  Mon Jun 22 23:26:45 2009
From: chriskessel at verizon.net (Chris Kessel/Lou Doherty)
Date: Mon, 22 Jun 2009 19:26:45 -0800
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
Message-ID: <0KLO000KW6S0KYV1@vms173013.mailsrvcs.net>

Well, one of the gurus answered, so I feel a bit silly answering, but here's
my .02.

First make sure you know how the object is being used. There are a great
many POJOs that never live beyond the length of a single thread. They're
loaded from a DB, modified, and saved all within a single thread (as a
common example). They aren't shared so the concurrency concerns aren't a
problem. I simply javadoc them as thread contained at the very top so that
folks know they aren't concurrent safe.

For those items that need thread safety, figure out the concern. Is it just
publishing that's the issue or do you have multiple threads modifying it?
I've discovered I can get away with creating immutable classes frequently
and then, when a mod is needed, create a new immutable instance to replace
it rather than modifying the original. As long as you aren't creating masses
of objects, that works well. If you've passing a collection around, you can
get publishing for free with the concurrent safe collections.

It's the rare class that gets really tricky, usually a service with some
sort of state, like objects in a persistent queue that are going to be
called asynchronously with listeners.

When I read JCIP, I realize how horribly unsafe all my code I'd ever written
was :), but I also found I didn't need mass changes to my coding approach so
much as to think about how each class might be used from a threading
viewpoint. From there, only a fairly small set needed thread safety. JCIP
gave me the tools to understand what thread safe means and how to make those
classes safe.

Chris

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Ashley
Williams
Sent: Monday, June 22, 2009 12:21 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] concurrency newbie question

Hi,

After reading java concurrency in practice, I've now realize how little I
know after all these years so I'm trying to put that right. So as a first
step I would like to make a settings class, which is just a bunch of getters
and setters, a little more threadsafe and so I would appreciate any helpful
comments.


I think I am right in just using a final reference to an atomic wrapper for
the simple property types, but I'm unsure if I'm approaching the map
property correctly. In the code below I've tried to follow these guidelines
for the 'machines' field:

1. The getter should always return a copy.

2. The setter should replace the currently held list, rather than trying to
clear() then putAll() which can cause a race condition if another thread
gets in between the two operations.

3. The accessor getMachine(key) method effectively does a double check to
decide whether it needs to create the entry. The first check is against null
and the second is an implicit check during the call to putIfAbsent().

4. My first attempt didn't wrap the map with an atomic, instead the map was
declared directly as a field. I rejected this because the set method
involved calling clear() then putAll() which can cause a race condition if
another thread gets in between the two operations. Was I right to reject
this approach?


public final class StandardSettings {
	private final AtomicBoolean statusMessage;

	private final AtomicReference<ConcurrentHashMap<String,  
MachineConfig>> machines;

	public StandardSettings() {
		this.statusMessage = new AtomicBoolean(true);
		this.machines = new
AtomicReference<ConcurrentHashMap<String,  
MachineConfig>>(
				new ConcurrentHashMap<String,
MachineConfig>());
	}

// getter and setter for a boolean property

	public Boolean getStatusMessage() {
		return statusMessage.get();
	}

	public void setStatusMessage(Boolean statusMessage) {
		this.statusMessage.set(statusMessage);
	}

// getter and setter for map property

	public ConcurrentHashMap<String, MachineConfig> getMachines() {
		return new ConcurrentHashMap<String,
MachineConfig>(machines.get());
	}

	public void setMachines(ConcurrentHashMap<String, MachineConfig>
machines) {
		this.machines.set(machines);
	}

// access to the named map entry that creates that entry if it doesn't exist

	public MachineConfig getMachine(String name) {
		MachineConfig config = machines.get().get(name);

		if (config == null) {
			MachineConfig newValue = new MachineConfig(name);
			// another thread may have just added after our null
check
			MachineConfig oldValue =
machines.get().putIfAbsent(name, newValue);
			config = oldValue != null ? oldValue : newValue;

		}

		return config;
	}

}

Am I on the right track for making this class thread safe and if not how
should I be approaching the problem?

Many thanks
- Ashley Williams
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

__________ Information from ESET NOD32 Antivirus, version of virus signature
database 4179 (20090622) __________

The message was checked by ESET NOD32 Antivirus.

http://www.eset.com




From bazhenov at farpost.com  Tue Jun 23 08:06:54 2009
From: bazhenov at farpost.com (Denis Bazhenov)
Date: Tue, 23 Jun 2009 23:06:54 +1100
Subject: [concurrency-interest] Atomic assignment
In-Reply-To: <4A074853.3040101@briangoetz.com>
References: <NFBBKALFDCPFIDBNKAPCEEGGIBAA.davidcholmes@aapt.net.au>	<4A04414C.7060303@cytetech.com>	<19196d860905080750i52d9bc28q9f2b793bb8b51a40@mail.gmail.com>
	<4A044998.4020801@cytetech.com> <4A074853.3040101@briangoetz.com>
Message-ID: <F85DF787-0B7E-4C67-88B5-A157B5C9891C@farpost.com>

Is synchronization on 64-bit types required to force visibility  
guarantee?

As far as I understand, if new variable value is not depend on  
previous value (in other terms all I need is memory visibility and  
assignment atomicity) I can use volatile variables without  
synchronization. Is it correct, or I missed something?

Denis Bazhenov



On May 11, 2009, at 8:34 AM, Brian Goetz wrote:

> In general, the issue over word tearing for nonvolatile longs/ 
> doubles is kind of a red herring; word tearing would occur when the  
> variable is shared between threads, in which case, you should be  
> synchronizing anyway (otherwise you risk stale values.)  So there's  
> very little "special" about thread-safety for longs/doubles --  
> unless you are deliberately writing code with data races, in which  
> case there is just one more failure mode.
>
> Gregg Wonderly wrote:
>> Okay, it we actually just have the ++/-- not atomic issue, than I  
>> am okay with that because I don't suddenly have new, broken code.   
>> I looked around some more and ran the test code on that old issue  
>> on my dual core laptop and saw no failures.  But, I'm not sure  
>> after looking at that code whether it actually makes modifications  
>> in a way that would show a problem.
>> Gregg Wonderly
>> Sam Berlin wrote:
>>> My interpretation is that the scenario today is that a volatile  
>>> long/double is atomic.  A non-volatile long/double is not atomic.   
>>> And the RFE that was closed as will-not-fix was asking for all  
>>> access to long/double (even non-volatile) to be atomic.
>>>
>>> Sam
>>>
>>> On Fri, May 8, 2009 at 10:27 AM, Gregg Wonderly  
>>> <gregg at cytetech.com <mailto:gregg at cytetech.com>> wrote:
>>>
>>>    So will the compiler be changed to not allow volatile to exist on
>>>    double/long declarations since it does not work?  Or might  
>>> there be
>>>    a warning that volatile does not produce atomic results on all
>>>    statements that assign to or reference a double/long value?
>>>
>>>    Sigh...
>>>
>>>    Gregg Wonderly
>>>
>>>
>>>    David Holmes wrote:
>>>
>>>        Hi Mark,
>>>
>>>        That bug is (or became) a RFE for the spec to make all  
>>> accesses to
>>>        double/long atomic and that is not going to happen hence the
>>>        "will not fix".
>>>        There are a number of other bugs that pertain to atomic  
>>> access
>>>        to volatile
>>>        long/double eg: 4247780 which was fixed back in 1.2.2
>>>
>>>        Thanks
>>>        David Holmes
>>>
>>>            -----Original Message-----
>>>            From: concurrency-interest-bounces at cs.oswego.edu
>>>            <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>            [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>            <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>            Behalf Of Mark
>>>            Thornton
>>>            Sent: Friday, 8 May 2009 7:29 AM
>>>            To: concurrency-interest at cs.oswego.edu
>>>            <mailto:concurrency-interest at cs.oswego.edu>
>>>            Subject: [concurrency-interest] Atomic assignment
>>>
>>>
>>>
>>>            I was sure that the problem of (non)atomic assignment to
>>>            volatile longs
>>>            and doubles had been fixed, but this bug report suggests
>>>            otherwise:
>>>
>>>            http://bugs.sun.com/bugdatabase/view_bug.do? 
>>> bug_id=4023233
>>>
>>>            Anyone know for sure?
>>>
>>>            Mark Thornton
>>>
>>>            _______________________________________________
>>>            Concurrency-interest mailing list
>>>            Concurrency-interest at cs.oswego.edu
>>>            <mailto:Concurrency-interest at cs.oswego.edu>
>>>            http://cs.oswego.edu/mailman/listinfo/concurrency- 
>>> interest
>>>
>>>
>>>
>>>        _______________________________________________
>>>        Concurrency-interest mailing list
>>>        Concurrency-interest at cs.oswego.edu
>>>        <mailto:Concurrency-interest at cs.oswego.edu>
>>>        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>    _______________________________________________
>>>    Concurrency-interest mailing list
>>>    Concurrency-interest at cs.oswego.edu
>>>    <mailto:Concurrency-interest at cs.oswego.edu>
>>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Tue Jun 23 08:27:36 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 23 Jun 2009 22:27:36 +1000
Subject: [concurrency-interest] Atomic assignment
In-Reply-To: <F85DF787-0B7E-4C67-88B5-A157B5C9891C@farpost.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEGCICAA.davidcholmes@aapt.net.au>

Denis,

- synchronization (ie use of locks/monitors) gives mutual exclusion and
visibility.
- volatile gives visibility and atomic load/store for long/double
- the language gives atomic load/store for all other types

So if you're using 64-bit types and don't need mutual exclusion then
volatile will suffice.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Denis
> Bazhenov
> Sent: Tuesday, 23 June 2009 10:07 PM
> To: concurrency-interest at cs.oswego.edu
> Cc: Brian Goetz
> Subject: Re: [concurrency-interest] Atomic assignment
>
>
>
> Is synchronization on 64-bit types required to force visibility
> guarantee?
>
> As far as I understand, if new variable value is not depend on
> previous value (in other terms all I need is memory visibility and
> assignment atomicity) I can use volatile variables without
> synchronization. Is it correct, or I missed something?
>
> Denis Bazhenov
>
>
>
> On May 11, 2009, at 8:34 AM, Brian Goetz wrote:
>
> > In general, the issue over word tearing for nonvolatile longs/
> > doubles is kind of a red herring; word tearing would occur when the
> > variable is shared between threads, in which case, you should be
> > synchronizing anyway (otherwise you risk stale values.)  So there's
> > very little "special" about thread-safety for longs/doubles --
> > unless you are deliberately writing code with data races, in which
> > case there is just one more failure mode.
> >
> > Gregg Wonderly wrote:
> >> Okay, it we actually just have the ++/-- not atomic issue, than I
> >> am okay with that because I don't suddenly have new, broken code.
> >> I looked around some more and ran the test code on that old issue
> >> on my dual core laptop and saw no failures.  But, I'm not sure
> >> after looking at that code whether it actually makes modifications
> >> in a way that would show a problem.
> >> Gregg Wonderly
> >> Sam Berlin wrote:
> >>> My interpretation is that the scenario today is that a volatile
> >>> long/double is atomic.  A non-volatile long/double is not atomic.
> >>> And the RFE that was closed as will-not-fix was asking for all
> >>> access to long/double (even non-volatile) to be atomic.
> >>>
> >>> Sam
> >>>
> >>> On Fri, May 8, 2009 at 10:27 AM, Gregg Wonderly
> >>> <gregg at cytetech.com <mailto:gregg at cytetech.com>> wrote:
> >>>
> >>>    So will the compiler be changed to not allow volatile to exist on
> >>>    double/long declarations since it does not work?  Or might
> >>> there be
> >>>    a warning that volatile does not produce atomic results on all
> >>>    statements that assign to or reference a double/long value?
> >>>
> >>>    Sigh...
> >>>
> >>>    Gregg Wonderly
> >>>
> >>>
> >>>    David Holmes wrote:
> >>>
> >>>        Hi Mark,
> >>>
> >>>        That bug is (or became) a RFE for the spec to make all
> >>> accesses to
> >>>        double/long atomic and that is not going to happen hence the
> >>>        "will not fix".
> >>>        There are a number of other bugs that pertain to atomic
> >>> access
> >>>        to volatile
> >>>        long/double eg: 4247780 which was fixed back in 1.2.2
> >>>
> >>>        Thanks
> >>>        David Holmes
> >>>
> >>>            -----Original Message-----
> >>>            From: concurrency-interest-bounces at cs.oswego.edu
> >>>            <mailto:concurrency-interest-bounces at cs.oswego.edu>
> >>>            [mailto:concurrency-interest-bounces at cs.oswego.edu
> >>>            <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
> >>>            Behalf Of Mark
> >>>            Thornton
> >>>            Sent: Friday, 8 May 2009 7:29 AM
> >>>            To: concurrency-interest at cs.oswego.edu
> >>>            <mailto:concurrency-interest at cs.oswego.edu>
> >>>            Subject: [concurrency-interest] Atomic assignment
> >>>
> >>>
> >>>
> >>>            I was sure that the problem of (non)atomic assignment to
> >>>            volatile longs
> >>>            and doubles had been fixed, but this bug report suggests
> >>>            otherwise:
> >>>
> >>>            http://bugs.sun.com/bugdatabase/view_bug.do?
> >>> bug_id=4023233
> >>>
> >>>            Anyone know for sure?
> >>>
> >>>            Mark Thornton
> >>>
> >>>            _______________________________________________
> >>>            Concurrency-interest mailing list
> >>>            Concurrency-interest at cs.oswego.edu
> >>>            <mailto:Concurrency-interest at cs.oswego.edu>
> >>>            http://cs.oswego.edu/mailman/listinfo/concurrency-
> >>> interest
> >>>
> >>>
> >>>
> >>>        _______________________________________________
> >>>        Concurrency-interest mailing list
> >>>        Concurrency-interest at cs.oswego.edu
> >>>        <mailto:Concurrency-interest at cs.oswego.edu>
> >>>        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>>
> >>>
> >>>    _______________________________________________
> >>>    Concurrency-interest mailing list
> >>>    Concurrency-interest at cs.oswego.edu
> >>>    <mailto:Concurrency-interest at cs.oswego.edu>
> >>>    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From tim at peierls.net  Tue Jun 23 09:40:35 2009
From: tim at peierls.net (Tim Peierls)
Date: Tue, 23 Jun 2009 09:40:35 -0400
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <0KLO000KW6S0KYV1@vms173013.mailsrvcs.net>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<0KLO000KW6S0KYV1@vms173013.mailsrvcs.net>
Message-ID: <63b4e4050906230640y6528e143w2be3a77aab5313d5@mail.gmail.com>

Excellent advice -- not silly at all!  A real guru would have included this
broader context from the start. ;-)
Minor point: For classes that must be confined to a single thread, rather
than (only) putting a prose description like "thread contained" in the
javadoc comments, consider in addition annotating such classes with
@NotThreadSafe (
http://jcip.net/annotations/doc/net/jcip/annotations/NotThreadSafe.html).

The only way @NotThreadSafe classes can be used correctly is through "serial
thread confinement", i.e., confinement of an object to a single thread at a
time with any hand-off of the object between threads restricted to *
happens-before* relationships such as those described in
http://java.sun.com/javase/6/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility.
(Serial thread confinement trivially includes simple confinement of an
object to a single thread for the lifetime of the object.)

Incidentally, there is no JCiP annotation for "effectively immutable"
classes, in which all mutative operations *happen-before* the object is
published and multiple threads may perform read-only access after (safe)
publication. Maybe there should be one.

--tim

On Mon, Jun 22, 2009 at 11:26 PM, Chris Kessel/Lou Doherty <
chriskessel at verizon.net> wrote:

> Well, one of the gurus answered, so I feel a bit silly answering, but
> here's
> my .02.
>
> First make sure you know how the object is being used. There are a great
> many POJOs that never live beyond the length of a single thread. They're
> loaded from a DB, modified, and saved all within a single thread (as a
> common example). They aren't shared so the concurrency concerns aren't a
> problem. I simply javadoc them as thread contained at the very top so that
> folks know they aren't concurrent safe.
>
> For those items that need thread safety, figure out the concern. Is it just
> publishing that's the issue or do you have multiple threads modifying it?
> I've discovered I can get away with creating immutable classes frequently
> and then, when a mod is needed, create a new immutable instance to replace
> it rather than modifying the original. As long as you aren't creating
> masses
> of objects, that works well. If you've passing a collection around, you can
> get publishing for free with the concurrent safe collections.
>
> It's the rare class that gets really tricky, usually a service with some
> sort of state, like objects in a persistent queue that are going to be
> called asynchronously with listeners.
>
> When I read JCIP, I realize how horribly unsafe all my code I'd ever
> written
> was :), but I also found I didn't need mass changes to my coding approach
> so
> much as to think about how each class might be used from a threading
> viewpoint. From there, only a fairly small set needed thread safety. JCIP
> gave me the tools to understand what thread safe means and how to make
> those
> classes safe.
>
> Chris
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Ashley
> Williams
> Sent: Monday, June 22, 2009 12:21 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] concurrency newbie question
>
> Hi,
>
> After reading java concurrency in practice, I've now realize how little I
> know after all these years so I'm trying to put that right. So as a first
> step I would like to make a settings class, which is just a bunch of
> getters
> and setters, a little more threadsafe and so I would appreciate any helpful
> comments.
>
>
> I think I am right in just using a final reference to an atomic wrapper for
> the simple property types, but I'm unsure if I'm approaching the map
> property correctly. In the code below I've tried to follow these guidelines
> for the 'machines' field:
>
> 1. The getter should always return a copy.
>
> 2. The setter should replace the currently held list, rather than trying to
> clear() then putAll() which can cause a race condition if another thread
> gets in between the two operations.
>
> 3. The accessor getMachine(key) method effectively does a double check to
> decide whether it needs to create the entry. The first check is against
> null
> and the second is an implicit check during the call to putIfAbsent().
>
> 4. My first attempt didn't wrap the map with an atomic, instead the map was
> declared directly as a field. I rejected this because the set method
> involved calling clear() then putAll() which can cause a race condition if
> another thread gets in between the two operations. Was I right to reject
> this approach?
>
>
> public final class StandardSettings {
>        private final AtomicBoolean statusMessage;
>
>        private final AtomicReference<ConcurrentHashMap<String,
> MachineConfig>> machines;
>
>        public StandardSettings() {
>                this.statusMessage = new AtomicBoolean(true);
>                this.machines = new
> AtomicReference<ConcurrentHashMap<String,
> MachineConfig>>(
>                                new ConcurrentHashMap<String,
> MachineConfig>());
>        }
>
> // getter and setter for a boolean property
>
>        public Boolean getStatusMessage() {
>                return statusMessage.get();
>        }
>
>        public void setStatusMessage(Boolean statusMessage) {
>                this.statusMessage.set(statusMessage);
>        }
>
> // getter and setter for map property
>
>        public ConcurrentHashMap<String, MachineConfig> getMachines() {
>                return new ConcurrentHashMap<String,
> MachineConfig>(machines.get());
>        }
>
>        public void setMachines(ConcurrentHashMap<String, MachineConfig>
> machines) {
>                this.machines.set(machines);
>        }
>
> // access to the named map entry that creates that entry if it doesn't
> exist
>
>        public MachineConfig getMachine(String name) {
>                MachineConfig config = machines.get().get(name);
>
>                if (config == null) {
>                        MachineConfig newValue = new MachineConfig(name);
>                        // another thread may have just added after our null
> check
>                        MachineConfig oldValue =
> machines.get().putIfAbsent(name, newValue);
>                        config = oldValue != null ? oldValue : newValue;
>
>                }
>
>                return config;
>        }
>
> }
>
> Am I on the right track for making this class thread safe and if not how
> should I be approaching the problem?
>
> Many thanks
> - Ashley Williams
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> __________ Information from ESET NOD32 Antivirus, version of virus
> signature
> database 4179 (20090622) __________
>
> The message was checked by ESET NOD32 Antivirus.
>
> http://www.eset.com
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/608c5615/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 09:47:07 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 14:47:07 +0100
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
Message-ID: <F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>

Hi Tim,

Just to give you a little more background, the settings class supports  
configuration and is designed to be exported and imported
to a properties file. To do this I have a piece of code that is able  
to parse a java bean such as this one and uses introspection to
call its getters and setters at the right time. This happens on a  
timer. This also explains why I need a setter for the map property,
since this is used to assign a newly created map based on the  
properties file contents.

Meanwhile the rest of the code is able to consult the settings at any  
time and therefore I need to make it threadsafe. I've pasted
a fuller version of the class below. I don't need an interface in this  
situation since there is no reason to create any alternative
implementations.

According to the feedback I got from Marcelo, I've changed from  
atomics to volatiles which instantly looks more readable -
but was this a wise decision, since I no longer have any final fields  
and am therefore at risk of having a partially
constructed object? The implications of this is that the defaults  
specified in the constructor won't be assigned in time and
would be a problem were I to make my defaults more meaningful.

So: "never want partially constructed objects -> always use final  
field modifier -> have to use atomics"???

- Ashley


@StandardProjectComponent
@ThreadSafe
public final class StandardSettings {
	/**
	 * See {@link #getStatusWindow()}.
	 */
	private volatile Boolean statusWindow;

	/**
	 * See {@link #getQuiet()}.
	 */
	private volatile Boolean quiet;

	/**
	 * See {@link #getLevel()}.
	 */
	private volatile Level level;

	/**
	 * See {@link #getStatusMessage()}.
	 */
	private volatile Boolean statusMessage;

	/**
	 * See {@link #getCompileSource()}.
	 */
	private volatile String compileSource;

	/**
	 * See {@link #getCompileTarget()}.
	 */
	private volatile String compileTarget;

	/**
	 * See {@link #getCompileBootclasspath()}.
	 */
	private volatile String compileBootclasspath;

	/**
	 * See {@link #getCompileExtdirs()}.
	 */
	private volatile String compileExtdirs;

	/**
	 * See {@link #getCompileMemory()}.
	 */
	private volatile String compileMemory;

	/**
	 * See {@link #getProfileHome()}.
	 */
	private volatile File profileHome;

	/**
	 * See {@link #getProfileUrl()}.
	 */
	private volatile String profileUrl;

	/**
	 * See {@link #getMachine(String)}.
	 */
	private volatile ConcurrentHashMap<String, MachineConfig> machines;

	/**
	 * Sets up default values.
	 */
	public MySettings() {
		this.statusWindow = false;
		this.quiet = true;
		this.statusMessage = true;
		this.level = Level.INFO;
		this.compileMemory = null;
		this.compileSource = null;
		this.compileTarget = null;
		this.compileBootclasspath = null;
		this.compileExtdirs = null;
		this.profileHome = null;
		this.profileUrl = null;
		this.machines = new ConcurrentHashMap<String, MachineConfig>();
	}

	/**
	 * Returns the machine configuration with the given name, creating it  
if it
	 * doesn't exist.
	 *
	 * @param name
	 * @return
	 */
	public MachineConfig getMachine(String name) {
		MachineConfig config = machines.get(name);

		if (config == null) {
			MachineConfig newValue = new MachineConfig(name);
			// another thread may have just added after our null check
			MachineConfig oldValue = machines.putIfAbsent(name, newValue);
			config = oldValue != null ? oldValue : newValue;

		}

		return config;
	}

	/**
	 * Returns a hash map that is a copy of the internal map.
	 *
	 * @return
	 */
	public ConcurrentHashMap<String, MachineConfig> getMachines() {
		return new ConcurrentHashMap<String, MachineConfig>(machines);
	}

	public void setMachines(ConcurrentHashMap<String, MachineConfig>  
machines) {
		this.machines = machines;
	}

	public MachineConfig getJunitMachine() {
		return getMachine("junit");
	}

	public MachineConfig getMainMachine() {
		return getMachine("main");
	}

	public Boolean getStatusWindow() {
		return statusWindow;
	}

	public void setStatusWindow(Boolean statusWindow) {
		this.statusWindow = statusWindow;
	}

	public Boolean getQuiet() {
		return quiet;
	}

	public void setQuiet(Boolean quiet) {
		this.quiet = quiet;
	}

	public Level getLevel() {
		return level;
	}

	public void setLevel(Level level) {
		this.level = level;
	}

	public Boolean getStatusMessage() {
		return statusMessage;
	}

	public void setStatusMessage(Boolean statusMessage) {
		this.statusMessage = statusMessage;
	}

	public String getCompileSource() {
		return compileSource;
	}

	public void setCompileSource(String compileSource) {
		this.compileSource = compileSource;
	}

	public String getCompileTarget() {
		return compileTarget;
	}

	public void setCompileTarget(String compileTarget) {
		this.compileTarget = compileTarget;
	}

	public String getCompileBootclasspath() {
		return compileBootclasspath;
	}

	public void setCompileBootclasspath(String compileBootclasspath) {
		this.compileBootclasspath = compileBootclasspath;
	}

	public String getCompileExtdirs() {
		return compileExtdirs;
	}

	public void setCompileExtdirs(String compileExtdirs) {
		this.compileExtdirs = compileExtdirs;
	}

	public String getCompileMemory() {
		return compileMemory;
	}

	public void setCompileMemory(String compileMemory) {
		this.compileMemory = compileMemory;
	}

	public File getProfileHome() {
		return profileHome;
	}

	public void setProfileHome(File profileHome) {
		this.profileHome = profileHome;
	}

	public String getProfileUrl() {
		return profileUrl;
	}

	public void setProfileUrl(String profileUrl) {
		this.profileUrl = profileUrl;
	}

}

On 23 Jun 2009, at 00:36, Tim Peierls wrote:

> Maybe we didn't emphasize this enough in JCiP, but it's almost  
> always best to start with something simple and correct and then move  
> to more complex designs only if it's clear that you really need to.
>
> Your example looks somewhat artificial, but if I were to take it  
> literally, I would start with something like this.
>
> public interface StandardSettings {
>     boolean isStatusMessage();
>     void setStatusMessage(boolean statusMessage);
>     ConcurrentMap<String, MachineConfig> getMachines();
>     MachineConfig get(String name);
> }
>
> @ThreadSafe
> public final class StandardSettingsImpl implements StandardSettings {
>
>        @GuardedBy("this") private boolean statusMessage = true;
>
>        private final ConcurrentMap<String, MachineConfig>> machines =
>            new ConcurrentHashMap<String, MachineConfig>();
>
>
>        public synchronized boolean isStatusMessage() {
>            return statusMessage;
>        }
>
>        public synchronized void setStatusMessage(boolean  
> statusMessage) {
>            this.statusMessage = statusMessage;
>        }
>
>        public ConcurrentMap<String, MachineConfig> getMachines() {
>            return machines;
>        }
>
>        public MachineConfig getMachine(String name) {
>            return machines.get(name);
>        }
> }
>
> Prefer the interface type ConcurrentMap (or just Map) in APIs, only  
> using concrete types like ConcurrentHashMap in initializers.
>
> If you're willing to expose the map from machine name to machine  
> config, you don't need a setMachines method at all. See chapter 4 of  
> JCiP for variations on this theme.
>
> Use the JCiP annotations (or similar comments) to document your  
> concurrency policy.
>
> Don't be shy about using simple synchronization.
>
> --tim
>
>
>
> On Mon, Jun 22, 2009 at 4:21 PM, Ashley Williams <ashpublic at mac.com>  
> wrote:
> Hi,
>
> After reading java concurrency in practice, I've now realize how  
> little I know after all these years so I'm trying to put that
> right. So as a first step I would like to make a settings class,  
> which is just a bunch of getters and setters, a little more
> threadsafe and so I would appreciate any helpful comments.
>
>
> I think I am right in just using a final reference to an atomic
> wrapper for the simple property types, but I'm unsure if I'm  
> approaching the map property correctly. In the code below
> I've tried to follow these guidelines for the 'machines' field:
>
> 1. The getter should always return a copy.
>
> 2. The setter should replace the currently held list, rather than  
> trying to clear() then putAll() which can cause a race condition
> if another thread gets in between the two operations.
>
> 3. The accessor getMachine(key) method effectively does a double  
> check to decide whether it needs to create the entry. The
> first check is against null and the second is an implicit check  
> during the call to putIfAbsent().
>
> 4. My first attempt didn't wrap the map with an atomic, instead the  
> map was declared directly as a field. I rejected this because
> the set method involved calling clear() then putAll() which can  
> cause a race condition
> if another thread gets in between the two operations. Was I right to  
> reject this approach?
>
>
> public final class StandardSettings {
>        private final AtomicBoolean statusMessage;
>
>        private final AtomicReference<ConcurrentHashMap<String,  
> MachineConfig>> machines;
>
>        public StandardSettings() {
>                this.statusMessage = new AtomicBoolean(true);
>                this.machines = new  
> AtomicReference<ConcurrentHashMap<String, MachineConfig>>(
>                                new ConcurrentHashMap<String,  
> MachineConfig>());
>        }
>
> // getter and setter for a boolean property
>
>        public Boolean getStatusMessage() {
>                return statusMessage.get();
>        }
>
>        public void setStatusMessage(Boolean statusMessage) {
>                this.statusMessage.set(statusMessage);
>        }
>
> // getter and setter for map property
>
>        public ConcurrentHashMap<String, MachineConfig> getMachines() {
>                return new ConcurrentHashMap<String,  
> MachineConfig>(machines.get());
>        }
>
>        public void setMachines(ConcurrentHashMap<String,  
> MachineConfig> machines) {
>                this.machines.set(machines);
>        }
>
> // access to the named map entry that creates that entry if it  
> doesn't exist
>
>        public MachineConfig getMachine(String name) {
>                MachineConfig config = machines.get().get(name);
>
>                if (config == null) {
>                        MachineConfig newValue = new  
> MachineConfig(name);
>                        // another thread may have just added after  
> our null check
>                        MachineConfig oldValue =  
> machines.get().putIfAbsent(name, newValue);
>                        config = oldValue != null ? oldValue :  
> newValue;
>
>                }
>
>                return config;
>        }
>
> }
>
> Am I on the right track for making this class thread safe and if not  
> how should I be approaching the problem?
>
> Many thanks
> - Ashley Williams
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/0bf31d2b/attachment-0001.html>

From tim at peierls.net  Tue Jun 23 09:58:03 2009
From: tim at peierls.net (Tim Peierls)
Date: Tue, 23 Jun 2009 09:58:03 -0400
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
Message-ID: <63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>

Consider using the builder pattern so that your StandardSettings class can
be immutable. See Effective Java, 2nd edition, Item 2. Then you can just
provide the settings with a volatile reference to a StandardSettings
instance.
--tim

On Tue, Jun 23, 2009 at 9:47 AM, Ashley Williams <ashpublic at mac.com> wrote:

> Hi Tim,
> Just to give you a little more background, the settings class supports
> configuration and is designed to be exported and imported
> to a properties file. To do this I have a piece of code that is able to
> parse a java bean such as this one and uses introspection to
> call its getters and setters at the right time. This happens on a timer.
> This also explains why I need a setter for the map property,
> since this is used to assign a newly created map based on the properties
> file contents.
>
> Meanwhile the rest of the code is able to consult the settings at any time
> and therefore I need to make it threadsafe. I've pasted
> a fuller version of the class below. I don't need an interface in this
> situation since there is no reason to create any alternative
> implementations.
>
> According to the feedback I got from Marcelo, I've changed from atomics to
> volatiles which instantly looks more readable -
> but was this a wise decision, since I no longer have any final fields and
> am therefore at risk of having a partially
> constructed object? The implications of this is that the defaults specified
> in the constructor won't be assigned in time and
> would be a problem were I to make my defaults more meaningful.
>
> So: "never want partially constructed objects -> always use final field
> modifier -> have to use atomics"???
>
> - Ashley
>
>
> @StandardProjectComponent
> @ThreadSafe
> public final class StandardSettings {
> /**
>  * See {@link #getStatusWindow()}.
>  */
> private volatile Boolean statusWindow;
>
> /**
>  * See {@link #getQuiet()}.
>  */
> private volatile Boolean quiet;
>
> /**
>  * See {@link #getLevel()}.
>  */
> private volatile Level level;
>
> /**
>  * See {@link #getStatusMessage()}.
>  */
> private volatile Boolean statusMessage;
>
> /**
>  * See {@link #getCompileSource()}.
>  */
> private volatile String compileSource;
>
> /**
>  * See {@link #getCompileTarget()}.
>  */
> private volatile String compileTarget;
>
> /**
>  * See {@link #getCompileBootclasspath()}.
>  */
> private volatile String compileBootclasspath;
>
> /**
>  * See {@link #getCompileExtdirs()}.
>  */
> private volatile String compileExtdirs;
>
> /**
>  * See {@link #getCompileMemory()}.
>  */
> private volatile String compileMemory;
>
> /**
>  * See {@link #getProfileHome()}.
>  */
> private volatile File profileHome;
>
> /**
>  * See {@link #getProfileUrl()}.
>  */
> private volatile String profileUrl;
>
> /**
>  * See {@link #getMachine(String)}.
>  */
> private volatile ConcurrentHashMap<String, MachineConfig> machines;
>
> /**
>  * Sets up default values.
>  */
> public MySettings() {
> this.statusWindow = false;
> this.quiet = true;
> this.statusMessage = true;
> this.level = Level.INFO;
> this.compileMemory = null;
> this.compileSource = null;
> this.compileTarget = null;
> this.compileBootclasspath = null;
> this.compileExtdirs = null;
> this.profileHome = null;
> this.profileUrl = null;
> this.machines = new ConcurrentHashMap<String, MachineConfig>();
> }
>
> /**
>  * Returns the machine configuration with the given name, creating it if
> it
>  * doesn't exist.
>  *
>  * @param name
>  * @return
>  */
> public MachineConfig getMachine(String name) {
> MachineConfig config = machines.get(name);
>
> if (config == null) {
> MachineConfig newValue = new MachineConfig(name);
> // another thread may have just added after our null check
> MachineConfig oldValue = machines.putIfAbsent(name, newValue);
> config = oldValue != null ? oldValue : newValue;
>
> }
>
> return config;
> }
>
> /**
>  * Returns a hash map that is a copy of the internal map.
>  *
>  * @return
>  */
> public ConcurrentHashMap<String, MachineConfig> getMachines() {
> return new ConcurrentHashMap<String, MachineConfig>(machines);
> }
>
> public void setMachines(ConcurrentHashMap<String, MachineConfig> machines)
> {
> this.machines = machines;
> }
>
> public MachineConfig getJunitMachine() {
> return getMachine("junit");
> }
>
> public MachineConfig getMainMachine() {
> return getMachine("main");
> }
>
> public Boolean getStatusWindow() {
> return statusWindow;
> }
>
> public void setStatusWindow(Boolean statusWindow) {
> this.statusWindow = statusWindow;
> }
>
> public Boolean getQuiet() {
> return quiet;
> }
>
> public void setQuiet(Boolean quiet) {
> this.quiet = quiet;
> }
>
> public Level getLevel() {
> return level;
> }
>
> public void setLevel(Level level) {
> this.level = level;
> }
>
> public Boolean getStatusMessage() {
> return statusMessage;
> }
>
> public void setStatusMessage(Boolean statusMessage) {
> this.statusMessage = statusMessage;
> }
>
> public String getCompileSource() {
> return compileSource;
> }
>
> public void setCompileSource(String compileSource) {
> this.compileSource = compileSource;
> }
>
> public String getCompileTarget() {
> return compileTarget;
> }
>
> public void setCompileTarget(String compileTarget) {
> this.compileTarget = compileTarget;
> }
>
> public String getCompileBootclasspath() {
> return compileBootclasspath;
> }
>
> public void setCompileBootclasspath(String compileBootclasspath) {
> this.compileBootclasspath = compileBootclasspath;
> }
>
> public String getCompileExtdirs() {
> return compileExtdirs;
> }
>
> public void setCompileExtdirs(String compileExtdirs) {
> this.compileExtdirs = compileExtdirs;
> }
>
> public String getCompileMemory() {
> return compileMemory;
> }
>
> public void setCompileMemory(String compileMemory) {
> this.compileMemory = compileMemory;
> }
>
> public File getProfileHome() {
> return profileHome;
> }
>
> public void setProfileHome(File profileHome) {
> this.profileHome = profileHome;
> }
>
> public String getProfileUrl() {
> return profileUrl;
> }
>
> public void setProfileUrl(String profileUrl) {
> this.profileUrl = profileUrl;
> }
>
> }
>
> On 23 Jun 2009, at 00:36, Tim Peierls wrote:
>
> Maybe we didn't emphasize this enough in JCiP, but it's almost always best
> to start with something simple and correct and then move to more complex
> designs only if it's clear that you really need to.
> Your example looks somewhat artificial, but if I were to take it literally,
> I would start with something like this.
>
> public interface StandardSettings {
>     boolean isStatusMessage();
>     void setStatusMessage(boolean statusMessage);
>     ConcurrentMap<String, MachineConfig> getMachines();
>     MachineConfig get(String name);
> }
>
> @ThreadSafe
> public final class StandardSettingsImpl implements StandardSettings {
>
>        @GuardedBy("this") private boolean statusMessage = true;
>
>        private final ConcurrentMap<String, MachineConfig>> machines =
>            new ConcurrentHashMap<String, MachineConfig>();
>
>
>        public synchronized boolean isStatusMessage() {
>            return statusMessage;
>        }
>
>        public synchronized void setStatusMessage(boolean statusMessage) {
>            this.statusMessage = statusMessage;
>        }
>
>        public ConcurrentMap<String, MachineConfig> getMachines() {
>            return machines;
>        }
>
>        public MachineConfig getMachine(String name) {
>            return machines.get(name);
>        }
> }
>
> Prefer the interface type ConcurrentMap (or just Map) in APIs, only using
> concrete types like ConcurrentHashMap in initializers.
>
> If you're willing to expose the map from machine name to machine config,
> you don't need a setMachines method at all. See chapter 4 of JCiP for
> variations on this theme.
>
> Use the JCiP annotations (or similar comments) to document your concurrency
> policy.
>
> Don't be shy about using simple synchronization.
>
> --tim
>
>
>
> On Mon, Jun 22, 2009 at 4:21 PM, Ashley Williams <ashpublic at mac.com>wrote:
>
>> Hi,
>>
>> After reading java concurrency in practice, I've now realize how little I
>> know after all these years so I'm trying to put that
>> right. So as a first step I would like to make a settings class, which is
>> just a bunch of getters and setters, a little more
>> threadsafe and so I would appreciate any helpful comments.
>>
>>
>> I think I am right in just using a final reference to an atomic
>> wrapper for the simple property types, but I'm unsure if I'm approaching
>> the map property correctly. In the code below
>> I've tried to follow these guidelines for the 'machines' field:
>>
>> 1. The getter should always return a copy.
>>
>> 2. The setter should replace the currently held list, rather than trying
>> to clear() then putAll() which can cause a race condition
>> if another thread gets in between the two operations.
>>
>> 3. The accessor getMachine(key) method effectively does a double check to
>> decide whether it needs to create the entry. The
>> first check is against null and the second is an implicit check during the
>> call to putIfAbsent().
>>
>> 4. My first attempt didn't wrap the map with an atomic, instead the map
>> was declared directly as a field. I rejected this because
>> the set method involved calling clear() then putAll() which can cause a
>> race condition
>> if another thread gets in between the two operations. Was I right to
>> reject this approach?
>>
>>
>> public final class StandardSettings {
>>        private final AtomicBoolean statusMessage;
>>
>>        private final AtomicReference<ConcurrentHashMap<String,
>> MachineConfig>> machines;
>>
>>        public StandardSettings() {
>>                this.statusMessage = new AtomicBoolean(true);
>>                this.machines = new
>> AtomicReference<ConcurrentHashMap<String, MachineConfig>>(
>>                                new ConcurrentHashMap<String,
>> MachineConfig>());
>>        }
>>
>> // getter and setter for a boolean property
>>
>>        public Boolean getStatusMessage() {
>>                return statusMessage.get();
>>        }
>>
>>        public void setStatusMessage(Boolean statusMessage) {
>>                this.statusMessage.set(statusMessage);
>>        }
>>
>> // getter and setter for map property
>>
>>        public ConcurrentHashMap<String, MachineConfig> getMachines() {
>>                return new ConcurrentHashMap<String,
>> MachineConfig>(machines.get());
>>        }
>>
>>        public void setMachines(ConcurrentHashMap<String, MachineConfig>
>> machines) {
>>                this.machines.set(machines);
>>        }
>>
>> // access to the named map entry that creates that entry if it doesn't
>> exist
>>
>>        public MachineConfig getMachine(String name) {
>>                MachineConfig config = machines.get().get(name);
>>
>>                if (config == null) {
>>                        MachineConfig newValue = new MachineConfig(name);
>>                        // another thread may have just added after our
>> null check
>>                        MachineConfig oldValue =
>> machines.get().putIfAbsent(name, newValue);
>>                        config = oldValue != null ? oldValue : newValue;
>>
>>                }
>>
>>                return config;
>>        }
>>
>> }
>>
>> Am I on the right track for making this class thread safe and if not how
>> should I be approaching the problem?
>>
>> Many thanks
>> - Ashley Williams
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/86b2dae6/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 10:25:45 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 15:25:45 +0100
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
Message-ID: <AFF5A18B-9A15-4621-A920-0475E1604ECB@mac.com>

Unfortunately that isn't an option for me, firstly because the code  
that loads and saves this class needs
to assume a bean-style interface rather than an intermediate Builder  
class, as it is part of a generic library
that others may use.

Also I've only included a few of the system wide settings there are  
potentially many more and therefore
it would be wasteful that somebody who just wants to change one of the  
dozens of settings
causes a brand new object to be created.

I'm open to the fact that I'm not yet thinking correctly when it comes  
to concurrency ;) but the settings class
I have seems to be fundamentally mutable in nature.

On 23 Jun 2009, at 14:58, Tim Peierls wrote:

> Consider using the builder pattern so that your StandardSettings  
> class can be immutable. See Effective Java, 2nd edition, Item 2.  
> Then you can just provide the settings with a volatile reference to  
> a StandardSettings instance.
>
> --tim
>
> On Tue, Jun 23, 2009 at 9:47 AM, Ashley Williams <ashpublic at mac.com>  
> wrote:
> Hi Tim,
>
> Just to give you a little more background, the settings class  
> supports configuration and is designed to be exported and imported
> to a properties file. To do this I have a piece of code that is able  
> to parse a java bean such as this one and uses introspection to
> call its getters and setters at the right time. This happens on a  
> timer. This also explains why I need a setter for the map property,
> since this is used to assign a newly created map based on the  
> properties file contents.
>
> Meanwhile the rest of the code is able to consult the settings at  
> any time and therefore I need to make it threadsafe. I've pasted
> a fuller version of the class below. I don't need an interface in  
> this situation since there is no reason to create any alternative
> implementations.
>
> According to the feedback I got from Marcelo, I've changed from  
> atomics to volatiles which instantly looks more readable -
> but was this a wise decision, since I no longer have any final  
> fields and am therefore at risk of having a partially
> constructed object? The implications of this is that the defaults  
> specified in the constructor won't be assigned in time and
> would be a problem were I to make my defaults more meaningful.
>
> So: "never want partially constructed objects -> always use final  
> field modifier -> have to use atomics"???
>
> - Ashley
>
>
> @StandardProjectComponent
> @ThreadSafe
> public final class StandardSettings {
> 	/**
> 	 * See {@link #getStatusWindow()}.
> 	 */
> 	private volatile Boolean statusWindow;
>
> 	/**
> 	 * See {@link #getQuiet()}.
> 	 */
> 	private volatile Boolean quiet;
>
> 	/**
> 	 * See {@link #getLevel()}.
> 	 */
> 	private volatile Level level;
>
> 	/**
> 	 * See {@link #getStatusMessage()}.
> 	 */
> 	private volatile Boolean statusMessage;
>
> 	/**
> 	 * See {@link #getCompileSource()}.
> 	 */
> 	private volatile String compileSource;
>
> 	/**
> 	 * See {@link #getCompileTarget()}.
> 	 */
> 	private volatile String compileTarget;
>
> 	/**
> 	 * See {@link #getCompileBootclasspath()}.
> 	 */
> 	private volatile String compileBootclasspath;
>
> 	/**
> 	 * See {@link #getCompileExtdirs()}.
> 	 */
> 	private volatile String compileExtdirs;
>
> 	/**
> 	 * See {@link #getCompileMemory()}.
> 	 */
> 	private volatile String compileMemory;
>
> 	/**
> 	 * See {@link #getProfileHome()}.
> 	 */
> 	private volatile File profileHome;
>
> 	/**
> 	 * See {@link #getProfileUrl()}.
> 	 */
> 	private volatile String profileUrl;
>
> 	/**
> 	 * See {@link #getMachine(String)}.
> 	 */
> 	private volatile ConcurrentHashMap<String, MachineConfig> machines;
>
> 	/**
> 	 * Sets up default values.
> 	 */
> 	public MySettings() {
> 		this.statusWindow = false;
> 		this.quiet = true;
> 		this.statusMessage = true;
> 		this.level = Level.INFO;
> 		this.compileMemory = null;
> 		this.compileSource = null;
> 		this.compileTarget = null;
> 		this.compileBootclasspath = null;
> 		this.compileExtdirs = null;
> 		this.profileHome = null;
> 		this.profileUrl = null;
> 		this.machines = new ConcurrentHashMap<String, MachineConfig>();
> 	}
>
> 	/**
> 	 * Returns the machine configuration with the given name, creating  
> it if it
> 	 * doesn't exist.
> 	 *
> 	 * @param name
> 	 * @return
> 	 */
> 	public MachineConfig getMachine(String name) {
> 		MachineConfig config = machines.get(name);
>
> 		if (config == null) {
> 			MachineConfig newValue = new MachineConfig(name);
> 			// another thread may have just added after our null check
> 			MachineConfig oldValue = machines.putIfAbsent(name, newValue);
> 			config = oldValue != null ? oldValue : newValue;
>
> 		}
>
> 		return config;
> 	}
>
> 	/**
> 	 * Returns a hash map that is a copy of the internal map.
> 	 *
> 	 * @return
> 	 */
> 	public ConcurrentHashMap<String, MachineConfig> getMachines() {
> 		return new ConcurrentHashMap<String, MachineConfig>(machines);
> 	}
>
> 	public void setMachines(ConcurrentHashMap<String, MachineConfig>  
> machines) {
> 		this.machines = machines;
> 	}
>
> 	public MachineConfig getJunitMachine() {
> 		return getMachine("junit");
> 	}
>
> 	public MachineConfig getMainMachine() {
> 		return getMachine("main");
> 	}
>
> 	public Boolean getStatusWindow() {
> 		return statusWindow;
> 	}
>
> 	public void setStatusWindow(Boolean statusWindow) {
> 		this.statusWindow = statusWindow;
> 	}
>
> 	public Boolean getQuiet() {
> 		return quiet;
> 	}
>
> 	public void setQuiet(Boolean quiet) {
> 		this.quiet = quiet;
> 	}
>
> 	public Level getLevel() {
> 		return level;
> 	}
>
> 	public void setLevel(Level level) {
> 		this.level = level;
> 	}
>
> 	public Boolean getStatusMessage() {
> 		return statusMessage;
> 	}
>
> 	public void setStatusMessage(Boolean statusMessage) {
> 		this.statusMessage = statusMessage;
> 	}
>
> 	public String getCompileSource() {
> 		return compileSource;
> 	}
>
> 	public void setCompileSource(String compileSource) {
> 		this.compileSource = compileSource;
> 	}
>
> 	public String getCompileTarget() {
> 		return compileTarget;
> 	}
>
> 	public void setCompileTarget(String compileTarget) {
> 		this.compileTarget = compileTarget;
> 	}
>
> 	public String getCompileBootclasspath() {
> 		return compileBootclasspath;
> 	}
>
> 	public void setCompileBootclasspath(String compileBootclasspath) {
> 		this.compileBootclasspath = compileBootclasspath;
> 	}
>
> 	public String getCompileExtdirs() {
> 		return compileExtdirs;
> 	}
>
> 	public void setCompileExtdirs(String compileExtdirs) {
> 		this.compileExtdirs = compileExtdirs;
> 	}
>
> 	public String getCompileMemory() {
> 		return compileMemory;
> 	}
>
> 	public void setCompileMemory(String compileMemory) {
> 		this.compileMemory = compileMemory;
> 	}
>
> 	public File getProfileHome() {
> 		return profileHome;
> 	}
>
> 	public void setProfileHome(File profileHome) {
> 		this.profileHome = profileHome;
> 	}
>
> 	public String getProfileUrl() {
> 		return profileUrl;
> 	}
>
> 	public void setProfileUrl(String profileUrl) {
> 		this.profileUrl = profileUrl;
> 	}
>
> }
>
> On 23 Jun 2009, at 00:36, Tim Peierls wrote:
>
>> Maybe we didn't emphasize this enough in JCiP, but it's almost  
>> always best to start with something simple and correct and then  
>> move to more complex designs only if it's clear that you really  
>> need to.
>>
>> Your example looks somewhat artificial, but if I were to take it  
>> literally, I would start with something like this.
>>
>> public interface StandardSettings {
>>     boolean isStatusMessage();
>>     void setStatusMessage(boolean statusMessage);
>>     ConcurrentMap<String, MachineConfig> getMachines();
>>     MachineConfig get(String name);
>> }
>>
>> @ThreadSafe
>> public final class StandardSettingsImpl implements StandardSettings {
>>
>>        @GuardedBy("this") private boolean statusMessage = true;
>>
>>        private final ConcurrentMap<String, MachineConfig>> machines =
>>            new ConcurrentHashMap<String, MachineConfig>();
>>
>>
>>        public synchronized boolean isStatusMessage() {
>>            return statusMessage;
>>        }
>>
>>        public synchronized void setStatusMessage(boolean  
>> statusMessage) {
>>            this.statusMessage = statusMessage;
>>        }
>>
>>        public ConcurrentMap<String, MachineConfig> getMachines() {
>>            return machines;
>>        }
>>
>>        public MachineConfig getMachine(String name) {
>>            return machines.get(name);
>>        }
>> }
>>
>> Prefer the interface type ConcurrentMap (or just Map) in APIs, only  
>> using concrete types like ConcurrentHashMap in initializers.
>>
>> If you're willing to expose the map from machine name to machine  
>> config, you don't need a setMachines method at all. See chapter 4  
>> of JCiP for variations on this theme.
>>
>> Use the JCiP annotations (or similar comments) to document your  
>> concurrency policy.
>>
>> Don't be shy about using simple synchronization.
>>
>> --tim
>>
>>
>>
>> On Mon, Jun 22, 2009 at 4:21 PM, Ashley Williams  
>> <ashpublic at mac.com> wrote:
>> Hi,
>>
>> After reading java concurrency in practice, I've now realize how  
>> little I know after all these years so I'm trying to put that
>> right. So as a first step I would like to make a settings class,  
>> which is just a bunch of getters and setters, a little more
>> threadsafe and so I would appreciate any helpful comments.
>>
>>
>> I think I am right in just using a final reference to an atomic
>> wrapper for the simple property types, but I'm unsure if I'm  
>> approaching the map property correctly. In the code below
>> I've tried to follow these guidelines for the 'machines' field:
>>
>> 1. The getter should always return a copy.
>>
>> 2. The setter should replace the currently held list, rather than  
>> trying to clear() then putAll() which can cause a race condition
>> if another thread gets in between the two operations.
>>
>> 3. The accessor getMachine(key) method effectively does a double  
>> check to decide whether it needs to create the entry. The
>> first check is against null and the second is an implicit check  
>> during the call to putIfAbsent().
>>
>> 4. My first attempt didn't wrap the map with an atomic, instead the  
>> map was declared directly as a field. I rejected this because
>> the set method involved calling clear() then putAll() which can  
>> cause a race condition
>> if another thread gets in between the two operations. Was I right  
>> to reject this approach?
>>
>>
>> public final class StandardSettings {
>>        private final AtomicBoolean statusMessage;
>>
>>        private final AtomicReference<ConcurrentHashMap<String,  
>> MachineConfig>> machines;
>>
>>        public StandardSettings() {
>>                this.statusMessage = new AtomicBoolean(true);
>>                this.machines = new  
>> AtomicReference<ConcurrentHashMap<String, MachineConfig>>(
>>                                new ConcurrentHashMap<String,  
>> MachineConfig>());
>>        }
>>
>> // getter and setter for a boolean property
>>
>>        public Boolean getStatusMessage() {
>>                return statusMessage.get();
>>        }
>>
>>        public void setStatusMessage(Boolean statusMessage) {
>>                this.statusMessage.set(statusMessage);
>>        }
>>
>> // getter and setter for map property
>>
>>        public ConcurrentHashMap<String, MachineConfig>  
>> getMachines() {
>>                return new ConcurrentHashMap<String,  
>> MachineConfig>(machines.get());
>>        }
>>
>>        public void setMachines(ConcurrentHashMap<String,  
>> MachineConfig> machines) {
>>                this.machines.set(machines);
>>        }
>>
>> // access to the named map entry that creates that entry if it  
>> doesn't exist
>>
>>        public MachineConfig getMachine(String name) {
>>                MachineConfig config = machines.get().get(name);
>>
>>                if (config == null) {
>>                        MachineConfig newValue = new  
>> MachineConfig(name);
>>                        // another thread may have just added after  
>> our null check
>>                        MachineConfig oldValue =  
>> machines.get().putIfAbsent(name, newValue);
>>                        config = oldValue != null ? oldValue :  
>> newValue;
>>
>>                }
>>
>>                return config;
>>        }
>>
>> }
>>
>> Am I on the right track for making this class thread safe and if  
>> not how should I be approaching the problem?
>>
>> Many thanks
>> - Ashley Williams
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/11ed6af5/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 13:05:24 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 18:05:24 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
Message-ID: <744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>

It seems to me that the only reason to use an intrinsic lock on a lazy  
getter (stick a synchronized keyword
on the method signature) is convenience of syntax. Please correct me  
if I am wrong.

So is one idea to simplify lazy instantiation, feedback welcome if  
anybody can improve on it. It's based
on the observation that double checked locking is mostly boilerplate  
except for the line that creates
the instance and so I've factored it out into a callable interface.

Admittedly the anonymous class makes for a more verbose constructor,  
but at least the dcl logic is
now encapsulated. And if java had support for closures then the  
readability problem would go away.

So first the class:

@ThreadSafe
public final class LazyField<T> {
	private volatile T obj;
	private final Callable<T> callable;

	public LazyField(Callable<T> callable) {
		this.callable = callable;
	}

	public T get() {
		if (obj == null) {
			synchronized (this) {
				if (obj == null) {
					obj = callable.call();
				}
			}
		}
		return obj;
	}
}

and here is an example usage:

@ThreadSafe
public final class MyClass {
	private final LazyField<String> message;

	public MyClass() {
		this.message = new LazyField<String>(new Callable<String>() {
			public String call() throws Exception {
				return "hello world";
			}
		});
	}

	public String getMessage() {
		return message.get();
	}
}

- Ashley Williams
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/5b7fb3f3/attachment.html>

From joe.bowbeer at gmail.com  Tue Jun 23 13:49:43 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 23 Jun 2009 10:49:43 -0700
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
Message-ID: <31f2a7bd0906231049j7fea2d50j85b233157a99dd06@mail.gmail.com>

Instead of a separate Callable, you might consider providing an abstract
"construct" method for subclasses to override.  Then the usage of LazyField
would be similar to that of ThreadLocal.

The user will need to create a class one way or another (Callable or
LazyField subclass), but the latter is often more compact:

   message = new LazyField<String>() {
        String construct() {
            return "hello world";
        }
    }

Joe

On Tue, Jun 23, 2009 at 10:05 AM, Ashley Williams wrote:

> It seems to me that the only reason to use an intrinsic lock on a lazy
> getter (stick a synchronized keyword
> on the method signature) is convenience of syntax. Please correct me if I
> am wrong.
>
> So is one idea to simplify lazy instantiation, feedback welcome if anybody
> can improve on it. It's based
> on the observation that double checked locking is mostly boilerplate except
> for the line that creates
> the instance and so I've factored it out into a callable interface.
>
> Admittedly the anonymous class makes for a more verbose constructor, but at
> least the dcl logic is
> now encapsulated. And if java had support for closures then the readability
> problem would go away.
>
> So first the class:
>
> @ThreadSafe
> public final class LazyField<T> {
> private volatile T obj;
> private final Callable<T> callable;
>
> public LazyField(Callable<T> callable) {
> this.callable = callable;
> }
>
> public T get() {
> if (obj == null) {
> synchronized (this) {
> if (obj == null) {
> obj = callable.call();
> }
> }
> }
> return obj;
> }
> }
>
> and here is an example usage:
>
> @ThreadSafe
> public final class MyClass {
> private final LazyField<String> message;
>
> public MyClass() {
> this.message = new LazyField<String>(new Callable<String>() {
> public String call() throws Exception {
> return "hello world";
> }
> });
> }
>
> public String getMessage() {
> return message.get();
> }
> }
>
> - Ashley Williams
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/dcbe0019/attachment.html>

From ben_manes at yahoo.com  Tue Jun 23 14:19:22 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 23 Jun 2009 11:19:22 -0700 (PDT)
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
Message-ID: <415022.18553.qm@web38805.mail.mud.yahoo.com>

I use this trick all the time, but its already supplied via FutureTask.  It has very similar semantics to your code.  This trick can be extended to build lazy maps (and other lazy structures) which is also very convenient.

public class Example {
    private final FutureTask<Computation> future = new FutureTask<Computation>(new Computable());

    // Lazily computes the work and returns the value
    public Computation getComputation() throws Exception {
        future.run(); // no-ops on all subsequent calls
        return future.get();
    }

    private static final class Computable implements Callable<Computation> {
        public Computation call() {
          // do work, return
        }
    }
}




________________________________
From: Ashley Williams <ashpublic at mac.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tuesday, June 23, 2009 10:05:24 AM
Subject: [concurrency-interest] syntax sugar for lazy instantiation


It seems to me that the only reason to use an intrinsic lock on a lazy getter (stick a synchronized keyword
on the method signature) is convenience of syntax. Please correct me if I am wrong.

So is one idea to simplify lazy instantiation, feedback welcome if anybody can improve on it. It's based
on the observation that double checked locking is mostly boilerplate except for the line that creates
the instance and so I've factored it out into a callable interface.

Admittedly the anonymous class makes for a more verbose constructor, but at least the dcl logic is
now encapsulated. And if java had support for closures then the readability problem would go away.

So first the class:

@ThreadSafe
public final class LazyField<T> {
privatevolatileT obj;
private final Callable<T> callable;

public LazyField(Callable<T> callable) {
this.callable = callable;
}

public T get() {
if (obj == null) {
synchronized(this) {
if (obj == null) {
obj = callable.call();
}
}
}
returnobj;
}
}

and here is an example usage:


@ThreadSafe
public final class MyClass {
private final LazyField<String> message;


public MyClass() {
this.message = new LazyField<String>(new Callable<String>() {
public String call() throws Exception {
return "hello world";
}
});
}

public String getMessage() {
returnmessage.get();
}
}

- Ashley Williams


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/d8c32356/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 14:31:16 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 19:31:16 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <31f2a7bd0906231049j7fea2d50j85b233157a99dd06@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<31f2a7bd0906231049j7fea2d50j85b233157a99dd06@mail.gmail.com>
Message-ID: <AFD2DE72-3F81-4A2F-8885-A07F257A6A12@mac.com>

Yes that makes a lot of sense - at the moment I'm also looking at  
groovy so I guess I'm seeing closures where
I don't always need them.


On 23 Jun 2009, at 18:49, Joe Bowbeer wrote:

> Instead of a separate Callable, you might consider providing an  
> abstract "construct" method for subclasses to override.  Then the  
> usage of LazyField would be similar to that of ThreadLocal.
>
> The user will need to create a class one way or another (Callable or  
> LazyField subclass), but the latter is often more compact:
>
>    message = new LazyField<String>() {
>         String construct() {
>             return "hello world";
>         }
>     }
>
> Joe
>
> On Tue, Jun 23, 2009 at 10:05 AM, Ashley Williams wrote:
> It seems to me that the only reason to use an intrinsic lock on a  
> lazy getter (stick a synchronized keyword
> on the method signature) is convenience of syntax. Please correct me  
> if I am wrong.
>
> So is one idea to simplify lazy instantiation, feedback welcome if  
> anybody can improve on it. It's based
> on the observation that double checked locking is mostly boilerplate  
> except for the line that creates
> the instance and so I've factored it out into a callable interface.
>
> Admittedly the anonymous class makes for a more verbose constructor,  
> but at least the dcl logic is
> now encapsulated. And if java had support for closures then the  
> readability problem would go away.
>
> So first the class:
>
> @ThreadSafe
> public final class LazyField<T> {
> 	private volatile T obj;
> 	private final Callable<T> callable;
>
> 	public LazyField(Callable<T> callable) {
> 		this.callable = callable;
> 	}
>
> 	public T get() {
> 		if (obj == null) {
> 			synchronized (this) {
> 				if (obj == null) {
> 					obj = callable.call();
> 				}
> 			}
> 		}
> 		return obj;
> 	}
> }
>
> and here is an example usage:
>
> @ThreadSafe
> public final class MyClass {
> 	private final LazyField<String> message;
>
> 	public MyClass() {
> 		this.message = new LazyField<String>(new Callable<String>() {
> 			public String call() throws Exception {
> 				return "hello world";
> 			}
> 		});
> 	}
>
> 	public String getMessage() {
> 		return message.get();
> 	}
> }
>
> - Ashley Williams
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/3cb727fc/attachment.html>

From ashpublic at mac.com  Tue Jun 23 14:38:44 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 19:38:44 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <415022.18553.qm@web38805.mail.mud.yahoo.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<415022.18553.qm@web38805.mail.mud.yahoo.com>
Message-ID: <0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>

I'm going to have to think about this one since I've used futures but  
never connected them to double checked locks.
Fo instance I want to check that:

- I get fast access to field  99% of the time
- I only pay for lock when initializing a field.

I'm sure there are a ton of tricks like this, what would be great is  
an "effective threading" book for those that have
read the theory and want to get straight to idioms.

On 23 Jun 2009, at 19:19, Ben Manes wrote:

> I use this trick all the time, but its already supplied via  
> FutureTask.  It has very similar semantics to your code.  This trick  
> can be extended to build lazy maps (and other lazy structures) which  
> is also very convenient.
>
> public class Example {
>     private final FutureTask<Computation> future = new  
> FutureTask<Computation>(new Computable());
>
>     // Lazily computes the work and returns the value
>     public Computation getComputation() throws Exception {
>         future.run(); // no-ops on all subsequent calls
>         return future.get();
>     }
>
>     private static final class Computable implements  
> Callable<Computation> {
>         public Computation call() {
>           // do work, return
>         }
>     }
> }
>
> From: Ashley Williams <ashpublic at mac.com>
> To: concurrency-interest at cs.oswego.edu
> Sent: Tuesday, June 23, 2009 10:05:24 AM
> Subject: [concurrency-interest] syntax sugar for lazy instantiation
>
> It seems to me that the only reason to use an intrinsic lock on a  
> lazy getter (stick a synchronized keyword
> on the method signature) is convenience of syntax. Please correct me  
> if I am wrong.
>
> So is one idea to simplify lazy instantiation, feedback welcome if  
> anybody can improve on it. It's based
> on the observation that double checked locking is mostly boilerplate  
> except for the line that creates
> the instance and so I've factored it out into a callable interface.
>
> Admittedly the anonymous class makes for a more verbose constructor,  
> but at least the dcl logic is
> now encapsulated. And if java had support for closures then the  
> readability problem would go away.
>
> So first the class:
>
> @ThreadSafe
> public final class LazyField<T> {
> 	private volatile T obj;
> 	private final Callable<T> callable;
>
> 	public LazyField(Callable<T> callable) {
> 		this.callable = callable;
> 	}
>
> 	public T get() {
> 		if (obj == null) {
> 			synchronized (this) {
> 				if (obj == null) {
> 					obj = callable.call();
> 				}
> 			}
> 		}
> 		return obj;
> 	}
> }
>
> and here is an example usage:
>
> @ThreadSafe
> public final class MyClass {
> 	private final LazyField<String> message;
>
> 	public MyClass() {
> 		this.message = new LazyField<String>(new Callable<String>() {
> 			public String call() throws Exception {
> 				return "hello world";
> 			}
> 		});
> 	}
>
> 	public String getMessage() {
> 		return message.get();
> 	}
> }
>
> - Ashley Williams
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/5a2e7504/attachment-0001.html>

From jim.andreou at gmail.com  Tue Jun 23 14:47:31 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Tue, 23 Jun 2009 21:47:31 +0300
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
Message-ID: <7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>

An piece of advice from Josh Bloch:

if (obj == null) {
                    ....
}
return obj;

It's better to store obj in a local field and use that for these two reads,
this way you save a volatile read operation.


I very much like Scala's implementation of this (though this is a language
feature instead of a library): lazy val function = ..., and there, you got a
nice version of the double checked locking idiom created for you :) (which
also allows the lengthy computation to return just null, since it uses an
extra bit to encode whether the field is initialized or not).

Dimitris

2009/6/23 Ashley Williams <ashpublic at mac.com>

> It seems to me that the only reason to use an intrinsic lock on a lazy
> getter (stick a synchronized keyword
> on the method signature) is convenience of syntax. Please correct me if I
> am wrong.
>
> So is one idea to simplify lazy instantiation, feedback welcome if anybody
> can improve on it. It's based
> on the observation that double checked locking is mostly boilerplate except
> for the line that creates
> the instance and so I've factored it out into a callable interface.
>
> Admittedly the anonymous class makes for a more verbose constructor, but at
> least the dcl logic is
> now encapsulated. And if java had support for closures then the readability
> problem would go away.
>
> So first the class:
>
> @ThreadSafe
> public final class LazyField<T> {
> private volatile T obj;
> private final Callable<T> callable;
>
> public LazyField(Callable<T> callable) {
> this.callable = callable;
> }
>
> public T get() {
> if (obj == null) {
> synchronized (this) {
> if (obj == null) {
> obj = callable.call();
> }
> }
> }
> return obj;
> }
> }
>
> and here is an example usage:
>
> @ThreadSafe
> public final class MyClass {
> private final LazyField<String> message;
>
> public MyClass() {
> this.message = new LazyField<String>(new Callable<String>() {
> public String call() throws Exception {
> return "hello world";
> }
> });
> }
>
> public String getMessage() {
> return message.get();
> }
> }
>
> - Ashley Williams
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/576a1557/attachment.html>

From hans.boehm at hp.com  Tue Jun 23 15:02:47 2009
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 23 Jun 2009 19:02:47 +0000
Subject: [concurrency-interest] Thread-safety annotations (was RE:
 concurrency newbie question)
In-Reply-To: <63b4e4050906230640y6528e143w2be3a77aab5313d5@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<0KLO000KW6S0KYV1@vms173013.mailsrvcs.net>
	<63b4e4050906230640y6528e143w2be3a77aab5313d5@mail.gmail.com>
Message-ID: <238A96A773B3934685A7269CC8A8D0424DFA98635C@GVW0436EXB.americas.hpqcorp.net>

I hadn't seen these "thread safety" annotations before.  It seems to me that they actually fail to cover the most important part of the space, namely classes that

a) permit read sharing without synchronization,

b) permit different class instances to be accessed concurrently without synchronization, but

c) require synchronization if the same instance is being accessed by multiple threads and one of the accesses is a write.

Such classes effectively behave like, for example, a built-in Java long or double.  (And they behave like a built-in Java int that is being accessed without data races, as it should be 99.9% of the time.)  I think this should be the default design point for most classes that are not specifically concurrency-related; instances should behave like built-in data types.  It is basically how the newer Java collections like ArrayList behave.  It is explicitly the default for the C++ standard library.

It is easily possible to build classes that are not safe for concurrent read accesses  (e.g. lists that are reorganized on a read access, or splay trees) or that are not safe for concurrent access of distinct instances (e.g. if components of the objects are allocated using a shared custom allocator that doesn't synchronize), so I think these distinctions are important.

Hans

________________________________
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tim Peierls
Sent: Tuesday, June 23, 2009 6:41 AM
To: Chris Kessel
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] concurrency newbie question

Excellent advice -- not silly at all!  A real guru would have included this broader context from the start. ;-)

Minor point: For classes that must be confined to a single thread, rather than (only) putting a prose description like "thread contained" in the javadoc comments, consider in addition annotating such classes with @NotThreadSafe (http://jcip.net/annotations/doc/net/jcip/annotations/NotThreadSafe.html).

The only way @NotThreadSafe classes can be used correctly is through "serial thread confinement", i.e., confinement of an object to a single thread at a time with any hand-off of the object between threads restricted to happens-before relationships such as those described in http://java.sun.com/javase/6/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility. (Serial thread confinement trivially includes simple confinement of an object to a single thread for the lifetime of the object.)

Incidentally, there is no JCiP annotation for "effectively immutable" classes, in which all mutative operations happen-before the object is published and multiple threads may perform read-only access after (safe) publication. Maybe there should be one.

--tim

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/1caf8f01/attachment.html>

From szabolcs.ferenczi at gmail.com  Tue Jun 23 16:57:57 2009
From: szabolcs.ferenczi at gmail.com (Szabolcs Ferenczi)
Date: Tue, 23 Jun 2009 22:57:57 +0200
Subject: [concurrency-interest] Thread-safety annotations (was RE:
	concurrency newbie question)
In-Reply-To: <238A96A773B3934685A7269CC8A8D0424DFA98635C@GVW0436EXB.americas.hpqcorp.net>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<0KLO000KW6S0KYV1@vms173013.mailsrvcs.net>
	<63b4e4050906230640y6528e143w2be3a77aab5313d5@mail.gmail.com>
	<238A96A773B3934685A7269CC8A8D0424DFA98635C@GVW0436EXB.americas.hpqcorp.net>
Message-ID: <c8955b000906231357vc04c4edpffb651a395a2389@mail.gmail.com>

> I hadn't seen these "thread safety" annotations before.

Well, it all started as a newbee question and Concurrent Pascal, the
first concurrent class based language is usually not known by newbees.
It containes something very similar to "thread safety" annotations:
access rights. It really adds safety since it allows compiler checks
in concurrent programs.

Cheers,
Szabolcs

2009/6/23 Boehm, Hans <hans.boehm at hp.com>:
> I hadn't seen these "thread safety" annotations before.? It seems to me that
> they actually fail to cover the most important part of the space, namely
> classes that
>
> a) permit read sharing without synchronization,
>
> b) permit different class instances to be accessed concurrently without
> synchronization, but
>
> c) require synchronization if the same instance is being accessed by
> multiple threads and one of the accesses is a write.
>
> Such classes effectively behave like, for example, a built-in Java long or
> double.? (And they behave like a built-in Java int that is being accessed
> without data races, as it should be 99.9% of the time.)? I think this should
> be the default design point for most classes that are not specifically
> concurrency-related; instances should behave like built-in data types.? It
> is basically how the newer Java collections like ArrayList behave.? It is
> explicitly the default for the C++ standard library.
>
> It is easily possible to build classes that are not safe for concurrent read
> accesses? (e.g. lists that are reorganized on a read access, or splay trees)
> or that are not safe for concurrent access of distinct instances (e.g. if
> components of the objects are allocated using a shared custom allocator that
> doesn't synchronize), so I think these distinctions are important.
>
> Hans
>
> ________________________________
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tim Peierls
> Sent: Tuesday, June 23, 2009 6:41 AM
> To: Chris Kessel
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] concurrency newbie question
>
> Excellent advice -- not silly at all! ?A real guru would have included this
> broader context from the start. ;-)
> Minor point: For classes that must be confined to a single thread, rather
> than (only) putting a prose description like "thread contained" in the
> javadoc comments, consider in addition annotating such classes with
> @NotThreadSafe
> (http://jcip.net/annotations/doc/net/jcip/annotations/NotThreadSafe.html).
> The only way @NotThreadSafe classes can be used correctly is through "serial
> thread confinement", i.e., confinement of an object to a single thread at a
> time with any hand-off of the object between threads restricted to
> happens-before relationships such as those described
> in?http://java.sun.com/javase/6/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility.
> (Serial thread confinement trivially includes simple confinement of an
> object to a single thread for the lifetime of the object.)
> Incidentally, there is no JCiP annotation for "effectively immutable"
> classes, in which all mutative operations happen-before the object is
> published and multiple threads may perform read-only access after (safe)
> publication. Maybe there should be one.
> --tim
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From ashpublic at mac.com  Tue Jun 23 17:03:17 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 22:03:17 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
Message-ID: <4236D957-9739-4872-981E-5C443A6D8211@mac.com>

Included this so now we have:

@ThreadSafe
public abstract class LazyField<T> implements Callable<T> {
	private volatile T obj;

	public T get() {
		// use a local variable to save on multiple reads of a volatile
		T result = obj;
		if (result == null) {
			synchronized (this) {
				if (result == null) {
					result = call();
					obj = result;
				}
			}
		}
		return result;
	}
}

with usage example:

	private final LazyField<Logger> antLogger = new LazyField<Logger>() {
		public Logger call() throws Exception {
			return Logger.getLogger(Log4jListener.LOG_ANT);
		}
	};

Looking a lot tidier now.


On 23 Jun 2009, at 19:47, Jim Andreou wrote:

> An piece of advice from Josh Bloch:
>
> 		if (obj == null) {
>                     ....
> 		}
> 		return obj;
>
> It's better to store obj in a local field and use that for these two  
> reads, this way you save a volatile read operation.
>
>
> I very much like Scala's implementation of this (though this is a  
> language feature instead of a library): lazy val function = ..., and  
> there, you got a nice version of the double checked locking idiom  
> created for you :) (which also allows the lengthy computation to  
> return just null, since it uses an extra bit to encode whether the  
> field is initialized or not).
>
> Dimitris
>
> 2009/6/23 Ashley Williams <ashpublic at mac.com>
> It seems to me that the only reason to use an intrinsic lock on a  
> lazy getter (stick a synchronized keyword
> on the method signature) is convenience of syntax. Please correct me  
> if I am wrong.
>
> So is one idea to simplify lazy instantiation, feedback welcome if  
> anybody can improve on it. It's based
> on the observation that double checked locking is mostly boilerplate  
> except for the line that creates
> the instance and so I've factored it out into a callable interface.
>
> Admittedly the anonymous class makes for a more verbose constructor,  
> but at least the dcl logic is
> now encapsulated. And if java had support for closures then the  
> readability problem would go away.
>
> So first the class:
>
> @ThreadSafe
> public final class LazyField<T> {
> 	private volatile T obj;
> 	private final Callable<T> callable;
>
> 	public LazyField(Callable<T> callable) {
> 		this.callable = callable;
> 	}
>
> 	public T get() {
> 		if (obj == null) {
> 			synchronized (this) {
> 				if (obj == null) {
> 					obj = callable.call();
> 				}
> 			}
> 		}
> 		return obj;
> 	}
> }
>
> and here is an example usage:
>
> @ThreadSafe
> public final class MyClass {
> 	private final LazyField<String> message;
>
> 	public MyClass() {
> 		this.message = new LazyField<String>(new Callable<String>() {
> 			public String call() throws Exception {
> 				return "hello world";
> 			}
> 		});
> 	}
>
> 	public String getMessage() {
> 		return message.get();
> 	}
> }
>
> - Ashley Williams
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/133ac2a3/attachment.html>

From jim.andreou at gmail.com  Tue Jun 23 17:08:42 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Wed, 24 Jun 2009 00:08:42 +0300
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <4236D957-9739-4872-981E-5C443A6D8211@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
	<4236D957-9739-4872-981E-5C443A6D8211@mac.com>
Message-ID: <7d7138c10906231408o44e6435ak2c651dd953fd3906@mail.gmail.com>

There is a typo inside the synchronized block, it should be obj == null.
All in all, it looks good, saves some boilerplate.

2009/6/24 Ashley Williams <ashpublic at mac.com>

> Included this so now we have:
> @ThreadSafe
> public abstract class LazyField<T> implements Callable<T> {
> private volatile T obj;
>
> public T get() {
> // use a local variable to save on multiple reads of a volatile
> T result = obj;
> if (result == null) {
> synchronized (this) {
> if (result == null) {
> result = call();
> obj = result;
> }
> }
> }
> return result;
> }
> }
>
> with usage example:
>
> private final LazyField<Logger> antLogger = new LazyField<Logger>() {
> public Logger call() throws Exception {
> return Logger.getLogger(Log4jListener.LOG_ANT);
> }
> };
>
> Looking a lot tidier now.
>
>
> On 23 Jun 2009, at 19:47, Jim Andreou wrote:
>
> An piece of advice from Josh Bloch:
>
> if (obj == null) {
>                     ....
>  }
>  return obj;
>
> It's better to store obj in a local field and use that for these two reads,
> this way you save a volatile read operation.
>
>
> I very much like Scala's implementation of this (though this is a language
> feature instead of a library): lazy val function = ..., and there, you got a
> nice version of the double checked locking idiom created for you :) (which
> also allows the lengthy computation to return just null, since it uses an
> extra bit to encode whether the field is initialized or not).
>
> Dimitris
>
> 2009/6/23 Ashley Williams <ashpublic at mac.com>
>
>> It seems to me that the only reason to use an intrinsic lock on a lazy
>> getter (stick a synchronized keyword
>> on the method signature) is convenience of syntax. Please correct me if I
>> am wrong.
>>
>> So is one idea to simplify lazy instantiation, feedback welcome if anybody
>> can improve on it. It's based
>> on the observation that double checked locking is mostly boilerplate
>> except for the line that creates
>> the instance and so I've factored it out into a callable interface.
>>
>> Admittedly the anonymous class makes for a more verbose constructor, but
>> at least the dcl logic is
>> now encapsulated. And if java had support for closures then the
>> readability problem would go away.
>>
>> So first the class:
>>
>> @ThreadSafe
>> public final class LazyField<T> {
>>  private volatile T obj;
>>  private final Callable<T> callable;
>>
>> public LazyField(Callable<T> callable) {
>>  this.callable = callable;
>>  }
>>
>>  public T get() {
>> if (obj == null) {
>>  synchronized (this) {
>>  if (obj == null) {
>>  obj = callable.call();
>>  }
>> }
>>  }
>>  return obj;
>>  }
>> }
>>
>> and here is an example usage:
>>
>> @ThreadSafe
>> public final class MyClass {
>>  private final LazyField<String> message;
>>
>> public MyClass() {
>>  this.message = new LazyField<String>(new Callable<String>() {
>>  public String call() throws Exception {
>>  return "hello world";
>>  }
>> });
>>  }
>>
>> public String getMessage() {
>>  return message.get();
>>  }
>> }
>>
>> - Ashley Williams
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090624/d6491ec4/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 17:14:47 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 22:14:47 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <7d7138c10906231408o44e6435ak2c651dd953fd3906@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
	<4236D957-9739-4872-981E-5C443A6D8211@mac.com>
	<7d7138c10906231408o44e6435ak2c651dd953fd3906@mail.gmail.com>
Message-ID: <7E44FD1B-0DE8-468A-AB95-34A317F19658@mac.com>

Yes this is in effect a single check, not double. Thanks, I wouldn't  
have seen that error for hours.

On 23 Jun 2009, at 22:08, Jim Andreou wrote:

> There is a typo inside the synchronized block, it should be obj ==  
> null.
>
> All in all, it looks good, saves some boilerplate.
>
> 2009/6/24 Ashley Williams <ashpublic at mac.com>
> Included this so now we have:
>
> @ThreadSafe
> public abstract class LazyField<T> implements Callable<T> {
> 	private volatile T obj;
>
> 	public T get() {
> 		// use a local variable to save on multiple reads of a volatile
> 		T result = obj;
> 		if (result == null) {
> 			synchronized (this) {
> 				if (result == null) {
> 					result = call();
> 					obj = result;
> 				}
> 			}
> 		}
> 		return result;
> 	}
> }
>
> with usage example:
>
> 	private final LazyField<Logger> antLogger = new LazyField<Logger>() {
> 		public Logger call() throws Exception {
> 			return Logger.getLogger(Log4jListener.LOG_ANT);
> 		}
> 	};
>
> Looking a lot tidier now.
>
>
> On 23 Jun 2009, at 19:47, Jim Andreou wrote:
>
>> An piece of advice from Josh Bloch:
>>
>> 		if (obj == null) {
>>                     ....
>> 		}
>> 		return obj;
>>
>> It's better to store obj in a local field and use that for these  
>> two reads, this way you save a volatile read operation.
>>
>>
>> I very much like Scala's implementation of this (though this is a  
>> language feature instead of a library): lazy val function = ...,  
>> and there, you got a nice version of the double checked locking  
>> idiom created for you :) (which also allows the lengthy computation  
>> to return just null, since it uses an extra bit to encode whether  
>> the field is initialized or not).
>>
>> Dimitris
>>
>> 2009/6/23 Ashley Williams <ashpublic at mac.com>
>> It seems to me that the only reason to use an intrinsic lock on a  
>> lazy getter (stick a synchronized keyword
>> on the method signature) is convenience of syntax. Please correct  
>> me if I am wrong.
>>
>> So is one idea to simplify lazy instantiation, feedback welcome if  
>> anybody can improve on it. It's based
>> on the observation that double checked locking is mostly  
>> boilerplate except for the line that creates
>> the instance and so I've factored it out into a callable interface.
>>
>> Admittedly the anonymous class makes for a more verbose  
>> constructor, but at least the dcl logic is
>> now encapsulated. And if java had support for closures then the  
>> readability problem would go away.
>>
>> So first the class:
>>
>> @ThreadSafe
>> public final class LazyField<T> {
>> 	private volatile T obj;
>> 	private final Callable<T> callable;
>>
>> 	public LazyField(Callable<T> callable) {
>> 		this.callable = callable;
>> 	}
>>
>> 	public T get() {
>> 		if (obj == null) {
>> 			synchronized (this) {
>> 				if (obj == null) {
>> 					obj = callable.call();
>> 				}
>> 			}
>> 		}
>> 		return obj;
>> 	}
>> }
>>
>> and here is an example usage:
>>
>> @ThreadSafe
>> public final class MyClass {
>> 	private final LazyField<String> message;
>>
>> 	public MyClass() {
>> 		this.message = new LazyField<String>(new Callable<String>() {
>> 			public String call() throws Exception {
>> 				return "hello world";
>> 			}
>> 		});
>> 	}
>>
>> 	public String getMessage() {
>> 		return message.get();
>> 	}
>> }
>>
>> - Ashley Williams
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/d2ebb782/attachment.html>

From tim at peierls.net  Tue Jun 23 17:19:31 2009
From: tim at peierls.net (Tim Peierls)
Date: Tue, 23 Jun 2009 17:19:31 -0400
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <4236D957-9739-4872-981E-5C443A6D8211@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
	<4236D957-9739-4872-981E-5C443A6D8211@mac.com>
Message-ID: <63b4e4050906231419m69063f05ged18d4d1462c6436@mail.gmail.com>

Doesn't compile, since call() throws Exception and get() doesn't.

And you need another "result = obj;" after acquiring the synch lock.

Suggested fixes inline below.

But do consider Effective Java 2nd edition, Item 71 (Use lazy initialization
judiciously) before making all your fields lazy this way, and consider that
the extra level of indirection that you're introducing here might dominate
whatever savings you were hoping to get from lazy initialization over
straightforward synchronization.

--tim

On Tue, Jun 23, 2009 at 5:03 PM, Ashley Williams <ashpublic at mac.com> wrote:

> @ThreadSafe
> public abstract class LazyField<T> implements Callable<T> {
> private volatile T obj;
>

           public abstract T call();


> public T get() {
> // use a local variable to save on multiple reads of a volatile
> T result = obj;
> if (result == null) {
> synchronized (this) {
>

                                   result = obj;


> if (result == null) {
> result = call();
> obj = result;
> }
> }
> }
> return result;
> }
> }
>
> with usage example:
>
> private final LazyField<Logger> antLogger = new LazyField<Logger>() {
> public Logger call() throws Exception {
> return Logger.getLogger(Log4jListener.LOG_ANT);
> }
> };
>
> Looking a lot tidier now.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/b3f47ef2/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 17:30:21 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 22:30:21 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <63b4e4050906231419m69063f05ged18d4d1462c6436@mail.gmail.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
	<4236D957-9739-4872-981E-5C443A6D8211@mac.com>
	<63b4e4050906231419m69063f05ged18d4d1462c6436@mail.gmail.com>
Message-ID: <F2D62416-C43D-4547-BC36-D33368779C96@mac.com>

I should have mentioned that I am using the aspectj softened  
exceptions feature.

But if there is a requirement that a field should be lazily  
instantiated, is there really any advantage when using intrinsic  
locking - other than cleaner syntax?
I'm still under the impression that for the post-initialization path  
the double checked lock technique is quicker - namely because there is  
no lock.

Also this mailing list doesn't seem to be updating in order of sent  
message.

On 23 Jun 2009, at 22:19, Tim Peierls wrote:

> Doesn't compile, since call() throws Exception and get() doesn't.
>
> And you need another "result = obj;" after acquiring the synch lock.
>
> Suggested fixes inline below.
>
> But do consider Effective Java 2nd edition, Item 71 (Use lazy  
> initialization judiciously) before making all your fields lazy this  
> way, and consider that the extra level of indirection that you're  
> introducing here might dominate whatever savings you were hoping to  
> get from lazy initialization over straightforward synchronization.
>
> --tim
>
> On Tue, Jun 23, 2009 at 5:03 PM, Ashley Williams <ashpublic at mac.com>  
> wrote:
> @ThreadSafe
> public abstract class LazyField<T> implements Callable<T> {
> 	private volatile T obj;
>
>            public abstract T call();
>
>
> 	public T get() {
> 		// use a local variable to save on multiple reads of a volatile
> 		T result = obj;
> 		if (result == null) {
> 			synchronized (this) {
>
>                                    result = obj;
>
> 				if (result == null) {
> 					result = call();
> 					obj = result;
> 				}
> 			}
> 		}
> 		return result;
> 	}
> }
>
> with usage example:
>
> 	private final LazyField<Logger> antLogger = new LazyField<Logger>() {
> 		public Logger call() throws Exception {
> 			return Logger.getLogger(Log4jListener.LOG_ANT);
> 		}
> 	};
>
> Looking a lot tidier now.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/f53621e4/attachment.html>

From ashpublic at mac.com  Tue Jun 23 17:46:14 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 23 Jun 2009 22:46:14 +0100
Subject: [concurrency-interest] Useful concurrency aspect
Message-ID: <C16C5A64-0D25-46B3-B66E-D1FED885BB6E@mac.com>

Here is another helper that can enforce a subset of immutable for  
aspectj projects.
It gets the compiler to check that any class marked with the Immutable  
annotation doesn't (effectively) contain any non final fields.
The aspect/annotation should probably be changed to something like  
"JustFinals" since I now realize the definition of immutable isn't  
quite so
straightforward:

public aspect ImmutablePolicy {
	declare error : set(!static !final * (@Immutable *).*) : "immutable  
classes can't assign to non final fields";
	
	@Target(ElementType.TYPE)
	@Retention(RetentionPolicy.RUNTIME)
	@ThreadSafe
	public static @interface Immutable {
	}
}

However there must be a great deal of boilerplate code and design  
pattern enforcement that aspectj can help with. The most obvious
one that springs to mind is some around advice that surrounds a method  
with a reentrant lock that makes sure it is released correctly.
In fact if I recall correctly, one of the objections in the jcip book  
for not abandoning intrinsic locks was that it is easy to forget to  
release
reentrant locks.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/6f5a8dfa/attachment.html>

From ben_manes at yahoo.com  Tue Jun 23 18:32:13 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 23 Jun 2009 15:32:13 -0700 (PDT)
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<415022.18553.qm@web38805.mail.mud.yahoo.com>
	<0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>
Message-ID: <155611.14344.qm@web38804.mail.mud.yahoo.com>

While I understand the performance concern, I have not seen a problem in practice and the locking in FutureTask is well optimized.  It provides a nice idiom than sprinkling the code with double-checked locking tricks or introducing a new interface.  By using a future you leverage an existing interface and can utilize it to chain lower-level futures for performing post-processing logic on the client.  For example...

   // written ad-hoc...
   // Retrieves the entry in a remote caching layer where the key/value are use a custom serialization scheme
   // The client's future is bubbled up and performs post-processing to deserialize the value into object form
   // The "lazyFuture" provides the idiom to run the callable, which blocks on the inner future, on a Future#get().
    public <V> Future<V> get(K key) {
        String externalKey = serializer(key);
        final Future<String> future = remoteCache.get(externalKey);
        return Futures.lazyFuture(new Callable<V>() {
             public V call() throws Exception {
                 return deserializer(future.get());
             }
         });
    }

Because this idiom is generalized into a custom utility, Futures#lazyFuture(), the implementation can tuned globally if there is a performance problem.  Since I haven't experienced any noticeable overhead, the simplest approach for me was to rely on FutureTask until that problem occurs.  If a problem later occurs during performance testing, then implementing a Future with double-checked locking is simple, easy to test, and applies globally to all of my usages.




________________________________
From: Ashley Williams <ashpublic at mac.com>
To: Ben Manes <ben_manes at yahoo.com>
Cc: concurrency-interest at cs.oswego.edu
Sent: Tuesday, June 23, 2009 11:38:44 AM
Subject: Re: [concurrency-interest] syntax sugar for lazy instantiation


I'm going to have to think about this one since I've used futures but never connected them to double checked locks.
Fo instance I want to check that:

- I get fast access to field  99% of the time
- I only pay for lock when initializing a field.

I'm sure there are a ton of tricks like this, what would be great is an "effective threading" book for those that have
read the theory and want to get straight to idioms.

On 23 Jun 2009, at 19:19, Ben Manes wrote:

I use this trick all the time, but its already supplied via FutureTask.  It has very similar semantics to your code.  This trick can be extended to build lazy maps (and other lazy structures) which is also very convenient.

public class Example {
    private final FutureTask<Computation> future = new FutureTask<Computation>(new Computable());

    // Lazily computes the work and returns the value
    public Computation getComputation() throws Exception {
        future.run(); // no-ops on all subsequent calls
        return future.get();
    }

    private static final class Computable implements Callable<Computation> {
        public Computation call() {
          // do work, return
        }
    }
}




________________________________
From: Ashley Williams <ashpublic at mac.com>
To: concurrency-interest at cs.oswego.edu
Sent: Tuesday, June 23, 2009 10:05:24 AM
Subject: [concurrency-interest] syntax sugar for lazy instantiation


It seems to me that the only reason to use an intrinsic lock on a lazy getter (stick a synchronized keyword
on the method signature) is convenience of syntax. Please correct me if I am wrong.

So is one idea to simplify lazy instantiation, feedback welcome if anybody can improve on it. It's based
on the observation that double checked locking is mostly boilerplate except for the line that creates
the instance and so I've factored it out into a callable interface.

Admittedly the anonymous class makes for a more verbose constructor, but at least the dcl logic is
now encapsulated. And if java had support for closures then the readability problem would go away.

So first the class:

@ThreadSafe
public final class LazyField<T> {
private volatile T obj;
private final Callable<T> callable;

public LazyField(Callable<T> callable) {
this.callable = callable;
}

public T get() {
if (obj == null) {
synchronized (this) {
if (obj == null) {
obj = callable.call();
}
}
}
return obj;
}
}

and here is an example usage:


@ThreadSafe
public final class MyClass {
private final LazyField<String> message;


public MyClass() {
this.message = new LazyField<String>(new Callable<String>() {
public String call() throws Exception {
return "hello world";
}
});
}

public String getMessage() {
return message.get();
}
}

- Ashley Williams


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/a3a10ad5/attachment-0001.html>

From ashpublic at mac.com  Tue Jun 23 19:02:44 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Wed, 24 Jun 2009 00:02:44 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <155611.14344.qm@web38804.mail.mud.yahoo.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<415022.18553.qm@web38805.mail.mud.yahoo.com>
	<0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>
	<155611.14344.qm@web38804.mail.mud.yahoo.com>
Message-ID: <09FFD144-49B1-4399-9DC2-9FE446E61A43@mac.com>

I guess what's making it hard for me to comment on this is that I  
don't have the source code for FutureTask so I have no idea
what it is doing under the hood (thanks Apple). I agree it would be  
nice not to have to introduce a new class and if the
"happy path" is just a null check as with DCL then I would definitely  
see the benefit of this approach.

The only thing that makes me a little uncomfortable is that I guess  
FutureTask must contain more than one field to record
the exception, callable and result for example. Therefore I would be  
effectively swapping a single field with multiple.
I'm not saying this is a deal breaker though.

On 23 Jun 2009, at 23:32, Ben Manes wrote:

> While I understand the performance concern, I have not seen a  
> problem in practice and the locking in FutureTask is well  
> optimized.  It provides a nice idiom than sprinkling the code with  
> double-checked locking tricks or introducing a new interface.  By  
> using a future you leverage an existing interface and can utilize it  
> to chain lower-level futures for performing post-processing logic on  
> the client.  For example...
>
>    // written ad-hoc...
>    // Retrieves the entry in a remote caching layer where the key/ 
> value are use a custom serialization scheme
>    // The client's future is bubbled up and performs post-processing  
> to deserialize the value into object form
>    // The "lazyFuture" provides the idiom to run the callable, which  
> blocks on the inner future, on a Future#get().
>     public <V> Future<V> get(K key) {
>         String externalKey = serializer(key);
>         final Future<String> future = remoteCache.get(externalKey);
>         return Futures.lazyFuture(new Callable<V>() {
>              public V call() throws Exception {
>                  return deserializer(future.get());
>              }
>          });
>     }
>
> Because this idiom is generalized into a custom utility,  
> Futures#lazyFuture(), the implementation can tuned globally if there  
> is a performance problem.  Since I haven't experienced any  
> noticeable overhead, the simplest approach for me was to rely on  
> FutureTask until that problem occurs.  If a problem later occurs  
> during performance testing, then implementing a Future with double- 
> checked locking is simple, easy to test, and applies globally to all  
> of my usages.
>
> From: Ashley Williams <ashpublic at mac.com>
> To: Ben Manes <ben_manes at yahoo.com>
> Cc: concurrency-interest at cs.oswego.edu
> Sent: Tuesday, June 23, 2009 11:38:44 AM
> Subject: Re: [concurrency-interest] syntax sugar for lazy  
> instantiation
>
> I'm going to have to think about this one since I've used futures  
> but never connected them to double checked locks.
> Fo instance I want to check that:
>
> - I get fast access to field  99% of the time
> - I only pay for lock when initializing a field.
>
> I'm sure there are a ton of tricks like this, what would be great is  
> an "effective threading" book for those that have
> read the theory and want to get straight to idioms.
>
> On 23 Jun 2009, at 19:19, Ben Manes wrote:
>
>> I use this trick all the time, but its already supplied via  
>> FutureTask.  It has very similar semantics to your code.  This  
>> trick can be extended to build lazy maps (and other lazy  
>> structures) which is also very convenient.
>>
>> public class Example {
>>     private final FutureTask<Computation> future = new  
>> FutureTask<Computation>(new Computable());
>>
>>     // Lazily computes the work and returns the value
>>     public Computation getComputation() throws Exception {
>>         future.run(); // no-ops on all subsequent calls
>>         return future.get();
>>     }
>>
>>     private static final class Computable implements  
>> Callable<Computation> {
>>         public Computation call() {
>>           // do work, return
>>         }
>>     }
>> }
>>
>> From: Ashley Williams <ashpublic at mac.com>
>> To: concurrency-interest at cs.oswego.edu
>> Sent: Tuesday, June 23, 2009 10:05:24 AM
>> Subject: [concurrency-interest] syntax sugar for lazy instantiation
>>
>> It seems to me that the only reason to use an intrinsic lock on a  
>> lazy getter (stick a synchronized keyword
>> on the method signature) is convenience of syntax. Please correct  
>> me if I am wrong.
>>
>> So is one idea to simplify lazy instantiation, feedback welcome if  
>> anybody can improve on it. It's based
>> on the observation that double checked locking is mostly  
>> boilerplate except for the line that creates
>> the instance and so I've factored it out into a callable interface.
>>
>> Admittedly the anonymous class makes for a more verbose  
>> constructor, but at least the dcl logic is
>> now encapsulated. And if java had support for closures then the  
>> readability problem would go away.
>>
>> So first the class:
>>
>> @ThreadSafe
>> public final class LazyField<T> {
>> 	private volatile T obj;
>> 	private final Callable<T> callable;
>>
>> 	public LazyField(Callable<T> callable) {
>> 		this.callable = callable;
>> 	}
>>
>> 	public T get() {
>> 		if (obj == null) {
>> 			synchronized (this) {
>> 				if (obj == null) {
>> 					obj = callable.call();
>> 				}
>> 			}
>> 		}
>> 		return obj;
>> 	}
>> }
>>
>> and here is an example usage:
>>
>> @ThreadSafe
>> public final class MyClass {
>> 	private final LazyField<String> message;
>>
>> 	public MyClass() {
>> 		this.message = new LazyField<String>(new Callable<String>() {
>> 			public String call() throws Exception {
>> 				return "hello world";
>> 			}
>> 		});
>> 	}
>>
>> 	public String getMessage() {
>> 		return message.get();
>> 	}
>> }
>>
>> - Ashley Williams
>>
>>
>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090624/dc220427/attachment-0001.html>

From joe.bowbeer at gmail.com  Tue Jun 23 20:18:53 2009
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 23 Jun 2009 17:18:53 -0700
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <4236D957-9739-4872-981E-5C443A6D8211@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<7d7138c10906231147s5dc5b377k34fccd33423df1dd@mail.gmail.com>
	<4236D957-9739-4872-981E-5C443A6D8211@mac.com>
Message-ID: <31f2a7bd0906231718w79608dbev8881559abfc48df3@mail.gmail.com>

Nit: I think it's misleading to implement Callable in this case.  That
forces LazyField to have a public call() method, but it's only supposed to
be called internally.

Instead, I suggest an abstract protected method with a descriptive name such
as "create" or "construct" or "initialize".

private final LazyField<Logger> antLogger = new LazyField<Logger>() {
protected Logger create() {
return Logger.getLogger(Log4jListener.LOG_ANT);
}
};

Another template for this (other than ThreadLocal) is SwingWorker, in which
users override the doInBackground method, while the SwingWorker itself
implements Future using a private FutureTask instance.

Joe

On Tue, Jun 23, 2009 at 2:03 PM, Ashley Williams wrote:

> Included this so now we have:
> @ThreadSafe
> public abstract class LazyField<T> implements Callable<T> {
> private volatile T obj;
>
> public T get() {
> // use a local variable to save on multiple reads of a volatile
> T result = obj;
> if (result == null) {
> synchronized (this) {
> if (result == null) {
> result = call();
> obj = result;
> }
> }
> }
> return result;
> }
> }
>
> with usage example:
>
> private final LazyField<Logger> antLogger = new LazyField<Logger>() {
> public Logger call() throws Exception {
> return Logger.getLogger(Log4jListener.LOG_ANT);
> }
> };
>
> Looking a lot tidier now.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/1bcb3a91/attachment.html>

From genman at noderunner.net  Tue Jun 23 21:28:57 2009
From: genman at noderunner.net (Elias Ross)
Date: Tue, 23 Jun 2009 18:28:57 -0700
Subject: [concurrency-interest] concurrency newbie question
In-Reply-To: <AFF5A18B-9A15-4621-A920-0475E1604ECB@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<AFF5A18B-9A15-4621-A920-0475E1604ECB@mac.com>
Message-ID: <b517768e0906231828v58390d69i648984a7e761d9cb@mail.gmail.com>

On Tue, Jun 23, 2009 at 7:25 AM, Ashley Williams <ashpublic at mac.com> wrote:

> Unfortunately that isn't an option for me, firstly because the code that
> loads and saves this class needs
> to assume a bean-style interface rather than an intermediate Builder class,
> as it is part of a generic library
> that others may use.
>
> Also I've only included a few of the system wide settings there are
> potentially many more and therefore
> it would be wasteful that somebody who just wants to change one of the
> dozens of settings
> causes a brand new object to be created.
>
> I'm open to the fact that I'm not yet thinking correctly when it comes to
> concurrency ;) but the settings class
> I have seems to be fundamentally mutable in nature.
>

In the days before volatile and Atomic variables were commonly used, people
would just simply mark every reader and writer method as synchronized.

And even today, I feel the plain-Jane "synchronized" keyword is fine,
although it appears to lack sophistication as a Java developer. The JCiP
book makes a good argument to continue to use the synchronized keyword since
it's simple to grok.

But at the same time, I wouldn't argue against having immutable objects
either. Allocation and copying is very cheap, and the more immutable objects
you have, the less trouble you have proving a program is correct. Or more
generally, it means less bugs. But on the other hand, having simpler code is
a virtue.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090623/ba481d12/attachment.html>

From jed at atlassian.com  Tue Jun 23 22:37:34 2009
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Wed, 24 Jun 2009 00:37:34 -0200
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <09FFD144-49B1-4399-9DC2-9FE446E61A43@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>	<415022.18553.qm@web38805.mail.mud.yahoo.com>	<0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>	<155611.14344.qm@web38804.mail.mud.yahoo.com>
	<09FFD144-49B1-4399-9DC2-9FE446E61A43@mac.com>
Message-ID: <4A41916E.1030403@atlassian.com>

The Java6 source code can be downloaded as the "Developer Documentation" 
from http://developer.apple.com/java/download/

We have a LazyReference[1] class used extensively internally that 
encapsulates all the required functionality. It is based on FutureTask 
as well, and is fully optimised[2] for performance.

I am very wary when people try to optimise for space over correctness 
and even readability. Concurrency is so hard for most developers that 
favouring correctness over space (unless space is proven to be the first 
order issue) seems like premature optimisation.

cheers,
jed.

[1] LazyReference from the atlassian-util-concurrent library
source: 
http://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/LazyReference.java?r=2605
doc: http://labs.atlassian.com/wiki/display/CONCURRENT/LazyReference
[2] FutureTask.run() is a no-op if already run, but this is implemented 
by a CAS update on the state which can perform worse than a simple read 
of the state (isDone()) under certain circumstances.

Ashley Williams wrote:
> I guess what's making it hard for me to comment on this is that I 
> don't have the source code for FutureTask so I have no idea
> what it is doing under the hood (thanks Apple). I agree it would be 
> nice not to have to introduce a new class and if the
> "happy path" is just a null check as with DCL then I would definitely 
> see the benefit of this approach.
>
> The only thing that makes me a little uncomfortable is that I guess 
> FutureTask must contain more than one field to record
> the exception, callable and result for example. Therefore I would be 
> effectively swapping a single field with multiple.
> I'm not saying this is a deal breaker though.
>
> On 23 Jun 2009, at 23:32, Ben Manes wrote:
>
>> While I understand the performance concern, I have not seen a problem 
>> in practice and the locking in FutureTask is well optimized.  It 
>> provides a nice idiom than sprinkling the code with double-checked 
>> locking tricks or introducing a new interface.  By using a future you 
>> leverage an existing interface and can utilize it to chain 
>> lower-level futures for performing post-processing logic on the 
>> client.  For example...
>>
>>    // written ad-hoc...
>>    // Retrieves the entry in a remote caching layer where the 
>> key/value are use a custom serialization scheme
>>    // The client's future is bubbled up and performs post-processing 
>> to deserialize the value into object form
>>    // The "lazyFuture" provides the idiom to run the callable, which 
>> blocks on the inner future, on a Future#get().
>>     public <V> Future<V> get(K key) {
>>         String externalKey = serializer(key);
>>         final Future<String> future = remoteCache.get(externalKey);
>>         return Futures.lazyFuture(new Callable<V>() {
>>              public V call() throws Exception {
>>                  return deserializer(future.get());
>>              }
>>          });
>>     }
>>
>> Because this idiom is generalized into a custom utility, 
>> Futures#lazyFuture(), the implementation can tuned globally if there 
>> is a performance problem.  Since I haven't experienced any noticeable 
>> overhead, the simplest approach for me was to rely on FutureTask 
>> until that problem occurs.  If a problem later occurs during 
>> performance testing, then implementing a Future with double-checked 
>> locking is simple, easy to test, and applies globally to all of my 
>> usages.
>>
>> ------------------------------------------------------------------------
>> *From:* Ashley Williams <ashpublic at mac.com <mailto:ashpublic at mac.com>>
>> *To:* Ben Manes <ben_manes at yahoo.com <mailto:ben_manes at yahoo.com>>
>> *Cc:* concurrency-interest at cs.oswego.edu 
>> <mailto:concurrency-interest at cs.oswego.edu>
>> *Sent:* Tuesday, June 23, 2009 11:38:44 AM
>> *Subject:* Re: [concurrency-interest] syntax sugar for lazy instantiation
>>
>> I'm going to have to think about this one since I've used futures but 
>> never connected them to double checked locks.
>> Fo instance I want to check that:
>>
>> - I get fast access to field  99% of the time
>> - I only pay for lock when initializing a field.
>>
>> I'm sure there are a ton of tricks like this, what would be great is 
>> an "effective threading" book for those that have
>> read the theory and want to get straight to idioms.
>>
>> On 23 Jun 2009, at 19:19, Ben Manes wrote:
>>
>>> I use this trick all the time, but its already supplied via 
>>> FutureTask.  It has very similar semantics to your code.  This trick 
>>> can be extended to build lazy maps (and other lazy structures) which 
>>> is also very convenient.
>>>
>>> public class Example {
>>>     private final FutureTask<Computation> future = new 
>>> FutureTask<Computation>(new Computable());
>>>
>>>     // Lazily computes the work and returns the value
>>>     public Computation getComputation() throws Exception {
>>>         future.run(); // no-ops on all subsequent calls
>>>         return future.get();
>>>     }
>>>
>>>     private static final class Computable implements 
>>> Callable<Computation> {
>>>         public Computation call() {
>>>           // do work, return
>>>         }
>>>     }
>>> }
>>>
>>> ------------------------------------------------------------------------
>>> *From:* Ashley Williams <ashpublic at mac.com <mailto:ashpublic at mac.com>>
>>> *To:* concurrency-interest at cs.oswego.edu 
>>> <mailto:concurrency-interest at cs.oswego.edu>
>>> *Sent:* Tuesday, June 23, 2009 10:05:24 AM
>>> *Subject:* [concurrency-interest] syntax sugar for lazy instantiation
>>>
>>> It seems to me that the only reason to use an intrinsic lock on a 
>>> lazy getter (stick a synchronized keyword
>>> on the method signature) is convenience of syntax. Please correct me 
>>> if I am wrong.
>>>
>>> So is one idea to simplify lazy instantiation, feedback welcome if 
>>> anybody can improve on it. It's based
>>> on the observation that double checked locking is mostly boilerplate 
>>> except for the line that creates
>>> the instance and so I've factored it out into a callable interface.
>>>
>>> Admittedly the anonymous class makes for a more verbose constructor, 
>>> but at least the dcl logic is
>>> now encapsulated. And if java had support for closures then the 
>>> readability problem would go away.
>>>
>>> So first the class:
>>>
>>> @ThreadSafe
>>> public final class LazyField<T> {
>>> private volatile T obj;
>>> private final Callable<T> callable;
>>>
>>> public LazyField(Callable<T> callable) {
>>> this.callable = callable;
>>> }
>>>
>>> public T get() {
>>> if (obj == null) {
>>> synchronized (this) {
>>> if (obj == null) {
>>> obj = callable.call();
>>> }
>>> }
>>> }
>>> return obj;
>>> }
>>> }
>>>
>>> and here is an example usage:
>>>
>>> @ThreadSafe
>>> public final class MyClass {
>>> private final LazyField<String> message;
>>>
>>> public MyClass() {
>>> this.message = new LazyField<String>(new Callable<String>() {
>>> public String call() throws Exception {
>>> return "hello world";
>>> }
>>> });
>>> }
>>>
>>> public String getMessage() {
>>> return message.get();
>>> }
>>> }
>>>
>>> - Ashley Williams
>>>
>>>
>>
>>
>>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>   


From ashpublic at mac.com  Wed Jun 24 05:33:07 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Wed, 24 Jun 2009 10:33:07 +0100
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <4A41916E.1030403@atlassian.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<415022.18553.qm@web38805.mail.mud.yahoo.com>
	<0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>
	<155611.14344.qm@web38804.mail.mud.yahoo.com>
	<09FFD144-49B1-4399-9DC2-9FE446E61A43@mac.com>
	<4A41916E.1030403@atlassian.com>
Message-ID: <896ED969-DAC7-4754-9B21-2C65EDC832A2@mac.com>

Actually there isn't a version of Java6 on the 32 bit mac, which is  
what I have, but I've now got the java5 docs - this is a great help,  
thanks.

I took a look at your LazyReference class and it looks similar to the  
one suggested by Ben. My requirements for lazy behavior are typically
because a resource I need isn't available at construction time and not  
because the result takes a long time to calculate. Given that, would
you still recommend using future task?

I'm starting to see how ingrained my tendency is to favor space,  
although this is more because mutable objects are second nature to me
rather than a deliberate attempt to optimize.


On 24 Jun 2009, at 03:37, Jed Wesley-Smith wrote:

> The Java6 source code can be downloaded as the "Developer  
> Documentation" from http://developer.apple.com/java/download/
>
> We have a LazyReference[1] class used extensively internally that  
> encapsulates all the required functionality. It is based on  
> FutureTask as well, and is fully optimised[2] for performance.
>
> I am very wary when people try to optimise for space over  
> correctness and even readability. Concurrency is so hard for most  
> developers that favouring correctness over space (unless space is  
> proven to be the first order issue) seems like premature optimisation.
>
> cheers,
> jed.
>
> [1] LazyReference from the atlassian-util-concurrent library
> source: http://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/LazyReference.java?r=2605
> doc: http://labs.atlassian.com/wiki/display/CONCURRENT/LazyReference
> [2] FutureTask.run() is a no-op if already run, but this is  
> implemented by a CAS update on the state which can perform worse  
> than a simple read of the state (isDone()) under certain  
> circumstances.
>
> Ashley Williams wrote:
>> I guess what's making it hard for me to comment on this is that I  
>> don't have the source code for FutureTask so I have no idea
>> what it is doing under the hood (thanks Apple). I agree it would be  
>> nice not to have to introduce a new class and if the
>> "happy path" is just a null check as with DCL then I would  
>> definitely see the benefit of this approach.
>>
>> The only thing that makes me a little uncomfortable is that I guess  
>> FutureTask must contain more than one field to record
>> the exception, callable and result for example. Therefore I would  
>> be effectively swapping a single field with multiple.
>> I'm not saying this is a deal breaker though.
>>
>> On 23 Jun 2009, at 23:32, Ben Manes wrote:
>>
>>> While I understand the performance concern, I have not seen a  
>>> problem in practice and the locking in FutureTask is well  
>>> optimized.  It provides a nice idiom than sprinkling the code with  
>>> double-checked locking tricks or introducing a new interface.  By  
>>> using a future you leverage an existing interface and can utilize  
>>> it to chain lower-level futures for performing post-processing  
>>> logic on the client.  For example...
>>>
>>>   // written ad-hoc...
>>>   // Retrieves the entry in a remote caching layer where the key/ 
>>> value are use a custom serialization scheme
>>>   // The client's future is bubbled up and performs post- 
>>> processing to deserialize the value into object form
>>>   // The "lazyFuture" provides the idiom to run the callable,  
>>> which blocks on the inner future, on a Future#get().
>>>    public <V> Future<V> get(K key) {
>>>        String externalKey = serializer(key);
>>>        final Future<String> future = remoteCache.get(externalKey);
>>>        return Futures.lazyFuture(new Callable<V>() {
>>>             public V call() throws Exception {
>>>                 return deserializer(future.get());
>>>             }
>>>         });
>>>    }
>>>
>>> Because this idiom is generalized into a custom utility,  
>>> Futures#lazyFuture(), the implementation can tuned globally if  
>>> there is a performance problem.  Since I haven't experienced any  
>>> noticeable overhead, the simplest approach for me was to rely on  
>>> FutureTask until that problem occurs.  If a problem later occurs  
>>> during performance testing, then implementing a Future with double- 
>>> checked locking is simple, easy to test, and applies globally to  
>>> all of my usages.
>>>
>>> ------------------------------------------------------------------------
>>> *From:* Ashley Williams <ashpublic at mac.com  
>>> <mailto:ashpublic at mac.com>>
>>> *To:* Ben Manes <ben_manes at yahoo.com <mailto:ben_manes at yahoo.com>>
>>> *Cc:* concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu 
>>> >
>>> *Sent:* Tuesday, June 23, 2009 11:38:44 AM
>>> *Subject:* Re: [concurrency-interest] syntax sugar for lazy  
>>> instantiation
>>>
>>> I'm going to have to think about this one since I've used futures  
>>> but never connected them to double checked locks.
>>> Fo instance I want to check that:
>>>
>>> - I get fast access to field  99% of the time
>>> - I only pay for lock when initializing a field.
>>>
>>> I'm sure there are a ton of tricks like this, what would be great  
>>> is an "effective threading" book for those that have
>>> read the theory and want to get straight to idioms.
>>>
>>> On 23 Jun 2009, at 19:19, Ben Manes wrote:
>>>
>>>> I use this trick all the time, but its already supplied via  
>>>> FutureTask.  It has very similar semantics to your code.  This  
>>>> trick can be extended to build lazy maps (and other lazy  
>>>> structures) which is also very convenient.
>>>>
>>>> public class Example {
>>>>    private final FutureTask<Computation> future = new  
>>>> FutureTask<Computation>(new Computable());
>>>>
>>>>    // Lazily computes the work and returns the value
>>>>    public Computation getComputation() throws Exception {
>>>>        future.run(); // no-ops on all subsequent calls
>>>>        return future.get();
>>>>    }
>>>>
>>>>    private static final class Computable implements  
>>>> Callable<Computation> {
>>>>        public Computation call() {
>>>>          // do work, return
>>>>        }
>>>>    }
>>>> }
>>>>
>>>> ------------------------------------------------------------------------
>>>> *From:* Ashley Williams <ashpublic at mac.com <mailto:ashpublic at mac.com 
>>>> >>
>>>> *To:* concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu 
>>>> >
>>>> *Sent:* Tuesday, June 23, 2009 10:05:24 AM
>>>> *Subject:* [concurrency-interest] syntax sugar for lazy  
>>>> instantiation
>>>>
>>>> It seems to me that the only reason to use an intrinsic lock on a  
>>>> lazy getter (stick a synchronized keyword
>>>> on the method signature) is convenience of syntax. Please correct  
>>>> me if I am wrong.
>>>>
>>>> So is one idea to simplify lazy instantiation, feedback welcome  
>>>> if anybody can improve on it. It's based
>>>> on the observation that double checked locking is mostly  
>>>> boilerplate except for the line that creates
>>>> the instance and so I've factored it out into a callable interface.
>>>>
>>>> Admittedly the anonymous class makes for a more verbose  
>>>> constructor, but at least the dcl logic is
>>>> now encapsulated. And if java had support for closures then the  
>>>> readability problem would go away.
>>>>
>>>> So first the class:
>>>>
>>>> @ThreadSafe
>>>> public final class LazyField<T> {
>>>> private volatile T obj;
>>>> private final Callable<T> callable;
>>>>
>>>> public LazyField(Callable<T> callable) {
>>>> this.callable = callable;
>>>> }
>>>>
>>>> public T get() {
>>>> if (obj == null) {
>>>> synchronized (this) {
>>>> if (obj == null) {
>>>> obj = callable.call();
>>>> }
>>>> }
>>>> }
>>>> return obj;
>>>> }
>>>> }
>>>>
>>>> and here is an example usage:
>>>>
>>>> @ThreadSafe
>>>> public final class MyClass {
>>>> private final LazyField<String> message;
>>>>
>>>> public MyClass() {
>>>> this.message = new LazyField<String>(new Callable<String>() {
>>>> public String call() throws Exception {
>>>> return "hello world";
>>>> }
>>>> });
>>>> }
>>>>
>>>> public String getMessage() {
>>>> return message.get();
>>>> }
>>>> }
>>>>
>>>> - Ashley Williams
>>>>
>>>>
>>>
>>>
>>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From jed at atlassian.com  Wed Jun 24 21:41:16 2009
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 25 Jun 2009 11:41:16 +1000
Subject: [concurrency-interest] syntax sugar for lazy instantiation
In-Reply-To: <896ED969-DAC7-4754-9B21-2C65EDC832A2@mac.com>
References: <66D6018F-EE07-4ED7-BAC4-F65A0EA1B684@mac.com>
	<63b4e4050906221636k788432ffr3d977f0e142ced39@mail.gmail.com>
	<F4D237C4-5748-4002-8793-ACBCE8106405@mac.com>
	<63b4e4050906230658n17687a13xa7c60b33c64f31a3@mail.gmail.com>
	<744173A9-67F6-4BC3-9156-432DD0A9FF94@mac.com>
	<415022.18553.qm@web38805.mail.mud.yahoo.com>
	<0809C6FE-EFB2-419C-891B-6A3930850D9E@mac.com>
	<155611.14344.qm@web38804.mail.mud.yahoo.com>
	<09FFD144-49B1-4399-9DC2-9FE446E61A43@mac.com>
	<4A41916E.1030403@atlassian.com>
	<896ED969-DAC7-4754-9B21-2C65EDC832A2@mac.com>
Message-ID: <4A42D5BC.2060404@atlassian.com>

Ashley Williams wrote:
> Actually there isn't a version of Java6 on the 32 bit mac, which is 
> what I have, but I've now got the java5 docs - this is a great help, 
> thanks.

Ah, yes ? bugger! glad to point you in the right direction though...

> I took a look at your LazyReference class and it looks similar to the 
> one suggested by Ben.

It is very similar, the biggest difference is that it is librafied and 
not a pattern for bespoke implementations (and the encapsulation allows 
a few optimisations).

> My requirements for lazy behavior are typically
> because a resource I need isn't available at construction time and not 
> because the result takes a long time to calculate. Given that, would
> you still recommend using future task?

Well, the FutureTask removes the need to manually sync and provides all 
the semantics you require, reducing the . It also neatly handles the 
case where your initialisation function throws an exception or returns 
null without retrying the function (which will be done serially in the 
case of the LazyField example).

> I'm starting to see how ingrained my tendency is to favor space, 
> although this is more because mutable objects are second nature to me
> rather than a deliberate attempt to optimize.

The more work I have done with concurrency, the more I have appreciated 
immutable objects, to the point where we use them exclusively for any 
(new) domain or transfer objects (the only shared mutable state in the 
VM is in caches (caveat, sometimes mutables are incorrectly stored in a 
web session)). Along with inherently safe publication semantics (which 
greatly complicate the implementation of mutable objects and their 
infrastructure) I find it makes _thinking_ concurrently a lot easier ? 
state changes are much simpler to understand.

cheers,
jed.

>
> On 24 Jun 2009, at 03:37, Jed Wesley-Smith wrote:
>
>> The Java6 source code can be downloaded as the "Developer 
>> Documentation" from http://developer.apple.com/java/download/
>>
>> We have a LazyReference[1] class used extensively internally that 
>> encapsulates all the required functionality. It is based on 
>> FutureTask as well, and is fully optimised[2] for performance.
>>
>> I am very wary when people try to optimise for space over correctness 
>> and even readability. Concurrency is so hard for most developers that 
>> favouring correctness over space (unless space is proven to be the 
>> first order issue) seems like premature optimisation.
>>
>> cheers,
>> jed.
>>
>> [1] LazyReference from the atlassian-util-concurrent library
>> source: 
>> http://labs.atlassian.com/source/browse/CONCURRENT/trunk/src/main/java/com/atlassian/util/concurrent/LazyReference.java?r=2605 
>>
>> doc: http://labs.atlassian.com/wiki/display/CONCURRENT/LazyReference
>> [2] FutureTask.run() is a no-op if already run, but this is 
>> implemented by a CAS update on the state which can perform worse than 
>> a simple read of the state (isDone()) under certain circumstances.
>>
>> Ashley Williams wrote:
>>> I guess what's making it hard for me to comment on this is that I 
>>> don't have the source code for FutureTask so I have no idea
>>> what it is doing under the hood (thanks Apple). I agree it would be 
>>> nice not to have to introduce a new class and if the
>>> "happy path" is just a null check as with DCL then I would 
>>> definitely see the benefit of this approach.
>>>
>>> The only thing that makes me a little uncomfortable is that I guess 
>>> FutureTask must contain more than one field to record
>>> the exception, callable and result for example. Therefore I would be 
>>> effectively swapping a single field with multiple.
>>> I'm not saying this is a deal breaker though.
>>>
>>> On 23 Jun 2009, at 23:32, Ben Manes wrote:
>>>
>>>> While I understand the performance concern, I have not seen a 
>>>> problem in practice and the locking in FutureTask is well 
>>>> optimized. It provides a nice idiom than sprinkling the code with 
>>>> double-checked locking tricks or introducing a new interface. By 
>>>> using a future you leverage an existing interface and can utilize 
>>>> it to chain lower-level futures for performing post-processing 
>>>> logic on the client. For example...
>>>>
>>>> // written ad-hoc...
>>>> // Retrieves the entry in a remote caching layer where the 
>>>> key/value are use a custom serialization scheme
>>>> // The client's future is bubbled up and performs post-processing 
>>>> to deserialize the value into object form
>>>> // The "lazyFuture" provides the idiom to run the callable, which 
>>>> blocks on the inner future, on a Future#get().
>>>> public <V> Future<V> get(K key) {
>>>> String externalKey = serializer(key);
>>>> final Future<String> future = remoteCache.get(externalKey);
>>>> return Futures.lazyFuture(new Callable<V>() {
>>>> public V call() throws Exception {
>>>> return deserializer(future.get());
>>>> }
>>>> });
>>>> }
>>>>
>>>> Because this idiom is generalized into a custom utility, 
>>>> Futures#lazyFuture(), the implementation can tuned globally if 
>>>> there is a performance problem. Since I haven't experienced any 
>>>> noticeable overhead, the simplest approach for me was to rely on 
>>>> FutureTask until that problem occurs. If a problem later occurs 
>>>> during performance testing, then implementing a Future with 
>>>> double-checked locking is simple, easy to test, and applies 
>>>> globally to all of my usages.
>>>>
>>>> ------------------------------------------------------------------------ 
>>>>
>>>> *From:* Ashley Williams <ashpublic at mac.com <mailto:ashpublic at mac.com>>
>>>> *To:* Ben Manes <ben_manes at yahoo.com <mailto:ben_manes at yahoo.com>>
>>>> *Cc:* concurrency-interest at cs.oswego.edu 
>>>> <mailto:concurrency-interest at cs.oswego.edu>
>>>> *Sent:* Tuesday, June 23, 2009 11:38:44 AM
>>>> *Subject:* Re: [concurrency-interest] syntax sugar for lazy 
>>>> instantiation
>>>>
>>>> I'm going to have to think about this one since I've used futures 
>>>> but never connected them to double checked locks.
>>>> Fo instance I want to check that:
>>>>
>>>> - I get fast access to field 99% of the time
>>>> - I only pay for lock when initializing a field.
>>>>
>>>> I'm sure there are a ton of tricks like this, what would be great 
>>>> is an "effective threading" book for those that have
>>>> read the theory and want to get straight to idioms.
>>>>
>>>> On 23 Jun 2009, at 19:19, Ben Manes wrote:
>>>>
>>>>> I use this trick all the time, but its already supplied via 
>>>>> FutureTask. It has very similar semantics to your code. This trick 
>>>>> can be extended to build lazy maps (and other lazy structures) 
>>>>> which is also very convenient.
>>>>>
>>>>> public class Example {
>>>>> private final FutureTask<Computation> future = new 
>>>>> FutureTask<Computation>(new Computable());
>>>>>
>>>>> // Lazily computes the work and returns the value
>>>>> public Computation getComputation() throws Exception {
>>>>> future.run(); // no-ops on all subsequent calls
>>>>> return future.get();
>>>>> }
>>>>>
>>>>> private static final class Computable implements 
>>>>> Callable<Computation> {
>>>>> public Computation call() {
>>>>> // do work, return
>>>>> }
>>>>> }
>>>>> }
>>>>>
>>>>> ------------------------------------------------------------------------ 
>>>>>
>>>>> *From:* Ashley Williams <ashpublic at mac.com 
>>>>> <mailto:ashpublic at mac.com>>
>>>>> *To:* concurrency-interest at cs.oswego.edu 
>>>>> <mailto:concurrency-interest at cs.oswego.edu>
>>>>> *Sent:* Tuesday, June 23, 2009 10:05:24 AM
>>>>> *Subject:* [concurrency-interest] syntax sugar for lazy instantiation
>>>>>
>>>>> It seems to me that the only reason to use an intrinsic lock on a 
>>>>> lazy getter (stick a synchronized keyword
>>>>> on the method signature) is convenience of syntax. Please correct 
>>>>> me if I am wrong.
>>>>>
>>>>> So is one idea to simplify lazy instantiation, feedback welcome if 
>>>>> anybody can improve on it. It's based
>>>>> on the observation that double checked locking is mostly 
>>>>> boilerplate except for the line that creates
>>>>> the instance and so I've factored it out into a callable interface.
>>>>>
>>>>> Admittedly the anonymous class makes for a more verbose 
>>>>> constructor, but at least the dcl logic is
>>>>> now encapsulated. And if java had support for closures then the 
>>>>> readability problem would go away.
>>>>>
>>>>> So first the class:
>>>>>
>>>>> @ThreadSafe
>>>>> public final class LazyField<T> {
>>>>> private volatile T obj;
>>>>> private final Callable<T> callable;
>>>>>
>>>>> public LazyField(Callable<T> callable) {
>>>>> this.callable = callable;
>>>>> }
>>>>>
>>>>> public T get() {
>>>>> if (obj == null) {
>>>>> synchronized (this) {
>>>>> if (obj == null) {
>>>>> obj = callable.call();
>>>>> }
>>>>> }
>>>>> }
>>>>> return obj;
>>>>> }
>>>>> }
>>>>>
>>>>> and here is an example usage:
>>>>>
>>>>> @ThreadSafe
>>>>> public final class MyClass {
>>>>> private final LazyField<String> message;
>>>>>
>>>>> public MyClass() {
>>>>> this.message = new LazyField<String>(new Callable<String>() {
>>>>> public String call() throws Exception {
>>>>> return "hello world";
>>>>> }
>>>>> });
>>>>> }
>>>>>
>>>>> public String getMessage() {
>>>>> return message.get();
>>>>> }
>>>>> }
>>>>>
>>>>> - Ashley Williams
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>
>>> ------------------------------------------------------------------------ 
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>


From ashpublic at mac.com  Thu Jun 25 07:02:19 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Thu, 25 Jun 2009 12:02:19 +0100
Subject: [concurrency-interest] Hibernate domain objects
Message-ID: <82A6551F-2B52-4B3A-8DF2-B22B0EBA6ABF@mac.com>

Many thanks for the help so far on resetting my way of thinking when  
it comes to concurrency.

I would like to apply those lessons on my hibernate codebase, which  
for the uninitiated, consists
of a bunch of java beans style pojos with getters and setters. These  
are automatically called from the
hibernate api in order to sync with the database rows. As I see it  
there are a number of options:

1. This is a case where the domain model is genuinely mutable.  
Following the path of least
resistance means that I shouldn't try to bend this domain layer into  
something it wasn't supposed
to be and therefore introduce a little concurrency api in order to  
make it threadsafe.

2. Manage the lifecycle of the domain objects to ensure they are only  
ever used locally to a
thread. This means that care would have to taken when for example  
using the long conversation
pattern, where the session and its domain objects need to outlive the  
current thread/transaction.
In other words don't make the domain objects threadsafe but work hard  
in the rest of the
application that there is never any contention over them.

3. Consider the domain objects as nothing more than parameter holders  
and wrap them
inside genuine rich, immutable domain objects.

I'm sure there are more options and that there is no simple answer,  
but I would welcome any
insight.

Thanks
- Ashley Williams

From hanson.char at gmail.com  Thu Jun 25 11:42:09 2009
From: hanson.char at gmail.com (Hanson Char)
Date: Thu, 25 Jun 2009 08:42:09 -0700
Subject: [concurrency-interest] Hibernate domain objects
In-Reply-To: <82A6551F-2B52-4B3A-8DF2-B22B0EBA6ABF@mac.com>
References: <82A6551F-2B52-4B3A-8DF2-B22B0EBA6ABF@mac.com>
Message-ID: <ca53c8f80906250842h3129f30btb1c0aa9278593183@mail.gmail.com>

Or detach/clone every persistence objects of Hibernate into genuine POJO
instances via reusing the same classes, and then confine the use of these
POJO's in the executing threads.  No concurrency issue, nor problems of long
conversation pattern since these pojo's are independent of Hibernate
sessions.

(Shameless plug: I use Beanlib to make the cloning trivially easy.)

Cheers,
Hanson

On Thu, Jun 25, 2009 at 4:02 AM, Ashley Williams <ashpublic at mac.com> wrote:

> Many thanks for the help so far on resetting my way of thinking when it
> comes to concurrency.
>
> I would like to apply those lessons on my hibernate codebase, which for the
> uninitiated, consists
> of a bunch of java beans style pojos with getters and setters. These are
> automatically called from the
> hibernate api in order to sync with the database rows. As I see it there
> are a number of options:
>
> 1. This is a case where the domain model is genuinely mutable. Following
> the path of least
> resistance means that I shouldn't try to bend this domain layer into
> something it wasn't supposed
> to be and therefore introduce a little concurrency api in order to make it
> threadsafe.
>
> 2. Manage the lifecycle of the domain objects to ensure they are only ever
> used locally to a
> thread. This means that care would have to taken when for example using the
> long conversation
> pattern, where the session and its domain objects need to outlive the
> current thread/transaction.
> In other words don't make the domain objects threadsafe but work hard in
> the rest of the
> application that there is never any contention over them.
>
> 3. Consider the domain objects as nothing more than parameter holders and
> wrap them
> inside genuine rich, immutable domain objects.
>
> I'm sure there are more options and that there is no simple answer, but I
> would welcome any
> insight.
>
> Thanks
> - Ashley Williams
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090625/ed35ecb3/attachment.html>

From sberlin at gmail.com  Fri Jun 26 10:13:39 2009
From: sberlin at gmail.com (Sam Berlin)
Date: Fri, 26 Jun 2009 10:13:39 -0400
Subject: [concurrency-interest] ReadWriteLock Deadlock Detection Flaws?
Message-ID: <19196d860906260713o10ef85e5ya08f6e5529d65ed1@mail.gmail.com>

There seem to be some classic scenarios of deadlock where the VM doesn't
detect deadlock.  With the following two threads:

   new Thread(new Runnable() {  // Thread 1
            @Override
            public void run() {
                System.out.println("t1 locking a");
                a.lock();
                try {
                    System.out.println("t1 locked a");
                    try {Thread.sleep(1000); } catch(Exception e) {}
                    System.out.println("t1 locking b");
                    b.lock();
                    try {
                        System.out.println("t1 locked b");
                        try {Thread.sleep(100000); } catch(Exception e) {}
                    } finally {
                        b.unlock();
                    }
                } finally {
                    a.unlock();
                }
            }
        }).start();

        new Thread(new Runnable() {  // Thread 2
            @Override
            public void run() {
                System.out.println("t2 locking b");
                b.lock();
                try {
                    System.out.println("t2 locked b");
                    System.out.println("t2 locking a");
                    a.lock();
                    try {
                        System.out.println("t2 locked a");
                        try {Thread.sleep(100000); } catch(Exception e) {}
                    } finally {
                        a.unlock();
                    }
                } finally {
                    b.unlock();
                }
            }
        }).start();

This prints out:
 t1 locking a
 t1 locked a
 t2 locking b
 t2 locked b
 t2 locking a
 t1 locking b
 [and flow halts because of deadlock]

In the simple case of 'a' and 'b' being simple ReentrantLocks (or Objects
and using synchronize()), the VM correctly finds a deadlock.  If 'a' and 'b'
are ReentrantReadWriteLocks, there are some conditions where it will not
find a deadlock.

Here's the possible deadlocking scenarios and the result:
  Thread 1 & Thread 2 all lock writeLock ---> VM finds deadlock
  Thread 1 locks all writeLocks, Thread 2 'b' locks writeLock, 'a' locks
readLock --> VM finds deadlock
  Thread 1 locks all writeLocks, Thread 2 'b' locks readLock , 'a' locks
writeLock--> NO DEADLOCK FOUND
  Thread 1 locks all writeLocks, Thread 2 locks all readLocks --> NO
DEADLOCK FOUND
  Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 locks all
writeLocks --> VM Finds deadlock
  Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 locks all
writeLocks --> NO DEADLOCK FOUND
  Thread 1 locks all readLocks, Thread 2 locks all writeLocks --> NO
DEADLOCK FOUND
  Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 'b' locks
writeLock, 'a' locks readLock --> VM finds deadlock
  Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 'b' locks
readLock, 'a' locks writeLock --> NO DEADLOCK FOUND

The pattern seems to be that whenever a deadlock would be encountered due to
out-of-order locking, if the readLock was locked before a deadlock-inducing
writeLock, then no deadlock is found.  Conversely, if the writeLock is
locked before the deadlock-inducing readLock, the VM does find deadlock.

This is with JDK 1.6.0_12-b04.

Is this a known issue, a bug, or something else?

Thanks much,
 Sam
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090626/bc807c9e/attachment.html>

From cleber at nightcoders.com.br  Fri Jun 26 22:57:22 2009
From: cleber at nightcoders.com.br (Cleber Muramoto)
Date: Fri, 26 Jun 2009 23:57:22 -0300
Subject: [concurrency-interest] ReadWriteLock Deadlock Detection Flaws?
Message-ID: <668a9da40906261957x43131feane72d9d1821546f03@mail.gmail.com>

I think the locks are only individually reentrant.

Even a single thread will 'deadlock' if the oposite lock isn't
unlocked before acquiring the intended lock.

On Fri, Jun 26, 2009 at 1:00 PM,
<concurrency-interest-request at cs.oswego.edu> wrote:
> Send Concurrency-interest mailing list submissions to
> ? ? ? ?concurrency-interest at cs.oswego.edu
>
> To subscribe or unsubscribe via the World Wide Web, visit
> ? ? ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
> ? ? ? ?concurrency-interest-request at cs.oswego.edu
>
> You can reach the person managing the list at
> ? ? ? ?concurrency-interest-owner at cs.oswego.edu
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
>
>
> Today's Topics:
>
> ? 1. ReadWriteLock Deadlock Detection Flaws? (Sam Berlin)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 26 Jun 2009 10:13:39 -0400
> From: Sam Berlin <sberlin at gmail.com>
> Subject: [concurrency-interest] ReadWriteLock Deadlock Detection
> ? ? ? ?Flaws?
> To: concurrency-interest <concurrency-interest at cs.oswego.edu>
> Message-ID:
> ? ? ? ?<19196d860906260713o10ef85e5ya08f6e5529d65ed1 at mail.gmail.com>
> Content-Type: text/plain; charset="iso-8859-1"
>
> There seem to be some classic scenarios of deadlock where the VM doesn't
> detect deadlock. ?With the following two threads:
>
> ? new Thread(new Runnable() { ?// Thread 1
> ? ? ? ? ? ?@Override
> ? ? ? ? ? ?public void run() {
> ? ? ? ? ? ? ? ?System.out.println("t1 locking a");
> ? ? ? ? ? ? ? ?a.lock();
> ? ? ? ? ? ? ? ?try {
> ? ? ? ? ? ? ? ? ? ?System.out.println("t1 locked a");
> ? ? ? ? ? ? ? ? ? ?try {Thread.sleep(1000); } catch(Exception e) {}
> ? ? ? ? ? ? ? ? ? ?System.out.println("t1 locking b");
> ? ? ? ? ? ? ? ? ? ?b.lock();
> ? ? ? ? ? ? ? ? ? ?try {
> ? ? ? ? ? ? ? ? ? ? ? ?System.out.println("t1 locked b");
> ? ? ? ? ? ? ? ? ? ? ? ?try {Thread.sleep(100000); } catch(Exception e) {}
> ? ? ? ? ? ? ? ? ? ?} finally {
> ? ? ? ? ? ? ? ? ? ? ? ?b.unlock();
> ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?} finally {
> ? ? ? ? ? ? ? ? ? ?a.unlock();
> ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ?}
> ? ? ? ?}).start();
>
> ? ? ? ?new Thread(new Runnable() { ?// Thread 2
> ? ? ? ? ? ?@Override
> ? ? ? ? ? ?public void run() {
> ? ? ? ? ? ? ? ?System.out.println("t2 locking b");
> ? ? ? ? ? ? ? ?b.lock();
> ? ? ? ? ? ? ? ?try {
> ? ? ? ? ? ? ? ? ? ?System.out.println("t2 locked b");
> ? ? ? ? ? ? ? ? ? ?System.out.println("t2 locking a");
> ? ? ? ? ? ? ? ? ? ?a.lock();
> ? ? ? ? ? ? ? ? ? ?try {
> ? ? ? ? ? ? ? ? ? ? ? ?System.out.println("t2 locked a");
> ? ? ? ? ? ? ? ? ? ? ? ?try {Thread.sleep(100000); } catch(Exception e) {}
> ? ? ? ? ? ? ? ? ? ?} finally {
> ? ? ? ? ? ? ? ? ? ? ? ?a.unlock();
> ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?} finally {
> ? ? ? ? ? ? ? ? ? ?b.unlock();
> ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ?}
> ? ? ? ?}).start();
>
> This prints out:
> ?t1 locking a
> ?t1 locked a
> ?t2 locking b
> ?t2 locked b
> ?t2 locking a
> ?t1 locking b
> ?[and flow halts because of deadlock]
>
> In the simple case of 'a' and 'b' being simple ReentrantLocks (or Objects
> and using synchronize()), the VM correctly finds a deadlock. ?If 'a' and 'b'
> are ReentrantReadWriteLocks, there are some conditions where it will not
> find a deadlock.
>
> Here's the possible deadlocking scenarios and the result:
> ?Thread 1 & Thread 2 all lock writeLock ---> VM finds deadlock
> ?Thread 1 locks all writeLocks, Thread 2 'b' locks writeLock, 'a' locks
> readLock --> VM finds deadlock
> ?Thread 1 locks all writeLocks, Thread 2 'b' locks readLock , 'a' locks
> writeLock--> NO DEADLOCK FOUND
> ?Thread 1 locks all writeLocks, Thread 2 locks all readLocks --> NO
> DEADLOCK FOUND
> ?Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 locks all
> writeLocks --> VM Finds deadlock
> ?Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 locks all
> writeLocks --> NO DEADLOCK FOUND
> ?Thread 1 locks all readLocks, Thread 2 locks all writeLocks --> NO
> DEADLOCK FOUND
> ?Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 'b' locks
> writeLock, 'a' locks readLock --> VM finds deadlock
> ?Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 'b' locks
> readLock, 'a' locks writeLock --> NO DEADLOCK FOUND
>
> The pattern seems to be that whenever a deadlock would be encountered due to
> out-of-order locking, if the readLock was locked before a deadlock-inducing
> writeLock, then no deadlock is found. ?Conversely, if the writeLock is
> locked before the deadlock-inducing readLock, the VM does find deadlock.
>
> This is with JDK 1.6.0_12-b04.
>
> Is this a known issue, a bug, or something else?
>
> Thanks much,
> ?Sam
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090626/bc807c9e/attachment-0001.html>
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> End of Concurrency-interest Digest, Vol 53, Issue 29
> ****************************************************
>
>


From sberlin at gmail.com  Fri Jun 26 23:57:03 2009
From: sberlin at gmail.com (Sam Berlin)
Date: Fri, 26 Jun 2009 23:57:03 -0400
Subject: [concurrency-interest] ReadWriteLock Deadlock Detection Flaws?
In-Reply-To: <668a9da40906261957x43131feane72d9d1821546f03@mail.gmail.com>
References: <668a9da40906261957x43131feane72d9d1821546f03@mail.gmail.com>
Message-ID: <19196d860906262057i59a52407xac347e6a21a889ef@mail.gmail.com>

True, but to me there's a difference between that and deadlock.  It's
perfectly valid for one thread to lock the readLock and another to lock the
writeLock -- the latter thread just waits until the former closes the lock.
What's invalid (and is deadlock without any question) is when each thread is
prevented from acquiring the next lock because the thread that is holding
the lock is trying to acquire the opposite lock.

Although I don't consider a single thread holding readLock and then
attempting to acquire writeLock the same situation as a classic deadlock
scenario, I wouldn't be against the VM also reporting that as a stalled
thread in a deadlock report.

Sam

On Fri, Jun 26, 2009 at 10:57 PM, Cleber Muramoto <cleber at nightcoders.com.br
> wrote:

> I think the locks are only individually reentrant.
>
> Even a single thread will 'deadlock' if the oposite lock isn't
> unlocked before acquiring the intended lock.
>
> On Fri, Jun 26, 2009 at 1:00 PM,
> <concurrency-interest-request at cs.oswego.edu> wrote:
> > Send Concurrency-interest mailing list submissions to
> >        concurrency-interest at cs.oswego.edu
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >        http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > or, via email, send a message with subject or body 'help' to
> >        concurrency-interest-request at cs.oswego.edu
> >
> > You can reach the person managing the list at
> >        concurrency-interest-owner at cs.oswego.edu
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of Concurrency-interest digest..."
> >
> >
> > Today's Topics:
> >
> >   1. ReadWriteLock Deadlock Detection Flaws? (Sam Berlin)
> >
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Fri, 26 Jun 2009 10:13:39 -0400
> > From: Sam Berlin <sberlin at gmail.com>
> > Subject: [concurrency-interest] ReadWriteLock Deadlock Detection
> >        Flaws?
> > To: concurrency-interest <concurrency-interest at cs.oswego.edu>
> > Message-ID:
> >        <19196d860906260713o10ef85e5ya08f6e5529d65ed1 at mail.gmail.com>
> > Content-Type: text/plain; charset="iso-8859-1"
> >
> > There seem to be some classic scenarios of deadlock where the VM doesn't
> > detect deadlock.  With the following two threads:
> >
> >   new Thread(new Runnable() {  // Thread 1
> >            @Override
> >            public void run() {
> >                System.out.println("t1 locking a");
> >                a.lock();
> >                try {
> >                    System.out.println("t1 locked a");
> >                    try {Thread.sleep(1000); } catch(Exception e) {}
> >                    System.out.println("t1 locking b");
> >                    b.lock();
> >                    try {
> >                        System.out.println("t1 locked b");
> >                        try {Thread.sleep(100000); } catch(Exception e) {}
> >                    } finally {
> >                        b.unlock();
> >                    }
> >                } finally {
> >                    a.unlock();
> >                }
> >            }
> >        }).start();
> >
> >        new Thread(new Runnable() {  // Thread 2
> >            @Override
> >            public void run() {
> >                System.out.println("t2 locking b");
> >                b.lock();
> >                try {
> >                    System.out.println("t2 locked b");
> >                    System.out.println("t2 locking a");
> >                    a.lock();
> >                    try {
> >                        System.out.println("t2 locked a");
> >                        try {Thread.sleep(100000); } catch(Exception e) {}
> >                    } finally {
> >                        a.unlock();
> >                    }
> >                } finally {
> >                    b.unlock();
> >                }
> >            }
> >        }).start();
> >
> > This prints out:
> >  t1 locking a
> >  t1 locked a
> >  t2 locking b
> >  t2 locked b
> >  t2 locking a
> >  t1 locking b
> >  [and flow halts because of deadlock]
> >
> > In the simple case of 'a' and 'b' being simple ReentrantLocks (or Objects
> > and using synchronize()), the VM correctly finds a deadlock.  If 'a' and
> 'b'
> > are ReentrantReadWriteLocks, there are some conditions where it will not
> > find a deadlock.
> >
> > Here's the possible deadlocking scenarios and the result:
> >  Thread 1 & Thread 2 all lock writeLock ---> VM finds deadlock
> >  Thread 1 locks all writeLocks, Thread 2 'b' locks writeLock, 'a' locks
> > readLock --> VM finds deadlock
> >  Thread 1 locks all writeLocks, Thread 2 'b' locks readLock , 'a' locks
> > writeLock--> NO DEADLOCK FOUND
> >  Thread 1 locks all writeLocks, Thread 2 locks all readLocks --> NO
> > DEADLOCK FOUND
> >  Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 locks all
> > writeLocks --> VM Finds deadlock
> >  Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 locks all
> > writeLocks --> NO DEADLOCK FOUND
> >  Thread 1 locks all readLocks, Thread 2 locks all writeLocks --> NO
> > DEADLOCK FOUND
> >  Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 'b' locks
> > writeLock, 'a' locks readLock --> VM finds deadlock
> >  Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 'b' locks
> > readLock, 'a' locks writeLock --> NO DEADLOCK FOUND
> >
> > The pattern seems to be that whenever a deadlock would be encountered due
> to
> > out-of-order locking, if the readLock was locked before a
> deadlock-inducing
> > writeLock, then no deadlock is found.  Conversely, if the writeLock is
> > locked before the deadlock-inducing readLock, the VM does find deadlock.
> >
> > This is with JDK 1.6.0_12-b04.
> >
> > Is this a known issue, a bug, or something else?
> >
> > Thanks much,
> >  Sam
> > -------------- next part --------------
> > An HTML attachment was scrubbed...
> > URL: <
> http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090626/bc807c9e/attachment-0001.html
> >
> >
> > ------------------------------
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > End of Concurrency-interest Digest, Vol 53, Issue 29
> > ****************************************************
> >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090626/abd6b1ae/attachment.html>

From alarmnummer at gmail.com  Sat Jun 27 19:27:29 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Sun, 28 Jun 2009 01:27:29 +0200
Subject: [concurrency-interest] Deadlock definition question
Message-ID: <1466c1d60906271627o3a20bfa8t67b2f5990738651@mail.gmail.com>

Hi Guys,

I have a corner case question about the definition of a deadlock.

In most literature I see that there at least 2 threads need to be
involved. But what if there is a single thread and a non reentrant
lock? As thread still can get in a 'deadlock' like sitation when he
tries to reacquire the lock he already owns. So 1 thread would be
sufficient as well I would say.

Peter

From tgautier at terracottatech.com  Sat Jun 27 20:52:12 2009
From: tgautier at terracottatech.com (Taylor Gautier)
Date: Sat, 27 Jun 2009 17:52:12 -0700 (PDT)
Subject: [concurrency-interest] Deadlock definition question
In-Reply-To: <1466c1d60906271627o3a20bfa8t67b2f5990738651@mail.gmail.com>
Message-ID: <23722500.2257091246150332047.JavaMail.root@mail01.terracottatech.com>

Heh, that's kind of like the trick I always use to hang a thread indefinitely: 


Thread.currentThread().join(); 


----- Original Message ----- 
From: "Peter Veentjer" <alarmnummer at gmail.com> 
To: concurrency-interest at cs.oswego.edu 
Sent: Saturday, June 27, 2009 4:27:29 PM GMT -08:00 US/Canada Pacific 
Subject: [concurrency-interest] Deadlock definition question 

Hi Guys, 

I have a corner case question about the definition of a deadlock. 

In most literature I see that there at least 2 threads need to be 
involved. But what if there is a single thread and a non reentrant 
lock? As thread still can get in a 'deadlock' like sitation when he 
tries to reacquire the lock he already owns. So 1 thread would be 
sufficient as well I would say. 

Peter 
_______________________________________________ 
Concurrency-interest mailing list 
Concurrency-interest at cs.oswego.edu 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090627/74e65422/attachment.html>

From martinrb at google.com  Sun Jun 28 12:31:14 2009
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 28 Jun 2009 09:31:14 -0700
Subject: [concurrency-interest] ReadWriteLock Deadlock Detection Flaws?
In-Reply-To: <19196d860906260713o10ef85e5ya08f6e5529d65ed1@mail.gmail.com>
References: <19196d860906260713o10ef85e5ya08f6e5529d65ed1@mail.gmail.com>
Message-ID: <1ccfd1c10906280931k5cfeb38cg77e2fcacbd2b2eb2@mail.gmail.com>

The deadlock detection is based on traditional exclusive locks,
where a lock can only have one locker.

I think the behavior can be understood by thinking about how
the libraries communicate their state to hotspot.
- whenever a lock is acquired _exclusively_
  AbstractOwnableSynchronizer
- whenever a thread is waiting to acquire a lock.
  LockSupport.park(lockObject)

In the case of T1 holding the read lock while T2 tries to acquire
the write lock,  hotspot is aware of T2's state,
but is not notified that T1 is  preventing it.

Fixing this would require revisiting the monitoring model,
which is unlikely to happen.

Martin

On Fri, Jun 26, 2009 at 07:13, Sam Berlin <sberlin at gmail.com> wrote:

> There seem to be some classic scenarios of deadlock where the VM doesn't
> detect deadlock.  With the following two threads:
>
>    new Thread(new Runnable() {  // Thread 1
>             @Override
>             public void run() {
>                 System.out.println("t1 locking a");
>                 a.lock();
>                 try {
>                     System.out.println("t1 locked a");
>                     try {Thread.sleep(1000); } catch(Exception e) {}
>                     System.out.println("t1 locking b");
>                     b.lock();
>                     try {
>                         System.out.println("t1 locked b");
>                         try {Thread.sleep(100000); } catch(Exception e) {}
>                     } finally {
>                         b.unlock();
>                     }
>                 } finally {
>                     a.unlock();
>                 }
>             }
>         }).start();
>
>         new Thread(new Runnable() {  // Thread 2
>             @Override
>             public void run() {
>                 System.out.println("t2 locking b");
>                 b.lock();
>                 try {
>                     System.out.println("t2 locked b");
>                     System.out.println("t2 locking a");
>                     a.lock();
>                     try {
>                         System.out.println("t2 locked a");
>                         try {Thread.sleep(100000); } catch(Exception e) {}
>                     } finally {
>                         a.unlock();
>                     }
>                 } finally {
>                     b.unlock();
>                 }
>             }
>         }).start();
>
> This prints out:
>  t1 locking a
>  t1 locked a
>  t2 locking b
>  t2 locked b
>  t2 locking a
>  t1 locking b
>  [and flow halts because of deadlock]
>
> In the simple case of 'a' and 'b' being simple ReentrantLocks (or Objects
> and using synchronize()), the VM correctly finds a deadlock.  If 'a' and 'b'
> are ReentrantReadWriteLocks, there are some conditions where it will not
> find a deadlock.
>
> Here's the possible deadlocking scenarios and the result:
>   Thread 1 & Thread 2 all lock writeLock ---> VM finds deadlock
>   Thread 1 locks all writeLocks, Thread 2 'b' locks writeLock, 'a' locks
> readLock --> VM finds deadlock
>   Thread 1 locks all writeLocks, Thread 2 'b' locks readLock , 'a' locks
> writeLock--> NO DEADLOCK FOUND
>   Thread 1 locks all writeLocks, Thread 2 locks all readLocks --> NO
> DEADLOCK FOUND
>   Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 locks all
> writeLocks --> VM Finds deadlock
>   Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 locks all
> writeLocks --> NO DEADLOCK FOUND
>   Thread 1 locks all readLocks, Thread 2 locks all writeLocks --> NO
> DEADLOCK FOUND
>   Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 'b' locks
> writeLock, 'a' locks readLock --> VM finds deadlock
>   Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 'b' locks
> readLock, 'a' locks writeLock --> NO DEADLOCK FOUND
>
> The pattern seems to be that whenever a deadlock would be encountered due
> to out-of-order locking, if the readLock was locked before a
> deadlock-inducing writeLock, then no deadlock is found.  Conversely, if the
> writeLock is locked before the deadlock-inducing readLock, the VM does find
> deadlock.
>
> This is with JDK 1.6.0_12-b04.
>
> Is this a known issue, a bug, or something else?
>
> Thanks much,
>  Sam
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090628/431346bf/attachment.html>

From takeshi10 at gmail.com  Sun Jun 28 13:12:54 2009
From: takeshi10 at gmail.com (Marcelo Fukushima)
Date: Sun, 28 Jun 2009 14:12:54 -0300
Subject: [concurrency-interest] Deadlock definition question
In-Reply-To: <1466c1d60906271627o3a20bfa8t67b2f5990738651@mail.gmail.com>
References: <1466c1d60906271627o3a20bfa8t67b2f5990738651@mail.gmail.com>
Message-ID: <7288749d0906281012u59aa8256v6aaa11daa3610f18@mail.gmail.com>

i guess it would be an impasse-like deadlock but a deadlock nonetheless

On Sat, Jun 27, 2009 at 8:27 PM, Peter Veentjer<alarmnummer at gmail.com> wrote:
> Hi Guys,
>
> I have a corner case question about the definition of a deadlock.
>
> In most literature I see that there at least 2 threads need to be
> involved. But what if there is a single thread and a non reentrant
> lock? As thread still can get in a 'deadlock' like sitation when he
> tries to reacquire the lock he already owns. So 1 thread would be
> sufficient as well I would say.
>
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
http://mapsdev.blogspot.com/
Marcelo Takeshi Fukushima

From martinrb at google.com  Sun Jun 28 14:29:02 2009
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 28 Jun 2009 11:29:02 -0700
Subject: [concurrency-interest] Why no blocking peek call for > j.u.c.BQ?
In-Reply-To: <457833.40854.qm@web32204.mail.mud.yahoo.com>
References: <mailman.1.1245340800.139.concurrency-interest@cs.oswego.edu>
	<457833.40854.qm@web32204.mail.mud.yahoo.com>
Message-ID: <1ccfd1c10906281129k7397235fy8fd9ccd4b78d4de9@mail.gmail.com>

On Thu, Jun 18, 2009 at 09:29, Alex Miller <alexdmiller at yahoo.com> wrote:

>
> Will TransferQueue help with this kind of functionality in JDK 7?
>

No.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090628/faa6c09e/attachment.html>

From martinrb at google.com  Sun Jun 28 14:53:00 2009
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 28 Jun 2009 11:53:00 -0700
Subject: [concurrency-interest] Why no blocking peek call for j.u.c.BQ?
In-Reply-To: <7d7138c10906182348t12d75502jefaf700786135dc5@mail.gmail.com>
References: <1466c1d60906171541q25ba2fafjffef6dca3e8a8633@mail.gmail.com>
	<6388526.2105621245279102790.JavaMail.root@mail01.terracottatech.com>
	<20090617233642.GA44430@jon.local>
	<7d7138c10906182348t12d75502jefaf700786135dc5@mail.gmail.com>
Message-ID: <1ccfd1c10906281153o22e4244ct74feb4118094f5a8@mail.gmail.com>

A belated followup.

I was the Sun engineer who supplied the evaluation for
 http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412

I agree with Dimitris that having to keep track of the "next" item
is a little annoying, but not so annoying that we should change the API.
Many of the iterators in j.u.c. cache the next item so that hasNext()
return of true does not become a lie.

Martin

On Thu, Jun 18, 2009 at 23:48, Jim Andreou <jim.andreou at gmail.com> wrote:

> I don't see this as a compelling use case, which can be summarized: "in
> cases where there is only a single consumer, I could use a blocking peek
> instead of having a variable". Use a variable already. :) The easiness of
> this outweights the cost of having another method (somewhere...), which
> people could call, creating race conditions (as mentioned) when someone
> decides at some time that "perhaps it would be a good idea to add more
> consumers for this queue".
> Regards,
>
> Dimitris
>
> 2009/6/18 Paul Phillips <paulp at improving.org>
>
> On Wed, Jun 17, 2009 at 03:51:42PM -0700, Taylor Gautier wrote:
>> > After asking this question, I read this bug report,
>> >
>> > http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6653412
>> >
>> > Where I think I agree with the reviewers comments - is there a real
>> > use case?
>>
>> I certainly noticed the absence of that method when writing this:
>>
>>
>> http://lampsvn.epfl.ch/svn-repos/scala/scala/trunk/src/library/scala/xml/pull/XMLEventReader.scala
>>
>> It is an XML pull parser.  It presents an iterator interface to the
>> user, but because the underlying data may be coming from an arbitrary
>> stream which may be arbitrarily slow, we need a way to distinguish end
>> of stream (hasNext returns false) from an empty queue (where hasNext
>> needs to block, since it doesn't know if there is will be a next.) So we
>> insert a poison object when the producer is done producing.
>>
>> If there is a blocking peek method, I can write it without having to
>> manually implement a one element buffer.  hasNext calls peek and returns
>> false if it sees the poison object, true if it sees anything else, and
>> blocks as long as necessary on an empty queue.  Lacking a blocking peek
>> I have to either poll or implement a buffer, neither of which appeals
>> compared to the missing alternative.
>>
>> So unless I missed some way better way to model this (undoubtedly a
>> possibility) there's at least one reason.  And there are more in the
>> later comments in that bug report.
>>
>> --
>> Paul Phillips      | A Sunday school is a prison in which children do
>> Apatheist          | penance for the evil conscience of their parents.
>> Empiricist         |     -- H. L. Mencken
>> slap pi uphill!    |----------* http://www.improving.org/paulp/*----------
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090628/421b1786/attachment-0001.html>

From davidcholmes at aapt.net.au  Sun Jun 28 20:05:55 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 29 Jun 2009 10:05:55 +1000
Subject: [concurrency-interest] Deadlock definition question
In-Reply-To: <1466c1d60906271627o3a20bfa8t67b2f5990738651@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEGPICAA.davidcholmes@aapt.net.au>

Hi Peter,

That's often referred to as a self-deadlock, but it isn't a classic
deadlock. People tend to use the term "deadlock" for any situation where a
thread becomes blocked and can never become unblocked, but that's really a
misuse of terminology as the classical deadlock definition is much more
specific.

That's my 2c.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter
> Veentjer
> Sent: Sunday, 28 June 2009 9:27 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Deadlock definition question
>
>
>
> Hi Guys,
>
> I have a corner case question about the definition of a deadlock.
>
> In most literature I see that there at least 2 threads need to be
> involved. But what if there is a single thread and a non reentrant
> lock? As thread still can get in a 'deadlock' like sitation when he
> tries to reacquire the lock he already owns. So 1 thread would be
> sufficient as well I would say.
>
> Peter
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From sberlin at gmail.com  Mon Jun 29 10:09:44 2009
From: sberlin at gmail.com (Sam Berlin)
Date: Mon, 29 Jun 2009 10:09:44 -0400
Subject: [concurrency-interest] ReadWriteLock Deadlock Detection Flaws?
In-Reply-To: <1ccfd1c10906280931k5cfeb38cg77e2fcacbd2b2eb2@mail.gmail.com>
References: <19196d860906260713o10ef85e5ya08f6e5529d65ed1@mail.gmail.com>
	<1ccfd1c10906280931k5cfeb38cg77e2fcacbd2b2eb2@mail.gmail.com>
Message-ID: <19196d860906290709u54aca6f7md24563e2c669947b@mail.gmail.com>

Thanks for the reply, Martin.  Do you think it would be possible to amend
the description in the javadocs saying that the current detection is based
on exlusive locks and does not work properly with ReadWriteLocks when the
ReadLock is held first?  Without that, it's a little misleading when the
descriptions say that deadlock can be detected, but deadlock isn't always
detected.

That, or revisit the model and fix it. :-)   (This would be my first
choice!)

The VM does seem to have knowledge that shared AbstractOwnableSynchronizers
are acquired (they are reported in thread dumps as LockInfos on ThreadInfo),
so it doesn't seem to be an insurmountable task.  In the absence of built-in
VM support, how possible do you think it would be to traverse ThreadInfo
objects and look at the LockInfo[] of what's locked & LockInfo of what it's
waiting on for each ThreadInfo to deduce a deadlock?

Sam

On Sun, Jun 28, 2009 at 12:31 PM, Martin Buchholz <martinrb at google.com>wrote:

> The deadlock detection is based on traditional exclusive locks,
> where a lock can only have one locker.
>
> I think the behavior can be understood by thinking about how
> the libraries communicate their state to hotspot.
> - whenever a lock is acquired _exclusively_
>   AbstractOwnableSynchronizer
> - whenever a thread is waiting to acquire a lock.
>   LockSupport.park(lockObject)
>
> In the case of T1 holding the read lock while T2 tries to acquire
> the write lock,  hotspot is aware of T2's state,
> but is not notified that T1 is  preventing it.
>
> Fixing this would require revisiting the monitoring model,
> which is unlikely to happen.
>
> Martin
>
> On Fri, Jun 26, 2009 at 07:13, Sam Berlin <sberlin at gmail.com> wrote:
>
>> There seem to be some classic scenarios of deadlock where the VM doesn't
>> detect deadlock.  With the following two threads:
>>
>>    new Thread(new Runnable() {  // Thread 1
>>             @Override
>>             public void run() {
>>                 System.out.println("t1 locking a");
>>                 a.lock();
>>                 try {
>>                     System.out.println("t1 locked a");
>>                     try {Thread.sleep(1000); } catch(Exception e) {}
>>                     System.out.println("t1 locking b");
>>                     b.lock();
>>                     try {
>>                         System.out.println("t1 locked b");
>>                         try {Thread.sleep(100000); } catch(Exception e) {}
>>                     } finally {
>>                         b.unlock();
>>                     }
>>                 } finally {
>>                     a.unlock();
>>                 }
>>             }
>>         }).start();
>>
>>         new Thread(new Runnable() {  // Thread 2
>>             @Override
>>             public void run() {
>>                 System.out.println("t2 locking b");
>>                 b.lock();
>>                 try {
>>                     System.out.println("t2 locked b");
>>                     System.out.println("t2 locking a");
>>                     a.lock();
>>                     try {
>>                         System.out.println("t2 locked a");
>>                         try {Thread.sleep(100000); } catch(Exception e) {}
>>                     } finally {
>>                         a.unlock();
>>                     }
>>                 } finally {
>>                     b.unlock();
>>                 }
>>             }
>>         }).start();
>>
>> This prints out:
>>  t1 locking a
>>  t1 locked a
>>  t2 locking b
>>  t2 locked b
>>  t2 locking a
>>  t1 locking b
>>  [and flow halts because of deadlock]
>>
>> In the simple case of 'a' and 'b' being simple ReentrantLocks (or Objects
>> and using synchronize()), the VM correctly finds a deadlock.  If 'a' and 'b'
>> are ReentrantReadWriteLocks, there are some conditions where it will not
>> find a deadlock.
>>
>> Here's the possible deadlocking scenarios and the result:
>>   Thread 1 & Thread 2 all lock writeLock ---> VM finds deadlock
>>   Thread 1 locks all writeLocks, Thread 2 'b' locks writeLock, 'a' locks
>> readLock --> VM finds deadlock
>>   Thread 1 locks all writeLocks, Thread 2 'b' locks readLock , 'a' locks
>> writeLock--> NO DEADLOCK FOUND
>>   Thread 1 locks all writeLocks, Thread 2 locks all readLocks --> NO
>> DEADLOCK FOUND
>>   Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 locks all
>> writeLocks --> VM Finds deadlock
>>   Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 locks all
>> writeLocks --> NO DEADLOCK FOUND
>>   Thread 1 locks all readLocks, Thread 2 locks all writeLocks --> NO
>> DEADLOCK FOUND
>>   Thread 1 'a' locks writeLock, 'b' locks readLock, Thread 2 'b' locks
>> writeLock, 'a' locks readLock --> VM finds deadlock
>>   Thread 1 'a' locks readLock, 'b' locks writeLock, Thread 2 'b' locks
>> readLock, 'a' locks writeLock --> NO DEADLOCK FOUND
>>
>> The pattern seems to be that whenever a deadlock would be encountered due
>> to out-of-order locking, if the readLock was locked before a
>> deadlock-inducing writeLock, then no deadlock is found.  Conversely, if the
>> writeLock is locked before the deadlock-inducing readLock, the VM does find
>> deadlock.
>>
>> This is with JDK 1.6.0_12-b04.
>>
>> Is this a known issue, a bug, or something else?
>>
>> Thanks much,
>>  Sam
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090629/daf75960/attachment.html>

From mads at renxo.com  Mon Jun 29 16:14:32 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Mon, 29 Jun 2009 17:14:32 -0300
Subject: [concurrency-interest] Bug in
	CustomConcurrentHashMap.KeySet.intern()
Message-ID: <4A4920A8.2030400@renxo.com>

Hi,

I found that CustomConcurrentHashMap.KeySet.intern() was the perfect fit 
for the object interning need we're having with a current project. 
However the implementation of this method fails returning null when a 
new object that is still not in the Map/Set is first interned. Currently 
the method implementation is the following:

        public K intern(K e) {
            return cchm.doPut(e, e, true);
        }

However, doPut() returns null when a key is first added to the map. It 
could be easily fixed as follows:

        public K intern(K e) {
            K oldElement = cchm.doPut(e, e, true);
            return (oldElement != null) ? oldElement : e;
        }

BTW, how stable is this preview release for production use? Any caveats?

Thanks,

-- 
Ing. Manuel Dominguez Sarmiento
Director General
Renxo S.A.
e-mail:	mads at renxo.com
Phone:	+54 11 4719 6806, ext. 104



From ashpublic at mac.com  Tue Jun 30 07:54:37 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 30 Jun 2009 12:54:37 +0100
Subject: [concurrency-interest] Immutable object conundrums
Message-ID: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>

Hi,

Like most developers I have worked with, the only immutable objects I  
create are more to do with keeping
control over internal data. For example I might return an unmodifiable  
list from a method so that I know it
can't have its content modified.

Changing styles in order to use many more immutable objects for the  
purposes of thread safety represents
a great challenge, at least for me, so I thought I'd jot down some  
thoughts in the hope that anyone who
has gone through a similar experience might comment on any part of  
this post.

----------------------------------------------

1. final doesn't imply immutable intentions.

It seems to me that immutability for the sake of propagating  
constructor changes to main memory
is something of a misnomer - this is more about using the 'final'  
keyword as a coarse grained hook into the
java memory model. Maybe if we had more direct access to that memory  
model then we could ensure
that mutable objects could safely be constructed as well, for example:

public class MyMutableClass {
    private String myNonFinal;

    public MyClass() {
       this.myNonFinal = "hello world";
       MemoryModel.flush(); // flush-commit similar to other cache  
technologies
    }
}

So my suggestion is that sometimes we rely on the side effects of  
'final' to help with safe publication rather
than expressing a desire to express immutable semantics. The only way  
I can see to gain the best of both
worlds is to use java atomics, which I can declare final but whose  
contents I can modify.

----------------------------------------------

2. Immutable Objects in aggregations and compositions

Unless an object is nothing more than a glorified utility then the  
chances are that it is a child component in some
parent aggregate. If this child component is mutable then one of the  
tactics I can use is to change the methods
that otherwise modify state, to return modified copies of itself  
instead:

public class MyParent {
    private MyChlld myChild;
    public void setChild(MyChild child) {...}
    public MyChild getChild() {...}
}

public class MyChild {
    public MyChild modify() {} // returns modified copy just like  
String.replace() does for example
}


Then I have to update the parent aggregate with the return value from  
MyChild.modify(). But if ThreadA and ThreadB
both try to do this then I have to consider the possibility that one  
of the updates will be overwritten by the other. So
rather than immutable objects being a silver bullet, I now appear to  
be firmly in the territory of lost-updates,
unrepeatable reads and other isolation problems. Is this an  
inevitability, or is there some other way people out there
are designing their way round this?

Maybe true concurrency should be limited just to a few well understood  
homogeneous bottleneck tasks and the rest
of the system should be synchronized with a strict locking policy,  
which would mean that many mutable objects
could remain in a kind of non-concurrent sandbox.

----------------------------------------------

3. immutable objects may require mutable construction

Yes there are many occasions when immutable objects are called for,  
but unless they are very trivial they
require great care in their construction. One technique I often use is  
to provide only the most basic constructors
and provide post construction methods to allow for further  
configuration. The documented understanding is that
you call the constructor followed by the post-construction methods in  
order to set the object up. The rest of
the API is immutable, just don't call the post-construction methods  
again.

// logically mutable even though it contains mutator methods
public class MyLogicallyImmutableClass {
    public MyLogicallyImmutableClass() {}

    @PostConstruction
    public MyLogicallyImmutableClass setParent(Object parent) {}

    @PostConstruction
    public MyLogicallyImmutableClass setData(int x, int y, int z) {...}
}

As an example I wouldn't normally set up the parent/child relationship  
in the constructors so the setParent() method
must separately be called, but 'parent' would be an immutable property  
from then on. So how would I handle
this situation - would I pepper my code with lots of factories and  
builders and move the post-construction data into
proper constructors? If so then I don't see how I can properly set up  
parent and child relationships in the light of
Domain Driven Design (Eric Evans) concerns where relationships are set  
up outside of the constructors.



Many thanks if you read this far!
- Ashley Williams


From jim.andreou at gmail.com  Tue Jun 30 08:21:49 2009
From: jim.andreou at gmail.com (Jim Andreou)
Date: Tue, 30 Jun 2009 15:21:49 +0300
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
Message-ID: <7d7138c10906300521w543b15f2jda36abe39d38a123@mail.gmail.com>

This is a big one, I'll answer only in the question in the middle.

2009/6/30 Ashley Williams <ashpublic at mac.com>:
>
> Then I have to update the parent aggregate with the return value from
> MyChild.modify(). But if ThreadA and ThreadB
> both try to do this then I have to consider the possibility that one of the
> updates will be overwritten by the other. So
> rather than immutable objects being a silver bullet, I now appear to be
> firmly in the territory of lost-updates,
> unrepeatable reads and other isolation problems. Is this an inevitability,
> or is there some other way people out there
> are designing their way round this?
>

You need to atomically update the root reference to this structure
(via cas). If a thread loses the race, it retries. This is a general
technique that can transform any sequential structure to a lock-free
one (described by Herlihy somewhere I think), but notice it can create
lots of contention if updates are often and/or copying is slow, i.e.
it doesn't really scale very well (as can be expected by a so
generallly applicable technique).

Dimitris

From alarmnummer at gmail.com  Tue Jun 30 08:25:38 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 30 Jun 2009 14:25:38 +0200
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
Message-ID: <1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>

> It seems to me that immutability for the sake of propagating constructor
> changes to main memory
> is something of a misnomer - this is more about using the 'final' keyword as
> a coarse grained hook into the
> java memory model. Maybe if we had more direct access to that memory model
> then we could ensure
> that mutable objects could safely be constructed as well, for example:
>
> public class MyMutableClass {
> ? private String myNonFinal;
>
> ? public MyClass() {
> ? ? ?this.myNonFinal = "hello world";
> ? ? ?MemoryModel.flush(); // flush-commit similar to other cache
> technologies
> ? }
> }

I don't see a happens before relation between the write of the
myNonFinal example and the usage. So I don't think this example is
going to work.

> So my suggestion is that sometimes we rely on the side effects of 'final' to
> help with safe publication rather
> than expressing a desire to express immutable semantics. The only way I can
> see to gain the best of both
> worlds is to use java atomics, which I can declare final but whose contents
> I can modify.
>

If you use a handover (so from thread1 to thread2, without the object
being touched by the thread1 after handover) you need some kind of
mechanism to safely handover the reference (for example a volatile or
Atomic class). But actions also ensures that all writes done  in
thread1 prior to the handover, are visible after the handover in
thread1. In JCiP this is called 'piggybacking on synchronisation'.

so

class Person{String name;}

volatile Person global;

//thread1
void foo(){
   Person p = new Person();
   p.name ="peter";
   global = p;
}

//thread2
void bar(){
  Person p = global;
  if(p!=null){print(p.name);}
}

So you don't need to litter your code with all kinds of JMM cruft.


From ashpublic at mac.com  Tue Jun 30 09:24:10 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 30 Jun 2009 14:24:10 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
Message-ID: <D6D1D2EC-76EB-4624-BEF0-A41593647882@mac.com>

Sorry I wasn't clear on this one, yes it was a bad example.

In your example I think you are talking about making use of the  
happens-before rule
knowledge i.e. program-order, volatility and transitivity? This is  
what I was suggesting
except replacing volatile with atomic.

What I wanted to imply was that if we had some sort of api (better  
than my suggestion)
to the memory model then we wouldn't need to declare state as final.  
Actually I'm not
advocating that there should be such an API, I'm just using the  
argument to suggest
that sometimes use of the final modifier has got nothing to do with  
immutability.

If I'm on the right track though then I'm very happy about that.

On 30 Jun 2009, at 13:25, Peter Veentjer wrote:

>> It seems to me that immutability for the sake of propagating  
>> constructor
>> changes to main memory
>> is something of a misnomer - this is more about using the 'final'  
>> keyword as
>> a coarse grained hook into the
>> java memory model. Maybe if we had more direct access to that  
>> memory model
>> then we could ensure
>> that mutable objects could safely be constructed as well, for  
>> example:
>>
>> public class MyMutableClass {
>>   private String myNonFinal;
>>
>>   public MyClass() {
>>      this.myNonFinal = "hello world";
>>      MemoryModel.flush(); // flush-commit similar to other cache
>> technologies
>>   }
>> }
>
> I don't see a happens before relation between the write of the
> myNonFinal example and the usage. So I don't think this example is
> going to work.
>
>> So my suggestion is that sometimes we rely on the side effects of  
>> 'final' to
>> help with safe publication rather
>> than expressing a desire to express immutable semantics. The only  
>> way I can
>> see to gain the best of both
>> worlds is to use java atomics, which I can declare final but whose  
>> contents
>> I can modify.
>>
>
> If you use a handover (so from thread1 to thread2, without the object
> being touched by the thread1 after handover) you need some kind of
> mechanism to safely handover the reference (for example a volatile or
> Atomic class). But actions also ensures that all writes done  in
> thread1 prior to the handover, are visible after the handover in
> thread1. In JCiP this is called 'piggybacking on synchronisation'.
>
> so
>
> class Person{String name;}
>
> volatile Person global;
>
> //thread1
> void foo(){
>   Person p = new Person();
>   p.name ="peter";
>   global = p;
> }
>
> //thread2
> void bar(){
>  Person p = global;
>  if(p!=null){print(p.name);}
> }
>
> So you don't need to litter your code with all kinds of JMM cruft.


From ashpublic at mac.com  Tue Jun 30 09:30:03 2009
From: ashpublic at mac.com (Ashley Williams)
Date: Tue, 30 Jun 2009 14:30:03 +0100
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <7d7138c10906300521w543b15f2jda36abe39d38a123@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<7d7138c10906300521w543b15f2jda36abe39d38a123@mail.gmail.com>
Message-ID: <CA475EF3-63D7-4B07-8EC2-A4B13CCEF410@mac.com>

Partial responses gratefully received.

Yes, I guessed CAS might be needed simply because the concepts from  
hibernate/jpa
seem to translate quite well to concurrency - optimistic locking in  
this case.

So I suppose in many situations I would also need to use a stamped  
reference
so that I could detect 'ABA' updates - and then some sort of conflict  
resolution
strategy to decide what to do when such a clash occurs.

As a corollary it looks like if you make an entity immutable then  
often you must make
references to it mutable, so for example in an entity relationship:

immutable child => mutable parent

On 30 Jun 2009, at 13:21, Jim Andreou wrote:

> This is a big one, I'll answer only in the question in the middle.
>
> 2009/6/30 Ashley Williams <ashpublic at mac.com>:
>>
>> Then I have to update the parent aggregate with the return value from
>> MyChild.modify(). But if ThreadA and ThreadB
>> both try to do this then I have to consider the possibility that  
>> one of the
>> updates will be overwritten by the other. So
>> rather than immutable objects being a silver bullet, I now appear  
>> to be
>> firmly in the territory of lost-updates,
>> unrepeatable reads and other isolation problems. Is this an  
>> inevitability,
>> or is there some other way people out there
>> are designing their way round this?
>>
>
> You need to atomically update the root reference to this structure
> (via cas). If a thread loses the race, it retries. This is a general
> technique that can transform any sequential structure to a lock-free
> one (described by Herlihy somewhere I think), but notice it can create
> lots of contention if updates are often and/or copying is slow, i.e.
> it doesn't really scale very well (as can be expected by a so
> generallly applicable technique).
>
> Dimitris


From alarmnummer at gmail.com  Tue Jun 30 09:58:51 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 30 Jun 2009 15:58:51 +0200
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <D6D1D2EC-76EB-4624-BEF0-A41593647882@mac.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<D6D1D2EC-76EB-4624-BEF0-A41593647882@mac.com>
Message-ID: <1466c1d60906300658g23ea9f8fv3324ef2cdf3a2616@mail.gmail.com>

On Tue, Jun 30, 2009 at 3:24 PM, Ashley Williams<ashpublic at mac.com> wrote:
> Sorry I wasn't clear on this one, yes it was a bad example.
>
> In your example I think you are talking about making use of the
> happens-before rule
> knowledge i.e. program-order, volatility and transitivity? This is what I
> was suggesting
> except replacing volatile with atomic.
>
> What I wanted to imply was that if we had some sort of api (better than my
> suggestion)
> to the memory model then we wouldn't need to declare state as final.
> Actually I'm not
> advocating that there should be such an API, I'm just using the argument to
> suggest
> that sometimes use of the final modifier has got nothing to do with
> immutability.

True. But that is why I'm trying to explain as well. In principle you
don't need final fields if you use a volatile write/read, unlock/lock
to transfer an object from one thread to another.

A practical example:

If you use a producer/consumer that communicates through a
blockingqueue, you can use ordinary pojo's as items (without any
volatile, final, atomic etc) because the blockingqueue ensures that
there is a happens before relation between the put of the item and the
take. So your POJO's can be arbitrary complex/deep.

So if you hand over objects from one thread to another, you don't need
to worry about any JMM stuff in the pojo's to transfer as long as
there is a safe handover.

This also is the reason why Spring beans don't suffer from visibility
and reordering problems as long as the setters on pojo's are not
called after bean creation :)

>
> If I'm on the right track though then I'm very happy about that.
>
> On 30 Jun 2009, at 13:25, Peter Veentjer wrote:
>
>>> It seems to me that immutability for the sake of propagating constructor
>>> changes to main memory
>>> is something of a misnomer - this is more about using the 'final' keyword
>>> as
>>> a coarse grained hook into the
>>> java memory model. Maybe if we had more direct access to that memory
>>> model
>>> then we could ensure
>>> that mutable objects could safely be constructed as well, for example:
>>>
>>> public class MyMutableClass {
>>> ?private String myNonFinal;
>>>
>>> ?public MyClass() {
>>> ? ? this.myNonFinal = "hello world";
>>> ? ? MemoryModel.flush(); // flush-commit similar to other cache
>>> technologies
>>> ?}
>>> }
>>
>> I don't see a happens before relation between the write of the
>> myNonFinal example and the usage. So I don't think this example is
>> going to work.
>>
>>> So my suggestion is that sometimes we rely on the side effects of 'final'
>>> to
>>> help with safe publication rather
>>> than expressing a desire to express immutable semantics. The only way I
>>> can
>>> see to gain the best of both
>>> worlds is to use java atomics, which I can declare final but whose
>>> contents
>>> I can modify.
>>>
>>
>> If you use a handover (so from thread1 to thread2, without the object
>> being touched by the thread1 after handover) you need some kind of
>> mechanism to safely handover the reference (for example a volatile or
>> Atomic class). But actions also ensures that all writes done ?in
>> thread1 prior to the handover, are visible after the handover in
>> thread1. In JCiP this is called 'piggybacking on synchronisation'.
>>
>> so
>>
>> class Person{String name;}
>>
>> volatile Person global;
>>
>> //thread1
>> void foo(){
>> ?Person p = new Person();
>> ?p.name ="peter";
>> ?global = p;
>> }
>>
>> //thread2
>> void bar(){
>> ?Person p = global;
>> ?if(p!=null){print(p.name);}
>> }
>>
>> So you don't need to litter your code with all kinds of JMM cruft.
>
>


From dl at cs.oswego.edu  Tue Jun 30 11:08:40 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 30 Jun 2009 11:08:40 -0400
Subject: [concurrency-interest] Bug
	in	CustomConcurrentHashMap.KeySet.intern()
In-Reply-To: <4A4920A8.2030400@renxo.com>
References: <4A4920A8.2030400@renxo.com>
Message-ID: <4A4A2A78.7050705@cs.oswego.edu>

Manuel Dominguez Sarmiento wrote:
> Hi,
> 
> I found that CustomConcurrentHashMap.KeySet.intern() was the perfect fit 
> for the object interning need we're having with a current project. 

> However, doPut() returns null when a key is first added to the map. It 
> could be easily fixed as follows:
> 
>        public K intern(K e) {
>            K oldElement = cchm.doPut(e, e, true);
>            return (oldElement != null) ? oldElement : e;
>        }

Thanks! Fixed.

> 
> BTW, how stable is this preview release for production use? Any caveats?

Not at all stable. The version there was checked in to
allow discussion about how to support various cache-like
uses (which is among the main reasons for people to use it.)
Which led to some explorations on my part on
how to efficiently support customized eviction policies
Which has in turn led to various diversions on concurrent
(and non-concurrent) hashing that further stall getting
this in releasable form.

The Map functionality has been well-tested, but as you saw, the
auxiliary functionality hasn't.

(While I'm at it: I will be away tomorrow (July 1) through
July 14 so might not respond to mail promptly.)

-Doug

From mads at renxo.com  Tue Jun 30 11:16:26 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Tue, 30 Jun 2009 12:16:26 -0300
Subject: [concurrency-interest] Bug
	in	CustomConcurrentHashMap.KeySet.intern()
In-Reply-To: <4A4A2A78.7050705@cs.oswego.edu>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
Message-ID: <4A4A2C4A.7040405@renxo.com>

Hi Doug,

Thanks for the update. I noticed that several projects are using some 
form or another of ConcurrentReferenceHashMap, which I believe is the 
precursor to CustomConcurrentHashMap (for instance, JBoss Remoting as 
well as a few others are using these on their releases). Are these 
versions any more stable? If so, were can I find the latest source (I 
can only find CustomConcurrentHashMap in CVS).

Thanks!

Ing. Manuel Dominguez Sarmiento
Director General
Renxo S.A.
e-mail:	mads at renxo.com
Phone:	+54 11 4719 6806, ext. 104



Doug Lea wrote:
> Manuel Dominguez Sarmiento wrote:
>> Hi,
>>
>> I found that CustomConcurrentHashMap.KeySet.intern() was the perfect 
>> fit for the object interning need we're having with a current project. 
>
>> However, doPut() returns null when a key is first added to the map. 
>> It could be easily fixed as follows:
>>
>>        public K intern(K e) {
>>            K oldElement = cchm.doPut(e, e, true);
>>            return (oldElement != null) ? oldElement : e;
>>        }
>
> Thanks! Fixed.
>
>>
>> BTW, how stable is this preview release for production use? Any caveats?
>
> Not at all stable. The version there was checked in to
> allow discussion about how to support various cache-like
> uses (which is among the main reasons for people to use it.)
> Which led to some explorations on my part on
> how to efficiently support customized eviction policies
> Which has in turn led to various diversions on concurrent
> (and non-concurrent) hashing that further stall getting
> this in releasable form.
>
> The Map functionality has been well-tested, but as you saw, the
> auxiliary functionality hasn't.
>
> (While I'm at it: I will be away tomorrow (July 1) through
> July 14 so might not respond to mail promptly.)
>
> -Doug


From david.lloyd at redhat.com  Tue Jun 30 12:02:13 2009
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 30 Jun 2009 11:02:13 -0500
Subject: [concurrency-interest]
	Bug	in	CustomConcurrentHashMap.KeySet.intern()
In-Reply-To: <4A4A2C4A.7040405@renxo.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4A2C4A.7040405@renxo.com>
Message-ID: <4A4A3705.4010605@redhat.com>

I can reply to that - yes, I use ConcurrentReferenceHashMap in several 
projects including the new JBoss Remoting, and it is also in use in a few 
other places in JBoss code.  My own testing demonstrates that it's quite 
stable for the uses to which I have put it, but there's certainly no 
warranty of any kind attached to it (as per the various license agreements).

That said, once there's an accepted standard implementation for this 
purpose, chances are good that I'll switch to it at that time unless 
there's a compelling reason not to; I'm using it mainly because I needed an 
immediate solution, and that's what was available (and that it was 
developed in large part by a coworker of mine (Jason T. Greene, also on 
this list), so I can hassle him directly with questions).

- DML

On 06/30/2009 10:16 AM, Manuel Dominguez Sarmiento wrote:
> Hi Doug,
> 
> Thanks for the update. I noticed that several projects are using some 
> form or another of ConcurrentReferenceHashMap, which I believe is the 
> precursor to CustomConcurrentHashMap (for instance, JBoss Remoting as 
> well as a few others are using these on their releases). Are these 
> versions any more stable? If so, were can I find the latest source (I 
> can only find CustomConcurrentHashMap in CVS).
> 
> Thanks!
> 
> Ing. Manuel Dominguez Sarmiento
> Director General
> Renxo S.A.
> e-mail:    mads at renxo.com
> Phone:    +54 11 4719 6806, ext. 104
> 
> 
> 
> Doug Lea wrote:
>> Manuel Dominguez Sarmiento wrote:
>>> Hi,
>>>
>>> I found that CustomConcurrentHashMap.KeySet.intern() was the perfect 
>>> fit for the object interning need we're having with a current project. 
>>
>>> However, doPut() returns null when a key is first added to the map. 
>>> It could be easily fixed as follows:
>>>
>>>        public K intern(K e) {
>>>            K oldElement = cchm.doPut(e, e, true);
>>>            return (oldElement != null) ? oldElement : e;
>>>        }
>>
>> Thanks! Fixed.
>>
>>>
>>> BTW, how stable is this preview release for production use? Any caveats?
>>
>> Not at all stable. The version there was checked in to
>> allow discussion about how to support various cache-like
>> uses (which is among the main reasons for people to use it.)
>> Which led to some explorations on my part on
>> how to efficiently support customized eviction policies
>> Which has in turn led to various diversions on concurrent
>> (and non-concurrent) hashing that further stall getting
>> this in releasable form.
>>
>> The Map functionality has been well-tested, but as you saw, the
>> auxiliary functionality hasn't.
>>
>> (While I'm at it: I will be away tomorrow (July 1) through
>> July 14 so might not respond to mail promptly.)
>>
>> -Doug
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From mads at renxo.com  Tue Jun 30 12:37:20 2009
From: mads at renxo.com (Manuel Dominguez Sarmiento)
Date: Tue, 30 Jun 2009 13:37:20 -0300
Subject: [concurrency-interest]
	Bug	in	CustomConcurrentHashMap.KeySet.intern()
In-Reply-To: <4A4A3705.4010605@redhat.com>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
	<4A4A2C4A.7040405@renxo.com> <4A4A3705.4010605@redhat.com>
Message-ID: <4A4A3F40.1020703@renxo.com>

Hi David,

Thanks for the info. Is the implementation of the new 
CustomConcurrentHashMap basically the same as ConcurrentReferenceHashMap 
or does it contain any significant design differences? On the surface 
they look pretty similar but I'm not so sure about the internals.

Ing. Manuel Dominguez Sarmiento
Director General
Renxo S.A.
e-mail:	mads at renxo.com
Phone:	+54 11 4719 6806, ext. 104



David M. Lloyd wrote:
> I can reply to that - yes, I use ConcurrentReferenceHashMap in several 
> projects including the new JBoss Remoting, and it is also in use in a 
> few other places in JBoss code.  My own testing demonstrates that it's 
> quite stable for the uses to which I have put it, but there's 
> certainly no warranty of any kind attached to it (as per the various 
> license agreements).
>
> That said, once there's an accepted standard implementation for this 
> purpose, chances are good that I'll switch to it at that time unless 
> there's a compelling reason not to; I'm using it mainly because I 
> needed an immediate solution, and that's what was available (and that 
> it was developed in large part by a coworker of mine (Jason T. Greene, 
> also on this list), so I can hassle him directly with questions).
>
> - DML
>
> On 06/30/2009 10:16 AM, Manuel Dominguez Sarmiento wrote:
>> Hi Doug,
>>
>> Thanks for the update. I noticed that several projects are using some 
>> form or another of ConcurrentReferenceHashMap, which I believe is the 
>> precursor to CustomConcurrentHashMap (for instance, JBoss Remoting as 
>> well as a few others are using these on their releases). Are these 
>> versions any more stable? If so, were can I find the latest source (I 
>> can only find CustomConcurrentHashMap in CVS).
>>
>> Thanks!
>>
>> Ing. Manuel Dominguez Sarmiento
>> Director General
>> Renxo S.A.
>> e-mail:    mads at renxo.com
>> Phone:    +54 11 4719 6806, ext. 104
>>
>>
>>
>> Doug Lea wrote:
>>> Manuel Dominguez Sarmiento wrote:
>>>> Hi,
>>>>
>>>> I found that CustomConcurrentHashMap.KeySet.intern() was the 
>>>> perfect fit for the object interning need we're having with a 
>>>> current project. 
>>>
>>>> However, doPut() returns null when a key is first added to the map. 
>>>> It could be easily fixed as follows:
>>>>
>>>>        public K intern(K e) {
>>>>            K oldElement = cchm.doPut(e, e, true);
>>>>            return (oldElement != null) ? oldElement : e;
>>>>        }
>>>
>>> Thanks! Fixed.
>>>
>>>>
>>>> BTW, how stable is this preview release for production use? Any 
>>>> caveats?
>>>
>>> Not at all stable. The version there was checked in to
>>> allow discussion about how to support various cache-like
>>> uses (which is among the main reasons for people to use it.)
>>> Which led to some explorations on my part on
>>> how to efficiently support customized eviction policies
>>> Which has in turn led to various diversions on concurrent
>>> (and non-concurrent) hashing that further stall getting
>>> this in releasable form.
>>>
>>> The Map functionality has been well-tested, but as you saw, the
>>> auxiliary functionality hasn't.
>>>
>>> (While I'm at it: I will be away tomorrow (July 1) through
>>> July 14 so might not respond to mail promptly.)
>>>
>>> -Doug
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ben_manes at yahoo.com  Tue Jun 30 15:19:22 2009
From: ben_manes at yahoo.com (Ben Manes)
Date: Tue, 30 Jun 2009 12:19:22 -0700 (PDT)
Subject: [concurrency-interest] Bug in
	CustomConcurrentHashMap.KeySet.intern()
In-Reply-To: <4A4A2A78.7050705@cs.oswego.edu>
References: <4A4920A8.2030400@renxo.com> <4A4A2A78.7050705@cs.oswego.edu>
Message-ID: <473271.15026.qm@web38807.mail.mud.yahoo.com>

> The version there was checked in to allow discussion...

My personal preference would be a decorator-style approach rather than a god class.  Its a hard trade-off between flexibility and usability, such as the debates over the merits of the design for the Java-1.0 file streaming APIs.  I tend to prefer the flexibility and reduce the verbosity through builders and utilities, so that the programming model is still convenient.

The nice aspect of a decorator approach is that it is pluggable, though coordination is definitely harder to get right.  I support all of the features of the CCHM, as well as features that are incompatible if I based my implementations off of it.  I have the following:
- SelfPopulatingMap: single and bulk memoization, atomic refresh
- ExpirableMap: expiration support (lazy or eager) + listener
- IndexMap: Multiple keys --> value mapping
- Pluggable  data store for eviction + listener (ConcurrentMap --> no-op, unbounded, reference map, ehcache, etc)
- A builder to coordinate the construction

If it was not for the builder to hide the complexity of the coordination between decorators I would find it a hard trade-off, but the flexibility has been quite valuable.  Even then, if I had not written these prior to CCHM being available I may not have originally found the effort worthwhile.

-Ben




________________________________
From: Doug Lea <dl at cs.oswego.edu>
To: mads at renxo.com
Cc: concurrency-interest at cs.oswego.edu
Sent: Tuesday, June 30, 2009 8:08:40 AM
Subject: Re: [concurrency-interest] Bug in CustomConcurrentHashMap.KeySet.intern()

Manuel Dominguez Sarmiento wrote:
> Hi,
> 
> I found that CustomConcurrentHashMap.KeySet.intern() was the perfect fit for the object interning need we're having with a current project. 

> However, doPut() returns null when a key is first added to the map. It could be easily fixed as follows:
> 
>        public K intern(K e) {
>            K oldElement = cchm.doPut(e, e, true);
>            return (oldElement != null) ? oldElement : e;
>        }

Thanks! Fixed.

> 
> BTW, how stable is this preview release for production use? Any caveats?

Not at all stable. The version there was checked in to
allow discussion about how to support various cache-like
uses (which is among the main reasons for people to use it.)
Which led to some explorations on my part on
how to efficiently support customized eviction policies
Which has in turn led to various diversions on concurrent
(and non-concurrent) hashing that further stall getting
this in releasable form.

The Map functionality has been well-tested, but as you saw, the
auxiliary functionality hasn't.

(While I'm at it: I will be away tomorrow (July 1) through
July 14 so might not respond to mail promptly.)

-Doug
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20090630/9536635c/attachment.html>

From alarmnummer at gmail.com  Tue Jun 30 16:22:49 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 30 Jun 2009 22:22:49 +0200
Subject: [concurrency-interest] adaptive spinning/biased locking and
	java.util.concurrent.lock
Message-ID: <1466c1d60906301322h7132529clf625a2ce68b011d9@mail.gmail.com>

Hi Guys,

do modern jvm's also provide adaptive spinning and biased locking for
the lock implementations (especially the reentrantlock) in the
java.util.concurrent.locks package or is this only provided for the
intrinsic lock?

Peter

From jeremy.manson at gmail.com  Tue Jun 30 16:23:54 2009
From: jeremy.manson at gmail.com (Jeremy Manson)
Date: Tue, 30 Jun 2009 13:23:54 -0700
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
Message-ID: <1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>

On Tue, Jun 30, 2009 at 5:25 AM, Peter Veentjer<alarmnummer at gmail.com> wrote:
>> It seems to me that immutability for the sake of propagating constructor
>> changes to main memory
>> is something of a misnomer - this is more about using the 'final' keyword as
>> a coarse grained hook into the
>> java memory model. Maybe if we had more direct access to that memory model
>> then we could ensure
>> that mutable objects could safely be constructed as well, for example:
>>
>> public class MyMutableClass {
>> ? private String myNonFinal;
>>
>> ? public MyClass() {
>> ? ? ?this.myNonFinal = "hello world";
>> ? ? ?MemoryModel.flush(); // flush-commit similar to other cache
>> technologies
>> ? }
>> }
>
> I don't see a happens before relation between the write of the
> myNonFinal example and the usage. So I don't think this example is
> going to work.

I think he was trying to express that the implicit relationship
between the write of a final and its reads is enforced by this API.
Something like this may be in the Fences API in Java 7.

Jeremy


From alarmnummer at gmail.com  Tue Jun 30 16:32:14 2009
From: alarmnummer at gmail.com (Peter Veentjer)
Date: Tue, 30 Jun 2009 22:32:14 +0200
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>
	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>
	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
Message-ID: <1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>

On Tue, Jun 30, 2009 at 10:23 PM, Jeremy Manson<jeremy.manson at gmail.com> wrote:
> On Tue, Jun 30, 2009 at 5:25 AM, Peter Veentjer<alarmnummer at gmail.com> wrote:
>>> It seems to me that immutability for the sake of propagating constructor
>>> changes to main memory
>>> is something of a misnomer - this is more about using the 'final' keyword as
>>> a coarse grained hook into the
>>> java memory model. Maybe if we had more direct access to that memory model
>>> then we could ensure
>>> that mutable objects could safely be constructed as well, for example:
>>>
>>> public class MyMutableClass {
>>> ? private String myNonFinal;
>>>
>>> ? public MyClass() {
>>> ? ? ?this.myNonFinal = "hello world";
>>> ? ? ?MemoryModel.flush(); // flush-commit similar to other cache
>>> technologies
>>> ? }
>>> }
>>
>> I don't see a happens before relation between the write of the
>> myNonFinal example and the usage. So I don't think this example is
>> going to work.
>
> I think he was trying to express that the implicit relationship
> between the write of a final and its reads is enforced by this API.
> Something like this may be in the Fences API in Java 7.
>
> Jeremy

Hi Jeremy,

but you still need a store and load fence to guarantee a happens
before relation between the write and the read *in nitpicking mode*.

PS: Do you have a reference to the other concurrency features that are
going to be added (apart from the fences and the fork/join
functionality) to Java 7?


From dl at cs.oswego.edu  Tue Jun 30 16:46:38 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 30 Jun 2009 16:46:38 -0400
Subject: [concurrency-interest] Immutable object conundrums
In-Reply-To: <1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
References: <1DE3381E-2E8F-4368-A937-7E01484BE117@mac.com>	<1466c1d60906300525hf70987cnf396d6947786764e@mail.gmail.com>	<1631da7d0906301323p3fa535d7va4f4e0a189b8086e@mail.gmail.com>
	<1466c1d60906301332j61bc8cb0r9001716ad9b518d7@mail.gmail.com>
Message-ID: <4A4A79AE.7020603@cs.oswego.edu>

Peter Veentjer wrote:

> PS: Do you have a reference to the other concurrency features that are
> going to be added (apart from the fences and the fork/join
> functionality) to Java 7?
> 

Definitely planned classes are in package jsr166y --
ForkJoin, Phasers, TransferQueue, ThreadLocalRandom. See
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/

Plus Fences, which can't be previewed in jsr166y since
it relies on JVM support. See
http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/Fences.html

Plus possibly some sort of customized hash map.
The main reason for delay on that is algorithmic:
Efficient support for features like eviction and
memoization across a large enough range of
policies to be worth supporting in concurrent maps is not a
fully solved problem. I want to make sure that
we offer only that range of them for which we are
very sure we can support well, but without closing
the door to future algorithmic overhauls.

-Doug


From dl at cs.oswego.edu  Tue Jun 30 16:51:58 2009
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 30 Jun 2009 16:51:58 -0400
Subject: [concurrency-interest] adaptive spinning/biased locking
	and	java.util.concurrent.lock
In-Reply-To: <1466c1d60906301322h7132529clf625a2ce68b011d9@mail.gmail.com>
References: <1466c1d60906301322h7132529clf625a2ce68b011d9@mail.gmail.com>
Message-ID: <4A4A7AEE.90102@cs.oswego.edu>

Peter Veentjer wrote:
> Hi Guys,
> 
> do modern jvm's also provide adaptive spinning and biased locking for
> the lock implementations (especially the reentrantlock) in the
> java.util.concurrent.locks package or is this only provided for the
> intrinsic lock?
> 

Only intrinsics. Biased locking does not work well
for locks that you expect to contend, which are among
the typical cases for using ReentrantLock. We might
someday want to automate adaptive spinning in
ReentrantLock and other AQS locks. However, this is
less pressing an issue than it is for in intrinsic locks,
since you can always use tryLock-based constructions
to increase spinning.

-Doug

From davidcholmes at aapt.net.au  Tue Jun 30 20:18:25 2009
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 1 Jul 2009 10:18:25 +1000
Subject: [concurrency-interest] adaptive spinning/biased lockingand
	java.util.concurrent.lock
In-Reply-To: <4A4A7AEE.90102@cs.oswego.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEHFICAA.davidcholmes@aapt.net.au>

Can I also clarify something about biased-locking as I recently encountered
some very mis-guided perceptions of what it is. :)

Biased-locking exists to make un-needed synchronization as cheap as
possible. It works on the assumption that objects are not shared, so locks
are not contended and so aren't in fact needed. So when an object acquires a
monitor lock it simply does a fast-lock by CAS'ing in the owning thread's Id
into the object header. But the release of the lock is almost a no-op, it
leaves the object "locked" by that original thread. Subsequent locks by that
thread then don't need the (expensive) CAS. If another thread tries to lock
the object we go through an expensive bias-revocation process and revert to
using normal locking - the fact that contention occurred shows biasedlocking
is not applicable to this object.

As Doug says you don't tend to use j.u.c Locks in circumstances where
biased-locking would be beneficial.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Doug Lea
> Sent: Wednesday, 1 July 2009 6:52 AM
> To: Peter Veentjer
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] adaptive spinning/biased lockingand
> java.util.concurrent.lock
>
>
>
> Peter Veentjer wrote:
> > Hi Guys,
> >
> > do modern jvm's also provide adaptive spinning and biased locking for
> > the lock implementations (especially the reentrantlock) in the
> > java.util.concurrent.locks package or is this only provided for the
> > intrinsic lock?
> >
>
> Only intrinsics. Biased locking does not work well
> for locks that you expect to contend, which are among
> the typical cases for using ReentrantLock. We might
> someday want to automate adaptive spinning in
> ReentrantLock and other AQS locks. However, this is
> less pressing an issue than it is for in intrinsic locks,
> since you can always use tryLock-based constructions
> to increase spinning.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



