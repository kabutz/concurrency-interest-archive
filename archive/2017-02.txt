From akarnokd at gmail.com  Thu Feb  2 08:01:51 2017
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Thu, 2 Feb 2017 14:01:51 +0100
Subject: [concurrency-interest] JDK 9 FutureTask's use of Thread.yield
Message-ID: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>

I'm trying to port some some building blocks of Java's ExecutorServices to
less fortunate platforms and I've noticed FutureTask of JDK 9 uses
Thread.yield in some of its spin loops (
http://hg.openjdk.java.net/jdk9/jdk9/jdk/file/e170c858888e/src/java.base/share/classes/java/util/concurrent/FutureTask.java#l333
for example) to wait some other party to finish up.

Maybe this was discussed before, but wouldn't it make more sense to have
Thread.onSpinWait() at these locations (now that it is available) just by
itself or as a code that leads to the current Thread.yield() approach?

-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170202/609fa6d6/attachment.html>

From rl.stpuu at gmail.com  Thu Feb  2 08:08:54 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Thu, 2 Feb 2017 14:08:54 +0100
Subject: [concurrency-interest] Logic Colloquium 2017: First Announcement
	and Call for Submissions
Message-ID: <CACAe74iLGUYWYfXyZ6=Qp8podmEJY5Kk-XLzS15s4XrJte=9CQ@mail.gmail.com>

Logic Colloquium 2017:
First Announcement and Call for Submissions

August 14-20, 2017, Stockholm, Sweden

https://www.lc17.conf.kth.se

The Logic Colloquium 2017 (LC2017) is the 2017 Annual European summer
meeting of the Association for Symbolic Logic (ASL) and will be held
during August 14-20, 2017 at the main campus of Stockholm University.
The Logic Colloquium 2017 is organised and hosted jointly by the
Departments of Mathematics and Philosophy at Stockholm University, and
is also supported by the KTH Royal Institute of Technology.

LC2017 will be co-located with two other logic-related events, all
taking place at Stockholm University:
- the 3rd Nordic Logic Summer School, NLS2017, August 7-12
- the 26th EACSL Annual Conference on Computer Science Logic, CSL2017,
August 20-24.

There will be a joint session of CSL2017 and LC2017 in the morning of August 20.
Further information about all events can be found at:

https://www.lis17.conf.kth.se

The programme of LC2017 will also include special sessions, which will
be announced later.

INVITED SPEAKERS
------------------------------
Plenary speakers:

- David Aspero (University of East Anglia)
- Alessandro Berarducci (Pisa)
- Elisabeth Bouscaren (Paris 11)
- Christina Brech (Sao Paolo)
- Sakae Fuchino (Kobe University)
- Denis Hirschfeldt (University of Chicago)
- Wilfrid Hodges (British Academy)
- Emil Jerabek (Prague)
- Per Martin-Löf (Stockholm University)
- Dag Prawitz (Stockholm University)
- Sonja Smets (University of Amsterdam)

Tutorial speakers:

- Patricia Bouyer-Decitre (LSV ENS Cachan)
- Mai Gehrke (Paris 7)

LC-CSL joint session highlight speakers:

- Veronica Becher (Buenos Aires)
- Pierre Simon (UC Berkeley)

SUBMISSIONS OF CONTRIBUTED TALKS
---------------------
Abstracts of contributed talks must be submitted as pdf files via this
EasyChair page:
https://easychair.org/conferences/?conf=lc2017
(If you do not have an EasyChair-account yet, you can create one at
the submission site.)

The abstracts must be prepared according to the ASL instructions here:
http://www.aslonline.org/rules_abstracts.html
Please enter Title and Abstract as plain text. As the first keyword, put
the AMS 2010 classification: 03xxx

Abstracts of contributed talks submitted by ASL members, which are
accepted and prepared according to the ASL Rules for Abstracts will be
published in The Bulletin of Symbolic Logic. Upon notification of
acceptance, authors will be requested to submit the LaTex source files.

ASL will provide some student grants for participation at the LC2017.

IMPORTANT DATES
--------------------------------------------------------
Abstract submission for contributed talks:  May 5, 2017
Notification:                               TBA
--------------------------------------------------------

PROGRAMME COMMITTEE
-------------------
- Rod Downey (University of Wellington)
- Mirna Dzamonja (PC chair, University of East Anglia)
- Ali Enayat (University of Gothenburg)
- Fernando Ferreira (University of Lisbon)
- Valentin Goranko (Stockholm University)
- Martin Hils (University of Münster)
- Sara Negri (University of Helsinki)
- Assaf Rinot (Bar-Ilan University)
- Igor Walukiewicz (University of Bordeaux)

ORGANISING COMMITTEE
--------------------
- Mads Dam, Department of Theoretical Computer Science, KTH
- Valentin Goranko (OC co-chair), Department of Philosophy, Stockholm University
- Sven-Ove Hansson, Department of Philosophy, KTH Royal Institute of Technology
- Eric Johannesson, Department of Philosophy, Stockholm University
- Vera Koponen, Department of Mathematics, Uppsala University
- Roussanka Loukanova, Department of Mathematics, Stockholm University
- Peter LeFanu Lumsdaine, Department of Mathematics, Stockholm University
- Peter Pagin, Department of Philosophy, Stockholm University
- Anders Lundstedt, Department of Philosophy, Stockholm University
- Erik Palmgren (OC co-chair), Department of Mathematics, Stockholm University
- Dag Westerståhl, Department of Philosophy, Stockholm University

CONTACTS AND ENQUIRIES
--------------------
For enquiries on scientific and programme issues, send email to:
Mirna Dzamonja (M.Dzamonja at uea.ac.uk)
For enquiries on organising matters, send email to:
lc2017 at philosophy.su.se

From heinz at javaspecialists.eu  Thu Feb  2 09:15:04 2017
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 02 Feb 2017 16:15:04 +0200
Subject: [concurrency-interest] Invitation to Webinar about Fork/Join and
	ManagedBlocker
Message-ID: <58933EE8.40206@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170202/f52b935c/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: regular fork-join.png
Type: image/png
Size: 1005916 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170202/f52b935c/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ManagedBlocker fork-join.png
Type: image/png
Size: 1033537 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170202/f52b935c/attachment-0003.png>

From aph at redhat.com  Thu Feb  2 09:24:25 2017
From: aph at redhat.com (Andrew Haley)
Date: Thu, 2 Feb 2017 14:24:25 +0000
Subject: [concurrency-interest] JDK 9 FutureTask's use of Thread.yield
In-Reply-To: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>
References: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>
Message-ID: <3275d3f4-04b7-56f2-7ad9-5259592e5901@redhat.com>

On 02/02/17 13:01, Dávid Karnok wrote:
> Maybe this was discussed before, but wouldn't it make more sense to have
> Thread.onSpinWait() at these locations (now that it is available) just by
> itself or as a code that leads to the current Thread.yield() approach?

They aren't really equivalent.  onSpinWait() should be used on x86
systems whenever there is a spin, but it doesn't actually yield.  A
common pattern would be something like

   while (state == INTERRUPTING && counter-- > 0) {
       Thread.onSpinWait();
   }
   while (state == INTERRUPTING) {
       Thread.yield();
   }

which does a hard spin for a while, then backs off to using yield().

BTW, I'm not sure that Thread.onSpinWait() has an implementation other
than x86, where it generates a PAUSE instruction.

Andrew.

From akarnokd at gmail.com  Thu Feb  2 09:36:03 2017
From: akarnokd at gmail.com (=?UTF-8?Q?D=C3=A1vid_Karnok?=)
Date: Thu, 2 Feb 2017 15:36:03 +0100
Subject: [concurrency-interest] JDK 9 FutureTask's use of Thread.yield
In-Reply-To: <3275d3f4-04b7-56f2-7ad9-5259592e5901@redhat.com>
References: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>
 <3275d3f4-04b7-56f2-7ad9-5259592e5901@redhat.com>
Message-ID: <CAAWwtm_VNH-3D2ZPaKdMbo+mbcNOSQfB5e8_tvH5_Z33PjgpUw@mail.gmail.com>

Yes, I understand onSpinWait may be no-op on platforms and that
Thread.yield() could be also no-op.

But in case they actually do something, are there any implications for
FutureTask in JDK 9 to have

 1) just the onSpinWait() loop,
 2) both loops or
 3) stay with the yield() loop?

As a support argument, many similar spin loops have been changed to
onSpinWait() in the JDK so I assume either this instance was overlooked or
there is something else that depends on these kinds of loops in FutureTask
to be yield().

2017-02-02 15:24 GMT+01:00 Andrew Haley <aph at redhat.com>:

> On 02/02/17 13:01, Dávid Karnok wrote:
> > Maybe this was discussed before, but wouldn't it make more sense to have
> > Thread.onSpinWait() at these locations (now that it is available) just by
> > itself or as a code that leads to the current Thread.yield() approach?
>
> They aren't really equivalent.  onSpinWait() should be used on x86
> systems whenever there is a spin, but it doesn't actually yield.  A
> common pattern would be something like
>
>    while (state == INTERRUPTING && counter-- > 0) {
>        Thread.onSpinWait();
>    }
>    while (state == INTERRUPTING) {
>        Thread.yield();
>    }
>
> which does a hard spin for a while, then backs off to using yield().
>
> BTW, I'm not sure that Thread.onSpinWait() has an implementation other
> than x86, where it generates a PAUSE instruction.
>
> Andrew.
>



-- 
Best regards,
David Karnok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170202/466e2bd5/attachment.html>

From dl at cs.oswego.edu  Thu Feb  2 15:39:16 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 2 Feb 2017 15:39:16 -0500
Subject: [concurrency-interest] JDK 9 FutureTask's use of Thread.yield
In-Reply-To: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>
References: <CAAWwtm9_trigB8MyFsjZ_zpfhFYm3b-O6iqUgbHGRBZ7_TmwJA@mail.gmail.com>
Message-ID: <dfb41952-bc81-d6f2-3821-e57b22a4033f@cs.oswego.edu>

On 02/02/2017 08:01 AM, Dávid Karnok wrote:
> I'm trying to port some some building blocks of Java's ExecutorServices
> to less fortunate platforms and I've noticed FutureTask of JDK 9 uses
> Thread.yield in some of its spin loops
> (http://hg.openjdk.java.net/jdk9/jdk9/jdk/file/e170c858888e/src/java.base/share/classes/java/util/concurrent/FutureTask.java#l333
> for example) to wait some other party to finish up.
>
> Maybe this was discussed before, but wouldn't it make more sense to have
> Thread.onSpinWait() at these locations (now that it is available) just
> by itself or as a code that leads to the current Thread.yield() approach?
>

Every use of Thread.onSpinWait and/or Thread.yield and/or some sort of
(possibly timed) blocking synchronization requires a rough prediction
about the cause of the blockage. When there's a good chance that it
is in part due to underprovisioning (many runnable threads, few
available CPUs), we don't normally use spin-waits. In other words, we
use spins in those  cases where by nature of component usages, there is
likely to be available parallelism (for example in Phasers). Which can
be overly conservative, and subject to re-evaluation from time to time.
In partial compensation, in almost all cases, we support poll-style
vs blocking methods that allow users themselves to attach spin loops
when it makes sense.


-Doug



From rl.stpuu at gmail.com  Thu Feb  2 16:10:54 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Thu, 2 Feb 2017 22:10:54 +0100
Subject: [concurrency-interest] Logic Colloquium 2017: First Announcement
	and Call for Submissions [CORRECTION]
Message-ID: <CACAe74g+Ok+e6pOmNEnXCY7bm8VQjvCumcSK2+zAXAtpaJF+wA@mail.gmail.com>

Logic Colloquium 2017:
First Announcement and Call for Submissions

August 14-20, 2017, Stockholm, Sweden

https://www.lc17.conf.kth.se

The Logic Colloquium 2017 (LC2017) is the 2017 Annual European summer
meeting of the Association for Symbolic Logic (ASL) and will be held
during August 14-20, 2017 at the main campus of Stockholm University.
The Logic Colloquium 2017 is organised and hosted jointly by the
Departments of Mathematics and Philosophy at Stockholm University, and
is also supported by the KTH Royal Institute of Technology.

LC2017 will be co-located with two other logic-related events, all
taking place at Stockholm University:
- the 3rd Nordic Logic Summer School, NLS2017, August 7-12
- the 26th EACSL Annual Conference on Computer Science Logic, CSL2017,
August 20-24.

There will be a joint session of CSL2017 and LC2017 in the morning of August 20.
Further information about all events can be found at:

https://www.lis17.conf.kth.se

The programme of LC2017 will also include special sessions, which will
be announced later.

INVITED SPEAKERS
------------------------------
Plenary speakers:

- David Aspero (University of East Anglia)
- Alessandro Berarducci (Pisa)
- Elisabeth Bouscaren (Paris 11)
- Christina Brech (Sao Paulo)
- Sakae Fuchino (Kobe University)
- Denis Hirschfeldt (University of Chicago)
- Wilfrid Hodges (British Academy)
- Emil Jerabek (Prague)
- Per Martin-Löf (Stockholm University)
- Dag Prawitz (Stockholm University)
- Sonja Smets (University of Amsterdam)

Tutorial speakers:

- Patricia Bouyer-Decitre (LSV ENS Cachan)
- Mai Gehrke (Paris 7)

LC2017 invited highlight speakers for the joint LC-CSL session:

- Veronica Becher (Buenos Aires)
- Pierre Simon (UC Berkeley)

SUBMISSIONS OF CONTRIBUTED TALKS
---------------------
Abstracts of contributed talks must be submitted as pdf files via this
EasyChair page:
https://easychair.org/conferences/?conf=lc2017
(If you do not have an EasyChair-account yet, you can create one at
the submission site.)

The abstracts must be prepared according to the ASL instructions here:
http://www.aslonline.org/rules_abstracts.html
Please enter Title and Abstract as plain text. As the first keyword, put
the AMS 2010 classification: 03xxx

Abstracts of contributed talks submitted by ASL members, which are
accepted and prepared according to the ASL Rules for Abstracts will be
published in The Bulletin of Symbolic Logic. Upon notification of
acceptance, authors will be requested to submit the LaTex source files.

ASL will provide some student grants for participation at the LC2017.

IMPORTANT DATES
--------------------------------------------------------
Abstract submission for contributed talks:  May 5, 2017
Notification:                               TBA
--------------------------------------------------------

PROGRAMME COMMITTEE
-------------------
- Rod Downey (University of Wellington)
- Mirna Dzamonja (PC chair, University of East Anglia)
- Ali Enayat (University of Gothenburg)
- Fernando Ferreira (University of Lisbon)
- Valentin Goranko (Stockholm University)
- Martin Hils (University of Münster)
- Sara Negri (University of Helsinki)
- Assaf Rinot (Bar-Ilan University)
- Igor Walukiewicz (University of Bordeaux)

ORGANISING COMMITTEE
--------------------
- Mads Dam, Department of Theoretical Computer Science, KTH
- Valentin Goranko (OC co-chair), Department of Philosophy, Stockholm University
- Sven-Ove Hansson, Department of Philosophy, KTH Royal Institute of Technology
- Eric Johannesson, Department of Philosophy, Stockholm University
- Vera Koponen, Department of Mathematics, Uppsala University
- Roussanka Loukanova, Department of Mathematics, Stockholm University
- Peter LeFanu Lumsdaine, Department of Mathematics, Stockholm University
- Peter Pagin, Department of Philosophy, Stockholm University
- Anders Lundstedt, Department of Philosophy, Stockholm University
- Erik Palmgren (OC co-chair), Department of Mathematics, Stockholm University
- Dag Westerståhl, Department of Philosophy, Stockholm University

CONTACTS AND ENQUIRIES
--------------------
For enquiries on scientific and programme issues, send email to:
Mirna Dzamonja (M.Dzamonja at uea.ac.uk)
For enquiries on organising matters, send email to:
lc2017 at philosophy.su.sew

From rl.stpuu at gmail.com  Thu Feb  2 16:44:18 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Thu, 2 Feb 2017 22:44:18 +0100
Subject: [concurrency-interest] Logic Colloquium 2017: First Announcement
	and Call for Submissions [CORRECTION-2]
Message-ID: <CACAe74griyEAk4mzd43Z3SbFjPfEgAW68PfpPsrtPDyWN__O=A@mail.gmail.com>

Logic Colloquium 2017:
First Announcement and Call for Submissions

August 14-20, 2017, Stockholm, Sweden

https://www.lc17.conf.kth.se

The Logic Colloquium 2017 (LC2017) is the 2017 Annual European summer
meeting of the Association for Symbolic Logic (ASL) and will be held
during August 14-20, 2017 at the main campus of Stockholm University.
The Logic Colloquium 2017 is organised and hosted jointly by the
Departments of Mathematics and Philosophy at Stockholm University, and
is also supported by the KTH Royal Institute of Technology.

LC2017 will be co-located with two other logic-related events, all
taking place at Stockholm University:
- the 3rd Nordic Logic Summer School, NLS2017, August 7-12
- the 26th EACSL Annual Conference on Computer Science Logic, CSL2017,
August 20-24.

There will be a joint session of CSL2017 and LC2017 in the morning of August 20.
Further information about all events can be found at:

https://www.lis17.conf.kth.se

The programme of LC2017 will also include special sessions, which will
be announced later.

INVITED SPEAKERS
------------------------------
Plenary speakers:

- David Aspero (University of East Anglia)
- Alessandro Berarducci (Pisa)
- Elisabeth Bouscaren (Paris 11)
- Christina Brech (Sao Paulo)
- Sakae Fuchino (Kobe University)
- Denis Hirschfeldt (University of Chicago)
- Wilfrid Hodges (British Academy)
- Emil Jerabek (Prague)
- Per Martin-Löf (Stockholm University)
- Dag Prawitz (Stockholm University)
- Sonja Smets (University of Amsterdam)

Tutorial speakers:

- Patricia Bouyer-Decitre (LSV ENS Cachan)
- Mai Gehrke (Paris 7)

LC2017 invited highlight speakers for the joint LC-CSL session:

- Veronica Becher (Buenos Aires)
- Pierre Simon (UC Berkeley)

SUBMISSIONS OF CONTRIBUTED TALKS
---------------------
Abstracts of contributed talks must be submitted as pdf files via this
EasyChair page:
https://easychair.org/conferences/?conf=lc2017
(If you do not have an EasyChair-account yet, you can create one at
the submission site.)

The abstracts must be prepared according to the ASL instructions here:
http://www.aslonline.org/rules_abstracts.html
Please enter Title and Abstract as plain text. As the first keyword, put
the AMS 2010 classification: 03xxx

Abstracts of contributed talks submitted by ASL members, which are
accepted and prepared according to the ASL Rules for Abstracts will be
published in The Bulletin of Symbolic Logic. Upon notification of
acceptance, authors will be requested to submit the LaTex source files.

ASL will provide some student grants for participation at the LC2017.

IMPORTANT DATES
--------------------------------------------------------
Abstract submission for contributed talks:  May 5, 2017
Notification:                               TBA
--------------------------------------------------------

PROGRAMME COMMITTEE
-------------------
- Rod Downey (University of Wellington)
- Mirna Dzamonja (PC chair, University of East Anglia)
- Ali Enayat (University of Gothenburg)
- Fernando Ferreira (University of Lisbon)
- Valentin Goranko (Stockholm University)
- Martin Hils (University of Münster)
- Sara Negri (University of Helsinki)
- Assaf Rinot (Bar-Ilan University)
- Igor Walukiewicz (University of Bordeaux)

ORGANISING COMMITTEE
--------------------
- Mads Dam, Department of Theoretical Computer Science, KTH
- Valentin Goranko (OC co-chair), Department of Philosophy, Stockholm University
- Sven-Ove Hansson, Department of Philosophy, KTH Royal Institute of Technology
- Eric Johannesson, Department of Philosophy, Stockholm University
- Vera Koponen, Department of Mathematics, Uppsala University
- Roussanka Loukanova, Department of Mathematics, Stockholm University
- Peter LeFanu Lumsdaine, Department of Mathematics, Stockholm University
- Peter Pagin, Department of Philosophy, Stockholm University
- Anders Lundstedt, Department of Philosophy, Stockholm University
- Erik Palmgren (OC co-chair), Department of Mathematics, Stockholm University
- Dag Westerståhl, Department of Philosophy, Stockholm University

CONTACTS AND ENQUIRIES
--------------------
For enquiries on scientific and programme issues, send email to:
Mirna Dzamonja (M.Dzamonja at uea.ac.uk)
For enquiries on organising matters, send email to:
lc2017 at philosophy.su.se

From rl.stpuu at gmail.com  Fri Feb  3 18:59:18 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Sat, 4 Feb 2017 00:59:18 +0100
Subject: [concurrency-interest] CfP - Logic, Information, Language, Memory,
 Reasoning 2017 (LogInfoLangMR'17) New Deadline Feb 13, 2017
Message-ID: <CACAe74iA5EzRqPRGrHWZ9VJQGSwL=xhbgALHSiVT_3Jaw8LY=A@mail.gmail.com>

=========================================================================
                        CALL FOR PAPERS

                      Special Session on
Logic, Information, Language, Memory, Reasoning 2017 (LogInfoLangMR’17)

   http://www.dcai-conference.net/special-sessions/loginfolangmr

14th International Conference on Distributed Computing and Artificial
Intelligence 2017 (DCAI'17)

             Polytechnic of Porto, Porto (Portugal)
                       June 21-23, 2017

            * Submission deadline: February 13, 2017 *
=========================================================================

DESCRIPTION
=====
We are in the reality of systems that model human language, reasoning,
and use advanced techniques for saving and accessing information.
Prominently, computational processing of human language is an
interdisciplinary area of research and development of computerized
systems. In nature, relations between information, language,
reasoning, and memory have many, interdependent facets that can be
heterogeneous. Theories, applications, and technologies strive to meet
adequate treatment of natural phenomena of information, language, and
information exchange. Furthermore, integrated approaches from
mathematics and computer science provide support for reliable,
advanced, applications.

We welcome submissions of papers on the following topics, without
limiting to them, across theories, applications, methods, approaches,
and technologies:

- Logic for applications to language processing
- Classic and new theories of formal and natural languages
- Computational processing of natural language --- approaches,
theories, methods, computerized systems
- Computational morphology, syntax, semantics, and syntax-semantics interfaces
- Multilingual Processing
- Speech Processing
- Logic for reasoning systems --- theories and applications
- Logic in data science
- Information theories
- Integration of data and reasoning
- Models of computation
- Mathematics for linguistics and cognitive science
- Interdisciplinary approaches to computation, language, reasoning, memory, data
- Computational theories and applications in life sciences
- Computational neuroscience of information, language, memory, reasoning
- Computational aspects of information, languages, and memory in nature

IMPORTANT DATES
=====
Submission dates:     13th February, 2017
Notification date:    13th March, 2017
Paper ready deadline: 27th March, 2017
Conference dates:     21st-23rd June, 2017

SUBMISSION INSTRUCTIONS
=====
DCAI Special Session papers must be formatted according to the
Springer LNCS Template, with a maximum length of 8 pages, including
figures and references. All proposed papers must be submitted in
electronic form (PDF format) using the Paper Submission Page:

http://www.dcai-conference.net/special-sessions

PUBLICATION:
=====
Accepted papers will be included in DCAI Proceedings. At least one of
the authors will be required to register and attend the symposium to
present the paper in order to include the paper in the conference
proceedings. All accepted papers will be published by Advances in
Intelligent Systems and Computing series of Springer Verlag. For more
details, see:
http://www.dcai-conference.net/special-sessions

CO-CHAIRS:
=====
Roussanka Loukanova, Stockholm University, Sweden
Kristina Liefke, Ludwig-Maximilians-University Munich, Germany

CONTACT:
=====
Roussanka Loukanova (rloukanova at gmail.com)
Kristina Liefke (Kristina.Liefke at lrz.uni-muenchen.de)

From cheremin at gmail.com  Sun Feb  5 10:34:00 2017
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Sun, 5 Feb 2017 18:34:00 +0300
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone() co-operates
	only with commonPool?
Message-ID: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>

Tracing the execution of FJTask.join() I've found the code
externalAwaitDone() (listed below), from which it is obvious external
(non-FJP) thread will try to help to execute tasks _only from commonPool_,
and just blocks otherwise.

I was sure FJP.commonPool is not any kind special, just the same as any
other FJPool. From the code below it looks like it is special: any external
thread doing .join() will try to help only commonPool's tasks, but not any
other FJPools.

Why it is implemented this way? Can't .join() always try to help the actual
FJPool current FJTask is enqueued into?

It is also interesting: is there any other places in FJTask/Pool machinery
there commonPool is treated specially?

--------- ForkJoinTask----

private int externalAwaitDone() {
        int s = ((this instanceof CountedCompleter) ? // try helping
                 ForkJoinPool.common.externalHelpComplete(
                     (CountedCompleter<?>)this, 0) :
                 ForkJoinPool.common.tryExternalUnpush(this) ? doExec() :
0);
        if (s >= 0 && (s = status) >= 0) {
            boolean interrupted = false;
            do {
                if (U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) {
                    synchronized (this) {
                        if (status >= 0) {
                            try {
                                wait(0L);
                            } catch (InterruptedException ie) {
                                interrupted = true;
                            }
                        }
                        else
                            notifyAll();
                    }
                }
            } while ((s = status) >= 0);
            if (interrupted)
                Thread.currentThread().interrupt();
        }
        return s;
    }

----
Ruslan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170205/3ad6b718/attachment.html>

From dl at cs.oswego.edu  Sun Feb  5 10:53:33 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 5 Feb 2017 10:53:33 -0500
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
Message-ID: <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>

On 02/05/2017 10:34 AM, Ruslan Cheremin wrote:
> Tracing the execution of FJTask.join() I've found the code
> externalAwaitDone() (listed below), from which it is obvious external
> (non-FJP) thread will try to help to execute tasks _only from
> commonPool_, and just blocks otherwise.

Threads in all cases try to help, but in non-commonPool they may
reach a point where they block sooner than in common pool,
where they must continue to find and help with tasks vs
block in case there are no other workers, until/unless they
are sure that they are not needed.

There are methods allowing manual control of this extra helping
in non-commonpool usage. For example helpQuiesce and helpComplete.
They are not performed otherwise because they can cause unnecessary
overhead.

-Doug



From cheremin at gmail.com  Sun Feb  5 11:33:31 2017
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Sun, 5 Feb 2017 19:33:31 +0300
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
Message-ID: <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>

>Threads in all cases try to help, but in non-commonPool they may
reach a point where they block sooner than in common pool,
where they must continue to find and help with tasks vs
block in case there are no other workers, until/unless they
are sure that they are not needed.

May be I miss something important, but I can't see in code how do threads
tries to help:

FJTask.join() invokes FJTask.doJoin(), which, indeed, do tryUnpush(this)
and doExec(), but only if (currentThread instanceof FJPThread), otherwise
doJoin() invokes .externalAwaitDone(), which tries to help only commonPool.

I see no way non-FJP-thread invoking FJTask.join() may help some pool other
than commonPool...

Is it because there is no way to find out to which FJPool given FJTask was
submitted?


----
Ruslan

2017-02-05 18:53 GMT+03:00 Doug Lea <dl at cs.oswego.edu>:

> On 02/05/2017 10:34 AM, Ruslan Cheremin wrote:
>
>> Tracing the execution of FJTask.join() I've found the code
>> externalAwaitDone() (listed below), from which it is obvious external
>> (non-FJP) thread will try to help to execute tasks _only from
>> commonPool_, and just blocks otherwise.
>>
>
> Threads in all cases try to help, but in non-commonPool they may
> reach a point where they block sooner than in common pool,
> where they must continue to find and help with tasks vs
> block in case there are no other workers, until/unless they
> are sure that they are not needed.
>
> There are methods allowing manual control of this extra helping
> in non-commonpool usage. For example helpQuiesce and helpComplete.
> They are not performed otherwise because they can cause unnecessary
> overhead.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170205/1479e4a7/attachment.html>

From dl at cs.oswego.edu  Sun Feb  5 16:44:49 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 5 Feb 2017 16:44:49 -0500
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
 <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
Message-ID: <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>

On 02/05/2017 11:33 AM, Ruslan Cheremin wrote:

> May be I miss something important, but I can't see in code how do
> threads tries to help:

Oh, sorry to misinterpret your question. "External" threads
(non-ForkJoinWorkerThreads) by design do not help normal pools,
which makes them act like other ExecutorServices.
(I was referring to "internal" threads in previous answer.)
But they must help in commonPool, mainly because the
commonPool might not have any workers, due to system-wide
policies. Doing it this way enables parallelStreams etc to
still work in managed environments (although with no
possibility of speedup). But this is an add-on to
ForkJoinPools that doesn't apply in general.


>
> Is it because there is no way to find out to which FJPool given FJTask
> was submitted?
>

Yes, although that's more of a consequence rather than a cause.

-Doug


From cheremin at gmail.com  Sun Feb  5 16:58:59 2017
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Mon, 6 Feb 2017 00:58:59 +0300
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
 <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
 <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
Message-ID: <CAOwENiJ3pQFm5=1Gb7HGnT3R4VmDWWBahi5XC9CKQ+TCerC5gg@mail.gmail.com>

>mainly because the commonPool might not have any workers, due to
system-wide policies. Doing it this way enables parallelStreams etc to still
work in managed environments (although with no possibility of speedup)

Oh, so it is for purposes of fallback/graceful degradation. Very
interesting, thank you for pointing this out, Doug.

But doesn't it put additional overhead on commonPool? I mean, every time I
use .join() on non-commonPool tasks, current thread tries to steal task
back from commonPool workQueue(s), which is never succeeded, but probably
do some cache trashing anyway?


2017-02-06 0:44 GMT+03:00 Doug Lea <dl at cs.oswego.edu>:

> On 02/05/2017 11:33 AM, Ruslan Cheremin wrote:
>
> May be I miss something important, but I can't see in code how do
>> threads tries to help:
>>
>
> Oh, sorry to misinterpret your question. "External" threads
> (non-ForkJoinWorkerThreads) by design do not help normal pools,
> which makes them act like other ExecutorServices.
> (I was referring to "internal" threads in previous answer.)
> But they must help in commonPool, mainly because the
> commonPool might not have any workers, due to system-wide
> policies. Doing it this way enables parallelStreams etc to
> still work in managed environments (although with no
> possibility of speedup). But this is an add-on to
> ForkJoinPools that doesn't apply in general.
>
>
>
>> Is it because there is no way to find out to which FJPool given FJTask
>> was submitted?
>>
>>
> Yes, although that's more of a consequence rather than a cause.
>
> -Doug
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170206/d616ea45/attachment.html>

From kirk at kodewerk.com  Mon Feb  6 01:47:45 2017
From: kirk at kodewerk.com (kirk at kodewerk.com)
Date: Mon, 6 Feb 2017 07:47:45 +0100
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
 <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
 <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
Message-ID: <9551EC56-D1A8-4DDA-AEDE-BF2F0C343698@kodewerk.com>

Hi,

A while back I sifted through f-j and sorted out a way to instrument it with JMX. I am sure that my hack wasn’t the best way to instrument f-j but it did give me the information I needed at the time. Given the importance of the common thread-pool and f-j I am wondering if it might be a good idea to explore a way to add instrumentation so that important metrics can be exposed via the Platform MBean server to improve observability in the runtime?

Kind regards,
Kirk Pepperdine

> On Feb 5, 2017, at 10:44 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> 
> On 02/05/2017 11:33 AM, Ruslan Cheremin wrote:
> 
>> May be I miss something important, but I can't see in code how do
>> threads tries to help:
> 
> Oh, sorry to misinterpret your question. "External" threads
> (non-ForkJoinWorkerThreads) by design do not help normal pools,
> which makes them act like other ExecutorServices.
> (I was referring to "internal" threads in previous answer.)
> But they must help in commonPool, mainly because the
> commonPool might not have any workers, due to system-wide
> policies. Doing it this way enables parallelStreams etc to
> still work in managed environments (although with no
> possibility of speedup). But this is an add-on to
> ForkJoinPools that doesn't apply in general.
> 
> 
>> 
>> Is it because there is no way to find out to which FJPool given FJTask
>> was submitted?
>> 
> 
> Yes, although that's more of a consequence rather than a cause.
> 
> -Doug
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Mon Feb  6 08:00:07 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 6 Feb 2017 08:00:07 -0500
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <CAOwENiJ3pQFm5=1Gb7HGnT3R4VmDWWBahi5XC9CKQ+TCerC5gg@mail.gmail.com>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
 <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
 <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
 <CAOwENiJ3pQFm5=1Gb7HGnT3R4VmDWWBahi5XC9CKQ+TCerC5gg@mail.gmail.com>
Message-ID: <8fdfbb19-4cb5-bca2-d211-17c7b8248f98@cs.oswego.edu>

On 02/05/2017 04:58 PM, Ruslan Cheremin wrote:
>>mainly because the commonPool might not have any workers, due to
> system-wide policies. Doing it this way enables parallelStreams etc
> to still work in managed environments (although with no possibility of
> speedup)
>
> Oh, so it is for purposes of fallback/graceful degradation. Very
> interesting, thank you for pointing this out, Doug.
>
> But doesn't it put additional overhead on commonPool? I mean, every time
> I use .join() on non-commonPool tasks, current thread tries to steal
> task back from commonPool workQueue(s), which is never succeeded, but
> probably do some cache trashing anyway?
>

You can concoct scenarios where this could have a measurable impact,
but it almost never does. In the usual case where
the commonPool is quiescent but your user pool is not,
it amounts to a table lookup on a variable that is not changing,
adding only a cache line or two to per-thread footprint.

-Doug



From dl at cs.oswego.edu  Mon Feb  6 09:14:56 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 6 Feb 2017 09:14:56 -0500
Subject: [concurrency-interest] ForkJoinTask.externalAwaitDone()
 co-operates only with commonPool?
In-Reply-To: <9551EC56-D1A8-4DDA-AEDE-BF2F0C343698@kodewerk.com>
References: <CAOwENiJskdx6UkW-raqVjUG_jnm8sxkz4kD8tX9nrn-1zd814w@mail.gmail.com>
 <b0f16297-1607-fb06-9480-b721c774048c@cs.oswego.edu>
 <CAOwENi+A8XOFzAno9zV4Kcuf3DvGSdQ-MrtuPaDhwdz3r=Nhow@mail.gmail.com>
 <15cbeaf2-38e2-6498-a9c6-881515436f83@cs.oswego.edu>
 <9551EC56-D1A8-4DDA-AEDE-BF2F0C343698@kodewerk.com>
Message-ID: <ddb2e2c5-1352-de7a-0efd-a380a9b1f639@cs.oswego.edu>

On 02/06/2017 01:47 AM, kirk at kodewerk.com wrote:
> Hi,
>
> A while back I sifted through f-j and sorted out a way to instrument
> it with JMX. I am sure that my hack wasn’t the best way to instrument
> f-j but it did give me the information I needed at the time. Given
> the importance of the common thread-pool and f-j I am wondering if it
> might be a good idea to explore a way to add instrumentation so that
> important metrics can be exposed via the Platform MBean server to
> improve observability in the runtime?
>

What metrics do you have in mind? Are they different than
what you can get by calling fjp.toString (which collects
up the status query methods)? Here's a sample output:

java.util.concurrent.ForkJoinPool at 2ef5e5e3[Running, parallelism = 64, 
size = 64, active = 0, running = 0, steals = 112778, tasks = 0, 
submissions = 0]

In general, rather than linking to JMX etc, j.u.c components
have status query methods summarized in toString methods, that
we hope are easy to connect to any monitoring facility.

-Doug


From rl.stpuu at gmail.com  Tue Feb  7 22:52:24 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Wed, 8 Feb 2017 04:52:24 +0100
Subject: [concurrency-interest] Third Nordic Logic Summer School (NLS) 2017:
 Second announcement and call for papers
Message-ID: <CACAe74i1Pa0n1R60ytByPu=K-iCgm9AN7mRcbPH2Bf45OJXxAQ@mail.gmail.com>

------------------------------------------------------------
Third Nordic Logic Summer School (NLS) 2017
Stockholm, August 7 - 11, 2017
------------------------------------------------------------

The third Nordic Logic Summer School is arranged under the  auspices
of the Scandinavian Logic Society (http://scandinavianlogic.org/). The
two previous schools were organized in Nordfjordeid, Norway (2013) and
Helsinki (2015). The intended audience is advanced master students,
PhD-students, postdocs and experienced researchers wishing to learn
the state of the art in a particular subject. The school is co-located
with Logic Colloquium 2017 (August 14-20) and Computer Science Logic
2017 (August 21-24).

The school will consist of 10 five-hour courses, running in two
parallel streams. In addition, there will be short student
presentations and poster sessions.

The lectures start on:

** Monday August 7, 9:00, and end Friday August 11, 16:15 **


LECTURERS AND COURSES
------------------------------

The following lecturers and course topics are confirmed.

* Mirna Dzamonja (University of East Anglia)
-- Set Theory

* Martin Escardo (Birmingham)
-- Topological and Constructive Aspects of Higher-Order Computation

* Henrik Forssell (Oslo)
-- Categorical Logic

* Volker Halbach (Oxford)
-- Truth & Paradox

* Larry Moss (Indiana University, Bloomington)
-- Natural Logic

* Anca Muscholl (LaBRI, Université Bordeaux)
-- Logic in Computer Science - Control and Synthesis, from a
Distributed Perspective

* Eric Pacuit (University of Maryland)
-- Logic and Rationality

* Peter Pagin and Dag Westerståhl (Stockholm University)
-- Compositionality

* Sara L. Uckelman (Durham)
-- Medieval Logic

* Andreas Weiermann (Ghent)
-- Proof Theory

---------------------
Certificates for participation will be provided. There will be
possibilities to take official credits for some of the courses.
---------------------

VENUE
---------------------
Department of Mathematics, Kräftriket Campus, Stockholm University.

IMPORTANT DATES
---------------------

Registration:
--
Registration opens: March 6, 2017
Early registration ends: ** May 15, 2017 **
Late registration ends: ** August 4, 2017 **
--
Submission of abstracts for presentations and posters:
--
Opening: March 6, 2017
Closing: May 2, 2017
Notification of acceptance: May 9, 2017
--

The early registration fee will be 1900 SEK including VAT (approx. 190
Euros) per participant, and includes coffee breaks and conference
materials. Late registration fee is 2600 SEK including VAT.

Some participation-fee grants may be available.

ACCOMMODATION
---------------------

The registration fee does not cover accommodation, but there will be
special offers at hostels and hotels (in the range 700 -1200 SEK/night
for single rooms) available when the registration opens.

SPECIAL OFFER FOR ACCOMMODATION
---------------------
There will be offers of inexpensive accommodation via the Stockholm
University Housing Office. The cost will be around 300 SEK per person
per night, in studio apartments shared by two people. To be able to
take part in this offer, participants need to register at the latest
May 15. Enquiries may be directed to:

logic2017-accommodation [at] math.su.se

FURTHER INFORMATION
-------------------------

Further information about submissions, registration and accommodation
possibilities will (in due time) be available on the NLS webpage:

https://www.sls17.conf.kth.se

General enquiries: nls2017 [at] philosophy.su.se
Accommodation enquiries: logic2017-accommodation [at] math.su.se

COMMITTEES
----------------

Program Committee of NLS 2017:

Thierry Coquand (Göteborg), Ali Enayat (Göteborg)
Mai Gehrke (IRIF, Paris), Nina Gierasimczuk (Copenhagen)
Valentin Goranko (Stockholm U), Lauri Hella (Tampere)
Lars Kristiansen (Oslo), Juha Kontinen (Helsinki)
Øystein Linnebo (Oslo), Sara Negri (Helsinki)
Erik Palmgren (chair, Stockholm U)

Local Organizing Committee of NLS 2017:

Valentin Goranko (co-chair), Dilian Gurov, Roussanka Loukanova,
Peter LeFanu Lumsdaine, Anders Lundstedt, Erik Palmgren (co-chair)
------------------------------------------------------------

From amirhadadi at hotmail.com  Wed Feb  8 01:52:38 2017
From: amirhadadi at hotmail.com (Amir Hadadi)
Date: Wed, 8 Feb 2017 06:52:38 +0000
Subject: [concurrency-interest] computeIfAbsent optimized for missing entries
Message-ID: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>

I read the source code for ConcurrentHashMap's computeIfAbsent, and I noticed it enters a synchronized block whether or not the key is present.

I would expect this method to first check if the key is present, and only then resort to locking. This would make computeIfAbsent slower when the key is missing, but will speed it up and reduce contention when the key is present.

In the common use case of using ConcurrentHashMap + computeIfAbsent to implement a registry that lazily initializes objects, and the same resource is accessed through the map frequently, contention will ensue.

Why this method was optimized for the missing entry case?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170208/f60ce84e/attachment.html>

From dl at cs.oswego.edu  Wed Feb  8 11:55:02 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 8 Feb 2017 11:55:02 -0500
Subject: [concurrency-interest] computeIfAbsent optimized for missing
 entries
In-Reply-To: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
Message-ID: <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>

On 02/08/2017 01:52 AM, Amir Hadadi wrote:
> I read the source code for ConcurrentHashMap's computeIfAbsent, and I
> noticed it enters a synchronized block whether or not the key is present.

computeIfAbsent must be more conservative than putIfAbsent because
we guarantee exclusion during the "compute" part.
Even if an element is apparently present, we need to guarantee
that it is not in the process of being removed (while holding lock).

There was a fair amount of pre-jdk8 discussion about whether to
guarantee locking/exclusion in CHM (it is not guaranteed for
ConcurrentMaps in general). The consensus was that it was
worth doing despite the extra overhead. Especially since it
is avoidable in cases where you know that a key will never be
removed once added, first calling get(), and then only
call computeIfAbsent if it returns null.


-Doug



From ben.manes at gmail.com  Wed Feb  8 12:22:37 2017
From: ben.manes at gmail.com (Benjamin Manes)
Date: Wed, 8 Feb 2017 09:22:37 -0800
Subject: [concurrency-interest] computeIfAbsent optimized for missing
	entries
In-Reply-To: <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
 <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
Message-ID: <CAGu0=MN6Mmx_Ez+3JWO5HU4VmGW1BYqzkcgjV-3XmkVZXXFAGw@mail.gmail.com>

In JDK9, it looks like you added a small prescreening
<http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ConcurrentHashMap.java?r1=1.295&r2=1.296>
to
check at the first node in the bin and eagerly return. That seems like a
smart compromise, given the performance analysis you shared on this forum
previously that dissuaded you from adopting a full pre-screening.

On Wed, Feb 8, 2017 at 8:55 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 02/08/2017 01:52 AM, Amir Hadadi wrote:
>
>> I read the source code for ConcurrentHashMap's computeIfAbsent, and I
>> noticed it enters a synchronized block whether or not the key is present.
>>
>
> computeIfAbsent must be more conservative than putIfAbsent because
> we guarantee exclusion during the "compute" part.
> Even if an element is apparently present, we need to guarantee
> that it is not in the process of being removed (while holding lock).
>
> There was a fair amount of pre-jdk8 discussion about whether to
> guarantee locking/exclusion in CHM (it is not guaranteed for
> ConcurrentMaps in general). The consensus was that it was
> worth doing despite the extra overhead. Especially since it
> is avoidable in cases where you know that a key will never be
> removed once added, first calling get(), and then only
> call computeIfAbsent if it returns null.
>
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170208/3a12bf43/attachment.html>

From amirhadadi at hotmail.com  Wed Feb  8 15:58:41 2017
From: amirhadadi at hotmail.com (Amir Hadadi)
Date: Wed, 8 Feb 2017 20:58:41 +0000
Subject: [concurrency-interest] computeIfAbsent optimized for missing
 entries
In-Reply-To: <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>,
 <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
Message-ID: <DB6P194MB024653FCA0C233D25D09A734D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>

> Even if an element is apparently present, we need to guarantee
> that it is not in the process of being removed (while holding lock).


Let's assume computeIfAbsent is implemented by first checking if the key is present, returning the associated value if it is, and otherwise goes on to lock. So the mapping function is still performed under lock.

Let's say we have a CHM which initially maps a key K -> V.

Now thread T1 calls remove(K) concurrently with thread T2 calling computeIfAbsent(K, mappingFunction).

What sequence of events could T1, T2 or another thread T3 observe that is precluded by the existing implementation?

________________________________
From: Concurrency-interest <concurrency-interest-bounces at cs.oswego.edu> on behalf of Doug Lea <dl at cs.oswego.edu>
Sent: Wednesday, February 8, 2017 6:55:02 PM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] computeIfAbsent optimized for missing entries

On 02/08/2017 01:52 AM, Amir Hadadi wrote:
> I read the source code for ConcurrentHashMap's computeIfAbsent, and I
> noticed it enters a synchronized block whether or not the key is present.

computeIfAbsent must be more conservative than putIfAbsent because
we guarantee exclusion during the "compute" part.
Even if an element is apparently present, we need to guarantee
that it is not in the process of being removed (while holding lock).

There was a fair amount of pre-jdk8 discussion about whether to
guarantee locking/exclusion in CHM (it is not guaranteed for
ConcurrentMaps in general). The consensus was that it was
worth doing despite the extra overhead. Especially since it
is avoidable in cases where you know that a key will never be
removed once added, first calling get(), and then only
call computeIfAbsent if it returns null.


-Doug


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170208/0fb39860/attachment.html>

From rl.stpuu at gmail.com  Wed Feb  8 16:04:21 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Wed, 8 Feb 2017 22:04:21 +0100
Subject: [concurrency-interest] CfP: LACompLing2017 - Logic and Algorithms
 in Computational Linguistics 2017
Message-ID: <CACAe74iYMjBMeca+9Vi=ujSQ4X63+NWXn42AV5BRipw3X7qF0g@mail.gmail.com>

============================================================

                        CALL FOR PAPERS

                          Workshop on
Logic and Algorithms in Computational Linguistics 2017 (LACompLing2017)
                   Stockholm, August 18-19, 2017

        http://staff.math.su.se/rloukanova/LACompLing17.html

     * Submission deadline for regular papers: April 14, 2017 *
============================================================

                      Affiliated with the
26th Annual EACSL Conference on Computer Science Logic CSL'2017
                   Stockholm, 20--26 August 2017
                   https://www.csl17.conf.kth.se/

                        Co-located with:
                     Logic in Stockholm 2017
                  https://www.lis17.conf.kth.se/
============================================================

DESCRIPTION
=====
Computational linguistics studies natural language in its various
manifestations from a computational point of view, both on the
theoretical level (modeling grammar modules dealing with natural
language form and meaning, and the relation between these two) and on
the practical level (developing applications for language and speech
technology). Right from the start in the 1950ties, there have been
strong links with computer science and logic - one can think of
Chomsky's contributions to the theory of formal languages and
automata, or Lambek's logical modeling of natural language syntax. The
workshop assesses the place of computer science logic in present day
computational linguistics. It intends to be a forum for presenting new
results as well as work in progress.
--------------------------------

SCOPE
=====
The workshop focuses on logical approaches to the computational
processing of natural language, and on the applicability of methods
and techniques from the study of artificial languages
(programming/logic) in computational linguistics.

The topics of LACompLing2017 include, but are not limited to:

- Computational theories of human language
- Computational syntax
- Computational semantics
- Computational syntax-semantics interface
- Interfaces between morphology, lexicon, syntax, semantics, speech,
text, pragmatics
- Computational grammar
- Logic and reasoning systems for linguistics
- Type theories for linguistics
- Models of computation and algorithms for linguistics
- Language processing
- Parsing algorithms
- Generation of language from semantic representations
- Large-scale grammars of natural languages
- Multilingual processing
- Data science in language processing
- Machine learning of language
- Interdisciplinary methods
- Integration of formal, computational, model theoretic, graphical,
diagrammatic, statistical, and other related methods
- Logic for information extraction or expression in written and spoken language
- Language theories based on biological fundamentals of information
and languages
- Computational neuroscience of language

IMPORTANT DATES
=====
Submission deadline for regular papers:          April 14, 2017
Notification of paper acceptance:                May 31, 2017
Deadline for abstracts of short presentations:   June 4, 2017
Notifications for short presentations:           June 12, 2017
Deadline for final submissions:                  June 25, 2017
Workshop:                                        August 18-19, 2017

SUBMISSION INSTRUCTIONS
=====
- Regular papers: between 10-15 pages, including figures and
references, by using LaTeX, with article.sty, the default font size

- Abstracts of short presentations: not more than 1 page, by using
LaTeX, with article.sty, the default font size

- We invite original papers that are not submitted concurrently to
another conference or for publication elsewhere

- The submissions of proposed papers and abstracts of short
presentations have to be in pdf

- The camera-ready submissions require the pdf of the papers and their
LaTeX sources

The submissions are via the EasyChair management system of LACompLing2017:

https://easychair.org/conferences/?conf=lacompling2017

PUBLICATIONS
=====
- The proceedings of the workshop on Logic and Algorithms in
Computational Linguistics 2017 (LACompLing2017) will be published
digitally by the DiVA system of Stockholm University:
http://su.diva-portal.org

- Improved and extended versions of selected papers, which have been
presented at the workshop LACompLing2017, will be published by the
Journal of Logic, Language and Information, JoLLI, after the workshop.

ORGANIZERS
=====
Krasimir Angelov, University of Gothenburg, Sweden
Valeria de Paiva, Nuance Communications, USA
Kristina Liefke, Ludwig-Maximilians-University Munich, Germany
Roussanka Loukanova, Stockholm University, Sweden
Michael Moortgat, Utrecht University, The Netherlands
Reinhard Muskens, Tilburg University, The Netherlands

CONTACT
=====
Roussanka Loukanova (rloukanova at gmail.com)
Valeria de Paiva (valeria.depaiva at gmail.com)
--------------------------------

From dl at cs.oswego.edu  Thu Feb  9 06:51:01 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 9 Feb 2017 06:51:01 -0500
Subject: [concurrency-interest] computeIfAbsent optimized for missing
 entries
In-Reply-To: <CAGu0=MN6Mmx_Ez+3JWO5HU4VmGW1BYqzkcgjV-3XmkVZXXFAGw@mail.gmail.com>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
 <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
 <CAGu0=MN6Mmx_Ez+3JWO5HU4VmGW1BYqzkcgjV-3XmkVZXXFAGw@mail.gmail.com>
Message-ID: <1f070b0d-d685-b811-d3d6-5cf7e2847f0e@cs.oswego.edu>

On 02/08/2017 12:22 PM, Benjamin Manes wrote:
> In JDK9, it looks like you added a small prescreening
> <http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ConcurrentHashMap.java?r1=1.295&r2=1.296>
> to check at the first node in the bin and eagerly return. That seems
> like a smart compromise, given the performance analysis you shared on
> this forum previously that dissuaded you from adopting a full
> pre-screening.

Thanks! I forgot that this made it into jdk9 (vs jdk8).
Amir: for more details see the discussions on this in the
archives: http://cs.oswego.edu/pipermail/concurrency-interest/

-Doug


From amirhadadi at hotmail.com  Tue Feb 14 08:46:27 2017
From: amirhadadi at hotmail.com (Amir Hadadi)
Date: Tue, 14 Feb 2017 13:46:27 +0000
Subject: [concurrency-interest] computeIfAbsent optimized for missing
 entries
In-Reply-To: <1f070b0d-d685-b811-d3d6-5cf7e2847f0e@cs.oswego.edu>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
 <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
 <CAGu0=MN6Mmx_Ez+3JWO5HU4VmGW1BYqzkcgjV-3XmkVZXXFAGw@mail.gmail.com>,
 <1f070b0d-d685-b811-d3d6-5cf7e2847f0e@cs.oswego.edu>
Message-ID: <DB6P194MB02462C80410C8335F1205CECD9580@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>

I went over the discussions, and found the following:
http://cs.oswego.edu/pipermail/concurrency-interest/2014-December/013360.html

And these are the current benchmarks from caffeine (the links in the post above are dead):
https://github.com/ben-manes/caffeine/wiki/Benchmarks


> As an intermediate
> test, I measured the impact of adding a single-node prescreen
> ("1cif") before locking inside CHM.computeIfAbsent, that is similar
> to what was done in some pre-release versions:
>
> Same key
>
> cif:        1402559
> get+cif: 3775886700
> 1cif:    1760916148
>
> Zipf-distributed keys
>
> cif:     1414945003
> get+cif:  882477874
> 1cif:     618668961


You refer to 2 benchmarks in this post, ComputingTest and ComputeBenchmark. I couldn't find ComputingTest, but I found ComputeBenchmark here:
https://github.com/ben-manes/caffeine/blob/master/caffeine/src/jmh/java/com/github/benmanes/caffeine/cache/ComputeBenchmark.java

I tested only the Zipf-distributed keys, running the cif vs get + cif versions using 8 threads, OSX 10.11.6, 2.8 GHz Intel Quad Core i7.
My results were:

cif:
Result "org.sample.ComputeBenchmark.compute_spread":
  83559118.933 ±(99.9%) 18403807.660 ops/s [Average]
  (min, avg, max) = (80998142.816, 83559118.933, 86575174.221), stdev = 2848009.607
  CI (99.9%): [65155311.273, 101962926.593] (assumes normal distribution)


get + cif:
  208177607.279 ±(99.9%) 12987916.190 ops/s [Average]
  (min, avg, max) = (206351511.981, 208177607.279, 210850461.612), stdev = 2009894.407
  CI (99.9%): [195189691.090, 221165523.469] (assumes normal distribution)

So the get + cif version is faster by a factor of 2.5.
I would be very surprised to find that get + cif is slower than cif when there are no absent entries.

Do these results seem reasonable? Did you run other benchmarks that convinced you that cif is better than the alternatives?


________________________________
From: Concurrency-interest <concurrency-interest-bounces at cs.oswego.edu> on behalf of Doug Lea <dl at cs.oswego.edu>
Sent: Thursday, February 9, 2017 1:51:01 PM
To: Benjamin Manes
Cc: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] computeIfAbsent optimized for missing entries

On 02/08/2017 12:22 PM, Benjamin Manes wrote:
> In JDK9, it looks like you added a small prescreening
> <http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ConcurrentHashMap.java?r1=1.295&r2=1.296>
> to check at the first node in the bin and eagerly return. That seems
> like a smart compromise, given the performance analysis you shared on
> this forum previously that dissuaded you from adopting a full
> pre-screening.

Thanks! I forgot that this made it into jdk9 (vs jdk8).
Amir: for more details see the discussions on this in the
archives: http://cs.oswego.edu/pipermail/concurrency-interest/

-Doug

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170214/081f1bd2/attachment.html>

From ben.manes at gmail.com  Tue Feb 14 14:09:41 2017
From: ben.manes at gmail.com (Benjamin Manes)
Date: Tue, 14 Feb 2017 11:09:41 -0800
Subject: [concurrency-interest] computeIfAbsent optimized for missing
	entries
In-Reply-To: <DB6P194MB02462C80410C8335F1205CECD9580@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
References: <DB6P194MB02463E4A851591037691C0F8D9420@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
 <295f646f-eba6-311b-601c-667bc2c9443a@cs.oswego.edu>
 <CAGu0=MN6Mmx_Ez+3JWO5HU4VmGW1BYqzkcgjV-3XmkVZXXFAGw@mail.gmail.com>
 <1f070b0d-d685-b811-d3d6-5cf7e2847f0e@cs.oswego.edu>
 <DB6P194MB02462C80410C8335F1205CECD9580@DB6P194MB0246.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CAGu0=MNQz7U_SPLf4wepVKhHVb_SjF_xCbEHWMR2XRi6nzUv5g@mail.gmail.com>

In that thread, Doug explains why:

However, the exact benefit depends on access patterns. For example, I reran
> your benchmark cases (urls below) on a 32way x86, and got throughputs
> (ops/sec) that are dramatically better with pre-screen for the case of a
> single key, but worse with your Zipf-distributed keys.



One might think (I did until running similar experiments) that the "1cif"
> version would be the best compromise. But currently it isn't. This is in
> part due to interactions with biased locking, that in some cases basically
> provide "free" prescreens, but in other cases add safepoint/GC pressure in
> addition to lock contention. This is all up for re-consideration though.


At the time, I spun up a 32-core machine and reproduced his findings. The
JDK9 partial pre-screening seems to be a compromise that hopefully avoids
lock contention in the common case, but I have not benchmarked it myself to
advise. Caffeine always performs its own pre-screening since a cache has a
high likelihood of the entry being present.

I believe ComputingTest became AsMapTest. This has the recursive
computation test cases discussed and fixed in that thread.

On Tue, Feb 14, 2017 at 5:46 AM, Amir Hadadi <amirhadadi at hotmail.com> wrote:

> I went over the discussions, and found the following:
> http://cs.oswego.edu/pipermail/concurrency-interest/2014-December/013360.
> html
>
> And these are the current benchmarks from caffeine (the links in the post
> above are dead):
> https://github.com/ben-manes/caffeine/wiki/Benchmarks
>
>
> > As an intermediate
> > test, I measured the impact of adding a single-node prescreen
> > ("1cif") before locking inside CHM.computeIfAbsent, that is similar
> > to what was done in some pre-release versions:
> >
> > Same key
> >
> > cif:        1402559
> > get+cif: 3775886700
> > 1cif:    1760916148
> >
> > Zipf-distributed keys
> >
> > cif:     1414945003
> > get+cif:  882477874
> > 1cif:     618668961
>
>
> You refer to 2 benchmarks in this post, ComputingTest and
> ComputeBenchmark. I couldn't find ComputingTest, but I found
> ComputeBenchmark here:
> https://github.com/ben-manes/caffeine/blob/master/caffeine/
> src/jmh/java/com/github/benmanes/caffeine/cache/ComputeBenchmark.java
>
> I tested only the Zipf-distributed keys, running the cif vs get + cif
> versions using 8 threads, OSX 10.11.6, 2.8 GHz Intel Quad Core i7.
> My results were:
>
> cif:
> Result "org.sample.ComputeBenchmark.compute_spread":
>   83559118.933 ±(99.9%) 18403807.660 ops/s [Average]
>   (min, avg, max) = (80998142.816, 83559118.933, 86575174.221), stdev =
> 2848009.607
>   CI (99.9%): [65155311.273, 101962926.593] (assumes normal distribution)
>
>
> get + cif:
>   208177607.279 ±(99.9%) 12987916.190 ops/s [Average]
>   (min, avg, max) = (206351511.981, 208177607.279, 210850461.612), stdev =
> 2009894.407
>   CI (99.9%): [195189691.090, 221165523.469] (assumes normal distribution)
>
> So the get + cif version is faster by a factor of 2.5.
> I would be very surprised to find that get + cif is slower than cif when
> there are no absent entries.
>
> Do these results seem reasonable? Did you run other benchmarks that
> convinced you that cif is better than the alternatives?
>
> ------------------------------
> *From:* Concurrency-interest <concurrency-interest-bounces at cs.oswego.edu>
> on behalf of Doug Lea <dl at cs.oswego.edu>
> *Sent:* Thursday, February 9, 2017 1:51:01 PM
> *To:* Benjamin Manes
> *Cc:* Concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] computeIfAbsent optimized for
> missing entries
>
> On 02/08/2017 12:22 PM, Benjamin Manes wrote:
> > In JDK9, it looks like you added a small prescreening
> > <http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/
> main/java/util/concurrent/ConcurrentHashMap.java?r1=1.295&r2=1.296>
> > to check at the first node in the bin and eagerly return. That seems
> > like a smart compromise, given the performance analysis you shared on
> > this forum previously that dissuaded you from adopting a full
> > pre-screening.
>
> Thanks! I forgot that this made it into jdk9 (vs jdk8).
> Amir: for more details see the discussions on this in the
> archives: http://cs.oswego.edu/pipermail/concurrency-interest/
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170214/1978502c/attachment.html>

From kedar.mhaswade at gmail.com  Fri Feb 24 23:53:53 2017
From: kedar.mhaswade at gmail.com (kedar mhaswade)
Date: Fri, 24 Feb 2017 20:53:53 -0800
Subject: [concurrency-interest] Spot the bug in stream processing,
	IntConsumer and Executor
Message-ID: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>

​Perhaps I had a long day. So, this might completely be a silly mistake,
but I need congenial help to figure it out.

To demonstrate race condition, I wrote the following program. The program
has ten concurrent tasks that modify count, a volatile shared variable. If
I use the *increment* task (line 39), I get different results (like, e.g.
[2]) every time I run it, demonstrating the race condition.

However, if I use the *incrementStream* task instead (line 39), then the
count variable is not updated at all. The output is like [1] *every time*.
In a separate program not involving threads, I have verified that the
lambda expression like incrementStream updates a member variable as
expected.

What am I doing wrong?

Regards,
Kedar


public class RaceCondition {

    private static volatile int count = 0;
    public static void main(String[] args) {
        // update the shared variable traditionally
        Runnable increment = () -> {
            for (int i = 0; i < 1000; i++)
                count++;
        };
        // update the shared variable as a side effect of an
IntConsumer#accept
        Runnable incrementStream = () -> IntStream.rangeClosed(1,
100).forEach(i -> count++);
        ExecutorService exec = Executors.newCachedThreadPool(); // short
lived tasks
        try {
            for (int i = 0; i < 10; i++) {

​// ​
exec.execute(incrementStream)
​;
// line 38​
​​

              exec.execute(increment);
​         // line 39​

                System.out.println("task: " + i + " updates count to: " +
count);
            }
        } finally {
            exec.shutdown();
            System.out.println("final: " + count);
        }
    }

}
[1]
task: 0 updates count to: 0
task: 1 updates count to: 0
task: 2 updates count to: 0
task: 3 updates count to: 0
task: 4 updates count to: 0
task: 5 updates count to: 0
task: 6 updates count to: 0
task: 7 updates count to: 0
task: 8 updates count to: 0
task: 9 updates count to: 0
final: 0
[2]
task: 0 updates count to: 0
task: 1 updates count to: 1000
task: 2 updates count to: 1000
task: 3 updates count to: 2000
task: 4 updates count to: 4027
task: 5 updates count to: 5000
task: 6 updates count to: 6000
task: 7 updates count to: 7005
task: 8 updates count to: 8000
task: 9 updates count to: 8185
final: 9381
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170224/9ba84b49/attachment.html>

From ben.manes at gmail.com  Sat Feb 25 00:07:55 2017
From: ben.manes at gmail.com (Benjamin Manes)
Date: Fri, 24 Feb 2017 21:07:55 -0800
Subject: [concurrency-interest] Spot the bug in stream processing,
 IntConsumer and Executor
In-Reply-To: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
References: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
Message-ID: <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>

You need to wait until the executor has completed, or else the main method
may complete prior to the task running.

exec.awaitTermination(1, TimeUnit.MINUTES);


On Fri, Feb 24, 2017 at 8:53 PM, kedar mhaswade <kedar.mhaswade at gmail.com>
wrote:

> ​Perhaps I had a long day. So, this might completely be a silly mistake,
> but I need congenial help to figure it out.
>
> To demonstrate race condition, I wrote the following program. The program
> has ten concurrent tasks that modify count, a volatile shared variable. If
> I use the *increment* task (line 39), I get different results (like, e.g.
> [2]) every time I run it, demonstrating the race condition.
>
> However, if I use the *incrementStream* task instead (line 39), then the
> count variable is not updated at all. The output is like [1] *every time*.
> In a separate program not involving threads, I have verified that the
> lambda expression like incrementStream updates a member variable as
> expected.
>
> What am I doing wrong?
>
> Regards,
> Kedar
>
>
> public class RaceCondition {
>
>     private static volatile int count = 0;
>     public static void main(String[] args) {
>         // update the shared variable traditionally
>         Runnable increment = () -> {
>             for (int i = 0; i < 1000; i++)
>                 count++;
>         };
>         // update the shared variable as a side effect of an
> IntConsumer#accept
>         Runnable incrementStream = () -> IntStream.rangeClosed(1,
> 100).forEach(i -> count++);
>         ExecutorService exec = Executors.newCachedThreadPool(); // short
> lived tasks
>         try {
>             for (int i = 0; i < 10; i++) {
>
> ​// ​
> exec.execute(incrementStream)
> ​;
> // line 38​
> ​​
>
>               exec.execute(increment);
> ​         // line 39​
>
>                 System.out.println("task: " + i + " updates count to: " +
> count);
>             }
>         } finally {
>             exec.shutdown();
>             System.out.println("final: " + count);
>         }
>     }
>
> }
> [1]
> task: 0 updates count to: 0
> task: 1 updates count to: 0
> task: 2 updates count to: 0
> task: 3 updates count to: 0
> task: 4 updates count to: 0
> task: 5 updates count to: 0
> task: 6 updates count to: 0
> task: 7 updates count to: 0
> task: 8 updates count to: 0
> task: 9 updates count to: 0
> final: 0
> [2]
> task: 0 updates count to: 0
> task: 1 updates count to: 1000
> task: 2 updates count to: 1000
> task: 3 updates count to: 2000
> task: 4 updates count to: 4027
> task: 5 updates count to: 5000
> task: 6 updates count to: 6000
> task: 7 updates count to: 7005
> task: 8 updates count to: 8000
> task: 9 updates count to: 8185
> final: 9381
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170224/fd26e899/attachment.html>

From concurrency-interest at tomlee.co  Sat Feb 25 03:09:03 2017
From: concurrency-interest at tomlee.co (Tom Lee)
Date: Sat, 25 Feb 2017 00:09:03 -0800
Subject: [concurrency-interest] Spot the bug in stream processing,
 IntConsumer and Executor
In-Reply-To: <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>
References: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
 <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>
Message-ID: <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>

Hi Kedar,

Disclaimer: I'd generally say something about this approach to having
multiple threads incrementing a variable being a bad idea in general, but
it sounds like you're just trying to explore the behavior of this race
right?

Benjamin's on the right track: you're seeing zeros because the code
submitted to the executor hasn't run by the time you print out the "task
... updates count to ..." messages. Still, it's not a complete fix & you'll
very likely continue to see very different results even if you add an
awaitTermination call after the shutdown() call. Also probably depends on
how fast your machine is etc. etc. too (e.g. perhaps on slower machines /
fewer cores you'd see similar output for both).

It's still kind of interesting why the exhibited behavior is so different.
Here's a bit of a hint -- with the following code I get very similar output
irrespective of whether I'm using "increment" or "incrementStream":

private static volatile int count = 0;
public static void main(String[] args) throws Exception {

    // warmup (slower)
    run(false);

    // do it for real (faster)
    count = 0;
    run(true);
}

private static void run(final boolean show) throws Exception {
    Runnable increment = () -> {
        for (int i = 0; i < 1000; i++)
            count++;
    };

    Runnable incrementStream = () -> {
        IntStream.rangeClosed(1, 1000).forEach(i -> count++);
    };
    ExecutorService exec = Executors.newCachedThreadPool();
    try {
        for (int i = 0; i < 10; i++) {
            exec.execute(increment);
            // exec.execute(incrementStream);
            if (show) System.out.println("task: " + i + " updates
count to: " + count);
        }
    }
    finally {
        exec.shutdown();
        exec.awaitTermination(10, TimeUnit.SECONDS);
        if (show) System.out.println("final: " + count);
    }
}

Weird right?

Another hint: I added code to println() a message to the end of
incrementStream() in your original code ("hello" or something silly like
that). I didn't see any "hello" messages until after all the "task ...
updates count to ..." messages were displayed.

Without going too deep, I suspect all your incrementStream() threads are
held up by class loading etc. Specifically, the stream APIs you're using in
incrementStream pull in maybe 40 additional classes on an Oracle JVM. To
see for yourself, run the JVM with -verbose:class and run both increment
and incrementStream -- notice the latter does a bunch of extra work. Since
classes are sort of loaded on-demand, that work needs to happen before your
incrementStream threads can run. Thus why the warmup step above improves
the situation.

Put another way: even though logically increment and incrementStream are
doing something very similar, the latter has to do a bunch of additional
work before any of the stuff that touches the count variable even gets to
run. And if it's not obvious it should be noted that your scenario here is
very small/fast and this effect will be less pronounced (but not entirely
absent) in a larger test.

Cheers,
Tom


On Fri, Feb 24, 2017 at 9:07 PM, Benjamin Manes <ben.manes at gmail.com> wrote:

> You need to wait until the executor has completed, or else the main method
> may complete prior to the task running.
>
> exec.awaitTermination(1, TimeUnit.MINUTES);
>
>
> On Fri, Feb 24, 2017 at 8:53 PM, kedar mhaswade <kedar.mhaswade at gmail.com>
> wrote:
>
>> ​Perhaps I had a long day. So, this might completely be a silly mistake,
>> but I need congenial help to figure it out.
>>
>> To demonstrate race condition, I wrote the following program. The program
>> has ten concurrent tasks that modify count, a volatile shared variable. If
>> I use the *increment* task (line 39), I get different results (like,
>> e.g. [2]) every time I run it, demonstrating the race condition.
>>
>> However, if I use the *incrementStream* task instead (line 39), then the
>> count variable is not updated at all. The output is like [1] *every time*.
>> In a separate program not involving threads, I have verified that the
>> lambda expression like incrementStream updates a member variable as
>> expected.
>>
>> What am I doing wrong?
>>
>> Regards,
>> Kedar
>>
>>
>> public class RaceCondition {
>>
>>     private static volatile int count = 0;
>>     public static void main(String[] args) {
>>         // update the shared variable traditionally
>>         Runnable increment = () -> {
>>             for (int i = 0; i < 1000; i++)
>>                 count++;
>>         };
>>         // update the shared variable as a side effect of an
>> IntConsumer#accept
>>         Runnable incrementStream = () -> IntStream.rangeClosed(1,
>> 100).forEach(i -> count++);
>>         ExecutorService exec = Executors.newCachedThreadPool(); // short
>> lived tasks
>>         try {
>>             for (int i = 0; i < 10; i++) {
>>
>> ​// ​
>> exec.execute(incrementStream)
>> ​;
>> // line 38​
>> ​​
>>
>>               exec.execute(increment);
>> ​         // line 39​
>>
>>                 System.out.println("task: " + i + " updates count to: " +
>> count);
>>             }
>>         } finally {
>>             exec.shutdown();
>>             System.out.println("final: " + count);
>>         }
>>     }
>>
>> }
>> [1]
>> task: 0 updates count to: 0
>> task: 1 updates count to: 0
>> task: 2 updates count to: 0
>> task: 3 updates count to: 0
>> task: 4 updates count to: 0
>> task: 5 updates count to: 0
>> task: 6 updates count to: 0
>> task: 7 updates count to: 0
>> task: 8 updates count to: 0
>> task: 9 updates count to: 0
>> final: 0
>> [2]
>> task: 0 updates count to: 0
>> task: 1 updates count to: 1000
>> task: 2 updates count to: 1000
>> task: 3 updates count to: 2000
>> task: 4 updates count to: 4027
>> task: 5 updates count to: 5000
>> task: 6 updates count to: 6000
>> task: 7 updates count to: 7005
>> task: 8 updates count to: 8000
>> task: 9 updates count to: 8185
>> final: 9381
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170225/0e035b7a/attachment-0001.html>

From davidcholmes at aapt.net.au  Sat Feb 25 04:45:28 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 25 Feb 2017 19:45:28 +1000
Subject: [concurrency-interest] Spot the bug in stream processing,
	IntConsumer and Executor
In-Reply-To: <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>
References: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
 <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>
 <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>
Message-ID: <000001d28f4b$e5d582e0$b18088a0$@aapt.net.au>

Also note that count++ is not an atomic operation so you will be losing updates and that will also cause erratic results.

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Tom Lee
Sent: Saturday, February 25, 2017 6:09 PM
To: Benjamin Manes <ben.manes at gmail.com>
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Spot the bug in stream processing, IntConsumer and Executor

 

Hi Kedar,

 

Disclaimer: I'd generally say something about this approach to having multiple threads incrementing a variable being a bad idea in general, but it sounds like you're just trying to explore the behavior of this race right?

 

Benjamin's on the right track: you're seeing zeros because the code submitted to the executor hasn't run by the time you print out the "task ... updates count to ..." messages. Still, it's not a complete fix & you'll very likely continue to see very different results even if you add an awaitTermination call after the shutdown() call. Also probably depends on how fast your machine is etc. etc. too (e.g. perhaps on slower machines / fewer cores you'd see similar output for both).

 

It's still kind of interesting why the exhibited behavior is so different. Here's a bit of a hint -- with the following code I get very similar output irrespective of whether I'm using "increment" or "incrementStream":

private static volatile int count = 0;
public static void main(String[] args) throws Exception {

    // warmup (slower)
    run(false);

    // do it for real (faster)
    count = 0;
    run(true);
}

private static void run(final boolean show) throws Exception {
    Runnable increment = () -> {
        for (int i = 0; i < 1000; i++)
            count++;
    };

    Runnable incrementStream = () -> {
        IntStream.rangeClosed(1, 1000).forEach(i -> count++);
    };
    ExecutorService exec = Executors.newCachedThreadPool();
    try {
        for (int i = 0; i < 10; i++) {
            exec.execute(increment);
            // exec.execute(incrementStream);
            if (show) System.out.println("task: " + i + " updates count to: " + count);
        }
    }
    finally {
        exec.shutdown();
        exec.awaitTermination(10, TimeUnit.SECONDS);
        if (show) System.out.println("final: " + count);
    }
}

Weird right?

 

Another hint: I added code to println() a message to the end of incrementStream() in your original code ("hello" or something silly like that). I didn't see any "hello" messages until after all the "task ... updates count to ..." messages were displayed.

 

Without going too deep, I suspect all your incrementStream() threads are held up by class loading etc. Specifically, the stream APIs you're using in incrementStream pull in maybe 40 additional classes on an Oracle JVM. To see for yourself, run the JVM with -verbose:class and run both increment and incrementStream -- notice the latter does a bunch of extra work. Since classes are sort of loaded on-demand, that work needs to happen before your incrementStream threads can run. Thus why the warmup step above improves the situation.

 

Put another way: even though logically increment and incrementStream are doing something very similar, the latter has to do a bunch of additional work before any of the stuff that touches the count variable even gets to run. And if it's not obvious it should be noted that your scenario here is very small/fast and this effect will be less pronounced (but not entirely absent) in a larger test.

 

Cheers,

Tom

 

 

On Fri, Feb 24, 2017 at 9:07 PM, Benjamin Manes <ben.manes at gmail.com <mailto:ben.manes at gmail.com> > wrote:

You need to wait until the executor has completed, or else the main method may complete prior to the task running.

exec.awaitTermination(1, TimeUnit.MINUTES);

 

 

On Fri, Feb 24, 2017 at 8:53 PM, kedar mhaswade <kedar.mhaswade at gmail.com <mailto:kedar.mhaswade at gmail.com> > wrote:

​Perhaps I had a long day. So, this might completely be a silly mistake, but I need congenial help to figure it out.

 

To demonstrate race condition, I wrote the following program. The program has ten concurrent tasks that modify count, a volatile shared variable. If I use the increment task (line 39), I get different results (like, e.g. [2]) every time I run it, demonstrating the race condition.

 

However, if I use the incrementStream task instead (line 39), then the count variable is not updated at all. The output is like [1] every time. In a separate program not involving threads, I have verified that the lambda expression like incrementStream updates a member variable as expected.

 

What am I doing wrong?

 

Regards,

Kedar

 

 

public class RaceCondition {

    private static volatile int count = 0;
    public static void main(String[] args) {
        // update the shared variable traditionally
        Runnable increment = () -> {
            for (int i = 0; i < 1000; i++)
                count++;
        };
        // update the shared variable as a side effect of an IntConsumer#accept
        Runnable incrementStream = () -> IntStream.rangeClosed(1, 100).forEach(i -> count++);
        ExecutorService exec = Executors.newCachedThreadPool(); // short lived tasks
        try {
            for (int i = 0; i < 10; i++) {
              

​// ​

exec.execute(incrementStream)

​;        

// line 38​

​​


              exec.execute(increment);

​         // line 39​


                System.out.println("task: " + i + " updates count to: " + count);
            }
        } finally {
            exec.shutdown();
            System.out.println("final: " + count);
        }
    }

}

[1]

task: 0 updates count to: 0

task: 1 updates count to: 0

task: 2 updates count to: 0

task: 3 updates count to: 0

task: 4 updates count to: 0

task: 5 updates count to: 0

task: 6 updates count to: 0

task: 7 updates count to: 0

task: 8 updates count to: 0

task: 9 updates count to: 0

final: 0

[2]

task: 0 updates count to: 0

task: 1 updates count to: 1000

task: 2 updates count to: 1000

task: 3 updates count to: 2000

task: 4 updates count to: 4027

task: 5 updates count to: 5000

task: 6 updates count to: 6000

task: 7 updates count to: 7005

task: 8 updates count to: 8000

task: 9 updates count to: 8185

final: 9381

 

 

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170225/78b3ec10/attachment.html>

From kedar.mhaswade at gmail.com  Sat Feb 25 12:32:54 2017
From: kedar.mhaswade at gmail.com (kedar mhaswade)
Date: Sat, 25 Feb 2017 09:32:54 -0800
Subject: [concurrency-interest] Spot the bug in stream processing,
 IntConsumer and Executor
In-Reply-To: <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>
References: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
 <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>
 <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>
Message-ID: <CABzSAw_y87uEMQjyNQ5BK4o3Eh+YZFv9Dvs3=ZZ8+on5-Oe19g@mail.gmail.com>

Thanks Tom and Benjamin. Yes, I am trying to demonstrate a race condition,
so yes, this code is for illustration purposes only.

*And upon a closer look, I found the bug in my code:*

        Runnable increment = () -> {
            for (int i = 0; i < *1000*; i++)
                count++;
        };

        // update the shared variable as a side effect of an
IntConsumer#accept
        Runnable incrementStream = () -> IntStream.rangeClosed(1,
*100*).forEach(i
-> count++);


The stream-oriented task was getting a *100* instead of a *1000* :-P.
Fixing this gives very similar results. Of course, it clearly demonstrates
that count++ is *not* an atomic operation and some updates are lost as
expected. I also verified that by using an AtomicInteger instead of a
simple volatile, the final value of count is 10,000, always.

Regards,
Kedar


On Sat, Feb 25, 2017 at 12:09 AM, Tom Lee <concurrency-interest at tomlee.co>
wrote:

> Hi Kedar,
>
> Disclaimer: I'd generally say something about this approach to having
> multiple threads incrementing a variable being a bad idea in general, but
> it sounds like you're just trying to explore the behavior of this race
> right?
>
> Benjamin's on the right track: you're seeing zeros because the code
> submitted to the executor hasn't run by the time you print out the "task
> ... updates count to ..." messages. Still, it's not a complete fix & you'll
> very likely continue to see very different results even if you add an
> awaitTermination call after the shutdown() call. Also probably depends on
> how fast your machine is etc. etc. too (e.g. perhaps on slower machines /
> fewer cores you'd see similar output for both).
>
> It's still kind of interesting why the exhibited behavior is so different.
> Here's a bit of a hint -- with the following code I get very similar output
> irrespective of whether I'm using "increment" or "incrementStream":
>
> private static volatile int count = 0;
> public static void main(String[] args) throws Exception {
>
>     // warmup (slower)
>     run(false);
>
>     // do it for real (faster)
>     count = 0;
>     run(true);
> }
>
> private static void run(final boolean show) throws Exception {
>     Runnable increment = () -> {
>         for (int i = 0; i < 1000; i++)
>             count++;
>     };
>
>     Runnable incrementStream = () -> {
>         IntStream.rangeClosed(1, 1000).forEach(i -> count++);
>     };
>     ExecutorService exec = Executors.newCachedThreadPool();
>     try {
>         for (int i = 0; i < 10; i++) {
>             exec.execute(increment);
>             // exec.execute(incrementStream);
>             if (show) System.out.println("task: " + i + " updates count to: " + count);
>         }
>     }
>     finally {
>         exec.shutdown();
>         exec.awaitTermination(10, TimeUnit.SECONDS);
>         if (show) System.out.println("final: " + count);
>     }
> }
>
> Weird right?
>
> Another hint: I added code to println() a message to the end of
> incrementStream() in your original code ("hello" or something silly like
> that). I didn't see any "hello" messages until after all the "task ...
> updates count to ..." messages were displayed.
>
> Without going too deep, I suspect all your incrementStream() threads are
> held up by class loading etc. Specifically, the stream APIs you're using in
> incrementStream pull in maybe 40 additional classes on an Oracle JVM. To
> see for yourself, run the JVM with -verbose:class and run both increment
> and incrementStream -- notice the latter does a bunch of extra work. Since
> classes are sort of loaded on-demand, that work needs to happen before your
> incrementStream threads can run. Thus why the warmup step above improves
> the situation.
>
> Put another way: even though logically increment and incrementStream are
> doing something very similar, the latter has to do a bunch of additional
> work before any of the stuff that touches the count variable even gets to
> run. And if it's not obvious it should be noted that your scenario here is
> very small/fast and this effect will be less pronounced (but not entirely
> absent) in a larger test.
>
> Cheers,
> Tom
>
>
> On Fri, Feb 24, 2017 at 9:07 PM, Benjamin Manes <ben.manes at gmail.com>
> wrote:
>
>> You need to wait until the executor has completed, or else the main
>> method may complete prior to the task running.
>>
>> exec.awaitTermination(1, TimeUnit.MINUTES);
>>
>>
>> On Fri, Feb 24, 2017 at 8:53 PM, kedar mhaswade <kedar.mhaswade at gmail.com
>> > wrote:
>>
>>> ​Perhaps I had a long day. So, this might completely be a silly mistake,
>>> but I need congenial help to figure it out.
>>>
>>> To demonstrate race condition, I wrote the following program. The
>>> program has ten concurrent tasks that modify count, a volatile shared
>>> variable. If I use the *increment* task (line 39), I get different
>>> results (like, e.g. [2]) every time I run it, demonstrating the race
>>> condition.
>>>
>>> However, if I use the *incrementStream* task instead (line 39), then
>>> the count variable is not updated at all. The output is like [1] *every
>>> time*. In a separate program not involving threads, I have verified
>>> that the lambda expression like incrementStream updates a member variable
>>> as expected.
>>>
>>> What am I doing wrong?
>>>
>>> Regards,
>>> Kedar
>>>
>>>
>>> public class RaceCondition {
>>>
>>>     private static volatile int count = 0;
>>>     public static void main(String[] args) {
>>>         // update the shared variable traditionally
>>>         Runnable increment = () -> {
>>>             for (int i = 0; i < 1000; i++)
>>>                 count++;
>>>         };
>>>         // update the shared variable as a side effect of an
>>> IntConsumer#accept
>>>         Runnable incrementStream = () -> IntStream.rangeClosed(1,
>>> 100).forEach(i -> count++);
>>>         ExecutorService exec = Executors.newCachedThreadPool(); //
>>> short lived tasks
>>>         try {
>>>             for (int i = 0; i < 10; i++) {
>>>
>>> ​// ​
>>> exec.execute(incrementStream)
>>> ​;
>>> // line 38​
>>> ​​
>>>
>>>               exec.execute(increment);
>>> ​         // line 39​
>>>
>>>                 System.out.println("task: " + i + " updates count to: "
>>> + count);
>>>             }
>>>         } finally {
>>>             exec.shutdown();
>>>             System.out.println("final: " + count);
>>>         }
>>>     }
>>>
>>> }
>>> [1]
>>> task: 0 updates count to: 0
>>> task: 1 updates count to: 0
>>> task: 2 updates count to: 0
>>> task: 3 updates count to: 0
>>> task: 4 updates count to: 0
>>> task: 5 updates count to: 0
>>> task: 6 updates count to: 0
>>> task: 7 updates count to: 0
>>> task: 8 updates count to: 0
>>> task: 9 updates count to: 0
>>> final: 0
>>> [2]
>>> task: 0 updates count to: 0
>>> task: 1 updates count to: 1000
>>> task: 2 updates count to: 1000
>>> task: 3 updates count to: 2000
>>> task: 4 updates count to: 4027
>>> task: 5 updates count to: 5000
>>> task: 6 updates count to: 6000
>>> task: 7 updates count to: 7005
>>> task: 8 updates count to: 8000
>>> task: 9 updates count to: 8185
>>> final: 9381
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170225/11c5a778/attachment.html>

From concurrency-interest at tomlee.co  Sat Feb 25 12:37:53 2017
From: concurrency-interest at tomlee.co (Tom Lee)
Date: Sat, 25 Feb 2017 09:37:53 -0800
Subject: [concurrency-interest] Spot the bug in stream processing,
 IntConsumer and Executor
In-Reply-To: <CABzSAw_y87uEMQjyNQ5BK4o3Eh+YZFv9Dvs3=ZZ8+on5-Oe19g@mail.gmail.com>
References: <CABzSAw8dvy05fuX=7EaEcauwk_k+f_hgh-NAs-ZELRKGPerYEQ@mail.gmail.com>
 <CAGu0=MOnu=A+p69fS9K8S3p67hs=7R4LYPP0kH_1thNeGFM0EA@mail.gmail.com>
 <CAKwFPQ94hjtKJjrj-B7SE8G=JWABafF2NbKT_xNcX-9M9c8C3g@mail.gmail.com>
 <CABzSAw_y87uEMQjyNQ5BK4o3Eh+YZFv9Dvs3=ZZ8+on5-Oe19g@mail.gmail.com>
Message-ID: <CAKwFPQ81BX_ZQC2G-DxaQmXaRrna9QKdN8XNLGxCiqhwNe7t4A@mail.gmail.com>

FWIW I noticed that 100/1000 thing too, and still got "bad" results (all
zeros) after changing the 100 to 1000.

On Feb 25, 2017 9:32 AM, "kedar mhaswade" <kedar.mhaswade at gmail.com> wrote:

> Thanks Tom and Benjamin. Yes, I am trying to demonstrate a race condition,
> so yes, this code is for illustration purposes only.
>
> *And upon a closer look, I found the bug in my code:*
>
>         Runnable increment = () -> {
>             for (int i = 0; i < *1000*; i++)
>                 count++;
>         };
>
>         // update the shared variable as a side effect of an
> IntConsumer#accept
>         Runnable incrementStream = () -> IntStream.rangeClosed(1, *100*).forEach(i
> -> count++);
>
>
> The stream-oriented task was getting a *100* instead of a *1000* :-P.
> Fixing this gives very similar results. Of course, it clearly demonstrates
> that count++ is *not* an atomic operation and some updates are lost as
> expected. I also verified that by using an AtomicInteger instead of a
> simple volatile, the final value of count is 10,000, always.
>
> Regards,
> Kedar
>
>
> On Sat, Feb 25, 2017 at 12:09 AM, Tom Lee <concurrency-interest at tomlee.co>
> wrote:
>
>> Hi Kedar,
>>
>> Disclaimer: I'd generally say something about this approach to having
>> multiple threads incrementing a variable being a bad idea in general, but
>> it sounds like you're just trying to explore the behavior of this race
>> right?
>>
>> Benjamin's on the right track: you're seeing zeros because the code
>> submitted to the executor hasn't run by the time you print out the "task
>> ... updates count to ..." messages. Still, it's not a complete fix & you'll
>> very likely continue to see very different results even if you add an
>> awaitTermination call after the shutdown() call. Also probably depends on
>> how fast your machine is etc. etc. too (e.g. perhaps on slower machines /
>> fewer cores you'd see similar output for both).
>>
>> It's still kind of interesting why the exhibited behavior is so
>> different. Here's a bit of a hint -- with the following code I get very
>> similar output irrespective of whether I'm using "increment" or
>> "incrementStream":
>>
>> private static volatile int count = 0;
>> public static void main(String[] args) throws Exception {
>>
>>     // warmup (slower)
>>     run(false);
>>
>>     // do it for real (faster)
>>     count = 0;
>>     run(true);
>> }
>>
>> private static void run(final boolean show) throws Exception {
>>     Runnable increment = () -> {
>>         for (int i = 0; i < 1000; i++)
>>             count++;
>>     };
>>
>>     Runnable incrementStream = () -> {
>>         IntStream.rangeClosed(1, 1000).forEach(i -> count++);
>>     };
>>     ExecutorService exec = Executors.newCachedThreadPool();
>>     try {
>>         for (int i = 0; i < 10; i++) {
>>             exec.execute(increment);
>>             // exec.execute(incrementStream);
>>             if (show) System.out.println("task: " + i + " updates count to: " + count);
>>         }
>>     }
>>     finally {
>>         exec.shutdown();
>>         exec.awaitTermination(10, TimeUnit.SECONDS);
>>         if (show) System.out.println("final: " + count);
>>     }
>> }
>>
>> Weird right?
>>
>> Another hint: I added code to println() a message to the end of
>> incrementStream() in your original code ("hello" or something silly like
>> that). I didn't see any "hello" messages until after all the "task ...
>> updates count to ..." messages were displayed.
>>
>> Without going too deep, I suspect all your incrementStream() threads are
>> held up by class loading etc. Specifically, the stream APIs you're using in
>> incrementStream pull in maybe 40 additional classes on an Oracle JVM. To
>> see for yourself, run the JVM with -verbose:class and run both increment
>> and incrementStream -- notice the latter does a bunch of extra work. Since
>> classes are sort of loaded on-demand, that work needs to happen before your
>> incrementStream threads can run. Thus why the warmup step above improves
>> the situation.
>>
>> Put another way: even though logically increment and incrementStream are
>> doing something very similar, the latter has to do a bunch of additional
>> work before any of the stuff that touches the count variable even gets to
>> run. And if it's not obvious it should be noted that your scenario here is
>> very small/fast and this effect will be less pronounced (but not entirely
>> absent) in a larger test.
>>
>> Cheers,
>> Tom
>>
>>
>> On Fri, Feb 24, 2017 at 9:07 PM, Benjamin Manes <ben.manes at gmail.com>
>> wrote:
>>
>>> You need to wait until the executor has completed, or else the main
>>> method may complete prior to the task running.
>>>
>>> exec.awaitTermination(1, TimeUnit.MINUTES);
>>>
>>>
>>> On Fri, Feb 24, 2017 at 8:53 PM, kedar mhaswade <
>>> kedar.mhaswade at gmail.com> wrote:
>>>
>>>> ​Perhaps I had a long day. So, this might completely be a silly
>>>> mistake, but I need congenial help to figure it out.
>>>>
>>>> To demonstrate race condition, I wrote the following program. The
>>>> program has ten concurrent tasks that modify count, a volatile shared
>>>> variable. If I use the *increment* task (line 39), I get different
>>>> results (like, e.g. [2]) every time I run it, demonstrating the race
>>>> condition.
>>>>
>>>> However, if I use the *incrementStream* task instead (line 39), then
>>>> the count variable is not updated at all. The output is like [1] *every
>>>> time*. In a separate program not involving threads, I have verified
>>>> that the lambda expression like incrementStream updates a member variable
>>>> as expected.
>>>>
>>>> What am I doing wrong?
>>>>
>>>> Regards,
>>>> Kedar
>>>>
>>>>
>>>> public class RaceCondition {
>>>>
>>>>     private static volatile int count = 0;
>>>>     public static void main(String[] args) {
>>>>         // update the shared variable traditionally
>>>>         Runnable increment = () -> {
>>>>             for (int i = 0; i < 1000; i++)
>>>>                 count++;
>>>>         };
>>>>         // update the shared variable as a side effect of an
>>>> IntConsumer#accept
>>>>         Runnable incrementStream = () -> IntStream.rangeClosed(1,
>>>> 100).forEach(i -> count++);
>>>>         ExecutorService exec = Executors.newCachedThreadPool(); //
>>>> short lived tasks
>>>>         try {
>>>>             for (int i = 0; i < 10; i++) {
>>>>
>>>> ​// ​
>>>> exec.execute(incrementStream)
>>>> ​;
>>>> // line 38​
>>>> ​​
>>>>
>>>>               exec.execute(increment);
>>>> ​         // line 39​
>>>>
>>>>                 System.out.println("task: " + i + " updates count to: "
>>>> + count);
>>>>             }
>>>>         } finally {
>>>>             exec.shutdown();
>>>>             System.out.println("final: " + count);
>>>>         }
>>>>     }
>>>>
>>>> }
>>>> [1]
>>>> task: 0 updates count to: 0
>>>> task: 1 updates count to: 0
>>>> task: 2 updates count to: 0
>>>> task: 3 updates count to: 0
>>>> task: 4 updates count to: 0
>>>> task: 5 updates count to: 0
>>>> task: 6 updates count to: 0
>>>> task: 7 updates count to: 0
>>>> task: 8 updates count to: 0
>>>> task: 9 updates count to: 0
>>>> final: 0
>>>> [2]
>>>> task: 0 updates count to: 0
>>>> task: 1 updates count to: 1000
>>>> task: 2 updates count to: 1000
>>>> task: 3 updates count to: 2000
>>>> task: 4 updates count to: 4027
>>>> task: 5 updates count to: 5000
>>>> task: 6 updates count to: 6000
>>>> task: 7 updates count to: 7005
>>>> task: 8 updates count to: 8000
>>>> task: 9 updates count to: 8185
>>>> final: 9381
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170225/d95228cd/attachment-0001.html>

From rstoyanchev at pivotal.io  Mon Feb 27 15:12:12 2017
From: rstoyanchev at pivotal.io (Rossen Stoyanchev)
Date: Mon, 27 Feb 2017 15:12:12 -0500
Subject: [concurrency-interest] JDK 9 Flow and Reactive Streams Rules / TCK
Message-ID: <CAOnZH-a5_pVbjuqoFL3YdhN=2BZCUe8DvFAH+v4zhsKWAkMUUw@mail.gmail.com>

hi,

The Javadoc for Flow.java [1] and also the JEP-266 [2] mention that these
interfaces correspond to the reactive-streams specification both linking to
reactive-streams.org but there is no explicit mention of spec rules + TCK
nor whether implementations of the Flow interfaces are required to conform.
The answer may be implied but it is worth stating that more explicitly and
optionally have links from the interfaces to corresponding sections of the
spec rules.

There are two underlying concerns. One, it is not clear what the actual
intent is. Since the spec's main intention is for implementations "to
interoperate smoothly" then this is a key aspect to bring up in the Javadoc
of Flow.java. Two, for the casual reader that navigates to Flow.java, or
its contained interfaces, the explanations look deceptively plain. Even if
one is simply on the consuming side via Flow.Subscriber it would be nice to
notice immediately there is much more to learn from the spec rules and for
library implementations to verify against the TCK.

Regards,
Rossen

[1]
http://download.java.net/java/jdk9/docs/api/java/util/concurrent/Flow.html
[2] http://openjdk.java.net/jeps/266
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170227/0cca45c4/attachment.html>

From dl at cs.oswego.edu  Tue Feb 28 19:59:12 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 28 Feb 2017 19:59:12 -0500
Subject: [concurrency-interest] JDK 9 Flow and Reactive Streams Rules /
 TCK
In-Reply-To: <CAOnZH-a5_pVbjuqoFL3YdhN=2BZCUe8DvFAH+v4zhsKWAkMUUw@mail.gmail.com>
References: <CAOnZH-a5_pVbjuqoFL3YdhN=2BZCUe8DvFAH+v4zhsKWAkMUUw@mail.gmail.com>
Message-ID: <43a3301b-d6b4-a958-eff8-4423578b647f@cs.oswego.edu>

On 02/27/2017 03:12 PM, Rossen Stoyanchev wrote:

> The Javadoc for Flow.java [1] and also the JEP-266 [2] mention that
> these interfaces correspond to the reactive-streams specification both
> linking to reactive-streams.org <http://reactive-streams.org> but there
> is no explicit mention of spec rules + TCK nor whether implementations
> of the Flow interfaces are required to conform.

I hope that you don't mean to imply that people should feel free
not to conform to or test their implementations of other j.u.c
interfaces :-)

Our javadocs cover the R-S specs, but are expressed in a typical
JDK interface-centric fashion. I'm not sure what more we can say
or do to make people click the reactive-streams.org links to find
out more about rationale and available tests.
Although we should consider your suggestion of adding the link in a
few more places just in case people missed them.

-Doug


