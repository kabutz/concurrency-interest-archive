From Johannes.Lichtenberger at uni-konstanz.de  Thu Feb  2 13:41:08 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Thu, 02 Feb 2012 19:41:08 +0100
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
Message-ID: <4F2AD8C4.4050800@uni-konstanz.de>

Hello,

why doesn't the BlockingQueue interface contain a method similar to

public E poll(long timeout, TimeUnit unit) throws InterruptedException;?

I think it would be great to allow waiting a specified time if nothing
is in the Queue. In some circumstances I'd like to peek() a
Future-instance instead of using take() or poll(long, TimeUnit) but it's
necessary to wait if at the time calling the method nothing is in the queue.

Perhaps I missed something? ;-)

Ok, seems peek() is defined in the Queue-interface together with an
element()-method. Do I have to catch the NoSuchElementException and loop
and sleep() until something is available and to give up after some time
period or do I really miss something?

kind regards,
Johannes

From Johannes.Lichtenberger at uni-konstanz.de  Thu Feb  2 14:19:08 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Thu, 02 Feb 2012 20:19:08 +0100
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
In-Reply-To: <4F2AD8C4.4050800@uni-konstanz.de>
References: <4F2AD8C4.4050800@uni-konstanz.de>
Message-ID: <4F2AE1AC.8020505@uni-konstanz.de>

On 02/02/2012 07:41 PM, Johannes.Lichtenberger wrote:
> Hello,
> 
> why doesn't the BlockingQueue interface contain a method similar to
> 
> public E poll(long timeout, TimeUnit unit) throws InterruptedException;?
> 
> I think it would be great to allow waiting a specified time if nothing
> is in the Queue. In some circumstances I'd like to peek() a
> Future-instance instead of using take() or poll(long, TimeUnit) but it's
> necessary to wait if at the time calling the method nothing is in the queue.
> 
> Perhaps I missed something? ;-)
> 
> Ok, seems peek() is defined in the Queue-interface together with an
> element()-method. Do I have to catch the NoSuchElementException and loop
> and sleep() until something is available and to give up after some time
> period or do I really miss something?

Or maybe "pulling" the top element and push it back, but hm.

kind regards,
Johannes

From Johannes.Lichtenberger at uni-konstanz.de  Thu Feb  2 14:29:38 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Thu, 02 Feb 2012 20:29:38 +0100
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
In-Reply-To: <4F2AE1AC.8020505@uni-konstanz.de>
References: <4F2AD8C4.4050800@uni-konstanz.de>
	<4F2AE1AC.8020505@uni-konstanz.de>
Message-ID: <4F2AE422.5040701@uni-konstanz.de>

On 02/02/2012 08:19 PM, Johannes.Lichtenberger wrote:
> On 02/02/2012 07:41 PM, Johannes.Lichtenberger wrote:
>> Hello,
>>
>> why doesn't the BlockingQueue interface contain a method similar to
>>
>> public E poll(long timeout, TimeUnit unit) throws InterruptedException;?
>>
>> I think it would be great to allow waiting a specified time if nothing
>> is in the Queue. In some circumstances I'd like to peek() a
>> Future-instance instead of using take() or poll(long, TimeUnit) but it's
>> necessary to wait if at the time calling the method nothing is in the queue.
>>
>> Perhaps I missed something? ;-)
>>
>> Ok, seems peek() is defined in the Queue-interface together with an
>> element()-method. Do I have to catch the NoSuchElementException and loop
>> and sleep() until something is available and to give up after some time
>> period or do I really miss something?
> 
> Or maybe "pulling" the top element and push it back, but hm.

Which certainly would involve some form of external synchronization such
that the producers can't add something in the meanwhile, not really
appropriate I think ;-)

From yshavit at akiban.com  Thu Feb  2 15:41:56 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 2 Feb 2012 15:41:56 -0500
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
In-Reply-To: <4F2AE422.5040701@uni-konstanz.de>
References: <4F2AD8C4.4050800@uni-konstanz.de>
	<4F2AE1AC.8020505@uni-konstanz.de>
	<4F2AE422.5040701@uni-konstanz.de>
Message-ID: <CAC2Zdp09_L=Sti5HYYCfmEM0n2-rG109XLKycaLfypSPCUAWjw@mail.gmail.com>

I may be missing something in your question, but it seems to me that
BlockingQueue does contain a method similar to the method you're asking
for. In fact, it's exactly what you're looking for. Same name, same inputs,
same output, same exception.

On Thu, Feb 2, 2012 at 2:29 PM, Johannes.Lichtenberger <
Johannes.Lichtenberger at uni-konstanz.de> wrote:

> On 02/02/2012 08:19 PM, Johannes.Lichtenberger wrote:
> > On 02/02/2012 07:41 PM, Johannes.Lichtenberger wrote:
> >> Hello,
> >>
> >> why doesn't the BlockingQueue interface contain a method similar to
> >>
> >> public E poll(long timeout, TimeUnit unit) throws InterruptedException;?
> >>
> >> I think it would be great to allow waiting a specified time if nothing
> >> is in the Queue. In some circumstances I'd like to peek() a
> >> Future-instance instead of using take() or poll(long, TimeUnit) but it's
> >> necessary to wait if at the time calling the method nothing is in the
> queue.
> >>
> >> Perhaps I missed something? ;-)
> >>
> >> Ok, seems peek() is defined in the Queue-interface together with an
> >> element()-method. Do I have to catch the NoSuchElementException and loop
> >> and sleep() until something is available and to give up after some time
> >> period or do I really miss something?
> >
> > Or maybe "pulling" the top element and push it back, but hm.
>
> Which certainly would involve some form of external synchronization such
> that the producers can't add something in the meanwhile, not really
> appropriate I think ;-)
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120202/8680e43a/attachment.html>

From Johannes.Lichtenberger at uni-konstanz.de  Thu Feb  2 15:46:34 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Thu, 02 Feb 2012 21:46:34 +0100
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
In-Reply-To: <CAC2Zdp09_L=Sti5HYYCfmEM0n2-rG109XLKycaLfypSPCUAWjw@mail.gmail.com>
References: <4F2AD8C4.4050800@uni-konstanz.de>
	<4F2AE1AC.8020505@uni-konstanz.de>
	<4F2AE422.5040701@uni-konstanz.de>
	<CAC2Zdp09_L=Sti5HYYCfmEM0n2-rG109XLKycaLfypSPCUAWjw@mail.gmail.com>
Message-ID: <4F2AF62A.4020303@uni-konstanz.de>

On 02/02/2012 09:41 PM, Yuval Shavit wrote:
> I may be missing something in your question, but it seems to me that
> BlockingQueue does contain a method similar to the method you're asking
> for. In fact, it's exactly what you're looking for. Same name, same inputs,
> same output, same exception.

E peek(long, TimeUnit)?


From stanimir at riflexo.com  Thu Feb  2 16:23:22 2012
From: stanimir at riflexo.com (bestsss)
Date: Thu, 2 Feb 2012 13:23:22 -0800 (PST)
Subject: [concurrency-interest] BlockingQueue or Queue / peek()
In-Reply-To: <4F2AF62A.4020303@uni-konstanz.de>
References: <4F2AD8C4.4050800@uni-konstanz.de>
	<4F2AE1AC.8020505@uni-konstanz.de>
	<4F2AE422.5040701@uni-konstanz.de>
	<CAC2Zdp09_L=Sti5HYYCfmEM0n2-rG109XLKycaLfypSPCUAWjw@mail.gmail.com>
	<4F2AF62A.4020303@uni-konstanz.de>
Message-ID: <33253261.post@talk.nabble.com>


I don't quite see the usefulness of the method.
As it's concurrent, by the time peek returns the element might not be in the
queue already.

What kind of a use case do you fancy?


Johannes.Lichtenberger wrote:
> 
> On 02/02/2012 09:41 PM, Yuval Shavit wrote:
>> I may be missing something in your question, but it seems to me that
>> BlockingQueue does contain a method similar to the method you're asking
>> for. In fact, it's exactly what you're looking for. Same name, same
>> inputs,
>> same output, same exception.
> 
> E peek(long, TimeUnit)?
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 

-- 
View this message in context: http://old.nabble.com/BlockingQueue-or-Queue---peek%28%29-tp33252294p33253261.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From pavel.rappo at gmail.com  Thu Feb  2 18:51:01 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 3 Feb 2012 03:51:01 +0400
Subject: [concurrency-interest] on happens-before formalism
Message-ID: <CAChcVunROakEqHiLsg=XODj7rX9p0ydEuG2Ho+SD_p8wGEzSsA@mail.gmail.com>

I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
Manson, William Pugh and Sarita Adve.
There's one (yet) thing seems strange to me. Though I think it's actually a
typo it's still worth mentioning.

page. 8, 2.1: "...Note that all of this means that happens-before is a
partial order: it is reflexive, transitive and anti-symmetric..."

Am I right saying authors actually meant "irreflexive"?

-- 
Sincerely yours, Pavel Rappo.

From qluo2 at illinois.edu  Fri Feb  3 00:16:17 2012
From: qluo2 at illinois.edu (Qingzhou Luo)
Date: Thu, 2 Feb 2012 23:16:17 -0600
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <CAChcVunROakEqHiLsg=XODj7rX9p0ydEuG2Ho+SD_p8wGEzSsA@mail.gmail.com>
References: <CAChcVunROakEqHiLsg=XODj7rX9p0ydEuG2Ho+SD_p8wGEzSsA@mail.gmail.com>
Message-ID: <CAMV5sD8k=FjiJasXnO8kH3gyLQdt=hPfKGkZUBCW7H=brJy44g@mail.gmail.com>

I think they did mean reflexive.

See partial order definition:
http://en.wikipedia.org/wiki/Partially_ordered_set

On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> Manson, William Pugh and Sarita Adve.
> There's one (yet) thing seems strange to me. Though I think it's actually a
> typo it's still worth mentioning.
>
> page. 8, 2.1: "...Note that all of this means that happens-before is a
> partial order: it is reflexive, transitive and anti-symmetric..."
>
> Am I right saying authors actually meant "irreflexive"?
>
> --
> Sincerely yours, Pavel Rappo.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Qingzhou Luo
http://mir.cs.illinois.edu/~qluo2/

Department of Computer Science
University of Illinois, Urbana Champaign
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120202/42ca935c/attachment.html>

From pavel.rappo at gmail.com  Fri Feb  3 02:17:56 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 3 Feb 2012 11:17:56 +0400
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <CAMV5sD8k=FjiJasXnO8kH3gyLQdt=hPfKGkZUBCW7H=brJy44g@mail.gmail.com>
References: <CAChcVunROakEqHiLsg=XODj7rX9p0ydEuG2Ho+SD_p8wGEzSsA@mail.gmail.com>
	<CAMV5sD8k=FjiJasXnO8kH3gyLQdt=hPfKGkZUBCW7H=brJy44g@mail.gmail.com>
Message-ID: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>

Then I think it's very different from Lamport's definition of happened-before which they reference to.
Maybe that's why Lamport calls it "happenED-before" (not "happenS-before").

Btw, there's such thing as strict partial order, which I guess in this case is more suitable. It's irreflexive, asymmetric and transitive.

On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:

> I think they did mean reflexive.
> 
> See partial order definition:
> http://en.wikipedia.org/wiki/Partially_ordered_set
> 
> On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:
> I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> Manson, William Pugh and Sarita Adve.
> There's one (yet) thing seems strange to me. Though I think it's actually a
> typo it's still worth mentioning.
> 
> page. 8, 2.1: "...Note that all of this means that happens-before is a
> partial order: it is reflexive, transitive and anti-symmetric..."
> 
> Am I right saying authors actually meant "irreflexive"?
> 
> --
> Sincerely yours, Pavel Rappo.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> -- 
> Qingzhou Luo
> http://mir.cs.illinois.edu/~qluo2/
> 
> Department of Computer Science
> University of Illinois, Urbana Champaign
> 



From davidcholmes at aapt.net.au  Fri Feb  3 02:28:58 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 3 Feb 2012 17:28:58 +1000
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>

It seems to me to be somewhat arbitrary to define this as either reflexive
or irreflexive as it makes no practical difference to the semantics. I think
irreflexive would be more appropriate in this case as intuitively it doesn't
make sense to say that "A happens-before A". I suspect that by selecting
reflexive and using a normal/simple notion of poset that the overall
formalism is simplified.

If you really want to know ask on the Java Memory Model list cc'ed.

Cheers,
David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Pavel
> Rappo
> Sent: Friday, 3 February 2012 5:18 PM
> To: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] on happens-before formalism
>
>
> Then I think it's very different from Lamport's definition of
> happened-before which they reference to.
> Maybe that's why Lamport calls it "happenED-before" (not
> "happenS-before").
>
> Btw, there's such thing as strict partial order, which I guess in
> this case is more suitable. It's irreflexive, asymmetric and transitive.
>
> On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:
>
> > I think they did mean reflexive.
> >
> > See partial order definition:
> > http://en.wikipedia.org/wiki/Partially_ordered_set
> >
> > On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo
> <pavel.rappo at gmail.com> wrote:
> > I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> > Manson, William Pugh and Sarita Adve.
> > There's one (yet) thing seems strange to me. Though I think
> it's actually a
> > typo it's still worth mentioning.
> >
> > page. 8, 2.1: "...Note that all of this means that happens-before is a
> > partial order: it is reflexive, transitive and anti-symmetric..."
> >
> > Am I right saying authors actually meant "irreflexive"?
> >
> > --
> > Sincerely yours, Pavel Rappo.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> > --
> > Qingzhou Luo
> > http://mir.cs.illinois.edu/~qluo2/
> >
> > Department of Computer Science
> > University of Illinois, Urbana Champaign
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Fri Feb  3 06:40:22 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 3 Feb 2012 21:40:22 +1000
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEMGJCAA.davidcholmes@aapt.net.au>

Sorry, now it's cc'd to the JMM list

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David
> Holmes
> Sent: Friday, 3 February 2012 5:29 PM
> To: Pavel Rappo; Concurrency-interest at cs.oswego.edu
> Cc: jmm
> Subject: Re: [concurrency-interest] on happens-before formalism
>
>
> It seems to me to be somewhat arbitrary to define this as either reflexive
> or irreflexive as it makes no practical difference to the
> semantics. I think
> irreflexive would be more appropriate in this case as intuitively
> it doesn't
> make sense to say that "A happens-before A". I suspect that by selecting
> reflexive and using a normal/simple notion of poset that the overall
> formalism is simplified.
>
> If you really want to know ask on the Java Memory Model list cc'ed.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Pavel
> > Rappo
> > Sent: Friday, 3 February 2012 5:18 PM
> > To: Concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] on happens-before formalism
> >
> >
> > Then I think it's very different from Lamport's definition of
> > happened-before which they reference to.
> > Maybe that's why Lamport calls it "happenED-before" (not
> > "happenS-before").
> >
> > Btw, there's such thing as strict partial order, which I guess in
> > this case is more suitable. It's irreflexive, asymmetric and transitive.
> >
> > On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:
> >
> > > I think they did mean reflexive.
> > >
> > > See partial order definition:
> > > http://en.wikipedia.org/wiki/Partially_ordered_set
> > >
> > > On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo
> > <pavel.rappo at gmail.com> wrote:
> > > I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> > > Manson, William Pugh and Sarita Adve.
> > > There's one (yet) thing seems strange to me. Though I think
> > it's actually a
> > > typo it's still worth mentioning.
> > >
> > > page. 8, 2.1: "...Note that all of this means that happens-before is a
> > > partial order: it is reflexive, transitive and anti-symmetric..."
> > >
> > > Am I right saying authors actually meant "irreflexive"?
> > >
> > > --
> > > Sincerely yours, Pavel Rappo.
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > >
> > >
> > > --
> > > Qingzhou Luo
> > > http://mir.cs.illinois.edu/~qluo2/
> > >
> > > Department of Computer Science
> > > University of Illinois, Urbana Champaign
> > >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From joe.bowbeer at gmail.com  Fri Feb  3 11:04:27 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 3 Feb 2012 08:04:27 -0800
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
References: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
Message-ID: <CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>

When this question arose on The Art of Multiprocessor Programming
discussion list a couple years ago, the resolution was that happens-before
(<=) is a strict partial order, therefore reflexive.

In other words, happens-before can be interpreted as
"happens-before-or-is-equal" -- but no one wants to say or write that.

--Joe

On Thu, Feb 2, 2012 at 11:28 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> It seems to me to be somewhat arbitrary to define this as either reflexive
> or irreflexive as it makes no practical difference to the semantics. I
> think
> irreflexive would be more appropriate in this case as intuitively it
> doesn't
> make sense to say that "A happens-before A". I suspect that by selecting
> reflexive and using a normal/simple notion of poset that the overall
> formalism is simplified.
>
> If you really want to know ask on the Java Memory Model list cc'ed.
>
> Cheers,
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Pavel
> > Rappo
> > Sent: Friday, 3 February 2012 5:18 PM
> > To: Concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] on happens-before formalism
> >
> >
> > Then I think it's very different from Lamport's definition of
> > happened-before which they reference to.
> > Maybe that's why Lamport calls it "happenED-before" (not
> > "happenS-before").
> >
> > Btw, there's such thing as strict partial order, which I guess in
> > this case is more suitable. It's irreflexive, asymmetric and transitive.
> >
> > On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:
> >
> > > I think they did mean reflexive.
> > >
> > > See partial order definition:
> > > http://en.wikipedia.org/wiki/Partially_ordered_set
> > >
> > > On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo
> > <pavel.rappo at gmail.com> wrote:
> > > I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> > > Manson, William Pugh and Sarita Adve.
> > > There's one (yet) thing seems strange to me. Though I think
> > it's actually a
> > > typo it's still worth mentioning.
> > >
> > > page. 8, 2.1: "...Note that all of this means that happens-before is a
> > > partial order: it is reflexive, transitive and anti-symmetric..."
> > >
> > > Am I right saying authors actually meant "irreflexive"?
> > >
> > > --
> > > Sincerely yours, Pavel Rappo.
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > >
> > >
> > > --
> > > Qingzhou Luo
> > > http://mir.cs.illinois.edu/~qluo2/
> > >
> > > Department of Computer Science
> > > University of Illinois, Urbana Champaign
> > >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120203/4eb3a196/attachment.html>

From pavel.rappo at gmail.com  Fri Feb  3 11:11:12 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 3 Feb 2012 20:11:12 +0400
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>
References: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
	<CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>
Message-ID: <EB9E6137-DC0D-4590-AFC9-D5807353EDA9@gmail.com>

Either non-strict or irreflexive :) But I think I got what you mean. Thanks.

On 3 Feb 2012, at 20:04, Joe Bowbeer wrote:

> When this question arose on The Art of Multiprocessor Programming discussion list a couple years ago, the resolution was that happens-before (<=) is a strict partial order, therefore reflexive.
> 
> In other words, happens-before can be interpreted as "happens-before-or-is-equal" -- but no one wants to say or write that.
> 
> --Joe
> 
> On Thu, Feb 2, 2012 at 11:28 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> It seems to me to be somewhat arbitrary to define this as either reflexive
> or irreflexive as it makes no practical difference to the semantics. I think
> irreflexive would be more appropriate in this case as intuitively it doesn't
> make sense to say that "A happens-before A". I suspect that by selecting
> reflexive and using a normal/simple notion of poset that the overall
> formalism is simplified.
> 
> If you really want to know ask on the Java Memory Model list cc'ed.
> 
> Cheers,
> David Holmes
> 
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Pavel
> > Rappo
> > Sent: Friday, 3 February 2012 5:18 PM
> > To: Concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] on happens-before formalism
> >
> >
> > Then I think it's very different from Lamport's definition of
> > happened-before which they reference to.
> > Maybe that's why Lamport calls it "happenED-before" (not
> > "happenS-before").
> >
> > Btw, there's such thing as strict partial order, which I guess in
> > this case is more suitable. It's irreflexive, asymmetric and transitive.
> >
> > On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:
> >
> > > I think they did mean reflexive.
> > >
> > > See partial order definition:
> > > http://en.wikipedia.org/wiki/Partially_ordered_set
> > >
> > > On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo
> > <pavel.rappo at gmail.com> wrote:
> > > I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
> > > Manson, William Pugh and Sarita Adve.
> > > There's one (yet) thing seems strange to me. Though I think
> > it's actually a
> > > typo it's still worth mentioning.
> > >
> > > page. 8, 2.1: "...Note that all of this means that happens-before is a
> > > partial order: it is reflexive, transitive and anti-symmetric..."
> > >
> > > Am I right saying authors actually meant "irreflexive"?
> > >
> > > --
> > > Sincerely yours, Pavel Rappo.
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> > >
> > >
> > > --
> > > Qingzhou Luo
> > > http://mir.cs.illinois.edu/~qluo2/
> > >
> > > Department of Computer Science
> > > University of Illinois, Urbana Champaign
> > >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From jason_mehrens at hotmail.com  Fri Feb  3 11:29:22 2012
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 3 Feb 2012 10:29:22 -0600
Subject: [concurrency-interest] ForkJoin updates
In-Reply-To: <4F20A70A.7030204@cs.oswego.edu>
References: <4F20A70A.7030204@cs.oswego.edu>
Message-ID: <SNT114-W307C47D76ECCAC9093CBC583710@phx.gbl>


Hi Doug,
 
Would unconditionally marking the ForkJoinTask as ineligible for biased locking, as described in http://blogs.oracle.com/dave/entry/biased_locking_in_hotspot, offer the same performance improvement as system wide disabling of biased locking?
According to this, http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6378256, you might want to test transforming System.identityHashCode(this) into super.hashCode() when that transformation is safe to perform.
 
Jason
 



> 5. Other minor changes that give a few percent improvement in
> common FJ task processing. On the other hand, this version is
> even more prone to GC cardmark contention. So if using hotspot
> on a multiprocessor (or even >4core multicore) you absolutely
> must run in -XX:UseCondCardMark or -XX:+UseG1GC. (Also, it is
> better behaved with biased locking disabled -XX:-UseBiasedLocking).
> 
> As always, suggestions and comments based on usage experience
> would be very welcome.
> 
> -Doug
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120203/9511cf8e/attachment-0001.html>

From joe.bowbeer at gmail.com  Fri Feb  3 11:34:15 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Fri, 3 Feb 2012 08:34:15 -0800
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <EB9E6137-DC0D-4590-AFC9-D5807353EDA9@gmail.com>
References: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
	<CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>
	<EB9E6137-DC0D-4590-AFC9-D5807353EDA9@gmail.com>
Message-ID: <CAHzJPErsVWM=k-VE=PMcgJ3ERRqOCeLUMHCV_aoJcgU3kNmPQg@mail.gmail.com>

Oops!  strict is < and non-strict is <=.

The following statement may be correct:

happens-before (<=) is a "non-strict" partial order (also known as a "reflexive
partial order" or "weak partial order").

--Joe

On Fri, Feb 3, 2012 at 8:11 AM, Pavel Rappo wrote:

> Either non-strict or irreflexive :) But I think I got what you mean.
> Thanks.
>
> On 3 Feb 2012, at 20:04, Joe Bowbeer wrote:
>
> > When this question arose on The Art of Multiprocessor Programming
> discussion list a couple years ago, the resolution was that happens-before
> (<=) is a strict partial order, therefore reflexive.
> >
> > In other words, happens-before can be interpreted as
> "happens-before-or-is-equal" -- but no one wants to say or write that.
> >
> > --Joe
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120203/3281cbd7/attachment.html>

From dl at cs.oswego.edu  Fri Feb  3 13:28:09 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 03 Feb 2012 13:28:09 -0500
Subject: [concurrency-interest] ForkJoin updates
In-Reply-To: <SNT114-W307C47D76ECCAC9093CBC583710@phx.gbl>
References: <4F20A70A.7030204@cs.oswego.edu>
	<SNT114-W307C47D76ECCAC9093CBC583710@phx.gbl>
Message-ID: <4F2C2739.7080008@cs.oswego.edu>

On 02/03/12 11:29, Jason Mehrens wrote:
> Hi Doug,
> Would unconditionally marking the ForkJoinTask as ineligible for biased locking,
> as described in http://blogs.oracle.com/dave/entry/biased_locking_in_hotspot,
> offer the same performance improvement as system wide disabling of biased locking?

I don't plan to do this, but resolving this in a better way is
among the  "other" remaining changes for this round I mentioned.

First, mostly as an aside, biased locking rarely improves, and
often reduces, performance on most Intel i7+ processors. (At
least on programs I run, for which bias code that averages more
than 10 cycles to avoid a sub-10 cycle uncontended CAS loses.)
Probably it should be disabled on them by default.

The main problem with biased locking for FJ is the current
revocation policy. Often, a task either signalling or being
signalled about a join gets stuck stalled until a GC pass
unbiases the lock. The unluckiest of these cases cascade into
stalls involving many threads/cores, which are the main cause
of the unwanted positive feedback loops I've mentioned that
force compensation to be overly conservative.

I'd rather not use a workaround (hashCode) that happens
to work only on (some versions of) hotspot. But there are
other means of somewhat more portably avoiding
biasing, thin-locks, etc. None are perfect but I plan on
settling on one of them soon.

-Doug




From gdenys at yahoo.com  Fri Feb  3 15:14:45 2012
From: gdenys at yahoo.com (Geert Denys)
Date: Fri, 3 Feb 2012 12:14:45 -0800 (PST)
Subject: [concurrency-interest] Fw:
Message-ID: <1328300085.54551.yint-ygo-j2me@web161205.mail.bf1.yahoo.com>


http://suavecitas.com/congratulation.php?akeluco=31&mohic=975&ljmivjkopyb=55

From pavel.rappo at gmail.com  Wed Feb  8 05:52:06 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Wed, 8 Feb 2012 14:52:06 +0400
Subject: [concurrency-interest] Strange concurrency behaviour on Java 6 Mac
	OS X Lion
Message-ID: <CE2FFF80-E419-4921-BF76-07FC6131F866@gmail.com>

Hello,

some time ago I found issue in jdk6 on mac os x lion. Looks like Apple finally fixed it:

http://stackoverflow.com/questions/9038169/strange-concurrency-behaviour-on-java-6-mac-os-x-lion

From yshavit at akiban.com  Thu Feb  9 12:29:27 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 9 Feb 2012 12:29:27 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
Message-ID: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>

I've wondered this for a bit, and it finally came up in a stackoverflow
discussion recently. The JLS's description of final field read semantics
(as far as all threads seeing the state at least as it was at the end of
the constructor) only seems to apply to member fields -- not statics.
Specifically, JLS 17,5 refers only to object construction, not class
instantiation. JLS 13.4.9 states that primitives and Strings have to be
seen initialized, but makes no reference to other fields. So, are there
actually any guarantees for static finals?

For instance, is this class thread-safe, given that it uses a
non-thread-safe map which is initialized statically and then never modified?

    import java.util.*;
    public class PoorMansEnum {
        private static final Map<String,Integer> map = createMap();

        private static Map<String,Integer> createMap() {
            Map<String,Integer> map = new HashMap<String,Integer>();
            map.put("Foo", 1);
            map.put("Bar", 2);
            return map;
        }

        public static int valueOf(String value) {
            Integer integer = map.get(value);
            if (integer == null)
                throw new IllegalArgumentException("not a value: " + value);
            return integer;
        }
    }

Is there even a guarantee that every thread will see a non-null "map"? I
can't find anything in the JLS about it.

Thanks,
-Yuval
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/b160816a/attachment.html>

From vitalyd at gmail.com  Thu Feb  9 12:48:55 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 9 Feb 2012 12:48:55 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
Message-ID: <CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>

Static initialization guarantees visibility, so even without final on the
map it's guaranteed that all static initializing writes are seen across
cores (obviously subsequent writes to non-final non-volatile static fields
aren't guaranteed to be visible).

Sent from my phone
On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> I've wondered this for a bit, and it finally came up in a stackoverflow
> discussion recently. The JLS's description of final field read semantics
> (as far as all threads seeing the state at least as it was at the end of
> the constructor) only seems to apply to member fields -- not statics.
> Specifically, JLS 17,5 refers only to object construction, not class
> instantiation. JLS 13.4.9 states that primitives and Strings have to be
> seen initialized, but makes no reference to other fields. So, are there
> actually any guarantees for static finals?
>
> For instance, is this class thread-safe, given that it uses a
> non-thread-safe map which is initialized statically and then never modified?
>
>     import java.util.*;
>     public class PoorMansEnum {
>         private static final Map<String,Integer> map = createMap();
>
>         private static Map<String,Integer> createMap() {
>             Map<String,Integer> map = new HashMap<String,Integer>();
>             map.put("Foo", 1);
>             map.put("Bar", 2);
>             return map;
>         }
>
>         public static int valueOf(String value) {
>             Integer integer = map.get(value);
>             if (integer == null)
>                 throw new IllegalArgumentException("not a value: " +
> value);
>             return integer;
>         }
>     }
>
> Is there even a guarantee that every thread will see a non-null "map"? I
> can't find anything in the JLS about it.
>
> Thanks,
> -Yuval
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/dd49dec2/attachment.html>

From yshavit at akiban.com  Thu Feb  9 13:27:10 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 9 Feb 2012 13:27:10 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
	<CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>
Message-ID: <CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>

Where is that in the JLS? I can't find it (I'm looking especially
at 17.4.5, "Happens-before Order").

On Thu, Feb 9, 2012 at 12:48 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Static initialization guarantees visibility, so even without final on the
> map it's guaranteed that all static initializing writes are seen across
> cores (obviously subsequent writes to non-final non-volatile static fields
> aren't guaranteed to be visible).
>
> Sent from my phone
> On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>
>> I've wondered this for a bit, and it finally came up in a stackoverflow
>> discussion recently. The JLS's description of final field read semantics
>> (as far as all threads seeing the state at least as it was at the end of
>> the constructor) only seems to apply to member fields -- not statics.
>> Specifically, JLS 17,5 refers only to object construction, not class
>> instantiation. JLS 13.4.9 states that primitives and Strings have to be
>> seen initialized, but makes no reference to other fields. So, are there
>> actually any guarantees for static finals?
>>
>> For instance, is this class thread-safe, given that it uses a
>> non-thread-safe map which is initialized statically and then never modified?
>>
>>     import java.util.*;
>>     public class PoorMansEnum {
>>         private static final Map<String,Integer> map = createMap();
>>
>>         private static Map<String,Integer> createMap() {
>>             Map<String,Integer> map = new HashMap<String,Integer>();
>>             map.put("Foo", 1);
>>             map.put("Bar", 2);
>>             return map;
>>         }
>>
>>         public static int valueOf(String value) {
>>             Integer integer = map.get(value);
>>             if (integer == null)
>>                 throw new IllegalArgumentException("not a value: " +
>> value);
>>             return integer;
>>         }
>>     }
>>
>> Is there even a guarantee that every thread will see a non-null "map"? I
>> can't find anything in the JLS about it.
>>
>> Thanks,
>> -Yuval
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/42fa1af7/attachment.html>

From vitalyd at gmail.com  Thu Feb  9 13:42:31 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 9 Feb 2012 13:42:31 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
	<CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>
	<CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>
Message-ID: <CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>

JVM spec 2.17.5 talks about static initialization in a bit of detail.  It
doesn't explicitly mention memory visibility but it does make it clear that
a lock/unlock is associated with initialization such that only 1 thread is
allowed to init the class.  I think this implies that initializing writes
will be visible.

Sent from my phone
On Feb 9, 2012 1:27 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> Where is that in the JLS? I can't find it (I'm looking especially
> at 17.4.5, "Happens-before Order").
>
> On Thu, Feb 9, 2012 at 12:48 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Static initialization guarantees visibility, so even without final on the
>> map it's guaranteed that all static initializing writes are seen across
>> cores (obviously subsequent writes to non-final non-volatile static fields
>> aren't guaranteed to be visible).
>>
>> Sent from my phone
>> On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>
>>> I've wondered this for a bit, and it finally came up in a stackoverflow
>>> discussion recently. The JLS's description of final field read semantics
>>> (as far as all threads seeing the state at least as it was at the end of
>>> the constructor) only seems to apply to member fields -- not statics.
>>> Specifically, JLS 17,5 refers only to object construction, not class
>>> instantiation. JLS 13.4.9 states that primitives and Strings have to be
>>> seen initialized, but makes no reference to other fields. So, are there
>>> actually any guarantees for static finals?
>>>
>>> For instance, is this class thread-safe, given that it uses a
>>> non-thread-safe map which is initialized statically and then never modified?
>>>
>>>     import java.util.*;
>>>     public class PoorMansEnum {
>>>         private static final Map<String,Integer> map = createMap();
>>>
>>>         private static Map<String,Integer> createMap() {
>>>             Map<String,Integer> map = new HashMap<String,Integer>();
>>>             map.put("Foo", 1);
>>>             map.put("Bar", 2);
>>>             return map;
>>>         }
>>>
>>>         public static int valueOf(String value) {
>>>             Integer integer = map.get(value);
>>>             if (integer == null)
>>>                 throw new IllegalArgumentException("not a value: " +
>>> value);
>>>             return integer;
>>>         }
>>>     }
>>>
>>> Is there even a guarantee that every thread will see a non-null "map"? I
>>> can't find anything in the JLS about it.
>>>
>>> Thanks,
>>> -Yuval
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/1cde3428/attachment-0001.html>

From yshavit at akiban.com  Thu Feb  9 14:16:08 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 9 Feb 2012 14:16:08 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
	<CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>
	<CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>
	<CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>
Message-ID: <CAC2Zdp3t7eeytJSGiVBT31RkBQtAhrzKMWBPudqKLyPk67hvUA@mail.gmail.com>

Is it generally valid to make visibility assumptions on the JVM spec? I've
always been going by the JLS, which from what I understand is a bit looser
in its guarantees.

JLS 12.4.2 does talk about class initialization in detail, and also
mentions a lock such that only one thread is allowed to init the class.
That said, if the class is already initialized, I don't see anything in the
spec that requires such a lock -- the details of answering "is this class
already initialized?" seems to be unspecified. So, it seems that if thread
A initializes the class, and some time later thread B uses the class for
the first time, there's nothing requiring thread B to try to initialize the
class, meaning there's no synchronization and no HB. Indeed, without that
behavior, every thread would be forced to acquire a lock at least once for
every class it sees, which would seem prohibitive.

On Thu, Feb 9, 2012 at 1:42 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> JVM spec 2.17.5 talks about static initialization in a bit of detail.  It
> doesn't explicitly mention memory visibility but it does make it clear that
> a lock/unlock is associated with initialization such that only 1 thread is
> allowed to init the class.  I think this implies that initializing writes
> will be visible.
>
> Sent from my phone
> On Feb 9, 2012 1:27 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>
>> Where is that in the JLS? I can't find it (I'm looking especially
>> at 17.4.5, "Happens-before Order").
>>
>> On Thu, Feb 9, 2012 at 12:48 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>
>>> Static initialization guarantees visibility, so even without final on
>>> the map it's guaranteed that all static initializing writes are seen across
>>> cores (obviously subsequent writes to non-final non-volatile static fields
>>> aren't guaranteed to be visible).
>>>
>>> Sent from my phone
>>> On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>>
>>>> I've wondered this for a bit, and it finally came up in a stackoverflow
>>>> discussion recently. The JLS's description of final field read semantics
>>>> (as far as all threads seeing the state at least as it was at the end of
>>>> the constructor) only seems to apply to member fields -- not statics.
>>>> Specifically, JLS 17,5 refers only to object construction, not class
>>>> instantiation. JLS 13.4.9 states that primitives and Strings have to be
>>>> seen initialized, but makes no reference to other fields. So, are there
>>>> actually any guarantees for static finals?
>>>>
>>>> For instance, is this class thread-safe, given that it uses a
>>>> non-thread-safe map which is initialized statically and then never modified?
>>>>
>>>>     import java.util.*;
>>>>     public class PoorMansEnum {
>>>>         private static final Map<String,Integer> map = createMap();
>>>>
>>>>         private static Map<String,Integer> createMap() {
>>>>             Map<String,Integer> map = new HashMap<String,Integer>();
>>>>             map.put("Foo", 1);
>>>>             map.put("Bar", 2);
>>>>             return map;
>>>>         }
>>>>
>>>>         public static int valueOf(String value) {
>>>>             Integer integer = map.get(value);
>>>>             if (integer == null)
>>>>                 throw new IllegalArgumentException("not a value: " +
>>>> value);
>>>>             return integer;
>>>>         }
>>>>     }
>>>>
>>>> Is there even a guarantee that every thread will see a non-null "map"?
>>>> I can't find anything in the JLS about it.
>>>>
>>>> Thanks,
>>>> -Yuval
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/0b6daa02/attachment.html>

From heinz at javaspecialists.eu  Thu Feb  9 14:20:07 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 09 Feb 2012 21:20:07 +0200
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>	<CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>	<CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>
	<CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>
Message-ID: <4F341C67.3020103@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/0344d661/attachment.html>

From vitalyd at gmail.com  Thu Feb  9 15:13:08 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 9 Feb 2012 15:13:08 -0500
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAC2Zdp3t7eeytJSGiVBT31RkBQtAhrzKMWBPudqKLyPk67hvUA@mail.gmail.com>
References: <CAC2Zdp3nODhk5FB+0qhM1uz1iqBr1RFfN=0kW3J0+zm22re43Q@mail.gmail.com>
	<CAHjP37Hqwfu_VrzFjvuhDMY33iOuJcCneHDbT=c7-yrTMjZGxQ@mail.gmail.com>
	<CAC2Zdp0Njp73T=2gJsiVDuDSt-RGCVtHM0pwo8hzQYDEHaR1ag@mail.gmail.com>
	<CAHjP37GAcsh1xpKwwrKjgeh-75t9UNygtWWFmn4Nw5XXDH6hkQ@mail.gmail.com>
	<CAC2Zdp3t7eeytJSGiVBT31RkBQtAhrzKMWBPudqKLyPk67hvUA@mail.gmail.com>
Message-ID: <CAHjP37Gb0WDsh6zd8W4mbComxFbWBYPh+GZg6AGBHa8AkMXuDg@mail.gmail.com>

I agree that it's not clearly spelled out in terms of HB and JMM (unless I
missed it).  However, I don't see how java would work if it didn't provide
this guarantee given what static means in java.  If two threads
(unknowingly) race to initialize the class (not much you can do about that
in practical terms as a developer) and then try to read a statically
initialized field, it shouldn't matter which thread actually came "first" -
they shouldn't see different values based on that or else the whole notion
of static is messed up.

Sent from my phone
On Feb 9, 2012 2:16 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> Is it generally valid to make visibility assumptions on the JVM spec? I've
> always been going by the JLS, which from what I understand is a bit looser
> in its guarantees.
>
> JLS 12.4.2 does talk about class initialization in detail, and also
> mentions a lock such that only one thread is allowed to init the class.
> That said, if the class is already initialized, I don't see anything in the
> spec that requires such a lock -- the details of answering "is this class
> already initialized?" seems to be unspecified. So, it seems that if thread
> A initializes the class, and some time later thread B uses the class for
> the first time, there's nothing requiring thread B to try to initialize the
> class, meaning there's no synchronization and no HB. Indeed, without that
> behavior, every thread would be forced to acquire a lock at least once for
> every class it sees, which would seem prohibitive.
>
> On Thu, Feb 9, 2012 at 1:42 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> JVM spec 2.17.5 talks about static initialization in a bit of detail.  It
>> doesn't explicitly mention memory visibility but it does make it clear that
>> a lock/unlock is associated with initialization such that only 1 thread is
>> allowed to init the class.  I think this implies that initializing writes
>> will be visible.
>>
>> Sent from my phone
>> On Feb 9, 2012 1:27 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>
>>> Where is that in the JLS? I can't find it (I'm looking especially
>>> at 17.4.5, "Happens-before Order").
>>>
>>> On Thu, Feb 9, 2012 at 12:48 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>>
>>>> Static initialization guarantees visibility, so even without final on
>>>> the map it's guaranteed that all static initializing writes are seen across
>>>> cores (obviously subsequent writes to non-final non-volatile static fields
>>>> aren't guaranteed to be visible).
>>>>
>>>> Sent from my phone
>>>> On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>>>
>>>>> I've wondered this for a bit, and it finally came up in a
>>>>> stackoverflow discussion recently. The JLS's description of final field
>>>>> read semantics (as far as all threads seeing the state at least as it was
>>>>> at the end of the constructor) only seems to apply to member fields -- not
>>>>> statics. Specifically, JLS 17,5 refers only to object construction, not
>>>>> class instantiation. JLS 13.4.9 states that primitives and Strings have to
>>>>> be seen initialized, but makes no reference to other fields. So, are there
>>>>> actually any guarantees for static finals?
>>>>>
>>>>> For instance, is this class thread-safe, given that it uses a
>>>>> non-thread-safe map which is initialized statically and then never modified?
>>>>>
>>>>>     import java.util.*;
>>>>>     public class PoorMansEnum {
>>>>>         private static final Map<String,Integer> map = createMap();
>>>>>
>>>>>         private static Map<String,Integer> createMap() {
>>>>>             Map<String,Integer> map = new HashMap<String,Integer>();
>>>>>             map.put("Foo", 1);
>>>>>             map.put("Bar", 2);
>>>>>             return map;
>>>>>         }
>>>>>
>>>>>         public static int valueOf(String value) {
>>>>>             Integer integer = map.get(value);
>>>>>             if (integer == null)
>>>>>                 throw new IllegalArgumentException("not a value: " +
>>>>> value);
>>>>>             return integer;
>>>>>         }
>>>>>     }
>>>>>
>>>>> Is there even a guarantee that every thread will see a non-null "map"?
>>>>> I can't find anything in the JLS about it.
>>>>>
>>>>> Thanks,
>>>>> -Yuval
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120209/2793efd3/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Feb  9 15:17:37 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 10 Feb 2012 06:17:37 +1000
Subject: [concurrency-interest] any read guarantees for static finals?
In-Reply-To: <CAC2Zdp3t7eeytJSGiVBT31RkBQtAhrzKMWBPudqKLyPk67hvUA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEOEJCAA.davidcholmes@aapt.net.au>

JLS 12.4.2 explains the class initialization process in detail and states
that the lock (it isn't the Class instance's lock any more) must be acquired
and then the initialization state is checked. This means that every thread
must act as-if it does this for every class that it uses, and which must be
initialized for that use. This locking/unlocking enforces a happens-before
ordering as per any locking/unlocking. No inference or assumptions about
visibility are needed.

The VM can of course optimize this in a variety of ways, but it must always
act as-if the lock were acquired then released. JLS 12.4.3 alludes to this
when discussing code generation and the elision of initialization checks
when it is known that the class is already initialized.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yuval Shavit
  Sent: Friday, 10 February 2012 5:16 AM
  To: Vitaly Davidovich
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] any read guarantees for static finals?


  Is it generally valid to make visibility assumptions on the JVM spec? I've
always been going by the JLS, which from what I understand is a bit looser
in its guarantees.


  JLS 12.4.2 does talk about class initialization in detail, and also
mentions a lock such that only one thread is allowed to init the class. That
said, if the class is already initialized, I don't see anything in the spec
that requires such a lock -- the details of answering "is this class already
initialized?" seems to be unspecified. So, it seems that if thread A
initializes the class, and some time later thread B uses the class for the
first time, there's nothing requiring thread B to try to initialize the
class, meaning there's no synchronization and no HB. Indeed, without that
behavior, every thread would be forced to acquire a lock at least once for
every class it sees, which would seem prohibitive.


  On Thu, Feb 9, 2012 at 1:42 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

    JVM spec 2.17.5 talks about static initialization in a bit of detail.
It doesn't explicitly mention memory visibility but it does make it clear
that a lock/unlock is associated with initialization such that only 1 thread
is allowed to init the class.  I think this implies that initializing writes
will be visible.

    Sent from my phone

    On Feb 9, 2012 1:27 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

      Where is that in the JLS? I can't find it (I'm looking especially at
17.4.5, "Happens-before Order").


      On Thu, Feb 9, 2012 at 12:48 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

        Static initialization guarantees visibility, so even without final
on the map it's guaranteed that all static initializing writes are seen
across cores (obviously subsequent writes to non-final non-volatile static
fields aren't guaranteed to be visible).

        Sent from my phone

        On Feb 9, 2012 12:32 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

          I've wondered this for a bit, and it finally came up in a
stackoverflow discussion recently. The JLS's description of final field read
semantics (as far as all threads seeing the state at least as it was at the
end of the constructor) only seems to apply to member fields -- not statics.
Specifically, JLS 17,5 refers only to object construction, not class
instantiation. JLS 13.4.9 states that primitives and Strings have to be seen
initialized, but makes no reference to other fields. So, are there actually
any guarantees for static finals?


          For instance, is this class thread-safe, given that it uses a
non-thread-safe map which is initialized statically and then never modified?


              import java.util.*;
              public class PoorMansEnum {
                  private static final Map<String,Integer> map =
createMap();

                  private static Map<String,Integer> createMap() {
                      Map<String,Integer> map = new
HashMap<String,Integer>();
                      map.put("Foo", 1);
                      map.put("Bar", 2);
                      return map;
                  }

                  public static int valueOf(String value) {
                      Integer integer = map.get(value);
                      if (integer == null)
                          throw new IllegalArgumentException("not a value: "
+ value);
                      return integer;
                  }
              }


          Is there even a guarantee that every thread will see a non-null
"map"? I can't find anything in the JLS about it.


          Thanks,
          -Yuval


          _______________________________________________
          Concurrency-interest mailing list
          Concurrency-interest at cs.oswego.edu
          http://cs.oswego.edu/mailman/listinfo/concurrency-interest





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120210/7388723d/attachment.html>

From al-javaconcurrencyinterest at none.at  Fri Feb 10 15:15:49 2012
From: al-javaconcurrencyinterest at none.at (Aleksandar Lazic)
Date: Fri, 10 Feb 2012 21:15:49 +0100
Subject: [concurrency-interest] EDU.oswego.cs.dl.util.concurrent.Latch and
	Sync replace with
	java.util.concurrent.locks.AbstractQueuedSynchronizer
Message-ID: <551dcf5c6a2cc84e6789c9a74cad6c90@none.at>

Dear list members,

currently I read the book

Concurrent Programming in Java: Design Principles and Patterns, (second 
edition)

and try to use the

abstract class DiskTask implements Runnable {
....
}

but there is the following line

protected final Latch done = new Latch(); // status indicator

After a little search I have found

http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html

with Sync and Latch but this classes are outdated.

Can I replace the class Latch with AbstractQueuedSynchronizer or is 
there a better replacement?

Thanks for your help

Aleks

From vitalyd at gmail.com  Fri Feb 10 15:22:40 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 10 Feb 2012 15:22:40 -0500
Subject: [concurrency-interest] EDU.oswego.cs.dl.util.concurrent.Latch
 and Sync replace with java.util.concurrent.locks.AbstractQueuedSynchronizer
In-Reply-To: <551dcf5c6a2cc84e6789c9a74cad6c90@none.at>
References: <551dcf5c6a2cc84e6789c9a74cad6c90@none.at>
Message-ID: <CAHjP37F2pY_DdAO+Uyz5aeRhTcy0Y-UgNsg3TkQPg0YALpq4Vg@mail.gmail.com>

You can replace it with j.u.c.CountdownLatch (with a count of 1 for a
one-time signal).

Sent from my phone
On Feb 10, 2012 3:17 PM, "Aleksandar Lazic" <
al-javaconcurrencyinterest at none.at> wrote:

> Dear list members,
>
> currently I read the book
>
> Concurrent Programming in Java: Design Principles and Patterns, (second
> edition)
>
> and try to use the
>
> abstract class DiskTask implements Runnable {
> ....
> }
>
> but there is the following line
>
> protected final Latch done = new Latch(); // status indicator
>
> After a little search I have found
>
> http://gee.cs.oswego.edu/dl/**classes/EDU/oswego/cs/dl/util/**
> concurrent/intro.html<http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html>
>
> with Sync and Latch but this classes are outdated.
>
> Can I replace the class Latch with AbstractQueuedSynchronizer or is there
> a better replacement?
>
> Thanks for your help
>
> Aleks
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120210/7f74f61c/attachment.html>

From al-javaconcurrencyinterest at none.at  Fri Feb 10 16:15:02 2012
From: al-javaconcurrencyinterest at none.at (Aleksandar Lazic)
Date: Fri, 10 Feb 2012 22:15:02 +0100
Subject: [concurrency-interest] EDU.oswego.cs.dl.util.concurrent.Latch
	and Sync replace with
	java.util.concurrent.locks.AbstractQueuedSynchronizer
In-Reply-To: <CAHjP37F2pY_DdAO+Uyz5aeRhTcy0Y-UgNsg3TkQPg0YALpq4Vg@mail.gmail.com>
References: <551dcf5c6a2cc84e6789c9a74cad6c90@none.at>
	<CAHjP37F2pY_DdAO+Uyz5aeRhTcy0Y-UgNsg3TkQPg0YALpq4Vg@mail.gmail.com>
Message-ID: <8865ff576161584c37f36d80fad61dcc@none.at>

 

Dear Vitaly, 

thanks. 

BR 

Aleks 

On 10-02-2012 21:22, Vitaly
Davidovich wrote: 

> You can replace it with j.u.c.CountdownLatch (with
a count of 1 for a one-time signal). 
> 
> Sent from my phone 
> On Feb
10, 2012 3:17 PM, "Aleksandar Lazic" <al-javaconcurrencyinterest at none.at
[4]> wrote:
> 
>> Dear list members,
>> 
>> currently I read the book
>>

>> Concurrent Programming in Java: Design Principles and Patterns,
(second edition)
>> 
>> and try to use the
>> 
>> abstract class
DiskTask implements Runnable {
>> ....
>> }
>> 
>> but there is the
following line
>> 
>> protected final Latch done = new Latch(); //
status indicator
>> 
>> After a little search I have found
>> 
>>
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
[1]
>> 
>> with Sync and Latch but this classes are outdated.
>> 
>>
Can I replace the class Latch with AbstractQueuedSynchronizer or is
there a better replacement?
>> 
>> Thanks for your help
>> 
>> Aleks
>>
_______________________________________________
>> Concurrency-interest
mailing list
>> Concurrency-interest at cs.oswego.edu [2]
>>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest [3]



Links:
------
[1]
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
[2]
mailto:Concurrency-interest at cs.oswego.edu
[3]
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
[4]
mailto:al-javaconcurrencyinterest at none.at
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120210/e9b8b53a/attachment.html>

From hanson.char at gmail.com  Mon Feb 13 22:52:45 2012
From: hanson.char at gmail.com (Hanson Char)
Date: Mon, 13 Feb 2012 19:52:45 -0800
Subject: [concurrency-interest] ThreadLocalRandom vs ThreadLocalSecureRandom
	?
Message-ID: <CABWgujaXMHAT-0LmJQ860Fwof6-t66DFKWZ1fy3CiqxYfKy8yQ@mail.gmail.com>

Apparently ThreadLocalRandom is made available in Java 7 for concurrency
reason:


http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadLocalRandom.html

I wonder why there isn't a thread local equivalence for SecureRandom.  Is
it just an "accident" or is there a good reason ?

Thanks,
Hanson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120213/f80ab1da/attachment.html>

From Holger.Peine at fh-hannover.de  Tue Feb 14 01:36:41 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Tue, 14 Feb 2012 07:36:41 +0100
Subject: [concurrency-interest] ThreadLocalRandom vs
 ThreadLocalSecureRandom ?
In-Reply-To: <CABWgujaXMHAT-0LmJQ860Fwof6-t66DFKWZ1fy3CiqxYfKy8yQ@mail.gmail.com>
References: <CABWgujaXMHAT-0LmJQ860Fwof6-t66DFKWZ1fy3CiqxYfKy8yQ@mail.gmail.com>
Message-ID: <4F3A00F9.7080404@fh-hannover.de>

Am 14.02.2012 04:52, schrieb Hanson Char:
> Apparently ThreadLocalRandom is made available in Java 7 for concurrency
> reason:
> 
>   http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadLocalRandom.html
> 
> I wonder why there isn't a thread local equivalence for SecureRandom.

Just making a spontaneous guess here:  The reason could be that, while a
pseudo-random number generator such as is used with Random and
ThreaLocalRandom can easily be implemented on a per-thread basis since
it is pure software, that is not true for SecureRandom, since the latter
is based on a hardware entropy source (such as mouse movements, clock
drift etc.), and you cannot give every thread its own piece of entropy-
generating hardware.

Kind regards,
Holger Peine


-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From oztalip at gmail.com  Tue Feb 14 09:09:54 2012
From: oztalip at gmail.com (Talip Ozturk)
Date: Tue, 14 Feb 2012 16:09:54 +0200
Subject: [concurrency-interest] volatile guarantee for directbuffer
Message-ID: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>

Say we have thread1 and thread2. Both can access a volatile boolean
variable, 'volatileVar' and DirectByteBuffer instance 'directBuffer'

thread1:
directBuffer.put(myByteArray);
directBuffer.putLong(myLong);
volatileVar = true;

thread2:
if (volatileVar) {
  // read the directBuffer
  directBuffer.get(myByteArray);
  long myLong = directBuffer.getLong();
}

Can I assume that thread2 did read the byte[] and long values?

Does volatile-reads give us happens-before guarantee for OffHeap data?

Thanks,
-talip

From pavel.rappo at gmail.com  Tue Feb 14 09:27:21 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Tue, 14 Feb 2012 18:27:21 +0400
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
Message-ID: <D5F95FDA-D8A8-42AB-868D-7227D76E6D4B@gmail.com>


On 14 Feb 2012, at 18:09, Talip Ozturk wrote:

> Say we have thread1 and thread2. Both can access a volatile boolean
> variable, 'volatileVar' and DirectByteBuffer instance 'directBuffer'
> 
> thread1:
> directBuffer.put(myByteArray);
> directBuffer.putLong(myLong);
> volatileVar = true;
> 
> thread2:
> if (volatileVar) {
>  // read the directBuffer
>  directBuffer.get(myByteArray);
>  long myLong = directBuffer.getLong();
> }
> 
> Can I assume that thread2 did read the byte[] and long values?
> 
> Does volatile-reads give us happens-before guarantee for OffHeap data?
> 
> Thanks,
> -talip
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From pavel.rappo at gmail.com  Tue Feb 14 09:28:41 2012
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Tue, 14 Feb 2012 18:28:41 +0400
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <D5F95FDA-D8A8-42AB-868D-7227D76E6D4B@gmail.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<D5F95FDA-D8A8-42AB-868D-7227D76E6D4B@gmail.com>
Message-ID: <DAC87ACD-A4B7-4C22-ABD2-5EBC8FE5AB02@gmail.com>

Sorry for previous email.

> Can I assume that thread2 did read the byte[] and long values?

Yes.

> Does volatile-reads give us happens-before guarantee for OffHeap data?

Could you please give an example of such a data?

On 14 Feb 2012, at 18:27, Pavel Rappo wrote:

> 
> On 14 Feb 2012, at 18:09, Talip Ozturk wrote:
> 
>> Say we have thread1 and thread2. Both can access a volatile boolean
>> variable, 'volatileVar' and DirectByteBuffer instance 'directBuffer'
>> 
>> thread1:
>> directBuffer.put(myByteArray);
>> directBuffer.putLong(myLong);
>> volatileVar = true;
>> 
>> thread2:
>> if (volatileVar) {
>> // read the directBuffer
>> directBuffer.get(myByteArray);
>> long myLong = directBuffer.getLong();
>> }
>> 
>> Can I assume that thread2 did read the byte[] and long values?
>> 
>> Does volatile-reads give us happens-before guarantee for OffHeap data?
>> 
>> Thanks,
>> -talip
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From Holger.Peine at fh-hannover.de  Tue Feb 14 10:53:53 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Tue, 14 Feb 2012 16:53:53 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
Message-ID: <4F3A8391.5090904@fh-hannover.de>

Am 14.02.2012 15:09, schrieb Talip Ozturk:
> Say we have thread1 and thread2. Both can access a volatile boolean
> variable, 'volatileVar' and DirectByteBuffer instance 'directBuffer'
> 
> thread1:
> directBuffer.put(myByteArray);
> directBuffer.putLong(myLong);
> volatileVar = true;
> 
> thread2:
> if (volatileVar) {
>   // read the directBuffer
>   directBuffer.get(myByteArray);
>   long myLong = directBuffer.getLong();
> }
> 
> Can I assume that thread2 did read the byte[] and long values?

Yes.

> Does volatile-reads give us happens-before guarantee for OffHeap data?

I'm not sure what you mean be OffHeap, but actually that doesn't matter
at all: Writing to a volatile will make _all_ writes that happened
earlier in the same thread visible to all threads, no matter what
and where that earlier-written data is. (I use to tell my students
"writing to a volatile flushes the cache".)

Regards,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From Holger.Peine at fh-hannover.de  Tue Feb 14 10:57:06 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Tue, 14 Feb 2012 16:57:06 +0100
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
Message-ID: <4F3A8452.900@fh-hannover.de>

Dear colleagues,

looking at their respective API, ForkJoinPool provides a superset of
ThreadPoolExecutor's functionality in standard scenarios (though
strictly speaking ThreadPoolExecutor offers more opportunities for
tuning than ForkJoinPool). Adding to this the observation that fork/join
tasks seem to be faster (possibly due to the work stealing scheduler),
need definitely fewer threads (due to the non-blocking join operation),
one might get the impression that ThreadPoolExecutor has been superseded
by ForkJoinPool.

But is this really correct? All the material I have read (the best
being Brian Goetz's article
http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
official JDK API doc) seems to sum up to a rather vague distinction
between the two types of thread pools:
- ForkJoinPool is for many, dependent, task-generated, short, hardly
  ever blocking (i.e. compute-intensive) tasks
- ThreadPoolExecutor is for few, independent, externally-generated,
  long, sometimes blocking tasks

Is this distinction correct at all? Can we say anything more specific
about this?

Thanks for your opinion,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From hans.boehm at hp.com  Tue Feb 14 14:46:48 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 14 Feb 2012 19:46:48 +0000
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3A8391.5090904@fh-hannover.de>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>

> From: Holger Peine
> (I use to tell my students "writing to a volatile flushes the cache".)

That somewhat conveys the right idea, but not entirely.  In particular:

- If only v is volatile, then x = 1; v = 1; z = 1 does not ensure that the write to x becomes visible before the write to z.  Furthermore if v is known not to be read by another thread, the write to v can be turned into a non-volatile write.

- The cost model is wrong.  Writing to a volatile is typically many orders of magnitude cheaper than what it would take to write the entire cache at full memory bandwidth.  It's typically at most a store buffer that's really flushed.

I'd instead go with something like "So long as accesses to the same non-volatile variable can't happen at the same time, or are all reads, you get sequential consistency."

Hans


From oztalip at gmail.com  Tue Feb 14 15:25:58 2012
From: oztalip at gmail.com (Talip Ozturk)
Date: Tue, 14 Feb 2012 22:25:58 +0200
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3A8391.5090904@fh-hannover.de>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
Message-ID: <CANGYBVF6uSJgDC=mVhr+ZiSpsOtcCy9P1gWq4reEQSm8m1uhxg@mail.gmail.com>

> I'm not sure what you mean be OffHeap, but actually that doesn't matter
> at all: Writing to a volatile will make _all_ writes that happened
> earlier in the same thread visible to all threads, no matter what
> and where that earlier-written data is. (I use to tell my students
> "writing to a volatile flushes the cache".)

Main question wasn't about guarantees of volatiles at all. We can use
volatile variables to guarantee 'happens-before' for the data we have
on-heap. Does it give the same guarantees for the the data stored
off-heap. DirectByteBuffer would be a good example of off-heap data.

I at least got one answer saying 'yes' to my question.

-talip

From davidcholmes at aapt.net.au  Tue Feb 14 16:49:51 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 15 Feb 2012 07:49:51 +1000
Subject: [concurrency-interest] What's the advantage of a Java-5
	ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <4F3A8452.900@fh-hannover.de>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>

Holger,

ForkJoinPool is designed for supporting fork/join based parallel
decomposition algorithms. It does that well via the work-stealing mechanisms
which reduce the task management overhead. It can only support other styles
of "parallel computation" with varying degrees of success.

ThreadPoolExecutor is a plain old thread pool. It makes no assumptions about
the type or nature of tasks or their dependencies.

Brian's summary is quite correct.

Obviously the two are, within limits, interchangeable, but they operate in
completely different spots in the design space.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Holger
> Peine
> Sent: Wednesday, 15 February 2012 1:57 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] What's the advantage of a Java-5
> ThreadPoolExecutor over a Java-7 ForkJoinPool?
>
>
> Dear colleagues,
>
> looking at their respective API, ForkJoinPool provides a superset of
> ThreadPoolExecutor's functionality in standard scenarios (though
> strictly speaking ThreadPoolExecutor offers more opportunities for
> tuning than ForkJoinPool). Adding to this the observation that fork/join
> tasks seem to be faster (possibly due to the work stealing scheduler),
> need definitely fewer threads (due to the non-blocking join operation),
> one might get the impression that ThreadPoolExecutor has been superseded
> by ForkJoinPool.
>
> But is this really correct? All the material I have read (the best
> being Brian Goetz's article
> http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
> official JDK API doc) seems to sum up to a rather vague distinction
> between the two types of thread pools:
> - ForkJoinPool is for many, dependent, task-generated, short, hardly
>   ever blocking (i.e. compute-intensive) tasks
> - ThreadPoolExecutor is for few, independent, externally-generated,
>   long, sometimes blocking tasks
>
> Is this distinction correct at all? Can we say anything more specific
> about this?
>
> Thanks for your opinion,
> Holger Peine
>
> --
> Prof. Dr. Holger Peine
> Hochschule Hannover, Fakult?t IV, Abt. Informatik
> Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
> Ricklinger Stadtweg 120, D-30459 Hannover, Germany
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From nathan.reynolds at oracle.com  Tue Feb 14 16:58:36 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Tue, 14 Feb 2012 14:58:36 -0700
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <CANGYBVF6uSJgDC=mVhr+ZiSpsOtcCy9P1gWq4reEQSm8m1uhxg@mail.gmail.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<CANGYBVF6uSJgDC=mVhr+ZiSpsOtcCy9P1gWq4reEQSm8m1uhxg@mail.gmail.com>
Message-ID: <4F3AD90C.8070101@oracle.com>

Yes, all stores preceeding a volatile store will be visible.  It doesn't 
matter if this store is on Java heap, off Java heap or else where.  On 
x86, the JVM puts in a fence after the volatile store.  This fence 
applies to all memory accesses regardless of where they are located.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 2/14/2012 1:25 PM, Talip Ozturk wrote:
>> I'm not sure what you mean be OffHeap, but actually that doesn't matter
>> at all: Writing to a volatile will make _all_ writes that happened
>> earlier in the same thread visible to all threads, no matter what
>> and where that earlier-written data is. (I use to tell my students
>> "writing to a volatile flushes the cache".)
> Main question wasn't about guarantees of volatiles at all. We can use
> volatile variables to guarantee 'happens-before' for the data we have
> on-heap. Does it give the same guarantees for the the data stored
> off-heap. DirectByteBuffer would be a good example of off-heap data.
>
> I at least got one answer saying 'yes' to my question.
>
> -talip
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120214/e731bfd5/attachment.html>

From hans.boehm at hp.com  Tue Feb 14 17:17:35 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 14 Feb 2012 22:17:35 +0000
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3AD90C.8070101@oracle.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<CANGYBVF6uSJgDC=mVhr+ZiSpsOtcCy9P1gWq4reEQSm8m1uhxg@mail.gmail.com>
	<4F3AD90C.8070101@oracle.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23275C22B@G4W3299.americas.hpqcorp.net>

> From: Nathan Reynolds

> Yes, all stores preceeding a volatile store will be visible.? It doesn't matter if this store
> is on Java heap, off Java heap or else where.? On x86, the JVM puts in a fence after the
> volatile store.? This fence applies to all memory accesses regardless of where they are located.

This sounds entirely correct, except that the fence after a volatile store doesn't help in this
case.  It's there only to order the volatile store with respect to a possible subsequent volatile load.
An x86 store by itself ensures that prior (in thread order) memory operations become visible
before the store, and that's the important point here.

This argument assumes that directBuffer is mapped write-back cacheable like the rest of the heap.
If the implementation plays with e.g. write-coalescing mappings, or uses non-temporal stores
without fences, then all bets are off.  I sincerely doubt that, but haven't looked at the implementation.

Hans




From Holger.Peine at fh-hannover.de  Wed Feb 15 01:58:56 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 07:58:56 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
Message-ID: <4F3B57B0.9000004@fh-hannover.de>

Am 14.02.2012 20:46, schrieb Boehm, Hans:
>> From: Holger Peine
>> (I use to tell my students "writing to a volatile flushes the cache".)
> 
> That somewhat conveys the right idea, but not entirely.  In particular:
> 
> - If only v is volatile,  
>[...]
> Furthermore if v is known not to be read by another thread, the write to v can be turned into a non-volatile write.

The hardware cannot know this, I assume - but the compiler could, in
certain cases. I hadn't thought oft that, but yes, the compiler could
"optimize away volatile" in such a cases - good point.

> - The cost model is wrong.  Writing to a volatile is typically many orders of magnitude cheaper than what it would take to write the entire cache at full memory bandwidth.  It's typically at most a store buffer that's really flushed.

Absolutely - my mnemonic "writing a volatile flushes the cache" is
correct regarding the functionality, but not regarding the performance,
since of course not the whole cache but only the dirty cache lines need
to be flushed.

> I'd instead go with something like "So long as accesses to the same non-volatile variable can't happen at the same time, or are all reads, you get sequential consistency."

That's a bit too complicated for a mnemonic, though - but "more correct"
of course.

Regards,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From Holger.Peine at fh-hannover.de  Wed Feb 15 01:59:01 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 07:59:01 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
Message-ID: <4F3B57B5.9080301@fh-hannover.de>

Am 14.02.2012 20:46, schrieb Boehm, Hans:
>> From: Holger Peine
>> (I use to tell my students "writing to a volatile flushes the cache".)
> 
> That somewhat conveys the right idea, but not entirely.  In particular:
> 
> - If only v is volatile, then x = 1; v = 1; z = 1 does not ensure that the write to x becomes visible before the write to z.  

The JMM does ensure that the write to x becomes visible together with
the write to v, and that was the original poster's (Talip Ozturk)
question.

What happens to z is another question: The JMM only guarantees that it
will not become visible before the write to x or v (since it
happens-after the x and v writes). It may never become visible at all.
It it becomes visible, however, then that will be after (or at the same
time as) the writes to x and v (since any other ordering would violate
the happens-before relation). So your above statement about z is
technically correct (since it may never become visible at all), but
somewhat misleading (since it cannot be become visible before x and v).

Your later statement that "the fence after a volatile
store ... It's there only to order the volatile
store with respect to a possible subsequent volatile load."
sounds like what was true in Java prior to Java 5. Since Java 5,
however, volatile stores do impose an ordering not only regarding
other volatile accesses, but also regarding non-volatile accesses
that happened-before the volatile store.

- At least that's how I understand the JMM. I'd be eager to hear that
I've been wrong all the time.

Regards,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From Holger.Peine at fh-hannover.de  Wed Feb 15 02:13:16 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 08:13:16 +0100
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
Message-ID: <4F3B5B0C.9020205@fh-hannover.de>

Am 14.02.2012 22:49, schrieb David Holmes:
> Holger,
> 
> ForkJoinPool is designed for supporting fork/join based parallel
> decomposition algorithms. It does that well via the work-stealing mechanisms
> which reduce the task management overhead. It can only support other styles
> of "parallel computation" with varying degrees of success.
> 
> ThreadPoolExecutor is a plain old thread pool. It makes no assumptions about
> the type or nature of tasks or their dependencies.
> 
> Brian's summary is quite correct.
> 
> Obviously the two are, within limits, interchangeable, but they operate in
> completely different spots in the design space.

Thanks for your reply, David. This reassures me that ...
(1) my "vague" understanding of the differences between the two thread
    pools was correct
(2) you cannot draw a clear line between the two beyond the criteria
    I had already named.

- Regarding the implementation of ForkJoinPool, I have the impression
that it has a global "entrance" task queue where the tasks submitted
"from the outside" go, and one task queue per thread where the tasks
generated "internally" (i.e. by the pool threads when executing tasks)
go and where the stealing happens. If that is correct, then a
ForkJoinPool whose tasks never generate child tasks would degenerate to
a ThreadPoolExecutor, and perform no better (nor, which is my point
here, any worse) than a ThreadPoolExecutor. Consequently, one could
argue that you should always use a ForkJoinPool: If your tasks are
actually fork/join tasks, then you get the benefit of ForkJoinPool,
but if they are not (i.e. if they are completely independent),
then you haven't lost anything compared using a ThreadPoolExecutor.
So, always using a ForkJoinPool would make your program more
flexible at no additional cost.

Is this correct?

Thanks for your opionion,
Holger.


>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Holger
>> Peine
>> Sent: Wednesday, 15 February 2012 1:57 AM
>> To: concurrency-interest at cs.oswego.edu
>> Subject: [concurrency-interest] What's the advantage of a Java-5
>> ThreadPoolExecutor over a Java-7 ForkJoinPool?
>>
>>
>> Dear colleagues,
>>
>> looking at their respective API, ForkJoinPool provides a superset of
>> ThreadPoolExecutor's functionality in standard scenarios (though
>> strictly speaking ThreadPoolExecutor offers more opportunities for
>> tuning than ForkJoinPool). Adding to this the observation that fork/join
>> tasks seem to be faster (possibly due to the work stealing scheduler),
>> need definitely fewer threads (due to the non-blocking join operation),
>> one might get the impression that ThreadPoolExecutor has been superseded
>> by ForkJoinPool.
>>
>> But is this really correct? All the material I have read (the best
>> being Brian Goetz's article
>> http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
>> official JDK API doc) seems to sum up to a rather vague distinction
>> between the two types of thread pools:
>> - ForkJoinPool is for many, dependent, task-generated, short, hardly
>>   ever blocking (i.e. compute-intensive) tasks
>> - ThreadPoolExecutor is for few, independent, externally-generated,
>>   long, sometimes blocking tasks
>>
>> Is this distinction correct at all? Can we say anything more specific
>> about this?
>>
>> Thanks for your opinion,
>> Holger Peine
>>
>> --
>> Prof. Dr. Holger Peine
>> Hochschule Hannover, Fakult?t IV, Abt. Informatik
>> Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
>> Ricklinger Stadtweg 120, D-30459 Hannover, Germany
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> 
> .
> 



-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From karmazilla at gmail.com  Wed Feb 15 03:26:39 2012
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Wed, 15 Feb 2012 09:26:39 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3B57B5.9080301@fh-hannover.de>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
	<4F3B57B5.9080301@fh-hannover.de>
Message-ID: <CACyP5Pdv+pxhhixNZ6+BMxSZH4SmQDHi0cXvfT8ML-9AAm8hCQ@mail.gmail.com>

On Wed, Feb 15, 2012 at 07:59, Holger Peine <Holger.Peine at fh-hannover.de>wrote:

> Am 14.02.2012 20:46, schrieb Boehm, Hans:
> >> From: Holger Peine
> >> (I use to tell my students "writing to a volatile flushes the cache".)
> >
> > That somewhat conveys the right idea, but not entirely.  In particular:
> >
> > - If only v is volatile, then x = 1; v = 1; z = 1 does not ensure that
> the write to x becomes visible before the write to z.
>
> The JMM does ensure that the write to x becomes visible together with
> the write to v, and that was the original poster's (Talip Ozturk)
> question.
>
> What happens to z is another question: The JMM only guarantees that it
> will not become visible before the write to x or v (since it
> happens-after the x and v writes).


Does it? Why is it prevented from re-ordering the write to z up before the
write to v, and indeed even before the write to x?


> It may never become visible at all.
> It it becomes visible, however, then that will be after (or at the same
> time as) the writes to x and v (since any other ordering would violate
> the happens-before relation). So your above statement about z is
> technically correct (since it may never become visible at all), but
> somewhat misleading (since it cannot be become visible before x and v).
>
> Your later statement that "the fence after a volatile
> store ... It's there only to order the volatile
> store with respect to a possible subsequent volatile load."
> sounds like what was true in Java prior to Java 5. Since Java 5,
> however, volatile stores do impose an ordering not only regarding
> other volatile accesses, but also regarding non-volatile accesses
> that happened-before the volatile store.
>
> - At least that's how I understand the JMM. I'd be eager to hear that
> I've been wrong all the time.
>
> Regards,
> Holger Peine
>
> --
> Prof. Dr. Holger Peine
> Hochschule Hannover, Fakult?t IV, Abt. Informatik
> Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
> Ricklinger Stadtweg 120, D-30459 Hannover, Germany
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120215/758ba89e/attachment.html>

From joe.bowbeer at gmail.com  Wed Feb 15 03:31:06 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 15 Feb 2012 00:31:06 -0800
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <4F3B5B0C.9020205@fh-hannover.de>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
Message-ID: <CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>

ThreadPoolExecutor provides a lot of different options for configuring the
worker threads.  The Executors tool class provides convenience methods to
create many of the useful configurations:

http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/Executors.html


The single-threaded variant, for example, is quite different from any
ForkJoinPool.  The CachedThreadPool is more like a ForkJoinPool.

It's difficult to manage multiple ForkJoinPools because each one will try
to achieve maximum throughput, whereas the classic thread pools can
designed to operate within limits.

ThreadPoolExecutor also supports custom BlockingQueue implementations, and
direct access to its queue.

Joe

On Tue, Feb 14, 2012 at 11:13 PM, Holger Peine wrote:

> Am 14.02.2012 22:49, schrieb David Holmes:
> > Holger,
> >
> > ForkJoinPool is designed for supporting fork/join based parallel
> > decomposition algorithms. It does that well via the work-stealing
> mechanisms
> > which reduce the task management overhead. It can only support other
> styles
> > of "parallel computation" with varying degrees of success.
> >
> > ThreadPoolExecutor is a plain old thread pool. It makes no assumptions
> about
> > the type or nature of tasks or their dependencies.
> >
> > Brian's summary is quite correct.
> >
> > Obviously the two are, within limits, interchangeable, but they operate
> in
> > completely different spots in the design space.
>
> Thanks for your reply, David. This reassures me that ...
> (1) my "vague" understanding of the differences between the two thread
>    pools was correct
> (2) you cannot draw a clear line between the two beyond the criteria
>    I had already named.
>
> - Regarding the implementation of ForkJoinPool, I have the impression
> that it has a global "entrance" task queue where the tasks submitted
> "from the outside" go, and one task queue per thread where the tasks
> generated "internally" (i.e. by the pool threads when executing tasks)
> go and where the stealing happens. If that is correct, then a
> ForkJoinPool whose tasks never generate child tasks would degenerate to
> a ThreadPoolExecutor, and perform no better (nor, which is my point
> here, any worse) than a ThreadPoolExecutor. Consequently, one could
> argue that you should always use a ForkJoinPool: If your tasks are
> actually fork/join tasks, then you get the benefit of ForkJoinPool,
> but if they are not (i.e. if they are completely independent),
> then you haven't lost anything compared using a ThreadPoolExecutor.
> So, always using a ForkJoinPool would make your program more
> flexible at no additional cost.
>
> Is this correct?
>
> Thanks for your opionion,
> Holger.
>
>
> >> -----Original Message-----
> >> From: concurrency-interest-bounces at cs.oswego.edu
> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Holger
> >> Peine
> >> Sent: Wednesday, 15 February 2012 1:57 AM
> >> To: concurrency-interest at cs.oswego.edu
> >> Subject: [concurrency-interest] What's the advantage of a Java-5
> >> ThreadPoolExecutor over a Java-7 ForkJoinPool?
> >>
> >>
> >> Dear colleagues,
> >>
> >> looking at their respective API, ForkJoinPool provides a superset of
> >> ThreadPoolExecutor's functionality in standard scenarios (though
> >> strictly speaking ThreadPoolExecutor offers more opportunities for
> >> tuning than ForkJoinPool). Adding to this the observation that fork/join
> >> tasks seem to be faster (possibly due to the work stealing scheduler),
> >> need definitely fewer threads (due to the non-blocking join operation),
> >> one might get the impression that ThreadPoolExecutor has been superseded
> >> by ForkJoinPool.
> >>
> >> But is this really correct? All the material I have read (the best
> >> being Brian Goetz's article
> >> http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
> >> official JDK API doc) seems to sum up to a rather vague distinction
> >> between the two types of thread pools:
> >> - ForkJoinPool is for many, dependent, task-generated, short, hardly
> >>   ever blocking (i.e. compute-intensive) tasks
> >> - ThreadPoolExecutor is for few, independent, externally-generated,
> >>   long, sometimes blocking tasks
> >>
> >> Is this distinction correct at all? Can we say anything more specific
> >> about this?
> >>
> >> Thanks for your opinion,
> >> Holger Peine
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120215/175e16e5/attachment.html>

From viktor.klang at gmail.com  Wed Feb 15 03:38:04 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 15 Feb 2012 09:38:04 +0100
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
Message-ID: <CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>

You guys should have a look at the latest post at letitcrash.com

Cheers,
?

On Wed, Feb 15, 2012 at 9:31 AM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:

> ThreadPoolExecutor provides a lot of different options for configuring the
> worker threads.  The Executors tool class provides convenience methods to
> create many of the useful configurations:
>
>
> http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/Executors.html
>
>
> The single-threaded variant, for example, is quite different from any
> ForkJoinPool.  The CachedThreadPool is more like a ForkJoinPool.
>
> It's difficult to manage multiple ForkJoinPools because each one will try
> to achieve maximum throughput, whereas the classic thread pools can
> designed to operate within limits.
>
> ThreadPoolExecutor also supports custom BlockingQueue implementations, and
> direct access to its queue.
>
> Joe
>
> On Tue, Feb 14, 2012 at 11:13 PM, Holger Peine wrote:
>
>> Am 14.02.2012 22:49, schrieb David Holmes:
>> > Holger,
>> >
>> > ForkJoinPool is designed for supporting fork/join based parallel
>> > decomposition algorithms. It does that well via the work-stealing
>> mechanisms
>> > which reduce the task management overhead. It can only support other
>> styles
>> > of "parallel computation" with varying degrees of success.
>> >
>> > ThreadPoolExecutor is a plain old thread pool. It makes no assumptions
>> about
>> > the type or nature of tasks or their dependencies.
>> >
>> > Brian's summary is quite correct.
>> >
>> > Obviously the two are, within limits, interchangeable, but they operate
>> in
>> > completely different spots in the design space.
>>
>> Thanks for your reply, David. This reassures me that ...
>> (1) my "vague" understanding of the differences between the two thread
>>    pools was correct
>> (2) you cannot draw a clear line between the two beyond the criteria
>>    I had already named.
>>
>> - Regarding the implementation of ForkJoinPool, I have the impression
>> that it has a global "entrance" task queue where the tasks submitted
>> "from the outside" go, and one task queue per thread where the tasks
>> generated "internally" (i.e. by the pool threads when executing tasks)
>> go and where the stealing happens. If that is correct, then a
>> ForkJoinPool whose tasks never generate child tasks would degenerate to
>> a ThreadPoolExecutor, and perform no better (nor, which is my point
>> here, any worse) than a ThreadPoolExecutor. Consequently, one could
>> argue that you should always use a ForkJoinPool: If your tasks are
>> actually fork/join tasks, then you get the benefit of ForkJoinPool,
>> but if they are not (i.e. if they are completely independent),
>> then you haven't lost anything compared using a ThreadPoolExecutor.
>> So, always using a ForkJoinPool would make your program more
>> flexible at no additional cost.
>>
>> Is this correct?
>>
>> Thanks for your opionion,
>> Holger.
>>
>>
>> >> -----Original Message-----
>> >> From: concurrency-interest-bounces at cs.oswego.edu
>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Holger
>> >> Peine
>> >> Sent: Wednesday, 15 February 2012 1:57 AM
>> >> To: concurrency-interest at cs.oswego.edu
>> >> Subject: [concurrency-interest] What's the advantage of a Java-5
>> >> ThreadPoolExecutor over a Java-7 ForkJoinPool?
>> >>
>> >>
>> >> Dear colleagues,
>> >>
>> >> looking at their respective API, ForkJoinPool provides a superset of
>> >> ThreadPoolExecutor's functionality in standard scenarios (though
>> >> strictly speaking ThreadPoolExecutor offers more opportunities for
>> >> tuning than ForkJoinPool). Adding to this the observation that
>> fork/join
>> >> tasks seem to be faster (possibly due to the work stealing scheduler),
>> >> need definitely fewer threads (due to the non-blocking join operation),
>> >> one might get the impression that ThreadPoolExecutor has been
>> superseded
>> >> by ForkJoinPool.
>> >>
>> >> But is this really correct? All the material I have read (the best
>> >> being Brian Goetz's article
>> >> http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
>> >> official JDK API doc) seems to sum up to a rather vague distinction
>> >> between the two types of thread pools:
>> >> - ForkJoinPool is for many, dependent, task-generated, short, hardly
>> >>   ever blocking (i.e. compute-intensive) tasks
>> >> - ThreadPoolExecutor is for few, independent, externally-generated,
>> >>   long, sometimes blocking tasks
>> >>
>> >> Is this distinction correct at all? Can we say anything more specific
>> >> about this?
>> >>
>> >> Thanks for your opinion,
>> >> Holger Peine
>> >
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120215/3afe89b3/attachment-0001.html>

From Holger.Peine at fh-hannover.de  Wed Feb 15 03:48:45 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 09:48:45 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <CACyP5Pdv+pxhhixNZ6+BMxSZH4SmQDHi0cXvfT8ML-9AAm8hCQ@mail.gmail.com>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
	<4F3B57B5.9080301@fh-hannover.de>
	<CACyP5Pdv+pxhhixNZ6+BMxSZH4SmQDHi0cXvfT8ML-9AAm8hCQ@mail.gmail.com>
Message-ID: <4F3B716D.6070601@fh-hannover.de>

Am 15.02.2012 09:26, schrieb Christian Vest Hansen:
> 
> On Wed, Feb 15, 2012 at 07:59, Holger Peine <Holger.Peine at fh-hannover.de
> <mailto:Holger.Peine at fh-hannover.de>> wrote:
> 
>     Am 14.02.2012 20:46, schrieb Boehm, Hans:
>     > - If only v is volatile, then x = 1; v = 1; z = 1 does not ensure
>     > that the write to x becomes visible before the write to z.
> 
>     The JMM does ensure that the write to x becomes visible together with
>     the write to v, and that was the original poster's (Talip Ozturk)
>     question.
> 
>     What happens to z is another question: The JMM only guarantees that it
>     will not become visible before the write to x or v (since it
>     happens-after the x and v writes).
> 
> 
> Does it? Why is it prevented from re-ordering the write to z up before
> the write to v, and indeed even before the write to x?

Because the three writes happen in the same thread, which establishes
a happens-before relation between them in the order of their appearance
in the source code ("program order").

Source of reference: "The Java Memory Model" by Pugh/Manson/Adve
POPL?05, January 12?14, 2005, Long Beach, California, USA.
http://www.google.de/url?sa=t&rct=j&q=java%20memory%20model&source=web&cd=4&ved=0CEgQFjAD&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.78.1977%26rep%3Drep1%26type%3Dpdf&ei=cW07T_6OFM7jtQbLqNHRBg&usg=AFQjCNEJWmr7bPSaZVK6Hy_0XtVxWm3A7g&cad=rja
as it says the following:
"Happens-before is the transitive closure of program order
and the synchronizes-with order", i.e. happens-before includes
program order.

Regards,
Holger.

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From davidcholmes at aapt.net.au  Wed Feb 15 04:18:21 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 15 Feb 2012 19:18:21 +1000
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3B716D.6070601@fh-hannover.de>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEBHJDAA.davidcholmes@aapt.net.au>

Holger Peine writes:
> Am 15.02.2012 09:26, schrieb Christian Vest Hansen:
> > 
> > On Wed, Feb 15, 2012 at 07:59, Holger Peine <Holger.Peine at fh-hannover.de
> > <mailto:Holger.Peine at fh-hannover.de>> wrote:
> > 
> >     Am 14.02.2012 20:46, schrieb Boehm, Hans:
> >     > - If only v is volatile, then x = 1; v = 1; z = 1 does not ensure
> >     > that the write to x becomes visible before the write to z.
> > 
> >     The JMM does ensure that the write to x becomes visible 
> together with
> >     the write to v, and that was the original poster's (Talip Ozturk)
> >     question.
> > 
> >     What happens to z is another question: The JMM only 
> guarantees that it
> >     will not become visible before the write to x or v (since it
> >     happens-after the x and v writes).
> > 
> > 
> > Does it? Why is it prevented from re-ordering the write to z up before
> > the write to v, and indeed even before the write to x?
> 
> Because the three writes happen in the same thread, which establishes
> a happens-before relation between them in the order of their appearance
> in the source code ("program order").

Not quite. Christian is correct. The thread that does the writes must not be able to detect them out of order but other threads can. The volatile write has release semantics which allows other accesses to be moved prior to the volatile write. ("roach motel" semantics)

David Holmes
------------
 
> Source of reference: "The Java Memory Model" by Pugh/Manson/Adve
> POPL?05, January 12?14, 2005, Long Beach, California, USA.
> http://www.google.de/url?sa=t&rct=j&q=java%20memory%20model&source
=web&cd=4&ved=0CEgQFjAD&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.78.1977%26rep%3Drep1%26type%3Dpdf&ei=cW07T_6OFM7jtQbLqNHRBg&usg=AFQjCNEJWmr7bPSaZVK6Hy_0XtVxWm3A7g&cad=rja
as it says the following:
"Happens-before is the transitive closure of program order
and the synchronizes-with order", i.e. happens-before includes
program order.

Regards,
Holger.

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From Holger.Peine at fh-hannover.de  Wed Feb 15 04:29:53 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 10:29:53 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEBHJDAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIEBHJDAA.davidcholmes@aapt.net.au>
Message-ID: <4F3B7B11.6040704@fh-hannover.de>

Am 15.02.2012 10:18, schrieb David Holmes:
> Holger Peine writes:
>> Am 15.02.2012 09:26, schrieb Christian Vest Hansen:
>>>
>>> On Wed, Feb 15, 2012 at 07:59, Holger Peine <Holger.Peine at fh-hannover.de
>>> <mailto:Holger.Peine at fh-hannover.de>> wrote:
>>>
>>>     Am 14.02.2012 20:46, schrieb Boehm, Hans:
>>>     > - If only v is volatile, then x = 1; v = 1; z = 1 does not ensure
>>>     > that the write to x becomes visible before the write to z.
>>>
>>>     The JMM does ensure that the write to x becomes visible 
>> together with
>>>     the write to v, and that was the original poster's (Talip Ozturk)
>>>     question.
>>>
>>>     What happens to z is another question: The JMM only 
>> guarantees that it
>>>     will not become visible before the write to x or v (since it
>>>     happens-after the x and v writes).
>>>
>>>
>>> Does it? Why is it prevented from re-ordering the write to z up before
>>> the write to v, and indeed even before the write to x?
>>
>> Because the three writes happen in the same thread, which establishes
>> a happens-before relation between them in the order of their appearance
>> in the source code ("program order").
> 
> Not quite. Christian is correct. The thread that does the writes must not be able to detect them out of order but other threads can. 

OK - apparently my understanding of the JMM is incorrect at this point
(at least). David, I hope that my first statement above ("The JMM does
ensure that the write to x becomes visible together with the write to
v") is correct nevertheless?

Concerned,
Holger.

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From Holger.Peine at fh-hannover.de  Wed Feb 15 04:33:35 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 10:33:35 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3B57B5.9080301@fh-hannover.de>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
	<4F3B57B5.9080301@fh-hannover.de>
Message-ID: <4F3B7BEF.4080200@fh-hannover.de>

Am 15.02.2012 07:59, schrieb Holger Peine:
> What happens to z is another question: The JMM only guarantees that it
> will not become visible before the write to x or v (since it
> happens-after the x and v writes). It may never become visible at all.
> It it becomes visible, however, then that will be after (or at the same
> time as) the writes to x and v (since any other ordering would violate
> the happens-before relation). So your above statement about z is
> technically correct (since it may never become visible at all), but
> somewhat misleading (since it cannot be become visible before x and v).

I'd like to retract this statement, to prevent creating further
confusion.

Sorry,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From Holger.Peine at fh-hannover.de  Wed Feb 15 05:04:53 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 11:04:53 +0100
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
Message-ID: <4F3B8345.4040008@fh-hannover.de>

Am 15.02.2012 09:38, schrieb ?iktor ?lang:
> You guys should have a look at the latest post at letitcrash.com
> <http://letitcrash.com>

This blog post shows an example that ForkJoinPool (in particular,
the latest implementation of it, which is not yet in the JDK) is
faster then ThreadPoolExecutor when you have many small tasks,
because the single queue in ThreadPoolExecutor is heavily contended
then, in contrast to the many queues in ForkJoinPool.

This is not surprising and in fact perfectly matches what I had
summarized as criteria for choosing between ForkJoinPool and
ThreadPoolExecutor. My question, on the other hand, was this:
"What advantages of ThreadPoolExecutor are left?". The blog post
rather seems to support my provocative suggestion (which I still
feel is not correct) that ForkJoinPool is a kind of "better
ThreadPoolExecutor".

Regards,
Holger.

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From davidcholmes at aapt.net.au  Wed Feb 15 05:25:39 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 15 Feb 2012 20:25:39 +1000
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3B7B11.6040704@fh-hannover.de>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEBIJDAA.davidcholmes@aapt.net.au>

Holger Peine writes:
> Am 15.02.2012 10:18, schrieb David Holmes:
> > Holger Peine writes:
> >> Am 15.02.2012 09:26, schrieb Christian Vest Hansen:
> >>>
> >>> On Wed, Feb 15, 2012 at 07:59, Holger Peine 
> <Holger.Peine at fh-hannover.de
> >>> <mailto:Holger.Peine at fh-hannover.de>> wrote:
> >>>
> >>>     Am 14.02.2012 20:46, schrieb Boehm, Hans:
> >>>     > - If only v is volatile, then x = 1; v = 1; z = 1 does 
> not ensure
> >>>     > that the write to x becomes visible before the write to z.
> >>>
> >>>     The JMM does ensure that the write to x becomes visible 
> >> together with
> >>>     the write to v, and that was the original poster's (Talip Ozturk)
> >>>     question.
> >>>
> >>>     What happens to z is another question: The JMM only 
> >> guarantees that it
> >>>     will not become visible before the write to x or v (since it
> >>>     happens-after the x and v writes).
> >>>
> >>>
> >>> Does it? Why is it prevented from re-ordering the write to z up before
> >>> the write to v, and indeed even before the write to x?
> >>
> >> Because the three writes happen in the same thread, which establishes
> >> a happens-before relation between them in the order of their appearance
> >> in the source code ("program order").
> > 
> > Not quite. Christian is correct. The thread that does the 
> writes must not be able to detect them out of order but other 
> threads can. 
> 
> OK - apparently my understanding of the JMM is incorrect at this point
> (at least). David, I hope that my first statement above ("The JMM does
> ensure that the write to x becomes visible together with the write to
> v") is correct nevertheless?

Well the write to x can be visible before the write to y. The happens-before relationship ensures that if you see the write to y then you must see the write to x.

David
 
> Concerned,
> Holger.
> 
> -- 
> Prof. Dr. Holger Peine
> Hochschule Hannover, Fakult?t IV, Abt. Informatik
> Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
> Ricklinger Stadtweg 120, D-30459 Hannover, Germany
> 



From Holger.Peine at fh-hannover.de  Wed Feb 15 05:30:48 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Wed, 15 Feb 2012 11:30:48 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEBIJDAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEBIJDAA.davidcholmes@aapt.net.au>
Message-ID: <4F3B8958.6020502@fh-hannover.de>

Am 15.02.2012 11:25, schrieb David Holmes:
> Holger Peine writes:
>> Am 15.02.2012 10:18, schrieb David Holmes:
>>> Holger Peine writes:
>>>> Am 15.02.2012 09:26, schrieb Christian Vest Hansen:
>>>>>
>>>>> On Wed, Feb 15, 2012 at 07:59, Holger Peine 
>> <Holger.Peine at fh-hannover.de
>>>>> <mailto:Holger.Peine at fh-hannover.de>> wrote:
>>>>>
>>>>>     Am 14.02.2012 20:46, schrieb Boehm, Hans:
>>>>>     > - If only v is volatile, then x = 1; v = 1; z = 1 does 
>> not ensure
>>>>>     > that the write to x becomes visible before the write to z.
>>>>>
>>>>>     The JMM does ensure that the write to x becomes visible 
>>>> together with
>>>>>     the write to v, and that was the original poster's (Talip Ozturk)
>>>>>     question.
>>>>>
>> David, I hope that my first statement above ("The JMM does
>> ensure that the write to x becomes visible together with the write to
>> v") is correct nevertheless?
> 
> Well the write to x can be visible before the write to y. The happens-before relationship ensures that if you see the write to y then you must see the write to x.

There was no y in the example - but substituting v for y (as I
hope you had intended), I fully agree.

Regards,
Holger.

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From joe.bowbeer at gmail.com  Wed Feb 15 07:17:34 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 15 Feb 2012 04:17:34 -0800
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
Message-ID: <CAHzJPEo_D31ZZ+JNcM54Dr4qzXsoDzT2EGhnNqWRBn-arU-=_Q@mail.gmail.com>

2012/2/15 ?iktor ?lang

> You guys should have a look at the latest post at letitcrash.com


Cool.  I also recommend Doug's paper:

http://gee.cs.oswego.edu/dl/papers/fj.pdf

and I think this interview is informative:

http://www.infoq.com/interviews/doug-lea-fork-join

Joe


> On Wed, Feb 15, 2012 at 9:31 AM, Joe Bowbeer wrote:
>
>> ThreadPoolExecutor provides a lot of different options for configuring
>> the worker threads.  The Executors tool class provides convenience methods
>> to create many of the useful configurations:
>>
>>
>> http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/Executors.html
>>
>>
>> The single-threaded variant, for example, is quite different from any
>> ForkJoinPool.  The CachedThreadPool is more like a ForkJoinPool.
>>
>> It's difficult to manage multiple ForkJoinPools because each one will try
>> to achieve maximum throughput, whereas the classic thread pools [are]
>> designed to operate within limits.
>>
>> ThreadPoolExecutor also supports custom BlockingQueue implementations,
>> and direct access to its queue.
>>
>> Joe
>>
>> On Tue, Feb 14, 2012 at 11:13 PM, Holger Peine wrote:
>>
>>> Am 14.02.2012 22:49, schrieb David Holmes:
>>> > Holger,
>>> >
>>> > ForkJoinPool is designed for supporting fork/join based parallel
>>> > decomposition algorithms. It does that well via the work-stealing
>>> mechanisms
>>> > which reduce the task management overhead. It can only support other
>>> styles
>>> > of "parallel computation" with varying degrees of success.
>>> >
>>> > ThreadPoolExecutor is a plain old thread pool. It makes no assumptions
>>> about
>>> > the type or nature of tasks or their dependencies.
>>> >
>>> > Brian's summary is quite correct.
>>> >
>>> > Obviously the two are, within limits, interchangeable, but they
>>> operate in
>>> > completely different spots in the design space.
>>>
>>> Thanks for your reply, David. This reassures me that ...
>>> (1) my "vague" understanding of the differences between the two thread
>>>    pools was correct
>>> (2) you cannot draw a clear line between the two beyond the criteria
>>>    I had already named.
>>>
>>> - Regarding the implementation of ForkJoinPool, I have the impression
>>> that it has a global "entrance" task queue where the tasks submitted
>>> "from the outside" go, and one task queue per thread where the tasks
>>> generated "internally" (i.e. by the pool threads when executing tasks)
>>> go and where the stealing happens. If that is correct, then a
>>> ForkJoinPool whose tasks never generate child tasks would degenerate to
>>> a ThreadPoolExecutor, and perform no better (nor, which is my point
>>> here, any worse) than a ThreadPoolExecutor. Consequently, one could
>>> argue that you should always use a ForkJoinPool: If your tasks are
>>> actually fork/join tasks, then you get the benefit of ForkJoinPool,
>>> but if they are not (i.e. if they are completely independent),
>>> then you haven't lost anything compared using a ThreadPoolExecutor.
>>> So, always using a ForkJoinPool would make your program more
>>> flexible at no additional cost.
>>>
>>> Is this correct?
>>>
>>> Thanks for your opionion,
>>> Holger.
>>>
>>>
>>> >> -----Original Message-----
>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>> Holger
>>> >> Peine
>>> >> Sent: Wednesday, 15 February 2012 1:57 AM
>>> >> To: concurrency-interest at cs.oswego.edu
>>> >> Subject: [concurrency-interest] What's the advantage of a Java-5
>>> >> ThreadPoolExecutor over a Java-7 ForkJoinPool?
>>> >>
>>> >>
>>> >> Dear colleagues,
>>> >>
>>> >> looking at their respective API, ForkJoinPool provides a superset of
>>> >> ThreadPoolExecutor's functionality in standard scenarios (though
>>> >> strictly speaking ThreadPoolExecutor offers more opportunities for
>>> >> tuning than ForkJoinPool). Adding to this the observation that
>>> fork/join
>>> >> tasks seem to be faster (possibly due to the work stealing scheduler),
>>> >> need definitely fewer threads (due to the non-blocking join
>>> operation),
>>> >> one might get the impression that ThreadPoolExecutor has been
>>> superseded
>>> >> by ForkJoinPool.
>>> >>
>>> >> But is this really correct? All the material I have read (the best
>>> >> being Brian Goetz's article
>>> >> http://www.ibm.com/developerworks/java/library/j-jtp11137 and the
>>> >> official JDK API doc) seems to sum up to a rather vague distinction
>>> >> between the two types of thread pools:
>>> >> - ForkJoinPool is for many, dependent, task-generated, short, hardly
>>> >>   ever blocking (i.e. compute-intensive) tasks
>>> >> - ThreadPoolExecutor is for few, independent, externally-generated,
>>> >>   long, sometimes blocking tasks
>>> >>
>>> >> Is this distinction correct at all? Can we say anything more specific
>>> >> about this?
>>> >>
>>> >> Thanks for your opinion,
>>> >> Holger Peine
>>> >
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120215/32e75d1a/attachment.html>

From cheremin at gmail.com  Wed Feb 15 10:00:59 2012
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 15 Feb 2012 19:00:59 +0400
Subject: [concurrency-interest] File object is not immutable?
Message-ID: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>

I was very surprised to see that field "path" in java.io.File is not
final. I was treating File object in concurrency area is something
like String --  fully immutable, and completely thread-safe, even
data-race safe.

Am I right supposing that File object is _not_ thread safe by itself
(as String does), and it is programmer's responsibility to safe
publish it between threads? Or may be it is some kind of hidden magic,
which makes File safe, even without explicit final? I mean, there is
native calls to FileSystem in constructor and deserialization, which
can create membars implictly...


----
Cheremin Ruslan

From forax at univ-mlv.fr  Wed Feb 15 12:14:25 2012
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Wed, 15 Feb 2012 18:14:25 +0100
Subject: [concurrency-interest] File object is not immutable?
In-Reply-To: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>
References: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>
Message-ID: <4F3BE7F1.3010300@univ-mlv.fr>

On 02/15/2012 04:00 PM, Ruslan Cheremin wrote:
> I was very surprised to see that field "path" in java.io.File is not
> final. I was treating File object in concurrency area is something
> like String --  fully immutable, and completely thread-safe, even
> data-race safe.
>
> Am I right supposing that File object is _not_ thread safe by itself
> (as String does), and it is programmer's responsibility to safe
> publish it between threads? Or may be it is some kind of hidden magic,
> which makes File safe, even without explicit final? I mean, there is
> native calls to FileSystem in constructor and deserialization, which
> can create membars implictly...

The javadoc says File is immutable so it's a bug :(
There is no guarantee that the fs object will do a memory barrier.

I think path is not final because of the serialization code but
it should be final and the seralization code should use
reflection or sun.misc.Unsafe.

I've put Alan Bateman in CC because I don't know if java.io.File is
managed by the core team or the nio one.

>
>
> ----
> Cheremin Ruslan

cheers,
R?mi


From stanimir at riflexo.com  Wed Feb 15 14:33:20 2012
From: stanimir at riflexo.com (bestsss)
Date: Wed, 15 Feb 2012 11:33:20 -0800 (PST)
Subject: [concurrency-interest] File object is not immutable?
In-Reply-To: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>
References: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>
Message-ID: <33331282.post@talk.nabble.com>




Ruslan Cheremin wrote:
> 
> I mean, there is
> native calls to FileSystem in constructor and deserialization, which
> can create membars implictly...
> 
> ----
> Cheremin Ruslan
> 

It'd not matter as the assignment is performed after the calls to fs, i.e.
this.prefixLength = fs.prefixLength(this.path);

Also java.io.File can be subclassed (and it is), so even if the java.io.File
is safe for publishing, nothing can be said about the subclasses. Hence I'd
assume, unless safe published it's not "safe".

-- 
View this message in context: http://old.nabble.com/File-object-is-not-immutable--tp33329436p33331282.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.


From hans.boehm at hp.com  Wed Feb 15 15:04:37 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 15 Feb 2012 20:04:37 +0000
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <4F3B57B5.9080301@fh-hannover.de>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
	<4F3B57B5.9080301@fh-hannover.de>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD23275C71B@G4W3299.americas.hpqcorp.net>

> From: Holger Peine
> Sent: Tuesday, February 14, 2012 10:59 PM
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] volatile guarantee for directbuffer
> 
> Am 14.02.2012 20:46, schrieb Boehm, Hans:
> >> From: Holger Peine
> [Earlier discussion was correctly resolved.]

> Your later statement that "the fence after a volatile
> store ... It's there only to order the volatile
> store with respect to a possible subsequent volatile load."
> sounds like what was true in Java prior to Java 5. Since Java 5,
> however, volatile stores do impose an ordering not only regarding
> other volatile accesses, but also regarding non-volatile accesses
> that happened-before the volatile store.
Definitely.  But on x86 the required ordering with respect to non-volatile operations is already ensured by the TSO memory model for ordinary loads and stores, at least if the compiler does nothing to violate it.  Earlier memory operations can't be reordered with respect to a store, and later operations can't be reordered with respect to a load.  That's actually enough to make your original example work.

Even on architectures where this is not automatically ensured, you'd need a fence BEFORE a volatile store, not after, to enforce the ordering required for your example.

The fence AFTER a volatile store is there to make things like the Dekker's example work: (v, w both volatile, initially zero, r1 and r2 are local)

Thread 1:
x = 1;
r1 = y;

Thread 2:
y = 1;
r2 = x;

Volatiles guarantee sequential consistency, so r1 = r2 = 0 must be impossible.  But on x86, a store followed by a load can effectively be reordered.  So you need a fence.

There is an argument that the hardware-software interface here could stand improvement, since the fences following volatile stores rarely actually order anything important, but do severely constrain the hardware in preventing reordering that doesn't matter.  And some architectures are beginning to redesign this interface.

Hans

> 
> - At least that's how I understand the JMM. I'd be eager to hear that
> I've been wrong all the time.
> 
> Regards,
> Holger Peine
> 
> --
> Prof. Dr. Holger Peine
> Hochschule Hannover, Fakult?t IV, Abt. Informatik
> Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
> Ricklinger Stadtweg 120, D-30459 Hannover, Germany
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From cheremin at gmail.com  Wed Feb 15 15:07:34 2012
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 15 Feb 2012 23:07:34 +0300
Subject: [concurrency-interest] File object is not immutable?
In-Reply-To: <4F3BCDA0.40701@oracle.com>
References: <CAOwENiK91bvU4Y373ggEf50by=W32+wo8vyBmPaTzBguguFY+w@mail.gmail.com>
	<4F3BCDA0.40701@oracle.com>
Message-ID: <CAOwENiJ3vAS=vuyfS_dnNd7OCwO3MVYQq9EBfyR3vG=Ot5KR1w@mail.gmail.com>

You mean I should CC core-libs-dev at openjdk.java.net ?

2012/2/15 Alan Bateman <Alan.Bateman at oracle.com>:
> On 15/02/2012 15:00, Ruslan Cheremin wrote:
>>
>> I was very surprised to see that field "path" in java.io.File is not
>> final. I was treating File object in concurrency area is something
>> like String -- ?fully immutable, and completely thread-safe, even
>> data-race safe.
>>
> It probably wasn't made final because of serialization. It's something to
> bring up on core-libs-dev.
>
> -Alan


From Holger.Peine at fh-hannover.de  Thu Feb 16 02:35:55 2012
From: Holger.Peine at fh-hannover.de (Holger Peine)
Date: Thu, 16 Feb 2012 08:35:55 +0100
Subject: [concurrency-interest] volatile guarantee for directbuffer
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD23275C71B@G4W3299.americas.hpqcorp.net>
References: <CANGYBVHWw+bGJP7hmKsToN+4_LC8_Ko5Fgd2_JFT5m9G1hxbeg@mail.gmail.com>
	<4F3A8391.5090904@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275BFD6@G4W3299.americas.hpqcorp.net>
	<4F3B57B5.9080301@fh-hannover.de>
	<A3E67C2071F49C4CBC4F17E6D77CDDD23275C71B@G4W3299.americas.hpqcorp.net>
Message-ID: <4F3CB1DB.8000809@fh-hannover.de>

Am 15.02.2012 21:04, schrieb Boehm, Hans:
> But on x86 the required ordering with respect to non-volatile operations is already ensured by the TSO memory model for ordinary loads and stores, at least if the compiler does nothing to violate it.  Earlier memory operations can't be reordered with respect to a store, and later operations can't be reordered with respect to a load.  That's actually enough to make your original example work.
> 
> Even on architectures where this is not automatically ensured, you'd need a fence BEFORE a volatile store, not after, to enforce the ordering required for your example.
> 
> The fence AFTER a volatile store is there to make things like the Dekker's example work: (v, w both volatile, initially zero, r1 and r2 are local)
> 
> Thread 1:
> x = 1;
> r1 = y;
> 
> Thread 2:
> y = 1;
> r2 = x;
> 
> Volatiles guarantee sequential consistency, so r1 = r2 = 0 must be impossible.  But on x86, a store followed by a load can effectively be reordered.  So you need a fence.

Agreed - discussion resolved, I think.

> There is an argument that the hardware-software interface here could stand improvement, since the fences following volatile stores rarely actually order anything important, but do severely constrain the hardware in preventing reordering that doesn't matter.  And some architectures are beginning to redesign this interface.

Interesting point (and news to me), but taking us too far here, I think.

Regards,
Holger Peine

-- 
Prof. Dr. Holger Peine
Hochschule Hannover, Fakult?t IV, Abt. Informatik
Tel: +49(511)9296-1830  Fax: -1810 (shared, please state my name)
Ricklinger Stadtweg 120, D-30459 Hannover, Germany

From radhakrishnan.mohan at gmail.com  Thu Feb 16 07:06:34 2012
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 16 Feb 2012 17:36:34 +0530
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
Message-ID: <CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>

Does the first point in
http://cs.oswego.edu/pipermail/concurrency-interest/2012-January/008987.html

mean that now I can submit independent tasks to the FJ framework
without the need for
a task and subtask graph and still get the benefits of work stealing ?

I am trying to apply this to a streaming financial message handler.
Have I understood this wrongly ? Any code snippet that demonstrates
this ? Should I check Akka source ?

Mohan

2012/2/15 ?iktor ?lang <viktor.klang at gmail.com>:
> You guys should have a look at the latest post at letitcrash.com
>
> Cheers,
> ?
>


From viktor.klang at gmail.com  Thu Feb 16 07:18:30 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 16 Feb 2012 13:18:30 +0100
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
Message-ID: <CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>

On Thu, Feb 16, 2012 at 1:06 PM, Mohan Radhakrishnan
<radhakrishnan.mohan at gmail.com> wrote:
> Does the first point in
> http://cs.oswego.edu/pipermail/concurrency-interest/2012-January/008987.html
>
> mean that now I can submit independent tasks to the FJ framework
> without the need for
> a task and subtask graph and still get the benefits of work stealing ?

Yes

>
> I am trying to apply this to a streaming financial message handler.
> Have I understood this wrongly ? Any code snippet that demonstrates
> this ? Should I check Akka source ?

We're not doing any magic, we just embedded the new code under a
modified package name so it doesn't clash with JDK7 and then replaced
the lookup for Unsafe so it works on Android. That's it.

Doug is a genius.

Cheers,
?

>
> Mohan
>
> 2012/2/15 ?iktor ?lang <viktor.klang at gmail.com>:
>> You guys should have a look at the latest post at letitcrash.com
>>
>> Cheers,
>> ?
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-- 
Viktor Klang

Akka Tech Lead
Typesafe?- The software stack for applications that scale

Twitter: @viktorklang


From adrian.tarau at gmail.com  Thu Feb 16 09:42:54 2012
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Thu, 16 Feb 2012 09:42:54 -0500
Subject: [concurrency-interest] Bug in  ConcurrentHashMap keyset iterator?
In-Reply-To: <CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>	<4F3B5B0C.9020205@fh-hannover.de>	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
Message-ID: <4F3D15EE.3050702@gmail.com>

Good morning,

I get recently several failures in one of the processes(a remote file 
collector) which looks like a bug in ConcurrentHashMap implementation. I 
attached all relevant code...I do not think I misused the map but... I 
searched for similar complaints but I couldn't find anything relevant - 
bugs.sun.com returns noting when searching for "ConcurrentHashMap 
ArrayIndexOutOfBoundsException".

Thank you,
Adrian Tarau.

I have a map declared like this:

/private final Map<Location, PriorityBlockingQueue<WorkUnit>> 
workUnitsPerLocation = new ConcurrentHashMap<Location, 
PriorityBlockingQueue<WorkUnit>>();/

a work unit is pushed like this:

......
Queue<WorkUnit> locationQueue = getLocationQueue(location);
boolean offer = locationQueue.offer(workUnit);
.......
private Queue<WorkUnit> getLocationQueue(Location location) {
         synchronized (workUnitsPerLocation) {
             PriorityBlockingQueue<WorkUnit> queue = 
workUnitsPerLocation.get(location);
             if (queue == null) {
                 queue = new PriorityBlockingQueue<WorkUnit>(100, new 
WorkUnit.Comparator());
                 workUnitsPerLocation.put(location, queue);
             }
             return queue;
         }
     }

and a working thread(scheduled to run every 5 seconds) is scanning for 
available work units, peeking one from every location(until a maximum 
number of working units are running) like this:

/class WorkUnitScheduler extends AbstractWorker {

         ...
         // volatile since the state of the iterator must be preserved 
under different working threads
         private volatile Iterator<Location> workUnitsIterator;

         ....

         private Queue<WorkUnit> getNextQueue() {
             for (int i = 0; i < 2; i++) {// loop twice so we go over 
all possible locations
                 if (workUnitsIterator == null || 
!workUnitsIterator.hasNext()) {
                     workUnitsIterator = 
workUnitsPerLocation.keySet().iterator();//start from beginning
                 }
                 while (workUnitsIterator.hasNext()) {
                     try {
                         Location location = workUnitsIterator.next(); 
*<--- fails here*
                         if (canScheduleFromLocation(location)) {//if 
allowed, get next working unit from this location
                             return workUnitsPerLocation.get(location);
                         }
                     } catch (NoSuchElementException e) {
                         // no location
                     }
                 }
             }
             return null;
         }

         @Override
         protected void doRun() {
                  ....
                 Queue<WorkUnit> queue = getNextQueue();
                 if (queue == null) {
                     break;
                 }
                 WorkUnit workingUnit = queue.poll();
                 if (workingUnit == null) {
                     continue;
                 }
                 WorkerService.getInstance().schedule(new 
DownloadUploadWorker(workingUnit));
                 ....
         }
     }/

and it fails with:

/got exception java.lang.ArrayIndexOutOfBoundsException: 3
      at 
java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
      at 
java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
      at 
java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)/

it fails here(ConcurrentHashMap implementation fragment):

/final void advance() {
             if (nextEntry != null && (nextEntry = nextEntry.next) != null)
                 return;

             while (nextTableIndex >= 0) {
                 if ( (nextEntry = currentTable[nextTableIndex--]) != null)
                     return;
             }

             while (nextSegmentIndex >= 0) {
                 Segment<K,V> seg = segments[nextSegmentIndex--];
                 if (seg.count != 0) {
                     currentTable = seg.table;
                     for (int j = currentTable.length - 1; j >= 0; --j) {
                         if ( (nextEntry = currentTable[j]) != null) 
{*<-- failure*
                             nextTableIndex = j - 1;
                             return;
                         }
                     }
                 }
             }
         }/

JVM info:

/java version "1.6.0_30"
Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/0d514eb0/attachment-0001.html>

From vitalyd at gmail.com  Thu Feb 16 10:26:10 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 16 Feb 2012 10:26:10 -0500
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <4F3D15EE.3050702@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
Message-ID: <CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>

Are you sharing the same iterator between multiple threads? That's what it
sounds like - you can't do that as they aren't threadsafe.

Sent from my phone
On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:

> **
> Good morning,
>
> I get recently several failures in one of the processes(a remote file
> collector) which looks like a bug in ConcurrentHashMap implementation. I
> attached all relevant code...I do not think I misused the map but... I
> searched for similar complaints but I couldn't find anything relevant -
> bugs.sun.com returns noting when searching for "ConcurrentHashMap
> ArrayIndexOutOfBoundsException".
>
> Thank you,
> Adrian Tarau.
>
> I have a map declared like this:
>
> *private final Map<Location, PriorityBlockingQueue<WorkUnit>>
> workUnitsPerLocation = new ConcurrentHashMap<Location,
> PriorityBlockingQueue<WorkUnit>>();*
>
> a work unit is pushed like this:
>
> ......
> Queue<WorkUnit> locationQueue = getLocationQueue(location);
> boolean offer = locationQueue.offer(workUnit);
> .......
> private Queue<WorkUnit> getLocationQueue(Location location) {
>         synchronized (workUnitsPerLocation) {
>             PriorityBlockingQueue<WorkUnit> queue =
> workUnitsPerLocation.get(location);
>             if (queue == null) {
>                 queue = new PriorityBlockingQueue<WorkUnit>(100, new
> WorkUnit.Comparator());
>                 workUnitsPerLocation.put(location, queue);
>             }
>             return queue;
>         }
>     }
>
> and a working thread(scheduled to run every 5 seconds) is scanning for
> available work units, peeking one from every location(until a maximum
> number of working units are running) like this:
>
> *class WorkUnitScheduler extends AbstractWorker {
>
>         ...
>         // volatile since the state of the iterator must be preserved
> under different working threads
>         private volatile Iterator<Location> workUnitsIterator;
>
>         ....
>
>         private Queue<WorkUnit> getNextQueue() {
>             for (int i = 0; i < 2; i++) {// loop twice so we go over all
> possible locations
>                 if (workUnitsIterator == null ||
> !workUnitsIterator.hasNext()) {
>                     workUnitsIterator =
> workUnitsPerLocation.keySet().iterator();//start from beginning
>                 }
>                 while (workUnitsIterator.hasNext()) {
>                     try {
>                         Location location = workUnitsIterator.next(); <---
> fails here
>                         if (canScheduleFromLocation(location)) {//if
> allowed, get next working unit from this location
>                             return workUnitsPerLocation.get(location);
>                         }
>                     } catch (NoSuchElementException e) {
>                         // no location
>                     }
>                 }
>             }
>             return null;
>         }
>
>         @Override
>         protected void doRun() {
>                  ....
>                 Queue<WorkUnit> queue = getNextQueue();
>                 if (queue == null) {
>                     break;
>                 }
>                 WorkUnit workingUnit = queue.poll();
>                 if (workingUnit == null) {
>                     continue;
>                 }
>                 WorkerService.getInstance().schedule(new
> DownloadUploadWorker(workingUnit));
>                 ....
>         }
>     }*
>
> and it fails with:
>
> *got exception java.lang.ArrayIndexOutOfBoundsException: 3
>      at
> java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>      at
> java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>      at
> java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)
> *
>
> it fails here(ConcurrentHashMap implementation fragment):
>
> *final void advance() {
>             if (nextEntry != null && (nextEntry = nextEntry.next) != null)
>                 return;
>
>             while (nextTableIndex >= 0) {
>                 if ( (nextEntry = currentTable[nextTableIndex--]) != null)
>                     return;
>             }
>
>             while (nextSegmentIndex >= 0) {
>                 Segment<K,V> seg = segments[nextSegmentIndex--];
>                 if (seg.count != 0) {
>                     currentTable = seg.table;
>                     for (int j = currentTable.length - 1; j >= 0; --j) {
>                         if ( (nextEntry = currentTable[j]) != null) { <--
> failure
>                             nextTableIndex = j - 1;
>                             return;
>                         }
>                     }
>                 }
>             }
>         }*
>
> JVM info:
>
> *java version "1.6.0_30"
> Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
> Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)*
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/b61f3671/attachment.html>

From adrian.tarau at gmail.com  Thu Feb 16 17:04:55 2012
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Thu, 16 Feb 2012 17:04:55 -0500
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>	<4F3B5B0C.9020205@fh-hannover.de>	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
Message-ID: <4F3D7D87.2070308@gmail.com>

Yes, I do. I presumed they are thread safe. There is no mention in the 
keySet method that is not thread safe(or the class documentation) and 
you can easily presume you will get a set that's thread safe(including 
the iterator) since you are using ConcurrentHashMap :)

//**
      * Returns a {@link Set} view of the keys contained in this map.
      * The set is backed by the map, so changes to the map are
      * reflected in the set, and vice-versa.  The set supports element
      * removal, which removes the corresponding mapping from this map,
      * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
      * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
      * operations.  It does not support the <tt>add</tt> or
      * <tt>addAll</tt> operations.
      *
      * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
      * that will never throw {@link ConcurrentModificationException},
      * and guarantees to traverse elements as they existed upon
      * construction of the iterator, and may (but is not guaranteed to)
      * reflect any modifications subsequent to construction.
      */
     public Set<K> keySet() {
         ....
     }/

On 02/16/2012 10:26 AM, Vitaly Davidovich wrote:
>
> Are you sharing the same iterator between multiple threads? That's 
> what it sounds like - you can't do that as they aren't threadsafe.
>
> Sent from my phone
>
> On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com 
> <mailto:adrian.tarau at gmail.com>> wrote:
>
>     Good morning,
>
>     I get recently several failures in one of the processes(a remote
>     file collector) which looks like a bug in ConcurrentHashMap
>     implementation. I attached all relevant code...I do not think I
>     misused the map but... I searched for similar complaints but I
>     couldn't find anything relevant - bugs.sun.com
>     <http://bugs.sun.com> returns noting when searching for
>     "ConcurrentHashMap ArrayIndexOutOfBoundsException".
>
>     Thank you,
>     Adrian Tarau.
>
>     I have a map declared like this:
>
>     /private final Map<Location, PriorityBlockingQueue<WorkUnit>>
>     workUnitsPerLocation = new ConcurrentHashMap<Location,
>     PriorityBlockingQueue<WorkUnit>>();/
>
>     a work unit is pushed like this:
>
>     ......
>     Queue<WorkUnit> locationQueue = getLocationQueue(location);
>     boolean offer = locationQueue.offer(workUnit);
>     .......
>     private Queue<WorkUnit> getLocationQueue(Location location) {
>             synchronized (workUnitsPerLocation) {
>                 PriorityBlockingQueue<WorkUnit> queue =
>     workUnitsPerLocation.get(location);
>                 if (queue == null) {
>                     queue = new PriorityBlockingQueue<WorkUnit>(100,
>     new WorkUnit.Comparator());
>                     workUnitsPerLocation.put(location, queue);
>                 }
>                 return queue;
>             }
>         }
>
>     and a working thread(scheduled to run every 5 seconds) is scanning
>     for available work units, peeking one from every location(until a
>     maximum number of working units are running) like this:
>
>     /class WorkUnitScheduler extends AbstractWorker {
>
>             ...
>             // volatile since the state of the iterator must be
>     preserved under different working threads
>             private volatile Iterator<Location> workUnitsIterator;
>
>             ....
>
>             private Queue<WorkUnit> getNextQueue() {
>                 for (int i = 0; i < 2; i++) {// loop twice so we go
>     over all possible locations
>                     if (workUnitsIterator == null ||
>     !workUnitsIterator.hasNext()) {
>                         workUnitsIterator =
>     workUnitsPerLocation.keySet().iterator();//start from beginning
>                     }
>                     while (workUnitsIterator.hasNext()) {
>                         try {
>                             Location location =
>     workUnitsIterator.next(); *<--- fails here*
>                             if (canScheduleFromLocation(location))
>     {//if allowed, get next working unit from this location
>                                 return workUnitsPerLocation.get(location);
>                             }
>                         } catch (NoSuchElementException e) {
>                             // no location
>                         }
>                     }
>                 }
>                 return null;
>             }
>
>             @Override
>             protected void doRun() {
>                      ....
>                     Queue<WorkUnit> queue = getNextQueue();
>                     if (queue == null) {
>                         break;
>                     }
>                     WorkUnit workingUnit = queue.poll();
>                     if (workingUnit == null) {
>                         continue;
>                     }
>                     WorkerService.getInstance().schedule(new
>     DownloadUploadWorker(workingUnit));
>                     ....
>             }
>         }/
>
>     and it fails with:
>
>     /got exception java.lang.ArrayIndexOutOfBoundsException: 3
>          at
>     java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>          at
>     java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>          at
>     java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)/
>
>     it fails here(ConcurrentHashMap implementation fragment):
>
>     /final void advance() {
>                 if (nextEntry != null && (nextEntry = nextEntry.next)
>     != null)
>                     return;
>
>                 while (nextTableIndex >= 0) {
>                     if ( (nextEntry = currentTable[nextTableIndex--])
>     != null)
>                         return;
>                 }
>
>                 while (nextSegmentIndex >= 0) {
>                     Segment<K,V> seg = segments[nextSegmentIndex--];
>                     if (seg.count != 0) {
>                         currentTable = seg.table;
>                         for (int j = currentTable.length - 1; j >= 0;
>     --j) {
>                             if ( (nextEntry = currentTable[j]) !=
>     null) {*<-- failure*
>                                 nextTableIndex = j - 1;
>                                 return;
>                             }
>                         }
>                     }
>                 }
>             }/
>
>     JVM info:
>
>     /java version "1.6.0_30"
>     Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
>     Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)/
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/9a358819/attachment.html>

From vitalyd at gmail.com  Thu Feb 16 17:07:34 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 16 Feb 2012 17:07:34 -0500
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <4F3D7D87.2070308@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
	<4F3D7D87.2070308@gmail.com>
Message-ID: <CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>

The keyset is threadsafe but not its iterator.  The CHM internally caches a
keyset instance, so I don't think you really need to cache anything in your
code.

Sent from my phone
On Feb 16, 2012 5:04 PM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:

> **
> Yes, I do. I presumed they are thread safe. There is no mention in the
> keySet method that is not thread safe(or the class documentation) and you
> can easily presume you will get a set that's thread safe(including the
> iterator) since you are using ConcurrentHashMap :)
>
> */**
>      * Returns a {@link Set} view of the keys contained in this map.
>      * The set is backed by the map, so changes to the map are
>      * reflected in the set, and vice-versa.  The set supports element
>      * removal, which removes the corresponding mapping from this map,
>      * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
>      * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
>      * operations.  It does not support the <tt>add</tt> or
>      * <tt>addAll</tt> operations.
>      *
>      * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
>      * that will never throw {@link ConcurrentModificationException},
>      * and guarantees to traverse elements as they existed upon
>      * construction of the iterator, and may (but is not guaranteed to)
>      * reflect any modifications subsequent to construction.
>      */
>     public Set<K> keySet() {
>         ....
>     }*
>
> On 02/16/2012 10:26 AM, Vitaly Davidovich wrote:
>
> Are you sharing the same iterator between multiple threads? That's what it
> sounds like - you can't do that as they aren't threadsafe.
>
> Sent from my phone
> On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:
>
>>  Good morning,
>>
>> I get recently several failures in one of the processes(a remote file
>> collector) which looks like a bug in ConcurrentHashMap implementation. I
>> attached all relevant code...I do not think I misused the map but... I
>> searched for similar complaints but I couldn't find anything relevant -
>> bugs.sun.com returns noting when searching for "ConcurrentHashMap
>> ArrayIndexOutOfBoundsException".
>>
>> Thank you,
>> Adrian Tarau.
>>
>> I have a map declared like this:
>>
>> *private final Map<Location, PriorityBlockingQueue<WorkUnit>>
>> workUnitsPerLocation = new ConcurrentHashMap<Location,
>> PriorityBlockingQueue<WorkUnit>>();*
>>
>> a work unit is pushed like this:
>>
>> ......
>> Queue<WorkUnit> locationQueue = getLocationQueue(location);
>> boolean offer = locationQueue.offer(workUnit);
>> .......
>> private Queue<WorkUnit> getLocationQueue(Location location) {
>>         synchronized (workUnitsPerLocation) {
>>             PriorityBlockingQueue<WorkUnit> queue =
>> workUnitsPerLocation.get(location);
>>             if (queue == null) {
>>                 queue = new PriorityBlockingQueue<WorkUnit>(100, new
>> WorkUnit.Comparator());
>>                 workUnitsPerLocation.put(location, queue);
>>             }
>>             return queue;
>>         }
>>     }
>>
>> and a working thread(scheduled to run every 5 seconds) is scanning for
>> available work units, peeking one from every location(until a maximum
>> number of working units are running) like this:
>>
>> *class WorkUnitScheduler extends AbstractWorker {
>>
>>         ...
>>         // volatile since the state of the iterator must be preserved
>> under different working threads
>>         private volatile Iterator<Location> workUnitsIterator;
>>
>>         ....
>>
>>         private Queue<WorkUnit> getNextQueue() {
>>             for (int i = 0; i < 2; i++) {// loop twice so we go over all
>> possible locations
>>                 if (workUnitsIterator == null ||
>> !workUnitsIterator.hasNext()) {
>>                     workUnitsIterator =
>> workUnitsPerLocation.keySet().iterator();//start from beginning
>>                 }
>>                 while (workUnitsIterator.hasNext()) {
>>                     try {
>>                         Location location = workUnitsIterator.next(); <---
>> fails here
>>                         if (canScheduleFromLocation(location)) {//if
>> allowed, get next working unit from this location
>>                             return workUnitsPerLocation.get(location);
>>                         }
>>                     } catch (NoSuchElementException e) {
>>                         // no location
>>                     }
>>                 }
>>             }
>>             return null;
>>         }
>>
>>         @Override
>>         protected void doRun() {
>>                  ....
>>                 Queue<WorkUnit> queue = getNextQueue();
>>                 if (queue == null) {
>>                     break;
>>                 }
>>                 WorkUnit workingUnit = queue.poll();
>>                 if (workingUnit == null) {
>>                     continue;
>>                 }
>>                 WorkerService.getInstance().schedule(new
>> DownloadUploadWorker(workingUnit));
>>                 ....
>>         }
>>     }*
>>
>> and it fails with:
>>
>> *got exception java.lang.ArrayIndexOutOfBoundsException: 3
>>      at
>> java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>>      at
>> java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>>      at
>> java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)
>> *
>>
>> it fails here(ConcurrentHashMap implementation fragment):
>>
>> *final void advance() {
>>             if (nextEntry != null && (nextEntry = nextEntry.next) != null)
>>                 return;
>>
>>             while (nextTableIndex >= 0) {
>>                 if ( (nextEntry = currentTable[nextTableIndex--]) != null)
>>                     return;
>>             }
>>
>>             while (nextSegmentIndex >= 0) {
>>                 Segment<K,V> seg = segments[nextSegmentIndex--];
>>                 if (seg.count != 0) {
>>                     currentTable = seg.table;
>>                     for (int j = currentTable.length - 1; j >= 0; --j) {
>>                         if ( (nextEntry = currentTable[j]) != null) {<-- failure
>>                             nextTableIndex = j - 1;
>>                             return;
>>                         }
>>                     }
>>                 }
>>             }
>>         }*
>>
>> JVM info:
>>
>> *java version "1.6.0_30"
>> Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
>> Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)*
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/a93298f3/attachment-0001.html>

From adrian.tarau at gmail.com  Thu Feb 16 22:06:59 2012
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Thu, 16 Feb 2012 22:06:59 -0500
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
	<4F3D7D87.2070308@gmail.com>
	<CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>
Message-ID: <4F3DC453.1060702@gmail.com>

Well, again, I do not see it specified "this is not thread safe" and by 
default you presume ConcurrentHashMap and its structures are thread 
safe. I usually dive into the JDK source code to understend the 
inner-things but I took ConcurrentHashMap as "everything it should be 
thread safe, why looking, it's obvious".

The reason why I'm caching the iterator(last used position) is the 
following: let's say I have 20 locations(everyone with it's own queue) 
and a maximum number of allowed "workers" 10. The scheduling worker(runs 
every N seconds) gets the iterator with the last known position(or it 
creates one) and consumes as many locations as it can. Next time when 
the scheduling worker is executed(it might be executed on a different 
thread) I want to continue from the last known position - I want to 
consume objects from queues in a round-robin fashion, not exceeding the 
maximum number of "processing units" running at any time.

That was the reason why grabbing the key iterator, cache it(since it 
might not be consumed all at once) and once it reaches the end grab a 
new one. It looked pretty trivial  but I guess I was wrong presuming the 
key set iterator is thread safe.

I'm looking at ConcurrentHashMap.HashIterator implementation and I can 
see it is not thread safe, but it would be good to have this mentioned 
in the javadoc of ConcurrentHashMap.keySet().

Thank you,
Adrian Tarau.

On 02/16/2012 05:07 PM, Vitaly Davidovich wrote:
>
> The keyset is threadsafe but not its iterator.  The CHM internally 
> caches a keyset instance, so I don't think you really need to cache 
> anything in your code.
>
> Sent from my phone
>
> On Feb 16, 2012 5:04 PM, "Adrian Tarau" <adrian.tarau at gmail.com 
> <mailto:adrian.tarau at gmail.com>> wrote:
>
>     Yes, I do. I presumed they are thread safe. There is no mention in
>     the keySet method that is not thread safe(or the class
>     documentation) and you can easily presume you will get a set
>     that's thread safe(including the iterator) since you are using
>     ConcurrentHashMap :)
>
>     //**
>          * Returns a {@link Set} view of the keys contained in this map.
>          * The set is backed by the map, so changes to the map are
>          * reflected in the set, and vice-versa.  The set supports element
>          * removal, which removes the corresponding mapping from this map,
>          * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
>          * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
>          * operations.  It does not support the <tt>add</tt> or
>          * <tt>addAll</tt> operations.
>          *
>          * <p>The view's <tt>iterator</tt> is a "weakly consistent"
>     iterator
>          * that will never throw {@link ConcurrentModificationException},
>          * and guarantees to traverse elements as they existed upon
>          * construction of the iterator, and may (but is not
>     guaranteed to)
>          * reflect any modifications subsequent to construction.
>          */
>         public Set<K> keySet() {
>             ....
>         }/
>
>     On 02/16/2012 10:26 AM, Vitaly Davidovich wrote:
>>
>>     Are you sharing the same iterator between multiple threads?
>>     That's what it sounds like - you can't do that as they aren't
>>     threadsafe.
>>
>>     Sent from my phone
>>
>>     On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com
>>     <mailto:adrian.tarau at gmail.com>> wrote:
>>
>>         Good morning,
>>
>>         I get recently several failures in one of the processes(a
>>         remote file collector) which looks like a bug in
>>         ConcurrentHashMap implementation. I attached all relevant
>>         code...I do not think I misused the map but... I searched for
>>         similar complaints but I couldn't find anything relevant -
>>         bugs.sun.com <http://bugs.sun.com> returns noting when
>>         searching for "ConcurrentHashMap ArrayIndexOutOfBoundsException".
>>
>>         Thank you,
>>         Adrian Tarau.
>>
>>         I have a map declared like this:
>>
>>         /private final Map<Location, PriorityBlockingQueue<WorkUnit>>
>>         workUnitsPerLocation = new ConcurrentHashMap<Location,
>>         PriorityBlockingQueue<WorkUnit>>();/
>>
>>         a work unit is pushed like this:
>>
>>         ......
>>         Queue<WorkUnit> locationQueue = getLocationQueue(location);
>>         boolean offer = locationQueue.offer(workUnit);
>>         .......
>>         private Queue<WorkUnit> getLocationQueue(Location location) {
>>                 synchronized (workUnitsPerLocation) {
>>                     PriorityBlockingQueue<WorkUnit> queue =
>>         workUnitsPerLocation.get(location);
>>                     if (queue == null) {
>>                         queue = new
>>         PriorityBlockingQueue<WorkUnit>(100, new WorkUnit.Comparator());
>>                         workUnitsPerLocation.put(location, queue);
>>                     }
>>                     return queue;
>>                 }
>>             }
>>
>>         and a working thread(scheduled to run every 5 seconds) is
>>         scanning for available work units, peeking one from every
>>         location(until a maximum number of working units are running)
>>         like this:
>>
>>         /class WorkUnitScheduler extends AbstractWorker {
>>
>>                 ...
>>                 // volatile since the state of the iterator must be
>>         preserved under different working threads
>>                 private volatile Iterator<Location> workUnitsIterator;
>>
>>                 ....
>>
>>                 private Queue<WorkUnit> getNextQueue() {
>>                     for (int i = 0; i < 2; i++) {// loop twice so we
>>         go over all possible locations
>>                         if (workUnitsIterator == null ||
>>         !workUnitsIterator.hasNext()) {
>>                             workUnitsIterator =
>>         workUnitsPerLocation.keySet().iterator();//start from beginning
>>                         }
>>                         while (workUnitsIterator.hasNext()) {
>>                             try {
>>                                 Location location =
>>         workUnitsIterator.next(); *<--- fails here*
>>                                 if
>>         (canScheduleFromLocation(location)) {//if allowed, get next
>>         working unit from this location
>>                                     return
>>         workUnitsPerLocation.get(location);
>>                                 }
>>                             } catch (NoSuchElementException e) {
>>                                 // no location
>>                             }
>>                         }
>>                     }
>>                     return null;
>>                 }
>>
>>                 @Override
>>                 protected void doRun() {
>>                          ....
>>                         Queue<WorkUnit> queue = getNextQueue();
>>                         if (queue == null) {
>>                             break;
>>                         }
>>                         WorkUnit workingUnit = queue.poll();
>>                         if (workingUnit == null) {
>>                             continue;
>>                         }
>>                         WorkerService.getInstance().schedule(new
>>         DownloadUploadWorker(workingUnit));
>>                         ....
>>                 }
>>             }/
>>
>>         and it fails with:
>>
>>         /got exception java.lang.ArrayIndexOutOfBoundsException: 3
>>              at
>>         java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>>              at
>>         java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>>              at
>>         java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)/
>>
>>         it fails here(ConcurrentHashMap implementation fragment):
>>
>>         /final void advance() {
>>                     if (nextEntry != null && (nextEntry =
>>         nextEntry.next) != null)
>>                         return;
>>
>>                     while (nextTableIndex >= 0) {
>>                         if ( (nextEntry =
>>         currentTable[nextTableIndex--]) != null)
>>                             return;
>>                     }
>>
>>                     while (nextSegmentIndex >= 0) {
>>                         Segment<K,V> seg = segments[nextSegmentIndex--];
>>                         if (seg.count != 0) {
>>                             currentTable = seg.table;
>>                             for (int j = currentTable.length - 1; j
>>         >= 0; --j) {
>>                                 if ( (nextEntry = currentTable[j]) !=
>>         null) {*<-- failure*
>>                                     nextTableIndex = j - 1;
>>                                     return;
>>                                 }
>>                             }
>>                         }
>>                     }
>>                 }/
>>
>>         JVM info:
>>
>>         /java version "1.6.0_30"
>>         Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
>>         Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)/
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/2f91d53e/attachment-0001.html>

From ben_manes at yahoo.com  Thu Feb 16 22:38:39 2012
From: ben_manes at yahoo.com (Ben Manes)
Date: Thu, 16 Feb 2012 19:38:39 -0800 (PST)
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <4F3DC453.1060702@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
	<4F3D7D87.2070308@gmail.com>
	<CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>
	<4F3DC453.1060702@gmail.com>
Message-ID: <1329449919.43288.YahooMailNeo@web38803.mail.mud.yahoo.com>

It is mentioned in the class JavaDoc:
Similarly, Iterators and Enumerations return elements reflecting the state of the hash table at some point at or since the creation of the iterator/enumeration. They do?not?throw?ConcurrentModificationException. However, iterators are designed to be used by only one thread at a time.


It sounds like your situation might be well served by a cyclical buffer, where the next location to process is just an increment of an atomic read counter % buffer size.


________________________________
 From: Adrian Tarau <adrian.tarau at gmail.com>
To: Vitaly Davidovich <vitalyd at gmail.com> 
Cc: concurrency-interest at cs.oswego.edu 
Sent: Thursday, February 16, 2012 7:06 PM
Subject: Re: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
 

Well, again, I do not see it specified "this is not thread safe" and by default you presume ConcurrentHashMap and its structures are thread safe. I usually dive into the JDK source code to understend the inner-things but I took ConcurrentHashMap as "everything it should be thread safe, why looking, it's obvious".

The reason why I'm caching the iterator(last used position) is the
    following: let's say I have 20 locations(everyone with it's own
    queue) and a maximum number of allowed "workers" 10. The scheduling
    worker(runs every N seconds) gets the iterator with the last known
    position(or it creates one) and consumes as many locations as it
    can. Next time when the scheduling worker is executed(it might be
    executed on a different thread) I want to continue from the last
    known position - I want to consume objects from queues in a
    round-robin fashion, not exceeding the maximum number of "processing
    units" running at any time.

That was the reason why grabbing the key iterator, cache it(since it
    might not be consumed all at once) and once it reaches the end grab
    a new one. It looked pretty trivial? but I guess I was wrong
    presuming the key set iterator is thread safe.

I'm looking at ConcurrentHashMap.HashIterator implementation and I
    can see it is not thread safe, but it would be good to have this
    mentioned in the javadoc of ConcurrentHashMap.keySet().

Thank you,
Adrian Tarau.

On 02/16/2012 05:07 PM, Vitaly Davidovich wrote: 
The keyset is threadsafe but not its iterator.? The CHM internally caches a keyset instance, so I don't think you really need to cache anything in your code.
>Sent from my phone
>On Feb 16, 2012 5:04 PM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:
>
>Yes, I do. I presumed they are thread safe. There is no mention in the keySet method that is not thread safe(or the class documentation) and you can easily presume you will get a set that's thread safe(including the iterator) since you are using ConcurrentHashMap :)
>>
>>/**
>>???? * Returns a {@link Set} view of the keys contained in
              this map.
>>???? * The set is backed by the map, so changes to the map
              are
>>???? * reflected in the set, and vice-versa.? The set
              supports element
>>???? * removal, which removes the corresponding mapping
              from this map,
>>???? * via the <tt>Iterator.remove</tt>,
              <tt>Set.remove</tt>,
>>???? * <tt>removeAll</tt>,
              <tt>retainAll</tt>, and
              <tt>clear</tt>
>>???? * operations.? It does not support the
              <tt>add</tt> or
>>???? * <tt>addAll</tt> operations.
>>???? *
>>???? * <p>The view's <tt>iterator</tt>
              is a "weakly consistent" iterator
>>???? * that will never throw {@link
              ConcurrentModificationException},
>>???? * and guarantees to traverse elements as they existed
              upon
>>???? * construction of the iterator, and may (but is not
              guaranteed to)
>>???? * reflect any modifications subsequent to
              construction.
>>???? */
>>??? public Set<K> keySet() {
>>??????? ....
>>??? }
>>
>>On 02/16/2012 10:26 AM, Vitaly Davidovich wrote: 
>>Are you sharing the same iterator between multiple threads? That's what it sounds like - you can't do that as they aren't threadsafe.
>>>Sent from my phone
>>>On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:
>>>
>>>Good morning,
>>>>
>>>>I get recently several failures in one of the
                    processes(a remote file collector) which looks like
                    a bug in ConcurrentHashMap implementation. I
                    attached all relevant code...I do not think I
                    misused the map but... I searched for similar
                    complaints but I couldn't find anything relevant - bugs.sun.com returns noting when searching for "ConcurrentHashMap ArrayIndexOutOfBoundsException".
>>>>
>>>>Thank you,
>>>>Adrian Tarau.
>>>>
>>>>I have a map declared like this:
>>>>
>>>>private final Map<Location, PriorityBlockingQueue<WorkUnit>> workUnitsPerLocation = new ConcurrentHashMap<Location, PriorityBlockingQueue<WorkUnit>>();
>>>>
>>>>a work unit is pushed like this:
>>>>
>>>>......
>>>>Queue<WorkUnit> locationQueue =
                      getLocationQueue(location);
>>>>boolean offer = locationQueue.offer(workUnit);
>>>>.......
>>>>private Queue<WorkUnit>
                      getLocationQueue(Location location) {
>>>>??????? synchronized (workUnitsPerLocation) {
>>>>??????????? PriorityBlockingQueue<WorkUnit>
                      queue = workUnitsPerLocation.get(location);
>>>>??????????? if (queue == null) {
>>>>??????????????? queue = new
                      PriorityBlockingQueue<WorkUnit>(100, new
                      WorkUnit.Comparator());
>>>>??????????????? workUnitsPerLocation.put(location,
                      queue);
>>>>??????????? }
>>>>??????????? return queue;
>>>>??????? }
>>>>??? }
>>>>
>>>>and a working thread(scheduled to run every 5
                    seconds) is scanning for available work units,
                    peeking one from every location(until a maximum
                    number of working units are running) like this:
>>>>
>>>>class WorkUnitScheduler extends AbstractWorker {
>>>>
>>>>??????? ...
>>>>??????? // volatile since the state of the
                        iterator must be preserved under different
                        working threads
>>>>??????? private volatile
                        Iterator<Location> workUnitsIterator;
>>>>
>>>>??????? ....
>>>>
>>>>??????? private Queue<WorkUnit>
                        getNextQueue() {
>>>>??????????? for (int i = 0; i < 2; i++) {//
                        loop twice so we go over all possible locations
>>>>??????????????? if (workUnitsIterator == null ||
                        !workUnitsIterator.hasNext()) {
>>>>??????????????????? workUnitsIterator =
                        workUnitsPerLocation.keySet().iterator();//start
                        from beginning
>>>>??????????????? }
>>>>??????????????? while
                        (workUnitsIterator.hasNext()) {
>>>>??????????????????? try {
>>>>??????????????????????? Location location =
                        workUnitsIterator.next(); <--- fails here
>>>>??????????????????????? if
                        (canScheduleFromLocation(location)) {//if
                        allowed, get next working unit from this
                        location
>>>>??????????????????????????? return
                        workUnitsPerLocation.get(location);
>>>>??????????????????????? }
>>>>??????????????????? } catch
                        (NoSuchElementException e) {
>>>>??????????????????????? // no location
>>>>??????????????????? }
>>>>??????????????? }
>>>>??????????? }
>>>>??????????? return null;
>>>>??????? }
>>>>
>>>>??????? @Override
>>>>??????? protected void doRun() {
>>>>???????????????? ....
>>>>??????????????? Queue<WorkUnit> queue =
                        getNextQueue();
>>>>??????????????? if (queue == null) {
>>>>??????????????????? break;
>>>>??????????????? }
>>>>??????????????? WorkUnit workingUnit =
                        queue.poll();
>>>>??????????????? if (workingUnit == null) {
>>>>??????????????????? continue;
>>>>??????????????? }
>>>>???????????????
                        WorkerService.getInstance().schedule(new
                        DownloadUploadWorker(workingUnit));
>>>>??????????????? ....
>>>>??????? }
>>>>??? }
>>>>
>>>>and it fails with:
>>>>
>>>>got exception java.lang.ArrayIndexOutOfBoundsException: 3
>>>>???? at
java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>>>>???? at
java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>>>>???? at
java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)
>>>>
>>>>it fails here(ConcurrentHashMap implementation
                    fragment):
>>>>
>>>>final void advance() {
>>>>??????????? if (nextEntry != null &&
                        (nextEntry = nextEntry.next) != null)
>>>>??????????????? return;
>>>>
>>>>??????????? while (nextTableIndex >= 0) {
>>>>??????????????? if ( (nextEntry =
                        currentTable[nextTableIndex--]) != null)
>>>>??????????????????? return;
>>>>??????????? }
>>>>
>>>>??????????? while (nextSegmentIndex >= 0) {
>>>>??????????????? Segment<K,V> seg =
                        segments[nextSegmentIndex--];
>>>>??????????????? if (seg.count != 0) {
>>>>??????????????????? currentTable = seg.table;
>>>>??????????????????? for (int j =
                        currentTable.length - 1; j >= 0; --j) {
>>>>??????????????????????? if ( (nextEntry =
                        currentTable[j]) != null) {<-- failure
>>>>??????????????????????????? nextTableIndex = j -
                        1;
>>>>??????????????????????????? return;
>>>>??????????????????????? }
>>>>??????????????????? }
>>>>??????????????? }
>>>>??????????? }
>>>>??????? }
>>>>
>>>>JVM info:
>>>>
>>>>java version "1.6.0_30"
>>>>Java(TM) SE Runtime Environment (build
                        1.6.0_30-b12)
>>>>Java HotSpot(TM) Server VM (build 20.5-b03,
                        mixed mode)
>>>>
>>>>_______________________________________________
>>>>Concurrency-interest mailing list
>>>>Concurrency-interest at cs.oswego.edu
>>>>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/8a89c91b/attachment-0001.html>

From joe.bowbeer at gmail.com  Thu Feb 16 22:56:21 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Thu, 16 Feb 2012 19:56:21 -0800
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <4F3DC453.1060702@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
	<4F3D7D87.2070308@gmail.com>
	<CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>
	<4F3DC453.1060702@gmail.com>
Message-ID: <CAHzJPErWzweWCm-Sz0fPjX6Fkxg+yz=+3tC4h5+240KOxaj4vA@mail.gmail.com>

This check-then-act sequence is fundamentally not thread-safe:

    while (workUnitsIterator.hasNext()) {
        try {
            Location location = workUnitsIterator.next(); <--- fails here

If the iterator were to be designed for multiple-thread access then these
operations would probably be merged so that, for example, next() would
return null when the end was reached.

    for (Location location; (location = iter.next()) != null; ) { ...

--Joe

On Thu, Feb 16, 2012 at 7:06 PM, Adrian Tarau wrote:

>  Well, again, I do not see it specified "this is not thread safe" and by
> default you presume ConcurrentHashMap and its structures are thread safe. I
> usually dive into the JDK source code to understend the inner-things but I
> took ConcurrentHashMap as "everything it should be thread safe, why
> looking, it's obvious".
>
> The reason why I'm caching the iterator(last used position) is the
> following: let's say I have 20 locations(everyone with it's own queue) and
> a maximum number of allowed "workers" 10. The scheduling worker(runs every
> N seconds) gets the iterator with the last known position(or it creates
> one) and consumes as many locations as it can. Next time when the
> scheduling worker is executed(it might be executed on a different thread) I
> want to continue from the last known position - I want to consume objects
> from queues in a round-robin fashion, not exceeding the maximum number of
> "processing units" running at any time.
>
> That was the reason why grabbing the key iterator, cache it(since it might
> not be consumed all at once) and once it reaches the end grab a new one. It
> looked pretty trivial  but I guess I was wrong presuming the key set
> iterator is thread safe.
>
> I'm looking at ConcurrentHashMap.HashIterator implementation and I can see
> it is not thread safe, but it would be good to have this mentioned in the
> javadoc of ConcurrentHashMap.keySet().
>
> Thank you,
> Adrian Tarau.
>
>
> On 02/16/2012 05:07 PM, Vitaly Davidovich wrote:
>
> The keyset is threadsafe but not its iterator.  The CHM internally caches
> a keyset instance, so I don't think you really need to cache anything in
> your code.
>
> Sent from my phone
> On Feb 16, 2012 5:04 PM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:
>
>>  Yes, I do. I presumed they are thread safe. There is no mention in the
>> keySet method that is not thread safe(or the class documentation) and you
>> can easily presume you will get a set that's thread safe(including the
>> iterator) since you are using ConcurrentHashMap :)
>>
>> */**
>>      * Returns a {@link Set} view of the keys contained in this map.
>>      * The set is backed by the map, so changes to the map are
>>      * reflected in the set, and vice-versa.  The set supports element
>>      * removal, which removes the corresponding mapping from this map,
>>      * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
>>      * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
>>      * operations.  It does not support the <tt>add</tt> or
>>      * <tt>addAll</tt> operations.
>>      *
>>      * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
>>      * that will never throw {@link ConcurrentModificationException},
>>      * and guarantees to traverse elements as they existed upon
>>      * construction of the iterator, and may (but is not guaranteed to)
>>      * reflect any modifications subsequent to construction.
>>      */
>>     public Set<K> keySet() {
>>         ....
>>     }*
>>
>> On 02/16/2012 10:26 AM, Vitaly Davidovich wrote:
>>
>> Are you sharing the same iterator between multiple threads? That's what
>> it sounds like - you can't do that as they aren't threadsafe.
>>
>> Sent from my phone
>> On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com> wrote:
>>
>>>  Good morning,
>>>
>>> I get recently several failures in one of the processes(a remote file
>>> collector) which looks like a bug in ConcurrentHashMap implementation. I
>>> attached all relevant code...I do not think I misused the map but... I
>>> searched for similar complaints but I couldn't find anything relevant -
>>> bugs.sun.com returns noting when searching for "ConcurrentHashMap
>>> ArrayIndexOutOfBoundsException".
>>>
>>> Thank you,
>>> Adrian Tarau.
>>>
>>> I have a map declared like this:
>>>
>>> *private final Map<Location, PriorityBlockingQueue<WorkUnit>>
>>> workUnitsPerLocation = new ConcurrentHashMap<Location,
>>> PriorityBlockingQueue<WorkUnit>>();*
>>>
>>> a work unit is pushed like this:
>>>
>>> ......
>>> Queue<WorkUnit> locationQueue = getLocationQueue(location);
>>> boolean offer = locationQueue.offer(workUnit);
>>> .......
>>> private Queue<WorkUnit> getLocationQueue(Location location) {
>>>         synchronized (workUnitsPerLocation) {
>>>             PriorityBlockingQueue<WorkUnit> queue =
>>> workUnitsPerLocation.get(location);
>>>             if (queue == null) {
>>>                 queue = new PriorityBlockingQueue<WorkUnit>(100, new
>>> WorkUnit.Comparator());
>>>                 workUnitsPerLocation.put(location, queue);
>>>             }
>>>             return queue;
>>>         }
>>>     }
>>>
>>> and a working thread(scheduled to run every 5 seconds) is scanning for
>>> available work units, peeking one from every location(until a maximum
>>> number of working units are running) like this:
>>>
>>> *class WorkUnitScheduler extends AbstractWorker {
>>>
>>>         ...
>>>         // volatile since the state of the iterator must be preserved
>>> under different working threads
>>>         private volatile Iterator<Location> workUnitsIterator;
>>>
>>>         ....
>>>
>>>         private Queue<WorkUnit> getNextQueue() {
>>>             for (int i = 0; i < 2; i++) {// loop twice so we go over all
>>> possible locations
>>>                 if (workUnitsIterator == null ||
>>> !workUnitsIterator.hasNext()) {
>>>                     workUnitsIterator =
>>> workUnitsPerLocation.keySet().iterator();//start from beginning
>>>                 }
>>>                 while (workUnitsIterator.hasNext()) {
>>>                     try {
>>>                         Location location = workUnitsIterator.next(); <---
>>> fails here
>>>                         if (canScheduleFromLocation(location)) {//if
>>> allowed, get next working unit from this location
>>>                             return workUnitsPerLocation.get(location);
>>>                         }
>>>                     } catch (NoSuchElementException e) {
>>>                         // no location
>>>                     }
>>>                 }
>>>             }
>>>             return null;
>>>         }
>>>
>>>         @Override
>>>         protected void doRun() {
>>>                  ....
>>>                 Queue<WorkUnit> queue = getNextQueue();
>>>                 if (queue == null) {
>>>                     break;
>>>                 }
>>>                 WorkUnit workingUnit = queue.poll();
>>>                 if (workingUnit == null) {
>>>                     continue;
>>>                 }
>>>                 WorkerService.getInstance().schedule(new
>>> DownloadUploadWorker(workingUnit));
>>>                 ....
>>>         }
>>>     }*
>>>
>>> and it fails with:
>>>
>>> *got exception java.lang.ArrayIndexOutOfBoundsException: 3
>>>      at
>>> java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>>>      at
>>> java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>>>      at
>>> java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)
>>> *
>>>
>>> it fails here(ConcurrentHashMap implementation fragment):
>>>
>>> *final void advance() {
>>>             if (nextEntry != null && (nextEntry = nextEntry.next) !=
>>> null)
>>>                 return;
>>>
>>>             while (nextTableIndex >= 0) {
>>>                 if ( (nextEntry = currentTable[nextTableIndex--]) !=
>>> null)
>>>                     return;
>>>             }
>>>
>>>             while (nextSegmentIndex >= 0) {
>>>                 Segment<K,V> seg = segments[nextSegmentIndex--];
>>>                 if (seg.count != 0) {
>>>                     currentTable = seg.table;
>>>                     for (int j = currentTable.length - 1; j >= 0; --j) {
>>>                         if ( (nextEntry = currentTable[j]) != null) {<-- failure
>>>                             nextTableIndex = j - 1;
>>>                             return;
>>>                         }
>>>                     }
>>>                 }
>>>             }
>>>         }*
>>>
>>> JVM info:
>>>
>>> *java version "1.6.0_30"
>>> Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
>>> Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)*
>>>
>> *
> *
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120216/e1b8baf9/attachment.html>

From Johannes.Lichtenberger at uni-konstanz.de  Fri Feb 17 00:55:43 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Fri, 17 Feb 2012 06:55:43 +0100
Subject: [concurrency-interest] Thread-safe iterator
Message-ID: <4F3DEBDF.3090504@uni-konstanz.de>

Hello,

I want to write a thread safe iterator for a DescendantAxis which
returns all descendants of a node in a tree-structure.

All movement is done within a transaction (the mRtx instance):

    @Override
    public synchronized final long nextNode() {
        synchronized (mRtx) {
            long retVal = -1;
            if (hasNext()) {
                retVal = next();
            }
            return retVal;
        }
    }

The "iterator" returns all unique nodeIDs. hasNext() and next() are
implementations of the Iterable<T> interface. As I'm synchronizing on
the transaction reference I think it's safe (mRtx is also declared
"final"). Should be safe even if hasNext() and next() are not
synchronized as the first thing is a movement in hasNext():

    /**
     * Make sure the transaction points to the node after the last
{@code hasNext()}.
     * This must be called first in {@code hasNext()}.
     *
     * @return key of node where transaction was after the last call of
     *         {@code hasNext()}
     */
    protected final long resetToLastKey() {
        // No check because of IAxis Convention 4.
        mRtx.moveTo(mKey);
        mNext = true;
        return mKey;
    }

Did I miss something?

kind regards,
Johannes


From chakravarthy.varaga at wipro.com  Fri Feb 17 01:42:34 2012
From: chakravarthy.varaga at wipro.com (chakravarthy.varaga at wipro.com)
Date: Fri, 17 Feb 2012 06:42:34 +0000
Subject: [concurrency-interest] Thread-safe iterator
In-Reply-To: <4F3DEBDF.3090504@uni-konstanz.de>
References: <4F3DEBDF.3090504@uni-konstanz.de>
Message-ID: <48E9F8119CA56C49A022F77460B67CF930DA2D57@BLR-EC-MBX5.wipro.com>

Hi,

	Is there a guarantee that your protected final long resetToLastKey() is not accessed outside your iteration and your concrete next() implementation isn't accessed outside the transaction?

Varaga

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Johannes.Lichtenberger
Sent: Friday, February 17, 2012 11:26 AM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Thread-safe iterator

Hello,

I want to write a thread safe iterator for a DescendantAxis which returns all descendants of a node in a tree-structure.

All movement is done within a transaction (the mRtx instance):

    @Override
    public synchronized final long nextNode() {
        synchronized (mRtx) {
            long retVal = -1;
            if (hasNext()) {
                retVal = next();
            }
            return retVal;
        }
    }

The "iterator" returns all unique nodeIDs. hasNext() and next() are implementations of the Iterable<T> interface. As I'm synchronizing on the transaction reference I think it's safe (mRtx is also declared "final"). Should be safe even if hasNext() and next() are not synchronized as the first thing is a movement in hasNext():

    /**
     * Make sure the transaction points to the node after the last {@code hasNext()}.
     * This must be called first in {@code hasNext()}.
     *
     * @return key of node where transaction was after the last call of
     *         {@code hasNext()}
     */
    protected final long resetToLastKey() {
        // No check because of IAxis Convention 4.
        mRtx.moveTo(mKey);
        mNext = true;
        return mKey;
    }

Did I miss something?

kind regards,
Johannes

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

Please do not print this email unless it is absolutely necessary. 

The information contained in this electronic message and any attachments to this message are intended for the exclusive use of the addressee(s) and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately and destroy all copies of this message and any attachments. 

WARNING: Computer viruses can be transmitted via email. The recipient should check this email and any attachments for the presence of viruses. The company accepts no liability for any damage caused by any virus transmitted by this email. 

www.wipro.com


From adrian.tarau at gmail.com  Fri Feb 17 09:44:29 2012
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 17 Feb 2012 09:44:29 -0500
Subject: [concurrency-interest] Bug in ConcurrentHashMap keyset iterator?
In-Reply-To: <1329449919.43288.YahooMailNeo@web38803.mail.mud.yahoo.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<CANPzfU893jOgV5MWfNK7AGjsK=Z0aNegDtHBnUUU_tD0UN3AmQ@mail.gmail.com>
	<4F3D15EE.3050702@gmail.com>
	<CAHjP37H0KQ9DL9RmwOdz1Q8QHXCTCcn-eh3-QnorbnZD1Qi84A@mail.gmail.com>
	<4F3D7D87.2070308@gmail.com>
	<CAHjP37GwBEGGR9MUbCyYQjYNr88NjA=qgp9u4x7364YV6dsz-A@mail.gmail.com>
	<4F3DC453.1060702@gmail.com>
	<1329449919.43288.YahooMailNeo@web38803.mail.mud.yahoo.com>
Message-ID: <4F3E67CD.6030704@gmail.com>

Indeed, mea culpa. To avoid keeping/updating another structure I will 
probably just do /new CopyOnWriteArrayList(map.keySet()) /and use this 
as a thread safe iterable structure.

Thank you for you help,
Adrian Tarau.

On 02/16/2012 10:38 PM, Ben Manes wrote:
> It is mentioned in the class JavaDoc:
> Similarly, Iterators and Enumerations return elements reflecting the 
> state of the hash table at some point at or since the creation of the 
> iterator/enumeration. They do /not/ throw 
> |ConcurrentModificationException| 
> <http://docs.oracle.com/javase/6/docs/api/java/util/ConcurrentModificationException.html>. 
> However, iterators are designed to be used by only one thread at a time.
>
> It sounds like your situation might be well served by a cyclical 
> buffer, where the next location to process is just an increment of an 
> atomic read counter % buffer size.
>
> ------------------------------------------------------------------------
> *From:* Adrian Tarau <adrian.tarau at gmail.com>
> *To:* Vitaly Davidovich <vitalyd at gmail.com>
> *Cc:* concurrency-interest at cs.oswego.edu
> *Sent:* Thursday, February 16, 2012 7:06 PM
> *Subject:* Re: [concurrency-interest] Bug in ConcurrentHashMap keyset 
> iterator?
>
> Well, again, I do not see it specified "this is not thread safe" and 
> by default you presume ConcurrentHashMap and its structures are thread 
> safe. I usually dive into the JDK source code to understend the 
> inner-things but I took ConcurrentHashMap as "everything it should be 
> thread safe, why looking, it's obvious".
>
> The reason why I'm caching the iterator(last used position) is the 
> following: let's say I have 20 locations(everyone with it's own queue) 
> and a maximum number of allowed "workers" 10. The scheduling 
> worker(runs every N seconds) gets the iterator with the last known 
> position(or it creates one) and consumes as many locations as it can. 
> Next time when the scheduling worker is executed(it might be executed 
> on a different thread) I want to continue from the last known position 
> - I want to consume objects from queues in a round-robin fashion, not 
> exceeding the maximum number of "processing units" running at any time.
>
> That was the reason why grabbing the key iterator, cache it(since it 
> might not be consumed all at once) and once it reaches the end grab a 
> new one. It looked pretty trivial  but I guess I was wrong presuming 
> the key set iterator is thread safe.
>
> I'm looking at ConcurrentHashMap.HashIterator implementation and I can 
> see it is not thread safe, but it would be good to have this mentioned 
> in the javadoc of ConcurrentHashMap.keySet().
>
> Thank you,
> Adrian Tarau.
>
> On 02/16/2012 05:07 PM, Vitaly Davidovich wrote:
>> The keyset is threadsafe but not its iterator.  The CHM internally 
>> caches a keyset instance, so I don't think you really need to cache 
>> anything in your code.
>> Sent from my phone
>> On Feb 16, 2012 5:04 PM, "Adrian Tarau" <adrian.tarau at gmail.com 
>> <mailto:adrian.tarau at gmail.com>> wrote:
>>
>>     Yes, I do. I presumed they are thread safe. There is no mention
>>     in the keySet method that is not thread safe(or the class
>>     documentation) and you can easily presume you will get a set
>>     that's thread safe(including the iterator) since you are using
>>     ConcurrentHashMap :)
>>
>>     //**
>>          * Returns a {@link Set} view of the keys contained in this map.
>>          * The set is backed by the map, so changes to the map are
>>          * reflected in the set, and vice-versa.  The set supports
>>     element
>>          * removal, which removes the corresponding mapping from this
>>     map,
>>          * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
>>          * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
>>          * operations.  It does not support the <tt>add</tt> or
>>          * <tt>addAll</tt> operations.
>>          *
>>          * <p>The view's <tt>iterator</tt> is a "weakly consistent"
>>     iterator
>>          * that will never throw {@link ConcurrentModificationException},
>>          * and guarantees to traverse elements as they existed upon
>>          * construction of the iterator, and may (but is not
>>     guaranteed to)
>>          * reflect any modifications subsequent to construction.
>>          */
>>         public Set<K> keySet() {
>>             ....
>>         }/
>>
>>     On 02/16/2012 10:26 AM, Vitaly Davidovich wrote:
>>>     Are you sharing the same iterator between multiple threads?
>>>     That's what it sounds like - you can't do that as they aren't
>>>     threadsafe.
>>>     Sent from my phone
>>>     On Feb 16, 2012 9:47 AM, "Adrian Tarau" <adrian.tarau at gmail.com
>>>     <mailto:adrian.tarau at gmail.com>> wrote:
>>>
>>>         Good morning,
>>>
>>>         I get recently several failures in one of the processes(a
>>>         remote file collector) which looks like a bug in
>>>         ConcurrentHashMap implementation. I attached all relevant
>>>         code...I do not think I misused the map but... I searched
>>>         for similar complaints but I couldn't find anything relevant
>>>         - bugs.sun.com <http://bugs.sun.com> returns noting when
>>>         searching for "ConcurrentHashMap
>>>         ArrayIndexOutOfBoundsException".
>>>
>>>         Thank you,
>>>         Adrian Tarau.
>>>
>>>         I have a map declared like this:
>>>
>>>         /private final Map<Location,
>>>         PriorityBlockingQueue<WorkUnit>> workUnitsPerLocation = new
>>>         ConcurrentHashMap<Location, PriorityBlockingQueue<WorkUnit>>();/
>>>
>>>         a work unit is pushed like this:
>>>
>>>         ......
>>>         Queue<WorkUnit> locationQueue = getLocationQueue(location);
>>>         boolean offer = locationQueue.offer(workUnit);
>>>         .......
>>>         private Queue<WorkUnit> getLocationQueue(Location location) {
>>>                 synchronized (workUnitsPerLocation) {
>>>                     PriorityBlockingQueue<WorkUnit> queue =
>>>         workUnitsPerLocation.get(location);
>>>                     if (queue == null) {
>>>                         queue = new
>>>         PriorityBlockingQueue<WorkUnit>(100, new WorkUnit.Comparator());
>>>                         workUnitsPerLocation.put(location, queue);
>>>                     }
>>>                     return queue;
>>>                 }
>>>             }
>>>
>>>         and a working thread(scheduled to run every 5 seconds) is
>>>         scanning for available work units, peeking one from every
>>>         location(until a maximum number of working units are
>>>         running) like this:
>>>
>>>         /class WorkUnitScheduler extends AbstractWorker {
>>>
>>>                 ...
>>>                 // volatile since the state of the iterator must be
>>>         preserved under different working threads
>>>                 private volatile Iterator<Location> workUnitsIterator;
>>>
>>>                 ....
>>>
>>>                 private Queue<WorkUnit> getNextQueue() {
>>>                     for (int i = 0; i < 2; i++) {// loop twice so we
>>>         go over all possible locations
>>>                         if (workUnitsIterator == null ||
>>>         !workUnitsIterator.hasNext()) {
>>>                             workUnitsIterator =
>>>         workUnitsPerLocation.keySet().iterator();//start from beginning
>>>                         }
>>>                         while (workUnitsIterator.hasNext()) {
>>>                             try {
>>>                                 Location location =
>>>         workUnitsIterator.next(); *<--- fails here*
>>>                                 if
>>>         (canScheduleFromLocation(location)) {//if allowed, get next
>>>         working unit from this location
>>>                                     return
>>>         workUnitsPerLocation.get(location);
>>>                                 }
>>>                             } catch (NoSuchElementException e) {
>>>                                 // no location
>>>                             }
>>>                         }
>>>                     }
>>>                     return null;
>>>                 }
>>>
>>>                 @Override
>>>                 protected void doRun() {
>>>                          ....
>>>                         Queue<WorkUnit> queue = getNextQueue();
>>>                         if (queue == null) {
>>>                             break;
>>>                         }
>>>                         WorkUnit workingUnit = queue.poll();
>>>                         if (workingUnit == null) {
>>>                             continue;
>>>                         }
>>>                         WorkerService.getInstance().schedule(new
>>>         DownloadUploadWorker(workingUnit));
>>>                         ....
>>>                 }
>>>             }/
>>>
>>>         and it fails with:
>>>
>>>         /got exception java.lang.ArrayIndexOutOfBoundsException: 3
>>>              at
>>>         java.util.concurrent.ConcurrentHashMap$HashIterator.advance(ConcurrentHashMap.java:1086)
>>>              at
>>>         java.util.concurrent.ConcurrentHashMap$HashIterator.nextEntry(ConcurrentHashMap.java:1101)
>>>              at
>>>         java.util.concurrent.ConcurrentHashMap$KeyIterator.next(ConcurrentHashMap.java:1117)/
>>>
>>>         it fails here(ConcurrentHashMap implementation fragment):
>>>
>>>         /final void advance() {
>>>                     if (nextEntry != null && (nextEntry =
>>>         nextEntry.next) != null)
>>>                         return;
>>>
>>>                     while (nextTableIndex >= 0) {
>>>                         if ( (nextEntry =
>>>         currentTable[nextTableIndex--]) != null)
>>>                             return;
>>>                     }
>>>
>>>                     while (nextSegmentIndex >= 0) {
>>>                         Segment<K,V> seg = segments[nextSegmentIndex--];
>>>                         if (seg.count != 0) {
>>>                             currentTable = seg.table;
>>>                             for (int j = currentTable.length - 1; j
>>>         >= 0; --j) {
>>>                                 if ( (nextEntry = currentTable[j])
>>>         != null) {*<-- failure*
>>>                                     nextTableIndex = j - 1;
>>>                                     return;
>>>                                 }
>>>                             }
>>>                         }
>>>                     }
>>>                 }/
>>>
>>>         JVM info:
>>>
>>>         /java version "1.6.0_30"
>>>         Java(TM) SE Runtime Environment (build 1.6.0_30-b12)
>>>         Java HotSpot(TM) Server VM (build 20.5-b03, mixed mode)/
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu 
> <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120217/427d093c/attachment-0001.html>

From Johannes.Lichtenberger at uni-konstanz.de  Fri Feb 17 10:54:27 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Fri, 17 Feb 2012 16:54:27 +0100
Subject: [concurrency-interest] Thread-safe iterator
In-Reply-To: <48E9F8119CA56C49A022F77460B67CF930DA2D57@BLR-EC-MBX5.wipro.com>
References: <4F3DEBDF.3090504@uni-konstanz.de>
	<48E9F8119CA56C49A022F77460B67CF930DA2D57@BLR-EC-MBX5.wipro.com>
Message-ID: <4F3E7833.3060601@uni-konstanz.de>

On 02/17/2012 07:42 AM, chakravarthy.varaga at wipro.com wrote:
> Hi,
> 
> 	Is there a guarantee that your protected final long resetToLastKey() is not accessed outside your iteration and your concrete next() implementation isn't accessed outside the transaction?

Well, next() is implemented in the abstract skeleton implementation with
a simple mWtx.moveTo(nextKey); and it should in general never be
overriden, but that must be properly documented.

resetToLastKey() also should never be exposed, but it has to be
protected as the abstract skeleton impl. is used from other packages.

kind regards,
Johannes




From Johannes.Lichtenberger at uni-konstanz.de  Fri Feb 17 11:42:01 2012
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Fri, 17 Feb 2012 17:42:01 +0100
Subject: [concurrency-interest] Thread-safe iterator
In-Reply-To: <4F3E7833.3060601@uni-konstanz.de>
References: <4F3DEBDF.3090504@uni-konstanz.de>
	<48E9F8119CA56C49A022F77460B67CF930DA2D57@BLR-EC-MBX5.wipro.com>
	<4F3E7833.3060601@uni-konstanz.de>
Message-ID: <4F3E8359.6090208@uni-konstanz.de>

On 02/17/2012 04:54 PM, Johannes.Lichtenberger wrote:
> On 02/17/2012 07:42 AM, chakravarthy.varaga at wipro.com wrote:
>> Hi,
>>
>> 	Is there a guarantee that your protected final long resetToLastKey() is not accessed outside your iteration and your concrete next() implementation isn't accessed outside the transaction?
> 
> Well, next() is implemented in the abstract skeleton implementation with
> a simple mWtx.moveTo(nextKey); and it should in general never be
> overriden, but that must be properly documented.
> 
> resetToLastKey() also should never be exposed, but it has to be
> protected as the abstract skeleton impl. is used from other packages.

More precisely:

    @Override
    public final Long next() {
        if (!mNext) {
            hasNext();
        }
        mRtx.moveTo(mNextKey);
        mNext = false;
        return mNextKey;
    }

BTW: next() is the method which implements the method from Iterable<Long>.

kind regards,
Johannes

From sergemasse1 at yahoo.com  Sun Feb 19 10:42:46 2012
From: sergemasse1 at yahoo.com (serge masse)
Date: Sun, 19 Feb 2012 07:42:46 -0800 (PST)
Subject: [concurrency-interest] Descending Iterator on ConcurrentSkipListSet
	is skipping 2 elements after one changed
Message-ID: <1329666166.19350.YahooMailNeo@web161206.mail.bf1.yahoo.com>

Using jsr166x.jar from Feb. 11, 2012, in an Android app with latest SDK. This happens on a device with Android 2.2 and in an emulator with Android 2.3.1. The jar is at the top of the Java Build Path library list in Eclipse.

Tested with a ConcurrentSkipListSet with 5 objects. The first use of the Iterator is fine, then one object is changed (i.e., one of the values used in the comparator is changed), then on the second pass the descending iterator is not showing the changed object and one next to it. Similar code using the ascending iterator does not have this behavior.


The output:

testDesc first pass:
a5 0
a4 0
a3 0
a2 0
a1 0
testDesc *a3.a.incrementAndGet()*
testDesc second pass:
a5 0
a2 0
a1 0


testAsc first pass:
a1 0
a2 0
a3 0
a4 0
a5 0
testAsc *a3.a.incrementAndGet()*
testAsc second pass:
a1 0
a2 0
a3 1
a4 0
a5 0


The code:

? private class Testob {
? public volatile String id = "0";
? public final AtomicInteger a = new AtomicInteger(0);
? }

? /** the signal with the most hits is ranked ahead. */
? private static final Comparator<Testob> TESTOB_COMPARATOR = new Comparator<Testob>(){
public int compare(Testob arg0, Testob arg1) {
 ? ?final int a0 = arg0.a.get();
 ? ?final int a1 = arg1.a.get();
if(a0 == a1){
return arg0.id.compareTo(arg1.id);
}
if(a0 < a1)return -1;
return 1;
? ? }
? };
??
? /**
? ?* ordered by a
? ?*/
? static final ConcurrentSkipListSet<Testob> TEST_OBS_DESC =?
? ? ? new ConcurrentSkipListSet<Testob>(TESTOB_COMPARATOR);?
? static final ConcurrentSkipListSet<Testob> TEST_OBS_ASC =?
? ? ? new ConcurrentSkipListSet<Testob>(TESTOB_COMPARATOR);?

? private void test(){
? testDesc();
? testAsc();
? }
??
? private void testDesc(){
? //create instances
? Testob a1 = new Testob();
? a1.id="a1";
? Testob a2 = new Testob();
? a2.id="a2";
? Testob a3 = new Testob();
? a3.id="a3";
? Testob a4 = new Testob();
? a4.id="a4";
? Testob a5 = new Testob();
? a5.id="a5";
? TEST_OBS_DESC.add(a1);
? TEST_OBS_DESC.add(a2);
? TEST_OBS_DESC.add(a3);
? TEST_OBS_DESC.add(a4);
? TEST_OBS_DESC.add(a5);
? 
? //get descending iterator and list ids
? Log.d("testob","testDesc first pass:");
? Iterator<Testob> it1 = TEST_OBS_DESC.descendingIterator();
? while(it1.hasNext()){
? Testob ob = it1.next();
? Log.d("testob",ob.id+" "+ob.a.get());
? }
? 
? //inc a for one
? Log.d("testob","testDesc *a3.a.incrementAndGet()*");
? a3.a.incrementAndGet();
? 
? ? ? ? //get descending iterator and list ids
? Log.d("testob","testDesc second pass:");
? Iterator<Testob> it2 = TEST_OBS_DESC.descendingIterator();
? while(it2.hasNext()){
? Testob ob = it2.next();
? Log.d("testob",ob.id+" "+ob.a.get());
? }
? }
??

? private void testAsc(){
? //create instances
? Testob a1 = new Testob();
? a1.id="a1";
? Testob a2 = new Testob();
? a2.id="a2";
? Testob a3 = new Testob();
? a3.id="a3";
? Testob a4 = new Testob();
? a4.id="a4";
? Testob a5 = new Testob();
? a5.id="a5";
? TEST_OBS_ASC.add(a1);
? TEST_OBS_ASC.add(a2);
? TEST_OBS_ASC.add(a3);
? TEST_OBS_ASC.add(a4);
? TEST_OBS_ASC.add(a5);
? 
? //get descending iterator and list ids
? Log.d("testob","testAsc first pass:");
? Iterator<Testob> it1 = TEST_OBS_ASC.iterator();
? while(it1.hasNext()){
? Testob ob = it1.next();
? Log.d("testob",ob.id+" "+ob.a.get());
? }
? 
? //inc a for one
? Log.d("testob","testAsc *a3.a.incrementAndGet()*");
? a3.a.incrementAndGet();
? 
? ? ? ? //get descending iterator and list ids
? Log.d("testob","testAsc second pass:");
? Iterator<Testob> it2 = TEST_OBS_ASC.iterator();
? while(it2.hasNext()){
? Testob ob = it2.next();
? Log.d("testob",ob.id+" "+ob.a.get());
? }
? }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120219/931f4eca/attachment.html>

From dl at cs.oswego.edu  Sun Feb 19 10:58:28 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 19 Feb 2012 10:58:28 -0500
Subject: [concurrency-interest] Descending Iterator on
 ConcurrentSkipListSet is skipping 2 elements after one changed
In-Reply-To: <1329666166.19350.YahooMailNeo@web161206.mail.bf1.yahoo.com>
References: <1329666166.19350.YahooMailNeo@web161206.mail.bf1.yahoo.com>
Message-ID: <4F411C24.5040301@cs.oswego.edu>

On 02/19/12 10:42, serge masse wrote:
> Using jsr166x.jar from Feb. 11, 2012, in an Android app with latest SDK. This
> happens on a device with Android 2.2 and in an emulator with Android 2.3.1. The
> jar is at the top of the Java Build Path library list in Eclipse.
>
> Tested with a ConcurrentSkipListSet with 5 objects. The first use of the
> Iterator is fine, then one object is changed (i.e., one of the values used in
> the comparator is changed), then on the second pass the descending iterator is
> not showing the changed object and one next to it. Similar code using the
> ascending iterator does not have this behavior.

Comparators in all java.util.* collections are required to be idempotent,
but yours appears not to be -- its value can change asynchronously
(in a way that no data structure could cope with).

As a separate issue though, we haven't reconciled the old jsr166x
source with Java6+ in a while. We'll do this.

-Doug



>
> The output:
>
> testDesc first pass:
> a5 0
> a4 0
> a3 0
> a2 0
> a1 0
> testDesc *a3.a.incrementAndGet()*
> testDesc second pass:
> a5 0
> a2 0
> a1 0
>
>
> testAsc first pass:
> a1 0
> a2 0
> a3 0
> a4 0
> a5 0
> testAsc *a3.a.incrementAndGet()*
> testAsc second pass:
> a1 0
> a2 0
> a3 1
> a4 0
> a5 0
>
>
> The code:
>
> private class Testob {
> public volatile String id = "0";
> public final AtomicInteger a = new AtomicInteger(0);
> }
>
> /** the signal with the most hits is ranked ahead. */
> private static final Comparator<Testob> TESTOB_COMPARATOR = new
> Comparator<Testob>(){
> public int compare(Testob arg0, Testob arg1) {
> final int a0 = arg0.a.get();
> final int a1 = arg1.a.get();
> if(a0 == a1){
> return arg0.id.compareTo(arg1.id);
> }
> if(a0 < a1)return -1;
> return 1;
> }
> };
> /**
> * ordered by a
> */
> static final ConcurrentSkipListSet<Testob> TEST_OBS_DESC =
> new ConcurrentSkipListSet<Testob>(TESTOB_COMPARATOR);
> static final ConcurrentSkipListSet<Testob> TEST_OBS_ASC =
> new ConcurrentSkipListSet<Testob>(TESTOB_COMPARATOR);
>
> private void test(){
> testDesc();
> testAsc();
> }
> private void testDesc(){
> //create instances
> Testob a1 = new Testob();
> a1.id="a1";
> Testob a2 = new Testob();
> a2.id="a2";
> Testob a3 = new Testob();
> a3.id="a3";
> Testob a4 = new Testob();
> a4.id="a4";
> Testob a5 = new Testob();
> a5.id="a5";
> TEST_OBS_DESC.add(a1);
> TEST_OBS_DESC.add(a2);
> TEST_OBS_DESC.add(a3);
> TEST_OBS_DESC.add(a4);
> TEST_OBS_DESC.add(a5);
> //get descending iterator and list ids
> Log.d("testob","testDesc first pass:");
> Iterator<Testob> it1 = TEST_OBS_DESC.descendingIterator();
> while(it1.hasNext()){
> Testob ob = it1.next();
> Log.d("testob",ob.id+" "+ob.a.get());
> }
> //inc a for one
> Log.d("testob","testDesc *a3.a.incrementAndGet()*");
> a3.a.incrementAndGet();
> //get descending iterator and list ids
> Log.d("testob","testDesc second pass:");
> Iterator<Testob> it2 = TEST_OBS_DESC.descendingIterator();
> while(it2.hasNext()){
> Testob ob = it2.next();
> Log.d("testob",ob.id+" "+ob.a.get());
> }
> }
>
> private void testAsc(){
> //create instances
> Testob a1 = new Testob();
> a1.id="a1";
> Testob a2 = new Testob();
> a2.id="a2";
> Testob a3 = new Testob();
> a3.id="a3";
> Testob a4 = new Testob();
> a4.id="a4";
> Testob a5 = new Testob();
> a5.id="a5";
> TEST_OBS_ASC.add(a1);
> TEST_OBS_ASC.add(a2);
> TEST_OBS_ASC.add(a3);
> TEST_OBS_ASC.add(a4);
> TEST_OBS_ASC.add(a5);
> //get descending iterator and list ids
> Log.d("testob","testAsc first pass:");
> Iterator<Testob> it1 = TEST_OBS_ASC.iterator();
> while(it1.hasNext()){
> Testob ob = it1.next();
> Log.d("testob",ob.id+" "+ob.a.get());
> }
> //inc a for one
> Log.d("testob","testAsc *a3.a.incrementAndGet()*");
> a3.a.incrementAndGet();
> //get descending iterator and list ids
> Log.d("testob","testAsc second pass:");
> Iterator<Testob> it2 = TEST_OBS_ASC.iterator();
> while(it2.hasNext()){
> Testob ob = it2.next();
> Log.d("testob",ob.id+" "+ob.a.get());
> }
> }
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hanson.char at gmail.com  Sun Feb 19 12:19:56 2012
From: hanson.char at gmail.com (Hanson Char)
Date: Sun, 19 Feb 2012 09:19:56 -0800
Subject: [concurrency-interest] on happens-before formalism
In-Reply-To: <CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>
References: <9024755B-1FAF-4C49-B9D0-D4A5367F92E5@gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEMFJCAA.davidcholmes@aapt.net.au>
	<CAHzJPEpPzqq9CYtTpPmbAzNs0x5o7AJF-FJkxn5fSsBeKuitjw@mail.gmail.com>
Message-ID: <CABWgujYJCQ7KOU1r2TFRF+eseNcnn8bq-UVsZ2r-LUoDFe8rjg@mail.gmail.com>

Alternatively, it seems "happens-before" really means
"happens-on-or-before", which probably is easier to say or write, and
fits more closely with it's actual definition as a partial order (and
not a strict partial order).

Hanson

On Fri, Feb 3, 2012 at 8:04 AM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> When this question arose on The Art of Multiprocessor Programming discussion
> list a couple years ago, the resolution was that happens-before (<=) is a
> strict partial order, therefore reflexive.
>
> In other words, happens-before can be interpreted as
> "happens-before-or-is-equal" -- but no one wants to say or write that.
>
> --Joe
>
>
> On Thu, Feb 2, 2012 at 11:28 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>>
>> It seems to me to be somewhat arbitrary to define this as either reflexive
>> or irreflexive as it makes no practical difference to the semantics. I
>> think
>> irreflexive would be more appropriate in this case as intuitively it
>> doesn't
>> make sense to say that "A happens-before A". I suspect that by selecting
>> reflexive and using a normal/simple notion of poset that the overall
>> formalism is simplified.
>>
>> If you really want to know ask on the Java Memory Model list cc'ed.
>>
>> Cheers,
>> David Holmes
>>
>> > -----Original Message-----
>> > From: concurrency-interest-bounces at cs.oswego.edu
>> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Pavel
>> > Rappo
>> > Sent: Friday, 3 February 2012 5:18 PM
>> > To: Concurrency-interest at cs.oswego.edu
>> > Subject: Re: [concurrency-interest] on happens-before formalism
>> >
>> >
>> > Then I think it's very different from Lamport's definition of
>> > happened-before which they reference to.
>> > Maybe that's why Lamport calls it "happenED-before" (not
>> > "happenS-before").
>> >
>> > Btw, there's such thing as strict partial order, which I guess in
>> > this case is more suitable. It's irreflexive, asymmetric and transitive.
>> >
>> > On 3 Feb 2012, at 09:16, Qingzhou Luo wrote:
>> >
>> > > I think they did mean reflexive.
>> > >
>> > > See partial order definition:
>> > > http://en.wikipedia.org/wiki/Partially_ordered_set
>> > >
>> > > On Thu, Feb 2, 2012 at 5:51 PM, Pavel Rappo
>> > <pavel.rappo at gmail.com> wrote:
>> > > I've been reading "SPECIAL POPL ISSUE The Java Memory Model" by Jeremy
>> > > Manson, William Pugh and Sarita Adve.
>> > > There's one (yet) thing seems strange to me. Though I think
>> > it's actually a
>> > > typo it's still worth mentioning.
>> > >
>> > > page. 8, 2.1: "...Note that all of this means that happens-before is a
>> > > partial order: it is reflexive, transitive and anti-symmetric..."
>> > >
>> > > Am I right saying authors actually meant "irreflexive"?
>> > >
>> > > --
>> > > Sincerely yours, Pavel Rappo.
>> > > _______________________________________________
>> > > Concurrency-interest mailing list
>> > > Concurrency-interest at cs.oswego.edu
>> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> > >
>> > >
>> > >
>> > > --
>> > > Qingzhou Luo
>> > > http://mir.cs.illinois.edu/~qluo2/
>> > >
>> > > Department of Computer Science
>> > > University of Illinois, Urbana Champaign
>> > >
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From sergemasse1 at yahoo.com  Mon Feb 20 09:58:35 2012
From: sergemasse1 at yahoo.com (serge masse)
Date: Mon, 20 Feb 2012 06:58:35 -0800 (PST)
Subject: [concurrency-interest] Descending Iterator on
	ConcurrentSkipListSet is skipping 2 elements after one changed
Message-ID: <1329749915.46727.androidMobile@web161203.mail.bf1.yahoo.com>

Thank you for the prompt and helpful reply. I was suspecting that my Comparator was a bit risky. I'll fix it.

Regards,
Serge

Sent from Yahoo! Mail on Android

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120220/c5ff6ec2/attachment.html>

From dl at cs.oswego.edu  Mon Feb 20 13:40:33 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 20 Feb 2012 13:40:33 -0500
Subject: [concurrency-interest] ForkJoin updates
In-Reply-To: <4F2C2739.7080008@cs.oswego.edu>
References: <4F20A70A.7030204@cs.oswego.edu>	<SNT114-W307C47D76ECCAC9093CBC583710@phx.gbl>
	<4F2C2739.7080008@cs.oswego.edu>
Message-ID: <4F4293A1.7030202@cs.oswego.edu>

On 02/03/12 13:28, Doug Lea wrote:
> On 02/03/12 11:29, Jason Mehrens wrote:
>> Would unconditionally marking the ForkJoinTask as ineligible for biased locking,

> I don't plan to do this, but resolving this in a better way is
> among the "other" remaining changes for this round I mentioned.

Which are now committed, and ...

>
>  The unluckiest of these cases cascade into
> stalls involving many threads/cores, which are the main cause
> of the unwanted positive feedback loops I've mentioned that
> force compensation to be overly conservative.

... which enabled a less conservative compensation
policy, giving some further speedups in some use cases.

These updates also include re-implementing timed gets
under new scheme rather than relying on some
placeholder code that could mis-report status, so if you
are using recent versions, you should get an update.
Available in the usual places -- see
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html


-Doug

From dl at cs.oswego.edu  Mon Feb 20 14:07:18 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 20 Feb 2012 14:07:18 -0500
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>	<4F3B5B0C.9020205@fh-hannover.de>	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
Message-ID: <4F4299E6.5030905@cs.oswego.edu>

(Slowly catching up with mail.)

On 02/16/12 07:06, Mohan Radhakrishnan wrote:
> Does ... mean that now I can submit independent tasks to the FJ framework
> without the need for a task and subtask graph and still get the benefits of
> work stealing ?
>

You get *some* of the benefits of work-stealing -- mainly decentralized
queuing and much better scalability.

The main tradeoff compared to ThreadPoolExecutor is that you have less
control (for example no direct access to submission queues) and essentially
no configuration methods. (Although most people seem to agree that
lack of such methods and options is a feature not a bug. In part because
it simplifies our ability to improve internal implementations over time
in ways that we cannot do with TPE because it reveals so much of its
internal workings.)

The other tradeoff is that FJP generally uses more CPU cycles
and memory than TPE.

All other things being equal, as a rough rule of thumb, if you are
running with 4 or fewer processors/cores, you probably won't see any
advantage to using FJP vs TPE as an "plain" ExecutorService. And
for a singleton (size one) pool, TPE is clearly better.
On larger platforms, FJP can be almost arbitrarily faster.

-Doug






From joe.bowbeer at gmail.com  Mon Feb 20 15:08:37 2012
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Mon, 20 Feb 2012 12:08:37 -0800
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <4F4299E6.5030905@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<4F4299E6.5030905@cs.oswego.edu>
Message-ID: <CAHzJPEriLQMNhk2Rx2MgJ5QJuVQR9RNQmk5PY+mMu03L+czeWQ@mail.gmail.com>

Is it (still) also true that it is difficult to manage multiple FJPs (because
each one will try to achieve maximum throughput)?

It would seem that TPE handles this better, because each pool can be
configured to operate with limits placed on its number of threads and
queued tasks.  Though I'm not optimistic that that works well in practice
when there are multiple apps running...  (For example, choosing a single
TPE configuration that works well for all SwingWorker clients -- providing
plenty of background processing without affecting the responsiveness of the
UI -- is a never-ending battle.)

Joe

On Mon, Feb 20, 2012 at 11:07 AM, Doug Lea wrote:

> (Slowly catching up with mail.)
>
> On 02/16/12 07:06, Mohan Radhakrishnan wrote:
>
>> Does ... mean that now I can submit independent tasks to the FJ framework
>>
>> without the need for a task and subtask graph and still get the benefits
>> of
>> work stealing ?
>>
>>
> You get *some* of the benefits of work-stealing -- mainly decentralized
> queuing and much better scalability.
>
> The main tradeoff compared to ThreadPoolExecutor is that you have less
> control (for example no direct access to submission queues) and essentially
> no configuration methods. (Although most people seem to agree that
> lack of such methods and options is a feature not a bug. In part because
> it simplifies our ability to improve internal implementations over time
> in ways that we cannot do with TPE because it reveals so much of its
> internal workings.)
>
> The other tradeoff is that FJP generally uses more CPU cycles
> and memory than TPE.
>
> All other things being equal, as a rough rule of thumb, if you are
> running with 4 or fewer processors/cores, you probably won't see any
> advantage to using FJP vs TPE as an "plain" ExecutorService. And
> for a singleton (size one) pool, TPE is clearly better.
> On larger platforms, FJP can be almost arbitrarily faster.
>
> -Doug
>
>
>
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120220/d6260695/attachment.html>

From dl at cs.oswego.edu  Mon Feb 20 17:22:31 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 20 Feb 2012 17:22:31 -0500
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <CAHzJPEriLQMNhk2Rx2MgJ5QJuVQR9RNQmk5PY+mMu03L+czeWQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>	<4F3B5B0C.9020205@fh-hannover.de>	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>	<4F4299E6.5030905@cs.oswego.edu>
	<CAHzJPEriLQMNhk2Rx2MgJ5QJuVQR9RNQmk5PY+mMu03L+czeWQ@mail.gmail.com>
Message-ID: <4F42C7A7.9020705@cs.oswego.edu>

On 02/20/12 15:08, Joe Bowbeer wrote:
> Is it (still) also true that it is difficult to manage multiple FJPs (because
> each one will try to achieve maximum throughput)?

While it is almost always best to use only one FJP, if your objective is
to maximize throughput, then multiple FJPs is probably still
better than alternatives. You are right that there is not usually
a simple answer when  mixing with latency concerns (as in SwingWorker)
though.

-Doug

>
> It would seem that TPE handles this better, because each pool can be configured
> to operate with limits placed on its number of threads and queued tasks. Though
> I'm not optimistic that that works well in practice when there are multiple apps
> running...  (For example, choosing a single TPE configuration that works well
> for all SwingWorker clients -- providing plenty of background processing without
> affecting the responsiveness of the UI -- is a never-ending battle.)
>
> Joe
>
> On Mon, Feb 20, 2012 at 11:07 AM, Doug Lea wrote:
>
>     (Slowly catching up with mail.)
>
>     On 02/16/12 07:06, Mohan Radhakrishnan wrote:
>
>         Does ... mean that now I can submit independent tasks to the FJ framework
>
>         without the need for a task and subtask graph and still get the benefits of
>         work stealing ?
>
>
>     You get *some* of the benefits of work-stealing -- mainly decentralized
>     queuing and much better scalability.
>
>     The main tradeoff compared to ThreadPoolExecutor is that you have less
>     control (for example no direct access to submission queues) and essentially
>     no configuration methods. (Although most people seem to agree that
>     lack of such methods and options is a feature not a bug. In part because
>     it simplifies our ability to improve internal implementations over time
>     in ways that we cannot do with TPE because it reveals so much of its
>     internal workings.)
>
>     The other tradeoff is that FJP generally uses more CPU cycles
>     and memory than TPE.
>
>     All other things being equal, as a rough rule of thumb, if you are
>     running with 4 or fewer processors/cores, you probably won't see any
>     advantage to using FJP vs TPE as an "plain" ExecutorService. And
>     for a singleton (size one) pool, TPE is clearly better.
>     On larger platforms, FJP can be almost arbitrarily faster.
>
>     -Doug
>
>
>
>
>
>
>     _________________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.__oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From radhakrishnan.mohan at gmail.com  Mon Feb 20 23:38:30 2012
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Tue, 21 Feb 2012 10:08:30 +0530
Subject: [concurrency-interest] What's the advantage of a Java-5
 ThreadPoolExecutor over a Java-7 ForkJoinPool?
In-Reply-To: <4F4299E6.5030905@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCGEBCJDAA.davidcholmes@aapt.net.au>
	<4F3B5B0C.9020205@fh-hannover.de>
	<CAHzJPEr-HU_LBXpD8mQxogwvPdLiLe4+wuStt8w4KPkBJem9qQ@mail.gmail.com>
	<CANPzfU_aS3DLa0psuMAF3P+NRacy_Ve78yhvw4HgHVAjh_LCJA@mail.gmail.com>
	<CAOoXFP9RgkYLROaRugO-Y_6Mo7FGWyrY6bzFYfwX_BGfrrrCvA@mail.gmail.com>
	<4F4299E6.5030905@cs.oswego.edu>
Message-ID: <CAOoXFP9Za4n8HjjH63mmMpiB1Jd22RASdha14+RMvP0S93UibQ@mail.gmail.com>

Thanks. Will there be some examples to look at ? Does anyone use it in
a real-time financial message procesor or something that requires high
throughput ? I have only written a simple merge sort example but that
did not fully help me learn.

Mohan

On Tue, Feb 21, 2012 at 12:37 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> (Slowly catching up with mail.)
>
> On 02/16/12 07:06, Mohan Radhakrishnan wrote:
>>
>> Does ... mean that now I can submit independent tasks to the FJ framework
>>
>> without the need for a task and subtask graph and still get the benefits
>> of
>> work stealing ?
>>
>
> You get *some* of the benefits of work-stealing -- mainly decentralized
> queuing and much better scalability.
>
> The main tradeoff compared to ThreadPoolExecutor is that you have less
> control (for example no direct access to submission queues) and essentially
> no configuration methods. (Although most people seem to agree that
> lack of such methods and options is a feature not a bug. In part because
> it simplifies our ability to improve internal implementations over time
> in ways that we cannot do with TPE because it reveals so much of its
> internal workings.)
>
> The other tradeoff is that FJP generally uses more CPU cycles
> and memory than TPE.
>
> All other things being equal, as a rough rule of thumb, if you are
> running with 4 or fewer processors/cores, you probably won't see any
> advantage to using FJP vs TPE as an "plain" ExecutorService. And
> for a singleton (size one) pool, TPE is clearly better.
> On larger platforms, FJP can be almost arbitrarily faster.
>
> -Doug
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From radhakrishnan.mohan at gmail.com  Thu Feb 23 05:16:16 2012
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 23 Feb 2012 15:46:16 +0530
Subject: [concurrency-interest] UseNUMA
Message-ID: <CAOoXFP9bQhhOhBoNJ=5wcwkfXPoP7tzrpAx56soyhDqgRUd48g@mail.gmail.com>

Hello,

It looks like a mac book with a i7 quadcore is a NUMA chip according to
http://software.intel.com/en-us/blogs/2009/03/11/learning-experience-of-numa-and-intels-next-generation-xeon-processor-i/

Is there a way to visualize using thread programs or something else
the effect of UseNUMA on thread programming ?

I was able to understand what false sharing is by looking at juc source.

Is there any such way to view an understand and explain the per-node
young gen pools that are created( Jon's blog ) ?

Thanks,
Mohan

From mjpt777 at gmail.com  Thu Feb 23 15:19:15 2012
From: mjpt777 at gmail.com (Martin Thompson)
Date: Thu, 23 Feb 2012 20:19:15 +0000
Subject: [concurrency-interest] UseNUMA
Message-ID: <CAChYfd9BHukiJwnEWDEVMp10xPxxe1pMsfkvs8YvTYvY1_C=pQ@mail.gmail.com>

Hi,

This is not my understanding of NUMA for the latter Intel CPU
architectures.  For a system to by NUMA it needs to have multiple CPU
sockets, each with local connected memory, that communicate with each other
over QPI interconnects.  It is the cost of crossing the interconnect to
access memory managed by the other socket where the costs escalate.

The UseNUMA setting is applied when you want the GC to be NUMA aware so
that when collecting memory it happens on a thread socket local to the
thread that created the memory.

Martin...


> It looks like a mac book with a i7 quadcore is a NUMA chip according to
>
> http://software.intel.com/en-us/blogs/2009/03/11/learning-experience-of-numa-and-intels-next-generation-xeon-processor-i/
>
> Is there a way to visualize using thread programs or something else
> the effect of UseNUMA on thread programming ?
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120223/d2a2a53a/attachment.html>

From oztalip at gmail.com  Fri Feb 24 10:36:02 2012
From: oztalip at gmail.com (Talip Ozturk)
Date: Fri, 24 Feb 2012 17:36:02 +0200
Subject: [concurrency-interest] Lock performance in virtualized environment
Message-ID: <CANGYBVET43w-vfPDfxWpepo8_fuLM-dHJfF9Rsmhs1a_yJv4Kg@mail.gmail.com>

Hi,

I did a simple test to see how virtualized environment affects the
performance of a multithreaded application. My test application was
creating a ConcurrentHashMap, starting 40 threads, each doing
map.put() in a while(true) loop. I ran it on my laptop (MacBookAir i7)
first and then started a Ubuntu on Parallels with same number of CPUs.
I was happy to see that both my laptop and the Ubuntu on Parallels
were doing -almost- the same number of map.put() operations per sec.
So virtualization wasn't affecting much.

Then I changed my ConcurrentHashMap to have concurrencyLevel=1 to see
how contention will affect. Performance went down on each as expected
but throughput of virtual machine was half of my laptop!

I then started playing with LockSupport.park/unpark. The results were
similar: Throughput is half on virtualized environment. I am getting
the same feeling when running my tests on Amazon EC2. Looks like
others had the same issue:
https://forums.aws.amazon.com/thread.jspa?threadID=75388

Is this a known issue? Any way to optimize it?

Thanks,
-talip

From al-javaconcurrencyinterest at none.at  Fri Feb 24 10:59:35 2012
From: al-javaconcurrencyinterest at none.at (Aleksandar Lazic)
Date: Fri, 24 Feb 2012 16:59:35 +0100
Subject: [concurrency-interest] Recursive Directory checker
Message-ID: <31a188f4e9a53f784a280a7735877cd1@none.at>

Dear list members,

I'm on the way to write a directory counter.

I'm new to all this thread/fork stuff, so please accept my apologize
for such a 'simple' question ;-)

What is the 'best' Class for such a program.

ForkJoinTask
RecursiveAction
RecursiveTask

I plan to use for the main program.

pseudocode
###
main:

  File startdir = new File("/home/user/");
  File[] files = file.listFiles()

  add directories to the Queue.

-----
I'm unsure which Queue is the best for this?

http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html

I tend to BlockingDeque
-----

   ForkJoinPool fjp = new ForkJoinPool(5);

   foreach worker
     get filesizes and $SummAtomicLong.addAndGet(filesizes);

print "the Directory and there subdirs have {} Mbytes", $SummAtomicLong

####

Worker:

   foreach directory
     if directory is not in queue
       add directory to the Queue.

   foreach file
     add filesize to $workerAtomicLong.addAndGet(file.size);
###

I hope it is a little bit clear what I want to do ;-)

No this is not a Homework ;-)

Should I use a global variable for the SummAtomicLong?
Should I use a global variable for the DirectoryQueue?

I expect that there are not more then 
'ForkJoinPool(5)'-Threads/Processes which work
on the disk, is that right?

I have try to understand some of the

http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

but I have still some questions.

Many thanks for all your help.

Cheers
Aleks

From viktor.klang at gmail.com  Fri Feb 24 11:42:27 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 24 Feb 2012 17:42:27 +0100
Subject: [concurrency-interest] Lock performance in virtualized
	environment
In-Reply-To: <CANGYBVET43w-vfPDfxWpepo8_fuLM-dHJfF9Rsmhs1a_yJv4Kg@mail.gmail.com>
References: <CANGYBVET43w-vfPDfxWpepo8_fuLM-dHJfF9Rsmhs1a_yJv4Kg@mail.gmail.com>
Message-ID: <CANPzfU_x96kDyrTgxZ3+ekkGAUDKkiiWQL3gDtSA4vv_51qB0g@mail.gmail.com>

Use a non-blocking concurrent hashmap.

Cheers
V
On Feb 24, 2012 4:42 PM, "Talip Ozturk" <oztalip at gmail.com> wrote:

> Hi,
>
> I did a simple test to see how virtualized environment affects the
> performance of a multithreaded application. My test application was
> creating a ConcurrentHashMap, starting 40 threads, each doing
> map.put() in a while(true) loop. I ran it on my laptop (MacBookAir i7)
> first and then started a Ubuntu on Parallels with same number of CPUs.
> I was happy to see that both my laptop and the Ubuntu on Parallels
> were doing -almost- the same number of map.put() operations per sec.
> So virtualization wasn't affecting much.
>
> Then I changed my ConcurrentHashMap to have concurrencyLevel=1 to see
> how contention will affect. Performance went down on each as expected
> but throughput of virtual machine was half of my laptop!
>
> I then started playing with LockSupport.park/unpark. The results were
> similar: Throughput is half on virtualized environment. I am getting
> the same feeling when running my tests on Amazon EC2. Looks like
> others had the same issue:
> https://forums.aws.amazon.com/thread.jspa?threadID=75388
>
> Is this a known issue? Any way to optimize it?
>
> Thanks,
> -talip
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120224/5d8e6ebf/attachment.html>

From nathan.reynolds at oracle.com  Fri Feb 24 12:52:30 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 24 Feb 2012 10:52:30 -0700
Subject: [concurrency-interest] Recursive Directory checker
In-Reply-To: <31a188f4e9a53f784a280a7735877cd1@none.at>
References: <31a188f4e9a53f784a280a7735877cd1@none.at>
Message-ID: <4F47CE5E.3010805@oracle.com>

I would like to point out that hard disks perform best when accessed in 
a single threaded manner.  If you have 2 threads making requests, then 
the disk head will have to swing back and forth between the 2 
locations.  With only 1 thread, the disk head doesn't have to travel as 
much.  Flash disks (SSDs) are a different story.  We have seen optimal 
throughput when 16 threads hit the disk concurrently.  Your mileage will 
vary depending upon the SSD.  So, you may not get much better 
performance from your directory size counter by using multiple threads.

I have found on Windows that defragmenting the hard drive and placing 
all of the directory meta data together makes this kind of thing run 
really fast.  (See MyDefrag). The disk head simply has to sit on the 
directory meta data section of the hard disk.  I realize you aren't 
running on Windows.  But, you might consider something similar.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 2/24/2012 8:59 AM, Aleksandar Lazic wrote:
> Dear list members,
>
> I'm on the way to write a directory counter.
>
> I'm new to all this thread/fork stuff, so please accept my apologize
> for such a 'simple' question ;-)
>
> What is the 'best' Class for such a program.
>
> ForkJoinTask
> RecursiveAction
> RecursiveTask
>
> I plan to use for the main program.
>
> pseudocode
> ###
> main:
>
>  File startdir = new File("/home/user/");
>  File[] files = file.listFiles()
>
>  add directories to the Queue.
>
> -----
> I'm unsure which Queue is the best for this?
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html
>
> I tend to BlockingDeque
> -----
>
>   ForkJoinPool fjp = new ForkJoinPool(5);
>
>   foreach worker
>     get filesizes and $SummAtomicLong.addAndGet(filesizes);
>
> print "the Directory and there subdirs have {} Mbytes", $SummAtomicLong
>
> ####
>
> Worker:
>
>   foreach directory
>     if directory is not in queue
>       add directory to the Queue.
>
>   foreach file
>     add filesize to $workerAtomicLong.addAndGet(file.size);
> ###
>
> I hope it is a little bit clear what I want to do ;-)
>
> No this is not a Homework ;-)
>
> Should I use a global variable for the SummAtomicLong?
> Should I use a global variable for the DirectoryQueue?
>
> I expect that there are not more then 
> 'ForkJoinPool(5)'-Threads/Processes which work
> on the disk, is that right?
>
> I have try to understand some of the
>
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
>
> but I have still some questions.
>
> Many thanks for all your help.
>
> Cheers
> Aleks
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120224/2d7d9ed8/attachment.html>

From nathan.reynolds at oracle.com  Fri Feb 24 12:59:05 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 24 Feb 2012 10:59:05 -0700
Subject: [concurrency-interest] Lock performance in virtualized
	environment
In-Reply-To: <CANPzfU_x96kDyrTgxZ3+ekkGAUDKkiiWQL3gDtSA4vv_51qB0g@mail.gmail.com>
References: <CANGYBVET43w-vfPDfxWpepo8_fuLM-dHJfF9Rsmhs1a_yJv4Kg@mail.gmail.com>
	<CANPzfU_x96kDyrTgxZ3+ekkGAUDKkiiWQL3gDtSA4vv_51qB0g@mail.gmail.com>
Message-ID: <4F47CFE9.6030800@oracle.com>

park()/unpark() and wait()/notify() both go into the kernel.  Inside the 
kernel, the scheduler logic has to send a software interrupt to another 
idling core to get it to wake up and start running the signaled thread.  
These interrupts are a lot more expensive in a virtualized environment.  
They can cause traps out to the hypervisor.  Check the system CPU time 
on both and see if in the virtualized environment it is higher.  If so, 
this might be on the right track.  There might be some tuning you can do 
with Parallels to get your test to perform better.  On the other hand, 
if all of the cores are 100% busy, then the software interrupt won't be 
necessary to wake up the idling core.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 2/24/2012 9:42 AM, ?iktor ?lang wrote:
>
> Use a non-blocking concurrent hashmap.
>
> Cheers
> V
>
> On Feb 24, 2012 4:42 PM, "Talip Ozturk" <oztalip at gmail.com 
> <mailto:oztalip at gmail.com>> wrote:
>
>     Hi,
>
>     I did a simple test to see how virtualized environment affects the
>     performance of a multithreaded application. My test application was
>     creating a ConcurrentHashMap, starting 40 threads, each doing
>     map.put() in a while(true) loop. I ran it on my laptop (MacBookAir i7)
>     first and then started a Ubuntu on Parallels with same number of CPUs.
>     I was happy to see that both my laptop and the Ubuntu on Parallels
>     were doing -almost- the same number of map.put() operations per sec.
>     So virtualization wasn't affecting much.
>
>     Then I changed my ConcurrentHashMap to have concurrencyLevel=1 to see
>     how contention will affect. Performance went down on each as expected
>     but throughput of virtual machine was half of my laptop!
>
>     I then started playing with LockSupport.park/unpark. The results were
>     similar: Throughput is half on virtualized environment. I am getting
>     the same feeling when running my tests on Amazon EC2. Looks like
>     others had the same issue:
>     https://forums.aws.amazon.com/thread.jspa?threadID=75388
>
>     Is this a known issue? Any way to optimize it?
>
>     Thanks,
>     -talip
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120224/84dd27ca/attachment.html>

From lists at laerad.com  Fri Feb 24 13:29:42 2012
From: lists at laerad.com (Benedict Elliott Smith)
Date: Fri, 24 Feb 2012 18:29:42 +0000
Subject: [concurrency-interest] Recursive Directory checker
In-Reply-To: <4F47CE5E.3010805@oracle.com>
References: <31a188f4e9a53f784a280a7735877cd1@none.at>
	<4F47CE5E.3010805@oracle.com>
Message-ID: <CACr06N0tPX-3tvBOpGPt-8EtmHDBrkYibC48CgyyegFFaBfRkA@mail.gmail.com>

I hate to nitpick, but this is only true for sequential reads; as soon as
you devolve to random IO (and for large directory trees metadata traversal
is unlikely at best to remain sequential, even if there are no other
competing IO requests) you are much better with multiple ops in flight so
the disk can select the order it services them and to some degree maximize
throughput. When performance testing new file servers I have found single
threaded random IOPs are typically dreadful, even with dozens of disks.

In my experience a multi-threaded directory traversal has usually been
considerably faster than single threaded.

I don't think the choice of queue is likely to have a material impact on
the performance of this algorithm, Aleksandar; IO will be your bottleneck.
However, I think the use of a queue defeats the point of using the ForkJoin
framework.


On 24 February 2012 17:52, Nathan Reynolds <nathan.reynolds at oracle.com>wrote:

>  I would like to point out that hard disks perform best when accessed in a
> single threaded manner.  If you have 2 threads making requests, then the
> disk head will have to swing back and forth between the 2 locations.  With
> only 1 thread, the disk head doesn't have to travel as much.  Flash disks
> (SSDs) are a different story.  We have seen optimal throughput when 16
> threads hit the disk concurrently.  Your mileage will vary depending upon
> the SSD.  So, you may not get much better performance from your directory
> size counter by using multiple threads.
>
> I have found on Windows that defragmenting the hard drive and placing all
> of the directory meta data together makes this kind of thing run really
> fast.  (See MyDefrag). The disk head simply has to sit on the directory
> meta data section of the hard disk.  I realize you aren't running on
> Windows.  But, you might consider something similar.
>
>  Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 2/24/2012 8:59 AM, Aleksandar Lazic wrote:
>
> Dear list members,
>
> I'm on the way to write a directory counter.
>
> I'm new to all this thread/fork stuff, so please accept my apologize
> for such a 'simple' question ;-)
>
> What is the 'best' Class for such a program.
>
> ForkJoinTask
> RecursiveAction
> RecursiveTask
>
> I plan to use for the main program.
>
> pseudocode
> ###
> main:
>
>  File startdir = new File("/home/user/");
>  File[] files = file.listFiles()
>
>  add directories to the Queue.
>
> -----
> I'm unsure which Queue is the best for this?
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html
>
> I tend to BlockingDeque
> -----
>
>   ForkJoinPool fjp = new ForkJoinPool(5);
>
>   foreach worker
>     get filesizes and $SummAtomicLong.addAndGet(filesizes);
>
> print "the Directory and there subdirs have {} Mbytes", $SummAtomicLong
>
> ####
>
> Worker:
>
>   foreach directory
>     if directory is not in queue
>       add directory to the Queue.
>
>   foreach file
>     add filesize to $workerAtomicLong.addAndGet(file.size);
> ###
>
> I hope it is a little bit clear what I want to do ;-)
>
> No this is not a Homework ;-)
>
> Should I use a global variable for the SummAtomicLong?
> Should I use a global variable for the DirectoryQueue?
>
> I expect that there are not more then 'ForkJoinPool(5)'-Threads/Processes
> which work
> on the disk, is that right?
>
> I have try to understand some of the
>
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
>
> but I have still some questions.
>
> Many thanks for all your help.
>
> Cheers
> Aleks
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120224/9142e269/attachment-0001.html>

From al-javaconcurrencyinterest at none.at  Fri Feb 24 14:21:47 2012
From: al-javaconcurrencyinterest at none.at (Aleksandar Lazic)
Date: Fri, 24 Feb 2012 20:21:47 +0100
Subject: [concurrency-interest] Recursive Directory checker
In-Reply-To: <CACr06N0tPX-3tvBOpGPt-8EtmHDBrkYibC48CgyyegFFaBfRkA@mail.gmail.com>
References: <31a188f4e9a53f784a280a7735877cd1@none.at>
	<4F47CE5E.3010805@oracle.com>
	<CACr06N0tPX-3tvBOpGPt-8EtmHDBrkYibC48CgyyegFFaBfRkA@mail.gmail.com>
Message-ID: <5f6a6d2ea2122aff907d07afd68a3f1d@none.at>

 

Hi, 

we scan over a NAS Share (NFS Netapp Filer), due to this fact
I don't think that the deep 

disk handling is in my hand. 

I use
currently the IO:AIO program treescan from the IO:AIO perl module


http://cvs.schmorp.de/IO-AIO/bin/treescan?view=markup 

which use 8
thread to collect the necessary data. 

The both links below shows my
description from the perl point of view


http://lists.schmorp.de/pipermail/anyevent/2012q1/000227.html


http://lists.schmorp.de/pipermail/anyevent/2012q1/000231.html 

The
reason why I want to switch to Java is that i need solution which I
'just' 

need to extract and run not to install a lot of modules for the
dedicated script language. 

Please can you tell me what do you suggest
to handle the directories which are already scanned? 

Best regards


Aleks 

On 24-02-2012 19:29, Benedict Elliott Smith wrote: 

> I hate
to nitpick, but this is only true for sequential reads; as soon as you
devolve to random IO (and for large directory trees metadata traversal
is unlikely at best to remain sequential, even if there are no other
competing IO requests) you are much better with multiple ops in flight
so the disk can select the order it services them and to some degree
maximize throughput. When performance testing new file servers I have
found single threaded random IOPs are typically dreadful, even with
dozens of disks. 
> In my experience a multi-threaded directory
traversal has usually been considerably faster than single threaded. 
>
I don't think the choice of queue is likely to have a material impact on
the performance of this algorithm, Aleksandar; IO will be your
bottleneck. However, I think the use of a queue defeats the point of
using the ForkJoin framework. 
> On 24 February 2012 17:52, Nathan
Reynolds <nathan.reynolds at oracle.com [9]> wrote:
> 
>> I would like to
point out that hard disks perform best when accessed in a single
threaded manner. If you have 2 threads making requests, then the disk
head will have to swing back and forth between the 2 locations. With
only 1 thread, the disk head doesn't have to travel as much. Flash disks
(SSDs) are a different story. We have seen optimal throughput when 16
threads hit the disk concurrently. Your mileage will vary depending upon
the SSD. So, you may not get much better performance from your directory
size counter by using multiple threads.
>> 
>> I have found on Windows
that defragmenting the hard drive and placing all of the directory meta
data together makes this kind of thing run really fast. (See MyDefrag).
The disk head simply has to sit on the directory meta data section of
the hard disk. I realize you aren't running on Windows. But, you might
consider something similar.
>> 
>> Nathan Reynolds [5] | Consulting
Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering [6] |
Server Technology 
>> 
>> On 2/24/2012 8:59 AM, Aleksandar Lazic wrote:

>> 
>>> Dear list members, 
>>> 
>>> I'm on the way to write a
directory counter. 
>>> 
>>> I'm new to all this thread/fork stuff, so
please accept my apologize 
>>> for such a 'simple' question ;-) 
>>>

>>> What is the 'best' Class for such a program. 
>>> 
>>> ForkJoinTask

>>> RecursiveAction 
>>> RecursiveTask 
>>> 
>>> I plan to use for the
main program. 
>>> 
>>> pseudocode 
>>> ### 
>>> main: 
>>> 
>>> File
startdir = new File("/home/user/"); 
>>> File[] files = file.listFiles()

>>> 
>>> add directories to the Queue. 
>>> 
>>> ----- 
>>> I'm unsure
which Queue is the best for this? 
>>> 
>>>
http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html [1]

>>> 
>>> I tend to BlockingDeque 
>>> ----- 
>>> 
>>> ForkJoinPool fjp
= new ForkJoinPool(5); 
>>> 
>>> foreach worker 
>>> get filesizes and
$SummAtomicLong.addAndGet(filesizes); 
>>> 
>>> print "the Directory and
there subdirs have {} Mbytes", $SummAtomicLong 
>>> 
>>> #### 
>>> 
>>>
Worker: 
>>> 
>>> foreach directory 
>>> if directory is not in queue

>>> add directory to the Queue. 
>>> 
>>> foreach file 
>>> add
filesize to $workerAtomicLong.addAndGet(file.size); 
>>> ### 
>>> 
>>> I
hope it is a little bit clear what I want to do ;-) 
>>> 
>>> No this is
not a Homework ;-) 
>>> 
>>> Should I use a global variable for the
SummAtomicLong? 
>>> Should I use a global variable for the
DirectoryQueue? 
>>> 
>>> I expect that there are not more then
'ForkJoinPool(5)'-Threads/Processes which work 
>>> on the disk, is that
right? 
>>> 
>>> I have try to understand some of the 
>>> 
>>>
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/ [2]

>>> 
>>> but I have still some questions. 
>>> 
>>> Many thanks for all
your help. 
>>> 
>>> Cheers 
>>> Aleks 
>>>
_______________________________________________ 
>>>
Concurrency-interest mailing list 
>>>
Concurrency-interest at cs.oswego.edu [3] 
>>>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest [4]
>> 
>>
_______________________________________________
>> Concurrency-interest
mailing list
>> Concurrency-interest at cs.oswego.edu [7]
>>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest [8]



Links:
------
[1]
http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html
[2]
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
[3]
mailto:Concurrency-interest at cs.oswego.edu
[4]
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
[5]
http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds
[6]
http://psr.us.oracle.com/
[7]
mailto:Concurrency-interest at cs.oswego.edu
[8]
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
[9]
mailto:nathan.reynolds at oracle.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120224/8e759f61/attachment.html>

From lists at laerad.com  Sun Feb 26 14:32:38 2012
From: lists at laerad.com (Benedict Elliott Smith)
Date: Sun, 26 Feb 2012 19:32:38 +0000
Subject: [concurrency-interest] Recursive Directory checker
In-Reply-To: <5f6a6d2ea2122aff907d07afd68a3f1d@none.at>
References: <31a188f4e9a53f784a280a7735877cd1@none.at>
	<4F47CE5E.3010805@oracle.com>
	<CACr06N0tPX-3tvBOpGPt-8EtmHDBrkYibC48CgyyegFFaBfRkA@mail.gmail.com>
	<5f6a6d2ea2122aff907d07afd68a3f1d@none.at>
Message-ID: <CACr06N1QZWxgJT_nPHb9Xe+20m25nLrG1un2k4-Y-kZW5ttFhw@mail.gmail.com>

It depends what you want to achieve. If I were solving this problem I would
choose to simply not follow sym-links, as this is the simplest way to
ensure you never visit a directory more than once (excepting concurrent
modifications of the directory structure which are difficult to deal with
on a remote file system anyway)


On 24 February 2012 19:21, Aleksandar Lazic <
al-javaconcurrencyinterest at none.at> wrote:

> **
>
> Hi,
>
> we scan over a NAS Share (NFS Netapp Filer), due to this fact I don't
> think that the deep
>
> disk handling is in my hand.
>
>
>
> I use currently the IO:AIO program treescan from the IO:AIO perl module
>
> http://cvs.schmorp.de/IO-AIO/bin/treescan?view=markup
>
> which use 8 thread to collect the necessary data.
>
>
>
> The both links below shows my description from the perl point of view
>
> http://lists.schmorp.de/pipermail/anyevent/2012q1/000227.html
>
> http://lists.schmorp.de/pipermail/anyevent/2012q1/000231.html
>
>
>
> The reason why I want to switch to Java is that i need solution which I
> 'just'
>
> need to extract and run not to install a lot of modules for the dedicated
> script language.
>
> Please can you tell me what do you suggest to handle the directories which
> are already scanned?
>
> Best regards
>
> Aleks
>
> On 24-02-2012 19:29, Benedict Elliott Smith wrote:
>
> I hate to nitpick, but this is only true for sequential reads; as soon as
> you devolve to random IO (and for large directory trees metadata traversal
> is unlikely at best to remain sequential, even if there are no other
> competing IO requests) you are much better with multiple ops in flight so
> the disk can select the order it services them and to some degree maximize
> throughput. When performance testing new file servers I have found single
> threaded random IOPs are typically dreadful, even with dozens of disks.
> In my experience a multi-threaded directory traversal has usually been
> considerably faster than single threaded.
> I don't think the choice of queue is likely to have a material impact on
> the performance of this algorithm, Aleksandar; IO will be your bottleneck.
> However, I think the use of a queue defeats the point of using the ForkJoin
> framework.
> On 24 February 2012 17:52, Nathan Reynolds <nathan.reynolds at oracle.com>wrote:
>
>> I would like to point out that hard disks perform best when accessed in a
>> single threaded manner.  If you have 2 threads making requests, then the
>> disk head will have to swing back and forth between the 2 locations.  With
>> only 1 thread, the disk head doesn't have to travel as much.  Flash disks
>> (SSDs) are a different story.  We have seen optimal throughput when 16
>> threads hit the disk concurrently.  Your mileage will vary depending upon
>> the SSD.  So, you may not get much better performance from your directory
>> size counter by using multiple threads.
>>
>> I have found on Windows that defragmenting the hard drive and placing all
>> of the directory meta data together makes this kind of thing run really
>> fast.  (See MyDefrag). The disk head simply has to sit on the directory
>> meta data section of the hard disk.  I realize you aren't running on
>> Windows.  But, you might consider something similar.
>>
>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>> 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 2/24/2012 8:59 AM, Aleksandar Lazic wrote:
>>
>> Dear list members,
>>
>> I'm on the way to write a directory counter.
>>
>> I'm new to all this thread/fork stuff, so please accept my apologize
>> for such a 'simple' question ;-)
>>
>> What is the 'best' Class for such a program.
>>
>> ForkJoinTask
>> RecursiveAction
>> RecursiveTask
>>
>> I plan to use for the main program.
>>
>> pseudocode
>> ###
>> main:
>>
>>  File startdir = new File("/home/user/");
>>  File[] files = file.listFiles()
>>
>>  add directories to the Queue.
>>
>> -----
>> I'm unsure which Queue is the best for this?
>>
>> http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/Queue.html
>>
>> I tend to BlockingDeque
>> -----
>>
>>   ForkJoinPool fjp = new ForkJoinPool(5);
>>
>>   foreach worker
>>     get filesizes and $SummAtomicLong.addAndGet(filesizes);
>>
>> print "the Directory and there subdirs have {} Mbytes", $SummAtomicLong
>>
>> ####
>>
>> Worker:
>>
>>   foreach directory
>>     if directory is not in queue
>>       add directory to the Queue.
>>
>>   foreach file
>>     add filesize to $workerAtomicLong.addAndGet(file.size);
>> ###
>>
>> I hope it is a little bit clear what I want to do ;-)
>>
>> No this is not a Homework ;-)
>>
>> Should I use a global variable for the SummAtomicLong?
>> Should I use a global variable for the DirectoryQueue?
>>
>> I expect that there are not more then 'ForkJoinPool(5)'-Threads/Processes
>> which work
>> on the disk, is that right?
>>
>> I have try to understand some of the
>>
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
>>
>> but I have still some questions.
>>
>> Many thanks for all your help.
>>
>> Cheers
>> Aleks
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120226/90d573d5/attachment.html>

From peter.firmstone at zeus.net.au  Wed Feb 29 08:37:16 2012
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Wed, 29 Feb 2012 23:37:16 +1000
Subject: [concurrency-interest] Scalable object cache
Message-ID: <1330522636.21014.848.camel@bluto>

I don't have the hardware to test this so I'm hoping someone on the list
will know.

In the class below, the get() method returns the referent, provided it
hasn't been enqueued.

Both read and clock are volatile, clock is written to, once every 10
seconds (or an interval the developer sets) by a single thread.

if (read < clock) read = clock; //Avoid unnecessary volatile write.

If many threads are retrieving the referent, the volatile read variable
is written at least once in between clock updates, but any further
retrievals will only be reads.

So in this case the volatile long values are multi read, with occasional
writes, does get() look scalable to you?

Regards,

Peter.

/*
 * Copyright 2012 Zeus Project Services Pty Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package au.net.zeus.collection;

/**
 * 
 * @author Peter Firmstone.
 */
class TimedReferrer<T> implements Referrer<T>, TimeBomb {
    
    private volatile long clock;
    private volatile long read;
    private final TimedRefQueue queue;
    private volatile T referent;
    private volatile boolean enqued;
    private final Object lock;
    private final int hash;
    
    TimedReferrer(T k, TimedRefQueue q){
        long time = System.nanoTime();
        clock = time;
        read = time;
        referent = k;
        queue = q;
        enqued = false;
        lock = new Object();
        int hash = 7;
        hash = 29 * hash + k.hashCode();
        hash = 29 * hash + k.getClass().hashCode();
        this.hash = hash;
    }

    public T get() {
        // Doesn't need to be atomic.
        if (read < clock) read = clock; //Avoid unnecessary volatile
write.
        return referent;
    }

    public void clear() {
        referent = null;
    }

    public boolean isEnqueued() {
        return enqued;
    }

    public boolean enqueue() {
        if (enqued) return false;
        if (referent == null) return false;
        if (queue == null) return false;
        synchronized (lock){ // Sync for atomic write of enqued.
            if (enqued) return false;
            enqued = queue.offer(this);
        }
        return enqued;
    }
    
    @Override
    public void updateClock(long time){
        if (read < clock) { // only write volatile if necessary.
            enqueue();
            clear();
        } else {
            clock = time;
        }
    }
    
    @Override
    public boolean equals(Object o) {
        if (this == o)  return true; // Same reference.
        if (!(o instanceof Referrer))  return false;
        Object k1 = get();
        Object k2 = ((Referrer) o).get();
        if ( k1 != null && k1.equals(k2)) return true;
        return ( k1 == null && k2 == null && hashCode() ==
o.hashCode()); // Both objects were collected.
    }

    @Override
    public int hashCode() {
        Object k = get();
        int hash = 7;
        if (k != null) {
            hash = 29 * hash + k.hashCode();
            hash = 29 * hash + k.getClass().hashCode();
        } else {
            hash = this.hash;
        }
        return hash;
    }
    
    @Override
    public String toString(){
        Object s = get();
        if (s != null) return s.toString();
        return super.toString();
    }
    
}


From viktor.klang at gmail.com  Wed Feb 29 09:39:43 2012
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 29 Feb 2012 15:39:43 +0100
Subject: [concurrency-interest] Scalable object cache
In-Reply-To: <1330522636.21014.848.camel@bluto>
References: <1330522636.21014.848.camel@bluto>
Message-ID: <CANPzfU9jN5_ioxjVpiS4jFTTPU4AnPih2RXRg44j0-QvNeSz5w@mail.gmail.com>

Sooo, you're saying that toString, hashCode and equals will only ever be
called by the Thread that calls get()?

On Wed, Feb 29, 2012 at 2:37 PM, Peter Firmstone <
peter.firmstone at zeus.net.au> wrote:

> I don't have the hardware to test this so I'm hoping someone on the list
> will know.
>
> In the class below, the get() method returns the referent, provided it
> hasn't been enqueued.
>
> Both read and clock are volatile, clock is written to, once every 10
> seconds (or an interval the developer sets) by a single thread.
>
> if (read < clock) read = clock; //Avoid unnecessary volatile write.
>
> If many threads are retrieving the referent, the volatile read variable
> is written at least once in between clock updates, but any further
> retrievals will only be reads.
>
> So in this case the volatile long values are multi read, with occasional
> writes, does get() look scalable to you?
>
> Regards,
>
> Peter.
>
> /*
>  * Copyright 2012 Zeus Project Services Pty Ltd.
>  *
>  * Licensed under the Apache License, Version 2.0 (the "License");
>  * you may not use this file except in compliance with the License.
>  * You may obtain a copy of the License at
>  *
>  *      http://www.apache.org/licenses/LICENSE-2.0
>  *
>  * Unless required by applicable law or agreed to in writing, software
>  * distributed under the License is distributed on an "AS IS" BASIS,
>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
> implied.
>  * See the License for the specific language governing permissions and
>  * limitations under the License.
>  */
> package au.net.zeus.collection;
>
> /**
>  *
>  * @author Peter Firmstone.
>  */
> class TimedReferrer<T> implements Referrer<T>, TimeBomb {
>
>    private volatile long clock;
>    private volatile long read;
>    private final TimedRefQueue queue;
>    private volatile T referent;
>    private volatile boolean enqued;
>    private final Object lock;
>    private final int hash;
>
>    TimedReferrer(T k, TimedRefQueue q){
>        long time = System.nanoTime();
>        clock = time;
>        read = time;
>        referent = k;
>        queue = q;
>        enqued = false;
>        lock = new Object();
>        int hash = 7;
>        hash = 29 * hash + k.hashCode();
>        hash = 29 * hash + k.getClass().hashCode();
>        this.hash = hash;
>    }
>
>    public T get() {
>        // Doesn't need to be atomic.
>        if (read < clock) read = clock; //Avoid unnecessary volatile
> write.
>        return referent;
>    }
>
>    public void clear() {
>        referent = null;
>    }
>
>    public boolean isEnqueued() {
>        return enqued;
>    }
>
>    public boolean enqueue() {
>        if (enqued) return false;
>        if (referent == null) return false;
>        if (queue == null) return false;
>        synchronized (lock){ // Sync for atomic write of enqued.
>            if (enqued) return false;
>            enqued = queue.offer(this);
>        }
>        return enqued;
>    }
>
>    @Override
>    public void updateClock(long time){
>        if (read < clock) { // only write volatile if necessary.
>            enqueue();
>            clear();
>        } else {
>            clock = time;
>        }
>    }
>
>    @Override
>    public boolean equals(Object o) {
>        if (this == o)  return true; // Same reference.
>        if (!(o instanceof Referrer))  return false;
>        Object k1 = get();
>        Object k2 = ((Referrer) o).get();
>        if ( k1 != null && k1.equals(k2)) return true;
>        return ( k1 == null && k2 == null && hashCode() ==
> o.hashCode()); // Both objects were collected.
>    }
>
>    @Override
>    public int hashCode() {
>        Object k = get();
>        int hash = 7;
>        if (k != null) {
>            hash = 29 * hash + k.hashCode();
>            hash = 29 * hash + k.getClass().hashCode();
>        } else {
>            hash = this.hash;
>        }
>        return hash;
>    }
>
>    @Override
>    public String toString(){
>        Object s = get();
>        if (s != null) return s.toString();
>        return super.toString();
>    }
>
> }
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - The software stack for applications
that scale

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120229/a3cd1293/attachment.html>

From nathan.reynolds at oracle.com  Wed Feb 29 11:18:23 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 29 Feb 2012 09:18:23 -0700
Subject: [concurrency-interest] Scalable object cache
In-Reply-To: <1330522636.21014.848.camel@bluto>
References: <1330522636.21014.848.camel@bluto>
Message-ID: <4F4E4FCF.20803@oracle.com>

While clock is constant, get() will scale very well.  So, the only 
concern is an occasional scalability issue when clock is updated.  The 
problem will show up as high CPU usage.

Every time clock is updated in the worst case, each thread will detect 
that "read" is behind and write to "read".  The fence after the write 
won't be a scalability issue.  The act of invalidating and updating the 
cache line holding "read" will be a bottleneck.  Unless the optimizer 
moves instructions in between, the window of vulnerability is very small 
(i.e. 1-2 instructions). Most likely only 1 thread is going to do the 
update.  Rarely 2 threads will.  So, I highly doubt you will have any 
trouble from get().

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 2/29/2012 6:37 AM, Peter Firmstone wrote:
> I don't have the hardware to test this so I'm hoping someone on the list
> will know.
>
> In the class below, the get() method returns the referent, provided it
> hasn't been enqueued.
>
> Both read and clock are volatile, clock is written to, once every 10
> seconds (or an interval the developer sets) by a single thread.
>
> if (read<  clock) read = clock; //Avoid unnecessary volatile write.
>
> If many threads are retrieving the referent, the volatile read variable
> is written at least once in between clock updates, but any further
> retrievals will only be reads.
>
> So in this case the volatile long values are multi read, with occasional
> writes, does get() look scalable to you?
>
> Regards,
>
> Peter.
>
> /*
>   * Copyright 2012 Zeus Project Services Pty Ltd.
>   *
>   * Licensed under the Apache License, Version 2.0 (the "License");
>   * you may not use this file except in compliance with the License.
>   * You may obtain a copy of the License at
>   *
>   *      http://www.apache.org/licenses/LICENSE-2.0
>   *
>   * Unless required by applicable law or agreed to in writing, software
>   * distributed under the License is distributed on an "AS IS" BASIS,
>   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
> implied.
>   * See the License for the specific language governing permissions and
>   * limitations under the License.
>   */
> package au.net.zeus.collection;
>
> /**
>   *
>   * @author Peter Firmstone.
>   */
> class TimedReferrer<T>  implements Referrer<T>, TimeBomb {
>
>      private volatile long clock;
>      private volatile long read;
>      private final TimedRefQueue queue;
>      private volatile T referent;
>      private volatile boolean enqued;
>      private final Object lock;
>      private final int hash;
>
>      TimedReferrer(T k, TimedRefQueue q){
>          long time = System.nanoTime();
>          clock = time;
>          read = time;
>          referent = k;
>          queue = q;
>          enqued = false;
>          lock = new Object();
>          int hash = 7;
>          hash = 29 * hash + k.hashCode();
>          hash = 29 * hash + k.getClass().hashCode();
>          this.hash = hash;
>      }
>
>      public T get() {
>          // Doesn't need to be atomic.
>          if (read<  clock) read = clock; //Avoid unnecessary volatile
> write.
>          return referent;
>      }
>
>      public void clear() {
>          referent = null;
>      }
>
>      public boolean isEnqueued() {
>          return enqued;
>      }
>
>      public boolean enqueue() {
>          if (enqued) return false;
>          if (referent == null) return false;
>          if (queue == null) return false;
>          synchronized (lock){ // Sync for atomic write of enqued.
>              if (enqued) return false;
>              enqued = queue.offer(this);
>          }
>          return enqued;
>      }
>
>      @Override
>      public void updateClock(long time){
>          if (read<  clock) { // only write volatile if necessary.
>              enqueue();
>              clear();
>          } else {
>              clock = time;
>          }
>      }
>
>      @Override
>      public boolean equals(Object o) {
>          if (this == o)  return true; // Same reference.
>          if (!(o instanceof Referrer))  return false;
>          Object k1 = get();
>          Object k2 = ((Referrer) o).get();
>          if ( k1 != null&&  k1.equals(k2)) return true;
>          return ( k1 == null&&  k2 == null&&  hashCode() ==
> o.hashCode()); // Both objects were collected.
>      }
>
>      @Override
>      public int hashCode() {
>          Object k = get();
>          int hash = 7;
>          if (k != null) {
>              hash = 29 * hash + k.hashCode();
>              hash = 29 * hash + k.getClass().hashCode();
>          } else {
>              hash = this.hash;
>          }
>          return hash;
>      }
>
>      @Override
>      public String toString(){
>          Object s = get();
>          if (s != null) return s.toString();
>          return super.toString();
>      }
>
> }
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120229/082e6f8f/attachment-0001.html>

From peter.firmstone at zeus.net.au  Wed Feb 29 15:40:45 2012
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Thu, 01 Mar 2012 06:40:45 +1000
Subject: [concurrency-interest] Scalable object cache
In-Reply-To: <4F4E4FCF.20803@oracle.com>
References: <1330522636.21014.848.camel@bluto>  <4F4E4FCF.20803@oracle.com>
Message-ID: <1330548045.21014.851.camel@bluto>

Thanks Nathan,

That's the sort of info I'm after, I don't have access to the hardware
I'm targeting unfortunately.

Cheers,

Peter.

On Thu, 2012-03-01 at 02:18, Nathan Reynolds wrote:
> While clock is constant, get() will scale very well.  So, the only
> concern is an occasional scalability issue when clock is updated.  The
> problem will show up as high CPU usage.
> 
> Every time clock is updated in the worst case, each thread will detect
> that "read" is behind and write to "read".  The fence after the write
> won't be a scalability issue.  The act of invalidating and updating
> the cache line holding "read" will be a bottleneck.  Unless the
> optimizer moves instructions in between, the window of vulnerability
> is very small (i.e. 1-2 instructions). Most likely only 1 thread is
> going to do the update.  Rarely 2 threads will.  So, I highly doubt
> you will have any trouble from get().
> 
> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering | Server Technology
> 
> On 2/29/2012 6:37 AM, Peter Firmstone wrote: 
> > I don't have the hardware to test this so I'm hoping someone on the list
> > will know.
> > 
> > In the class below, the get() method returns the referent, provided it
> > hasn't been enqueued.
> > 
> > Both read and clock are volatile, clock is written to, once every 10
> > seconds (or an interval the developer sets) by a single thread.
> > 
> > if (read < clock) read = clock; //Avoid unnecessary volatile write.
> > 
> > If many threads are retrieving the referent, the volatile read variable
> > is written at least once in between clock updates, but any further
> > retrievals will only be reads.
> > 
> > So in this case the volatile long values are multi read, with occasional
> > writes, does get() look scalable to you?
> > 
> > Regards,
> > 
> > Peter.
> > 
> > /*
> >  * Copyright 2012 Zeus Project Services Pty Ltd.
> >  *
> >  * Licensed under the Apache License, Version 2.0 (the "License");
> >  * you may not use this file except in compliance with the License.
> >  * You may obtain a copy of the License at
> >  *
> >  *      http://www.apache.org/licenses/LICENSE-2.0
> >  *
> >  * Unless required by applicable law or agreed to in writing, software
> >  * distributed under the License is distributed on an "AS IS" BASIS,
> >  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
> > implied.
> >  * See the License for the specific language governing permissions and
> >  * limitations under the License.
> >  */
> > package au.net.zeus.collection;
> > 
> > /**
> >  * 
> >  * @author Peter Firmstone.
> >  */
> > class TimedReferrer<T> implements Referrer<T>, TimeBomb {
> >     
> >     private volatile long clock;
> >     private volatile long read;
> >     private final TimedRefQueue queue;
> >     private volatile T referent;
> >     private volatile boolean enqued;
> >     private final Object lock;
> >     private final int hash;
> >     
> >     TimedReferrer(T k, TimedRefQueue q){
> >         long time = System.nanoTime();
> >         clock = time;
> >         read = time;
> >         referent = k;
> >         queue = q;
> >         enqued = false;
> >         lock = new Object();
> >         int hash = 7;
> >         hash = 29 * hash + k.hashCode();
> >         hash = 29 * hash + k.getClass().hashCode();
> >         this.hash = hash;
> >     }
> > 
> >     public T get() {
> >         // Doesn't need to be atomic.
> >         if (read < clock) read = clock; //Avoid unnecessary volatile
> > write.
> >         return referent;
> >     }
> > 
> >     public void clear() {
> >         referent = null;
> >     }
> > 
> >     public boolean isEnqueued() {
> >         return enqued;
> >     }
> > 
> >     public boolean enqueue() {
> >         if (enqued) return false;
> >         if (referent == null) return false;
> >         if (queue == null) return false;
> >         synchronized (lock){ // Sync for atomic write of enqued.
> >             if (enqued) return false;
> >             enqued = queue.offer(this);
> >         }
> >         return enqued;
> >     }
> >     
> >     @Override
> >     public void updateClock(long time){
> >         if (read < clock) { // only write volatile if necessary.
> >             enqueue();
> >             clear();
> >         } else {
> >             clock = time;
> >         }
> >     }
> >     
> >     @Override
> >     public boolean equals(Object o) {
> >         if (this == o)  return true; // Same reference.
> >         if (!(o instanceof Referrer))  return false;
> >         Object k1 = get();
> >         Object k2 = ((Referrer) o).get();
> >         if ( k1 != null && k1.equals(k2)) return true;
> >         return ( k1 == null && k2 == null && hashCode() ==
> > o.hashCode()); // Both objects were collected.
> >     }
> > 
> >     @Override
> >     public int hashCode() {
> >         Object k = get();
> >         int hash = 7;
> >         if (k != null) {
> >             hash = 29 * hash + k.hashCode();
> >             hash = 29 * hash + k.getClass().hashCode();
> >         } else {
> >             hash = this.hash;
> >         }
> >         return hash;
> >     }
> >     
> >     @Override
> >     public String toString(){
> >         Object s = get();
> >         if (s != null) return s.toString();
> >         return super.toString();
> >     }
> >     
> > }
> > 
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From peter.firmstone at zeus.net.au  Wed Feb 29 16:24:21 2012
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Thu, 01 Mar 2012 07:24:21 +1000
Subject: [concurrency-interest] Scalable object cache
In-Reply-To: <CANPzfU9jN5_ioxjVpiS4jFTTPU4AnPih2RXRg44j0-QvNeSz5w@mail.gmail.com>
References: <1330522636.21014.848.camel@bluto>
	<CANPzfU9jN5_ioxjVpiS4jFTTPU4AnPih2RXRg44j0-QvNeSz5w@mail.gmail.com>
Message-ID: <1330550660.21014.896.camel@bluto>


On Thu, 2012-03-01 at 00:39, ?iktor ?lang wrote:
> Sooo, you're saying that toString, hashCode and equals will only ever
> be called by the Thread that calls get()?

No, these methods could be called by any thread.  It could be used as a
key in a hash map, or in a tree map, if using a Comparator.  The
Comparator implementation tries to avoid calling get on TimedReferrer
unless it has a positive match.  This allows unmatching TimedReferrers
to be removed from a map or set, if they are not being matched.

It's up to the implementor of the referent to make their hashCode(),
equals() and Comparator nonblocking / scalable if they want.  I'm just
trying to allow that to be possible.

All this is invisible to client developers the public API is very small,
but well documented.

Cheers,

Peter.

/* Copyright (c) 2010-2012 Zeus Project Services Pty Ltd.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package au.net.zeus.collection;

import java.util.Comparator;

/**
 * Implements equals and hashCode, subclass ReferenceComparator
implements 
 * Serializable and contains serial data.
 * 
 * @author Peter Firmstone.
 */
abstract class AbstractReferenceComparator<T> implements
Comparator<Referrer<T>> {

    AbstractReferenceComparator() {
    }

    /**
     * This is implemented such that if either Referrer contains a null
     * referent, the comparison is only made using Referrer's, this may
     * have a different natural order, than the comparator provided,
however
     * equals will always return 0, this is important to correctly
remove
     * a Referrer once its referent has been collected.
     * 
     * The following tests give this a good workout:
     * 
     * com/sun/jini/test/impl/joinmanager/ZRegisterStorm.td
     * com/sun/jini/test/spec/renewalmanager/EventTest.td
     * 
     * @param o1
     * @param o2
     * @return 
     */
    public int compare(Referrer<T> o1, Referrer<T> o2) {
        if (o1 == o2) return 0;
        T t1 = null;
        if (o1 instanceof UntouchableReferrer){
            t1 = ((UntouchableReferrer<T>)o1).lookDontTouch();
        } else {
            t1 = o1.get();
        }
        T t2 = null;
        if (o2 instanceof UntouchableReferrer){
            t2 = ((UntouchableReferrer<T>)o2).lookDontTouch();
        } else {
            t2 = o2.get();
        }
        if ( t1 != null && t2 != null){
            int c = get().compare(t1, t2);
            if ( c == 0 ){// If untouchable this is a hit.
                o1.get();
                o2.get();
            }
            return c;
        }
        int hash1 = o1.hashCode();
        int hash2 = o2.hashCode();
        if (hash1 < hash2) return -1;
        if (hash1 > hash2) return 1;
        if (o1.equals(o2)) return 0;
        return -1;
    }

    @Override
    public boolean equals(Object o) {
        if (o == this) {
            return true;
        }
        if (o instanceof AbstractReferenceComparator) {
            return get().equals(((AbstractReferenceComparator)
o).get());
        }
        return false;
    }

    abstract Comparator<? super T> get();

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 61 * hash + (this.get() != null ? this.get().hashCode() :
0);
        return hash;
    }
    
}


> 
> On Wed, Feb 29, 2012 at 2:37 PM, Peter Firmstone
> <peter.firmstone at zeus.net.au> wrote:
>         I don't have the hardware to test this so I'm hoping someone
>         on the list
>         will know.
>         
>         In the class below, the get() method returns the referent,
>         provided it
>         hasn't been enqueued.
>         
>         Both read and clock are volatile, clock is written to, once
>         every 10
>         seconds (or an interval the developer sets) by a single
>         thread.
>         
>         if (read < clock) read = clock; //Avoid unnecessary volatile
>         write.
>         
>         If many threads are retrieving the referent, the volatile read
>         variable
>         is written at least once in between clock updates, but any
>         further
>         retrievals will only be reads.
>         
>         So in this case the volatile long values are multi read, with
>         occasional
>         writes, does get() look scalable to you?
>         
>         Regards,
>         
>         Peter.
>         
>         /*
>          * Copyright 2012 Zeus Project Services Pty Ltd.
>          *
>          * Licensed under the Apache License, Version 2.0 (the
>         "License");
>          * you may not use this file except in compliance with the
>         License.
>          * You may obtain a copy of the License at
>          *
>          *      http://www.apache.org/licenses/LICENSE-2.0
>          *
>          * Unless required by applicable law or agreed to in writing,
>         software
>          * distributed under the License is distributed on an "AS IS"
>         BASIS,
>          * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
>         express or
>         implied.
>          * See the License for the specific language governing
>         permissions and
>          * limitations under the License.
>          */
>         package au.net.zeus.collection;
>         
>         /**
>          *
>          * @author Peter Firmstone.
>          */
>         class TimedReferrer<T> implements Referrer<T>, TimeBomb {
>         
>            private volatile long clock;
>            private volatile long read;
>            private final TimedRefQueue queue;
>            private volatile T referent;
>            private volatile boolean enqued;
>            private final Object lock;
>            private final int hash;
>         
>            TimedReferrer(T k, TimedRefQueue q){
>                long time = System.nanoTime();
>                clock = time;
>                read = time;
>                referent = k;
>                queue = q;
>                enqued = false;
>                lock = new Object();
>                int hash = 7;
>                hash = 29 * hash + k.hashCode();
>                hash = 29 * hash + k.getClass().hashCode();
>                this.hash = hash;
>            }
>         
>            public T get() {
>                // Doesn't need to be atomic.
>                if (read < clock) read = clock; //Avoid unnecessary
>         volatile
>         write.
>                return referent;
>            }
>         
>            public void clear() {
>                referent = null;
>            }
>         
>            public boolean isEnqueued() {
>                return enqued;
>            }
>         
>            public boolean enqueue() {
>                if (enqued) return false;
>                if (referent == null) return false;
>                if (queue == null) return false;
>                synchronized (lock){ // Sync for atomic write of
>         enqued.
>                    if (enqued) return false;
>                    enqued = queue.offer(this);
>                }
>                return enqued;
>            }
>         
>            @Override
>            public void updateClock(long time){
>                if (read < clock) { // only write volatile if
>         necessary.
>                    enqueue();
>                    clear();
>                } else {
>                    clock = time;
>                }
>            }
>         
>            @Override
>            public boolean equals(Object o) {
>                if (this == o)  return true; // Same reference.
>                if (!(o instanceof Referrer))  return false;
>                Object k1 = get();
>                Object k2 = ((Referrer) o).get();
>                if ( k1 != null && k1.equals(k2)) return true;
>                return ( k1 == null && k2 == null && hashCode() ==
>         o.hashCode()); // Both objects were collected.
>            }
>         
>            @Override
>            public int hashCode() {
>                Object k = get();
>                int hash = 7;
>                if (k != null) {
>                    hash = 29 * hash + k.hashCode();
>                    hash = 29 * hash + k.getClass().hashCode();
>                } else {
>                    hash = this.hash;
>                }
>                return hash;
>            }
>         
>            @Override
>            public String toString(){
>                Object s = get();
>                if (s != null) return s.toString();
>                return super.toString();
>            }
>         
>         }
>         
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> -- 
> Viktor Klang
> 
> Akka Tech Lead
> Typesafe - The software stack for applications that scale
> 
> Twitter: @viktorklang


From peter.firmstone at zeus.net.au  Wed Feb 29 20:38:39 2012
From: peter.firmstone at zeus.net.au (Peter Firmstone)
Date: Thu, 01 Mar 2012 11:38:39 +1000
Subject: [concurrency-interest] Scalable object cache
In-Reply-To: <4F4E4FCF.20803@oracle.com>
References: <1330522636.21014.848.camel@bluto>  <4F4E4FCF.20803@oracle.com>
Message-ID: <1330565919.21014.983.camel@bluto>

I've made some minor modifications to TimedReferrer, to support
cancellation of Future tasks in Queue's, this may act as a throttling
mechanism.

This may provide an alternative throttling mechanism to using a
BlockingQueue, to obtain similar but non blocking behaviour for
ConcurrentLinkedQueue, or multiple ConcurrentLinkedQueue's.

Example usage:

Queue<Referrer<Future>> internal = new
ConcurrentLinkedQueue<Referrer<Future>>();
Queue<Future> taskQue = RC.queue(internal, Ref.TIME, 10000L);

In this case the cycle time will be ten seconds, so the task won't be
cancelled until 20 seconds or more has elapsed, the Queue will be
visited once every ten seconds, this could be set to less than a second,
say 100ms, however it's important that the cycle period is sensible,
rapid cycle times may reduce scalability or prune too many tasks, while
long cycle times may cause OME.  Tuning is left up to the user.  I
haven't experimented with dynamically adjustable cycle times, it's set
at construction.

The Future is first cancelled, by visiting each TimedReferrer in the
queue using an Iterator,  TimedReferrers enqueue themselves for removal
after timeout and finally are removed from the queue by another thread.

Is it right to assume a linked queue for example, will be easier to
iterate for a background thread?  If all other threads are accessing the
head and tail of the queue, the middle should be quiet and not compete
for access?

TimedReferrer, guarantees that a Future will be cancelled prior to
removal from a Queue, so an Executor may poll cancelled tasks.

N.B. On that topic, is there a possibility that ForkJoinPool, will allow
the use of different Queue implementations, eg via a QueueFactory?

Regards,

Peter.


/*
 * Copyright 2012 Zeus Project Services Pty Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package au.net.zeus.collection;

import java.util.concurrent.Future;

/**
 * 
 * @author Peter Firmstone.
 */
class TimedReferrer<T> implements UntouchableReferrer<T>, TimeBomb {
    
    private volatile long clock;
    private volatile long read;
    private final TimedRefQueue queue;
    private volatile T referent;
    private volatile boolean enqued;
    private final Object lock;
    private final int hash;
    
    TimedReferrer(T k, TimedRefQueue q){
        long time = System.nanoTime();
        clock = time;
        read = time;
        referent = k;
        queue = q;
        enqued = false;
        lock = new Object();
        int hash = 7;
        hash = 29 * hash + k.hashCode();
        hash = 29 * hash + k.getClass().hashCode();
        this.hash = hash;
    }

    public T get() {
        // Doesn't need to be atomic.
        if (read < clock) read = clock; //Avoid unnecessary volatile
write.
        return referent;
    }

    public void clear() {
        referent = null;
    }

    public boolean isEnqueued() {
        return enqued;
    }

    public boolean enqueue() {
        if (enqued) return false;
        if (referent == null) return false;
        if (queue == null) return false;
        synchronized (lock){ // Sync for atomic write of enqued.
            if (enqued) return false;
            enqued = queue.offer(this);
        }
        return enqued;
    }
    
    @Override
    public void updateClock(long time){
        if (read < clock) { // only write volatile if necessary.
            if (referent instanceof Future)
((Future)referent).cancel(false);
            enqueue();
            // Don't clear, it will be removed soon anyway, prevents 
            // non empty Queue.poll() returning null.
            //clear();
        } else {
            clock = time;
        }
    }
    
    @Override
    public boolean equals(Object o) {
        if (this == o)  return true; // Same reference.
        if (!(o instanceof Referrer))  return false;
        Object k1 = get(); //call get(), so equals updates clock for
key's in a hash map.
        Object k2 =((Referrer) o).get();
        if ( k1 != null && k1.equals(k2)) return true;
        return ( k1 == null && k2 == null && hashCode() ==
o.hashCode()); // Both objects were collected.
    }

    @Override
    public int hashCode() {
        Object k = referent; //don't call get(), avoid read update.
        int hash = 7;
        if (k != null) {
            hash = 29 * hash + k.hashCode();
            hash = 29 * hash + k.getClass().hashCode();
        } else {
            hash = this.hash;
        }
        return hash;
    }
    
    @Override
    public String toString(){
        Object s = get();
        if (s != null) return s.toString();
        return super.toString();
    }

    public T lookDontTouch() {
        return referent;
    }
    
}


