From david.lloyd at redhat.com  Fri Oct  3 11:13:16 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Fri, 03 Oct 2014 10:13:16 -0500
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
	checking is broken
Message-ID: <542EBD0C.7080301@redhat.com>

This discussion fizzled out last time it happened (2011 or something?). 
  So to avoid that happening again, I'm going to (hopefully clearly and 
in simple unambiguous terms) explain what the problem is, why it should 
be fixed, why the problem occurs, and exactly what should be done to fix 
the problem.

What the problem is
-------------------
The expectation that users have when creating atomic field updaters is 
that they have full access to any field that plain field accesses would 
have (I believe this was reasonably well-established - or at least 
implied - by all sides in the prior email thread).

The problem, as observed by users, is that when you have code which 
looks like this:

    public class Foo {
       private volatile int foo;
       private static final AtomicIntegerFieldUpdater up =
             AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
       ...
    }

...if you run with a security manager, and Foo.class.getClassLoader() != 
AtomicIntegerFieldUpdater.class.getClassLoader(), you get an access 
control exception unless Foo.class's ProtectionDomain includes the 
"accessDeclaredMembers".  This is very contrary to the primary 
expectation of users.

Enter the obvious workaround - first grant the requisite permission, 
then do this:

    public class Foo {
       private volatile int foo;
       private static final AtomicIntegerFieldUpdater up =
             AccessController.doPrivileged(
                new PrivilegedAction<AtomicIntegerFieldUpdater>() {
                   public AtomicIntegerFieldUpdater run() {
                      return 
AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
                   }
                }
             );
       ...
    }

Problem solved, yes?  No.  The newUpdater() method uses getCallerClass() 
to get the class which is requesting access to the field.  Since the 
caller class is actually Foo$1.class or some such, the equality check in 
the constructor of the implementation fails, causing an extra dynamic 
check to be run on every invocation.

Here's the better, but still awful, non-obvious workaround:

    public class Foo {
       private volatile int foo;
       private static AtomicIntegerFieldUpdater getIt() {
          return AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
       }

       private static final AtomicIntegerFieldUpdater up =
             AccessController.doPrivileged(
                new PrivilegedAction<AtomicIntegerFieldUpdater>() {
                   public AtomicIntegerFieldUpdater run() {
                      return getIt();
                   }
                }
             );
       ...
    }

This solves the getCallerClass() problem, however it still requires that 
Foo get the dangerous accessDeclaredMembers permission.

Why it is critical to fix this issue
------------------------------------
Any code which uses Atomic*FieldUpdaters cannot run in a security 
manager environment (like, say, a standard Java EE configuration) 
without potentially destructive global permissions.  Period.  This 
reason should speak for itself.

Why the problem occurs
----------------------
The root of the problem traces back to 
SecurityManager.checkMemberAccess().  This method is the one remaining 
method in all of SecurityManager which uses the calling class context 
(stack) in order to determine the nature of the access check that is 
needed.  Basically it assumes the stack will look like this:

      Class               Method
   0: SecurityManager     checkMemberAccess
   1: java.lang.Class     checkMemberAccess
   2: java.lang.Class     (some reflection API method call)
   3: ????                <consuming user code>

So, it looks at the class of position 3, and checks that class's class 
loader against the class loader of the class to whom access is being 
requested.  If the class loaders are equal, the check short-circuits and 
exits (permission granted).  Otherwise, we fall back to the permission 
check on the whole access control context.

There are two problems with this.  The first problem is general - the 
assumption that positions 1 and 2 are java.lang.Class calls is never 
actually verified, meaning if some user code (for some reason) wanted to 
use this method to check the accessDeclaredMembers permission, it would 
not be able to do so (granted this is fairly unlikely).

The second problem is specific to construction of Atomic*FieldUpdaters. 
  In this case the call stack looks like this:

      Class                           Method
   0: SecurityManager                 checkMemberAccess
   1: java.lang.Class                 checkMemberAccess
   2: java.lang.Class                 getDeclaredField
   3: j.u.c.Atomic*FieldUpdater$*Impl <init>
   4: j.u.c.Atomic*FieldUpdater       newUpdater
   5: ????                            <consuming user code>

The class loader at position 3 on the stack belongs to JDK code, and 
thus will probably have a null class loader or the system class loader. 
  If the user code is not a part of this class loader (and it almost 
never is, in the real world), then the fast check will always fail, 
which causes the fallback to the global permission check.

What should - no, *must* - be done to fix the problem
-----------------------------------------------------
I understand that in the Java 9 SDK we're likely to see improved stack 
introspection APIs and mechanisms, which may allow this problem to be 
solved in other more elegant ways.  However, I'm focusing on the 
existing code because this issue still really needs to be fixed in 8 and 
7, and even 6 for anyone who may still be maintaining a tree therefor.

The fix must come in two parts.

* Part 1 - checkMemberAccess assumptions should be verified

This should simply amount to adding equality comparisons for frames 1 
and 2 of the introspected call stack.

* Part 2 - check for atomic field updaters

The code in checkMemberAccess should examine positions 3 and 4 in the 
call stack (after an appropriate bounds check).  If they correspond to 
an Atomic*FieldUpdater implementation and the base class itself, 
respectively, then the class in position 5 should be used to verify the 
class loader rather than position 3.

While this special-case fix is not pretty, it does solve the issue and 
does not measurably worsen the already somewhat fragile existing code. 
It also solves a potentially serious security issue, by removing the 
need to grant potentially dangerous globally effective permissions to 
any code using these otherwise-innocuous atomic constructs.  There is 
little danger of this kind of fix creeping out to other constructs, 
simply because there are no other similar constructs with the same 
problem in the JDK.

Thank you for your consideration.
-- 
- DML

From dl at cs.oswego.edu  Fri Oct  3 20:14:03 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 03 Oct 2014 20:14:03 -0400
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <542EBD0C.7080301@redhat.com>
References: <542EBD0C.7080301@redhat.com>
Message-ID: <542F3BCB.2010203@cs.oswego.edu>


Thanks for the careful explanation. In short, the current checks
reject reasonable EE usages, which can lead users to widen
permissions, which can lead to less overall security.

The solution to inspect other caller frames seems OK to me.
But acceptance into OpenJDK requires approval from security folks.
We shouldn't/won't change jsr166 base source until cleared.

So probably the best way to make this happen is to file a CR with
your proposed patch/fix and ask for review?

-Doug


On 10/03/2014 11:13 AM, David M. Lloyd wrote:
> This discussion fizzled out last time it happened (2011 or something?).  So to
> avoid that happening again, I'm going to (hopefully clearly and in simple
> unambiguous terms) explain what the problem is, why it should be fixed, why the
> problem occurs, and exactly what should be done to fix the problem.
>
> What the problem is
> -------------------
> The expectation that users have when creating atomic field updaters is that they
> have full access to any field that plain field accesses would have (I believe
> this was reasonably well-established - or at least implied - by all sides in the
> prior email thread).
>
> The problem, as observed by users, is that when you have code which looks like
> this:
>
>     public class Foo {
>        private volatile int foo;
>        private static final AtomicIntegerFieldUpdater up =
>              AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
>        ...
>     }
>
> ...if you run with a security manager, and Foo.class.getClassLoader() !=
> AtomicIntegerFieldUpdater.class.getClassLoader(), you get an access control
> exception unless Foo.class's ProtectionDomain includes the
> "accessDeclaredMembers".  This is very contrary to the primary expectation of
> users.
>
> Enter the obvious workaround - first grant the requisite permission, then do this:
>
>     public class Foo {
>        private volatile int foo;
>        private static final AtomicIntegerFieldUpdater up =
>              AccessController.doPrivileged(
>                 new PrivilegedAction<AtomicIntegerFieldUpdater>() {
>                    public AtomicIntegerFieldUpdater run() {
>                       return AtomicIntegerFieldUpdater.newUpdater(Foo.class,
> "foo");
>                    }
>                 }
>              );
>        ...
>     }
>
> Problem solved, yes?  No.  The newUpdater() method uses getCallerClass() to get
> the class which is requesting access to the field.  Since the caller class is
> actually Foo$1.class or some such, the equality check in the constructor of the
> implementation fails, causing an extra dynamic check to be run on every invocation.
>
> Here's the better, but still awful, non-obvious workaround:
>
>     public class Foo {
>        private volatile int foo;
>        private static AtomicIntegerFieldUpdater getIt() {
>           return AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
>        }
>
>        private static final AtomicIntegerFieldUpdater up =
>              AccessController.doPrivileged(
>                 new PrivilegedAction<AtomicIntegerFieldUpdater>() {
>                    public AtomicIntegerFieldUpdater run() {
>                       return getIt();
>                    }
>                 }
>              );
>        ...
>     }
>
> This solves the getCallerClass() problem, however it still requires that Foo get
> the dangerous accessDeclaredMembers permission.
>
> Why it is critical to fix this issue
> ------------------------------------
> Any code which uses Atomic*FieldUpdaters cannot run in a security manager
> environment (like, say, a standard Java EE configuration) without potentially
> destructive global permissions.  Period.  This reason should speak for itself.
>
> Why the problem occurs
> ----------------------
> The root of the problem traces back to SecurityManager.checkMemberAccess().
> This method is the one remaining method in all of SecurityManager which uses the
> calling class context (stack) in order to determine the nature of the access
> check that is needed.  Basically it assumes the stack will look like this:
>
>       Class               Method
>    0: SecurityManager     checkMemberAccess
>    1: java.lang.Class     checkMemberAccess
>    2: java.lang.Class     (some reflection API method call)
>    3: ????                <consuming user code>
>
> So, it looks at the class of position 3, and checks that class's class loader
> against the class loader of the class to whom access is being requested.  If the
> class loaders are equal, the check short-circuits and exits (permission
> granted).  Otherwise, we fall back to the permission check on the whole access
> control context.
>
> There are two problems with this.  The first problem is general - the assumption
> that positions 1 and 2 are java.lang.Class calls is never actually verified,
> meaning if some user code (for some reason) wanted to use this method to check
> the accessDeclaredMembers permission, it would not be able to do so (granted
> this is fairly unlikely).
>
> The second problem is specific to construction of Atomic*FieldUpdaters.  In this
> case the call stack looks like this:
>
>       Class                           Method
>    0: SecurityManager                 checkMemberAccess
>    1: java.lang.Class                 checkMemberAccess
>    2: java.lang.Class                 getDeclaredField
>    3: j.u.c.Atomic*FieldUpdater$*Impl <init>
>    4: j.u.c.Atomic*FieldUpdater       newUpdater
>    5: ????                            <consuming user code>
>
> The class loader at position 3 on the stack belongs to JDK code, and thus will
> probably have a null class loader or the system class loader.  If the user code
> is not a part of this class loader (and it almost never is, in the real world),
> then the fast check will always fail, which causes the fallback to the global
> permission check.
>
> What should - no, *must* - be done to fix the problem
> -----------------------------------------------------
> I understand that in the Java 9 SDK we're likely to see improved stack
> introspection APIs and mechanisms, which may allow this problem to be solved in
> other more elegant ways.  However, I'm focusing on the existing code because
> this issue still really needs to be fixed in 8 and 7, and even 6 for anyone who
> may still be maintaining a tree therefor.
>
> The fix must come in two parts.
>
> * Part 1 - checkMemberAccess assumptions should be verified
>
> This should simply amount to adding equality comparisons for frames 1 and 2 of
> the introspected call stack.
>
> * Part 2 - check for atomic field updaters
>
> The code in checkMemberAccess should examine positions 3 and 4 in the call stack
> (after an appropriate bounds check).  If they correspond to an
> Atomic*FieldUpdater implementation and the base class itself, respectively, then
> the class in position 5 should be used to verify the class loader rather than
> position 3.
>
> While this special-case fix is not pretty, it does solve the issue and does not
> measurably worsen the already somewhat fragile existing code. It also solves a
> potentially serious security issue, by removing the need to grant potentially
> dangerous globally effective permissions to any code using these
> otherwise-innocuous atomic constructs.  There is little danger of this kind of
> fix creeping out to other constructs, simply because there are no other similar
> constructs with the same problem in the JDK.
>
> Thank you for your consideration.


From Alan.Bateman at oracle.com  Fri Oct  3 23:15:13 2014
From: Alan.Bateman at oracle.com (Alan Bateman)
Date: Fri, 03 Oct 2014 20:15:13 -0700
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <542EBD0C.7080301@redhat.com>
References: <542EBD0C.7080301@redhat.com>
Message-ID: <542F6641.3090600@oracle.com>

On 03/10/2014 08:13, David M. Lloyd wrote:
> :
>
> Why the problem occurs
> ----------------------
> The root of the problem traces back to 
> SecurityManager.checkMemberAccess().  This method is the one remaining 
> method in all of SecurityManager which uses the calling class context 
> (stack) in order to determine the nature of the access check that is 
> needed.
Are you sure you see this in JDK 8 too? I ask because I remember David 
Holmes changed the Atomic*Updater methods to call getDeclaredField in a 
privileged block (JDK-7103570). Also there work in JDK 8 on caller 
sensitive methods (JEP 176). As part of this then SM.checkMemberAccess 
was deprecated and usages in the JDK dropped (Class.getDeclaredField and 
the others no longer use it).

-Alan.


From forax at univ-mlv.fr  Sat Oct  4 05:39:43 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Sat, 04 Oct 2014 11:39:43 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <542EBD0C.7080301@redhat.com>
References: <542EBD0C.7080301@redhat.com>
Message-ID: <542FC05F.3040904@univ-mlv.fr>


On 10/03/2014 05:13 PM, David M. Lloyd wrote:
> This discussion fizzled out last time it happened (2011 or 
> something?).  So to avoid that happening again, I'm going to 
> (hopefully clearly and in simple unambiguous terms) explain what the 
> problem is, why it should be fixed, why the problem occurs, and 
> exactly what should be done to fix the problem.
>
> What the problem is
> -------------------
> The expectation that users have when creating atomic field updaters is 
> that they have full access to any field that plain field accesses 
> would have (I believe this was reasonably well-established - or at 
> least implied - by all sides in the prior email thread).
>
> The problem, as observed by users, is that when you have code which 
> looks like this:
>
>    public class Foo {
>       private volatile int foo;
>       private static final AtomicIntegerFieldUpdater up =
>             AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
>       ...
>    }
>
> ...if you run with a security manager, and Foo.class.getClassLoader() 
> != AtomicIntegerFieldUpdater.class.getClassLoader(), you get an access 
> control exception unless Foo.class's ProtectionDomain includes the 
> "accessDeclaredMembers".  This is very contrary to the primary 
> expectation of users.
>
> Enter the obvious workaround - first grant the requisite permission, 
> then do this:
>
>    public class Foo {
>       private volatile int foo;
>       private static final AtomicIntegerFieldUpdater up =
>             AccessController.doPrivileged(
>                new PrivilegedAction<AtomicIntegerFieldUpdater>() {
>                   public AtomicIntegerFieldUpdater run() {
>                      return 
> AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
>                   }
>                }
>             );
>       ...
>    }
>
> Problem solved, yes?  No.  The newUpdater() method uses 
> getCallerClass() to get the class which is requesting access to the 
> field.  Since the caller class is actually Foo$1.class or some such, 
> the equality check in the constructor of the implementation fails, 
> causing an extra dynamic check to be run on every invocation.
>
> Here's the better, but still awful, non-obvious workaround:
>
>    public class Foo {
>       private volatile int foo;
>       private static AtomicIntegerFieldUpdater getIt() {
>          return AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo");
>       }
>
>       private static final AtomicIntegerFieldUpdater up =
>             AccessController.doPrivileged(
>                new PrivilegedAction<AtomicIntegerFieldUpdater>() {
>                   public AtomicIntegerFieldUpdater run() {
>                      return getIt();
>                   }
>                }
>             );
>       ...
>    }
>
> This solves the getCallerClass() problem, however it still requires 
> that Foo get the dangerous accessDeclaredMembers permission.

There is a better workaround, use a lambda, a lambda body is de-sugared 
to a private static method.

public class Foo {
       private volatile int foo;
       private static final AtomicIntegerFieldUpdater up =
             AccessController.doPrivileged(() -> 
AtomicIntegerFieldUpdater.newUpdater(Foo.class, "foo"));
       ...
}

It's just a workaround, as you said you still need to add 
accessDeclaredMembers permission.

cheers,
R?mi


From david.lloyd at redhat.com  Sat Oct  4 11:14:16 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Sat, 04 Oct 2014 10:14:16 -0500
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <542F6641.3090600@oracle.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
Message-ID: <54300EC8.20207@redhat.com>

On 10/03/2014 10:15 PM, Alan Bateman wrote:
> On 03/10/2014 08:13, David M. Lloyd wrote:
>> :
>>
>> Why the problem occurs
>> ----------------------
>> The root of the problem traces back to
>> SecurityManager.checkMemberAccess().  This method is the one remaining
>> method in all of SecurityManager which uses the calling class context
>> (stack) in order to determine the nature of the access check that is
>> needed.
> Are you sure you see this in JDK 8 too? I ask because I remember David
> Holmes changed the Atomic*Updater methods to call getDeclaredField in a
> privileged block (JDK-7103570). Also there work in JDK 8 on caller
> sensitive methods (JEP 176). As part of this then SM.checkMemberAccess
> was deprecated and usages in the JDK dropped (Class.getDeclaredField and
> the others no longer use it).

Ah, I will double check.  I admit my JDK 8 checkout is (still) very old, 
and it appeared like the code was similar, and given the prior 
discussion it did not occur to me to check out more recent code.  But 
I'll check with a newer JDK 8 - if I can target the workaround, all the 
better.

Either way though I do feel that a JDK 7 backport is warranted, 
especially considering that Java EE 7 is the state of the art for EE 
right now.

-- 
- DML

From peter.levart at gmail.com  Sun Oct  5 16:44:21 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Sun, 05 Oct 2014 22:44:21 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <542F6641.3090600@oracle.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
Message-ID: <5431ADA5.2070904@gmail.com>


On 10/04/2014 05:15 AM, Alan Bateman wrote:
> On 03/10/2014 08:13, David M. Lloyd wrote:
>> :
>>
>> Why the problem occurs
>> ----------------------
>> The root of the problem traces back to 
>> SecurityManager.checkMemberAccess().  This method is the one 
>> remaining method in all of SecurityManager which uses the calling 
>> class context (stack) in order to determine the nature of the access 
>> check that is needed.
> Are you sure you see this in JDK 8 too? I ask because I remember David 
> Holmes changed the Atomic*Updater methods to call getDeclaredField in 
> a privileged block (JDK-7103570). Also there work in JDK 8 on caller 
> sensitive methods (JEP 176). As part of this then SM.checkMemberAccess 
> was deprecated and usages in the JDK dropped (Class.getDeclaredField 
> and the others no longer use it).
>
> -Alan.
>

Hi,

It seems that construction-time access checks are fine in JDK9 and 8u20. 
But I found a corner case where invocation-time access check is overly 
restrictive. Take for example the following code:

package test;

import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;

public class Test {

     static class A {
         protected volatile int x;
     }

     static class B extends A {
         static void test() {
             A a = new A();
             B b = new B();

             b.x = 10; // OK

             a.x = 10; // OK

             AtomicIntegerFieldUpdater<A> xUpdater =
                 AtomicIntegerFieldUpdater.newUpdater(A.class, "x"); // OK

             xUpdater.set(b, 10); // OK

             xUpdater.set(a, 10); // IllegalAccessException:
             // Class test.Test$B can not access a protected member of class
             // test.Test$A using an instance of test.Test$A
         }
     }

     public static void main(String[] args) {
         B.test();
     }
}


Here we see that Java allows accessing protected field A.x from class B 
using either instance of A or instance of B. That's because B is in the 
same package as A .

Atomic*FieldUpdater check is therefore overly restrictive. If the 
'protected' modifier is removed from A.x field, the test passes.

So here's a preview of how this could be fixed:

http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/webrev.01/

I have just made a fix for AtomicIntegerFieldUpdater. Other 
Atomic*FieldUpdaters have similar code. The fix also includes a 
simplification of invocation-time access check. In original code, 
'cclass' is non-null and equal to 'caller' only in case when the field 
is protected and 'caller' class is different from 'tclass', meaning that 
fullCheck() is always called in such cases. fullCheck() in such cases 
checks that 'obj' is instanceof 'tclass' and 'caller' at the same time. 
But in such cases, 'caller' is also a subclass of 'tclass' or else the 
construction-time checks would fail.

So I think that we can get away with only one instanceof check. In 
patched code the class to check against is equal to 'tclass' if we are 
not performing a protected field access check or 'caller' if protected 
access is checked. So if we change the meaning of 'cclass' from:

             this.cclass = (Modifier.isProtected(modifiers) &&
                            caller != tclass) ? caller : null;

to:

             this.cclass = (Modifier.isProtected(modifiers)) ? caller : 
tclass;

we can change the invocation-time check from:

             if (obj == null || obj.getClass() != tclass || cclass != 
null) fullCheck(obj);

to:

             if (!cclass.isInstance(obj)) failCheck(obj);

That's the whole check, so fullCheck() becomes failCheck() which always 
throws exception (the type of which is determined from the runtime class 
of 'obj' instance).

Now is this check fast enough? It seems so. The Class.isInstance() is 
intrinsified. I checked with the following benchmark (the results on my 
i7 Linux PC are attached as comments):

http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AtomicUpdaterBench.java

The 1st and 2nd report should be compared. It seems that get() is even 
faster with simplified check while other methods are the same.

The 3rd report shows a result of experimental AtomicIntegerFieldUpdater 
implementation which loads new VM-anonymous class for each new instance 
which allows VM compiler to specialize code for a particular field. Such 
implementation is nearly as fast as Java field access. This is just a 
proof of concept. A little hack-ish, doesn't include the fix for the 
overly restrictive protected access yet, but here it is if anyone is 
interested:

  http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java


Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141005/4f564c9d/attachment.html>

From peter.levart at gmail.com  Wed Oct  8 05:38:52 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 11:38:52 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <5431ADA5.2070904@gmail.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com>
Message-ID: <5435062C.6020200@gmail.com>

On 10/05/2014 10:44 PM, Peter Levart wrote:
> The 3rd report shows a result of experimental 
> AtomicIntegerFieldUpdater implementation which loads new VM-anonymous 
> class for each new instance which allows VM compiler to specialize 
> code for a particular field. Such implementation is nearly as fast as 
> Java field access. This is just a proof of concept. A little hack-ish, 
> doesn't include the fix for the overly restrictive protected access 
> yet, but here it is if anyone is interested:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java 
>

Hi,

I experimented further with this.

It seems that making 'offset' a static final field is not necessary to 
get optimal performance out of specialized one-class-per-instance 
Atomic*FieldUpdater. Only the 'cclass' field used in check matters. So 
'offset' can be pushed up to abstract Atomic*FieldUpdaterImpl as a final 
instance field. Now that specialized subclass of Atomic*FieldUpdaterImpl 
is only 'cclass' specific, it can be shared among instances that use the 
same 'cclass'. That means only one VM-anonymous subclass per target 
class (or subclass/caller of target class when protected access is 
involved). The VM-anonymous subclass is cached using ClassValue:

http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java

I seems that with such Atomic*FieldUpdater there is no compelling reason 
to use Unsafe directly as there is almost no additional runtime 
overhead. The only method that is about 30% slower than Java counterpart 
is get(), but there's hardly a reason to use it instead of simple Java 
volatile field read.

Regards, Peter


From thurston at nomagicsoftware.com  Wed Oct  8 06:19:04 2014
From: thurston at nomagicsoftware.com (thurstonn)
Date: Wed, 8 Oct 2014 03:19:04 -0700 (MST)
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
Message-ID: <1412763544022-11323.post@n7.nabble.com>

Hello,

If I read the  jsr-133 cookbook
<http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
following:


<code>
//y is a global, non-volatile
enter monitor x
...
//do some work not involving y
. . .
exit monitor x
y = 43

</code>

then at least according to the JMM, the following execution is possible:
<code>
//y is a global, non-volatile
enter monitor x
...
//do some work not involving y
y = 43
exit monitor x
</code>

as in the first table in the cookbook, *normal stores* are allowed to be
re-ordered before a *monitor exit* (but not before a *monitor enter*).

Although the issue isn't really one involving memory consistency, is that
really allowed?  Because *increasing* the size of a critical section seems .
. . I don't know . . . unhealthy.
What if the program code computed the first 1000 prime numbers or something
and wrote them to a global array (after the monitor exit)?

I was always under the impression that only the operations specified within
a critical section would actually be executed between the enter/exit monitor
pair 

NB: Although, presumably the runtime/CPU would only do this if the critical
section was leading to CPU stalls or the like and so in reality, not really
producing a longer critical section execution time




--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From viktor.klang at gmail.com  Wed Oct  8 06:23:33 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 8 Oct 2014 12:23:33 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <5435062C.6020200@gmail.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
Message-ID: <CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>

Hi Peter,

can you quantify: " is almost no additional runtime overhead."?

On Wed, Oct 8, 2014 at 11:38 AM, Peter Levart <peter.levart at gmail.com>
wrote:

> On 10/05/2014 10:44 PM, Peter Levart wrote:
>
>> The 3rd report shows a result of experimental AtomicIntegerFieldUpdater
>> implementation which loads new VM-anonymous class for each new instance
>> which allows VM compiler to specialize code for a particular field. Such
>> implementation is nearly as fast as Java field access. This is just a proof
>> of concept. A little hack-ish, doesn't include the fix for the overly
>> restrictive protected access yet, but here it is if anyone is interested:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.
>> AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java
>>
>
> Hi,
>
> I experimented further with this.
>
> It seems that making 'offset' a static final field is not necessary to get
> optimal performance out of specialized one-class-per-instance
> Atomic*FieldUpdater. Only the 'cclass' field used in check matters. So
> 'offset' can be pushed up to abstract Atomic*FieldUpdaterImpl as a final
> instance field. Now that specialized subclass of Atomic*FieldUpdaterImpl is
> only 'cclass' specific, it can be shared among instances that use the same
> 'cclass'. That means only one VM-anonymous subclass per target class (or
> subclass/caller of target class when protected access is involved). The
> VM-anonymous subclass is cached using ClassValue:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.
> AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>
> I seems that with such Atomic*FieldUpdater there is no compelling reason
> to use Unsafe directly as there is almost no additional runtime overhead.
> The only method that is about 30% slower than Java counterpart is get(),
> but there's hardly a reason to use it instead of simple Java volatile field
> read.
>
> Regards, Peter
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/7b2bcb62/attachment.html>

From davidcholmes at aapt.net.au  Wed Oct  8 06:37:11 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 8 Oct 2014 20:37:11 +1000
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <1412763544022-11323.post@n7.nabble.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKEKJAA.davidcholmes@aapt.net.au>

thurstonn writes:
>
> Hello,
>
> If I read the  jsr-133 cookbook
> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
> following:
>
>
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> . . .
> exit monitor x
> y = 43
>
> </code>
>
> then at least according to the JMM, the following execution is possible:
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> y = 43
> exit monitor x
> </code>
>
> as in the first table in the cookbook, *normal stores* are allowed to be
> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>
> Although the issue isn't really one involving memory consistency, is that
> really allowed?  Because *increasing* the size of a critical
> section seems .
> . . I don't know . . . unhealthy.
> What if the program code computed the first 1000 prime numbers or
> something
> and wrote them to a global array (after the monitor exit)?
>
> I was always under the impression that only the operations
> specified within
> a critical section would actually be executed between the
> enter/exit monitor
> pair
>
> NB: Although, presumably the runtime/CPU would only do this if
> the critical
> section was leading to CPU stalls or the like and so in reality,
> not really
> producing a longer critical section execution time

Not only is it allowed, it can easily be performed by the JIT. If that seems
"unhealthy" you will be really freaked out by lock-coarsening which can
coalesce:

synchronized(x) {
 // aaa
}
// other code
synchronized(x) {
 // bbb
}

into

synchronized(x) {
  // aaa
  // other code
  // bbb
}

where anything in the sync block can of course be further reordered.

Of course this can't be done arbitrarily but it can be done.

Cheers,
David Holmes

>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and
-exit-monitor-tp11323.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Wed Oct  8 06:51:20 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 8 Oct 2014 12:51:20 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <1412763544022-11323.post@n7.nabble.com>
References: <1412763544022-11323.post@n7.nabble.com>
Message-ID: <CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>

Sounds really bad if this is the case. I can totally understand eliding
locks that are re-taken in a nested fashion, but coarsening in terms of
coalescing neighboring acquisitions seems dubious.

On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <thurston at nomagicsoftware.com>
wrote:

> Hello,
>
> If I read the  jsr-133 cookbook
> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
> following:
>
>
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> . . .
> exit monitor x
> y = 43
>
> </code>
>
> then at least according to the JMM, the following execution is possible:
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> y = 43
> exit monitor x
> </code>
>
> as in the first table in the cookbook, *normal stores* are allowed to be
> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>
> Although the issue isn't really one involving memory consistency, is that
> really allowed?  Because *increasing* the size of a critical section seems
> .
> . . I don't know . . . unhealthy.
> What if the program code computed the first 1000 prime numbers or something
> and wrote them to a global array (after the monitor exit)?
>
> I was always under the impression that only the operations specified within
> a critical section would actually be executed between the enter/exit
> monitor
> pair
>
> NB: Although, presumably the runtime/CPU would only do this if the critical
> section was leading to CPU stalls or the like and so in reality, not really
> producing a longer critical section execution time
>
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/0331f508/attachment.html>

From dl at cs.oswego.edu  Wed Oct  8 07:19:48 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 08 Oct 2014 07:19:48 -0400
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <5435062C.6020200@gmail.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
Message-ID: <54351DD4.6050500@cs.oswego.edu>


On 10/08/2014 05:38 AM, Peter Levart wrote:
>
> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>

Paul Sandoz has been working on VarHandles (like MethodHandles)
for similar purposes. Possibly even the same purposes.
See his JavaOne talk slides at
http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
It seems worth waiting for more progress on this front before
contemplating changes along these lines.

-Doug




From thurston at nomagicsoftware.com  Wed Oct  8 07:44:59 2014
From: thurston at nomagicsoftware.com (thurstonn)
Date: Wed, 8 Oct 2014 04:44:59 -0700 (MST)
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKEKJAA.davidcholmes@aapt.net.au>
References: <1412763544022-11323.post@n7.nabble.com>
	<NFBBKALFDCPFIDBNKAPCCEKEKJAA.davidcholmes@aapt.net.au>
Message-ID: <1412768699357-11328.post@n7.nabble.com>

David Holmes-6 wrote
> Not only is it allowed, it can easily be performed by the JIT. If that
> seems
> "unhealthy" you will be really freaked out by lock-coarsening which can
> coalesce:
> 
> synchronized(x) {
>  // aaa
> }
> // other code
> synchronized(x) {
>  // bbb
> }
> 
> into
> 
> synchronized(x) {
>   // aaa
>   // other code
>   // bbb
> }
> 
> where anything in the sync block can of course be further reordered.
> 
> Of course this can't be done arbitrarily but it can be done.
> 
> Cheers,
> David Holmes
> 
>>

Thanks.
To be precise, there is a hb(aaa, bbb), surely that needs to be respected in
the rewritten *coalesced* code; as far as "other code", anything goes I
guess



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323p11328.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From dl at cs.oswego.edu  Wed Oct  8 07:49:51 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 08 Oct 2014 07:49:51 -0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
Message-ID: <543524DF.2000104@cs.oswego.edu>

On 10/08/2014 06:51 AM, ?iktor ?lang wrote:
> Sounds really bad if this is the case. I can totally understand eliding locks
> that are re-taken in a nested fashion, but coarsening in terms of coalescing
> neighboring acquisitions seems dubious.

A memory model just says what reorderings etc are legal,
but doesn't tell you if any are desirable. The rules enable
but don't mandate biased locking, coarsening etc that might
be performed by compilers and processors. In practice, these
sometimes occur for "synchronized" blocks, but not for
j.u.c.locks Locks or related synchronizers, at least
for hotspot running on currently supported processors.

-Doug

>
> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <thurston at nomagicsoftware.com
> <mailto:thurston at nomagicsoftware.com>> wrote:
>
>     Hello,
>
>     If I read the  jsr-133 cookbook
>     <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>     following:
>
>
>     <code>
>     //y is a global, non-volatile
>     enter monitor x
>     ...
>     //do some work not involving y
>     . . .
>     exit monitor x
>     y = 43
>
>     </code>
>
>     then at least according to the JMM, the following execution is possible:
>     <code>
>     //y is a global, non-volatile
>     enter monitor x
>     ...
>     //do some work not involving y
>     y = 43
>     exit monitor x
>     </code>
>
>     as in the first table in the cookbook, *normal stores* are allowed to be
>     re-ordered before a *monitor exit* (but not before a *monitor enter*).
>
>     Although the issue isn't really one involving memory consistency, is that
>     really allowed?  Because *increasing* the size of a critical section seems .
>     . . I don't know . . . unhealthy.
>     What if the program code computed the first 1000 prime numbers or something
>     and wrote them to a global array (after the monitor exit)?
>
>     I was always under the impression that only the operations specified within
>     a critical section would actually be executed between the enter/exit monitor
>     pair
>
>     NB: Although, presumably the runtime/CPU would only do this if the critical
>     section was leading to CPU stalls or the like and so in reality, not really
>     producing a longer critical section execution time
>
>
>
>
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>




From forax at univ-mlv.fr  Wed Oct  8 08:09:45 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Wed, 08 Oct 2014 14:09:45 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
Message-ID: <54352989.6060308@univ-mlv.fr>


On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
> Sounds really bad if this is the case. I can totally understand 
> eliding locks that are re-taken in a nested fashion, but coarsening in 
> terms of coalescing neighboring acquisitions seems dubious.

even in this case,
class Foo {
   public synchronized void setBar(Bar bar) { ... }
   public synchronized void setBaz(Baz baz) { ... }
}
...
   Foo foo = ...
   foo.setBar(bar);
   foo.setBaz(baz);

because sadly this code is very common :(

R?mi

>
> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn 
> <thurston at nomagicsoftware.com <mailto:thurston at nomagicsoftware.com>> 
> wrote:
>
>     Hello,
>
>     If I read the  jsr-133 cookbook
>     <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>  correctly, given the
>     following:
>
>
>     <code>
>     //y is a global, non-volatile
>     enter monitor x
>     ...
>     //do some work not involving y
>     . . .
>     exit monitor x
>     y = 43
>
>     </code>
>
>     then at least according to the JMM, the following execution is
>     possible:
>     <code>
>     //y is a global, non-volatile
>     enter monitor x
>     ...
>     //do some work not involving y
>     y = 43
>     exit monitor x
>     </code>
>
>     as in the first table in the cookbook, *normal stores* are allowed
>     to be
>     re-ordered before a *monitor exit* (but not before a *monitor enter*).
>
>     Although the issue isn't really one involving memory consistency,
>     is that
>     really allowed?  Because *increasing* the size of a critical
>     section seems .
>     . . I don't know . . . unhealthy.
>     What if the program code computed the first 1000 prime numbers or
>     something
>     and wrote them to a global array (after the monitor exit)?
>
>     I was always under the impression that only the operations
>     specified within
>     a critical section would actually be executed between the
>     enter/exit monitor
>     pair
>
>     NB: Although, presumably the runtime/CPU would only do this if the
>     critical
>     section was leading to CPU stalls or the like and so in reality,
>     not really
>     producing a longer critical section execution time
>
>
>
>
>     --
>     View this message in context:
>     http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>     Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/846735ca/attachment.html>

From viktor.klang at gmail.com  Wed Oct  8 08:30:37 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 8 Oct 2014 14:30:37 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <54352989.6060308@univ-mlv.fr>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
Message-ID: <CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>

On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr> wrote:

>
> On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>
> Sounds really bad if this is the case. I can totally understand eliding
> locks that are re-taken in a nested fashion, but coarsening in terms of
> coalescing neighboring acquisitions seems dubious.
>
>
> even in this case,
> class Foo {
>   public synchronized void setBar(Bar bar) { ... }
>   public synchronized void setBaz(Baz baz) { ... }
> }
> ...
>   Foo foo = ...
>   foo.setBar(bar);
>   foo.setBaz(baz);
>
> because sadly this code is very common :(
>

Agreed. The case above is not really problematic since there are no
invocations/reads/writes in between.


>
> R?mi
>
>
>
> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <thurston at nomagicsoftware.com>
> wrote:
>
>> Hello,
>>
>> If I read the  jsr-133 cookbook
>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>> following:
>>
>>
>> <code>
>> //y is a global, non-volatile
>> enter monitor x
>> ...
>> //do some work not involving y
>> . . .
>> exit monitor x
>> y = 43
>>
>> </code>
>>
>> then at least according to the JMM, the following execution is possible:
>> <code>
>> //y is a global, non-volatile
>> enter monitor x
>> ...
>> //do some work not involving y
>> y = 43
>> exit monitor x
>> </code>
>>
>> as in the first table in the cookbook, *normal stores* are allowed to be
>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>
>> Although the issue isn't really one involving memory consistency, is that
>> really allowed?  Because *increasing* the size of a critical section
>> seems .
>> . . I don't know . . . unhealthy.
>> What if the program code computed the first 1000 prime numbers or
>> something
>> and wrote them to a global array (after the monitor exit)?
>>
>> I was always under the impression that only the operations specified
>> within
>> a critical section would actually be executed between the enter/exit
>> monitor
>> pair
>>
>> NB: Although, presumably the runtime/CPU would only do this if the
>> critical
>> section was leading to CPU stalls or the like and so in reality, not
>> really
>> producing a longer critical section execution time
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
>  Cheers,
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/6720830e/attachment-0001.html>

From forax at univ-mlv.fr  Wed Oct  8 08:33:56 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Wed, 08 Oct 2014 14:33:56 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
References: <542EBD0C.7080301@redhat.com>
	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>
	<5435062C.6020200@gmail.com>
	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
Message-ID: <54352F34.1010100@univ-mlv.fr>

The code generates a different class for each field updater,
so in that case the ccClass (the type of the field) is considered as a 
constant
so the instanceof check can be removed by the JIT.

Usually, it's not a good idea to do that because you trade a constant 
argument for
a non constant implementation of the interface Atomic*FieldUpdater, but 
given
that the updater are usually static final, i.e. a constant for the JIT,
here, it should be faster.

Peter, in term of implementation, you can use the fact that you can patch
the class when you call defineAnonymous class, so you can insert the 
offset and the class,
without using a thread local which is really a hack.

There is another way to do exactly the same things, make ccClass 
constant foldable for
the JIT without asking to load a bunch of classes. The implementation of 
the Updater
can be moved into java.lang.invoke and use the annotation @Stable, in 
that case,
the field ccCache will be considered as constant if the updater is 
constant itself,
this trick doesn't come from me but from Paul Sandoz which currently 
works on
this area as Doug mention.

cheers,
R?mi

On 10/08/2014 12:23 PM, ?iktor ?lang wrote:
> Hi Peter,
>
> can you quantify: " is almost no additional runtime overhead."?
>
> On Wed, Oct 8, 2014 at 11:38 AM, Peter Levart <peter.levart at gmail.com 
> <mailto:peter.levart at gmail.com>> wrote:
>
>     On 10/05/2014 10:44 PM, Peter Levart wrote:
>
>         The 3rd report shows a result of experimental
>         AtomicIntegerFieldUpdater implementation which loads new
>         VM-anonymous class for each new instance which allows VM
>         compiler to specialize code for a particular field. Such
>         implementation is nearly as fast as Java field access. This is
>         just a proof of concept. A little hack-ish, doesn't include
>         the fix for the overly restrictive protected access yet, but
>         here it is if anyone is interested:
>
>         http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java
>         <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java>
>
>
>
>     Hi,
>
>     I experimented further with this.
>
>     It seems that making 'offset' a static final field is not
>     necessary to get optimal performance out of specialized
>     one-class-per-instance Atomic*FieldUpdater. Only the 'cclass'
>     field used in check matters. So 'offset' can be pushed up to
>     abstract Atomic*FieldUpdaterImpl as a final instance field. Now
>     that specialized subclass of Atomic*FieldUpdaterImpl is only
>     'cclass' specific, it can be shared among instances that use the
>     same 'cclass'. That means only one VM-anonymous subclass per
>     target class (or subclass/caller of target class when protected
>     access is involved). The VM-anonymous subclass is cached using
>     ClassValue:
>
>     http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>     <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java>
>
>     I seems that with such Atomic*FieldUpdater there is no compelling
>     reason to use Unsafe directly as there is almost no additional
>     runtime overhead. The only method that is about 30% slower than
>     Java counterpart is get(), but there's hardly a reason to use it
>     instead of simple Java volatile field read.
>
>     Regards, Peter
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/024873fb/attachment.html>

From forax at univ-mlv.fr  Wed Oct  8 08:36:36 2014
From: forax at univ-mlv.fr (Remi Forax)
Date: Wed, 08 Oct 2014 14:36:36 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
Message-ID: <54352FD4.7060003@univ-mlv.fr>


On 10/08/2014 02:30 PM, ?iktor ?lang wrote:
>
>
> On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr 
> <mailto:forax at univ-mlv.fr>> wrote:
>
>
>     On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>>     Sounds really bad if this is the case. I can totally understand
>>     eliding locks that are re-taken in a nested fashion, but
>>     coarsening in terms of coalescing neighboring acquisitions seems
>>     dubious.
>
>     even in this case,
>     class Foo {
>       public synchronized void setBar(Bar bar) { ... }
>       public synchronized void setBaz(Baz baz) { ... }
>     }
>     ...
>       Foo foo = ...
>       foo.setBar(bar);
>       foo.setBaz(baz);
>
>     because sadly this code is very common :(
>
>
> Agreed. The case above is not really problematic since there are no 
> invocations/reads/writes in between.

sorry my code was not clear, I should have written:
   Foo foo = ...
   foo.setBar(this.bar);
   foo.setBaz(this.baz);

there is a load of the field baz in between the call to setBar and the 
call to setBaz.

R?mi

>
>     R?mi
>
>
>>
>>     On Wed, Oct 8, 2014 at 12:19 PM, thurstonn
>>     <thurston at nomagicsoftware.com
>>     <mailto:thurston at nomagicsoftware.com>> wrote:
>>
>>         Hello,
>>
>>         If I read the  jsr-133 cookbook
>>         <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>  correctly,
>>         given the
>>         following:
>>
>>
>>         <code>
>>         //y is a global, non-volatile
>>         enter monitor x
>>         ...
>>         //do some work not involving y
>>         . . .
>>         exit monitor x
>>         y = 43
>>
>>         </code>
>>
>>         then at least according to the JMM, the following execution
>>         is possible:
>>         <code>
>>         //y is a global, non-volatile
>>         enter monitor x
>>         ...
>>         //do some work not involving y
>>         y = 43
>>         exit monitor x
>>         </code>
>>
>>         as in the first table in the cookbook, *normal stores* are
>>         allowed to be
>>         re-ordered before a *monitor exit* (but not before a *monitor
>>         enter*).
>>
>>         Although the issue isn't really one involving memory
>>         consistency, is that
>>         really allowed?  Because *increasing* the size of a critical
>>         section seems .
>>         . . I don't know . . . unhealthy.
>>         What if the program code computed the first 1000 prime
>>         numbers or something
>>         and wrote them to a global array (after the monitor exit)?
>>
>>         I was always under the impression that only the operations
>>         specified within
>>         a critical section would actually be executed between the
>>         enter/exit monitor
>>         pair
>>
>>         NB: Although, presumably the runtime/CPU would only do this
>>         if the critical
>>         section was leading to CPU stalls or the like and so in
>>         reality, not really
>>         producing a longer critical section execution time
>>
>>
>>
>>
>>         --
>>         View this message in context:
>>         http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>         Sent from the JSR166 Concurrency mailing list archive at
>>         Nabble.com.
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     -- 
>>     Cheers,
>>     ?
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/17bfaed8/attachment-0001.html>

From peter.levart at gmail.com  Wed Oct  8 09:02:46 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 15:02:46 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>
	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
Message-ID: <543535F6.2000808@gmail.com>

On 10/08/2014 12:23 PM, ?iktor ?lang wrote:
> Hi Peter,
>
> can you quantify: " is almost no additional runtime overhead."?

Limited to AtomicIntegerFieldUpdater, all individual modifying 
operations that map directly to Unsafe intrinsics benchmarked with JMH 
tests run at same speed as normal Java volatile write of int field. 
Thanks to Doug for pointing me to Paul Sandoz's J1 slides about 
VarHandles, I'll do some more tests... I have checked the slides and 
will try to do some benchmarks comparable to those done by Paul. I can 
see Paul is comparing VarHandles to AtomicReferenceFieldUpdater which 
will be harder to make as performant since it not only has to do a type 
check on target reference, but also on the value that is written to 
memory location (the type of object reference).


Regards, Peter

>
> On Wed, Oct 8, 2014 at 11:38 AM, Peter Levart <peter.levart at gmail.com>
> wrote:
>
>> On 10/05/2014 10:44 PM, Peter Levart wrote:
>>
>>> The 3rd report shows a result of experimental AtomicIntegerFieldUpdater
>>> implementation which loads new VM-anonymous class for each new instance
>>> which allows VM compiler to specialize code for a particular field. Such
>>> implementation is nearly as fast as Java field access. This is just a proof
>>> of concept. A little hack-ish, doesn't include the fix for the overly
>>> restrictive protected access yet, but here it is if anyone is interested:
>>>
>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.
>>> AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java
>>>
>> Hi,
>>
>> I experimented further with this.
>>
>> It seems that making 'offset' a static final field is not necessary to get
>> optimal performance out of specialized one-class-per-instance
>> Atomic*FieldUpdater. Only the 'cclass' field used in check matters. So
>> 'offset' can be pushed up to abstract Atomic*FieldUpdaterImpl as a final
>> instance field. Now that specialized subclass of Atomic*FieldUpdaterImpl is
>> only 'cclass' specific, it can be shared among instances that use the same
>> 'cclass'. That means only one VM-anonymous subclass per target class (or
>> subclass/caller of target class when protected access is involved). The
>> VM-anonymous subclass is cached using ClassValue:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.
>> AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>>
>> I seems that with such Atomic*FieldUpdater there is no compelling reason
>> to use Unsafe directly as there is almost no additional runtime overhead.
>> The only method that is about 30% slower than Java counterpart is get(),
>> but there's hardly a reason to use it instead of simple Java volatile field
>> read.
>>
>> Regards, Peter
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>


From viktor.klang at gmail.com  Wed Oct  8 09:05:03 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 8 Oct 2014 15:05:03 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <54352FD4.7060003@univ-mlv.fr>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
Message-ID: <CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>

On Wed, Oct 8, 2014 at 2:36 PM, Remi Forax <forax at univ-mlv.fr> wrote:

>
> On 10/08/2014 02:30 PM, ?iktor ?lang wrote:
>
>
>
> On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>
>>
>> On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>>
>> Sounds really bad if this is the case. I can totally understand eliding
>> locks that are re-taken in a nested fashion, but coarsening in terms of
>> coalescing neighboring acquisitions seems dubious.
>>
>>
>>  even in this case,
>> class Foo {
>>   public synchronized void setBar(Bar bar) { ... }
>>   public synchronized void setBaz(Baz baz) { ... }
>> }
>> ...
>>   Foo foo = ...
>>   foo.setBar(bar);
>>   foo.setBaz(baz);
>>
>> because sadly this code is very common :(
>>
>
>  Agreed. The case above is not really problematic since there are no
> invocations/reads/writes in between.
>
>
> sorry my code was not clear, I should have written:
>   Foo foo = ...
>   foo.setBar(this.bar);
>   foo.setBaz(this.baz);
>
> there is a load of the field baz in between the call to setBar and the
> call to setBaz.
>

It sounds like an (unhealthy?) possible interaction between roach motel
rule and lock coarsening?


>
> R?mi
>
>
>
>
>>
>> R?mi
>>
>>
>>
>> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <thurston at nomagicsoftware.com>
>> wrote:
>>
>>> Hello,
>>>
>>> If I read the  jsr-133 cookbook
>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>>> following:
>>>
>>>
>>> <code>
>>> //y is a global, non-volatile
>>> enter monitor x
>>> ...
>>> //do some work not involving y
>>> . . .
>>> exit monitor x
>>> y = 43
>>>
>>> </code>
>>>
>>> then at least according to the JMM, the following execution is possible:
>>> <code>
>>> //y is a global, non-volatile
>>> enter monitor x
>>> ...
>>> //do some work not involving y
>>> y = 43
>>> exit monitor x
>>> </code>
>>>
>>> as in the first table in the cookbook, *normal stores* are allowed to be
>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>
>>> Although the issue isn't really one involving memory consistency, is that
>>> really allowed?  Because *increasing* the size of a critical section
>>> seems .
>>> . . I don't know . . . unhealthy.
>>> What if the program code computed the first 1000 prime numbers or
>>> something
>>> and wrote them to a global array (after the monitor exit)?
>>>
>>> I was always under the impression that only the operations specified
>>> within
>>> a critical section would actually be executed between the enter/exit
>>> monitor
>>> pair
>>>
>>> NB: Although, presumably the runtime/CPU would only do this if the
>>> critical
>>> section was leading to CPU stalls or the like and so in reality, not
>>> really
>>> producing a longer critical section execution time
>>>
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>>  Cheers,
>> ?
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
>  Cheers,
> ?
>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/8d9a8e8b/attachment.html>

From peter.levart at gmail.com  Wed Oct  8 09:29:27 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 15:29:27 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <54352F34.1010100@univ-mlv.fr>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
	<54352F34.1010100@univ-mlv.fr>
Message-ID: <54353C37.3080107@gmail.com>

On 10/08/2014 02:33 PM, Remi Forax wrote:
> The code generates a different class for each field updater,
> so in that case the ccClass (the type of the field) is considered as a 
> constant
> so the instanceof check can be removed by the JIT.
>
> Usually, it's not a good idea to do that because you trade a constant 
> argument for
> a non constant implementation of the interface Atomic*FieldUpdater, 
> but given
> that the updater are usually static final, i.e. a constant for the JIT,
> here, it should be faster.
>
> Peter, in term of implementation, you can use the fact that you can patch
> the class when you call defineAnonymous class, so you can insert the 
> offset and the class,
> without using a thread local which is really a hack.

Yeah, I said it's a hack. But I don't know any other easy way. The 
constant patches requires me to parse or generate the bytecode to 
compute the index of the constant pool entry. In my hack, as you can 
see, I use javac in ahead-of-time mode to "generate" the bytecode...

>
> There is another way to do exactly the same things, make ccClass 
> constant foldable for
> the JIT without asking to load a bunch of classes. The implementation 
> of the Updater
> can be moved into java.lang.invoke and use the annotation @Stable, in 
> that case,
> the field ccCache will be considered as constant if the updater is 
> constant itself,
> this trick doesn't come from me but from Paul Sandoz which currently 
> works on
> this area as Doug mention.

Thanks for sharing, Remi.
I wondered what those @Stable annotations meant. I thought they were 
just fancy documentation. It's a pity that this is reserved for 
java.lang.invoke package use only. The annotation could be public, but 
be effective only on system classes like @CallerSensitive for example...

Regards, Peter

>
> cheers,
> R?mi
>
> On 10/08/2014 12:23 PM, ?iktor ?lang wrote:
>> Hi Peter,
>>
>> can you quantify: " is almost no additional runtime overhead."?
>>
>> On Wed, Oct 8, 2014 at 11:38 AM, Peter Levart <peter.levart at gmail.com 
>> <mailto:peter.levart at gmail.com>> wrote:
>>
>>     On 10/05/2014 10:44 PM, Peter Levart wrote:
>>
>>         The 3rd report shows a result of experimental
>>         AtomicIntegerFieldUpdater implementation which loads new
>>         VM-anonymous class for each new instance which allows VM
>>         compiler to specialize code for a particular field. Such
>>         implementation is nearly as fast as Java field access. This is
>>         just a proof of concept. A little hack-ish, doesn't include
>>         the fix for the overly restrictive protected access yet, but
>>         here it is if anyone is interested:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java
>> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java>
>>
>>
>>
>>     Hi,
>>
>>     I experimented further with this.
>>
>>     It seems that making 'offset' a static final field is not
>>     necessary to get optimal performance out of specialized
>>     one-class-per-instance Atomic*FieldUpdater. Only the 'cclass'
>>     field used in check matters. So 'offset' can be pushed up to
>>     abstract Atomic*FieldUpdaterImpl as a final instance field. Now
>>     that specialized subclass of Atomic*FieldUpdaterImpl is only
>>     'cclass' specific, it can be shared among instances that use the
>>     same 'cclass'. That means only one VM-anonymous subclass per
>>     target class (or subclass/caller of target class when protected
>>     access is involved). The VM-anonymous subclass is cached using
>>     ClassValue:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java>
>>
>>     I seems that with such Atomic*FieldUpdater there is no compelling
>>     reason to use Unsafe directly as there is almost no additional
>>     runtime overhead. The only method that is about 30% slower than
>>     Java counterpart is get(), but there's hardly a reason to use it
>>     instead of simple Java volatile field read.
>>
>>     Regards, Peter
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> -- 
>> Cheers,
>> ?
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/6f0e5fca/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  8 09:55:34 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 8 Oct 2014 09:55:34 -0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
Message-ID: <CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>

What is unhealthy about this? That a critical section lifetime is extended?
Let's assume both fields are in cache, why would you want two relatively
expensive lock acquisitions back to back instead of one?

Sent from my phone
On Oct 8, 2014 9:36 AM, "?iktor ?lang" <viktor.klang at gmail.com> wrote:

>
>
> On Wed, Oct 8, 2014 at 2:36 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>
>>
>> On 10/08/2014 02:30 PM, ?iktor ?lang wrote:
>>
>>
>>
>> On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>
>>>
>>> On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>>>
>>> Sounds really bad if this is the case. I can totally understand eliding
>>> locks that are re-taken in a nested fashion, but coarsening in terms of
>>> coalescing neighboring acquisitions seems dubious.
>>>
>>>
>>>  even in this case,
>>> class Foo {
>>>   public synchronized void setBar(Bar bar) { ... }
>>>   public synchronized void setBaz(Baz baz) { ... }
>>> }
>>> ...
>>>   Foo foo = ...
>>>   foo.setBar(bar);
>>>   foo.setBaz(baz);
>>>
>>> because sadly this code is very common :(
>>>
>>
>>  Agreed. The case above is not really problematic since there are no
>> invocations/reads/writes in between.
>>
>>
>> sorry my code was not clear, I should have written:
>>   Foo foo = ...
>>   foo.setBar(this.bar);
>>   foo.setBaz(this.baz);
>>
>> there is a load of the field baz in between the call to setBar and the
>> call to setBaz.
>>
>
> It sounds like an (unhealthy?) possible interaction between roach motel
> rule and lock coarsening?
>
>
>>
>> R?mi
>>
>>
>>
>>
>>>
>>> R?mi
>>>
>>>
>>>
>>> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <thurston at nomagicsoftware.com
>>> > wrote:
>>>
>>>> Hello,
>>>>
>>>> If I read the  jsr-133 cookbook
>>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>>>> following:
>>>>
>>>>
>>>> <code>
>>>> //y is a global, non-volatile
>>>> enter monitor x
>>>> ...
>>>> //do some work not involving y
>>>> . . .
>>>> exit monitor x
>>>> y = 43
>>>>
>>>> </code>
>>>>
>>>> then at least according to the JMM, the following execution is possible:
>>>> <code>
>>>> //y is a global, non-volatile
>>>> enter monitor x
>>>> ...
>>>> //do some work not involving y
>>>> y = 43
>>>> exit monitor x
>>>> </code>
>>>>
>>>> as in the first table in the cookbook, *normal stores* are allowed to be
>>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>>
>>>> Although the issue isn't really one involving memory consistency, is
>>>> that
>>>> really allowed?  Because *increasing* the size of a critical section
>>>> seems .
>>>> . . I don't know . . . unhealthy.
>>>> What if the program code computed the first 1000 prime numbers or
>>>> something
>>>> and wrote them to a global array (after the monitor exit)?
>>>>
>>>> I was always under the impression that only the operations specified
>>>> within
>>>> a critical section would actually be executed between the enter/exit
>>>> monitor
>>>> pair
>>>>
>>>> NB: Although, presumably the runtime/CPU would only do this if the
>>>> critical
>>>> section was leading to CPU stalls or the like and so in reality, not
>>>> really
>>>> producing a longer critical section execution time
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> View this message in context:
>>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>>
>>> --
>>>  Cheers,
>>> ?
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>>  Cheers,
>> ?
>>
>>
>>
>
>
> --
> Cheers,
> ?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/1abb6e45/attachment.html>

From peter.levart at gmail.com  Wed Oct  8 10:16:09 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 16:16:09 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <54351DD4.6050500@cs.oswego.edu>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
	<54351DD4.6050500@cs.oswego.edu>
Message-ID: <54354729.805@gmail.com>

On 10/08/2014 01:19 PM, Doug Lea wrote:
>
> On 10/08/2014 05:38 AM, Peter Levart wrote:
>>
>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java 
>>
>>
>
> Paul Sandoz has been working on VarHandles (like MethodHandles)
> for similar purposes. Possibly even the same purposes.
> See his JavaOne talk slides at
> http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
> It seems worth waiting for more progress on this front before
> contemplating changes along these lines.
>
> -Doug
>

Thanks Doug for pointing me to Paul's slides. I can see that Paul's 
VarHandles are based around the idea of methods with polymorphic 
signature akin to MethodHandles.invoke* with the benefit that they don't 
declare Throwable as thrown exception and he's adding some type 
inference changes on top of that.

Paul is exploring alternative approaches to JEP 193 which don't require 
language changes although he has already stepped beyond that line as I 
can see that his patch contains a few lines of javac changes.

I'm trying to see if there is an alternative to Paul's approach which 
doesn't require JVM changes either. I think it all boils down to how 
types involved are encoded and how type-checks can be optimized at 
runtime. As my preliminary hacking shows, there might be a solution in 
the existing virtual machinery.

Regards, Peter


From viktor.klang at gmail.com  Wed Oct  8 10:17:01 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 8 Oct 2014 16:17:01 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
	<CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>
Message-ID: <CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>

On Wed, Oct 8, 2014 at 3:55 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> What is unhealthy about this? That a critical section lifetime is
> extended? Let's assume both fields are in cache, why would you want two
> relatively expensive lock acquisitions back to back instead of one?
>
(Sidenote: Personally as I wouldn't want -any- expensive lock
acquisitions?I'd go lock-free.)

I'll have to think about it some more but my "Spidey senses are tingling".

What I reacted to was:

synchronized(x) { do stuff }
do other stuff
synchronized(x) { do more stuff }

The thing in the middle there is deliberately put outside of critical
sections, so it seems more like a compiler suggestion to widen it than a
runtime decision.

Let me dig a bit in my archives and see if I can find a use case for the
construct above.

Sent from my phone
> On Oct 8, 2014 9:36 AM, "?iktor ?lang" <viktor.klang at gmail.com> wrote:
>
>>
>>
>> On Wed, Oct 8, 2014 at 2:36 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>
>>>
>>> On 10/08/2014 02:30 PM, ?iktor ?lang wrote:
>>>
>>>
>>>
>>> On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>>
>>>>
>>>> On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>>>>
>>>> Sounds really bad if this is the case. I can totally understand eliding
>>>> locks that are re-taken in a nested fashion, but coarsening in terms of
>>>> coalescing neighboring acquisitions seems dubious.
>>>>
>>>>
>>>>  even in this case,
>>>> class Foo {
>>>>   public synchronized void setBar(Bar bar) { ... }
>>>>   public synchronized void setBaz(Baz baz) { ... }
>>>> }
>>>> ...
>>>>   Foo foo = ...
>>>>   foo.setBar(bar);
>>>>   foo.setBaz(baz);
>>>>
>>>> because sadly this code is very common :(
>>>>
>>>
>>>  Agreed. The case above is not really problematic since there are no
>>> invocations/reads/writes in between.
>>>
>>>
>>> sorry my code was not clear, I should have written:
>>>   Foo foo = ...
>>>   foo.setBar(this.bar);
>>>   foo.setBaz(this.baz);
>>>
>>> there is a load of the field baz in between the call to setBar and the
>>> call to setBaz.
>>>
>>
>> It sounds like an (unhealthy?) possible interaction between roach motel
>> rule and lock coarsening?
>>
>>
>>>
>>> R?mi
>>>
>>>
>>>
>>>
>>>>
>>>> R?mi
>>>>
>>>>
>>>>
>>>> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <
>>>> thurston at nomagicsoftware.com> wrote:
>>>>
>>>>> Hello,
>>>>>
>>>>> If I read the  jsr-133 cookbook
>>>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>>>>> following:
>>>>>
>>>>>
>>>>> <code>
>>>>> //y is a global, non-volatile
>>>>> enter monitor x
>>>>> ...
>>>>> //do some work not involving y
>>>>> . . .
>>>>> exit monitor x
>>>>> y = 43
>>>>>
>>>>> </code>
>>>>>
>>>>> then at least according to the JMM, the following execution is
>>>>> possible:
>>>>> <code>
>>>>> //y is a global, non-volatile
>>>>> enter monitor x
>>>>> ...
>>>>> //do some work not involving y
>>>>> y = 43
>>>>> exit monitor x
>>>>> </code>
>>>>>
>>>>> as in the first table in the cookbook, *normal stores* are allowed to
>>>>> be
>>>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>>>
>>>>> Although the issue isn't really one involving memory consistency, is
>>>>> that
>>>>> really allowed?  Because *increasing* the size of a critical section
>>>>> seems .
>>>>> . . I don't know . . . unhealthy.
>>>>> What if the program code computed the first 1000 prime numbers or
>>>>> something
>>>>> and wrote them to a global array (after the monitor exit)?
>>>>>
>>>>> I was always under the impression that only the operations specified
>>>>> within
>>>>> a critical section would actually be executed between the enter/exit
>>>>> monitor
>>>>> pair
>>>>>
>>>>> NB: Although, presumably the runtime/CPU would only do this if the
>>>>> critical
>>>>> section was leading to CPU stalls or the like and so in reality, not
>>>>> really
>>>>> producing a longer critical section execution time
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> View this message in context:
>>>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>>  Cheers,
>>>> ?
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>>
>>> --
>>>  Cheers,
>>> ?
>>>
>>>
>>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/76d50a79/attachment-0001.html>

From vladimir.x.ivanov at oracle.com  Wed Oct  8 10:28:03 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Wed, 08 Oct 2014 18:28:03 +0400
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <54353C37.3080107@gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<54353C37.3080107@gmail.com>
Message-ID: <543549F3.3030304@oracle.com>

>> Peter, in term of implementation, you can use the fact that you can patch
>> the class when you call defineAnonymous class, so you can insert the
>> offset and the class,
>> without using a thread local which is really a hack.
>
> Yeah, I said it's a hack. But I don't know any other easy way. The
> constant patches requires me to parse or generate the bytecode to
> compute the index of the constant pool entry. In my hack, as you can
> see, I use javac in ahead-of-time mode to "generate" the bytecode...
FTR, ClassWriter.newConst() is the way to get the index of constant pool 
entry.

This is how constant pool patches are used for j.l.i.LambdaForms:

java.lang.invoke.InvokerBytecodeGenerator:
     String constantPlaceholder(Object arg) {
         String cpPlaceholder = "CONSTANT_PLACEHOLDER_" + cph++;
         // insert placeholder in CP and remember the patch
         int index = cw.newConst((Object) cpPlaceholder);
         cpPatches.put(cpPlaceholder, new CpPatch(index, cpPlaceholder, 
arg));
         return cpPlaceholder;
     }

     Object[] cpPatches(byte[] classFile) {
         int size = getConstantPoolSize(classFile);
         Object[] res = new Object[size];
         for (CpPatch p : cpPatches.values()) {
	    res[p.index] = p.value;
         }
         return res;
     }

UNSAFE.defineAnonymousClass(HOST_CLASS, classBytes, cpPatches(classBytes));

Best regards,
Vladimir Ivanov

>
>>
>> There is another way to do exactly the same things, make ccClass
>> constant foldable for
>> the JIT without asking to load a bunch of classes. The implementation
>> of the Updater
>> can be moved into java.lang.invoke and use the annotation @Stable, in
>> that case,
>> the field ccCache will be considered as constant if the updater is
>> constant itself,
>> this trick doesn't come from me but from Paul Sandoz which currently
>> works on
>> this area as Doug mention.
>
> Thanks for sharing, Remi.
> I wondered what those @Stable annotations meant. I thought they were
> just fancy documentation. It's a pity that this is reserved for
> java.lang.invoke package use only. The annotation could be public, but
> be effective only on system classes like @CallerSensitive for example...
>
> Regards, Peter
>
>>
>> cheers,
>> R?mi
>>
>> On 10/08/2014 12:23 PM, ?iktor ?lang wrote:
>>> Hi Peter,
>>>
>>> can you quantify: " is almost no additional runtime overhead."?
>>>
>>> On Wed, Oct 8, 2014 at 11:38 AM, Peter Levart <peter.levart at gmail.com
>>> <mailto:peter.levart at gmail.com>> wrote:
>>>
>>>     On 10/05/2014 10:44 PM, Peter Levart wrote:
>>>
>>>         The 3rd report shows a result of experimental
>>>         AtomicIntegerFieldUpdater implementation which loads new
>>>         VM-anonymous class for each new instance which allows VM
>>>         compiler to specialize code for a particular field. Such
>>>         implementation is nearly as fast as Java field access. This is
>>>         just a proof of concept. A little hack-ish, doesn't include
>>>         the fix for the overly restrictive protected access yet, but
>>>         here it is if anyone is interested:
>>>
>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java
>>> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerInstance/AtomicIntegerFieldUpdater.java>
>>>
>>>
>>>
>>>     Hi,
>>>
>>>     I experimented further with this.
>>>
>>>     It seems that making 'offset' a static final field is not
>>>     necessary to get optimal performance out of specialized
>>>     one-class-per-instance Atomic*FieldUpdater. Only the 'cclass'
>>>     field used in check matters. So 'offset' can be pushed up to
>>>     abstract Atomic*FieldUpdaterImpl as a final instance field. Now
>>>     that specialized subclass of Atomic*FieldUpdaterImpl is only
>>>     'cclass' specific, it can be shared among instances that use the
>>>     same 'cclass'. That means only one VM-anonymous subclass per
>>>     target class (or subclass/caller of target class when protected
>>>     access is involved). The VM-anonymous subclass is cached using
>>>     ClassValue:
>>>
>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>>> <http://cr.openjdk.java.net/%7Eplevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java>
>>>
>>>     I seems that with such Atomic*FieldUpdater there is no compelling
>>>     reason to use Unsafe directly as there is almost no additional
>>>     runtime overhead. The only method that is about 30% slower than
>>>     Java counterpart is get(), but there's hardly a reason to use it
>>>     instead of simple Java volatile field read.
>>>
>>>     Regards, Peter
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> --
>>> Cheers,
>>> ?
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From vitalyd at gmail.com  Wed Oct  8 10:34:03 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 8 Oct 2014 10:34:03 -0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
	<CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>
	<CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>
Message-ID: <CAHjP37HcvT0YdQjea0r6Xn0N9XBxPPvOwQtyriXrQtfUYCHJQg@mail.gmail.com>

Yes, as Doug pointed out, the "roach motel" semantics is just an allowed
reordering -- compiler will hopefully not stuff more things into a critical
section unless it has strong evidence that it's worthwhile.  I'd actually
be curious to hear from anyone that's seen such a transformation.

On Wed, Oct 8, 2014 at 10:17 AM, ?iktor ?lang <viktor.klang at gmail.com>
wrote:

>
>
> On Wed, Oct 8, 2014 at 3:55 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
>
>> What is unhealthy about this? That a critical section lifetime is
>> extended? Let's assume both fields are in cache, why would you want two
>> relatively expensive lock acquisitions back to back instead of one?
>>
> (Sidenote: Personally as I wouldn't want -any- expensive lock
> acquisitions?I'd go lock-free.)
>
> I'll have to think about it some more but my "Spidey senses are tingling".
>
> What I reacted to was:
>
> synchronized(x) { do stuff }
> do other stuff
> synchronized(x) { do more stuff }
>
> The thing in the middle there is deliberately put outside of critical
> sections, so it seems more like a compiler suggestion to widen it than a
> runtime decision.
>
> Let me dig a bit in my archives and see if I can find a use case for the
> construct above.
>
> Sent from my phone
>> On Oct 8, 2014 9:36 AM, "?iktor ?lang" <viktor.klang at gmail.com> wrote:
>>
>>>
>>>
>>> On Wed, Oct 8, 2014 at 2:36 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>>
>>>>
>>>> On 10/08/2014 02:30 PM, ?iktor ?lang wrote:
>>>>
>>>>
>>>>
>>>> On Wed, Oct 8, 2014 at 2:09 PM, Remi Forax <forax at univ-mlv.fr> wrote:
>>>>
>>>>>
>>>>> On 10/08/2014 12:51 PM, ?iktor ?lang wrote:
>>>>>
>>>>> Sounds really bad if this is the case. I can totally understand
>>>>> eliding locks that are re-taken in a nested fashion, but coarsening in
>>>>> terms of coalescing neighboring acquisitions seems dubious.
>>>>>
>>>>>
>>>>>  even in this case,
>>>>> class Foo {
>>>>>   public synchronized void setBar(Bar bar) { ... }
>>>>>   public synchronized void setBaz(Baz baz) { ... }
>>>>> }
>>>>> ...
>>>>>   Foo foo = ...
>>>>>   foo.setBar(bar);
>>>>>   foo.setBaz(baz);
>>>>>
>>>>> because sadly this code is very common :(
>>>>>
>>>>
>>>>  Agreed. The case above is not really problematic since there are no
>>>> invocations/reads/writes in between.
>>>>
>>>>
>>>> sorry my code was not clear, I should have written:
>>>>   Foo foo = ...
>>>>   foo.setBar(this.bar);
>>>>   foo.setBaz(this.baz);
>>>>
>>>> there is a load of the field baz in between the call to setBar and the
>>>> call to setBaz.
>>>>
>>>
>>> It sounds like an (unhealthy?) possible interaction between roach motel
>>> rule and lock coarsening?
>>>
>>>
>>>>
>>>> R?mi
>>>>
>>>>
>>>>
>>>>
>>>>>
>>>>> R?mi
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Oct 8, 2014 at 12:19 PM, thurstonn <
>>>>> thurston at nomagicsoftware.com> wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> If I read the  jsr-133 cookbook
>>>>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given
>>>>>> the
>>>>>> following:
>>>>>>
>>>>>>
>>>>>> <code>
>>>>>> //y is a global, non-volatile
>>>>>> enter monitor x
>>>>>> ...
>>>>>> //do some work not involving y
>>>>>> . . .
>>>>>> exit monitor x
>>>>>> y = 43
>>>>>>
>>>>>> </code>
>>>>>>
>>>>>> then at least according to the JMM, the following execution is
>>>>>> possible:
>>>>>> <code>
>>>>>> //y is a global, non-volatile
>>>>>> enter monitor x
>>>>>> ...
>>>>>> //do some work not involving y
>>>>>> y = 43
>>>>>> exit monitor x
>>>>>> </code>
>>>>>>
>>>>>> as in the first table in the cookbook, *normal stores* are allowed to
>>>>>> be
>>>>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>>>>
>>>>>> Although the issue isn't really one involving memory consistency, is
>>>>>> that
>>>>>> really allowed?  Because *increasing* the size of a critical section
>>>>>> seems .
>>>>>> . . I don't know . . . unhealthy.
>>>>>> What if the program code computed the first 1000 prime numbers or
>>>>>> something
>>>>>> and wrote them to a global array (after the monitor exit)?
>>>>>>
>>>>>> I was always under the impression that only the operations specified
>>>>>> within
>>>>>> a critical section would actually be executed between the enter/exit
>>>>>> monitor
>>>>>> pair
>>>>>>
>>>>>> NB: Although, presumably the runtime/CPU would only do this if the
>>>>>> critical
>>>>>> section was leading to CPU stalls or the like and so in reality, not
>>>>>> really
>>>>>> producing a longer critical section execution time
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> View this message in context:
>>>>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>>>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>>  Cheers,
>>>>> ?
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>>  Cheers,
>>>> ?
>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> Cheers,
>>> ?
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>
>
> --
> Cheers,
> ?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/8334bf23/attachment-0001.html>

From peter.levart at gmail.com  Wed Oct  8 11:09:15 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 17:09:15 +0200
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <54352F34.1010100@univ-mlv.fr>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
	<54352F34.1010100@univ-mlv.fr>
Message-ID: <5435539B.3010004@gmail.com>

On 10/08/2014 02:33 PM, Remi Forax wrote:
> There is another way to do exactly the same things, make ccClass 
> constant foldable for
> the JIT without asking to load a bunch of classes. The implementation 
> of the Updater
> can be moved into java.lang.invoke and use the annotation @Stable, in 
> that case,
> the field ccCache will be considered as constant if the updater is 
> constant itself,
> this trick doesn't come from me but from Paul Sandoz which currently 
> works on
> this area as Doug mention. 

That's really cool, Remi!

Just by moving the nested 
AtomicIntegerFieldUpdater.AtomicIntegerFieldUpdaterImpl class to 
java.lang.invoke package, annotating the final instance fields 'tclass', 
'cclass' and 'offset' with @Stable annotation and simplifying the 
invocation check, I get the same benchmark results. Why are those JVM 
pearls so hidden in the java.lang.invoke package?

Now let me try to get something similar from AtomicReferenceFieldUpdater...

Regards, Peter




From vladimir.x.ivanov at oracle.com  Wed Oct  8 11:41:37 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Wed, 08 Oct 2014 19:41:37 +0400
Subject: [concurrency-interest] Here's why Atomic*FieldReference access
 checking is broken
In-Reply-To: <5435539B.3010004@gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com>
Message-ID: <54355B31.5010009@oracle.com>

> Just by moving the nested
> AtomicIntegerFieldUpdater.AtomicIntegerFieldUpdaterImpl class to
> java.lang.invoke package, annotating the final instance fields 'tclass',
> 'cclass' and 'offset' with @Stable annotation and simplifying the
> invocation check, I get the same benchmark results. Why are those JVM
> pearls so hidden in the java.lang.invoke package?
Mostly because they are not ready for prime time yet.
There's a draft proposal for "lazy final" fields [1], but it hasn't been 
submitted officially yet. It covers part of the functionality provided 
by @Stable (fields, but not arrays).

Best regards,
Vladimir Ivanov

[1] http://cr.openjdk.java.net/~jrose/draft/lazy-final.html

>
> Now let me try to get something similar from AtomicReferenceFieldUpdater...
>
> Regards, Peter
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From paul.sandoz at oracle.com  Wed Oct  8 12:00:09 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Wed, 8 Oct 2014 09:00:09 -0700
Subject: [concurrency-interest] Optimizing Atomic*FieldReference <was> Re:
	Here's why Atomic*FieldReference access checking is broken
In-Reply-To: <54354729.805@gmail.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
	<54351DD4.6050500@cs.oswego.edu> <54354729.805@gmail.com>
Message-ID: <40A19A42-4DA5-4546-A87E-480D6ECF1FA2@oracle.com>


On Oct 8, 2014, at 7:16 AM, Peter Levart <peter.levart at gmail.com> wrote:

> On 10/08/2014 01:19 PM, Doug Lea wrote:
>> 
>> On 10/08/2014 05:38 AM, Peter Levart wrote:
>>> 
>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java 
>>> 
>> 
>> Paul Sandoz has been working on VarHandles (like MethodHandles)
>> for similar purposes. Possibly even the same purposes.
>> See his JavaOne talk slides at
>> http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
>> It seems worth waiting for more progress on this front before
>> contemplating changes along these lines.
>> 
>> -Doug
>> 
> 
> Thanks Doug for pointing me to Paul's slides. I can see that Paul's VarHandles are based around the idea of methods with polymorphic signature akin to MethodHandles.invoke* with the benefit that they don't declare Throwable as thrown exception and he's adding some type inference changes on top of that.
> 
> Paul is exploring alternative approaches to JEP 193 which don't require language changes although he has already stepped beyond that line as I can see that his patch contains a few lines of javac changes.
> 

Yes, it requires some small changes to how polymorphic signature methods are expressed but requires no new language syntax. The downside is the specs require updating to say "here is another class with polymorphic signature methods" so it is not very general.


> I'm trying to see if there is an alternative to Paul's approach which doesn't require JVM changes either. I think it all boils down to how types involved are encoded and how type-checks can be optimized at runtime. As my preliminary hacking shows, there might be a solution in the existing virtual machinery.
> 

The key optimization is "final fields are really final" [*], the privilege of which is bestowed on all classes in java.lang.invoke. That enables cast checks to be optimized away under the right conditions. I experimented with Atomic* like classes in that package (plus it is possible to extend the privilege to all classes which of course can be dangerous).

The current VarHandle prototype provides access over fields and array elements (and arrays of primitives off-heap) using just one abstract class. The API is a little raw but when specialization arrives it should be possible to surface a better API without creating specific classes for int/long/ref etc (i managed to hack in an approach in the current prototype to reify type variables while also avoiding boxing, but unfortunately i don't think we can use that technique).

There may be ways to surface the same functionality using indy. The trick would be to do this in such a way that javac could use indy or not and there would be no change in semantics, but the JIT could better optimize the former.

Regardless of what way we surface the API there are a few tweaks to the hotspot compiler we can do related to casts and bounds checks (which are mostly important for CAS).

Paul.

[*] This generally seems a very good thing to do if we can work out how to safely support reflection-based seriaization and DI frameworks.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/b5c79711/attachment.bin>

From boehm at acm.org  Wed Oct  8 14:12:54 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 8 Oct 2014 11:12:54 -0700
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CAHjP37HcvT0YdQjea0r6Xn0N9XBxPPvOwQtyriXrQtfUYCHJQg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
	<CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>
	<CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>
	<CAHjP37HcvT0YdQjea0r6Xn0N9XBxPPvOwQtyriXrQtfUYCHJQg@mail.gmail.com>
Message-ID: <CAPUmR1YBrLip-sF=0r3EeMYRmMwyhaYg-W0tXn1Wv8QpXVWu+w@mail.gmail.com>

The original transformation, moving a trailing "y = 43" into a critical
section, can typically happen on a weakly ordered architecture like ARM as
a result of hardware reordering.   On such an architecture, an ordinary
lock release is essentially a fence followed by an unordered CAS (or on
ARMv8, a CAS with release semantics).  There is nothing to prevent a later
store to y from becoming visible before the CAS releasing the lock.  No
compiler transformations required ...

Hans

On Wed, Oct 8, 2014 at 7:34 AM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Yes, as Doug pointed out, the "roach motel" semantics is just an allowed
> reordering -- compiler will hopefully not stuff more things into a critical
> section unless it has strong evidence that it's worthwhile.  I'd actually
> be curious to hear from anyone that's seen such a transformation.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/e72ca18b/attachment.html>

From peter.levart at gmail.com  Wed Oct  8 14:19:56 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 08 Oct 2014 20:19:56 +0200
Subject: [concurrency-interest] FieldReference vs. AtomicFieldUpdater - was
 Re: Optimizing Atomic*FieldReference <was> Re: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <40A19A42-4DA5-4546-A87E-480D6ECF1FA2@oracle.com>
References: <542EBD0C.7080301@redhat.com>
	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>
	<5435062C.6020200@gmail.com>	<54351DD4.6050500@cs.oswego.edu>
	<54354729.805@gmail.com>
	<40A19A42-4DA5-4546-A87E-480D6ECF1FA2@oracle.com>
Message-ID: <5435804C.2050400@gmail.com>

Hi Paul,

Since this thread is way from original topic, I changed it. It is very 
interesting though.

On 10/08/2014 06:00 PM, Paul Sandoz wrote:
> On Oct 8, 2014, at 7:16 AM, Peter Levart <peter.levart at gmail.com> wrote:
>
>> On 10/08/2014 01:19 PM, Doug Lea wrote:
>>> On 10/08/2014 05:38 AM, Peter Levart wrote:
>>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>>>>
>>> Paul Sandoz has been working on VarHandles (like MethodHandles)
>>> for similar purposes. Possibly even the same purposes.
>>> See his JavaOne talk slides at
>>> http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
>>> It seems worth waiting for more progress on this front before
>>> contemplating changes along these lines.
>>>
>>> -Doug
>>>
>> Thanks Doug for pointing me to Paul's slides. I can see that Paul's VarHandles are based around the idea of methods with polymorphic signature akin to MethodHandles.invoke* with the benefit that they don't declare Throwable as thrown exception and he's adding some type inference changes on top of that.
>>
>> Paul is exploring alternative approaches to JEP 193 which don't require language changes although he has already stepped beyond that line as I can see that his patch contains a few lines of javac changes.
>>
> Yes, it requires some small changes to how polymorphic signature methods are expressed but requires no new language syntax. The downside is the specs require updating to say "here is another class with polymorphic signature methods" so it is not very general.

And I think you also showed on your slides, that polymorphic signature 
methods don't provide static type checking. Are there any plans to merge 
polymorphic signature methods with generic types? Currently both 
polymorphic signature methods that I know of 
(MethodHandle.invoke[Exact]) allow passing any type and number of 
arguments and return Object. Would it be possible to have "constrained" 
polymorphic signature methods that are static type-checked as normal 
methods, but otherwise "behave" like polymorphic signature methods?

>
>
>> I'm trying to see if there is an alternative to Paul's approach which doesn't require JVM changes either. I think it all boils down to how types involved are encoded and how type-checks can be optimized at runtime. As my preliminary hacking shows, there might be a solution in the existing virtual machinery.
>>
> The key optimization is "final fields are really final" [*], the privilege of which is bestowed on all classes in java.lang.invoke. That enables cast checks to be optimized away under the right conditions. I experimented with Atomic* like classes in that package (plus it is possible to extend the privilege to all classes which of course can be dangerous).

So if that works, why is FieldReference API designed around polymorphic 
signature methods then? What do they buy you? Specialization for 
primitive types? Reification of static types used at call-site?


>
> The current VarHandle prototype provides access over fields and array elements (and arrays of primitives off-heap) using just one abstract class. The API is a little raw but when specialization arrives it should be possible to surface a better API without creating specific classes for int/long/ref etc (i managed to hack in an approach in the current prototype to reify type variables while also avoiding boxing, but unfortunately i don't think we can use that technique).

It may be necessary to have specific classes for int/long/ref because 
there are operations that you do with int/long that have no meaning with 
references like addAndGet, etc... but I can see that the number of 
classes can be reduced this way.

>
> There may be ways to surface the same functionality using indy. The trick would be to do this in such a way that javac could use indy or not and there would be no change in semantics, but the JIT could better optimize the former.
>
> Regardless of what way we surface the API there are a few tweaks to the hotspot compiler we can do related to casts and bounds checks (which are mostly important for CAS).
>
> Paul.
>
> [*] This generally seems a very good thing to do if we can work out how to safely support reflection-based seriaization and DI frameworks.

One way perhaps could be to simply not support it. Static final fields 
are really final (with exception of System.out/in/err). If instance 
field is marked as "transient final", reflection could refuse updating 
it. There are serialization frameworks that (de)serialize even 
"transient final" fields, so they would fail. But if they are worth 
anything, they surely must have a mode that works in SecurityManager 
enabled environments, where updating final fields is not possible so 
they must be skipped. If backwards compatibility is a must, then a VM 
switch could turn this feature off. It is, after all, only an optimization.

Otherwise, there would have to be a new language way to mark those 
fields. What's wrong with @Stable annotation in addition to "transient 
final" modifiers? It doesn't change the semantics of a program after 
all. Java serialization would not touch it and reflection could be 
easily tweaked to refuse updating such fields even if 
Field.setAccessible(true) was used... It could be useful at least for 
global JDK-internal use, if it is not fancy enough for general use.

Regards, Peter

>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/1491427e/attachment.html>

From vitalyd at gmail.com  Wed Oct  8 14:23:11 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 8 Oct 2014 14:23:11 -0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CAPUmR1YBrLip-sF=0r3EeMYRmMwyhaYg-W0tXn1Wv8QpXVWu+w@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>
	<54352989.6060308@univ-mlv.fr>
	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>
	<54352FD4.7060003@univ-mlv.fr>
	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>
	<CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>
	<CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>
	<CAHjP37HcvT0YdQjea0r6Xn0N9XBxPPvOwQtyriXrQtfUYCHJQg@mail.gmail.com>
	<CAPUmR1YBrLip-sF=0r3EeMYRmMwyhaYg-W0tXn1Wv8QpXVWu+w@mail.gmail.com>
Message-ID: <CAHjP37HEndZhzgxzTue0y15eWT2Lx8EMevu=DF37yuiWKa1_NA@mail.gmail.com>

That's fine -- if hardware wants to reorder, no issues (and it typically
does that for efficiency anyway).  My curiosity is about compiler-only
transformation, as I'm interested in seeing what that code would look like.

On Wed, Oct 8, 2014 at 2:12 PM, Hans Boehm <boehm at acm.org> wrote:

> The original transformation, moving a trailing "y = 43" into a critical
> section, can typically happen on a weakly ordered architecture like ARM as
> a result of hardware reordering.   On such an architecture, an ordinary
> lock release is essentially a fence followed by an unordered CAS (or on
> ARMv8, a CAS with release semantics).  There is nothing to prevent a later
> store to y from becoming visible before the CAS releasing the lock.  No
> compiler transformations required ...
>
> Hans
>
> On Wed, Oct 8, 2014 at 7:34 AM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
>
>> Yes, as Doug pointed out, the "roach motel" semantics is just an allowed
>> reordering -- compiler will hopefully not stuff more things into a critical
>> section unless it has strong evidence that it's worthwhile.  I'd actually
>> be curious to hear from anyone that's seen such a transformation.
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/68dac699/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Oct  8 23:16:28 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 9 Oct 2014 13:16:28 +1000
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <1412768699357-11328.post@n7.nabble.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>

Thurston writes:
> David Holmes-6 wrote
> > Not only is it allowed, it can easily be performed by the JIT. If that
> > seems
> > "unhealthy" you will be really freaked out by lock-coarsening which can
> > coalesce:
> >
> > synchronized(x) {
> >  // aaa
> > }
> > // other code
> > synchronized(x) {
> >  // bbb
> > }
> >
> > into
> >
> > synchronized(x) {
> >   // aaa
> >   // other code
> >   // bbb
> > }
> >
> > where anything in the sync block can of course be further reordered.
> >
> > Of course this can't be done arbitrarily but it can be done.
> >
> > Cheers,
> > David Holmes
> >
> >>
>
> Thanks.
> To be precise, there is a hb(aaa, bbb), surely that needs to be
> respected in the rewritten *coalesced* code; as far as "other code",
> anything goes I guess

I don't believe hb has any impact here - as long as intra thread semantics
are obeyed.

Lock coarsening has been employed in hotspot for years now:

http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2

Personally I opposed it on liveness grounds - I presume that if you wrote
two close but seperate sync blocks then you had a good reason to do so, most
likely relating to liveness.

David
-----




>
>
>
> --
> View this message in context:
http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-moni
tor-tp11323p11328.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From nathan.reynolds at oracle.com  Thu Oct  9 00:43:33 2014
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 08 Oct 2014 21:43:33 -0700
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
Message-ID: <54361275.9070203@oracle.com>

Generally, I am against lock coarsening.  When facing a problematic 
lock, the first thing I do is move everything out of the lock that can 
possibly be done.

In HotSpot version 7349, JIT will generate code with aggressive lock 
coarsening.  If the lock becomes contended, then it will iteratively 
reduce or remove the coarsening and see if that improves lock 
throughput.  It will even go further and automatically pull out all of 
the code which doesn't need to be inside the lock.  ;)

*Example #1*

Consider this code which models an actual problem seen. key.hashCode() 
takes a lot of CPU time but fortunately the result is cached inside the 
key object.  The problem is that key.hashCode() was being computed 
inside the lock for most key objects.

synchronized (map)
{
    map.put(key, value);
}

The solution was to simply call key.hashCode() just before the lock.  
Fortunately, HotSpot doesn't pull this back inside the lock.

key.hashCode();

synchronized (map)
{
    map.put(key, value);
}

However, there are some cases where lock coarsening makes sense.

*Example #2*

Consider this code which models an actual problem seen.  In the actual 
problem, we weren't dealing with a Map however this code suffices to 
make the point.  Each iteration is going to acquire and release the 
lock.  The code executed outside of the lock (i.e. the for statement) is 
very light.  It makes sense to coarsen the lock to surround the entire 
for loop so that the lock is acquired and released one time.

private Map<String, String> map = Collections.synchronizedMap(new 
HashMap<>());

...
    for (i = 0; i < array.length; i++)
       map.put(array[i], ""));

*Example #3*

Consider this code.  If functionA() is inlined into functionB(), then 
there will be 2 synchronized blocks on the same lock back to back to 
each other.  The programmer isn't being dumb.  This is where software 
design creates a situation where lock coarsening is good.

void functionA()
{
    // some code

     synchronized (lock)
     {
         // some more code
     }
}

void functionB()
{
     functionA();

     synchronized (lock)
     {
         // some more code
     }

    // some code
}

-Nathan

On 10/8/2014 8:16 PM, David Holmes wrote:
> Thurston writes:
>> David Holmes-6 wrote
>>> Not only is it allowed, it can easily be performed by the JIT. If that
>>> seems
>>> "unhealthy" you will be really freaked out by lock-coarsening which can
>>> coalesce:
>>>
>>> synchronized(x) {
>>>   // aaa
>>> }
>>> // other code
>>> synchronized(x) {
>>>   // bbb
>>> }
>>>
>>> into
>>>
>>> synchronized(x) {
>>>    // aaa
>>>    // other code
>>>    // bbb
>>> }
>>>
>>> where anything in the sync block can of course be further reordered.
>>>
>>> Of course this can't be done arbitrarily but it can be done.
>>>
>>> Cheers,
>>> David Holmes
>>>
>> Thanks.
>> To be precise, there is a hb(aaa, bbb), surely that needs to be
>> respected in the rewritten *coalesced* code; as far as "other code",
>> anything goes I guess
> I don't believe hb has any impact here - as long as intra thread semantics
> are obeyed.
>
> Lock coarsening has been employed in hotspot for years now:
>
> http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2
>
> Personally I opposed it on liveness grounds - I presume that if you wrote
> two close but seperate sync blocks then you had a good reason to do so, most
> likely relating to liveness.
>
> David
> -----
>
>
>
>
>>
>>
>> --
>> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-moni
> tor-tp11323p11328.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141008/2eb0664d/attachment.html>

From thurston at nomagicsoftware.com  Thu Oct  9 04:10:26 2014
From: thurston at nomagicsoftware.com (thurstonn)
Date: Thu, 9 Oct 2014 01:10:26 -0700 (MST)
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
References: <1412763544022-11323.post@n7.nabble.com>
	<NFBBKALFDCPFIDBNKAPCCEKEKJAA.davidcholmes@aapt.net.au>
	<1412768699357-11328.post@n7.nabble.com>
	<NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
Message-ID: <1412842226979-11350.post@n7.nabble.com>

"I don't believe hb has any impact here - as long as intra thread semantics
are obeyed." 

Yes, you're right - any other thread that subsequently acquires the monitor
will see aaa and other code and bbb no matter what their 'original'
execution order; silly comment on my part



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323p11350.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From peter.levart at gmail.com  Thu Oct  9 05:52:43 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 09 Oct 2014 11:52:43 +0200
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <54355B31.5010009@oracle.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com> <54355B31.5010009@oracle.com>
Message-ID: <54365AEB.5070002@gmail.com>

On 10/08/2014 05:41 PM, Vladimir Ivanov wrote:
>> Just by moving the nested
>> AtomicIntegerFieldUpdater.AtomicIntegerFieldUpdaterImpl class to
>> java.lang.invoke package, annotating the final instance fields 'tclass',
>> 'cclass' and 'offset' with @Stable annotation and simplifying the
>> invocation check, I get the same benchmark results. Why are those JVM
>> pearls so hidden in the java.lang.invoke package?
> Mostly because they are not ready for prime time yet.
> There's a draft proposal for "lazy final" fields [1], but it hasn't 
> been submitted officially yet. It covers part of the functionality 
> provided by @Stable (fields, but not arrays).
>
> Best regards,
> Vladimir Ivanov
>
> [1] http://cr.openjdk.java.net/~jrose/draft/lazy-final.html

That's great. I can see that there are two points encapsulated in this 
lazy finals proposal. One is the lazy assignment that can occur any time 
after constructor, restricted perhaps only to code of the declaring 
class, and the other is that such fields are *really* final, or in other 
words @Stable, meaning they can not be assigned twice, not even with 
reflection, which enables compiler optimizations. It's a little odd that 
in order to achieve *really* final behaviour and consequently better 
optimization, you would have to give up on  the definitive assignment 
rules help from javac.

But what about this idea:

Reflection supports updating ordinary final instance fields (via 
privileged setAccessible(true)) in order to achieve just what the lazy 
final fields are trying to achieve - lazy initialization outside 
constructor. Mainly to support Java  and other kinds of 
deserializations. I would say that any other uses of setAccessible(true) 
which assigns final field more than once are rare or non-existent. So 
why not making ordinary instance final fields *really* final by treating 
them in reflection as lazy final fields with a little tweak - the 
assignment of null/zero value to an "unassigned" field would not throw 
exception, but just be a NOOP - leave the field in "unassinged" state.

This way deserialization of ordinary final fields would still work, but 
VM compiler could treat them all as @Stable, immediately optimizing huge 
codebases on a different level.

Am I not seeing something in that simplified picture?

Regards, Peter

>
>>
>> Now let me try to get something similar from 
>> AtomicReferenceFieldUpdater...
>>
>> Regards, Peter
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From vladimir.x.ivanov at oracle.com  Thu Oct  9 06:23:56 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Thu, 09 Oct 2014 14:23:56 +0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <54365AEB.5070002@gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com> <54355B31.5010009@oracle.com>
	<54365AEB.5070002@gmail.com>
Message-ID: <5436623C.1030104@oracle.com>

Peter,

>> [1] http://cr.openjdk.java.net/~jrose/draft/lazy-final.html
>
> That's great. I can see that there are two points encapsulated in this
> lazy finals proposal. One is the lazy assignment that can occur any time
> after constructor, restricted perhaps only to code of the declaring
> class, and the other is that such fields are *really* final, or in other
> words @Stable, meaning they can not be assigned twice, not even with
> reflection, which enables compiler optimizations. It's a little odd that
> in order to achieve *really* final behaviour and consequently better
> optimization, you would have to give up on  the definitive assignment
> rules help from javac.
I don't see how it improves the situation, except allowing lazy 
initialization. It suffers from the very same problems as final fields, 
if you want to perform multiple updates. And the price for lazy 
initialization is default value, which can't be optimized anymore.

> But what about this idea:
>
> Reflection supports updating ordinary final instance fields (via
> privileged setAccessible(true)) in order to achieve just what the lazy
> final fields are trying to achieve - lazy initialization outside
> constructor. Mainly to support Java  and other kinds of
> deserializations. I would say that any other uses of setAccessible(true)
> which assigns final field more than once are rare or non-existent. So
> why not making ordinary instance final fields *really* final by treating
> them in reflection as lazy final fields with a little tweak - the
> assignment of null/zero value to an "unassigned" field would not throw
> exception, but just be a NOOP - leave the field in "unassinged" state.
>
> This way deserialization of ordinary final fields would still work, but
> VM compiler could treat them all as @Stable, immediately optimizing huge
> codebases on a different level.
>
> Am I not seeing something in that simplified picture?
It's all about JIT compiler. Lazy finals/@Stable aren't a full match for 
final field case, but they are close.

The problem with treating final fields as lazy finals, is it can't be 
limited only to accesses through Reflection API. The change should be 
pervasive and default values should be treated specially everywhere, 
forbidding constant-folding of loads from final fields w/ default 
values. Do we really want that?

Regarding constant folding of loads from final fields, Hotspot already 
optimizes loads for static final fields and there's an experimental flag 
TrustFinalNonStaticFields for final instance fields case.

What HotSpot misses right now (to preserve correctness w.r.t. Reflection 
API) is a way to track dependencies between final fields and nmethods 
which embed their values. It would allow to invalidate all nmethods 
which rely on stale value and ensure the updated value is "visible" 
everywhere in the running application.

Best regards,
Vladimir Ivanov
>
> Regards, Peter
>
>>
>>>
>>> Now let me try to get something similar from
>>> AtomicReferenceFieldUpdater...
>>>
>>> Regards, Peter
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From java at java4.info  Thu Oct  9 07:00:46 2014
From: java at java4.info (Florian Binder)
Date: Thu, 09 Oct 2014 13:00:46 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <54361275.9070203@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
	<54361275.9070203@oracle.com>
Message-ID: <54366ADE.7080707@java4.info>

I would like to throw another question into this interesting discussion:

How is the relationship between lock coarsening and biased locking?

Both depends on contention. So if the lock is not contended biased 
locking can be used and coarsening is not necessary anymore. But is 
coarsening really useful in the case where it is contended so biased 
locking can not be used?

Or is it maybe dependent on the degree of contention like this:

no contention: biased locking
low contention: coarsening
high contention: nothing

Flo

Am 09.10.2014 um 06:43 schrieb Nathan Reynolds:
> Generally, I am against lock coarsening.  When facing a problematic 
> lock, the first thing I do is move everything out of the lock that can 
> possibly be done.
>
> In HotSpot version 7349, JIT will generate code with aggressive lock 
> coarsening.  If the lock becomes contended, then it will iteratively 
> reduce or remove the coarsening and see if that improves lock 
> throughput.  It will even go further and automatically pull out all of 
> the code which doesn't need to be inside the lock.  ;)
>
> *Example #1*
>
> Consider this code which models an actual problem seen. key.hashCode() 
> takes a lot of CPU time but fortunately the result is cached inside 
> the key object.  The problem is that key.hashCode() was being computed 
> inside the lock for most key objects.
>
> synchronized (map)
> {
>    map.put(key, value);
> }
>
> The solution was to simply call key.hashCode() just before the lock.  
> Fortunately, HotSpot doesn't pull this back inside the lock.
>
> key.hashCode();
>
> synchronized (map)
> {
>    map.put(key, value);
> }
>
> However, there are some cases where lock coarsening makes sense.
>
> *Example #2*
>
> Consider this code which models an actual problem seen.  In the actual 
> problem, we weren't dealing with a Map however this code suffices to 
> make the point.  Each iteration is going to acquire and release the 
> lock.  The code executed outside of the lock (i.e. the for statement) 
> is very light.  It makes sense to coarsen the lock to surround the 
> entire for loop so that the lock is acquired and released one time.
>
> private Map<String, String> map = Collections.synchronizedMap(new 
> HashMap<>());
>
> ...
>    for (i = 0; i < array.length; i++)
>       map.put(array[i], ""));
>
> *Example #3*
>
> Consider this code.  If functionA() is inlined into functionB(), then 
> there will be 2 synchronized blocks on the same lock back to back to 
> each other.  The programmer isn't being dumb.  This is where software 
> design creates a situation where lock coarsening is good.
>
> void functionA()
> {
>    // some code
>
>     synchronized (lock)
>     {
>         // some more code
>     }
> }
>
> void functionB()
> {
>     functionA();
>
>     synchronized (lock)
>     {
>         // some more code
>     }
>
>    // some code
> }
> -Nathan
> On 10/8/2014 8:16 PM, David Holmes wrote:
>> Thurston writes:
>>> David Holmes-6 wrote
>>>> Not only is it allowed, it can easily be performed by the JIT. If that
>>>> seems
>>>> "unhealthy" you will be really freaked out by lock-coarsening which can
>>>> coalesce:
>>>>
>>>> synchronized(x) {
>>>>   // aaa
>>>> }
>>>> // other code
>>>> synchronized(x) {
>>>>   // bbb
>>>> }
>>>>
>>>> into
>>>>
>>>> synchronized(x) {
>>>>    // aaa
>>>>    // other code
>>>>    // bbb
>>>> }
>>>>
>>>> where anything in the sync block can of course be further reordered.
>>>>
>>>> Of course this can't be done arbitrarily but it can be done.
>>>>
>>>> Cheers,
>>>> David Holmes
>>>>
>>> Thanks.
>>> To be precise, there is a hb(aaa, bbb), surely that needs to be
>>> respected in the rewritten *coalesced* code; as far as "other code",
>>> anything goes I guess
>> I don't believe hb has any impact here - as long as intra thread semantics
>> are obeyed.
>>
>> Lock coarsening has been employed in hotspot for years now:
>>
>> http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2
>>
>> Personally I opposed it on liveness grounds - I presume that if you wrote
>> two close but seperate sync blocks then you had a good reason to do so, most
>> likely relating to liveness.
>>
>> David
>> -----
>>
>>
>>
>>
>>>
>>> --
>>> View this message in context:
>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-moni
>> tor-tp11323p11328.html
>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/36f44300/attachment.html>

From davidcholmes at aapt.net.au  Thu Oct  9 07:15:52 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 9 Oct 2014 21:15:52 +1000
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <54366ADE.7080707@java4.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELKKJAA.davidcholmes@aapt.net.au>

HI Florian,

Biased-locking and lock coarsening are orthogonal issues. The JIT will
impose lock coarsening when compiling the code. Biased-locking is applied
when actually acquiring a lock.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Florian
Binder
  Sent: Thursday, 9 October 2014 9:01 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] JSR-133 Cookbook and exit monitor


  I would like to throw another question into this interesting discussion:

  How is the relationship between lock coarsening and biased locking?

  Both depends on contention. So if the lock is not contended biased locking
can be used and coarsening is not necessary anymore. But is coarsening
really useful in the case where it is contended so biased locking can not be
used?

  Or is it maybe dependent on the degree of contention like this:

  no contention: biased locking
  low contention: coarsening
  high contention: nothing

  Flo


  Am 09.10.2014 um 06:43 schrieb Nathan Reynolds:

    Generally, I am against lock coarsening.  When facing a problematic
lock, the first thing I do is move everything out of the lock that can
possibly be done.

    In HotSpot version 7349, JIT will generate code with aggressive lock
coarsening.  If the lock becomes contended, then it will iteratively reduce
or remove the coarsening and see if that improves lock throughput.  It will
even go further and automatically pull out all of the code which doesn't
need to be inside the lock.  ;)

    Example #1

    Consider this code which models an actual problem seen.  key.hashCode()
takes a lot of CPU time but fortunately the result is cached inside the key
object.  The problem is that key.hashCode() was being computed inside the
lock for most key objects.

    synchronized (map)
    {
       map.put(key, value);
    }

    The solution was to simply call key.hashCode() just before the lock.
Fortunately, HotSpot doesn't pull this back inside the lock.

    key.hashCode();

    synchronized (map)
    {
       map.put(key, value);
    }

    However, there are some cases where lock coarsening makes sense.

    Example #2

    Consider this code which models an actual problem seen.  In the actual
problem, we weren't dealing with a Map however this code suffices to make
the point.  Each iteration is going to acquire and release the lock.  The
code executed outside of the lock (i.e. the for statement) is very light.
It makes sense to coarsen the lock to surround the entire for loop so that
the lock is acquired and released one time.

    private Map<String, String> map = Collections.synchronizedMap(new
HashMap<>());

    ...
       for (i = 0; i < array.length; i++)
          map.put(array[i], ""));

    Example #3

    Consider this code.  If functionA() is inlined into functionB(), then
there will be 2 synchronized blocks on the same lock back to back to each
other.  The programmer isn't being dumb.  This is where software design
creates a situation where lock coarsening is good.

    void functionA()
    {
       // some code

        synchronized (lock)
        {
            // some more code
        }
    }

    void functionB()
    {
        functionA();

        synchronized (lock)
        {
            // some more code
        }

       // some code
    }

-NathanOn 10/8/2014 8:16 PM, David Holmes wrote:

Thurston writes:
David Holmes-6 wrote
Not only is it allowed, it can easily be performed by the JIT. If that
seems
"unhealthy" you will be really freaked out by lock-coarsening which can
coalesce:

synchronized(x) {
 // aaa
}
// other code
synchronized(x) {
 // bbb
}

into

synchronized(x) {
  // aaa
  // other code
  // bbb
}

where anything in the sync block can of course be further reordered.

Of course this can't be done arbitrarily but it can be done.

Cheers,
David Holmes

Thanks.
To be precise, there is a hb(aaa, bbb), surely that needs to be
respected in the rewritten *coalesced* code; as far as "other code",
anything goes I guess
I don't believe hb has any impact here - as long as intra thread semantics
are obeyed.

Lock coarsening has been employed in hotspot for years now:

http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2

Personally I opposed it on liveness grounds - I presume that if you wrote
two close but seperate sync blocks then you had a good reason to do so, most
likely relating to liveness.

David
-----





--
View this message in context:
http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-moni
tor-tp11323p11328.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/26ef10ec/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Oct  9 08:45:10 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 09 Oct 2014 13:45:10 +0100
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <1412763544022-11323.post@n7.nabble.com>
References: <1412763544022-11323.post@n7.nabble.com>
Message-ID: <54368356.7000404@oracle.com>

This is certainly part of the language spec.

unlock/lock for the same object synchronize-with each other. This 
enables us to only establish happens-before between writes before the 
unlock in program order and reads after a lock in program order. This 
does not establish any ordering with any actions following unlock, or 
preceding lock.

Alex

On 08/10/2014 11:19, thurstonn wrote:
> Hello,
>
> If I read the  jsr-133 cookbook
> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
> following:
>
>
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> . . .
> exit monitor x
> y = 43
>
> </code>
>
> then at least according to the JMM, the following execution is possible:
> <code>
> //y is a global, non-volatile
> enter monitor x
> ...
> //do some work not involving y
> y = 43
> exit monitor x
> </code>
>
> as in the first table in the cookbook, *normal stores* are allowed to be
> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>
> Although the issue isn't really one involving memory consistency, is that
> really allowed?  Because *increasing* the size of a critical section seems .
> . . I don't know . . . unhealthy.
> What if the program code computed the first 1000 prime numbers or something
> and wrote them to a global array (after the monitor exit)?
>
> I was always under the impression that only the operations specified within
> a critical section would actually be executed between the enter/exit monitor
> pair
>
> NB: Although, presumably the runtime/CPU would only do this if the critical
> section was leading to CPU stalls or the like and so in reality, not really
> producing a longer critical section execution time
>
>
>
>
> --
> View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Thu Oct  9 09:04:37 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 09 Oct 2014 14:04:37 +0100
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CAHjP37HEndZhzgxzTue0y15eWT2Lx8EMevu=DF37yuiWKa1_NA@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<CANPzfU80qeqo5M3m3T2XSWoBnwLjSpR91KCxhH0BgL22M71J5Q@mail.gmail.com>	<54352989.6060308@univ-mlv.fr>	<CANPzfU_iwDBS-q=yh67ktzJ0wUDD=MTnaXP3n=6_XMCmo2WaCg@mail.gmail.com>	<54352FD4.7060003@univ-mlv.fr>	<CANPzfU_5NA=O+FBDZbVRMvdBei=6Nrwz1RFKQTnX3VkdB-SXYg@mail.gmail.com>	<CAHjP37F8DagwxbZ-h9E2TTZfds-LgXUshoct2D1WQTHvzh5ZpQ@mail.gmail.com>	<CANPzfU-Luv3xh8b_zdNkUkFq2o0-OOfkX3Cr7otNLCJiZh0EuA@mail.gmail.com>	<CAHjP37HcvT0YdQjea0r6Xn0N9XBxPPvOwQtyriXrQtfUYCHJQg@mail.gmail.com>	<CAPUmR1YBrLip-sF=0r3EeMYRmMwyhaYg-W0tXn1Wv8QpXVWu+w@mail.gmail.com>
	<CAHjP37HEndZhzgxzTue0y15eWT2Lx8EMevu=DF37yuiWKa1_NA@mail.gmail.com>
Message-ID: <543687E5.5020809@oracle.com>

It seems sensible to coarsen the lock by consuming any sequence of 
instructions that will cost less than lock release + acquire.

It makes sense to coarsen the lock by extending the section until a lock 
release for another lock, if the sequence of instructions is short enough.

Alex

On 08/10/2014 19:23, Vitaly Davidovich wrote:
> That's fine -- if hardware wants to reorder, no issues (and it 
> typically does that for efficiency anyway).  My curiosity is about 
> compiler-only transformation, as I'm interested in seeing what that 
> code would look like.
>
> On Wed, Oct 8, 2014 at 2:12 PM, Hans Boehm <boehm at acm.org 
> <mailto:boehm at acm.org>> wrote:
>
>     The original transformation, moving a trailing "y = 43" into a
>     critical section, can typically happen on a weakly ordered
>     architecture like ARM as a result of hardware reordering.   On
>     such an architecture, an ordinary lock release is essentially a
>     fence followed by an unordered CAS (or on ARMv8, a CAS with
>     release semantics).  There is nothing to prevent a later store to
>     y from becoming visible before the CAS releasing the lock.  No
>     compiler transformations required ...
>
>     Hans
>
>     On Wed, Oct 8, 2014 at 7:34 AM, Vitaly Davidovich
>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>
>         Yes, as Doug pointed out, the "roach motel" semantics is just
>         an allowed reordering -- compiler will hopefully not stuff
>         more things into a critical section unless it has strong
>         evidence that it's worthwhile.  I'd actually be curious to
>         hear from anyone that's seen such a transformation.
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/bf4728af/attachment.html>

From vitalyd at gmail.com  Thu Oct  9 09:16:47 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 9 Oct 2014 09:16:47 -0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
References: <1412768699357-11328.post@n7.nabble.com>
	<NFBBKALFDCPFIDBNKAPCAELGKJAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37H2T-9VG-w=Ce-3B4d4rLmBQuXwoJ3NiGa+jTN_4M0ghg@mail.gmail.com>

"Personally I opposed it on liveness grounds - I presume that if you wrote
two close but seperate sync blocks then you had a good reason to do so, most
likely relating to liveness."

That's true but sometimes (probably most) the coarsening opportunities fall
out of other optimizations, which may result in two sync blocks being back
to back and the programmer didn't write that.  We just have to trust that
compiler's cost model/heuristics enable it to make an appropriate decision.

Sent from my phone
On Oct 8, 2014 11:39 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> Thurston writes:
> > David Holmes-6 wrote
> > > Not only is it allowed, it can easily be performed by the JIT. If that
> > > seems
> > > "unhealthy" you will be really freaked out by lock-coarsening which can
> > > coalesce:
> > >
> > > synchronized(x) {
> > >  // aaa
> > > }
> > > // other code
> > > synchronized(x) {
> > >  // bbb
> > > }
> > >
> > > into
> > >
> > > synchronized(x) {
> > >   // aaa
> > >   // other code
> > >   // bbb
> > > }
> > >
> > > where anything in the sync block can of course be further reordered.
> > >
> > > Of course this can't be done arbitrarily but it can be done.
> > >
> > > Cheers,
> > > David Holmes
> > >
> > >>
> >
> > Thanks.
> > To be precise, there is a hb(aaa, bbb), surely that needs to be
> > respected in the rewritten *coalesced* code; as far as "other code",
> > anything goes I guess
>
> I don't believe hb has any impact here - as long as intra thread semantics
> are obeyed.
>
> Lock coarsening has been employed in hotspot for years now:
>
> http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2
>
> Personally I opposed it on liveness grounds - I presume that if you wrote
> two close but seperate sync blocks then you had a good reason to do so,
> most
> likely relating to liveness.
>
> David
> -----
>
>
>
>
> >
> >
> >
> > --
> > View this message in context:
>
> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-moni
> tor-tp11323p11328.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/fe6af39c/attachment.html>

From viktor.klang at gmail.com  Thu Oct  9 09:25:12 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 9 Oct 2014 15:25:12 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <54368356.7000404@oracle.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<54368356.7000404@oracle.com>
Message-ID: <CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>

But given the following logic:

method A = {
synchronized(foo) {
  ?
}

synchronized(bar) {
  ?
}

synchronized(foo) {
  ?
}
}

method B = {
  synchronized(bar) {
    ?
    synchronized(foo) {
      ?
    }
  }
}

If method A's synchronized(foo)s are coarsened to -contain- the
synchronized(bar), we now had a deadlock situation between A and B, where
there was none before. Does the lock coarsening take things like this into
account? (I hope?)

On Thu, Oct 9, 2014 at 2:45 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

> This is certainly part of the language spec.
>
> unlock/lock for the same object synchronize-with each other. This enables
> us to only establish happens-before between writes before the unlock in
> program order and reads after a lock in program order. This does not
> establish any ordering with any actions following unlock, or preceding lock.
>
> Alex
>
>
> On 08/10/2014 11:19, thurstonn wrote:
>
>> Hello,
>>
>> If I read the  jsr-133 cookbook
>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>> following:
>>
>>
>> <code>
>> //y is a global, non-volatile
>> enter monitor x
>> ...
>> //do some work not involving y
>> . . .
>> exit monitor x
>> y = 43
>>
>> </code>
>>
>> then at least according to the JMM, the following execution is possible:
>> <code>
>> //y is a global, non-volatile
>> enter monitor x
>> ...
>> //do some work not involving y
>> y = 43
>> exit monitor x
>> </code>
>>
>> as in the first table in the cookbook, *normal stores* are allowed to be
>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>
>> Although the issue isn't really one involving memory consistency, is that
>> really allowed?  Because *increasing* the size of a critical section
>> seems .
>> . . I don't know . . . unhealthy.
>> What if the program code computed the first 1000 prime numbers or
>> something
>> and wrote them to a global array (after the monitor exit)?
>>
>> I was always under the impression that only the operations specified
>> within
>> a critical section would actually be executed between the enter/exit
>> monitor
>> pair
>>
>> NB: Although, presumably the runtime/CPU would only do this if the
>> critical
>> section was leading to CPU stalls or the like and so in reality, not
>> really
>> producing a longer critical section execution time
>>
>>
>>
>>
>> --
>> View this message in context: http://jsr166-concurrency.
>> 10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/e6bb7e20/attachment-0001.html>

From oleksandr.otenko at oracle.com  Thu Oct  9 09:53:50 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 09 Oct 2014 14:53:50 +0100
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<54368356.7000404@oracle.com>
	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
Message-ID: <5436936E.8030200@oracle.com>

Sure. lock/unlock are synchronization actions, so they form a total order.

Alex

On 09/10/2014 14:25, ?iktor ?lang wrote:
> But given the following logic:
>
> method A = {
> synchronized(foo) {
>   ?
> }
>
> synchronized(bar) {
>   ?
> }
>
> synchronized(foo) {
>   ?
> }
> }
>
> method B = {
>   synchronized(bar) {
>     ?
>     synchronized(foo) {
>       ?
>     }
>   }
> }
>
> If method A's synchronized(foo)s are coarsened to -contain- the 
> synchronized(bar), we now had a deadlock situation between A and B, 
> where there was none before. Does the lock coarsening take things like 
> this into account? (I hope?)
>
> On Thu, Oct 9, 2014 at 2:45 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     This is certainly part of the language spec.
>
>     unlock/lock for the same object synchronize-with each other. This
>     enables us to only establish happens-before between writes before
>     the unlock in program order and reads after a lock in program
>     order. This does not establish any ordering with any actions
>     following unlock, or preceding lock.
>
>     Alex
>
>
>     On 08/10/2014 11:19, thurstonn wrote:
>
>         Hello,
>
>         If I read the  jsr-133 cookbook
>         <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>  correctly,
>         given the
>         following:
>
>
>         <code>
>         //y is a global, non-volatile
>         enter monitor x
>         ...
>         //do some work not involving y
>         . . .
>         exit monitor x
>         y = 43
>
>         </code>
>
>         then at least according to the JMM, the following execution is
>         possible:
>         <code>
>         //y is a global, non-volatile
>         enter monitor x
>         ...
>         //do some work not involving y
>         y = 43
>         exit monitor x
>         </code>
>
>         as in the first table in the cookbook, *normal stores* are
>         allowed to be
>         re-ordered before a *monitor exit* (but not before a *monitor
>         enter*).
>
>         Although the issue isn't really one involving memory
>         consistency, is that
>         really allowed?  Because *increasing* the size of a critical
>         section seems .
>         . . I don't know . . . unhealthy.
>         What if the program code computed the first 1000 prime numbers
>         or something
>         and wrote them to a global array (after the monitor exit)?
>
>         I was always under the impression that only the operations
>         specified within
>         a critical section would actually be executed between the
>         enter/exit monitor
>         pair
>
>         NB: Although, presumably the runtime/CPU would only do this if
>         the critical
>         section was leading to CPU stalls or the like and so in
>         reality, not really
>         producing a longer critical section execution time
>
>
>
>
>         --
>         View this message in context:
>         http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>         Sent from the JSR166 Concurrency mailing list archive at
>         Nabble.com.
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/90388988/attachment.html>

From viktor.klang at gmail.com  Thu Oct  9 09:56:54 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 9 Oct 2014 15:56:54 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <5436936E.8030200@oracle.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<54368356.7000404@oracle.com>
	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
	<5436936E.8030200@oracle.com>
Message-ID: <CANPzfU-q16vpMFP1y36Enx598aia5jMRViT9Hfm3ofKHhekYpg@mail.gmail.com>

On Thu, Oct 9, 2014 at 3:53 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  Sure. lock/unlock are synchronization actions, so they form a total order.
>

Yes, so let's say that synchronized(bar) in the code is really a reference
to the class Bar, and the static initializer of Bar does synchronized(foo)?


>
> Alex
>
>
> On 09/10/2014 14:25, ?iktor ?lang wrote:
>
>    But given the following logic:
>
>  method A = {
>  synchronized(foo) {
>   ?
> }
>
>  synchronized(bar) {
>   ?
> }
>
>  synchronized(foo) {
>   ?
> }
> }
>
>  method B = {
>    synchronized(bar) {
>     ?
>     synchronized(foo) {
>       ?
>     }
>   }
>  }
>
>  If method A's synchronized(foo)s are coarsened to -contain- the
> synchronized(bar), we now had a deadlock situation between A and B, where
> there was none before. Does the lock coarsening take things like this into
> account? (I hope?)
>
> On Thu, Oct 9, 2014 at 2:45 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>> This is certainly part of the language spec.
>>
>> unlock/lock for the same object synchronize-with each other. This enables
>> us to only establish happens-before between writes before the unlock in
>> program order and reads after a lock in program order. This does not
>> establish any ordering with any actions following unlock, or preceding lock.
>>
>> Alex
>>
>>
>> On 08/10/2014 11:19, thurstonn wrote:
>>
>>> Hello,
>>>
>>> If I read the  jsr-133 cookbook
>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>>> following:
>>>
>>>
>>> <code>
>>> //y is a global, non-volatile
>>> enter monitor x
>>> ...
>>> //do some work not involving y
>>> . . .
>>> exit monitor x
>>> y = 43
>>>
>>> </code>
>>>
>>> then at least according to the JMM, the following execution is possible:
>>> <code>
>>> //y is a global, non-volatile
>>> enter monitor x
>>> ...
>>> //do some work not involving y
>>> y = 43
>>> exit monitor x
>>> </code>
>>>
>>> as in the first table in the cookbook, *normal stores* are allowed to be
>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>
>>> Although the issue isn't really one involving memory consistency, is that
>>> really allowed?  Because *increasing* the size of a critical section
>>> seems .
>>> . . I don't know . . . unhealthy.
>>> What if the program code computed the first 1000 prime numbers or
>>> something
>>> and wrote them to a global array (after the monitor exit)?
>>>
>>> I was always under the impression that only the operations specified
>>> within
>>> a critical section would actually be executed between the enter/exit
>>> monitor
>>> pair
>>>
>>> NB: Although, presumably the runtime/CPU would only do this if the
>>> critical
>>> section was leading to CPU stalls or the like and so in reality, not
>>> really
>>> producing a longer critical section execution time
>>>
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
>  Cheers,
> ?
>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/e5ded95c/attachment.html>

From aleksey.shipilev at oracle.com  Thu Oct  9 10:11:50 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 09 Oct 2014 18:11:50 +0400
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<54368356.7000404@oracle.com>
	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
Message-ID: <543697A6.1010406@oracle.com>

On 10/09/2014 05:25 PM, ?iktor ?lang wrote:
> But given the following logic:
> 
> method A = {
> synchronized(foo) {
>   ?
> }
> 
> synchronized(bar) {
>   ?
> }
> 
> synchronized(foo) {
>   ?
> }
> }
> 
> method B = {
>   synchronized(bar) {
>     ?
>     synchronized(foo) {
>       ?
>     }
>   }
> }
> 
> If method A's synchronized(foo)s are coarsened to -contain- the
> synchronized(bar), we now had a deadlock situation between A and B,
> where there was none before. Does the lock coarsening take things like
> this into account? (I hope?)

Lock/unlock actions are synchronization actions, and are in total order
which is consistent with program order. The transformation you are
proposing is violating "unlock(foo) --so/po--> lock(bar) --so/po-->
unlock(bar) --so/po--> lock(foo)" constraint, and it is therefore
prohibited under JMM rules.

In other words, you can coarsen the locks, but not when you mess with
other synchronization actions.

-Aleksey.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/62680c69/attachment-0001.bin>

From viktor.klang at gmail.com  Thu Oct  9 10:16:12 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 9 Oct 2014 16:16:12 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <543697A6.1010406@oracle.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<54368356.7000404@oracle.com>
	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
	<543697A6.1010406@oracle.com>
Message-ID: <CANPzfU8nDJpLPeTp0r8ZGZJSJEG5jJMKY2a41SHa7uyUhvcUVQ@mail.gmail.com>

On Thu, Oct 9, 2014 at 4:11 PM, Aleksey Shipilev <
aleksey.shipilev at oracle.com> wrote:

> On 10/09/2014 05:25 PM, ?iktor ?lang wrote:
> > But given the following logic:
> >
> > method A = {
> > synchronized(foo) {
> >   ?
> > }
> >
> > synchronized(bar) {
> >   ?
> > }
> >
> > synchronized(foo) {
> >   ?
> > }
> > }
> >
> > method B = {
> >   synchronized(bar) {
> >     ?
> >     synchronized(foo) {
> >       ?
> >     }
> >   }
> > }
> >
> > If method A's synchronized(foo)s are coarsened to -contain- the
> > synchronized(bar), we now had a deadlock situation between A and B,
> > where there was none before. Does the lock coarsening take things like
> > this into account? (I hope?)
>
> Lock/unlock actions are synchronization actions, and are in total order
> which is consistent with program order. The transformation you are
> proposing is violating "unlock(foo) --so/po--> lock(bar) --so/po-->
> unlock(bar) --so/po--> lock(foo)" constraint, and it is therefore
> prohibited under JMM rules.
>
> In other words, you can coarsen the locks, but not when you mess with
> other synchronization actions.
>

Yes, agreed, my point was that class loading is a synchronization action,
so that means that coarsening would only ever be able to subsume/merge
adjacent locking on the same monitor if the instructions in between are not
referring to possibly unloaded classes. (amongst other things).


>
> -Aleksey.
>
>
>


-- 
Cheers,
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/fe4920e0/attachment.html>

From oleksandr.otenko at oracle.com  Thu Oct  9 10:48:39 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 09 Oct 2014 15:48:39 +0100
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU-q16vpMFP1y36Enx598aia5jMRViT9Hfm3ofKHhekYpg@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<54368356.7000404@oracle.com>	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>	<5436936E.8030200@oracle.com>
	<CANPzfU-q16vpMFP1y36Enx598aia5jMRViT9Hfm3ofKHhekYpg@mail.gmail.com>
Message-ID: <5436A047.2060602@oracle.com>

So they will appear in program order.

Lock fusing / coarsening can only occur if no one can observe the 
absence of lock/unlock. That is, if there is nothing that someone can 
synchronize-with between unlock and lock.

Alex

On 09/10/2014 14:56, ?iktor ?lang wrote:
>
>
> On Thu, Oct 9, 2014 at 3:53 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Sure. lock/unlock are synchronization actions, so they form a
>     total order.
>
>
> Yes, so let's say that synchronized(bar) in the code is really a 
> reference to the class Bar, and the static initializer of Bar does 
> synchronized(foo)?
>
>
>     Alex
>
>
>     On 09/10/2014 14:25, ?iktor ?lang wrote:
>>     But given the following logic:
>>
>>     method A = {
>>     synchronized(foo) {
>>       ?
>>     }
>>
>>     synchronized(bar) {
>>       ?
>>     }
>>
>>     synchronized(foo) {
>>       ?
>>     }
>>     }
>>
>>     method B = {
>>       synchronized(bar) {
>>         ?
>>         synchronized(foo) {
>>           ?
>>         }
>>       }
>>     }
>>
>>     If method A's synchronized(foo)s are coarsened to -contain- the
>>     synchronized(bar), we now had a deadlock situation between A and
>>     B, where there was none before. Does the lock coarsening take
>>     things like this into account? (I hope?)
>>
>>     On Thu, Oct 9, 2014 at 2:45 PM, Oleksandr Otenko
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         This is certainly part of the language spec.
>>
>>         unlock/lock for the same object synchronize-with each other.
>>         This enables us to only establish happens-before between
>>         writes before the unlock in program order and reads after a
>>         lock in program order. This does not establish any ordering
>>         with any actions following unlock, or preceding lock.
>>
>>         Alex
>>
>>
>>         On 08/10/2014 11:19, thurstonn wrote:
>>
>>             Hello,
>>
>>             If I read the  jsr-133 cookbook
>>             <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>
>>              correctly, given the
>>             following:
>>
>>
>>             <code>
>>             //y is a global, non-volatile
>>             enter monitor x
>>             ...
>>             //do some work not involving y
>>             . . .
>>             exit monitor x
>>             y = 43
>>
>>             </code>
>>
>>             then at least according to the JMM, the following
>>             execution is possible:
>>             <code>
>>             //y is a global, non-volatile
>>             enter monitor x
>>             ...
>>             //do some work not involving y
>>             y = 43
>>             exit monitor x
>>             </code>
>>
>>             as in the first table in the cookbook, *normal stores*
>>             are allowed to be
>>             re-ordered before a *monitor exit* (but not before a
>>             *monitor enter*).
>>
>>             Although the issue isn't really one involving memory
>>             consistency, is that
>>             really allowed?  Because *increasing* the size of a
>>             critical section seems .
>>             . . I don't know . . . unhealthy.
>>             What if the program code computed the first 1000 prime
>>             numbers or something
>>             and wrote them to a global array (after the monitor exit)?
>>
>>             I was always under the impression that only the
>>             operations specified within
>>             a critical section would actually be executed between the
>>             enter/exit monitor
>>             pair
>>
>>             NB: Although, presumably the runtime/CPU would only do
>>             this if the critical
>>             section was leading to CPU stalls or the like and so in
>>             reality, not really
>>             producing a longer critical section execution time
>>
>>
>>
>>
>>             --
>>             View this message in context:
>>             http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>             Sent from the JSR166 Concurrency mailing list archive at
>>             Nabble.com.
>>             _______________________________________________
>>             Concurrency-interest mailing list
>>             Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     -- 
>>     Cheers,
>>     ?
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/353834c3/attachment.html>

From oleksandr.otenko at oracle.com  Thu Oct  9 10:57:40 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 09 Oct 2014 15:57:40 +0100
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <CANPzfU8nDJpLPeTp0r8ZGZJSJEG5jJMKY2a41SHa7uyUhvcUVQ@mail.gmail.com>
References: <1412763544022-11323.post@n7.nabble.com>	<54368356.7000404@oracle.com>	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>	<543697A6.1010406@oracle.com>
	<CANPzfU8nDJpLPeTp0r8ZGZJSJEG5jJMKY2a41SHa7uyUhvcUVQ@mail.gmail.com>
Message-ID: <5436A264.4050000@oracle.com>

I am not sure what scenario you have in mind, but it is always safe to 
subsume any "last level" lock - ie a lock/unlock pair between which 
there is no lock acquired.

If you mean that a class initializer has a lock acquisition inside, then 
deadlocks can happen with or without lock coarsening. This is a fact of 
life, and the cause is lazy class loading/initialization/lack of control 
over class lifecycle.

Alex

On 09/10/2014 15:16, ?iktor ?lang wrote:
>
>
> On Thu, Oct 9, 2014 at 4:11 PM, Aleksey Shipilev 
> <aleksey.shipilev at oracle.com <mailto:aleksey.shipilev at oracle.com>> wrote:
>
>     On 10/09/2014 05:25 PM, ?iktor ?lang wrote:
>     > But given the following logic:
>     >
>     > method A = {
>     > synchronized(foo) {
>     >   ?
>     > }
>     >
>     > synchronized(bar) {
>     >   ?
>     > }
>     >
>     > synchronized(foo) {
>     >   ?
>     > }
>     > }
>     >
>     > method B = {
>     >   synchronized(bar) {
>     >     ?
>     >     synchronized(foo) {
>     >       ?
>     >     }
>     >   }
>     > }
>     >
>     > If method A's synchronized(foo)s are coarsened to -contain- the
>     > synchronized(bar), we now had a deadlock situation between A and B,
>     > where there was none before. Does the lock coarsening take
>     things like
>     > this into account? (I hope?)
>
>     Lock/unlock actions are synchronization actions, and are in total
>     order
>     which is consistent with program order. The transformation you are
>     proposing is violating "unlock(foo) --so/po--> lock(bar) --so/po-->
>     unlock(bar) --so/po--> lock(foo)" constraint, and it is therefore
>     prohibited under JMM rules.
>
>     In other words, you can coarsen the locks, but not when you mess with
>     other synchronization actions.
>
>
> Yes, agreed, my point was that class loading is a synchronization 
> action, so that means that coarsening would only ever be able to 
> subsume/merge adjacent locking on the same monitor if the instructions 
> in between are not referring to possibly unloaded classes. (amongst 
> other things).
>
>
>     -Aleksey.
>
>
>
>
>
> -- 
> Cheers,
> ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/79672bd1/attachment-0001.html>

From peter.levart at gmail.com  Thu Oct  9 11:21:35 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 09 Oct 2014 17:21:35 +0200
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5436623C.1030104@oracle.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com> <54355B31.5010009@oracle.com>
	<54365AEB.5070002@gmail.com> <5436623C.1030104@oracle.com>
Message-ID: <5436A7FF.8020404@gmail.com>

Hi Vladimir,

Thanks for explaining these things.

On 10/09/2014 12:23 PM, Vladimir Ivanov wrote:
> Peter,
>
>>> [1] http://cr.openjdk.java.net/~jrose/draft/lazy-final.html
>>
>> That's great. I can see that there are two points encapsulated in this
>> lazy finals proposal. One is the lazy assignment that can occur any time
>> after constructor, restricted perhaps only to code of the declaring
>> class, and the other is that such fields are *really* final, or in other
>> words @Stable, meaning they can not be assigned twice, not even with
>> reflection, which enables compiler optimizations. It's a little odd that
>> in order to achieve *really* final behaviour and consequently better
>> optimization, you would have to give up on  the definitive assignment
>> rules help from javac.
> I don't see how it improves the situation, except allowing lazy 
> initialization. It suffers from the very same problems as final 
> fields, if you want to perform multiple updates. 

But since they are new kind of fields, multiple updates can be 
prohibited on them from day one. Who would want such a feature anyway. 
Lazy setting yes, but not multiple updates. Normal fields are meant to 
be updated multiple times, finals are special-purpose fields.

> And the price for lazy initialization is default value, which can't be 
> optimized anymore.

That's a pity yes, but as I understand, lazy-initialized finals are 
expected to be assigned a non-default value before they are used in hot 
code which can then benefit from constant folding, right?

>
>> But what about this idea:
>>
>> Reflection supports updating ordinary final instance fields (via
>> privileged setAccessible(true)) in order to achieve just what the lazy
>> final fields are trying to achieve - lazy initialization outside
>> constructor. Mainly to support Java  and other kinds of
>> deserializations. I would say that any other uses of setAccessible(true)
>> which assigns final field more than once are rare or non-existent. So
>> why not making ordinary instance final fields *really* final by treating
>> them in reflection as lazy final fields with a little tweak - the
>> assignment of null/zero value to an "unassigned" field would not throw
>> exception, but just be a NOOP - leave the field in "unassinged" state.
>>
>> This way deserialization of ordinary final fields would still work, but
>> VM compiler could treat them all as @Stable, immediately optimizing huge
>> codebases on a different level.
>>
>> Am I not seeing something in that simplified picture?
> It's all about JIT compiler. Lazy finals/@Stable aren't a full match 
> for final field case, but they are close.
>
> The problem with treating final fields as lazy finals, is it can't be 
> limited only to accesses through Reflection API. The change should be 
> pervasive and default values should be treated specially everywhere, 
> forbidding constant-folding of loads from final fields w/ default 
> values. Do we really want that?

Well, it would not be worse than it is now when constant-folding can't 
be performed regardless of final field's value. null/zero value would 
become a second-class citizen then. Not very nice, but perhaps acceptable.

>
> Regarding constant folding of loads from final fields, Hotspot already 
> optimizes loads for static final fields and there's an experimental 
> flag TrustFinalNonStaticFields for final instance fields case.

So for static final fields, Hotspot already knows how to prove that some 
code can not observe uninitialized value before constant-folding it? 
Does it do any such thing for instance fields when this experimental 
flag is enabled or just trusts blindly that the code in question is only 
observing the "final" value when the time comes to optimize it? In other 
words, does this experimental flag guarantee correctness in all 
situations with the only exception being reflective final field updates?

>
> What HotSpot misses right now (to preserve correctness w.r.t. 
> Reflection API) is a way to track dependencies between final fields 
> and nmethods which embed their values. It would allow to invalidate 
> all nmethods which rely on stale value and ensure the updated value is 
> "visible" everywhere in the running application.

This would be a cool optimization for mostly read-only and rarely 
updated fields, but do we want to transform final instance fields into 
such thing just to support deserialization via reflection? If this is 
not a big deal to support than perhaps it is a better approach since it 
does not neglect null/zero values.

Regards, Peter

>
> Best regards,
> Vladimir Ivanov
>>
>> Regards, Peter
>>
>>>
>>>>
>>>> Now let me try to get something similar from
>>>> AtomicReferenceFieldUpdater...
>>>>
>>>> Regards, Peter
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>


From aaron.grunthal at infinite-source.de  Thu Oct  9 12:29:17 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Thu, 09 Oct 2014 18:29:17 +0200
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5436A7FF.8020404@gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>	<5435539B.3010004@gmail.com>
	<54355B31.5010009@oracle.com>	<54365AEB.5070002@gmail.com>
	<5436623C.1030104@oracle.com> <5436A7FF.8020404@gmail.com>
Message-ID: <5436B7DD.2050305@infinite-source.de>

On 09.10.2014 17:21, Peter Levart wrote:
>
> This would be a cool optimization for mostly read-only and rarely
> updated fields, but do we want to transform final instance fields into
> such thing just to support deserialization via reflection? If this is
> not a big deal to support than perhaps it is a better approach since it
> does not neglect null/zero values.

I think the issue here may be that final is used to signal two slightly 
distinct purposes.

1. It's to tell the compiler: "This data (almost) never changes, please 
optimize aggressively, I'm willing to take a significant performance hit 
if I ever have to change it via reflection"
This might also be relevant for other language implementers, e.g. for 
jruby class variables and constants which should remain constant but can 
be easily changed via metaprogramming or initialized multiple times by 
various modules.

2. It's to tell users of the class that it's immutable data, it's safe 
to pass around, that they're doing something wrong if they want to 
change the value, etc.
Think value-types.
Since immutable data objects are often ephemeral and not assigned to 
static fields the programmer doesn't really expect the compiler to 
perform constant folding.
It's also where the deserialization problem commonly occurs.

- Aaron

From paul.sandoz at oracle.com  Thu Oct  9 13:33:23 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 9 Oct 2014 10:33:23 -0700
Subject: [concurrency-interest] FieldReference vs. AtomicFieldUpdater -
	was Re: Optimizing Atomic*FieldReference <was> Re: Here's why
	Atomic*FieldReference access checking is broken
In-Reply-To: <5435804C.2050400@gmail.com>
References: <542EBD0C.7080301@redhat.com>
	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>
	<5435062C.6020200@gmail.com>	<54351DD4.6050500@cs.oswego.edu>
	<54354729.805@gmail.com>
	<40A19A42-4DA5-4546-A87E-480D6ECF1FA2@oracle.com>
	<5435804C.2050400@gmail.com>
Message-ID: <B10625BD-9384-4CF7-9200-F66DB315BF9A@oracle.com>


On Oct 8, 2014, at 11:19 AM, Peter Levart <peter.levart at gmail.com> wrote:

> Hi Paul,
> 
> Since this thread is way from original topic, I changed it. It is very interesting though.
> 
> On 10/08/2014 06:00 PM, Paul Sandoz wrote:
>> On Oct 8, 2014, at 7:16 AM, Peter Levart <peter.levart at gmail.com> wrote:
>> 
>>> On 10/08/2014 01:19 PM, Doug Lea wrote:
>>>> On 10/08/2014 05:38 AM, Peter Levart wrote:
>>>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java 
>>>>> 
>>>> Paul Sandoz has been working on VarHandles (like MethodHandles)
>>>> for similar purposes. Possibly even the same purposes.
>>>> See his JavaOne talk slides at
>>>> http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
>>>> It seems worth waiting for more progress on this front before
>>>> contemplating changes along these lines.
>>>> 
>>>> -Doug
>>>> 
>>> Thanks Doug for pointing me to Paul's slides. I can see that Paul's VarHandles are based around the idea of methods with polymorphic signature akin to MethodHandles.invoke* with the benefit that they don't declare Throwable as thrown exception and he's adding some type inference changes on top of that.
>>> 
>>> Paul is exploring alternative approaches to JEP 193 which don't require language changes although he has already stepped beyond that line as I can see that his patch contains a few lines of javac changes.
>>> 
>> Yes, it requires some small changes to how polymorphic signature methods are expressed but requires no new language syntax. The downside is the specs require updating to say "here is another class with polymorphic signature methods" so it is not very general.
> 
> And I think you also showed on your slides, that polymorphic signature methods don't provide static type checking. Are there any plans to merge polymorphic signature methods with generic types? Currently both polymorphic signature methods that I know of (MethodHandle.invoke[Exact]) allow passing any type and number of arguments and return Object. Would it be possible to have "constrained" polymorphic signature methods that are static type-checked as normal methods, but otherwise "behave" like polymorphic signature methods?
> 

It's possible:

  http://hg.openjdk.java.net/valhalla/valhalla/jdk/file/bc9fae81d774/src/java.base/share/classes/java/lang/invoke/FieldHandle.java

  http://hg.openjdk.java.net/valhalla/valhalla/jdk/file/bc9fae81d774/src/java.base/share/classes/java/lang/invoke/ArrayHandle.java

(These support a hack that avoids boxing, i referred to in my last email, so explicit int/long versions are not required.)

There is a tension here between what we do for Java 9 and what we can do later on when specialization arrives.

You can find more stuff here:

  http://cr.openjdk.java.net/~psandoz/varhandles/


>> 
>> 
>>> I'm trying to see if there is an alternative to Paul's approach which doesn't require JVM changes either. I think it all boils down to how types involved are encoded and how type-checks can be optimized at runtime. As my preliminary hacking shows, there might be a solution in the existing virtual machinery.
>>> 
>> The key optimization is "final fields are really final" [*], the privilege of which is bestowed on all classes in java.lang.invoke. That enables cast checks to be optimized away under the right conditions. I experimented with Atomic* like classes in that package (plus it is possible to extend the privilege to all classes which of course can be dangerous).
> 
> So if that works, why is FieldReference API designed around polymorphic signature methods then? What do they buy you? Specialization for primitive types? Reification of static types used at call-site?
> 

Essentially one abstract class that covers many access-kinds (static field, instance field, array element, off-heap array, ...) and value-kinds (ref, int, long, ...). The method invocation mechanism is fundamentally the same as that for indy so if we can switch to indy i would expect similar performance characteristics.

Additionally it follows the same approach to lookup as MethodHandles, which I think that is an important pattern access control pattern.


> 
>> 
>> The current VarHandle prototype provides access over fields and array elements (and arrays of primitives off-heap) using just one abstract class. The API is a little raw but when specialization arrives it should be possible to surface a better API without creating specific classes for int/long/ref etc (i managed to hack in an approach in the current prototype to reify type variables while also avoiding boxing, but unfortunately i don't think we can use that technique).
> 
> It may be necessary to have specific classes for int/long/ref because there are operations that you do with int/long that have no meaning with references like addAndGet, etc... but I can see that the number of classes can be reduced this way.
> 

Yes, there could be a concept of a numeric handle exposing addAndGet and such (currently the prototype throws USOE for value-kinds that do not support such operations). This could be surfaced differently using specialization.

>> 
>> There may be ways to surface the same functionality using indy. The trick would be to do this in such a way that javac could use indy or not and there would be no change in semantics, but the JIT could better optimize the former.
>> 
>> Regardless of what way we surface the API there are a few tweaks to the hotspot compiler we can do related to casts and bounds checks (which are mostly important for CAS).
>> 
>> Paul.
>> 
>> [*] This generally seems a very good thing to do if we can work out how to safely support reflection-based seriaization and DI frameworks.
> 
> One way perhaps could be to simply not support it. Static final fields are really final (with exception of System.out/in/err). If instance field is marked as "transient final", reflection could refuse updating it. There are serialization frameworks that (de)serialize even "transient final" fields, so they would fail. But if they are worth anything, they surely must have a mode that works in SecurityManager enabled environments, where updating final fields is not possible so they must be skipped. If backwards compatibility is a must, then a VM switch could turn this feature off. It is, after all, only an optimization.
> 

While it certainly is important for optimization i also consider it important for enforcing the integrity of a class and it's instances (the security manager is a poor mechanism to enforce such integrity). At the moment final does not really mean final (and private does not really mean private).
 

> Otherwise, there would have to be a new language way to mark those fields. What's wrong with @Stable annotation in addition to "transient final" modifiers? It doesn't change the semantics of a program after all. Java serialization would not touch it and reflection could be easily tweaked to refuse updating such fields even if Field.setAccessible(true) was used... It could be useful at least for global JDK-internal use, if it is not fancy enough for general use.
> 

@Stable annotated fields are subtly different, they are really lazy finals as Validmir mentions, something that can be set once from a default to a non-default value (either during the construction phase or anytime outside of that).

My preference at the moment would be to explore how to really make final fields final without any additional qualifications. This connects with how we might improve construction/deserialization and replace usages of Unsafe with safe alternatives using some sort of larval object concept [1].

Paul.

[1] https://blogs.oracle.com/jrose/entry/larval_objects_in_the_vm

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/34e902b5/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/34e902b5/attachment.bin>

From paul.sandoz at oracle.com  Thu Oct  9 13:53:31 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 9 Oct 2014 10:53:31 -0700
Subject: [concurrency-interest] lazy finals - was: Here's why
	Atomic*FieldReference access checking is broken
In-Reply-To: <5436623C.1030104@oracle.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com> <54355B31.5010009@oracle.com>
	<54365AEB.5070002@gmail.com> <5436623C.1030104@oracle.com>
Message-ID: <60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>

On Oct 9, 2014, at 3:23 AM, Vladimir Ivanov <vladimir.x.ivanov at oracle.com> wrote:
> What HotSpot misses right now (to preserve correctness w.r.t. Reflection API) is a way to track dependencies between final fields and nmethods which embed their values. It would allow to invalidate all nmethods which rely on stale value and ensure the updated value is "visible" everywhere in the running application.
> 

In such a case would it provide a form of eventual consistency or would there be checks in place before a final field is used? e.g. one thread could be stomping on a final field while another thread is executing an nmethod under the assumption the field is final (and what if the nmethod is executing a large or infinite loop?). 

Instead perhaps final fields should really be final and safe mechanisms are provided to support the DI and serialization use-cases, which i suspect cover almost all use-cases.

Paul.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/7e629118/attachment-0001.bin>

From viktor.klang at gmail.com  Thu Oct  9 14:45:13 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Thu, 9 Oct 2014 20:45:13 +0200
Subject: [concurrency-interest] JSR-133 Cookbook and exit monitor
In-Reply-To: <5436A047.2060602@oracle.com>
References: <1412763544022-11323.post@n7.nabble.com>
	<54368356.7000404@oracle.com>
	<CANPzfU8YyV64Q_qjgdocHMyoKXpsCoVHyCeEL7ffRzs1tSXugg@mail.gmail.com>
	<5436936E.8030200@oracle.com>
	<CANPzfU-q16vpMFP1y36Enx598aia5jMRViT9Hfm3ofKHhekYpg@mail.gmail.com>
	<5436A047.2060602@oracle.com>
Message-ID: <CANPzfU8Y7FmkAd=PVpN+Jtrm63iX96_j+W890A7gsKL_1gmMZQ@mail.gmail.com>

That covers my question! Thanks
On Oct 9, 2014 4:48 PM, "Oleksandr Otenko" <oleksandr.otenko at oracle.com>
wrote:

>  So they will appear in program order.
>
> Lock fusing / coarsening can only occur if no one can observe the absence
> of lock/unlock. That is, if there is nothing that someone can
> synchronize-with between unlock and lock.
>
> Alex
>
> On 09/10/2014 14:56, ?iktor ?lang wrote:
>
>
>
> On Thu, Oct 9, 2014 at 3:53 PM, Oleksandr Otenko <
> oleksandr.otenko at oracle.com> wrote:
>
>>  Sure. lock/unlock are synchronization actions, so they form a total
>> order.
>>
>
>  Yes, so let's say that synchronized(bar) in the code is really a
> reference to the class Bar, and the static initializer of Bar does
> synchronized(foo)?
>
>
>>
>> Alex
>>
>>
>> On 09/10/2014 14:25, ?iktor ?lang wrote:
>>
>>    But given the following logic:
>>
>>  method A = {
>>  synchronized(foo) {
>>   ?
>> }
>>
>>  synchronized(bar) {
>>   ?
>> }
>>
>>  synchronized(foo) {
>>   ?
>> }
>> }
>>
>>  method B = {
>>    synchronized(bar) {
>>     ?
>>     synchronized(foo) {
>>       ?
>>     }
>>   }
>>  }
>>
>>  If method A's synchronized(foo)s are coarsened to -contain- the
>> synchronized(bar), we now had a deadlock situation between A and B, where
>> there was none before. Does the lock coarsening take things like this into
>> account? (I hope?)
>>
>> On Thu, Oct 9, 2014 at 2:45 PM, Oleksandr Otenko <
>> oleksandr.otenko at oracle.com> wrote:
>>
>>> This is certainly part of the language spec.
>>>
>>> unlock/lock for the same object synchronize-with each other. This
>>> enables us to only establish happens-before between writes before the
>>> unlock in program order and reads after a lock in program order. This does
>>> not establish any ordering with any actions following unlock, or preceding
>>> lock.
>>>
>>> Alex
>>>
>>>
>>> On 08/10/2014 11:19, thurstonn wrote:
>>>
>>>> Hello,
>>>>
>>>> If I read the  jsr-133 cookbook
>>>> <http://gee.cs.oswego.edu/dl/jmm/cookbook.html>   correctly, given the
>>>> following:
>>>>
>>>>
>>>> <code>
>>>> //y is a global, non-volatile
>>>> enter monitor x
>>>> ...
>>>> //do some work not involving y
>>>> . . .
>>>> exit monitor x
>>>> y = 43
>>>>
>>>> </code>
>>>>
>>>> then at least according to the JMM, the following execution is possible:
>>>> <code>
>>>> //y is a global, non-volatile
>>>> enter monitor x
>>>> ...
>>>> //do some work not involving y
>>>> y = 43
>>>> exit monitor x
>>>> </code>
>>>>
>>>> as in the first table in the cookbook, *normal stores* are allowed to be
>>>> re-ordered before a *monitor exit* (but not before a *monitor enter*).
>>>>
>>>> Although the issue isn't really one involving memory consistency, is
>>>> that
>>>> really allowed?  Because *increasing* the size of a critical section
>>>> seems .
>>>> . . I don't know . . . unhealthy.
>>>> What if the program code computed the first 1000 prime numbers or
>>>> something
>>>> and wrote them to a global array (after the monitor exit)?
>>>>
>>>> I was always under the impression that only the operations specified
>>>> within
>>>> a critical section would actually be executed between the enter/exit
>>>> monitor
>>>> pair
>>>>
>>>> NB: Although, presumably the runtime/CPU would only do this if the
>>>> critical
>>>> section was leading to CPU stalls or the like and so in reality, not
>>>> really
>>>> producing a longer critical section execution time
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> View this message in context:
>>>> http://jsr166-concurrency.10961.n7.nabble.com/JSR-133-Cookbook-and-exit-monitor-tp11323.html
>>>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>>  Cheers,
>> ?
>>
>>
>>
>
>
> --
>  Cheers,
> ?
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/af155070/attachment.html>

From david.lloyd at redhat.com  Thu Oct  9 15:42:46 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 09 Oct 2014 14:42:46 -0500
Subject: [concurrency-interest] FieldReference vs. AtomicFieldUpdater -
 was Re: Optimizing Atomic*FieldReference <was> Re: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <B10625BD-9384-4CF7-9200-F66DB315BF9A@oracle.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<54351DD4.6050500@cs.oswego.edu>	<54354729.805@gmail.com>	<40A19A42-4DA5-4546-A87E-480D6ECF1FA2@oracle.com>	<5435804C.2050400@gmail.com>
	<B10625BD-9384-4CF7-9200-F66DB315BF9A@oracle.com>
Message-ID: <5436E536.3090802@redhat.com>

On 10/09/2014 12:33 PM, Paul Sandoz wrote:
> On Oct 8, 2014, at 11:19 AM, Peter Levart <peter.levart at gmail.com
> <mailto:peter.levart at gmail.com>> wrote:
>
>> Hi Paul,
>>
>> Since this thread is way from original topic, I changed it. It is very
>> interesting though.
>>
>> On 10/08/2014 06:00 PM, Paul Sandoz wrote:
>>> On Oct 8, 2014, at 7:16 AM, Peter Levart<peter.levart at gmail.com>  wrote:
>>>
>>>> On 10/08/2014 01:19 PM, Doug Lea wrote:
>>>>> On 10/08/2014 05:38 AM, Peter Levart wrote:
>>>>>> http://cr.openjdk.java.net/~plevart/jdk9-dev/AtomicFieldUpdater.AccessChecks/AnonClassPerCclass/AtomicIntegerFieldUpdater.java
>>>>>>
>>>>> Paul Sandoz has been working on VarHandles (like MethodHandles)
>>>>> for similar purposes. Possibly even the same purposes.
>>>>> See his JavaOne talk slides at
>>>>> http://cr.openjdk.java.net/~psandoz/j1-2014-unsafe-CON5150.pdf
>>>>> It seems worth waiting for more progress on this front before
>>>>> contemplating changes along these lines.
>>>>>
>>>>> -Doug
>>>>>
>>>> Thanks Doug for pointing me to Paul's slides. I can see that Paul's VarHandles are based around the idea of methods with polymorphic signature akin to MethodHandles.invoke* with the benefit that they don't declare Throwable as thrown exception and he's adding some type inference changes on top of that.
>>>>
>>>> Paul is exploring alternative approaches to JEP 193 which don't require language changes although he has already stepped beyond that line as I can see that his patch contains a few lines of javac changes.
>>>>
>>> Yes, it requires some small changes to how polymorphic signature methods are expressed but requires no new language syntax. The downside is the specs require updating to say "here is another class with polymorphic signature methods" so it is not very general.
>>
>> And I think you also showed on your slides, that polymorphic signature
>> methods don't provide static type checking. Are there any plans to
>> merge polymorphic signature methods with generic types? Currently both
>> polymorphic signature methods that I know of
>> (MethodHandle.invoke[Exact]) allow passing any type and number of
>> arguments and return Object. Would it be possible to have
>> "constrained" polymorphic signature methods that are static
>> type-checked as normal methods, but otherwise "behave" like
>> polymorphic signature methods?
>>
>
> It's possible:
>
> http://hg.openjdk.java.net/valhalla/valhalla/jdk/file/bc9fae81d774/src/java.base/share/classes/java/lang/invoke/FieldHandle.java
> http://hg.openjdk.java.net/valhalla/valhalla/jdk/file/bc9fae81d774/src/java.base/share/classes/java/lang/invoke/ArrayHandle.java
>
> (These support a hack that avoids boxing, i referred to in my last
> email, so explicit int/long versions are not required.)
>
> There is a tension here between what we do for Java 9 and what we can do
> later on when specialization arrives.
>
> You can find more stuff here:
>
> http://cr.openjdk.java.net/~psandoz/varhandles/

This is all quite interesting exploration.  But I admit I'm having a 
hard time understanding why this apparently more complex mechanism is 
better than *Updaters, especially if the latter has as much room for 
optimization as Peter's work suggests.  While a few extra capabilities 
have been added and changed, from the perspective of a user the only 
difference from *Handles to *Updaters seems to be that considerably more 
of the implementation details have bubbled up to the surface with 
*Handles, making them somewhat more difficult to understand, and making 
the apparent expected usage seem much more complex than *Updaters (or 
the [apparently DOA?] proposed .volatile idea, with its virtual objects, 
which I personally liked a lot better, as a user who is a human being 
and not some kind of complex embodiment of a deparser algorithm).

-- 
- DML

From peter.levart at gmail.com  Thu Oct  9 16:53:59 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 09 Oct 2014 22:53:59 +0200
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>	<5435539B.3010004@gmail.com>
	<54355B31.5010009@oracle.com>	<54365AEB.5070002@gmail.com>
	<5436623C.1030104@oracle.com>
	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>
Message-ID: <5436F5E7.7040509@gmail.com>


On 10/09/2014 07:53 PM, Paul Sandoz wrote:
> On Oct 9, 2014, at 3:23 AM, Vladimir Ivanov <vladimir.x.ivanov at oracle.com> wrote:
>> What HotSpot misses right now (to preserve correctness w.r.t. Reflection API) is a way to track dependencies between final fields and nmethods which embed their values. It would allow to invalidate all nmethods which rely on stale value and ensure the updated value is "visible" everywhere in the running application.
>>
> In such a case would it provide a form of eventual consistency or would there be checks in place before a final field is used? e.g. one thread could be stomping on a final field while another thread is executing an nmethod under the assumption the field is final (and what if the nmethod is executing a large or infinite loop?).

Or, if nmethod that depends on the value of the field which is 
constant-folded in it's code, modifies this same field in 1st part and 
after that executes 2nd part that uses constant-folded value? How does 
Hotspot deal in general with situations where the optimized code, while 
executing, invalidates it's assumptions? Does this ever happen currently?

Regards, Peter

> Instead perhaps final fields should really be final and safe mechanisms are provided to support the DI and serialization use-cases, which i suspect cover almost all use-cases.
>
> Paul.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/954a0fc8/attachment-0001.html>

From vitalyd at gmail.com  Thu Oct  9 17:30:35 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 9 Oct 2014 17:30:35 -0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5436F5E7.7040509@gmail.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
	<54352F34.1010100@univ-mlv.fr> <5435539B.3010004@gmail.com>
	<54355B31.5010009@oracle.com> <54365AEB.5070002@gmail.com>
	<5436623C.1030104@oracle.com>
	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>
	<5436F5E7.7040509@gmail.com>
Message-ID: <CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>

>
> How does Hotspot deal in general with situations where the optimized code,
> while executing, invalidates it's assumptions? Does this ever happen
> currently?


I think this depends on the type of assumptions/optimizations made.  In
some cases, a "guard" is installed, which if it doesn't pass, triggers
deoptimization (i.e. generated code does some cheap check, and if it
doesn't pass, calls a runtime function that triggers deopt).  Other cases
piggyback on things like class loading (e.g. devirtualizing because only
one known type is loaded), and register class loading dependencies that, if
triggered, will trigger deoptimization.

I suspect Vladimir's proposal will require another type of hook that
triggers when a final field is modified (so similar in principle to class
loading hooks).

On Thu, Oct 9, 2014 at 4:53 PM, Peter Levart <peter.levart at gmail.com> wrote:

>
> On 10/09/2014 07:53 PM, Paul Sandoz wrote:
>
> On Oct 9, 2014, at 3:23 AM, Vladimir Ivanov <vladimir.x.ivanov at oracle.com> <vladimir.x.ivanov at oracle.com> wrote:
>
>  What HotSpot misses right now (to preserve correctness w.r.t. Reflection API) is a way to track dependencies between final fields and nmethods which embed their values. It would allow to invalidate all nmethods which rely on stale value and ensure the updated value is "visible" everywhere in the running application.
>
>
>  In such a case would it provide a form of eventual consistency or would there be checks in place before a final field is used? e.g. one thread could be stomping on a final field while another thread is executing an nmethod under the assumption the field is final (and what if the nmethod is executing a large or infinite loop?).
>
>
> Or, if nmethod that depends on the value of the field which is
> constant-folded in it's code, modifies this same field in 1st part and
> after that executes 2nd part that uses constant-folded value? How does
> Hotspot deal in general with situations where the optimized code, while
> executing, invalidates it's assumptions? Does this ever happen currently?
>
> Regards, Peter
>
>  Instead perhaps final fields should really be final and safe mechanisms are provided to support the DI and serialization use-cases, which i suspect cover almost all use-cases.
>
> Paul.
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141009/b1f03f59/attachment.html>

From mr.chrisvest at gmail.com  Fri Oct 10 06:12:08 2014
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Fri, 10 Oct 2014 12:12:08 +0200
Subject: [concurrency-interest] The atomicity of StampedLock lock conversion
Message-ID: <225F5036-57EE-42A9-B1F3-3578DA27F601@gmail.com>

Hi,

One might, without further research, come to be ostensibly reasonable conclusion that a read-write lock that offers lock conversion, would be able to convert a write-lock into a read-lock atomically.

Reading the documentation for the StampedLock#tryConvertToRead, we?re told that if given a write-lock stamp, the method will first release that write-lock, and then obtain a read-lock, thus leaving a window for someone else to grab the lock ahead of us.

This ends up being a bad thing in my case. My code can, however, also use optimistic read-locks just as well as the pessimistic read-lock, so I turn to StampedLock#tryConvertToOptimisticRead. I?m told that the write-lock will be released and that I?ll get an observation stamp. I am not told whether or not this transition is atomic. That is, if it?s possible for the lock to be taken and then released again, in between me releasing my write-lock and obtaining the observation stamp, in some sense, such that the observation stamp will validate when I ask about it later.

So that?s my question: Is StampedLock#tryConvertToOptimisticRead atomic in this respect?

Cheers,
Chris

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141010/245bb928/attachment.html>

From dl at cs.oswego.edu  Fri Oct 10 09:43:23 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 10 Oct 2014 09:43:23 -0400
Subject: [concurrency-interest] The atomicity of StampedLock lock
	conversion
In-Reply-To: <225F5036-57EE-42A9-B1F3-3578DA27F601@gmail.com>
References: <225F5036-57EE-42A9-B1F3-3578DA27F601@gmail.com>
Message-ID: <5437E27B.9040005@cs.oswego.edu>

On 10/10/2014 06:12 AM, Chris Vest wrote:
> One might, without further research, come to be ostensibly reasonable conclusion
> that a read-write lock that offers lock conversion, would be able to convert a
> write-lock into a read-lock atomically.

Yes.

>
> Reading the documentation for the StampedLock#tryConvertToRead, we?re told that
> if given a write-lock stamp, the method will first release that write-lock, and
> /then/ obtain a read-lock, thus leaving a window for someone else to grab the
> lock ahead of us.

The word "then" doesn't appear in specs. Perhaps we should clarify
by adding "atomically" in:

     /**
      * If the lock state matches the given stamp, performs one of
=>
      * If the lock state matches the given stamp, atomically performs one of

      * the following actions. If the stamp represents holding a write
      * lock, releases it and obtains a read lock.  Or, if a read lock,
      * returns it. Or, if an optimistic read, acquires a read lock and
      * returns a read stamp only if immediately available. This method
      * returns zero in all other cases.

And similarly for the others.

-Doug






From mr.chrisvest at gmail.com  Fri Oct 10 10:09:41 2014
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Fri, 10 Oct 2014 16:09:41 +0200
Subject: [concurrency-interest] The atomicity of StampedLock lock
	conversion
In-Reply-To: <5437E27B.9040005@cs.oswego.edu>
References: <225F5036-57EE-42A9-B1F3-3578DA27F601@gmail.com>
	<5437E27B.9040005@cs.oswego.edu>
Message-ID: <E0F4A895-659D-4758-8221-83F6ECDF4A1A@gmail.com>

Okay, so I was just reading it wrong. Putting in the word ?atomically? as you?ve shown makes it clear.

Cheers,
Chris

On 10 Oct 2014, at 15:43, Doug Lea <dl at cs.oswego.edu> wrote:

> On 10/10/2014 06:12 AM, Chris Vest wrote:
>> One might, without further research, come to be ostensibly reasonable conclusion
>> that a read-write lock that offers lock conversion, would be able to convert a
>> write-lock into a read-lock atomically.
> 
> Yes.
> 
>> 
>> Reading the documentation for the StampedLock#tryConvertToRead, we?re told that
>> if given a write-lock stamp, the method will first release that write-lock, and
>> /then/ obtain a read-lock, thus leaving a window for someone else to grab the
>> lock ahead of us.
> 
> The word "then" doesn't appear in specs. Perhaps we should clarify
> by adding "atomically" in:
> 
>    /**
>     * If the lock state matches the given stamp, performs one of
> =>
>     * If the lock state matches the given stamp, atomically performs one of
> 
>     * the following actions. If the stamp represents holding a write
>     * lock, releases it and obtains a read lock.  Or, if a read lock,
>     * returns it. Or, if an optimistic read, acquires a read lock and
>     * returns a read stamp only if immediately available. This method
>     * returns zero in all other cases.
> 
> And similarly for the others.
> 
> -Doug
> 
> 
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141010/a51e55b2/attachment.html>

From dl at cs.oswego.edu  Fri Oct 10 10:44:44 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 10 Oct 2014 10:44:44 -0400
Subject: [concurrency-interest] The atomicity of StampedLock lock
	conversion
In-Reply-To: <E0F4A895-659D-4758-8221-83F6ECDF4A1A@gmail.com>
References: <225F5036-57EE-42A9-B1F3-3578DA27F601@gmail.com>
	<5437E27B.9040005@cs.oswego.edu>
	<E0F4A895-659D-4758-8221-83F6ECDF4A1A@gmail.com>
Message-ID: <5437F0DC.3030006@cs.oswego.edu>

On 10/10/2014 10:09 AM, Chris Vest wrote:
> Okay, so I was just reading it wrong. Putting in the word ?atomically? as you?ve
> shown makes it clear.

I committed this to our sources (3 places).
It might not appear in OpenJDK until next misc minor integration pass.

-Doug

>
> Cheers,
> Chris
>
> On 10 Oct 2014, at 15:43, Doug Lea <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>>
> wrote:
>
>> On 10/10/2014 06:12 AM, Chris Vest wrote:
>>> One might, without further research, come to be ostensibly reasonable conclusion
>>> that a read-write lock that offers lock conversion, would be able to convert a
>>> write-lock into a read-lock atomically.
>>
>> Yes.
>>
>>>
>>> Reading the documentation for the StampedLock#tryConvertToRead, we?re told that
>>> if given a write-lock stamp, the method will first release that write-lock, and
>>> /then/ obtain a read-lock, thus leaving a window for someone else to grab the
>>> lock ahead of us.
>>
>> The word "then" doesn't appear in specs. Perhaps we should clarify
>> by adding "atomically" in:
>>
>>    /**
>>     * If the lock state matches the given stamp, performs one of
>> =>
>>     * If the lock state matches the given stamp, atomically performs one of
>>
>>     * the following actions. If the stamp represents holding a write
>>     * lock, releases it and obtains a read lock.  Or, if a read lock,
>>     * returns it. Or, if an optimistic read, acquires a read lock and
>>     * returns a read stamp only if immediately available. This method
>>     * returns zero in all other cases.
>>
>> And similarly for the others.
>>
>> -Doug
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>




From vladimir.x.ivanov at oracle.com  Fri Oct 10 10:48:59 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Fri, 10 Oct 2014 18:48:59 +0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>
References: <542EBD0C.7080301@redhat.com>
	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>
	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com>	<54355B31.5010009@oracle.com>
	<54365AEB.5070002@gmail.com>	<5436623C.1030104@oracle.com>	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>	<5436F5E7.7040509@gmail.com>
	<CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>
Message-ID: <5437F1DB.8020304@oracle.com>

Guards and nmethod dependencies are complementary mechanisms to track 
actual dependencies of the generated code. What matters is how frequent 
"uncommon" is: "never" (0 out of 1M), "seldom" (10s out of 1M), "rare" 
(1000s out of 1M). Guards are always executed, so it's a good fit for 
checks for relatively rare conditions, but if condition is never met, it 
may be too much work. On the other hand, dependencies has zero overhead 
for common case, but deoptimization is prohibitively expensive - 
requires the whole VM to reach safepoint and invalidates all nmethod 
activations.

Depending on the property a dependency tracks, nmethod invalidation can 
be delayed or even never happen.

Consider 2 cases: class redefinition and CHA property invalidation.

In the former case, it's fine to have activations of stale versions in 
the system (spec allows that), but new invocations should target latest 
version. There's no need to invalidate existing activations.

For the latter case, after the class (which violates CHA dependency) is 
loaded, VM guarantees there are no and won't be any running activations 
of affected nmethods in the system. To achieve that VM supports forcible 
deoptimization (and guards are an example of cooperative deoptimization) 
- it patches all affected activations forcing execution to continue in 
the interpreter.

IMO, finals are closer to latter case, so once a field is changed, there 
should be no nmethods embedding stale value running in the system. The 
strategy should adapts to the application, so if an application 
repeatedly changes a final field and invalidates some methods, VM should 
leave the loads from that field as is. Current deoptimization machinery 
supports such scenario.

But it's just a way to optimize existing scenario. I agree with Pal that 
safe mechanism for the DI and serialization would be much better.

Best regards,
Vladimir Ivanov

On 10/10/14, 1:30 AM, Vitaly Davidovich wrote:
>     How does Hotspot deal in general with situations where the optimized
>     code, while executing, invalidates it's assumptions? Does this ever
>     happen currently?
>
>
> I think this depends on the type of assumptions/optimizations made.  In
> some cases, a "guard" is installed, which if it doesn't pass, triggers
> deoptimization (i.e. generated code does some cheap check, and if it
> doesn't pass, calls a runtime function that triggers deopt).  Other
> cases piggyback on things like class loading (e.g. devirtualizing
> because only one known type is loaded), and register class loading
> dependencies that, if triggered, will trigger deoptimization.
>
> I suspect Vladimir's proposal will require another type of hook that
> triggers when a final field is modified (so similar in principle to
> class loading hooks).
>
> On Thu, Oct 9, 2014 at 4:53 PM, Peter Levart <peter.levart at gmail.com
> <mailto:peter.levart at gmail.com>> wrote:
>
>
>     On 10/09/2014 07:53 PM, Paul Sandoz wrote:
>>     On Oct 9, 2014, at 3:23 AM, Vladimir Ivanov<vladimir.x.ivanov at oracle.com>  <mailto:vladimir.x.ivanov at oracle.com>  wrote:
>>>     What HotSpot misses right now (to preserve correctness w.r.t. Reflection API) is a way to track dependencies between final fields and nmethods which embed their values. It would allow to invalidate all nmethods which rely on stale value and ensure the updated value is "visible" everywhere in the running application.
>>>
>>     In such a case would it provide a form of eventual consistency or would there be checks in place before a final field is used? e.g. one thread could be stomping on a final field while another thread is executing an nmethod under the assumption the field is final (and what if the nmethod is executing a large or infinite loop?).
>
>     Or, if nmethod that depends on the value of the field which is
>     constant-folded in it's code, modifies this same field in 1st part
>     and after that executes 2nd part that uses constant-folded value?
>     How does Hotspot deal in general with situations where the optimized
>     code, while executing, invalidates it's assumptions? Does this ever
>     happen currently?
>
>     Regards, Peter
>
>>     Instead perhaps final fields should really be final and safe mechanisms are provided to support the DI and serialization use-cases, which i suspect cover almost all use-cases.
>>
>>     Paul.
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From vladimir.x.ivanov at oracle.com  Fri Oct 10 11:04:20 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Fri, 10 Oct 2014 19:04:20 +0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5436A7FF.8020404@gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>
	<5435539B.3010004@gmail.com> <54355B31.5010009@oracle.com>
	<54365AEB.5070002@gmail.com> <5436623C.1030104@oracle.com>
	<5436A7FF.8020404@gmail.com>
Message-ID: <5437F574.2000607@oracle.com>

Peter,

 >> I don't see how it improves the situation, except allowing lazy
>> initialization. It suffers from the very same problems as final
>> fields, if you want to perform multiple updates.
>
> But since they are new kind of fields, multiple updates can be
> prohibited on them from day one. Who would want such a feature anyway.
> Lazy setting yes, but not multiple updates. Normal fields are meant to
> be updated multiple times, finals are special-purpose fields.
That's true. My point was about changing final fields using Reflection 
API. It doesn't prohibit multiple updates of the same final field. For 
lazy finals it should be forbidden.

>> And the price for lazy initialization is default value, which can't be
>> optimized anymore.
>
> That's a pity yes, but as I understand, lazy-initialized finals are
> expected to be assigned a non-default value before they are used in hot
> code which can then benefit from constant folding, right?
Exactly. The problem is when the final value coincides with default 
value, but there are workarounds (use a wrapper/box).

>>> But what about this idea:
>>>
>>> Reflection supports updating ordinary final instance fields (via
>>> privileged setAccessible(true)) in order to achieve just what the lazy
>>> final fields are trying to achieve - lazy initialization outside
>>> constructor. Mainly to support Java  and other kinds of
>>> deserializations. I would say that any other uses of setAccessible(true)
>>> which assigns final field more than once are rare or non-existent. So
>>> why not making ordinary instance final fields *really* final by treating
>>> them in reflection as lazy final fields with a little tweak - the
>>> assignment of null/zero value to an "unassigned" field would not throw
>>> exception, but just be a NOOP - leave the field in "unassinged" state.
>>>
>>> This way deserialization of ordinary final fields would still work, but
>>> VM compiler could treat them all as @Stable, immediately optimizing huge
>>> codebases on a different level.
>>>
>>> Am I not seeing something in that simplified picture?
>> It's all about JIT compiler. Lazy finals/@Stable aren't a full match
>> for final field case, but they are close.
>>
>> The problem with treating final fields as lazy finals, is it can't be
>> limited only to accesses through Reflection API. The change should be
>> pervasive and default values should be treated specially everywhere,
>> forbidding constant-folding of loads from final fields w/ default
>> values. Do we really want that?
>
> Well, it would not be worse than it is now when constant-folding can't
> be performed regardless of final field's value. null/zero value would
> become a second-class citizen then. Not very nice, but perhaps acceptable.
>
>>
>> Regarding constant folding of loads from final fields, Hotspot already
>> optimizes loads for static final fields and there's an experimental
>> flag TrustFinalNonStaticFields for final instance fields case.
>
> So for static final fields, Hotspot already knows how to prove that some
> code can not observe uninitialized value before constant-folding it?
> Does it do any such thing for instance fields when this experimental
> flag is enabled or just trusts blindly that the code in question is only
> observing the "final" value when the time comes to optimize it? In other
> words, does this experimental flag guarantee correctness in all
> situations with the only exception being reflective final field updates?
HotSpot doesn't do anything special for both static & instance final 
fields. So, if you change them through Reflection API, you are on your 
own - in some situations some updates can go unnoticed by some parts of 
the application.

>> What HotSpot misses right now (to preserve correctness w.r.t.
>> Reflection API) is a way to track dependencies between final fields
>> and nmethods which embed their values. It would allow to invalidate
>> all nmethods which rely on stale value and ensure the updated value is
>> "visible" everywhere in the running application.
>
> This would be a cool optimization for mostly read-only and rarely
> updated fields, but do we want to transform final instance fields into
> such thing just to support deserialization via reflection? If this is
> not a big deal to support than perhaps it is a better approach since it
> does not neglect null/zero values.
DI & serialization shouldn't cause too much trouble IMO. IIUC, they 
mostly modify newly created objects which haven't been published yet.
So, there shouldn't be any embedded values to care about.

For corner cases of highly mutable final fields, VM should avoid 
optimizing them after a number of unsuccessful attempts.

Best regards,
Vladimir Ivanov

From vitalyd at gmail.com  Fri Oct 10 11:09:17 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 10 Oct 2014 11:09:17 -0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5437F1DB.8020304@oracle.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
	<54352F34.1010100@univ-mlv.fr> <5435539B.3010004@gmail.com>
	<54355B31.5010009@oracle.com> <54365AEB.5070002@gmail.com>
	<5436623C.1030104@oracle.com>
	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>
	<5436F5E7.7040509@gmail.com>
	<CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>
	<5437F1DB.8020304@oracle.com>
Message-ID: <CAHjP37HXAOvbLXNMMJYHWv+9hi1tky=BijvDZgm+aqfa=nzH+w@mail.gmail.com>

Thanks Vladimir for expanding.

For the latter case, after the class (which violates CHA dependency) is
> loaded, VM guarantees there are no and won't be any running activations of
> affected nmethods in the system. To achieve that VM supports forcible
> deoptimization (and guards are an example of cooperative deoptimization) -
> it patches all affected activations forcing execution to continue in the
> interpreter.


Just to confirm, the VM loads the class and sees a dependency was
registered for CHA purposes that the newly loaded class violates.  The
ensuing patching is done under a safepoint, right?

As an aside, classes marked final do not register any loader dependencies
right? (i.e. the JIT respects final on the class, even if none of the
non-private methods are marked final).  This is what I'd expect, but just
want to double-check.

IMO, finals are closer to latter case, so once a field is changed, there
> should be no nmethods embedding stale value running in the system. The
> strategy should adapts to the application, so if an application repeatedly
> changes a final field and invalidates some methods, VM should leave the
> loads from that field as is. Current deoptimization machinery supports such
> scenario.


Makes sense, agree.

But it's just a way to optimize existing scenario. I agree with Pal that
> safe mechanism for the DI and serialization would be much better.


Also agree :).  It's a shame that optimizations for final fields needs to
jump through hoops because of DI/serialization.

On Fri, Oct 10, 2014 at 10:48 AM, Vladimir Ivanov <
vladimir.x.ivanov at oracle.com> wrote:

> Guards and nmethod dependencies are complementary mechanisms to track
> actual dependencies of the generated code. What matters is how frequent
> "uncommon" is: "never" (0 out of 1M), "seldom" (10s out of 1M), "rare"
> (1000s out of 1M). Guards are always executed, so it's a good fit for
> checks for relatively rare conditions, but if condition is never met, it
> may be too much work. On the other hand, dependencies has zero overhead for
> common case, but deoptimization is prohibitively expensive - requires the
> whole VM to reach safepoint and invalidates all nmethod activations.
>
> Depending on the property a dependency tracks, nmethod invalidation can be
> delayed or even never happen.
>
> Consider 2 cases: class redefinition and CHA property invalidation.
>
> In the former case, it's fine to have activations of stale versions in the
> system (spec allows that), but new invocations should target latest
> version. There's no need to invalidate existing activations.
>
> For the latter case, after the class (which violates CHA dependency) is
> loaded, VM guarantees there are no and won't be any running activations of
> affected nmethods in the system. To achieve that VM supports forcible
> deoptimization (and guards are an example of cooperative deoptimization) -
> it patches all affected activations forcing execution to continue in the
> interpreter.
>
> IMO, finals are closer to latter case, so once a field is changed, there
> should be no nmethods embedding stale value running in the system. The
> strategy should adapts to the application, so if an application repeatedly
> changes a final field and invalidates some methods, VM should leave the
> loads from that field as is. Current deoptimization machinery supports such
> scenario.
>
> But it's just a way to optimize existing scenario. I agree with Pal that
> safe mechanism for the DI and serialization would be much better.
>
> Best regards,
> Vladimir Ivanov
>
> On 10/10/14, 1:30 AM, Vitaly Davidovich wrote:
>
>>     How does Hotspot deal in general with situations where the optimized
>>     code, while executing, invalidates it's assumptions? Does this ever
>>     happen currently?
>>
>>
>> I think this depends on the type of assumptions/optimizations made.  In
>> some cases, a "guard" is installed, which if it doesn't pass, triggers
>> deoptimization (i.e. generated code does some cheap check, and if it
>> doesn't pass, calls a runtime function that triggers deopt).  Other
>> cases piggyback on things like class loading (e.g. devirtualizing
>> because only one known type is loaded), and register class loading
>> dependencies that, if triggered, will trigger deoptimization.
>>
>> I suspect Vladimir's proposal will require another type of hook that
>> triggers when a final field is modified (so similar in principle to
>> class loading hooks).
>>
>> On Thu, Oct 9, 2014 at 4:53 PM, Peter Levart <peter.levart at gmail.com
>> <mailto:peter.levart at gmail.com>> wrote:
>>
>>
>>     On 10/09/2014 07:53 PM, Paul Sandoz wrote:
>>
>>>     On Oct 9, 2014, at 3:23 AM, Vladimir Ivanov<vladimir.x.ivanov@
>>> oracle.com>  <mailto:vladimir.x.ivanov at oracle.com>  wrote:
>>>
>>>>     What HotSpot misses right now (to preserve correctness w.r.t.
>>>> Reflection API) is a way to track dependencies between final fields and
>>>> nmethods which embed their values. It would allow to invalidate all
>>>> nmethods which rely on stale value and ensure the updated value is
>>>> "visible" everywhere in the running application.
>>>>
>>>>      In such a case would it provide a form of eventual consistency or
>>> would there be checks in place before a final field is used? e.g. one
>>> thread could be stomping on a final field while another thread is executing
>>> an nmethod under the assumption the field is final (and what if the nmethod
>>> is executing a large or infinite loop?).
>>>
>>
>>     Or, if nmethod that depends on the value of the field which is
>>     constant-folded in it's code, modifies this same field in 1st part
>>     and after that executes 2nd part that uses constant-folded value?
>>     How does Hotspot deal in general with situations where the optimized
>>     code, while executing, invalidates it's assumptions? Does this ever
>>     happen currently?
>>
>>     Regards, Peter
>>
>>      Instead perhaps final fields should really be final and safe
>>> mechanisms are provided to support the DI and serialization use-cases,
>>> which i suspect cover almost all use-cases.
>>>
>>>     Paul.
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest@
>>> cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141010/baf56783/attachment.html>

From vladimir.x.ivanov at oracle.com  Fri Oct 10 11:16:54 2014
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Fri, 10 Oct 2014 19:16:54 +0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <CAHjP37HXAOvbLXNMMJYHWv+9hi1tky=BijvDZgm+aqfa=nzH+w@mail.gmail.com>
References: <542EBD0C.7080301@redhat.com>	<542F6641.3090600@oracle.com>	<5431ADA5.2070904@gmail.com>	<5435062C.6020200@gmail.com>	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>	<54352F34.1010100@univ-mlv.fr>	<5435539B.3010004@gmail.com>	<54355B31.5010009@oracle.com>	<54365AEB.5070002@gmail.com>	<5436623C.1030104@oracle.com>	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>	<5436F5E7.7040509@gmail.com>	<CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>	<5437F1DB.8020304@oracle.com>
	<CAHjP37HXAOvbLXNMMJYHWv+9hi1tky=BijvDZgm+aqfa=nzH+w@mail.gmail.com>
Message-ID: <5437F866.90204@oracle.com>

Vitaly,

>     For the latter case, after the class (which violates CHA dependency)
>     is loaded, VM guarantees there are no and won't be any running
>     activations of affected nmethods in the system. To achieve that VM
>     supports forcible deoptimization (and guards are an example of
>     cooperative deoptimization) - it patches all affected activations
>     forcing execution to continue in the interpreter.
>
>
> Just to confirm, the VM loads the class and sees a dependency was
> registered for CHA purposes that the newly loaded class violates.  The
> ensuing patching is done under a safepoint, right?
Yes, forcible deoptimization is performed during a safepoint. 
Cooperative deoptimization doesn't trigger a safepoint - the thread 
hitting deoptimization point does all the work itself.

> As an aside, classes marked final do not register any loader
> dependencies right? (i.e. the JIT respects final on the class, even if
> none of the non-private methods are marked final).  This is what I'd
> expect, but just want to double-check.
Yes, there's no need to register a dependency for a method in a final 
class.

Best regards,
Vladimir Ivanov

>
>     IMO, finals are closer to latter case, so once a field is changed,
>     there should be no nmethods embedding stale value running in the
>     system. The strategy should adapts to the application, so if an
>     application repeatedly changes a final field and invalidates some
>     methods, VM should leave the loads from that field as is. Current
>     deoptimization machinery supports such scenario.
>
>
> Makes sense, agree.
>
>     But it's just a way to optimize existing scenario. I agree with Pal
>     that safe mechanism for the DI and serialization would be much better.
>
>
> Also agree :).  It's a shame that optimizations for final fields needs
> to jump through hoops because of DI/serialization.
>
> On Fri, Oct 10, 2014 at 10:48 AM, Vladimir Ivanov
> <vladimir.x.ivanov at oracle.com <mailto:vladimir.x.ivanov at oracle.com>> wrote:
>
>     Guards and nmethod dependencies are complementary mechanisms to
>     track actual dependencies of the generated code. What matters is how
>     frequent "uncommon" is: "never" (0 out of 1M), "seldom" (10s out of
>     1M), "rare" (1000s out of 1M). Guards are always executed, so it's a
>     good fit for checks for relatively rare conditions, but if condition
>     is never met, it may be too much work. On the other hand,
>     dependencies has zero overhead for common case, but deoptimization
>     is prohibitively expensive - requires the whole VM to reach
>     safepoint and invalidates all nmethod activations.
>
>     Depending on the property a dependency tracks, nmethod invalidation
>     can be delayed or even never happen.
>
>     Consider 2 cases: class redefinition and CHA property invalidation.
>
>     In the former case, it's fine to have activations of stale versions
>     in the system (spec allows that), but new invocations should target
>     latest version. There's no need to invalidate existing activations.
>
>     For the latter case, after the class (which violates CHA dependency)
>     is loaded, VM guarantees there are no and won't be any running
>     activations of affected nmethods in the system. To achieve that VM
>     supports forcible deoptimization (and guards are an example of
>     cooperative deoptimization) - it patches all affected activations
>     forcing execution to continue in the interpreter.
>
>     IMO, finals are closer to latter case, so once a field is changed,
>     there should be no nmethods embedding stale value running in the
>     system. The strategy should adapts to the application, so if an
>     application repeatedly changes a final field and invalidates some
>     methods, VM should leave the loads from that field as is. Current
>     deoptimization machinery supports such scenario.
>
>     But it's just a way to optimize existing scenario. I agree with Pal
>     that safe mechanism for the DI and serialization would be much better.
>
>     Best regards,
>     Vladimir Ivanov
>
>     On 10/10/14, 1:30 AM, Vitaly Davidovich wrote:
>
>              How does Hotspot deal in general with situations where the
>         optimized
>              code, while executing, invalidates it's assumptions? Does
>         this ever
>              happen currently?
>
>
>         I think this depends on the type of assumptions/optimizations
>         made.  In
>         some cases, a "guard" is installed, which if it doesn't pass,
>         triggers
>         deoptimization (i.e. generated code does some cheap check, and if it
>         doesn't pass, calls a runtime function that triggers deopt).  Other
>         cases piggyback on things like class loading (e.g. devirtualizing
>         because only one known type is loaded), and register class loading
>         dependencies that, if triggered, will trigger deoptimization.
>
>         I suspect Vladimir's proposal will require another type of hook that
>         triggers when a final field is modified (so similar in principle to
>         class loading hooks).
>
>         On Thu, Oct 9, 2014 at 4:53 PM, Peter Levart
>         <peter.levart at gmail.com <mailto:peter.levart at gmail.com>
>         <mailto:peter.levart at gmail.com
>         <mailto:peter.levart at gmail.com>__>> wrote:
>
>
>              On 10/09/2014 07:53 PM, Paul Sandoz wrote:
>
>                  On Oct 9, 2014, at 3:23 AM, Vladimir
>             Ivanov<vladimir.x.ivanov at __oracle.com
>             <mailto:vladimir.x.ivanov at oracle.com>>
>             <mailto:vladimir.x.ivanov at __oracle.com
>             <mailto:vladimir.x.ivanov at oracle.com>>  wrote:
>
>                      What HotSpot misses right now (to preserve
>                 correctness w.r.t. Reflection API) is a way to track
>                 dependencies between final fields and nmethods which
>                 embed their values. It would allow to invalidate all
>                 nmethods which rely on stale value and ensure the
>                 updated value is "visible" everywhere in the running
>                 application.
>
>                  In such a case would it provide a form of eventual
>             consistency or would there be checks in place before a final
>             field is used? e.g. one thread could be stomping on a final
>             field while another thread is executing an nmethod under the
>             assumption the field is final (and what if the nmethod is
>             executing a large or infinite loop?).
>
>
>              Or, if nmethod that depends on the value of the field which is
>              constant-folded in it's code, modifies this same field in
>         1st part
>              and after that executes 2nd part that uses constant-folded
>         value?
>              How does Hotspot deal in general with situations where the
>         optimized
>              code, while executing, invalidates it's assumptions? Does
>         this ever
>              happen currently?
>
>              Regards, Peter
>
>                  Instead perhaps final fields should really be final and
>             safe mechanisms are provided to support the DI and
>             serialization use-cases, which i suspect cover almost all
>             use-cases.
>
>                  Paul.
>
>
>                  _________________________________________________
>                  Concurrency-interest mailing list
>             Concurrency-interest at cs.__oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             <mailto:Concurrency-interest at __cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>>
>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>              _________________________________________________
>              Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>              <mailto:Concurrency-interest at __cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
>         _________________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>

From vitalyd at gmail.com  Fri Oct 10 11:36:23 2014
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 10 Oct 2014 11:36:23 -0400
Subject: [concurrency-interest] lazy finals - was: Here's why
 Atomic*FieldReference access checking is broken
In-Reply-To: <5437F866.90204@oracle.com>
References: <542EBD0C.7080301@redhat.com> <542F6641.3090600@oracle.com>
	<5431ADA5.2070904@gmail.com> <5435062C.6020200@gmail.com>
	<CANPzfU9W3nPN+eMg5fRfFLMCB5iB0g3c_oeDPT=ZC2RPHvAtNQ@mail.gmail.com>
	<54352F34.1010100@univ-mlv.fr> <5435539B.3010004@gmail.com>
	<54355B31.5010009@oracle.com> <54365AEB.5070002@gmail.com>
	<5436623C.1030104@oracle.com>
	<60EAB61D-A3E5-4C21-B2F6-0FC3869702E5@oracle.com>
	<5436F5E7.7040509@gmail.com>
	<CAHjP37GGTYnV0aL3tYTKrJ1=dAFQnj+muh5=sSuJxwdWfQc0ag@mail.gmail.com>
	<5437F1DB.8020304@oracle.com>
	<CAHjP37HXAOvbLXNMMJYHWv+9hi1tky=BijvDZgm+aqfa=nzH+w@mail.gmail.com>
	<5437F866.90204@oracle.com>
Message-ID: <CAHjP37FFhqVk0v--DBb45Eabzwrn0cRKeEjd-fh82MJE+S0Eag@mail.gmail.com>

Thanks for confirming.

On the subject of CHA, I think one thing I've noticed is the following.
Given the following type hierarchy and use of it:

interface Bar { void foo(); }

abstract class AbstractBar implements Bar {
      final void foo() {...}
}

final class A extends AbstractBar {}
final class B extends AbstractBar {}

class UserOfBar {
   void doFooOnBar(Bar b) {
        b.foo();
    }
}

Suppose doFooOnBar() only sees A for a while, enough times to compile the
code.  It then generates a guard checking that the receiver is A.  When B
is received, the method is deoptimized with a maybe_recompile reason (I
*think*, if I remember correctly).  Now, I think I understand why it does
that, but from a high-level standpoint, there's really no reason to deopt
because both A and B share the same impl of foo(), which is final in their
base class.  I wonder if there's any way to make the type check/guard
somehow narrow it down such that only if it sees a Bar that's not extending
AbstractBar a deopt occurs.

Is this consistent with your understanding of what would happen in the
above case?


On Fri, Oct 10, 2014 at 11:16 AM, Vladimir Ivanov <
vladimir.x.ivanov at oracle.com> wrote:

> Vitaly,
>
>      For the latter case, after the class (which violates CHA dependency)
>>     is loaded, VM guarantees there are no and won't be any running
>>     activations of affected nmethods in the system. To achieve that VM
>>     supports forcible deoptimization (and guards are an example of
>>     cooperative deoptimization) - it patches all affected activations
>>     forcing execution to continue in the interpreter.
>>
>>
>> Just to confirm, the VM loads the class and sees a dependency was
>> registered for CHA purposes that the newly loaded class violates.  The
>> ensuing patching is done under a safepoint, right?
>>
> Yes, forcible deoptimization is performed during a safepoint. Cooperative
> deoptimization doesn't trigger a safepoint - the thread hitting
> deoptimization point does all the work itself.
>
>  As an aside, classes marked final do not register any loader
>> dependencies right? (i.e. the JIT respects final on the class, even if
>> none of the non-private methods are marked final).  This is what I'd
>> expect, but just want to double-check.
>>
> Yes, there's no need to register a dependency for a method in a final
> class.
>
> Best regards,
> Vladimir Ivanov
>
>
>>     IMO, finals are closer to latter case, so once a field is changed,
>>     there should be no nmethods embedding stale value running in the
>>     system. The strategy should adapts to the application, so if an
>>     application repeatedly changes a final field and invalidates some
>>     methods, VM should leave the loads from that field as is. Current
>>     deoptimization machinery supports such scenario.
>>
>>
>> Makes sense, agree.
>>
>>     But it's just a way to optimize existing scenario. I agree with Pal
>>     that safe mechanism for the DI and serialization would be much better.
>>
>>
>> Also agree :).  It's a shame that optimizations for final fields needs
>> to jump through hoops because of DI/serialization.
>>
>> On Fri, Oct 10, 2014 at 10:48 AM, Vladimir Ivanov
>> <vladimir.x.ivanov at oracle.com <mailto:vladimir.x.ivanov at oracle.com>>
>> wrote:
>>
>>     Guards and nmethod dependencies are complementary mechanisms to
>>     track actual dependencies of the generated code. What matters is how
>>     frequent "uncommon" is: "never" (0 out of 1M), "seldom" (10s out of
>>     1M), "rare" (1000s out of 1M). Guards are always executed, so it's a
>>     good fit for checks for relatively rare conditions, but if condition
>>     is never met, it may be too much work. On the other hand,
>>     dependencies has zero overhead for common case, but deoptimization
>>     is prohibitively expensive - requires the whole VM to reach
>>     safepoint and invalidates all nmethod activations.
>>
>>     Depending on the property a dependency tracks, nmethod invalidation
>>     can be delayed or even never happen.
>>
>>     Consider 2 cases: class redefinition and CHA property invalidation.
>>
>>     In the former case, it's fine to have activations of stale versions
>>     in the system (spec allows that), but new invocations should target
>>     latest version. There's no need to invalidate existing activations.
>>
>>     For the latter case, after the class (which violates CHA dependency)
>>     is loaded, VM guarantees there are no and won't be any running
>>     activations of affected nmethods in the system. To achieve that VM
>>     supports forcible deoptimization (and guards are an example of
>>     cooperative deoptimization) - it patches all affected activations
>>     forcing execution to continue in the interpreter.
>>
>>     IMO, finals are closer to latter case, so once a field is changed,
>>     there should be no nmethods embedding stale value running in the
>>     system. The strategy should adapts to the application, so if an
>>     application repeatedly changes a final field and invalidates some
>>     methods, VM should leave the loads from that field as is. Current
>>     deoptimization machinery supports such scenario.
>>
>>     But it's just a way to optimize existing scenario. I agree with Pal
>>     that safe mechanism for the DI and serialization would be much better.
>>
>>     Best regards,
>>     Vladimir Ivanov
>>
>>     On 10/10/14, 1:30 AM, Vitaly Davidovich wrote:
>>
>>              How does Hotspot deal in general with situations where the
>>         optimized
>>              code, while executing, invalidates it's assumptions? Does
>>         this ever
>>              happen currently?
>>
>>
>>         I think this depends on the type of assumptions/optimizations
>>         made.  In
>>         some cases, a "guard" is installed, which if it doesn't pass,
>>         triggers
>>         deoptimization (i.e. generated code does some cheap check, and if
>> it
>>         doesn't pass, calls a runtime function that triggers deopt).
>> Other
>>         cases piggyback on things like class loading (e.g. devirtualizing
>>         because only one known type is loaded), and register class loading
>>         dependencies that, if triggered, will trigger deoptimization.
>>
>>         I suspect Vladimir's proposal will require another type of hook
>> that
>>         triggers when a final field is modified (so similar in principle
>> to
>>         class loading hooks).
>>
>>         On Thu, Oct 9, 2014 at 4:53 PM, Peter Levart
>>         <peter.levart at gmail.com <mailto:peter.levart at gmail.com>
>>         <mailto:peter.levart at gmail.com
>>         <mailto:peter.levart at gmail.com>__>> wrote:
>>
>>
>>              On 10/09/2014 07:53 PM, Paul Sandoz wrote:
>>
>>                  On Oct 9, 2014, at 3:23 AM, Vladimir
>>             Ivanov<vladimir.x.ivanov at __oracle.com
>>             <mailto:vladimir.x.ivanov at oracle.com>>
>>             <mailto:vladimir.x.ivanov at __oracle.com
>>
>>             <mailto:vladimir.x.ivanov at oracle.com>>  wrote:
>>
>>                      What HotSpot misses right now (to preserve
>>                 correctness w.r.t. Reflection API) is a way to track
>>                 dependencies between final fields and nmethods which
>>                 embed their values. It would allow to invalidate all
>>                 nmethods which rely on stale value and ensure the
>>                 updated value is "visible" everywhere in the running
>>                 application.
>>
>>                  In such a case would it provide a form of eventual
>>             consistency or would there be checks in place before a final
>>             field is used? e.g. one thread could be stomping on a final
>>             field while another thread is executing an nmethod under the
>>             assumption the field is final (and what if the nmethod is
>>             executing a large or infinite loop?).
>>
>>
>>              Or, if nmethod that depends on the value of the field which
>> is
>>              constant-folded in it's code, modifies this same field in
>>         1st part
>>              and after that executes 2nd part that uses constant-folded
>>         value?
>>              How does Hotspot deal in general with situations where the
>>         optimized
>>              code, while executing, invalidates it's assumptions? Does
>>         this ever
>>              happen currently?
>>
>>              Regards, Peter
>>
>>                  Instead perhaps final fields should really be final and
>>             safe mechanisms are provided to support the DI and
>>             serialization use-cases, which i suspect cover almost all
>>             use-cases.
>>
>>                  Paul.
>>
>>
>>                  _________________________________________________
>>                  Concurrency-interest mailing list
>>             Concurrency-interest at cs.__oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             <mailto:Concurrency-interest at __cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>>
>>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>              _________________________________________________
>>              Concurrency-interest mailing list
>>         Concurrency-interest at cs.__oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>              <mailto:Concurrency-interest at __cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>>
>>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>>         _________________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.__oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141010/6043f32b/attachment.html>

From cowwoc at bbs.darktech.org  Sun Oct 26 22:21:28 2014
From: cowwoc at bbs.darktech.org (cowwoc)
Date: Sun, 26 Oct 2014 19:21:28 -0700 (MST)
Subject: [concurrency-interest] How to subclass CompletableFuture?
Message-ID: <1414376488284-11382.post@n7.nabble.com>

Hi,

I believe that CompletableFuture was designed to allow for subclassing but I
can't seem to figure out how to implement such a subclass:
http://stackoverflow.com/q/26579139/14731

I figured if anyone would know how to implement this kind of thing, it would
be you :)

Thanks,
Gili



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From kasperni at gmail.com  Mon Oct 27 01:44:41 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Mon, 27 Oct 2014 06:44:41 +0100
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <1414376488284-11382.post@n7.nabble.com>
References: <1414376488284-11382.post@n7.nabble.com>
Message-ID: <CAPs6153trc+BQjdyPixKJz8fvbXjVqQjx64FGFQULpfmPbJVzQ@mail.gmail.com>

I've found CompletableFuture impossible to extend. Mainly because all the
methods returns new instances of CompletableFuture. Where you probably want
to return new instances of your CompletableFutureSubClass.

So I think the proper way is using composition. However with all the
methods in CompletableStage it takes some determination.

- Kasper


On Mon, Oct 27, 2014 at 3:21 AM, cowwoc <cowwoc at bbs.darktech.org> wrote:

> Hi,
>
> I believe that CompletableFuture was designed to allow for subclassing but
> I
> can't seem to figure out how to implement such a subclass:
> http://stackoverflow.com/q/26579139/14731
>
> I figured if anyone would know how to implement this kind of thing, it
> would
> be you :)
>
> Thanks,
> Gili
>
>
>
> --
> View this message in context:
> http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141027/b50533b7/attachment.html>

From cowwoc at bbs.darktech.org  Mon Oct 27 04:13:08 2014
From: cowwoc at bbs.darktech.org (cowwoc)
Date: Mon, 27 Oct 2014 01:13:08 -0700 (MST)
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <CAPs6153trc+BQjdyPixKJz8fvbXjVqQjx64FGFQULpfmPbJVzQ@mail.gmail.com>
References: <1414376488284-11382.post@n7.nabble.com>
	<CAPs6153trc+BQjdyPixKJz8fvbXjVqQjx64FGFQULpfmPbJVzQ@mail.gmail.com>
Message-ID: <1414397588979-11384.post@n7.nabble.com>

Hi Kasper,

I actually tried composition before subclassing, but I found that
thenComposeAsync() would hang indefinitely. I never did figure out the cause
but I suspect it has to do with the fact the code invokes:

  dst = new CompletableFuture<U>();

in a couple of places. In other words, I don't think composition is possible
either.

Has anyone successfully extended this class using subclassing or
composition? If not, is it possible for us to add methods which would make
it suitable for extension?

This class violates DRY if users wish to execute multiple tasks
asynchronously on the same (custom) Executor. I appreciate the fact that
some people might want to specify a different Executor per task, but the
inability to add a Facade on top of this class is making it very painful to
use.

Gili


Kasper Nielsen-4 wrote
> I've found CompletableFuture impossible to extend. Mainly because all the
> methods returns new instances of CompletableFuture. Where you probably
> want
> to return new instances of your CompletableFutureSubClass.
> 
> So I think the proper way is using composition. However with all the
> methods in CompletableStage it takes some determination.
> 
> - Kasper
> 
> 
> On Mon, Oct 27, 2014 at 3:21 AM, cowwoc &lt;

> cowwoc at .darktech

> &gt; wrote:
> 
>> Hi,
>>
>> I believe that CompletableFuture was designed to allow for subclassing
>> but
>> I
>> can't seem to figure out how to implement such a subclass:
>> http://stackoverflow.com/q/26579139/14731
>>
>> I figured if anyone would know how to implement this kind of thing, it
>> would
>> be you :)
>>
>> Thanks,
>> Gili
>>
>>
>>
>> --
>> View this message in context:
>> http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382.html
>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>> _______________________________________________
>> Concurrency-interest mailing list
>> 

> Concurrency-interest at .oswego

>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> 
> _______________________________________________
> Concurrency-interest mailing list

> Concurrency-interest at .oswego

> http://cs.oswego.edu/mailman/listinfo/concurrency-interest





--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382p11384.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From dl at cs.oswego.edu  Thu Oct 30 16:52:04 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 30 Oct 2014 16:52:04 -0400
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <1414376488284-11382.post@n7.nabble.com>
References: <1414376488284-11382.post@n7.nabble.com>
Message-ID: <5452A4F4.5020309@cs.oswego.edu>

On 10/26/2014 10:21 PM, cowwoc wrote:
> Hi,
>
> I believe that CompletableFuture was designed to allow for subclassing but I
> can't seem to figure out how to implement such a subclass:
> http://stackoverflow.com/q/26579139/14731

I was about to answer this, but I see that Holger already posted
one good approach on stackoverflow. Thanks Holger!

One further note though: One reason interface CompletionStage exists
is so that you don't have to subclass CompletableFuture, or
use it in any way at all for alternative implementations. However,
the handy static methods to get chains started aren't available,
so you'd need to provide alternatives.

-Doug


From cowwoc at bbs.darktech.org  Thu Oct 30 17:46:58 2014
From: cowwoc at bbs.darktech.org (cowwoc)
Date: Thu, 30 Oct 2014 14:46:58 -0700 (MST)
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <5452A4F4.5020309@cs.oswego.edu>
References: <1414376488284-11382.post@n7.nabble.com>
	<5452A4F4.5020309@cs.oswego.edu>
Message-ID: <5452B2AD.20409@bbs.darktech.org>

On 30/10/2014 5:00 PM, Doug Lea [via JSR166 Concurrency] wrote:
> On 10/26/2014 10:21 PM, cowwoc wrote:
> > Hi,
> >
> > I believe that CompletableFuture was designed to allow for 
> subclassing but I
> > can't seem to figure out how to implement such a subclass:
> > http://stackoverflow.com/q/26579139/14731
>
> I was about to answer this, but I see that Holger already posted
> one good approach on stackoverflow. Thanks Holger!
>
> One further note though: One reason interface CompletionStage exists
> is so that you don't have to subclass CompletableFuture, or
> use it in any way at all for alternative implementations. However,
> the handy static methods to get chains started aren't available,
> so you'd need to provide alternatives.
>
> -Doug

Hi Doug,

Holger pretty much nailed the answer, but I did have a related question: 
is complete() equivalent to internalComplete()? Meaning, can one 
implement supplyAsync() as follows?

CompletionStage<T> supplyAsync(Supplier<T> s, Executor e)
{
   CompletionStage<T> result = new MyCompletionStage(...);
   e.execute(() ->
   {
     result.complete(s.get());
   });
   return result;
}

Imagine we have 
MyCompletionStage.supplyAsync(...).thenApplyAsync(...).thenComplete(...);

The Javadoc for complete() sound as if we're locking the future's value 
such that subsequent operations (i.e. thenApplyAsync()) cannot invoke 
complete() with a different value. Does complete() work this way or do 
you mean that the proceeding code consists of 3 stages and each stage 
may only invoke complete() once?

Is there a way to clarify the Javadoc of CompletableFuture or 
CompletionStage on this point (ideally by way of example code)?

Thanks,
Gili




--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382p11386.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141030/11859dde/attachment.html>

From dl at cs.oswego.edu  Thu Oct 30 19:58:45 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 30 Oct 2014 19:58:45 -0400
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <5452B2AD.20409@bbs.darktech.org>
References: <1414376488284-11382.post@n7.nabble.com>	<5452A4F4.5020309@cs.oswego.edu>
	<5452B2AD.20409@bbs.darktech.org>
Message-ID: <5452D0B5.1000901@cs.oswego.edu>

On 10/30/2014 05:46 PM, cowwoc wrote:

> Hi Doug,
>
> Holger pretty much nailed the answer, but I did have a related question:
> is complete() equivalent to internalComplete()?

For your purposes, yes. The internals shouldn't matter in
any usages, but complete() atomically establishes result
using internalComplete (and its variants), and then non-atomically
triggers dependents using postComplete.

> Meaning, can one
> implement supplyAsync() as follows?
>
> CompletionStage<T> supplyAsync(Supplier<T> s, Executor e)
> {
>     CompletionStage<T> result = new MyCompletionStage(...);
>     e.execute(() ->
>     {
>       result.complete(s.get());
>     });
>     return result;
> }

Yes.

> Imagine we have
> MyCompletionStage.supplyAsync(...).thenApplyAsync(...).thenComplete(...);

There is no "thenComplete", so I'm not sure what you are asking?

>
> The Javadoc for complete() sound as if we're locking the future's value
> such that subsequent operations (i.e. thenApplyAsync()) cannot invoke
> complete() with a different value.

In general yes. (There is a last-resort escape hatch
obtrudeValue, with known use cases only for failure recovery.)

>
> Is there a way to clarify the Javadoc of CompletableFuture or
> CompletionStage on this point (ideally by way of example code)?
>

Please let us know what kinds of wordings and examples would be
helpful!

-Doug



From cowwoc at bbs.darktech.org  Fri Oct 31 08:43:35 2014
From: cowwoc at bbs.darktech.org (cowwoc)
Date: Fri, 31 Oct 2014 05:43:35 -0700 (MST)
Subject: [concurrency-interest] How to subclass CompletableFuture?
In-Reply-To: <5452D0B5.1000901@cs.oswego.edu>
References: <1414376488284-11382.post@n7.nabble.com>
	<5452A4F4.5020309@cs.oswego.edu> <5452B2AD.20409@bbs.darktech.org>
	<5452D0B5.1000901@cs.oswego.edu>
Message-ID: <545384D9.30503@bbs.darktech.org>

On 30/10/2014 8:05 PM, Doug Lea [via JSR166 Concurrency] wrote:
> > Imagine we have
> > 
> MyCompletionStage.supplyAsync(...).thenApplyAsync(...).thenComplete(...);
>
> There is no "thenComplete", so I'm not sure what you are asking?

My mistake. The last phase was meant to be a thenApplyAsync() that 
invokes complete().

> > The Javadoc for complete() sound as if we're locking the future's value
> > such that subsequent operations (i.e. thenApplyAsync()) cannot invoke
> > complete() with a different value.
>
> In general yes. (There is a last-resort escape hatch
> obtrudeValue, with known use cases only for failure recovery.)
>
> >
> > Is there a way to clarify the Javadoc of CompletableFuture or
> > CompletionStage on this point (ideally by way of example code)?
> >
>
> Please let us know what kinds of wordings and examples would be
> helpful!

I'll give you some example paragraphs I liked and we can work together 
to come up with a specific text for CompletableFuture.

http://keyholesoftware.com/2014/07/23/javascript-promises-are-cool/ reads:

     "A rejected or resolved promise is/settled/. A promise state can 
only move from pending to settled. Thereafter its state is immutable. A 
promise can be held long after its associated action has settled. At 
leisure, we can extract the result multiple times. We carry this out by 
calling/promise.then()/. That call won?t return unless, or until, the 
associated action has been settled. We can fluidly chain promises. The 
chained ?then? functions should each either return a promise, or let the 
original promise be the return value."

Further down they give a concrete example of how to flatten Promise 
chains (search for "Flattened promise chain").

I'd like the class Javadoc to make the following additional points:

  * A CompletableFuture is meant to be used by chaining together
    multiple instances together, where each stage returns a value or
    throws an exception.
  * Each stage may transform the value returned by a previous stage or
    return the original value unmodified.
  * The value returned by the initially-constructed CompletableFuture is
    equal to the value returned (or the exception thrown) by the
    last-executed stage.
  * (Provide a short example of how to flatten promise chains, inline or
    by linking to it.)

Let me know what you think.

Gili




--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/How-to-subclass-CompletableFuture-tp11382p11388.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20141031/ceb20cd9/attachment.html>

