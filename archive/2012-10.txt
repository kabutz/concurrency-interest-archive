From ebegoli at gmail.com  Mon Oct  1 10:47:55 2012
From: ebegoli at gmail.com (Edmon Begoli)
Date: Mon, 1 Oct 2012 10:47:55 -0400
Subject: [concurrency-interest] Call for participation in development of the
 Open Source Java concurrency benchmark (Hydra)
Message-ID: <CAGj+Ysc7nWkkVU_zc8UTf5cM2upzLd-JESFDMiJ3FV2RD597KA@mail.gmail.com>

All,


I would like to invite all on this mailing list who might be
interested in establishing,
having and using a widely recognized benchmark to contribute design
ideas and code to what I am proposing.

I have started developing a Java concurrency benchmark and it is
listed on Github.
Repository is here:
https://github.com/ebegoli/hydra

and wiki, just created is here:
https://github.com/ebegoli/hydra/wiki

I am doing this as part of the research effort I started at my lab
(Oak Ridge National Laboratory),
and since this is an open research I intend to make this an open
source, collaborative project and available to broader community.

So far, code is generally influenced by test code as provided in
jsr166y and extra, and I am needing to make it Java 6 compliant,
although Java 7 and Java 8 version will be implemented either
immediately or as branches.


At the minimum, you can help me with ideas what you think would be
relevant and should be benchmarked.

So far, I have been implementing a ParallelArraySort for arrays of
arbitrary size and possibly dynamic parallel sorting threshold.

I have also taken a Fibonacci example and want to turn it into a
benchmark. I would also like to have more numerical, parallel
benchmarks.

I am also developing a simple Latch or CyclicBarrier based benchark
for stateless, Actors like execution of functions with common
barrier/arrival point. With this I want to benchmark maximal thread
count and completion capabilities of the system.

If you are interested to participate please send me an e-mail or reply
to this. ANY help is appreciated.

For those interested in research and academic publishing we would also
work on a research paper outlining the benchmark
once the work is complete.

Thank you for your attention,
Edmon Begoli
ebegoli gmail com
begolie ornl gov

From andrew_nuss at yahoo.com  Wed Oct  3 09:24:33 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 06:24:33 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading under
	the covers?
Message-ID: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>

Hi,

I have a class with a single member, a reference to a new MessageDigest obtained in the constructor based on the algorithm name passed to the constructor.? The constructor also has a Reader argument and reads all the data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru to the digest with my own OutputStream filter.? The call to the constructor then accesses the MessageDigest member and calls digest() to get the resulting byte[].? My code by all appearances is single threaded, but I am having strange bugs that on one particular machine running vmware, the digest result I am getting (for password hashing) appears not to be repeatable.

Basically, I am wondering if another thread can execute the body of the constructor (or in the construction and use of the OutputStreamWriter, within my constructor) that could be causing a bug where memory written by the MessageDigest.update() function (triggered within the constructor by writing thru OutputStreamWriter) is not seen in the call to digest() on the newly created MessageDigest member after the constructor returns.

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/7c9c4673/attachment.html>

From aleksey.shipilev at oracle.com  Wed Oct  3 09:47:51 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 17:47:51 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
Message-ID: <506C4207.5020907@oracle.com>

Hi Andy,

On 10/03/2012 05:24 PM, Andy Nuss wrote:
> My code by all appearances is single
> threaded, but I am having strange bugs that on one particular machine
> running vmware, the digest result I am getting (for password hashing)
> appears not to be repeatable.

I don't think this has something to do with concurrency at all. Are you
sure you are reading up all the buffers, flushing and closing the
streams appropriately, etc? What if you have your own dummy
implementation of MessageDigest which only counts the consumed data
size? A test case would be helpful.

> Basically, I am wondering if another thread can execute the body of the
> constructor (or in the construction and use of the OutputStreamWriter,
> within my constructor) that could be causing a bug where memory written
> by the MessageDigest.update() function (triggered within the constructor
> by writing thru OutputStreamWriter) is not seen in the call to digest()
> on the newly created MessageDigest member after the constructor returns.

While the construction you describe here is possible, most MessageDigest
implementations are not threaded, and so both update() and digest() are
getting executed in the single callee context, which means there is no
races. Even if there are digest providers which execute update() and/or
digest() in separate threads, I would be surprised if they are not
enforcing any particular ordering (given concurrent update()-s make
sense for hashing at all).

-Aleksey.


From andrew_nuss at yahoo.com  Wed Oct  3 10:04:48 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 07:04:48 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <1349273088.59764.YahooMailNeo@web120303.mail.ne1.yahoo.com>

I call close on the outputstreamwriter in the finally of the constructor, flush implied by close.?? In the debugger, I see that at that point the write method in MyOutputStream is called, which calls digest.update().? The digest is SHA256.? I've walked thru my code over and over and over.? The bug only happens on one particular dual core machine, a Mac running Centos under vmware.


The reason I ask about the constructor is this: java memory model provides a guarantee that all memory set/changed in the constructor is immediately visible to any other thread (that receives a reference to new object) after the constructor returns.? Is this true?? Is the contructor always executed in the same thread as its caller?



________________________________
 From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 6:47 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
Hi Andy,

On 10/03/2012 05:24 PM, Andy Nuss wrote:
> My code by all appearances is single
> threaded, but I am having strange bugs that on one particular machine
> running vmware, the digest result I am getting (for password hashing)
> appears not to be repeatable.

I don't think this has something to do with concurrency at all. Are you
sure you are reading up all the buffers, flushing and closing the
streams appropriately, etc? What if you have your own dummy
implementation of MessageDigest which only counts the consumed data
size? A test case would be helpful.

> Basically, I am wondering if another thread can execute the body of the
> constructor (or in the construction and use of the OutputStreamWriter,
> within my constructor) that could be causing a bug where memory written
> by the MessageDigest.update() function (triggered within the constructor
> by writing thru
 OutputStreamWriter) is not seen in the call to digest()
> on the newly created MessageDigest member after the constructor returns.

While the construction you describe here is possible, most MessageDigest
implementations are not threaded, and so both update() and digest() are
getting executed in the single callee context, which means there is no
races. Even if there are digest providers which execute update() and/or
digest() in separate threads, I would be surprised if they are not
enforcing any particular ordering (given concurrent update()-s make
sense for hashing at all).

-Aleksey.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/112a8aed/attachment.html>

From vitalyd at gmail.com  Wed Oct  3 10:20:22 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 10:20:22 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349273088.59764.YahooMailNeo@web120303.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349273088.59764.YahooMailNeo@web120303.mail.ne1.yahoo.com>
Message-ID: <CAHjP37Fco0wiWkWa+s+hPi9swPjSxrhXZwhatNV+VP7CRmX63A@mail.gmail.com>

Your last statement is untrue in the general case - it depends on how you
publish the newly constructed instance and/or whether the fields of the
class are final.

The constructor for a *given instance* is on a single thread, that part is
true.  If your constructor modifies static shared state, then it's racy.
Basically, a constructor should be thought of just like a normal method in
this regard.

Sent from my phone
On Oct 3, 2012 10:07 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> I call close on the outputstreamwriter in the finally of the constructor,
> flush implied by close.   In the debugger, I see that at that point the
> write method in MyOutputStream is called, which calls digest.update().  The
> digest is SHA256.  I've walked thru my code over and over and over.  The
> bug only happens on one particular dual core machine, a Mac running Centos
> under vmware.
>
> The reason I ask about the constructor is this: java memory model provides
> a guarantee that all memory set/changed in the constructor is immediately
> visible to any other thread (that receives a reference to new object) after
> the constructor returns.  Is this true?  Is the contructor always executed
> in the same thread as its caller?
>
>   ------------------------------
> *From:* Aleksey Shipilev <aleksey.shipilev at oracle.com>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 6:47 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> Hi Andy,
>
> On 10/03/2012 05:24 PM, Andy Nuss wrote:
> > My code by all appearances is single
> > threaded, but I am having strange bugs that on one particular machine
> > running vmware, the digest result I am getting (for password hashing)
> > appears not to be repeatable.
>
> I don't think this has something to do with concurrency at all. Are you
> sure you are reading up all the buffers, flushing and closing the
> streams appropriately, etc? What if you have your own dummy
> implementation of MessageDigest which only counts the consumed data
> size? A test case would be helpful.
>
> > Basically, I am wondering if another thread can execute the body of the
> > constructor (or in the construction and use of the OutputStreamWriter,
> > within my constructor) that could be causing a bug where memory written
> > by the MessageDigest.update() function (triggered within the constructor
> > by writing thru OutputStreamWriter) is not seen in the call to digest()
> > on the newly created MessageDigest member after the constructor returns.
>
> While the construction you describe here is possible, most MessageDigest
> implementations are not threaded, and so both update() and digest() are
> getting executed in the single callee context, which means there is no
> races. Even if there are digest providers which execute update() and/or
> digest() in separate threads, I would be surprised if they are not
> enforcing any particular ordering (given concurrent update()-s make
> sense for hashing at all).
>
> -Aleksey.
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/7cf1c25a/attachment-0001.html>

From andrew_nuss at yahoo.com  Wed Oct  3 10:22:55 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 07:22:55 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <506C47AA.5070906@oracle.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
Message-ID: <1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>

(It was a reply accident that I did not reply to list.)

So if I follow you correctly, for a constructor that has an array or ArrayList member, creates that array/ArrayList, and fills it with a bunch of seeded values, which are effectively final: another thread will not see the values in the array/ArrayList unless the constructed object is "published" to the other thread, such as with a volatile variable or concurrent map.

In that case, can someone explain to me how java String, which holds an array of characters, is threadsafe without the need for publishing the string to the other thread?? I.e. even if the array reference is final, the "final" attribute does not apply to the elements of the array.? Same with a final ArrayList reference.



________________________________
 From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Sent: Wednesday, October 3, 2012 7:11 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
Any specific reason you are not replying to the list? :)

On 10/03/2012 06:04 PM, Andy Nuss wrote:
> The reason I ask about the constructor is this: java memory model
> provides a guarantee that all memory set/changed in the constructor is
> immediately visible to any other thread (that receives a reference to
> new object) after the constructor returns.? Is this true?? 

Ughm, there is a requirement for the final field values of newly
constructed objects set in constructor are visible after constructor
finishes, and only in the case if you haven't leaked the reference to
"this" in the constructor.

There is no memory semantics for constructor invocation otherwise. I.e.:

class A {
?  private int myField;

?  public int get() {
? ? ? // DOES NOT force $myField visibility
? ? ? return new A(myField).value;
?  }
}

class B {
?  int v;
?  public B(int v) { value = v; }
}

Neither it would change if you make B.v final.

> Is the contructor always executed in the same thread as its caller?

Yes, it acts like ordinary method in this regard, no specific treatment.

-Aleksey.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/ed4280d0/attachment.html>

From aleksey.shipilev at oracle.com  Wed Oct  3 10:23:02 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 18:23:02 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349273088.59764.YahooMailNeo@web120303.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349273088.59764.YahooMailNeo@web120303.mail.ne1.yahoo.com>
Message-ID: <506C4A46.8010708@oracle.com>

On 10/03/2012 06:04 PM, Andy Nuss wrote:
> The reason I ask about the constructor is this: java memory model
> provides a guarantee that all memory set/changed in the constructor is
> immediately visible to any other thread (that receives a reference to
> new object) after the constructor returns.  Is this true?

Ughm, there is a requirement for the final field values of newly
constructed objects set in constructor are visible after constructor
finishes, and only in the case if you haven't leaked the reference to
"this" in the constructor.

There is no memory semantics for constructor invocation otherwise. I.e.:

class A {
   private int myField;

   public int get() {
      // DOES NOT force $myField visibility
      return new B(myField).value;
   }
}

class B {
   final int value;
   public B(int v) { value = v; }
}

> Is the contructor always executed in the same thread as its caller?

Yes, it acts like ordinary method in this regard, no specific implicit
treatment.

-Aleksey.


From vitalyd at gmail.com  Wed Oct  3 10:31:26 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 10:31:26 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <CAHjP37E28asTOSOKi2zisFyuVxx0eH5MMsFE7fxqdqvXxtnSgw@mail.gmail.com>

The final array reference is sufficient for preventing reordering of the
writes into the array with the subsequent assignment to the array.
Moreover, final field assignments in the constructor prevent the reordering
of those statements in the constructor with the assignment of the newly
constructed instance with the reference pointing at it.

I think what you're referring to is that a volatile array does not imply
volatile behavior for its elements (I.e. stores into the array).  But
assignment into the array reference is still volatile (but you need final
if you're publishing via data race).

Sent from my phone
On Oct 3, 2012 10:25 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> (It was a reply accident that I did not reply to list.)
>
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a bunch
> of seeded values, which are effectively final: another thread will not see
> the values in the array/ArrayList unless the constructed object is
> "published" to the other thread, such as with a volatile variable or
> concurrent map.
>
> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?  I.e. even if the array reference is final, the
> "final" attribute does not apply to the elements of the array.  Same with a
> final ArrayList reference.
>
>   ------------------------------
> *From:* Aleksey Shipilev <aleksey.shipilev at oracle.com>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Sent:* Wednesday, October 3, 2012 7:11 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> Any specific reason you are not replying to the list? :)
>
> On 10/03/2012 06:04 PM, Andy Nuss wrote:
> > The reason I ask about the constructor is this: java memory model
> > provides a guarantee that all memory set/changed in the constructor is
> > immediately visible to any other thread (that receives a reference to
> > new object) after the constructor returns.  Is this true?
>
> Ughm, there is a requirement for the final field values of newly
> constructed objects set in constructor are visible after constructor
> finishes, and only in the case if you haven't leaked the reference to
> "this" in the constructor.
>
> There is no memory semantics for constructor invocation otherwise. I.e.:
>
> class A {
>   private int myField;
>
>   public int get() {
>       // DOES NOT force $myField visibility
>       return new A(myField).value;
>   }
> }
>
> class B {
>   int v;
>   public B(int v) { value = v; }
> }
>
> Neither it would change if you make B.v final.
>
> > Is the contructor always executed in the same thread as its caller?
>
> Yes, it acts like ordinary method in this regard, no specific treatment.
>
> -Aleksey.
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/80161bb4/attachment.html>

From andrew_nuss at yahoo.com  Wed Oct  3 10:37:14 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 07:37:14 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>

For clarification, lets say a caller passes my constructor an ArrayList with seeded values.

class EffectivelyImmutableArrayListWrapper {
??? private volatile ArrayList? mylist;

??? EffectivelyImmutableArrayListWrapper (ArrayList list)
??? {
????????? // .... create mylist and copy all values from list into mylist
????????? // this class only provides getters for mylist
????????? // mylist never changes except in this constructor where created and filled

??? }

??? // getter functions for mylist

}

From the above snippet, we see that we are attempting to provide a publishing wrapper/snapshot for an ArrayList.? Is "volatile" necessary here?? I assume that "final" does not work, because "mylist" is just a reference.? Also, what if the contract of the constructor was that the caller would never change/use the arraylist arg after calling the constructor: in that case, could the constructor just copy the arg reference to the volatile "mylist" member and be done?

Assuming that I am correct that "mylist" has to be volatile, how does java.lang.String accomplish immutability of the private char[] without making it volatile?



________________________________
 From: Andy Nuss <andrew_nuss at yahoo.com>
To: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 7:22 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 

(It was a reply accident that I did not reply to list.)

So if I follow you correctly, for a constructor that has an array or ArrayList member, creates that array/ArrayList, and fills it with a bunch of seeded values, which are effectively final: another thread will not see the values in the array/ArrayList unless the constructed object is "published" to the other thread, such as with a volatile variable or concurrent map.

In that case, can someone explain to me how java String, which holds an array of characters, is threadsafe without the need for publishing the string to the other thread?? I.e. even if the array reference is final, the "final" attribute does not apply to the elements of the array.? Same with a final ArrayList reference.


________________________________
 From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Sent: Wednesday, October 3, 2012 7:11 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
Any specific reason you are not replying to the list? :)

On 10/03/2012 06:04 PM, Andy Nuss wrote:
> The reason I ask about the constructor is this: java memory model
> provides a guarantee that all memory set/changed in the constructor is
> immediately visible to any other thread (that receives a reference to
> new object) after the constructor returns.? Is this true?? 

Ughm, there is a requirement for the final field values of newly
constructed objects set in constructor are visible after constructor
finishes, and only in the case if you haven't leaked the reference to
"this" in the constructor.

There is no memory semantics for constructor invocation otherwise. I.e.:

class A {
?  private int myField;

?  public int get() {
? ? ? // DOES NOT force $myField visibility
? ? ? return new A(myField).value;
? 
 }
}

class B {
?  int v;
?  public B(int v) { value = v; }
}

Neither it would change if you make B.v final.

> Is the contructor always executed in the same thread as its caller?

Yes, it acts like ordinary method in this regard, no specific treatment.

-Aleksey.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/b167904e/attachment-0001.html>

From aleksey.shipilev at oracle.com  Wed Oct  3 10:44:34 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 18:44:34 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <506C4F52.3000400@oracle.com>

Andy,

On 10/03/2012 06:22 PM, Andy Nuss wrote:
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a
> bunch of seeded values, which are effectively final: another thread will
> not see the values in the array/ArrayList unless the constructed object
> is "published" to the other thread, such as with a volatile variable or
> concurrent map.

If you are reading those "seeded" values from somewhere else, then there
is no guarantees you will read the actual values in the constructor
unless you take the precaution of publishing those values safely. If you
are populating the list in the constructor with generated values and
store it in the field, then you are fine:

public class A {
    private final List<Integer> list;
    public A() {
        list = new ArrayList<>();
        list.add(1); list.add(2); list.add(3);
    }
}

// everything is visible
List<Integer> l = new A().list;

---------

private int myRogueField;

public class B {
    private final List<Integer> list;
    public B() {
        list = new ArrayList<>();
        list.add(myRogueField);
    }
}

// no guarantees actual $myRogueField value is there
List<Integer> l = new B().list;

---------

private volatile int myAwesomeField;

public class C {
    private final List<Integer> list;
    public C() {
        list = new ArrayList<>();
        list.add(myAwesomeField);
    }
}

// extra care was given when reading $myAwesomeField
// guaranteed to be visible in the list.
List<Integer> l = new C().list;

---------

Note that you have to make sure you *read* the correct values when
passing those to the constructor. Target constructor itself could not
enforce this.

> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?  I.e. even if the array reference is final,
> the "final" attribute does not apply to the elements of the array.  Same
> with a final ArrayList reference.

Sorry, can't see the problem.

String is immutable, you can not write into the backing char[] array
there. Once string is created, it copies the contents into its own array
(modulo contrived cases of subString()) in constructor, gets everything
freezed as required by JMM, and uses the array then. If you are
providing the String with safely-acquired source char[] array, it goes
the "class A" as described above.

-Aleksey.


From aleksey.shipilev at oracle.com  Wed Oct  3 10:49:30 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 18:49:30 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
Message-ID: <506C507A.7070609@oracle.com>

On 10/03/2012 06:37 PM, Andy Nuss wrote:
> For clarification, lets say a caller passes my constructor an ArrayList
> with seeded values.
> 
> class EffectivelyImmutableArrayListWrapper {
>     private volatile ArrayList  mylist;
>     EffectivelyImmutableArrayListWrapper (ArrayList list)
>     {
>           // .... create mylist and copy all values from list into mylist
>           // this class only provides getters for mylist
>           // mylist never changes except in this constructor where
> created and filled
>     }
> 
>     // getter functions for mylist
> }
> 
> From the above snippet, we see that we are attempting to provide a
> publishing wrapper/snapshot for an ArrayList.  Is "volatile" necessary
> here?  

It wouldn't help if $list passed in constructor is published unsafely.
It's too late for EffectivelyImmutableArrayListWrapper to do anything
about it.

-Aleksey.




From andrew_nuss at yahoo.com  Wed Oct  3 10:59:59 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 07:59:59 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <506C4F52.3000400@oracle.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
Message-ID: <1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>

My assumption: I am never 
getting seeded values from somewhere else.? All seed values are passed 
into the constructor with argument containers.

My first question is:? why is it ok to assign the final reference to the newly created ArrayList before filling it with values?
Second question is: how is data race for the newly created values in the ArrayList solved just by making ArrayList member variable final (rather than volatile)?

So I am getting from you guys that I just have to deep copy the argument containers into my own newly created containers, and make the reference to the new containers final, AND make sure that no values are ever added to the containers after the constructor finishes.? Is this correct?

Would it be possible to eliminate the deep copy step if my apis required that the caller never change the contents of the containers after passing them to my constructor?? In that case, maybe I could just assign the references to the argument containers to "final volatile" members, and all my getters would access thru the final volatile members.



________________________________
 From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 7:44 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
Andy,

On 10/03/2012 06:22 PM, Andy Nuss wrote:
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a
> bunch of seeded values, which are effectively final: another thread will
> not see the values in the array/ArrayList unless the constructed object
> is "published" to the other thread, such as with a volatile variable or
> concurrent map.

If you are reading those "seeded" values from somewhere else, then there
is no guarantees you will read the actual values in the constructor
unless you take the precaution of publishing those values safely. If you
are populating the list in the constructor with generated values and
store it in the field, then you are fine:

public class A {
? ? private final List<Integer> list;
? ? public A() {
? ? ? ? list = new ArrayList<>();
? ? ? ? list.add(1); list.add(2); list.add(3);
? ? }
}

// everything is visible
List<Integer> l = new A().list;

---------

private int myRogueField;

public class B {
? ? private final List<Integer> list;
? ? public B() {
? ? ? ? list = new ArrayList<>();
? ? ? ? list.add(myRogueField);
? ? }
}

// no guarantees actual $myRogueField value is there
List<Integer> l = new B().list;

---------

private volatile int myAwesomeField;

public class C {
? ? private final List<Integer> list;
? ? public C() {
? ? ? ? list = new ArrayList<>();
? ? ? ? list.add(myAwesomeField);
? ? }
}

// extra care was given when reading $myAwesomeField
// guaranteed to be visible in the list.
List<Integer> l = new C().list;

---------

Note that you have to make sure you *read* the correct values when
passing those to the constructor. Target constructor itself could not
enforce this.

> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?? I.e. even if the array reference is final,
> the "final" attribute does not apply to the elements of the array.? Same
> with a final ArrayList reference.

Sorry, can't see the problem.

String is immutable, you can not write into the backing char[] array
there. Once string is created, it copies the contents into its own array
(modulo contrived cases of subString()) in constructor, gets everything
freezed as required by JMM, and uses the array then. If you are
providing the String with safely-acquired source char[] array, it goes
the "class A" as described above.

-Aleksey.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/faf0e875/attachment.html>

From vitalyd at gmail.com  Wed Oct  3 11:22:01 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 11:22:01 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
Message-ID: <CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>

Andy,

I'm still unclear on whether you have any multi threaded code or not.

To answer your questions:

1) assigning to final list *before* populating it doesn't conform to JMM.
It may work in practice if JIT doesn't rearrange things just because
there's *any* final assignment in the ctor, but it could.  You'd have to
instead populate a temp list and then assign it to the final field.  Again,
this is only important if you're doing data race publishing.

2) final fields get special treatment in JMM - they prevent the reordering
of the final assignment with any prior assignment in program order.
Consider this:

Foo f = new Foo();
In program order, you have assignment in the ctor body followed by normal
assignment to f.  Volatile allows normal stores that *follow* a volatile
store to reorder before it; final doesn't.  Let's decompose the above:
ctor:
      x = ...
      y = ....
f = <new obj>

If x and/or y are volatile, then f assignment can float above assignments
to x and/or y.  If f is static and read by another thread, it can see
non-null f but not see x and y writes yet.  If x and y are final (or in the
order above, just y can be final), this reordering cannot occur (outside of
bug in JVM).

If you publish f safely, then none of the above makes any difference - the
publication will ensure all writes are visible with the synchronizing
reader.

Sent from my phone
On Oct 3, 2012 11:02 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> My assumption: I am never getting seeded values from somewhere else.  All
> seed values are passed into the constructor with argument containers.
>
> My first question is:  why is it ok to assign the final reference to the
> newly created ArrayList before filling it with values?
> Second question is: how is data race for the newly created values in the
> ArrayList solved just by making ArrayList member variable final (rather
> than volatile)?
>
> So I am getting from you guys that I just have to deep copy the argument
> containers into my own newly created containers, and make the reference to
> the new containers final, AND make sure that no values are ever added to
> the containers after the constructor finishes.  Is this correct?
>
> Would it be possible to eliminate the deep copy step if my apis required
> that the caller never change the contents of the containers after passing
> them to my constructor?  In that case, maybe I could just assign the
> references to the argument containers to "final volatile" members, and all
> my getters would access thru the final volatile members.
>
>   ------------------------------
> *From:* Aleksey Shipilev <aleksey.shipilev at oracle.com>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 7:44 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> Andy,
>
> On 10/03/2012 06:22 PM, Andy Nuss wrote:
> > So if I follow you correctly, for a constructor that has an array or
> > ArrayList member, creates that array/ArrayList, and fills it with a
> > bunch of seeded values, which are effectively final: another thread will
> > not see the values in the array/ArrayList unless the constructed object
> > is "published" to the other thread, such as with a volatile variable or
> > concurrent map.
>
> If you are reading those "seeded" values from somewhere else, then there
> is no guarantees you will read the actual values in the constructor
> unless you take the precaution of publishing those values safely. If you
> are populating the list in the constructor with generated values and
> store it in the field, then you are fine:
>
> public class A {
>     private final List<Integer> list;
>     public A() {
>         list = new ArrayList<>();
>         list.add(1); list.add(2); list.add(3);
>     }
> }
>
> // everything is visible
> List<Integer> l = new A().list;
>
> ---------
>
> private int myRogueField;
>
> public class B {
>     private final List<Integer> list;
>     public B() {
>         list = new ArrayList<>();
>         list.add(myRogueField);
>     }
> }
>
> // no guarantees actual $myRogueField value is there
> List<Integer> l = new B().list;
>
> ---------
>
> private volatile int myAwesomeField;
>
> public class C {
>     private final List<Integer> list;
>     public C() {
>         list = new ArrayList<>();
>         list.add(myAwesomeField);
>     }
> }
>
> // extra care was given when reading $myAwesomeField
> // guaranteed to be visible in the list.
> List<Integer> l = new C().list;
>
> ---------
>
> Note that you have to make sure you *read* the correct values when
> passing those to the constructor. Target constructor itself could not
> enforce this.
>
> > In that case, can someone explain to me how java String, which holds an
> > array of characters, is threadsafe without the need for publishing the
> > string to the other thread?  I.e. even if the array reference is final,
> > the "final" attribute does not apply to the elements of the array.  Same
> > with a final ArrayList reference.
>
> Sorry, can't see the problem.
>
> String is immutable, you can not write into the backing char[] array
> there. Once string is created, it copies the contents into its own array
> (modulo contrived cases of subString()) in constructor, gets everything
> freezed as required by JMM, and uses the array then. If you are
> providing the String with safely-acquired source char[] array, it goes
> the "class A" as described above.
>
> -Aleksey.
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/5db4c504/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  3 11:24:40 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 11:24:40 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
Message-ID: <CAHjP37F_atfibFx2TPqRdfMf6A0NOodns7db6SC2XNmUHqk9ew@mail.gmail.com>

Oops, I miswrote #2 - final fields prevent *subsequent* reordering, not
prior.

Sent from my phone
On Oct 3, 2012 11:22 AM, "Vitaly Davidovich" <vitalyd at gmail.com> wrote:

> Andy,
>
> I'm still unclear on whether you have any multi threaded code or not.
>
> To answer your questions:
>
> 1) assigning to final list *before* populating it doesn't conform to JMM.
> It may work in practice if JIT doesn't rearrange things just because
> there's *any* final assignment in the ctor, but it could.  You'd have to
> instead populate a temp list and then assign it to the final field.  Again,
> this is only important if you're doing data race publishing.
>
> 2) final fields get special treatment in JMM - they prevent the reordering
> of the final assignment with any prior assignment in program order.
> Consider this:
>
> Foo f = new Foo();
> In program order, you have assignment in the ctor body followed by normal
> assignment to f.  Volatile allows normal stores that *follow* a volatile
> store to reorder before it; final doesn't.  Let's decompose the above:
> ctor:
>       x = ...
>       y = ....
> f = <new obj>
>
> If x and/or y are volatile, then f assignment can float above assignments
> to x and/or y.  If f is static and read by another thread, it can see
> non-null f but not see x and y writes yet.  If x and y are final (or in the
> order above, just y can be final), this reordering cannot occur (outside of
> bug in JVM).
>
> If you publish f safely, then none of the above makes any difference - the
> publication will ensure all writes are visible with the synchronizing
> reader.
>
> Sent from my phone
> On Oct 3, 2012 11:02 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:
>
>> My assumption: I am never getting seeded values from somewhere else.  All
>> seed values are passed into the constructor with argument containers.
>>
>> My first question is:  why is it ok to assign the final reference to the
>> newly created ArrayList before filling it with values?
>> Second question is: how is data race for the newly created values in the
>> ArrayList solved just by making ArrayList member variable final (rather
>> than volatile)?
>>
>> So I am getting from you guys that I just have to deep copy the argument
>> containers into my own newly created containers, and make the reference to
>> the new containers final, AND make sure that no values are ever added to
>> the containers after the constructor finishes.  Is this correct?
>>
>> Would it be possible to eliminate the deep copy step if my apis required
>> that the caller never change the contents of the containers after passing
>> them to my constructor?  In that case, maybe I could just assign the
>> references to the argument containers to "final volatile" members, and all
>> my getters would access thru the final volatile members.
>>
>>   ------------------------------
>> *From:* Aleksey Shipilev <aleksey.shipilev at oracle.com>
>> *To:* Andy Nuss <andrew_nuss at yahoo.com>
>> *Cc:* "concurrency-interest at cs.oswego.edu" <
>> concurrency-interest at cs.oswego.edu>
>> *Sent:* Wednesday, October 3, 2012 7:44 AM
>> *Subject:* Re: [concurrency-interest] do constructors ever involve
>> threading under the covers?
>>
>> Andy,
>>
>> On 10/03/2012 06:22 PM, Andy Nuss wrote:
>> > So if I follow you correctly, for a constructor that has an array or
>> > ArrayList member, creates that array/ArrayList, and fills it with a
>> > bunch of seeded values, which are effectively final: another thread will
>> > not see the values in the array/ArrayList unless the constructed object
>> > is "published" to the other thread, such as with a volatile variable or
>> > concurrent map.
>>
>> If you are reading those "seeded" values from somewhere else, then there
>> is no guarantees you will read the actual values in the constructor
>> unless you take the precaution of publishing those values safely. If you
>> are populating the list in the constructor with generated values and
>> store it in the field, then you are fine:
>>
>> public class A {
>>     private final List<Integer> list;
>>     public A() {
>>         list = new ArrayList<>();
>>         list.add(1); list.add(2); list.add(3);
>>     }
>> }
>>
>> // everything is visible
>> List<Integer> l = new A().list;
>>
>> ---------
>>
>> private int myRogueField;
>>
>> public class B {
>>     private final List<Integer> list;
>>     public B() {
>>         list = new ArrayList<>();
>>         list.add(myRogueField);
>>     }
>> }
>>
>> // no guarantees actual $myRogueField value is there
>> List<Integer> l = new B().list;
>>
>> ---------
>>
>> private volatile int myAwesomeField;
>>
>> public class C {
>>     private final List<Integer> list;
>>     public C() {
>>         list = new ArrayList<>();
>>         list.add(myAwesomeField);
>>     }
>> }
>>
>> // extra care was given when reading $myAwesomeField
>> // guaranteed to be visible in the list.
>> List<Integer> l = new C().list;
>>
>> ---------
>>
>> Note that you have to make sure you *read* the correct values when
>> passing those to the constructor. Target constructor itself could not
>> enforce this.
>>
>> > In that case, can someone explain to me how java String, which holds an
>> > array of characters, is threadsafe without the need for publishing the
>> > string to the other thread?  I.e. even if the array reference is final,
>> > the "final" attribute does not apply to the elements of the array.  Same
>> > with a final ArrayList reference.
>>
>> Sorry, can't see the problem.
>>
>> String is immutable, you can not write into the backing char[] array
>> there. Once string is created, it copies the contents into its own array
>> (modulo contrived cases of subString()) in constructor, gets everything
>> freezed as required by JMM, and uses the array then. If you are
>> providing the String with safely-acquired source char[] array, it goes
>> the "class A" as described above.
>>
>> -Aleksey.
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/af0f045a/attachment.html>

From jacyg at alumni.rice.edu  Wed Oct  3 11:45:46 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Wed, 3 Oct 2012 10:45:46 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
Message-ID: <CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>

I think there are two streams of thought here that are getting crossed.

First, I agree with Vitaly that it's still unclear if you have
multi-threading going on at all.  In the example you provide, is the
EffectivelyImmutableArrayListWrapper used across multiple threads?  If
it's not, than there's no need for really any modifier.  For a single
thread, you never have to worry about reordering.  It might likely
happen, but you are guaranteed that, going by program order,
operations which happen 'before' will be done prior to their use.  So
if the Wrapper is constructed and used within a single thread, you
don't need volatile, or final, or even to create a copy at all if the
'list' arg is never going to be modified subsequent to wrapping.

Second, based on the snipped below, if you *do* have multiple threads,
which surely you must?  then the areas for concern would be how the
'list' arg is passed in (i.e., is it getting populated in another
thread?) and then how the Wrapper is used after construction.  So
let's address those:

the list arg that you are passing in:  if it comes from the same
thread, you're in the single thread situation and
concurrency/reordering isn't an issue *up to the point of calling the
constructor*.  However, if you are populating the list in a different
thread before passing in, you need to make sure you pass/populate the
list in a thread safe fashion.  Otherwise, writes from the populating
thread might not have been done in the list when the Wrapper
constructing thread does its thing.

use of the wrapper:  if the wrapper will be used in the same thread it
was constructed in, then you're in the single thread scenario.  If it
will be used by multiple threads, then you have to worry about how you
construct it.  If the list arg you are passing in is not referenced by
any other threads and isn't going to be updated anywhere else, you
don't need to create a deep copy.  You can simply assign it to a final
variable, and you are good to go.  String(char[]) creates a defensive
copy to *guarantee* that the contents won't change (it doesn't trust
that you'll behave and drop your reference to the char[] you pass in).
 But creating a defensive copy is only necessary if you don't have
control over who might invoke the constructor.  If you are going to
create a defensive copy, your best bet would be to create the copy,
then assign the fully populated copy to a final variable.  Assigning
an empty copy to a volatile variable and then populating it doesn't
work.  The volatile only applies to that reference, not to the
references maintained inside the list itself.  You could create a
fully populated copy and then assign to a volatile variable, but if
you don't plan to change that reference, final would be a much better
option.

Does that help?

jacy


On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> For clarification, lets say a caller passes my constructor an ArrayList with
> seeded values.
>
> class EffectivelyImmutableArrayListWrapper {
>     private volatile ArrayList  mylist;
>     EffectivelyImmutableArrayListWrapper (ArrayList list)
>     {
>           // .... create mylist and copy all values from list into mylist
>           // this class only provides getters for mylist
>           // mylist never changes except in this constructor where created
> and filled
>     }
>
>     // getter functions for mylist
> }
>
> From the above snippet, we see that we are attempting to provide a
> publishing wrapper/snapshot for an ArrayList.  Is "volatile" necessary here?
> I assume that "final" does not work, because "mylist" is just a reference.
> Also, what if the contract of the constructor was that the caller would
> never change/use the arraylist arg after calling the constructor: in that
> case, could the constructor just copy the arg reference to the volatile
> "mylist" member and be done?
>
> Assuming that I am correct that "mylist" has to be volatile, how does
> java.lang.String accomplish immutability of the private char[] without
> making it volatile?
>
> ________________________________
> From: Andy Nuss <andrew_nuss at yahoo.com>
> To: "concurrency-interest at cs.oswego.edu"
> <concurrency-interest at cs.oswego.edu>
> Sent: Wednesday, October 3, 2012 7:22 AM
>
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
> (It was a reply accident that I did not reply to list.)
>
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a bunch of
> seeded values, which are effectively final: another thread will not see the
> values in the array/ArrayList unless the constructed object is "published"
> to the other thread, such as with a volatile variable or concurrent map.
>
> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?  I.e. even if the array reference is final, the
> "final" attribute does not apply to the elements of the array.  Same with a
> final ArrayList reference.
>
> ________________________________
> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> To: Andy Nuss <andrew_nuss at yahoo.com>
> Sent: Wednesday, October 3, 2012 7:11 AM
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
> Any specific reason you are not replying to the list? :)
>
> On 10/03/2012 06:04 PM, Andy Nuss wrote:
>> The reason I ask about the constructor is this: java memory model
>> provides a guarantee that all memory set/changed in the constructor is
>> immediately visible to any other thread (that receives a reference to
>> new object) after the constructor returns.  Is this true?
>
> Ughm, there is a requirement for the final field values of newly
> constructed objects set in constructor are visible after constructor
> finishes, and only in the case if you haven't leaked the reference to
> "this" in the constructor.
>
> There is no memory semantics for constructor invocation otherwise. I.e.:
>
> class A {
>   private int myField;
>
>   public int get() {
>       // DOES NOT force $myField visibility
>       return new A(myField).value;
>   }
> }
>
> class B {
>   int v;
>   public B(int v) { value = v; }
> }
>
> Neither it would change if you make B.v final.
>
>> Is the contructor always executed in the same thread as its caller?
>
> Yes, it acts like ordinary method in this regard, no specific treatment.
>
> -Aleksey.
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From aleksey.shipilev at oracle.com  Wed Oct  3 11:48:25 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 19:48:25 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
Message-ID: <506C5E49.9010704@oracle.com>

On 10/03/2012 07:22 PM, Vitaly Davidovich wrote:
> 1) assigning to final list *before* populating it doesn't conform to
> JMM.  It may work in practice if JIT doesn't rearrange things just
> because there's *any* final assignment in the ctor, but it could.  You'd
> have to instead populate a temp list and then assign it to the final
> field. 

This is true for volatile fields. But the semantics for final fields
seems to guarantee that the added element would be visible, because
(List.add) hb (freeze) in program order, and (freeze) hb (read reference
to new obj). Am I reading the spec incorrectly? Is it wrong to say
freeze action is the last action in program order of constructor?

-Aleksey.


From aleksey.shipilev at oracle.com  Wed Oct  3 11:49:50 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 19:49:50 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
Message-ID: <506C5E9E.2010901@oracle.com>

On 10/03/2012 06:59 PM, Andy Nuss wrote:
> My assumption: I am never getting seeded values from somewhere else. 
> All seed values are passed into the constructor with argument containers.
> 
> My first question is:  why is it ok to assign the final reference to the
> newly created ArrayList before filling it with values?

Because JMM guarantees nobody would see the under-initialized list
stored in the final field before constructor ends.

> Second question is: how is data race for the newly created values in the
> ArrayList solved just by making ArrayList member variable final (rather
> than volatile)?

Where's the data race exactly? Once constructor is doing freeze action,
everything in the list stored in final field is visible.

> So I am getting from you guys that I just have to deep copy the argument
> containers into my own newly created containers, and make the reference
> to the new containers final, AND make sure that no values are ever added
> to the containers after the constructor finishes.  Is this correct?

I think we are still confused here. My point is *it is too late* for
reader to enforce proper visibility if writer had published something
unsafely. Nothing will save you at this point, nor final, nor volatile,
nor deep-copying.

And if writer had indeed published something safely, and the published
value never changes, you might as well store the reference to it.

-Aleksey.

From aleksey.shipilev at oracle.com  Wed Oct  3 11:52:18 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 03 Oct 2012 19:52:18 +0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <506C5E49.9010704@oracle.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
	<506C5E49.9010704@oracle.com>
Message-ID: <506C5F32.6000401@oracle.com>

On 10/03/2012 07:48 PM, Aleksey Shipilev wrote:
> On 10/03/2012 07:22 PM, Vitaly Davidovich wrote:
>> 1) assigning to final list *before* populating it doesn't conform to
>> JMM.  It may work in practice if JIT doesn't rearrange things just
>> because there's *any* final assignment in the ctor, but it could.  You'd
>> have to instead populate a temp list and then assign it to the final
>> field. 
> 
> This is true for volatile fields. But the semantics for final fields
> seems to guarantee that the added element would be visible, because
> (List.add) hb (freeze) in program order, and (freeze) hb (read reference
> to new obj). Am I reading the spec incorrectly? Is it wrong to say
> freeze action is the last action in program order of constructor?

Otherwise, BTW, it is unclear for me how come this code is safe:
  http://www.javaconcurrencyinpractice.com/listings/ThreeStooges.java

-Aleksey.

From vitalyd at gmail.com  Wed Oct  3 12:05:58 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 12:05:58 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <506C5F32.6000401@oracle.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C4F52.3000400@oracle.com>
	<1349276399.28014.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAHjP37EThJxNXQ3vPVB90tcbEVEF0oxY3xW7hJjsJp_uK=JFvw@mail.gmail.com>
	<506C5E49.9010704@oracle.com> <506C5F32.6000401@oracle.com>
Message-ID: <CAHjP37G1e3gXGszx0R1YBWO6uGXZwyEd-yzvxo3SZXrSRbHfeg@mail.gmail.com>

You might be right Aleksey - it's a bit unclear to me as to where exactly
the StoreStore is placed; it's definitely before the assignment to the
shared ref, but not sure if it's immediately after the final store or at
the end of constructor.  Putting it at the end of ctor even if assignment
happened at the beginning would possibly be a perf impact on something like
ARM/PPC since more stores will have to drain, but I'm not that familiar
with ARM/PPC barrier performance.

Sent from my phone
On Oct 3, 2012 11:52 AM, "Aleksey Shipilev" <aleksey.shipilev at oracle.com>
wrote:

> On 10/03/2012 07:48 PM, Aleksey Shipilev wrote:
> > On 10/03/2012 07:22 PM, Vitaly Davidovich wrote:
> >> 1) assigning to final list *before* populating it doesn't conform to
> >> JMM.  It may work in practice if JIT doesn't rearrange things just
> >> because there's *any* final assignment in the ctor, but it could.  You'd
> >> have to instead populate a temp list and then assign it to the final
> >> field.
> >
> > This is true for volatile fields. But the semantics for final fields
> > seems to guarantee that the added element would be visible, because
> > (List.add) hb (freeze) in program order, and (freeze) hb (read reference
> > to new obj). Am I reading the spec incorrectly? Is it wrong to say
> > freeze action is the last action in program order of constructor?
>
> Otherwise, BTW, it is unclear for me how come this code is safe:
>   http://www.javaconcurrencyinpractice.com/listings/ThreeStooges.java
>
> -Aleksey.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/53f4129a/attachment.html>

From andrew_nuss at yahoo.com  Wed Oct  3 12:22:57 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 09:22:57 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
Message-ID: <1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>

This does help.

My model is this, and does involve multiple threads.? One thread creates and fills container data structure(s) that has no immutable guarantees, such as an ArrayList, HashMap, etc.? Then in that same thread, it calls a constructor to wrap the container, and give it an immutable api.? Then, the hope is that absolutely anyway that any other thread obtains a reference to the immutable wrapper, it will "see" all the data in the non-immutable containers.? Yes, I hope to not have to make defensive copies!? Yes, the same thread that seeded the data into non-thread safe containers is the thread that passes those containers to the immutable wrapper.


I understand now that all I have to do is assign my argument containers to a final member references in the immutable wrapper.? And that if I do defensive copy, do it first, and assign to the final member references at the end.

What I don't understand is this: another thread picks up the reference and starts using the object.? In all of the above, there was never a volatile member involved to ensure that other threads picking up the reference see the data in the containers.? Say I do this: new SomeThread(immutableReference).start().? This is the beginning of the second thread.? What is it about the final references in the immutable wrapper that causes SomeThread to "see" that data that Thread A seeded in ArrayList/HashMap and then wrapped in immutable wrapper, especially if there was no defensive copy?

Once I understand this, then I'll understand the workings of String, which clearly have no volatile members.? Strings assume that the thread which seeded the char[] is the thread that constructs the String, and somehow without any use of volatile, other threads that pick up the reference to the constructed String "see" the data in the defensively copyied char[].? "final" appears to solve reordering problems within the thread, but how does it "publish" data?



________________________________
 From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 8:45 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
I think there are two streams of thought here that are getting crossed.

First, I agree with Vitaly that it's still unclear if you have
multi-threading going on at all.? In the example you provide, is the
EffectivelyImmutableArrayListWrapper used across multiple threads?? If
it's not, than there's no need for really any modifier.? For a single
thread, you never have to worry about reordering.? It might likely
happen, but you are guaranteed that, going by program order,
operations which happen 'before' will be done prior to their use.? So
if the Wrapper is constructed and used within a single thread, you
don't need volatile, or final, or even to create a copy at all if the
'list' arg is never going to be modified subsequent to wrapping.

Second, based on the snipped below, if you *do* have multiple threads,
which surely you must?? then the areas for concern would be how the
'list' arg is passed in (i.e., is it getting populated in another
thread?) and then how the Wrapper is used after construction.? So
let's address those:

the list arg that you are passing in:? if it comes from the same
thread, you're in the single thread situation and
concurrency/reordering isn't an issue *up to the point of calling the
constructor*.? However, if you are populating the list in a different
thread before passing in, you need to make sure you pass/populate the
list in a thread safe fashion.? Otherwise, writes from the populating
thread might not have been done in the list when the Wrapper
constructing thread does its thing.

use of the wrapper:? if the wrapper will be used in the same thread it
was constructed in, then you're in the single thread scenario.? If it
will be used by multiple threads, then you have to worry about how you
construct it.? If the list arg you are passing in is not referenced by
any other threads and isn't going to be updated anywhere else, you
don't need to create a deep copy.? You can simply assign it to a final
variable, and you are good to go.? String(char[]) creates a defensive
copy to *guarantee* that the contents won't change (it doesn't trust
that you'll behave and drop your reference to the char[] you pass in).
But creating a defensive copy is only necessary if you don't have
control over who might invoke the constructor.? If you are going to
create a defensive copy, your best bet would be to create the copy,
then assign the fully populated copy to a final variable.? Assigning
an empty copy to a volatile variable and then populating it doesn't
work.? The volatile only applies to that reference, not to the
references maintained inside the list itself.? You could create a
fully populated copy and then assign to a volatile variable, but if
you don't plan to change that reference, final would be a much better
option.

Does that help?

jacy


On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> For clarification, lets say a caller passes my constructor an ArrayList with
> seeded values.
>
> class EffectivelyImmutableArrayListWrapper {
>? ?  private volatile ArrayList? mylist;
>? ?  EffectivelyImmutableArrayListWrapper (ArrayList list)
>? ?  {
>? ? ? ? ?  // .... create mylist and copy all values from list into mylist
>? ? ? ? ?  // this class only provides getters for mylist
>? ? ? ? ?  // mylist never changes except in this constructor where created
> and filled
>? ?  }
>
>? ?  // getter functions for mylist
> }
>
> From the above snippet, we see that we are attempting to provide a
> publishing wrapper/snapshot for an ArrayList.? Is "volatile" necessary here?
> I assume that "final" does not work, because "mylist" is just a reference.
> Also, what if the contract of the constructor was that the caller would
> never change/use the arraylist arg after calling the constructor: in that
> case, could the constructor just copy the arg reference to the volatile
> "mylist" member and be done?
>
> Assuming that I am correct that "mylist" has to be volatile, how does
> java.lang.String accomplish immutability of the private char[] without
> making it volatile?
>
> ________________________________
> From: Andy Nuss <andrew_nuss at yahoo.com>
> To: "concurrency-interest at cs.oswego.edu"
> <concurrency-interest at cs.oswego.edu>
> Sent: Wednesday, October 3, 2012 7:22 AM
>
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
> (It was a reply accident that I did not reply to list.)
>
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a bunch of
> seeded values, which are effectively final: another thread will not see the
> values in the array/ArrayList unless the constructed object is "published"
> to the other thread, such as with a volatile variable or concurrent map.
>
> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?? I.e. even if the array reference is final, the
> "final" attribute does not apply to the elements of the array.? Same with a
> final ArrayList reference.
>
> ________________________________
> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> To: Andy Nuss <andrew_nuss at yahoo.com>
> Sent: Wednesday, October 3, 2012 7:11 AM
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
> Any specific reason you are not replying to the list? :)
>
> On 10/03/2012 06:04 PM, Andy Nuss wrote:
>> The reason I ask about the constructor is this: java memory model
>> provides a guarantee that all memory set/changed in the constructor is
>> immediately visible to any other thread (that receives a reference to
>> new object) after the constructor returns.? Is this true?
>
> Ughm, there is a requirement for the final field values of newly
> constructed objects set in constructor are visible after constructor
> finishes, and only in the case if you haven't leaked the reference to
> "this" in the constructor.
>
> There is no memory semantics for constructor invocation otherwise. I.e.:
>
> class A {
>?  private int myField;
>
>?  public int get() {
>? ? ?  // DOES NOT force $myField visibility
>? ? ?  return new A(myField).value;
>?  }
> }
>
> class B {
>?  int v;
>?  public B(int v) { value = v; }
> }
>
> Neither it would change if you make B.v final.
>
>> Is the contructor always executed in the same thread as its caller?
>
> Yes, it acts like ordinary method in this regard, no specific treatment.
>
> -Aleksey.
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/f335da30/attachment-0001.html>

From andrew_nuss at yahoo.com  Wed Oct  3 12:28:52 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 09:28:52 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
	<1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
Message-ID: <1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>

A simple way of asking, if thread (that receives the immutable wrapper) runs on a different cpu, then without a memory fence, how does it "see" the data?? Do constructors hide a memory fence instruction under the covers?



________________________________
 From: Andy Nuss <andrew_nuss at yahoo.com>
To: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 9:22 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 

This does help.

My model is this, and does involve multiple threads.? One thread creates and fills container data structure(s) that has no immutable guarantees, such as an ArrayList, HashMap, etc.? Then in that same thread, it calls a constructor to wrap the container, and give it an immutable api.? Then, the hope is that absolutely anyway that any other thread obtains a reference to the immutable wrapper, it will "see" all the data in the non-immutable containers.? Yes, I hope to not have to make defensive copies!? Yes, the same thread that seeded the data into non-thread safe containers is the thread that passes those containers to the immutable wrapper.


I understand now that all I have to do is assign my argument containers to a final member references in the immutable wrapper.? And that if I do defensive copy, do it first, and assign to the final member references at the end.

What I don't understand is this: another thread picks up the reference and starts using the object.? In all of the above, there was never a volatile member involved to ensure that other threads picking up the reference see the data in the containers.? Say I do this: new SomeThread(immutableReference).start().? This is the beginning of the second thread.? What is it about the final references in the immutable wrapper that causes SomeThread to "see" that data that Thread A seeded in ArrayList/HashMap and then wrapped in immutable wrapper, especially if there was no defensive copy?

Once I understand this, then I'll understand the workings of String, which clearly have no volatile members.? Strings assume that the thread which seeded the char[] is the thread that constructs the String, and somehow without any use of volatile, other threads that pick up the reference to the constructed String "see" the data in the defensively copyied char[].? "final" appears to solve reordering problems within the thread, but how does it "publish" data?



________________________________
 From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 8:45 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 
I think there are two streams of thought here that are getting crossed.

First, I agree with Vitaly that it's still unclear if you have
multi-threading going on at all.? In the example you provide, is the
EffectivelyImmutableArrayListWrapper used across multiple threads?? If
it's not, than there's no need for really any modifier.? For a single
thread, you never have to worry about reordering.? It might likely
happen, but you are guaranteed that, going by program order,
operations which happen 'before' will be done prior to their use.? So
if the Wrapper is constructed and used within a single thread, you
don't need volatile, or final, or even to create a copy at all if the
'list' arg is never going to be modified subsequent to wrapping.

Second, based on the snipped below, if you *do* have multiple threads,
which surely you must?? then the areas for concern would be how the
'list'
 arg is passed in (i.e., is it getting populated in another
thread?) and then how the Wrapper is used after construction.? So
let's address those:

the list arg that you are passing in:? if it comes from the same
thread, you're in the single thread situation and
concurrency/reordering isn't an issue *up to the point of calling the
constructor*.? However, if you are populating the list in a different
thread before passing in, you need to make sure you pass/populate the
list in a thread safe fashion.? Otherwise, writes from the populating
thread might not have been done in the list when the Wrapper
constructing thread does its thing.

use of the wrapper:? if the wrapper will be used in the same thread it
was constructed in, then you're in the single thread scenario.? If it
will be used by multiple threads, then you have to worry about how you
construct it.? If the list arg
 you are passing in is not referenced by
any other threads and isn't going to be updated anywhere else, you
don't need to create a deep copy.? You can simply assign it to a final
variable, and you are good to go.? String(char[]) creates a defensive
copy to *guarantee* that the contents won't change (it doesn't trust
that you'll behave and drop your reference to the char[] you pass in).
But creating a defensive copy is only necessary if you don't have
control over who might invoke the constructor.? If you are going to
create a defensive copy, your best bet would be to create the copy,
then assign the fully populated copy to a final variable.? Assigning
an empty copy to a volatile variable and then populating it doesn't
work.? The volatile only applies to that reference, not to the
references maintained inside the list itself.? You could create a
fully populated copy and then assign to a
 volatile variable, but if
you don't plan to change that reference, final would be a much better
option.

Does that help?

jacy


On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> For clarification, lets say a caller passes my constructor an ArrayList with
> seeded values.
>
> class EffectivelyImmutableArrayListWrapper {
>? ?  private volatile ArrayList? mylist;
>? ?  EffectivelyImmutableArrayListWrapper (ArrayList list)
>? ?  {
>? ? ? ? ?  // .... create mylist and copy all values from list into mylist
>? ? ? ? ?  // this class only provides getters for mylist
>? ? ? ? ?  // mylist never changes except in this constructor where created
> and
 filled
>? ?  }
>
>? ?  // getter functions for mylist
> }
>
> From the above snippet, we see that we are attempting to provide a
> publishing wrapper/snapshot for an ArrayList.? Is "volatile" necessary here?
> I assume that "final" does not work, because "mylist" is just a reference.
> Also, what if the contract of the constructor was that the caller would
> never change/use the arraylist arg after calling the constructor: in that
> case, could the constructor just copy the arg reference to the volatile
> "mylist" member and be done?
>
> Assuming that I am correct that "mylist" has to be volatile, how does
> java.lang.String accomplish immutability of the private char[] without
> making it volatile?
>
> ________________________________
> From: Andy Nuss <andrew_nuss at yahoo.com>
> To: "concurrency-interest at cs.oswego.edu"
> <concurrency-interest at cs.oswego.edu>
> Sent: Wednesday, October 3, 2012 7:22 AM
>
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
> (It was a reply accident that I did not reply to list.)
>
> So if I follow you correctly, for a constructor that has an array or
> ArrayList member, creates that array/ArrayList, and fills it with a bunch of
> seeded values, which are effectively final: another thread will not see the
> values in the array/ArrayList unless the constructed object is "published"
> to
 the other thread, such as with a volatile variable or concurrent map.
>
> In that case, can someone explain to me how java String, which holds an
> array of characters, is threadsafe without the need for publishing the
> string to the other thread?? I.e. even if the array reference is final, the
> "final" attribute does not apply to the elements of the array.? Same with a
> final ArrayList reference.
>
> ________________________________
> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> To: Andy Nuss <andrew_nuss at yahoo.com>
> Sent: Wednesday, October 3, 2012 7:11 AM
> Subject: Re: [concurrency-interest] do constructors ever involve threading
> under the covers?
>
>
 Any specific reason you are not replying to the list? :)
>
> On 10/03/2012 06:04 PM, Andy Nuss wrote:
>> The reason I ask about the constructor is this: java memory model
>> provides a guarantee that all memory set/changed in the constructor is
>> immediately visible to any other thread (that receives a reference to
>> new object) after the constructor returns.? Is this true?
>
> Ughm, there is a requirement for the final field values of newly
> constructed objects set in constructor are visible after constructor
> finishes, and only in the case if you haven't leaked the reference to
> "this" in the constructor.
>
> There is no memory semantics for constructor invocation otherwise. I.e.:
>
> class A {
>?  private int myField;
>
>?  public int get() {
>? ? ?  // DOES NOT force $myField
 visibility
>? ? ?  return new A(myField).value;
>?  }
> }
>
> class B {
>?  int v;
>?  public B(int v) { value = v; }
> }
>
> Neither it would change if you make B.v final.
>
>> Is the contructor always executed in the same thread as its caller?
>
> Yes, it acts like ordinary method in this regard, no specific treatment.
>
> -Aleksey.
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/0bac7eed/attachment.html>

From stanimir at riflexo.com  Wed Oct  3 12:48:46 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Wed, 3 Oct 2012 19:48:46 +0300
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
	<1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
Message-ID: <CAEJX8opzAnKVAVydJ_1kz+5Yze72ZQVOxaF2VBcTapw3z5A8NQ@mail.gmail.com>

On Wed, Oct 3, 2012 at 7:28 PM, Andy Nuss <andrew_nuss at yahoo.com> wrote:

> A simple way of asking, if thread (that receives the immutable wrapper)
> runs on a different cpu, then without a memory fence, how does it "see" the
> data?  Do constructors hide a memory fence instruction under the covers?
>

on x86/sparc i.e. TSO, no hardware fence is required only a compilation one
(no reorder of the stores, although the compilers rarely reorder that
anyways). Other than that a store-store fence is required for the final
fields. If the c-tor has no final fields the compiler is free to reorder
the stores as it sees fit.

Stanimir



>   ------------------------------
> *From:* Andy Nuss <andrew_nuss at yahoo.com>
> *To:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 9:22 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> This does help.
>
> My model is this, and does involve multiple threads.  One thread creates
> and fills container data structure(s) that has no immutable guarantees,
> such as an ArrayList, HashMap, etc.  Then in that same thread, it calls a
> constructor to wrap the container, and give it an immutable api.  Then, the
> hope is that absolutely anyway that any other thread obtains a reference to
> the immutable wrapper, it will "see" all the data in the non-immutable
> containers.  Yes, I hope to not have to make defensive copies!  Yes, the
> same thread that seeded the data into non-thread safe containers is the
> thread that passes those containers to the immutable wrapper.
>
> I understand now that all I have to do is assign my argument containers to
> a final member references in the immutable wrapper.  And that if I do
> defensive copy, do it first, and assign to the final member references at
> the end.
>
> What I don't understand is this: another thread picks up the reference and
> starts using the object.  In all of the above, there was never a volatile
> member involved to ensure that other threads picking up the reference see
> the data in the containers.  Say I do this: new
> SomeThread(immutableReference).start().  This is the beginning of the
> second thread.  What is it about the final references in the immutable
> wrapper that causes SomeThread to "see" that data that Thread A seeded in
> ArrayList/HashMap and then wrapped in immutable wrapper, especially if
> there was no defensive copy?
>
> Once I understand this, then I'll understand the workings of String, which
> clearly have no volatile members.  Strings assume that the thread which
> seeded the char[] is the thread that constructs the String, and somehow
> without any use of volatile, other threads that pick up the reference to
> the constructed String "see" the data in the defensively copyied char[].
> "final" appears to solve reordering problems within the thread, but how
> does it "publish" data?
>
>   ------------------------------
> *From:* Jacy Odin Grannis <jacyg at alumni.rice.edu>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 8:45 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> I think there are two streams of thought here that are getting crossed.
>
> First, I agree with Vitaly that it's still unclear if you have
> multi-threading going on at all.  In the example you provide, is the
> EffectivelyImmutableArrayListWrapper used across multiple threads?  If
> it's not, than there's no need for really any modifier.  For a single
> thread, you never have to worry about reordering.  It might likely
> happen, but you are guaranteed that, going by program order,
> operations which happen 'before' will be done prior to their use.  So
> if the Wrapper is constructed and used within a single thread, you
> don't need volatile, or final, or even to create a copy at all if the
> 'list' arg is never going to be modified subsequent to wrapping.
>
> Second, based on the snipped below, if you *do* have multiple threads,
> which surely you must?  then the areas for concern would be how the
> 'list' arg is passed in (i.e., is it getting populated in another
> thread?) and then how the Wrapper is used after construction.  So
> let's address those:
>
> the list arg that you are passing in:  if it comes from the same
> thread, you're in the single thread situation and
> concurrency/reordering isn't an issue *up to the point of calling the
> constructor*.  However, if you are populating the list in a different
> thread before passing in, you need to make sure you pass/populate the
> list in a thread safe fashion.  Otherwise, writes from the populating
> thread might not have been done in the list when the Wrapper
> constructing thread does its thing.
>
> use of the wrapper:  if the wrapper will be used in the same thread it
> was constructed in, then you're in the single thread scenario.  If it
> will be used by multiple threads, then you have to worry about how you
> construct it.  If the list arg you are passing in is not referenced by
> any other threads and isn't going to be updated anywhere else, you
> don't need to create a deep copy.  You can simply assign it to a final
> variable, and you are good to go.  String(char[]) creates a defensive
> copy to *guarantee* that the contents won't change (it doesn't trust
> that you'll behave and drop your reference to the char[] you pass in).
> But creating a defensive copy is only necessary if you don't have
> control over who might invoke the constructor.  If you are going to
> create a defensive copy, your best bet would be to create the copy,
> then assign the fully populated copy to a final variable.  Assigning
> an empty copy to a volatile variable and then populating it doesn't
> work.  The volatile only applies to that reference, not to the
> references maintained inside the list itself.  You could create a
> fully populated copy and then assign to a volatile variable, but if
> you don't plan to change that reference, final would be a much better
> option.
>
> Does that help?
>
> jacy
>
>
> On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> > For clarification, lets say a caller passes my constructor an ArrayList
> with
> > seeded values.
> >
> > class EffectivelyImmutableArrayListWrapper {
> >    private volatile ArrayList  mylist;
> >    EffectivelyImmutableArrayListWrapper (ArrayList list)
> >    {
> >          // .... create mylist and copy all values from list into mylist
> >          // this class only provides getters for mylist
> >          // mylist never changes except in this constructor where created
> > and filled
> >    }
> >
> >    // getter functions for mylist
> > }
> >
> > From the above snippet, we see that we are attempting to provide a
> > publishing wrapper/snapshot for an ArrayList.  Is "volatile" necessary
> here?
> > I assume that "final" does not work, because "mylist" is just a
> reference.
> > Also, what if the contract of the constructor was that the caller would
> > never change/use the arraylist arg after calling the constructor: in that
> > case, could the constructor just copy the arg reference to the volatile
> > "mylist" member and be done?
> >
> > Assuming that I am correct that "mylist" has to be volatile, how does
> > java.lang.String accomplish immutability of the private char[] without
> > making it volatile?
> >
> > ________________________________
> > From: Andy Nuss <andrew_nuss at yahoo.com>
> > To: "concurrency-interest at cs.oswego.edu"
> > <concurrency-interest at cs.oswego.edu>
> > Sent: Wednesday, October 3, 2012 7:22 AM
> >
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > (It was a reply accident that I did not reply to list.)
> >
> > So if I follow you correctly, for a constructor that has an array or
> > ArrayList member, creates that array/ArrayList, and fills it with a
> bunch of
> > seeded values, which are effectively final: another thread will not see
> the
> > values in the array/ArrayList unless the constructed object is
> "published"
> > to the other thread, such as with a volatile variable or concurrent map.
> >
> > In that case, can someone explain to me how java String, which holds an
> > array of characters, is threadsafe without the need for publishing the
> > string to the other thread?  I.e. even if the array reference is final,
> the
> > "final" attribute does not apply to the elements of the array.  Same
> with a
> > final ArrayList reference.
> >
> > ________________________________
> > From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> > To: Andy Nuss <andrew_nuss at yahoo.com>
> > Sent: Wednesday, October 3, 2012 7:11 AM
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > Any specific reason you are not replying to the list? :)
> >
> > On 10/03/2012 06:04 PM, Andy Nuss wrote:
> >> The reason I ask about the constructor is this: java memory model
> >> provides a guarantee that all memory set/changed in the constructor is
> >> immediately visible to any other thread (that receives a reference to
> >> new object) after the constructor returns.  Is this true?
> >
> > Ughm, there is a requirement for the final field values of newly
> > constructed objects set in constructor are visible after constructor
> > finishes, and only in the case if you haven't leaked the reference to
> > "this" in the constructor.
> >
> > There is no memory semantics for constructor invocation otherwise. I.e.:
> >
> > class A {
> >  private int myField;
> >
> >  public int get() {
> >      // DOES NOT force $myField visibility
> >      return new A(myField).value;
> >  }
> > }
> >
> > class B {
> >  int v;
> >  public B(int v) { value = v; }
> > }
> >
> > Neither it would change if you make B.v final.
> >
> >> Is the contructor always executed in the same thread as its caller?
> >
> > Yes, it acts like ordinary method in this regard, no specific treatment.
> >
> > -Aleksey.
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/5fc94b79/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  3 12:59:00 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 12:59:00 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
	<1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
Message-ID: <CAHjP37FG=OB_SeV4CY8MD-TAJ0hiFvf8QPZTb34v=3BxnmkvKg@mail.gmail.com>

Calling Thread.start() ensures that the new thread sees all writes done by
the thread calling start() - this is documented/spec'd behavior.

However, I think what you're really asking is how final fields ensure
unsafe publishing works? Suppose you have two threads, W and R.  W
constructs some object with final fields and then stores this into a shared
static field.  R just spins doing the following:
Foo f = null;
while ((f = static_field) == null);
// f is not null here
int x = f.x; // some read of f

What final ensures is that if f is observed as not being null, then the
stores done inside the constructor are visible.

Let's leave theoretical pathology aside (e.g. it's a preemptive OS
scheduler, CPU store buffer drains at some point in time, etc).  In this
case, R will eventually read non-null as the write in W drains out of the
store buffer into L1 (assuming it was put into store buffer in the first
place).  At that point, normal cache coherency protocol takes care of R
seeing the writes - the question then is in what order were the writes made
visible by the CPU/core that W was running on.  On x86/64, the CPU does not
reorder stores - they are visible in execution order; this means we need to
ensure the compiler didn't move code around such that writes got
reordered.  On weaker memory models (e.g. arm, ppc) that do allow store
reordering, the jit has to not just avoid code motion but also emit
appropriate fence instructions.  This means on x86/64 final field store is
just a compiler fence - no CPU fence instructions needed.  On arm/ppc
though, fence instructions are needed.

Sent from my phone
On Oct 3, 2012 12:31 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> A simple way of asking, if thread (that receives the immutable wrapper)
> runs on a different cpu, then without a memory fence, how does it "see" the
> data?  Do constructors hide a memory fence instruction under the covers?
>
>   ------------------------------
> *From:* Andy Nuss <andrew_nuss at yahoo.com>
> *To:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 9:22 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> This does help.
>
> My model is this, and does involve multiple threads.  One thread creates
> and fills container data structure(s) that has no immutable guarantees,
> such as an ArrayList, HashMap, etc.  Then in that same thread, it calls a
> constructor to wrap the container, and give it an immutable api.  Then, the
> hope is that absolutely anyway that any other thread obtains a reference to
> the immutable wrapper, it will "see" all the data in the non-immutable
> containers.  Yes, I hope to not have to make defensive copies!  Yes, the
> same thread that seeded the data into non-thread safe containers is the
> thread that passes those containers to the immutable wrapper.
>
> I understand now that all I have to do is assign my argument containers to
> a final member references in the immutable wrapper.  And that if I do
> defensive copy, do it first, and assign to the final member references at
> the end.
>
> What I don't understand is this: another thread picks up the reference and
> starts using the object.  In all of the above, there was never a volatile
> member involved to ensure that other threads picking up the reference see
> the data in the containers.  Say I do this: new
> SomeThread(immutableReference).start().  This is the beginning of the
> second thread.  What is it about the final references in the immutable
> wrapper that causes SomeThread to "see" that data that Thread A seeded in
> ArrayList/HashMap and then wrapped in immutable wrapper, especially if
> there was no defensive copy?
>
> Once I understand this, then I'll understand the workings of String, which
> clearly have no volatile members.  Strings assume that the thread which
> seeded the char[] is the thread that constructs the String, and somehow
> without any use of volatile, other threads that pick up the reference to
> the constructed String "see" the data in the defensively copyied char[].
> "final" appears to solve reordering problems within the thread, but how
> does it "publish" data?
>
>   ------------------------------
> *From:* Jacy Odin Grannis <jacyg at alumni.rice.edu>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 8:45 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> I think there are two streams of thought here that are getting crossed.
>
> First, I agree with Vitaly that it's still unclear if you have
> multi-threading going on at all.  In the example you provide, is the
> EffectivelyImmutableArrayListWrapper used across multiple threads?  If
> it's not, than there's no need for really any modifier.  For a single
> thread, you never have to worry about reordering.  It might likely
> happen, but you are guaranteed that, going by program order,
> operations which happen 'before' will be done prior to their use.  So
> if the Wrapper is constructed and used within a single thread, you
> don't need volatile, or final, or even to create a copy at all if the
> 'list' arg is never going to be modified subsequent to wrapping.
>
> Second, based on the snipped below, if you *do* have multiple threads,
> which surely you must?  then the areas for concern would be how the
> 'list' arg is passed in (i.e., is it getting populated in another
> thread?) and then how the Wrapper is used after construction.  So
> let's address those:
>
> the list arg that you are passing in:  if it comes from the same
> thread, you're in the single thread situation and
> concurrency/reordering isn't an issue *up to the point of calling the
> constructor*.  However, if you are populating the list in a different
> thread before passing in, you need to make sure you pass/populate the
> list in a thread safe fashion.  Otherwise, writes from the populating
> thread might not have been done in the list when the Wrapper
> constructing thread does its thing.
>
> use of the wrapper:  if the wrapper will be used in the same thread it
> was constructed in, then you're in the single thread scenario.  If it
> will be used by multiple threads, then you have to worry about how you
> construct it.  If the list arg you are passing in is not referenced by
> any other threads and isn't going to be updated anywhere else, you
> don't need to create a deep copy.  You can simply assign it to a final
> variable, and you are good to go.  String(char[]) creates a defensive
> copy to *guarantee* that the contents won't change (it doesn't trust
> that you'll behave and drop your reference to the char[] you pass in).
> But creating a defensive copy is only necessary if you don't have
> control over who might invoke the constructor.  If you are going to
> create a defensive copy, your best bet would be to create the copy,
> then assign the fully populated copy to a final variable.  Assigning
> an empty copy to a volatile variable and then populating it doesn't
> work.  The volatile only applies to that reference, not to the
> references maintained inside the list itself.  You could create a
> fully populated copy and then assign to a volatile variable, but if
> you don't plan to change that reference, final would be a much better
> option.
>
> Does that help?
>
> jacy
>
>
> On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> > For clarification, lets say a caller passes my constructor an ArrayList
> with
> > seeded values.
> >
> > class EffectivelyImmutableArrayListWrapper {
> >    private volatile ArrayList  mylist;
> >    EffectivelyImmutableArrayListWrapper (ArrayList list)
> >    {
> >          // .... create mylist and copy all values from list into mylist
> >          // this class only provides getters for mylist
> >          // mylist never changes except in this constructor where created
> > and filled
> >    }
> >
> >    // getter functions for mylist
> > }
> >
> > From the above snippet, we see that we are attempting to provide a
> > publishing wrapper/snapshot for an ArrayList.  Is "volatile" necessary
> here?
> > I assume that "final" does not work, because "mylist" is just a
> reference.
> > Also, what if the contract of the constructor was that the caller would
> > never change/use the arraylist arg after calling the constructor: in that
> > case, could the constructor just copy the arg reference to the volatile
> > "mylist" member and be done?
> >
> > Assuming that I am correct that "mylist" has to be volatile, how does
> > java.lang.String accomplish immutability of the private char[] without
> > making it volatile?
> >
> > ________________________________
> > From: Andy Nuss <andrew_nuss at yahoo.com>
> > To: "concurrency-interest at cs.oswego.edu"
> > <concurrency-interest at cs.oswego.edu>
> > Sent: Wednesday, October 3, 2012 7:22 AM
> >
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > (It was a reply accident that I did not reply to list.)
> >
> > So if I follow you correctly, for a constructor that has an array or
> > ArrayList member, creates that array/ArrayList, and fills it with a
> bunch of
> > seeded values, which are effectively final: another thread will not see
> the
> > values in the array/ArrayList unless the constructed object is
> "published"
> > to the other thread, such as with a volatile variable or concurrent map.
> >
> > In that case, can someone explain to me how java String, which holds an
> > array of characters, is threadsafe without the need for publishing the
> > string to the other thread?  I.e. even if the array reference is final,
> the
> > "final" attribute does not apply to the elements of the array.  Same
> with a
> > final ArrayList reference.
> >
> > ________________________________
> > From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> > To: Andy Nuss <andrew_nuss at yahoo.com>
> > Sent: Wednesday, October 3, 2012 7:11 AM
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > Any specific reason you are not replying to the list? :)
> >
> > On 10/03/2012 06:04 PM, Andy Nuss wrote:
> >> The reason I ask about the constructor is this: java memory model
> >> provides a guarantee that all memory set/changed in the constructor is
> >> immediately visible to any other thread (that receives a reference to
> >> new object) after the constructor returns.  Is this true?
> >
> > Ughm, there is a requirement for the final field values of newly
> > constructed objects set in constructor are visible after constructor
> > finishes, and only in the case if you haven't leaked the reference to
> > "this" in the constructor.
> >
> > There is no memory semantics for constructor invocation otherwise. I.e.:
> >
> > class A {
> >  private int myField;
> >
> >  public int get() {
> >      // DOES NOT force $myField visibility
> >      return new A(myField).value;
> >  }
> > }
> >
> > class B {
> >  int v;
> >  public B(int v) { value = v; }
> > }
> >
> > Neither it would change if you make B.v final.
> >
> >> Is the contructor always executed in the same thread as its caller?
> >
> > Yes, it acts like ordinary method in this regard, no specific treatment.
> >
> > -Aleksey.
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/087b67b3/attachment-0001.html>

From zhong.j.yu at gmail.com  Wed Oct  3 13:32:00 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 12:32:00 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
Message-ID: <CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>

We may say `final` is stronger than `volatile`, it has all the
semantics of `volatile', and more.

`volatile` is not strong enough to build thread-safe immutable
objects, `final` is.

On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> Hi,
>
> I have a class with a single member, a reference to a new MessageDigest
> obtained in the constructor based on the algorithm name passed to the
> constructor.  The constructor also has a Reader argument and reads all the
> data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru to
> the digest with my own OutputStream filter.  The call to the constructor
> then accesses the MessageDigest member and calls digest() to get the
> resulting byte[].  My code by all appearances is single threaded, but I am
> having strange bugs that on one particular machine running vmware, the
> digest result I am getting (for password hashing) appears not to be
> repeatable.
>
> Basically, I am wondering if another thread can execute the body of the
> constructor (or in the construction and use of the OutputStreamWriter,
> within my constructor) that could be causing a bug where memory written by
> the MessageDigest.update() function (triggered within the constructor by
> writing thru OutputStreamWriter) is not seen in the call to digest() on the
> newly created MessageDigest member after the constructor returns.
>
> Andy
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From yshavit at akiban.com  Wed Oct  3 13:48:14 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Wed, 3 Oct 2012 13:48:14 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
Message-ID: <CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>

Is that true? I was under the impression that final only has memory
visibility implications for the final field itself, and anything gotten
from it. So for instance:

class Foo {
    int a;
    final boolean ctorDone;

    Foo() {
        a = 1;
        ctorDone = true;
    }

    void verify() {
        while (!ctorDone) { /* spin */ }
        assert a == 1 : a;
    }
}

My understanding is that (assuming unsafe publication and all that) the JMM
is allowed to have a == 0 in Foo.verify, because the memory visibility only
applies to ctorDone. If ctorDone were a volatile, then reading it would
ensure a full HB edge, and you'd be guaranteed to see a == 1.

On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> We may say `final` is stronger than `volatile`, it has all the
> semantics of `volatile', and more.
>
> `volatile` is not strong enough to build thread-safe immutable
> objects, `final` is.
>
> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> > Hi,
> >
> > I have a class with a single member, a reference to a new MessageDigest
> > obtained in the constructor based on the algorithm name passed to the
> > constructor.  The constructor also has a Reader argument and reads all
> the
> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru
> to
> > the digest with my own OutputStream filter.  The call to the constructor
> > then accesses the MessageDigest member and calls digest() to get the
> > resulting byte[].  My code by all appearances is single threaded, but I
> am
> > having strange bugs that on one particular machine running vmware, the
> > digest result I am getting (for password hashing) appears not to be
> > repeatable.
> >
> > Basically, I am wondering if another thread can execute the body of the
> > constructor (or in the construction and use of the OutputStreamWriter,
> > within my constructor) that could be causing a bug where memory written
> by
> > the MessageDigest.update() function (triggered within the constructor by
> > writing thru OutputStreamWriter) is not seen in the call to digest() on
> the
> > newly created MessageDigest member after the constructor returns.
> >
> > Andy
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/018e4167/attachment.html>

From andrew_nuss at yahoo.com  Wed Oct  3 13:51:17 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 10:51:17 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <CAEJX8opzAnKVAVydJ_1kz+5Yze72ZQVOxaF2VBcTapw3z5A8NQ@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
	<1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<CAEJX8opzAnKVAVydJ_1kz+5Yze72ZQVOxaF2VBcTapw3z5A8NQ@mail.gmail.com>
Message-ID: <1349286677.6309.YahooMailNeo@web120301.mail.ne1.yahoo.com>

I am definitely fanatically pro-Oracle/Java.? However, just curious, what does the Android vm do to adhere to the JMM?



________________________________
 From: Stanimir Simeonoff <stanimir at riflexo.com>
To: Andy Nuss <andrew_nuss at yahoo.com> 
Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
Sent: Wednesday, October 3, 2012 9:48 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 




On Wed, Oct 3, 2012 at 7:28 PM, Andy Nuss <andrew_nuss at yahoo.com> wrote:

A simple way of asking, if thread (that receives the immutable wrapper) runs on a different cpu, then without a memory fence, how does it "see" the data?? Do constructors hide a memory fence instruction under the covers?
>

on x86/sparc i.e. TSO, no hardware fence is required only a compilation one (no reorder of the stores, although the compilers rarely reorder that anyways). Other than that a store-store fence is required for the final fields. If the c-tor has no final fields the compiler is free to reorder the stores as it sees fit.

Stanimir 


?

>________________________________
> From: Andy Nuss <andrew_nuss at yahoo.com>
>To: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
>Sent: Wednesday, October 3, 2012 9:22 AM
>Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
> 
>
>This does help.
>
>
>My model is this, and does involve multiple threads.? One thread creates and fills container data structure(s) that has no immutable guarantees, such as an ArrayList, HashMap, etc.? Then in that same thread, it calls a constructor to wrap the container, and give it an immutable api.? Then, the hope is that absolutely anyway that any other thread obtains a reference to the immutable wrapper, it will "see" all the data in the non-immutable containers.? Yes, I hope to not have to make defensive copies!? Yes, the same thread that seeded the data into non-thread safe containers is the thread that passes those containers to the immutable wrapper.
>
>
>
>I understand now that all I have to do is assign my argument containers to a final member references in the immutable wrapper.? And that if I do defensive copy, do it first, and assign to the final member references at the end.
>
>
>What I don't understand is this: another thread picks up the reference and starts using the object.? In all of the above, there was never a volatile member involved to ensure that other threads picking up the reference see the data in the containers.? Say I do this: new SomeThread(immutableReference).start().? This is the beginning of the second thread.? What is it about the final references in the immutable wrapper that causes SomeThread to "see" that data that Thread A seeded in ArrayList/HashMap and then wrapped in immutable wrapper, especially if there was no defensive copy?
>
>
>Once I understand this, then I'll understand the workings of String, which clearly have no volatile members.? Strings assume that the thread which seeded the char[] is the thread that constructs the String, and somehow without any use of volatile, other threads that pick up the reference to the constructed String "see" the data in the defensively copyied char[].? "final" appears to solve reordering problems within the thread, but how does it "publish" data?
>
>
>
>
>________________________________
> From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
>To: Andy Nuss <andrew_nuss at yahoo.com> 
>Cc: "concurrency-interest at cs.oswego.edu" <concurrency-interest at cs.oswego.edu> 
>Sent: Wednesday, October 3, 2012 8:45 AM
>Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
> 
>I think there are two streams of thought here that are getting crossed.
>
>First, I agree with Vitaly that it's still unclear if you have
>multi-threading going on at all.? In the example you provide, is the
>EffectivelyImmutableArrayListWrapper used across multiple threads?? If
>it's not, than there's no need for really any modifier.? For a single
>thread, you never have to worry about reordering.? It might likely
>happen, but you are guaranteed that, going by program order,
>operations which happen 'before' will be done prior to their use.? So
>if the Wrapper is constructed and used within a single thread, you
>don't need volatile, or final, or even to create a copy at all if the
>'list' arg is never going to be modified subsequent to wrapping.
>
>Second, based on the snipped below, if you *do* have multiple threads,
>which surely you must?? then the areas for concern would be how the
>'list'
 arg is passed in (i.e., is it getting populated in another
>thread?) and then how the Wrapper is used after construction.? So
>let's address those:
>
>the list arg that you are passing in:? if it comes from the same
>thread, you're in the single thread situation and
>concurrency/reordering isn't an issue *up to the point of calling the
>constructor*.? However, if you are populating the list in a different
>thread before passing in, you need to make sure you pass/populate the
>list in a thread safe fashion.? Otherwise, writes from the populating
>thread might not have been done in the list when the Wrapper
>constructing thread does its thing.
>
>use of the wrapper:? if the wrapper will be used in the same thread it
>was constructed in, then you're in the single thread scenario.? If it
>will be used by multiple threads, then you have to worry about how you
>construct it.? If the list arg
 you are passing in is not referenced by
>any other threads and isn't going to be updated anywhere else, you
>don't need to create a deep copy.? You can simply assign it to a final
>variable, and you are good to go.? String(char[]) creates a defensive
>copy to *guarantee* that the contents won't change (it doesn't trust
>that you'll behave and drop your reference to the char[] you pass in).
>But creating a defensive copy is only necessary if you don't have
>control over who might invoke the constructor.? If you are going to
>create a defensive copy, your best bet would be to create the copy,
>then assign the fully populated copy to a final variable.? Assigning
>an empty copy to a volatile variable and then populating it doesn't
>work.? The volatile only applies to that reference, not to the
>references maintained inside the list itself.? You could create a
>fully populated copy and then assign to a
 volatile variable, but if
>you don't plan to change that reference, final would be a much better
>option.
>
>Does that help?
>
>jacy
>
>
>On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>> For clarification, lets say a caller passes my constructor an ArrayList with
>> seeded values.
>>
>> class EffectivelyImmutableArrayListWrapper {
>>? ?  private volatile ArrayList? mylist;
>>? ?  EffectivelyImmutableArrayListWrapper (ArrayList list)
>>? ?  {
>>? ? ? ? ?  // .... create mylist and copy all values from list into mylist
>>? ? ? ? ?  // this class only provides getters for mylist
>>? ? ? ? ?  // mylist never changes except in this
 constructor where created
>> and
 filled
>>? ?  }
>>
>>? ?  // getter functions for mylist
>> }
>>
>> From the above snippet, we see that we are attempting to provide a
>> publishing wrapper/snapshot for an ArrayList.? Is "volatile" necessary here?
>> I assume that "final" does not work, because "mylist" is just a reference.
>> Also, what if the contract of the constructor was that the caller would
>> never change/use the arraylist arg after calling the constructor: in that
>> case, could the constructor just copy the arg reference to the volatile
>> "mylist" member and be done?
>>
>> Assuming that I am correct that "mylist" has to be volatile, how does
>> java.lang.String accomplish immutability of the private char[] without
>> making it volatile?
>>
>> ________________________________
>> From: Andy Nuss <andrew_nuss at yahoo.com>
>> To: "concurrency-interest at cs.oswego.edu"
>> <concurrency-interest at cs.oswego.edu>
>> Sent: Wednesday, October 3, 2012 7:22 AM
>>
>> Subject: Re: [concurrency-interest] do constructors ever involve threading
>> under the covers?
>>
>> (It was a reply accident that I did not reply to list.)
>>
>> So if I follow you correctly, for a constructor that has an array or
>> ArrayList member, creates that array/ArrayList, and fills it with a bunch of
>> seeded values, which are effectively final: another thread will not see the
>> values
 in the array/ArrayList unless the constructed object is "published"
>> to
 the other thread, such as with a volatile variable or concurrent map.
>>
>> In that case, can someone explain to me how java String, which holds an
>> array of characters, is threadsafe without the need for publishing the
>> string to the other thread?? I.e. even if the array reference is final, the
>> "final" attribute does not apply to the elements of the array.? Same with a
>> final ArrayList reference.
>>
>> ________________________________
>> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
>> To: Andy Nuss <andrew_nuss at yahoo.com>
>> Sent: Wednesday, October 3, 2012 7:11 AM
>> Subject: Re: [concurrency-interest] do constructors
 ever involve threading
>> under the covers?
>>
>>
 Any specific reason you are not replying to the list? :)
>>
>> On 10/03/2012 06:04 PM, Andy Nuss wrote:
>>> The reason I ask about the constructor is this: java memory model
>>> provides a guarantee that all memory set/changed in the constructor is
>>> immediately visible to any other thread (that receives a reference to
>>> new object) after the constructor returns.? Is this true?
>>
>> Ughm, there is a requirement for the final field values of newly
>> constructed objects set in constructor are visible after constructor
>> finishes, and only in the case if you haven't leaked the reference to
>> "this" in the constructor.
>>
>> There is no memory semantics for constructor invocation otherwise. I.e.:
>>
>> class A {
>>?  private int myField;
>>
>>?  public int get() {
>>? ? ?  // DOES NOT force $myField
 visibility
>>? ? ?  return new A(myField).value;
>>?  }
>> }
>>
>> class B {
>>?  int v;
>>?  public B(int v) { value = v; }
>> }
>>
>> Neither it would change if you make B.v final.
>>
>>> Is the contructor always executed in the same thread as its caller?
>>
>> Yes, it acts like ordinary method in this regard, no specific treatment.
>>
>> -Aleksey.
>>
>>
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
>
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/d6a95f4b/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  3 14:25:51 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 14:25:51 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349286677.6309.YahooMailNeo@web120301.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<506C4207.5020907@oracle.com>
	<1349273043.52962.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506C47AA.5070906@oracle.com>
	<1349274175.66542.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<1349275034.4362.YahooMailNeo@web120306.mail.ne1.yahoo.com>
	<CAESiqEppa_7zB+TUTjh32OUUOh8Ud8axMvBsZ4Cw9DdtUW5cLA@mail.gmail.com>
	<1349281377.39514.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<1349281732.51549.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<CAEJX8opzAnKVAVydJ_1kz+5Yze72ZQVOxaF2VBcTapw3z5A8NQ@mail.gmail.com>
	<1349286677.6309.YahooMailNeo@web120301.mail.ne1.yahoo.com>
Message-ID: <CAHjP37GHqScC6G0mAX0HXWGzQpDSh3xPmhDAs=x9k8Qtz22UHQ@mail.gmail.com>

I would expect that they fully adhere, modulo any bugs, to the JMM.  In
that regard, they'd have to do the same thing as other JVMs in terms of (a)
preventing compiler code motion and (b) emitting appropriate architectural
fences, where required.

Sent from my phone
On Oct 3, 2012 1:54 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> I am definitely fanatically pro-Oracle/Java.  However, just curious, what
> does the Android vm do to adhere to the JMM?
>
>   ------------------------------
> *From:* Stanimir Simeonoff <stanimir at riflexo.com>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 9:48 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
>
>
> On Wed, Oct 3, 2012 at 7:28 PM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>
> A simple way of asking, if thread (that receives the immutable wrapper)
> runs on a different cpu, then without a memory fence, how does it "see" the
> data?  Do constructors hide a memory fence instruction under the covers?
>
>
> on x86/sparc i.e. TSO, no hardware fence is required only a compilation
> one (no reorder of the stores, although the compilers rarely reorder that
> anyways). Other than that a store-store fence is required for the final
> fields. If the c-tor has no final fields the compiler is free to reorder
> the stores as it sees fit.
>
> Stanimir
>
>
>
>    ------------------------------
> *From:* Andy Nuss <andrew_nuss at yahoo.com>
> *To:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 9:22 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> This does help.
>
> My model is this, and does involve multiple threads.  One thread creates
> and fills container data structure(s) that has no immutable guarantees,
> such as an ArrayList, HashMap, etc.  Then in that same thread, it calls a
> constructor to wrap the container, and give it an immutable api.  Then, the
> hope is that absolutely anyway that any other thread obtains a reference to
> the immutable wrapper, it will "see" all the data in the non-immutable
> containers.  Yes, I hope to not have to make defensive copies!  Yes, the
> same thread that seeded the data into non-thread safe containers is the
> thread that passes those containers to the immutable wrapper.
>
> I understand now that all I have to do is assign my argument containers to
> a final member references in the immutable wrapper.  And that if I do
> defensive copy, do it first, and assign to the final member references at
> the end.
>
> What I don't understand is this: another thread picks up the reference and
> starts using the object.  In all of the above, there was never a volatile
> member involved to ensure that other threads picking up the reference see
> the data in the containers.  Say I do this: new
> SomeThread(immutableReference).start().  This is the beginning of the
> second thread.  What is it about the final references in the immutable
> wrapper that causes SomeThread to "see" that data that Thread A seeded in
> ArrayList/HashMap and then wrapped in immutable wrapper, especially if
> there was no defensive copy?
>
> Once I understand this, then I'll understand the workings of String, which
> clearly have no volatile members.  Strings assume that the thread which
> seeded the char[] is the thread that constructs the String, and somehow
> without any use of volatile, other threads that pick up the reference to
> the constructed String "see" the data in the defensively copyied char[].
> "final" appears to solve reordering problems within the thread, but how
> does it "publish" data?
>
>   ------------------------------
> *From:* Jacy Odin Grannis <jacyg at alumni.rice.edu>
> *To:* Andy Nuss <andrew_nuss at yahoo.com>
> *Cc:* "concurrency-interest at cs.oswego.edu" <
> concurrency-interest at cs.oswego.edu>
> *Sent:* Wednesday, October 3, 2012 8:45 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> I think there are two streams of thought here that are getting crossed.
>
> First, I agree with Vitaly that it's still unclear if you have
> multi-threading going on at all.  In the example you provide, is the
> EffectivelyImmutableArrayListWrapper used across multiple threads?  If
> it's not, than there's no need for really any modifier.  For a single
> thread, you never have to worry about reordering.  It might likely
> happen, but you are guaranteed that, going by program order,
> operations which happen 'before' will be done prior to their use.  So
> if the Wrapper is constructed and used within a single thread, you
> don't need volatile, or final, or even to create a copy at all if the
> 'list' arg is never going to be modified subsequent to wrapping.
>
> Second, based on the snipped below, if you *do* have multiple threads,
> which surely you must?  then the areas for concern would be how the
> 'list' arg is passed in (i.e., is it getting populated in another
> thread?) and then how the Wrapper is used after construction.  So
> let's address those:
>
> the list arg that you are passing in:  if it comes from the same
> thread, you're in the single thread situation and
> concurrency/reordering isn't an issue *up to the point of calling the
> constructor*.  However, if you are populating the list in a different
> thread before passing in, you need to make sure you pass/populate the
> list in a thread safe fashion.  Otherwise, writes from the populating
> thread might not have been done in the list when the Wrapper
> constructing thread does its thing.
>
> use of the wrapper:  if the wrapper will be used in the same thread it
> was constructed in, then you're in the single thread scenario.  If it
> will be used by multiple threads, then you have to worry about how you
> construct it.  If the list arg you are passing in is not referenced by
> any other threads and isn't going to be updated anywhere else, you
> don't need to create a deep copy.  You can simply assign it to a final
> variable, and you are good to go.  String(char[]) creates a defensive
> copy to *guarantee* that the contents won't change (it doesn't trust
> that you'll behave and drop your reference to the char[] you pass in).
> But creating a defensive copy is only necessary if you don't have
> control over who might invoke the constructor.  If you are going to
> create a defensive copy, your best bet would be to create the copy,
> then assign the fully populated copy to a final variable.  Assigning
> an empty copy to a volatile variable and then populating it doesn't
> work.  The volatile only applies to that reference, not to the
> references maintained inside the list itself.  You could create a
> fully populated copy and then assign to a volatile variable, but if
> you don't plan to change that reference, final would be a much better
> option.
>
> Does that help?
>
> jacy
>
>
> On Wed, Oct 3, 2012 at 9:37 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> > For clarification, lets say a caller passes my constructor an ArrayList
> with
> > seeded values.
> >
> > class EffectivelyImmutableArrayListWrapper {
> >    private volatile ArrayList  mylist;
> >    EffectivelyImmutableArrayListWrapper (ArrayList list)
> >    {
> >          // .... create mylist and copy all values from list into mylist
> >          // this class only provides getters for mylist
> >          // mylist never changes except in this constructor where created
> > and filled
> >    }
> >
> >    // getter functions for mylist
> > }
> >
> > From the above snippet, we see that we are attempting to provide a
> > publishing wrapper/snapshot for an ArrayList.  Is "volatile" necessary
> here?
> > I assume that "final" does not work, because "mylist" is just a
> reference.
> > Also, what if the contract of the constructor was that the caller would
> > never change/use the arraylist arg after calling the constructor: in that
> > case, could the constructor just copy the arg reference to the volatile
> > "mylist" member and be done?
> >
> > Assuming that I am correct that "mylist" has to be volatile, how does
> > java.lang.String accomplish immutability of the private char[] without
> > making it volatile?
> >
> > ________________________________
> > From: Andy Nuss <andrew_nuss at yahoo.com>
> > To: "concurrency-interest at cs.oswego.edu"
> > <concurrency-interest at cs.oswego.edu>
> > Sent: Wednesday, October 3, 2012 7:22 AM
> >
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > (It was a reply accident that I did not reply to list.)
> >
> > So if I follow you correctly, for a constructor that has an array or
> > ArrayList member, creates that array/ArrayList, and fills it with a
> bunch of
> > seeded values, which are effectively final: another thread will not see
> the
> > values in the array/ArrayList unless the constructed object is
> "published"
> > to the other thread, such as with a volatile variable or concurrent map.
> >
> > In that case, can someone explain to me how java String, which holds an
> > array of characters, is threadsafe without the need for publishing the
> > string to the other thread?  I.e. even if the array reference is final,
> the
> > "final" attribute does not apply to the elements of the array.  Same
> with a
> > final ArrayList reference.
> >
> > ________________________________
> > From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> > To: Andy Nuss <andrew_nuss at yahoo.com>
> > Sent: Wednesday, October 3, 2012 7:11 AM
> > Subject: Re: [concurrency-interest] do constructors ever involve
> threading
> > under the covers?
> >
> > Any specific reason you are not replying to the list? :)
> >
> > On 10/03/2012 06:04 PM, Andy Nuss wrote:
> >> The reason I ask about the constructor is this: java memory model
> >> provides a guarantee that all memory set/changed in the constructor is
> >> immediately visible to any other thread (that receives a reference to
> >> new object) after the constructor returns.  Is this true?
> >
> > Ughm, there is a requirement for the final field values of newly
> > constructed objects set in constructor are visible after constructor
> > finishes, and only in the case if you haven't leaked the reference to
> > "this" in the constructor.
> >
> > There is no memory semantics for constructor invocation otherwise. I.e.:
> >
> > class A {
> >  private int myField;
> >
> >  public int get() {
> >      // DOES NOT force $myField visibility
> >      return new A(myField).value;
> >  }
> > }
> >
> > class B {
> >  int v;
> >  public B(int v) { value = v; }
> > }
> >
> > Neither it would change if you make B.v final.
> >
> >> Is the contructor always executed in the same thread as its caller?
> >
> > Yes, it acts like ordinary method in this regard, no specific treatment.
> >
> > -Aleksey.
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/788e352b/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  3 14:44:15 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 14:44:15 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
Message-ID: <CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>

Final is stronger than volatile in terms of store operations inside ctor
and subsequent assignment to the ref, which happens to enable the racy
publication that still works; volatile wouldn't work.

As for your example, it's not allowed.  In order for another thread to call
verify(), they must have seen a non-null reference.  We also know that
final assignment prevents reordering of ctor body with assignment to shared
ref.  I think I agree with Aleksey in that any final assignment in the ctor
prevents the reordering.  Therefore, if thread sees non-null ref to call
verify() on, it cannot see a == 0.

Sent from my phone
On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> Is that true? I was under the impression that final only has memory
> visibility implications for the final field itself, and anything gotten
> from it. So for instance:
>
> class Foo {
>     int a;
>     final boolean ctorDone;
>
>     Foo() {
>         a = 1;
>         ctorDone = true;
>     }
>
>     void verify() {
>         while (!ctorDone) { /* spin */ }
>         assert a == 1 : a;
>     }
> }
>
> My understanding is that (assuming unsafe publication and all that) the
> JMM is allowed to have a == 0 in Foo.verify, because the memory visibility
> only applies to ctorDone. If ctorDone were a volatile, then reading it
> would ensure a full HB edge, and you'd be guaranteed to see a == 1.
>
> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>
>> We may say `final` is stronger than `volatile`, it has all the
>> semantics of `volatile', and more.
>>
>> `volatile` is not strong enough to build thread-safe immutable
>> objects, `final` is.
>>
>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>> > Hi,
>> >
>> > I have a class with a single member, a reference to a new MessageDigest
>> > obtained in the constructor based on the algorithm name passed to the
>> > constructor.  The constructor also has a Reader argument and reads all
>> the
>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru
>> to
>> > the digest with my own OutputStream filter.  The call to the constructor
>> > then accesses the MessageDigest member and calls digest() to get the
>> > resulting byte[].  My code by all appearances is single threaded, but I
>> am
>> > having strange bugs that on one particular machine running vmware, the
>> > digest result I am getting (for password hashing) appears not to be
>> > repeatable.
>> >
>> > Basically, I am wondering if another thread can execute the body of the
>> > constructor (or in the construction and use of the OutputStreamWriter,
>> > within my constructor) that could be causing a bug where memory written
>> by
>> > the MessageDigest.update() function (triggered within the constructor by
>> > writing thru OutputStreamWriter) is not seen in the call to digest() on
>> the
>> > newly created MessageDigest member after the constructor returns.
>> >
>> > Andy
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/5e2e48db/attachment.html>

From zhong.j.yu at gmail.com  Wed Oct  3 14:44:39 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 13:44:39 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
Message-ID: <CACuKZqGDG0+71nhf00ZAGQ0ioKBKmV_GK3=KCF9BKaHrELPGaw@mail.gmail.com>

You are right, it only applies to the final field itself and fields
referenced through the final field. Especially when the final field is
of a primitive type, compiler has no difficulty move actions before
the write to the field field to a much later place.

On Wed, Oct 3, 2012 at 12:48 PM, Yuval Shavit <yshavit at akiban.com> wrote:
> Is that true? I was under the impression that final only has memory
> visibility implications for the final field itself, and anything gotten from
> it. So for instance:
>
> class Foo {
>     int a;
>     final boolean ctorDone;
>
>     Foo() {
>         a = 1;
>         ctorDone = true;
>     }
>
>     void verify() {
>         while (!ctorDone) { /* spin */ }
>         assert a == 1 : a;
>     }
> }
>
> My understanding is that (assuming unsafe publication and all that) the JMM
> is allowed to have a == 0 in Foo.verify, because the memory visibility only
> applies to ctorDone. If ctorDone were a volatile, then reading it would
> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>
>
> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>
>> We may say `final` is stronger than `volatile`, it has all the
>> semantics of `volatile', and more.
>>
>> `volatile` is not strong enough to build thread-safe immutable
>> objects, `final` is.
>>
>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>> > Hi,
>> >
>> > I have a class with a single member, a reference to a new MessageDigest
>> > obtained in the constructor based on the algorithm name passed to the
>> > constructor.  The constructor also has a Reader argument and reads all
>> > the
>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru
>> > to
>> > the digest with my own OutputStream filter.  The call to the constructor
>> > then accesses the MessageDigest member and calls digest() to get the
>> > resulting byte[].  My code by all appearances is single threaded, but I
>> > am
>> > having strange bugs that on one particular machine running vmware, the
>> > digest result I am getting (for password hashing) appears not to be
>> > repeatable.
>> >
>> > Basically, I am wondering if another thread can execute the body of the
>> > constructor (or in the construction and use of the OutputStreamWriter,
>> > within my constructor) that could be causing a bug where memory written
>> > by
>> > the MessageDigest.update() function (triggered within the constructor by
>> > writing thru OutputStreamWriter) is not seen in the call to digest() on
>> > the
>> > newly created MessageDigest member after the constructor returns.
>> >
>> > Andy
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From zhong.j.yu at gmail.com  Wed Oct  3 14:52:49 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 13:52:49 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
Message-ID: <CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>

On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> Final is stronger than volatile in terms of store operations inside ctor and
> subsequent assignment to the ref, which happens to enable the racy
> publication that still works; volatile wouldn't work.
>
> As for your example, it's not allowed.  In order for another thread to call
> verify(), they must have seen a non-null reference.  We also know that final
> assignment prevents reordering of ctor body with assignment to shared ref.

If the compiler can prove that a write in ctor is to a location that
cannot be referenced through the final field, then the write can be
reordered, even after the write to shared ref.

Such proof is probably difficult; unless the field is primitive.

> I think I agree with Aleksey in that any final assignment in the ctor
> prevents the reordering.  Therefore, if thread sees non-null ref to call
> verify() on, it cannot see a == 0.
>
> Sent from my phone
>
> On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>
>> Is that true? I was under the impression that final only has memory
>> visibility implications for the final field itself, and anything gotten from
>> it. So for instance:
>>
>> class Foo {
>>     int a;
>>     final boolean ctorDone;
>>
>>     Foo() {
>>         a = 1;
>>         ctorDone = true;
>>     }
>>
>>     void verify() {
>>         while (!ctorDone) { /* spin */ }
>>         assert a == 1 : a;
>>     }
>> }
>>
>> My understanding is that (assuming unsafe publication and all that) the
>> JMM is allowed to have a == 0 in Foo.verify, because the memory visibility
>> only applies to ctorDone. If ctorDone were a volatile, then reading it would
>> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>>
>> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>
>>> We may say `final` is stronger than `volatile`, it has all the
>>> semantics of `volatile', and more.
>>>
>>> `volatile` is not strong enough to build thread-safe immutable
>>> objects, `final` is.
>>>
>>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>>> > Hi,
>>> >
>>> > I have a class with a single member, a reference to a new MessageDigest
>>> > obtained in the constructor based on the algorithm name passed to the
>>> > constructor.  The constructor also has a Reader argument and reads all
>>> > the
>>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru
>>> > to
>>> > the digest with my own OutputStream filter.  The call to the
>>> > constructor
>>> > then accesses the MessageDigest member and calls digest() to get the
>>> > resulting byte[].  My code by all appearances is single threaded, but I
>>> > am
>>> > having strange bugs that on one particular machine running vmware, the
>>> > digest result I am getting (for password hashing) appears not to be
>>> > repeatable.
>>> >
>>> > Basically, I am wondering if another thread can execute the body of the
>>> > constructor (or in the construction and use of the OutputStreamWriter,
>>> > within my constructor) that could be causing a bug where memory written
>>> > by
>>> > the MessageDigest.update() function (triggered within the constructor
>>> > by
>>> > writing thru OutputStreamWriter) is not seen in the call to digest() on
>>> > the
>>> > newly created MessageDigest member after the constructor returns.
>>> >
>>> > Andy
>>> >
>>> > _______________________________________________
>>> > Concurrency-interest mailing list
>>> > Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

From vitalyd at gmail.com  Wed Oct  3 14:58:44 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 14:58:44 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
Message-ID: <CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>

This depends on what exactly is the scope of a final field assignment, as
Aleksey and I have discussed here.  If the mere presence of a final
assignment in the ctor, irrespective of its order with other local
assignments, means there's a StoreStore barrier placed right before shared
ref assignment, then the whole body of the ctor is visible if the shared
ref is, and thus no such reordering can occur.

If StoreStore is placed right after the final assignment only, then it can.

Sent from my phone
On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
> > Final is stronger than volatile in terms of store operations inside ctor
> and
> > subsequent assignment to the ref, which happens to enable the racy
> > publication that still works; volatile wouldn't work.
> >
> > As for your example, it's not allowed.  In order for another thread to
> call
> > verify(), they must have seen a non-null reference.  We also know that
> final
> > assignment prevents reordering of ctor body with assignment to shared
> ref.
>
> If the compiler can prove that a write in ctor is to a location that
> cannot be referenced through the final field, then the write can be
> reordered, even after the write to shared ref.
>
> Such proof is probably difficult; unless the field is primitive.
>
> > I think I agree with Aleksey in that any final assignment in the ctor
> > prevents the reordering.  Therefore, if thread sees non-null ref to call
> > verify() on, it cannot see a == 0.
> >
> > Sent from my phone
> >
> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
> >>
> >> Is that true? I was under the impression that final only has memory
> >> visibility implications for the final field itself, and anything gotten
> from
> >> it. So for instance:
> >>
> >> class Foo {
> >>     int a;
> >>     final boolean ctorDone;
> >>
> >>     Foo() {
> >>         a = 1;
> >>         ctorDone = true;
> >>     }
> >>
> >>     void verify() {
> >>         while (!ctorDone) { /* spin */ }
> >>         assert a == 1 : a;
> >>     }
> >> }
> >>
> >> My understanding is that (assuming unsafe publication and all that) the
> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
> visibility
> >> only applies to ctorDone. If ctorDone were a volatile, then reading it
> would
> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
> >>
> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> >>>
> >>> We may say `final` is stronger than `volatile`, it has all the
> >>> semantics of `volatile', and more.
> >>>
> >>> `volatile` is not strong enough to build thread-safe immutable
> >>> objects, `final` is.
> >>>
> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com>
> wrote:
> >>> > Hi,
> >>> >
> >>> > I have a class with a single member, a reference to a new
> MessageDigest
> >>> > obtained in the constructor based on the algorithm name passed to the
> >>> > constructor.  The constructor also has a Reader argument and reads
> all
> >>> > the
> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes
> thru
> >>> > to
> >>> > the digest with my own OutputStream filter.  The call to the
> >>> > constructor
> >>> > then accesses the MessageDigest member and calls digest() to get the
> >>> > resulting byte[].  My code by all appearances is single threaded,
> but I
> >>> > am
> >>> > having strange bugs that on one particular machine running vmware,
> the
> >>> > digest result I am getting (for password hashing) appears not to be
> >>> > repeatable.
> >>> >
> >>> > Basically, I am wondering if another thread can execute the body of
> the
> >>> > constructor (or in the construction and use of the
> OutputStreamWriter,
> >>> > within my constructor) that could be causing a bug where memory
> written
> >>> > by
> >>> > the MessageDigest.update() function (triggered within the constructor
> >>> > by
> >>> > writing thru OutputStreamWriter) is not seen in the call to digest()
> on
> >>> > the
> >>> > newly created MessageDigest member after the constructor returns.
> >>> >
> >>> > Andy
> >>> >
> >>> > _______________________________________________
> >>> > Concurrency-interest mailing list
> >>> > Concurrency-interest at cs.oswego.edu
> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>> >
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/27b07e6e/attachment-0001.html>

From zhong.j.yu at gmail.com  Wed Oct  3 15:09:14 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 14:09:14 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
Message-ID: <CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>

I guess the spec is deliberately weakened, so that for example

    anInt = 1;
    anStr = new String(bytes);

no ordering constraint is imposed; the 1st write can be reordered
after the 2nd, passing the constructor with final field writes.

This seems unnecessarily sophisticated; too much for mortals.

On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> This depends on what exactly is the scope of a final field assignment, as
> Aleksey and I have discussed here.  If the mere presence of a final
> assignment in the ctor, irrespective of its order with other local
> assignments, means there's a StoreStore barrier placed right before shared
> ref assignment, then the whole body of the ctor is visible if the shared ref
> is, and thus no such reordering can occur.
>
> If StoreStore is placed right after the final assignment only, then it can.
>
> Sent from my phone
>
> On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>> > Final is stronger than volatile in terms of store operations inside ctor
>> > and
>> > subsequent assignment to the ref, which happens to enable the racy
>> > publication that still works; volatile wouldn't work.
>> >
>> > As for your example, it's not allowed.  In order for another thread to
>> > call
>> > verify(), they must have seen a non-null reference.  We also know that
>> > final
>> > assignment prevents reordering of ctor body with assignment to shared
>> > ref.
>>
>> If the compiler can prove that a write in ctor is to a location that
>> cannot be referenced through the final field, then the write can be
>> reordered, even after the write to shared ref.
>>
>> Such proof is probably difficult; unless the field is primitive.
>>
>> > I think I agree with Aleksey in that any final assignment in the ctor
>> > prevents the reordering.  Therefore, if thread sees non-null ref to call
>> > verify() on, it cannot see a == 0.
>> >
>> > Sent from my phone
>> >
>> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>> >>
>> >> Is that true? I was under the impression that final only has memory
>> >> visibility implications for the final field itself, and anything gotten
>> >> from
>> >> it. So for instance:
>> >>
>> >> class Foo {
>> >>     int a;
>> >>     final boolean ctorDone;
>> >>
>> >>     Foo() {
>> >>         a = 1;
>> >>         ctorDone = true;
>> >>     }
>> >>
>> >>     void verify() {
>> >>         while (!ctorDone) { /* spin */ }
>> >>         assert a == 1 : a;
>> >>     }
>> >> }
>> >>
>> >> My understanding is that (assuming unsafe publication and all that) the
>> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
>> >> visibility
>> >> only applies to ctorDone. If ctorDone were a volatile, then reading it
>> >> would
>> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>> >>
>> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> >>>
>> >>> We may say `final` is stronger than `volatile`, it has all the
>> >>> semantics of `volatile', and more.
>> >>>
>> >>> `volatile` is not strong enough to build thread-safe immutable
>> >>> objects, `final` is.
>> >>>
>> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com>
>> >>> wrote:
>> >>> > Hi,
>> >>> >
>> >>> > I have a class with a single member, a reference to a new
>> >>> > MessageDigest
>> >>> > obtained in the constructor based on the algorithm name passed to
>> >>> > the
>> >>> > constructor.  The constructor also has a Reader argument and reads
>> >>> > all
>> >>> > the
>> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes
>> >>> > thru
>> >>> > to
>> >>> > the digest with my own OutputStream filter.  The call to the
>> >>> > constructor
>> >>> > then accesses the MessageDigest member and calls digest() to get the
>> >>> > resulting byte[].  My code by all appearances is single threaded,
>> >>> > but I
>> >>> > am
>> >>> > having strange bugs that on one particular machine running vmware,
>> >>> > the
>> >>> > digest result I am getting (for password hashing) appears not to be
>> >>> > repeatable.
>> >>> >
>> >>> > Basically, I am wondering if another thread can execute the body of
>> >>> > the
>> >>> > constructor (or in the construction and use of the
>> >>> > OutputStreamWriter,
>> >>> > within my constructor) that could be causing a bug where memory
>> >>> > written
>> >>> > by
>> >>> > the MessageDigest.update() function (triggered within the
>> >>> > constructor
>> >>> > by
>> >>> > writing thru OutputStreamWriter) is not seen in the call to digest()
>> >>> > on
>> >>> > the
>> >>> > newly created MessageDigest member after the constructor returns.
>> >>> >
>> >>> > Andy
>> >>> >
>> >>> > _______________________________________________
>> >>> > Concurrency-interest mailing list
>> >>> > Concurrency-interest at cs.oswego.edu
>> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>> >
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >

From vitalyd at gmail.com  Wed Oct  3 15:14:21 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 15:14:21 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
	<CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
Message-ID: <CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>

Right, but that's a different matter since final assignment is specifically
the order between the final assignment in ctor and ref assignment rather
than other surrounding operations.

Sent from my phone
On Oct 3, 2012 3:09 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> I guess the spec is deliberately weakened, so that for example
>
>     anInt = 1;
>     anStr = new String(bytes);
>
> no ordering constraint is imposed; the 1st write can be reordered
> after the 2nd, passing the constructor with final field writes.
>
> This seems unnecessarily sophisticated; too much for mortals.
>
> On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
> > This depends on what exactly is the scope of a final field assignment, as
> > Aleksey and I have discussed here.  If the mere presence of a final
> > assignment in the ctor, irrespective of its order with other local
> > assignments, means there's a StoreStore barrier placed right before
> shared
> > ref assignment, then the whole body of the ctor is visible if the shared
> ref
> > is, and thus no such reordering can occur.
> >
> > If StoreStore is placed right after the final assignment only, then it
> can.
> >
> > Sent from my phone
> >
> > On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
> >>
> >> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com>
> >> wrote:
> >> > Final is stronger than volatile in terms of store operations inside
> ctor
> >> > and
> >> > subsequent assignment to the ref, which happens to enable the racy
> >> > publication that still works; volatile wouldn't work.
> >> >
> >> > As for your example, it's not allowed.  In order for another thread to
> >> > call
> >> > verify(), they must have seen a non-null reference.  We also know that
> >> > final
> >> > assignment prevents reordering of ctor body with assignment to shared
> >> > ref.
> >>
> >> If the compiler can prove that a write in ctor is to a location that
> >> cannot be referenced through the final field, then the write can be
> >> reordered, even after the write to shared ref.
> >>
> >> Such proof is probably difficult; unless the field is primitive.
> >>
> >> > I think I agree with Aleksey in that any final assignment in the ctor
> >> > prevents the reordering.  Therefore, if thread sees non-null ref to
> call
> >> > verify() on, it cannot see a == 0.
> >> >
> >> > Sent from my phone
> >> >
> >> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
> >> >>
> >> >> Is that true? I was under the impression that final only has memory
> >> >> visibility implications for the final field itself, and anything
> gotten
> >> >> from
> >> >> it. So for instance:
> >> >>
> >> >> class Foo {
> >> >>     int a;
> >> >>     final boolean ctorDone;
> >> >>
> >> >>     Foo() {
> >> >>         a = 1;
> >> >>         ctorDone = true;
> >> >>     }
> >> >>
> >> >>     void verify() {
> >> >>         while (!ctorDone) { /* spin */ }
> >> >>         assert a == 1 : a;
> >> >>     }
> >> >> }
> >> >>
> >> >> My understanding is that (assuming unsafe publication and all that)
> the
> >> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
> >> >> visibility
> >> >> only applies to ctorDone. If ctorDone were a volatile, then reading
> it
> >> >> would
> >> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
> >> >>
> >> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com>
> wrote:
> >> >>>
> >> >>> We may say `final` is stronger than `volatile`, it has all the
> >> >>> semantics of `volatile', and more.
> >> >>>
> >> >>> `volatile` is not strong enough to build thread-safe immutable
> >> >>> objects, `final` is.
> >> >>>
> >> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com>
> >> >>> wrote:
> >> >>> > Hi,
> >> >>> >
> >> >>> > I have a class with a single member, a reference to a new
> >> >>> > MessageDigest
> >> >>> > obtained in the constructor based on the algorithm name passed to
> >> >>> > the
> >> >>> > constructor.  The constructor also has a Reader argument and reads
> >> >>> > all
> >> >>> > the
> >> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes
> >> >>> > thru
> >> >>> > to
> >> >>> > the digest with my own OutputStream filter.  The call to the
> >> >>> > constructor
> >> >>> > then accesses the MessageDigest member and calls digest() to get
> the
> >> >>> > resulting byte[].  My code by all appearances is single threaded,
> >> >>> > but I
> >> >>> > am
> >> >>> > having strange bugs that on one particular machine running vmware,
> >> >>> > the
> >> >>> > digest result I am getting (for password hashing) appears not to
> be
> >> >>> > repeatable.
> >> >>> >
> >> >>> > Basically, I am wondering if another thread can execute the body
> of
> >> >>> > the
> >> >>> > constructor (or in the construction and use of the
> >> >>> > OutputStreamWriter,
> >> >>> > within my constructor) that could be causing a bug where memory
> >> >>> > written
> >> >>> > by
> >> >>> > the MessageDigest.update() function (triggered within the
> >> >>> > constructor
> >> >>> > by
> >> >>> > writing thru OutputStreamWriter) is not seen in the call to
> digest()
> >> >>> > on
> >> >>> > the
> >> >>> > newly created MessageDigest member after the constructor returns.
> >> >>> >
> >> >>> > Andy
> >> >>> >
> >> >>> > _______________________________________________
> >> >>> > Concurrency-interest mailing list
> >> >>> > Concurrency-interest at cs.oswego.edu
> >> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>> >
> >> >>> _______________________________________________
> >> >>> Concurrency-interest mailing list
> >> >>> Concurrency-interest at cs.oswego.edu
> >> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>
> >> >>
> >> >>
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>
> >> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/4878724c/attachment.html>

From yshavit at akiban.com  Wed Oct  3 15:27:21 2012
From: yshavit at akiban.com (Yuval Shavit)
Date: Wed, 3 Oct 2012 15:27:21 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
	<CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
	<CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
Message-ID: <CAC2Zdp2avUofS6DL32ZkmFkjdFONsD6gabZu9ngAh0Prok0sGw@mail.gmail.com>

 We may be talking at cross purposes. My example (and claim that the assert
could fail) was based purely on the JMM as described in the JLS, not on the
JVM spec (which I believe is stronger?).

On Wed, Oct 3, 2012 at 3:14 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Right, but that's a different matter since final assignment is
> specifically the order between the final assignment in ctor and ref
> assignment rather than other surrounding operations.
>
> Sent from my phone
> On Oct 3, 2012 3:09 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>
>> I guess the spec is deliberately weakened, so that for example
>>
>>     anInt = 1;
>>     anStr = new String(bytes);
>>
>> no ordering constraint is imposed; the 1st write can be reordered
>> after the 2nd, passing the constructor with final field writes.
>>
>> This seems unnecessarily sophisticated; too much for mortals.
>>
>> On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>> > This depends on what exactly is the scope of a final field assignment,
>> as
>> > Aleksey and I have discussed here.  If the mere presence of a final
>> > assignment in the ctor, irrespective of its order with other local
>> > assignments, means there's a StoreStore barrier placed right before
>> shared
>> > ref assignment, then the whole body of the ctor is visible if the
>> shared ref
>> > is, and thus no such reordering can occur.
>> >
>> > If StoreStore is placed right after the final assignment only, then it
>> can.
>> >
>> > Sent from my phone
>> >
>> > On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>> >>
>> >> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> >> wrote:
>> >> > Final is stronger than volatile in terms of store operations inside
>> ctor
>> >> > and
>> >> > subsequent assignment to the ref, which happens to enable the racy
>> >> > publication that still works; volatile wouldn't work.
>> >> >
>> >> > As for your example, it's not allowed.  In order for another thread
>> to
>> >> > call
>> >> > verify(), they must have seen a non-null reference.  We also know
>> that
>> >> > final
>> >> > assignment prevents reordering of ctor body with assignment to shared
>> >> > ref.
>> >>
>> >> If the compiler can prove that a write in ctor is to a location that
>> >> cannot be referenced through the final field, then the write can be
>> >> reordered, even after the write to shared ref.
>> >>
>> >> Such proof is probably difficult; unless the field is primitive.
>> >>
>> >> > I think I agree with Aleksey in that any final assignment in the ctor
>> >> > prevents the reordering.  Therefore, if thread sees non-null ref to
>> call
>> >> > verify() on, it cannot see a == 0.
>> >> >
>> >> > Sent from my phone
>> >> >
>> >> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>> >> >>
>> >> >> Is that true? I was under the impression that final only has memory
>> >> >> visibility implications for the final field itself, and anything
>> gotten
>> >> >> from
>> >> >> it. So for instance:
>> >> >>
>> >> >> class Foo {
>> >> >>     int a;
>> >> >>     final boolean ctorDone;
>> >> >>
>> >> >>     Foo() {
>> >> >>         a = 1;
>> >> >>         ctorDone = true;
>> >> >>     }
>> >> >>
>> >> >>     void verify() {
>> >> >>         while (!ctorDone) { /* spin */ }
>> >> >>         assert a == 1 : a;
>> >> >>     }
>> >> >> }
>> >> >>
>> >> >> My understanding is that (assuming unsafe publication and all that)
>> the
>> >> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
>> >> >> visibility
>> >> >> only applies to ctorDone. If ctorDone were a volatile, then reading
>> it
>> >> >> would
>> >> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>> >> >>
>> >> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com>
>> wrote:
>> >> >>>
>> >> >>> We may say `final` is stronger than `volatile`, it has all the
>> >> >>> semantics of `volatile', and more.
>> >> >>>
>> >> >>> `volatile` is not strong enough to build thread-safe immutable
>> >> >>> objects, `final` is.
>> >> >>>
>> >> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com>
>> >> >>> wrote:
>> >> >>> > Hi,
>> >> >>> >
>> >> >>> > I have a class with a single member, a reference to a new
>> >> >>> > MessageDigest
>> >> >>> > obtained in the constructor based on the algorithm name passed to
>> >> >>> > the
>> >> >>> > constructor.  The constructor also has a Reader argument and
>> reads
>> >> >>> > all
>> >> >>> > the
>> >> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and
>> passes
>> >> >>> > thru
>> >> >>> > to
>> >> >>> > the digest with my own OutputStream filter.  The call to the
>> >> >>> > constructor
>> >> >>> > then accesses the MessageDigest member and calls digest() to get
>> the
>> >> >>> > resulting byte[].  My code by all appearances is single threaded,
>> >> >>> > but I
>> >> >>> > am
>> >> >>> > having strange bugs that on one particular machine running
>> vmware,
>> >> >>> > the
>> >> >>> > digest result I am getting (for password hashing) appears not to
>> be
>> >> >>> > repeatable.
>> >> >>> >
>> >> >>> > Basically, I am wondering if another thread can execute the body
>> of
>> >> >>> > the
>> >> >>> > constructor (or in the construction and use of the
>> >> >>> > OutputStreamWriter,
>> >> >>> > within my constructor) that could be causing a bug where memory
>> >> >>> > written
>> >> >>> > by
>> >> >>> > the MessageDigest.update() function (triggered within the
>> >> >>> > constructor
>> >> >>> > by
>> >> >>> > writing thru OutputStreamWriter) is not seen in the call to
>> digest()
>> >> >>> > on
>> >> >>> > the
>> >> >>> > newly created MessageDigest member after the constructor returns.
>> >> >>> >
>> >> >>> > Andy
>> >> >>> >
>> >> >>> > _______________________________________________
>> >> >>> > Concurrency-interest mailing list
>> >> >>> > Concurrency-interest at cs.oswego.edu
>> >> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>> >
>> >> >>> _______________________________________________
>> >> >>> Concurrency-interest mailing list
>> >> >>> Concurrency-interest at cs.oswego.edu
>> >> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >>
>> >> >>
>> >> >> _______________________________________________
>> >> >> Concurrency-interest mailing list
>> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/fc1289a5/attachment-0001.html>

From zhong.j.yu at gmail.com  Wed Oct  3 15:32:49 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 14:32:49 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
	<CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
	<CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
Message-ID: <CACuKZqGT962h8sbUZqK1x_8boo2Sy1R1KuiYnqVDp8+iqoJsEw@mail.gmail.com>

We may say a final field `f` protects an extended territory, anything
reachable from `f` is in the territory. Any write (before constructor
exit) into the territory cannot be reordered with publication of
`this`. Other writes are not protected by this treaty. In Yuval's
example, `a=1` can be reordered to an arbitrarily late place.

On Wed, Oct 3, 2012 at 2:14 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> Right, but that's a different matter since final assignment is specifically
> the order between the final assignment in ctor and ref assignment rather
> than other surrounding operations.
>
> Sent from my phone
>
> On Oct 3, 2012 3:09 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>> I guess the spec is deliberately weakened, so that for example
>>
>>     anInt = 1;
>>     anStr = new String(bytes);
>>
>> no ordering constraint is imposed; the 1st write can be reordered
>> after the 2nd, passing the constructor with final field writes.
>>
>> This seems unnecessarily sophisticated; too much for mortals.
>>
>> On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>> > This depends on what exactly is the scope of a final field assignment,
>> > as
>> > Aleksey and I have discussed here.  If the mere presence of a final
>> > assignment in the ctor, irrespective of its order with other local
>> > assignments, means there's a StoreStore barrier placed right before
>> > shared
>> > ref assignment, then the whole body of the ctor is visible if the shared
>> > ref
>> > is, and thus no such reordering can occur.
>> >
>> > If StoreStore is placed right after the final assignment only, then it
>> > can.
>> >
>> > Sent from my phone
>> >
>> > On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>> >>
>> >> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> >> wrote:
>> >> > Final is stronger than volatile in terms of store operations inside
>> >> > ctor
>> >> > and
>> >> > subsequent assignment to the ref, which happens to enable the racy
>> >> > publication that still works; volatile wouldn't work.
>> >> >
>> >> > As for your example, it's not allowed.  In order for another thread
>> >> > to
>> >> > call
>> >> > verify(), they must have seen a non-null reference.  We also know
>> >> > that
>> >> > final
>> >> > assignment prevents reordering of ctor body with assignment to shared
>> >> > ref.
>> >>
>> >> If the compiler can prove that a write in ctor is to a location that
>> >> cannot be referenced through the final field, then the write can be
>> >> reordered, even after the write to shared ref.
>> >>
>> >> Such proof is probably difficult; unless the field is primitive.
>> >>
>> >> > I think I agree with Aleksey in that any final assignment in the ctor
>> >> > prevents the reordering.  Therefore, if thread sees non-null ref to
>> >> > call
>> >> > verify() on, it cannot see a == 0.
>> >> >
>> >> > Sent from my phone
>> >> >
>> >> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>> >> >>
>> >> >> Is that true? I was under the impression that final only has memory
>> >> >> visibility implications for the final field itself, and anything
>> >> >> gotten
>> >> >> from
>> >> >> it. So for instance:
>> >> >>
>> >> >> class Foo {
>> >> >>     int a;
>> >> >>     final boolean ctorDone;
>> >> >>
>> >> >>     Foo() {
>> >> >>         a = 1;
>> >> >>         ctorDone = true;
>> >> >>     }
>> >> >>
>> >> >>     void verify() {
>> >> >>         while (!ctorDone) { /* spin */ }
>> >> >>         assert a == 1 : a;
>> >> >>     }
>> >> >> }
>> >> >>
>> >> >> My understanding is that (assuming unsafe publication and all that)
>> >> >> the
>> >> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
>> >> >> visibility
>> >> >> only applies to ctorDone. If ctorDone were a volatile, then reading
>> >> >> it
>> >> >> would
>> >> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>> >> >>
>> >> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com>
>> >> >> wrote:
>> >> >>>
>> >> >>> We may say `final` is stronger than `volatile`, it has all the
>> >> >>> semantics of `volatile', and more.
>> >> >>>
>> >> >>> `volatile` is not strong enough to build thread-safe immutable
>> >> >>> objects, `final` is.
>> >> >>>
>> >> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com>
>> >> >>> wrote:
>> >> >>> > Hi,
>> >> >>> >
>> >> >>> > I have a class with a single member, a reference to a new
>> >> >>> > MessageDigest
>> >> >>> > obtained in the constructor based on the algorithm name passed to
>> >> >>> > the
>> >> >>> > constructor.  The constructor also has a Reader argument and
>> >> >>> > reads
>> >> >>> > all
>> >> >>> > the
>> >> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and
>> >> >>> > passes
>> >> >>> > thru
>> >> >>> > to
>> >> >>> > the digest with my own OutputStream filter.  The call to the
>> >> >>> > constructor
>> >> >>> > then accesses the MessageDigest member and calls digest() to get
>> >> >>> > the
>> >> >>> > resulting byte[].  My code by all appearances is single threaded,
>> >> >>> > but I
>> >> >>> > am
>> >> >>> > having strange bugs that on one particular machine running
>> >> >>> > vmware,
>> >> >>> > the
>> >> >>> > digest result I am getting (for password hashing) appears not to
>> >> >>> > be
>> >> >>> > repeatable.
>> >> >>> >
>> >> >>> > Basically, I am wondering if another thread can execute the body
>> >> >>> > of
>> >> >>> > the
>> >> >>> > constructor (or in the construction and use of the
>> >> >>> > OutputStreamWriter,
>> >> >>> > within my constructor) that could be causing a bug where memory
>> >> >>> > written
>> >> >>> > by
>> >> >>> > the MessageDigest.update() function (triggered within the
>> >> >>> > constructor
>> >> >>> > by
>> >> >>> > writing thru OutputStreamWriter) is not seen in the call to
>> >> >>> > digest()
>> >> >>> > on
>> >> >>> > the
>> >> >>> > newly created MessageDigest member after the constructor returns.
>> >> >>> >
>> >> >>> > Andy
>> >> >>> >
>> >> >>> > _______________________________________________
>> >> >>> > Concurrency-interest mailing list
>> >> >>> > Concurrency-interest at cs.oswego.edu
>> >> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>> >
>> >> >>> _______________________________________________
>> >> >>> Concurrency-interest mailing list
>> >> >>> Concurrency-interest at cs.oswego.edu
>> >> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >>
>> >> >>
>> >> >> _______________________________________________
>> >> >> Concurrency-interest mailing list
>> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >

From andrew_nuss at yahoo.com  Wed Oct  3 15:44:07 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 3 Oct 2012 12:44:07 -0700 (PDT)
Subject: [concurrency-interest] do constructors ever involve threading
	under the covers?
In-Reply-To: <CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
Message-ID: <1349293447.6948.YahooMailNeo@web120302.mail.ne1.yahoo.com>

Vitaly,

Can you explain what could go wrong in racy publication within constructor if we declared the reference to the member as volatile instead of final?? For example, we create a temporary reference to the container, and fill it.? That's a bunch of stores.? Then we save the temporary container reference to a private volatile reference, to "publish" the data to other threads that use the class.

Andy



________________________________
 From: Vitaly Davidovich <vitalyd at gmail.com>
To: Yuval Shavit <yshavit at akiban.com> 
Cc: concurrency-interest at cs.oswego.edu 
Sent: Wednesday, October 3, 2012 11:44 AM
Subject: Re: [concurrency-interest] do constructors ever involve threading under the covers?
 

Final is stronger than volatile in terms of store operations inside ctor and subsequent assignment to the ref, which happens to enable the racy publication that still works; volatile wouldn't work.
As for your example, it's not allowed.? In order for another thread to call verify(), they must have seen a non-null reference.? We also know that final assignment prevents reordering of ctor body with assignment to shared ref.? I think I agree with Aleksey in that any final assignment in the ctor prevents the reordering.? Therefore, if thread sees non-null ref to call verify() on, it cannot see a == 0.
Sent from my phone
On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

Is that true? I was under the impression that final only has memory visibility implications for the final field itself, and anything gotten from it. So for instance:
>
>
>class Foo {
>? ? int a;
>? ? final boolean ctorDone;
>
>
>? ? Foo() {
>? ? ? ? a = 1;
>? ? ? ? ctorDone = true;
>? ? }
>
>
>? ? void verify() {
>? ? ? ? while (!ctorDone) { /* spin */ }
>? ? ? ? assert a == 1 : a;
>? ? }
>}
>
>
>My understanding is that (assuming unsafe publication and all that) the JMM is allowed to have a == 0 in Foo.verify, because the memory visibility only applies to ctorDone. If ctorDone were a volatile, then reading it would ensure a full HB edge, and you'd be guaranteed to see a == 1.
>
>
>On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>
>We may say `final` is stronger than `volatile`, it has all the
>>semantics of `volatile', and more.
>>
>>`volatile` is not strong enough to build thread-safe immutable
>>objects, `final` is.
>>
>>
>>On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
>>> Hi,
>>>
>>> I have a class with a single member, a reference to a new MessageDigest
>>> obtained in the constructor based on the algorithm name passed to the
>>> constructor. ?The constructor also has a Reader argument and reads all the
>>> data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru to
>>> the digest with my own OutputStream filter. ?The call to the constructor
>>> then accesses the MessageDigest member and calls digest() to get the
>>> resulting byte[]. ?My code by all appearances is single threaded, but I am
>>> having strange bugs that on one particular machine running vmware, the
>>> digest result I am getting (for password hashing) appears not to be
>>> repeatable.
>>>
>>> Basically, I am wondering if another thread can execute the body of the
>>> constructor (or in the construction and use of the OutputStreamWriter,
>>> within my constructor) that could be causing a bug where memory written by
>>> the MessageDigest.update() function (triggered within the constructor by
>>> writing thru OutputStreamWriter) is not seen in the call to digest() on the
>>> newly created MessageDigest member after the constructor returns.
>>>
>>> Andy
>>>
>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>_______________________________________________
>>Concurrency-interest mailing list
>>Concurrency-interest at cs.oswego.edu
>>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/c751369b/attachment.html>

From vitalyd at gmail.com  Wed Oct  3 15:59:37 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 15:59:37 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <1349293447.6948.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<1349293447.6948.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <CAHjP37GBcVH88DamCmzOf2mNO_fKbKpBoqH+TmmLbV2pUv21gw@mail.gmail.com>

The reason is because volatile store allows subsequent (in program order)
normal store to move before it.  The volatile store in your example is the
write of the container to the field, and the normal subsequent store is
assignment of the newly constructed object into the shared ref.  This means
the assignment into shared ref (normal store) can move before volatile
store (the container).  Thus, a reference can be made visible to other
threads before the container is written (I.e. you may see null in the other
thread).

Sent from my phone
On Oct 3, 2012 3:46 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> Vitaly,
>
> Can you explain what could go wrong in racy publication within constructor
> if we declared the reference to the member as volatile instead of final?
> For example, we create a temporary reference to the container, and fill
> it.  That's a bunch of stores.  Then we save the temporary container
> reference to a private volatile reference, to "publish" the data to other
> threads that use the class.
>
> Andy
>
>   ------------------------------
> *From:* Vitaly Davidovich <vitalyd at gmail.com>
> *To:* Yuval Shavit <yshavit at akiban.com>
> *Cc:* concurrency-interest at cs.oswego.edu
> *Sent:* Wednesday, October 3, 2012 11:44 AM
> *Subject:* Re: [concurrency-interest] do constructors ever involve
> threading under the covers?
>
> Final is stronger than volatile in terms of store operations inside ctor
> and subsequent assignment to the ref, which happens to enable the racy
> publication that still works; volatile wouldn't work.
> As for your example, it's not allowed.  In order for another thread to
> call verify(), they must have seen a non-null reference.  We also know that
> final assignment prevents reordering of ctor body with assignment to shared
> ref.  I think I agree with Aleksey in that any final assignment in the ctor
> prevents the reordering.  Therefore, if thread sees non-null ref to call
> verify() on, it cannot see a == 0.
> Sent from my phone
> On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>
> Is that true? I was under the impression that final only has memory
> visibility implications for the final field itself, and anything gotten
> from it. So for instance:
>
> class Foo {
>     int a;
>     final boolean ctorDone;
>
>     Foo() {
>         a = 1;
>         ctorDone = true;
>     }
>
>     void verify() {
>         while (!ctorDone) { /* spin */ }
>         assert a == 1 : a;
>     }
> }
>
> My understanding is that (assuming unsafe publication and all that) the
> JMM is allowed to have a == 0 in Foo.verify, because the memory visibility
> only applies to ctorDone. If ctorDone were a volatile, then reading it
> would ensure a full HB edge, and you'd be guaranteed to see a == 1.
>
> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>
> We may say `final` is stronger than `volatile`, it has all the
> semantics of `volatile', and more.
>
> `volatile` is not strong enough to build thread-safe immutable
> objects, `final` is.
>
> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> > Hi,
> >
> > I have a class with a single member, a reference to a new MessageDigest
> > obtained in the constructor based on the algorithm name passed to the
> > constructor.  The constructor also has a Reader argument and reads all
> the
> > data from the Reader thru an OutputStreamWriter("UTF-8) and passes thru
> to
> > the digest with my own OutputStream filter.  The call to the constructor
> > then accesses the MessageDigest member and calls digest() to get the
> > resulting byte[].  My code by all appearances is single threaded, but I
> am
> > having strange bugs that on one particular machine running vmware, the
> > digest result I am getting (for password hashing) appears not to be
> > repeatable.
> >
> > Basically, I am wondering if another thread can execute the body of the
> > constructor (or in the construction and use of the OutputStreamWriter,
> > within my constructor) that could be causing a bug where memory written
> by
> > the MessageDigest.update() function (triggered within the constructor by
> > writing thru OutputStreamWriter) is not seen in the call to digest() on
> the
> > newly created MessageDigest member after the constructor returns.
> >
> > Andy
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/6f0e1ee6/attachment-0001.html>

From vitalyd at gmail.com  Wed Oct  3 16:10:19 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 3 Oct 2012 16:10:19 -0400
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CACuKZqGT962h8sbUZqK1x_8boo2Sy1R1KuiYnqVDp8+iqoJsEw@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
	<CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
	<CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
	<CACuKZqGT962h8sbUZqK1x_8boo2Sy1R1KuiYnqVDp8+iqoJsEw@mail.gmail.com>
Message-ID: <CAHjP37Gr4Swa2-ciwB8iahe22h5G_nDKyhjAN3vuvs-uhit4+w@mail.gmail.com>

I think Yuval and you are right.  I just looked at the JLS and example
17.5-1 shows that the StoreStore barrier doesn't extend to end of
constructor automatically.  I guess the ThreeStooges.java example that
Aleksey linked to earlier works, despite the final assignment occurring
before the writes into the list, is because those writes are reachable via
the final field and thus get included in the freeze action.

Sent from my phone
On Oct 3, 2012 3:32 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> We may say a final field `f` protects an extended territory, anything
> reachable from `f` is in the territory. Any write (before constructor
> exit) into the territory cannot be reordered with publication of
> `this`. Other writes are not protected by this treaty. In Yuval's
> example, `a=1` can be reordered to an arbitrarily late place.
>
> On Wed, Oct 3, 2012 at 2:14 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
> > Right, but that's a different matter since final assignment is
> specifically
> > the order between the final assignment in ctor and ref assignment rather
> > than other surrounding operations.
> >
> > Sent from my phone
> >
> > On Oct 3, 2012 3:09 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
> >>
> >> I guess the spec is deliberately weakened, so that for example
> >>
> >>     anInt = 1;
> >>     anStr = new String(bytes);
> >>
> >> no ordering constraint is imposed; the 1st write can be reordered
> >> after the 2nd, passing the constructor with final field writes.
> >>
> >> This seems unnecessarily sophisticated; too much for mortals.
> >>
> >> On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com>
> >> wrote:
> >> > This depends on what exactly is the scope of a final field assignment,
> >> > as
> >> > Aleksey and I have discussed here.  If the mere presence of a final
> >> > assignment in the ctor, irrespective of its order with other local
> >> > assignments, means there's a StoreStore barrier placed right before
> >> > shared
> >> > ref assignment, then the whole body of the ctor is visible if the
> shared
> >> > ref
> >> > is, and thus no such reordering can occur.
> >> >
> >> > If StoreStore is placed right after the final assignment only, then it
> >> > can.
> >> >
> >> > Sent from my phone
> >> >
> >> > On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
> >> >>
> >> >> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich <vitalyd at gmail.com
> >
> >> >> wrote:
> >> >> > Final is stronger than volatile in terms of store operations inside
> >> >> > ctor
> >> >> > and
> >> >> > subsequent assignment to the ref, which happens to enable the racy
> >> >> > publication that still works; volatile wouldn't work.
> >> >> >
> >> >> > As for your example, it's not allowed.  In order for another thread
> >> >> > to
> >> >> > call
> >> >> > verify(), they must have seen a non-null reference.  We also know
> >> >> > that
> >> >> > final
> >> >> > assignment prevents reordering of ctor body with assignment to
> shared
> >> >> > ref.
> >> >>
> >> >> If the compiler can prove that a write in ctor is to a location that
> >> >> cannot be referenced through the final field, then the write can be
> >> >> reordered, even after the write to shared ref.
> >> >>
> >> >> Such proof is probably difficult; unless the field is primitive.
> >> >>
> >> >> > I think I agree with Aleksey in that any final assignment in the
> ctor
> >> >> > prevents the reordering.  Therefore, if thread sees non-null ref to
> >> >> > call
> >> >> > verify() on, it cannot see a == 0.
> >> >> >
> >> >> > Sent from my phone
> >> >> >
> >> >> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
> >> >> >>
> >> >> >> Is that true? I was under the impression that final only has
> memory
> >> >> >> visibility implications for the final field itself, and anything
> >> >> >> gotten
> >> >> >> from
> >> >> >> it. So for instance:
> >> >> >>
> >> >> >> class Foo {
> >> >> >>     int a;
> >> >> >>     final boolean ctorDone;
> >> >> >>
> >> >> >>     Foo() {
> >> >> >>         a = 1;
> >> >> >>         ctorDone = true;
> >> >> >>     }
> >> >> >>
> >> >> >>     void verify() {
> >> >> >>         while (!ctorDone) { /* spin */ }
> >> >> >>         assert a == 1 : a;
> >> >> >>     }
> >> >> >> }
> >> >> >>
> >> >> >> My understanding is that (assuming unsafe publication and all
> that)
> >> >> >> the
> >> >> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
> >> >> >> visibility
> >> >> >> only applies to ctorDone. If ctorDone were a volatile, then
> reading
> >> >> >> it
> >> >> >> would
> >> >> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
> >> >> >>
> >> >> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com>
> >> >> >> wrote:
> >> >> >>>
> >> >> >>> We may say `final` is stronger than `volatile`, it has all the
> >> >> >>> semantics of `volatile', and more.
> >> >> >>>
> >> >> >>> `volatile` is not strong enough to build thread-safe immutable
> >> >> >>> objects, `final` is.
> >> >> >>>
> >> >> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss <andrew_nuss at yahoo.com
> >
> >> >> >>> wrote:
> >> >> >>> > Hi,
> >> >> >>> >
> >> >> >>> > I have a class with a single member, a reference to a new
> >> >> >>> > MessageDigest
> >> >> >>> > obtained in the constructor based on the algorithm name passed
> to
> >> >> >>> > the
> >> >> >>> > constructor.  The constructor also has a Reader argument and
> >> >> >>> > reads
> >> >> >>> > all
> >> >> >>> > the
> >> >> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and
> >> >> >>> > passes
> >> >> >>> > thru
> >> >> >>> > to
> >> >> >>> > the digest with my own OutputStream filter.  The call to the
> >> >> >>> > constructor
> >> >> >>> > then accesses the MessageDigest member and calls digest() to
> get
> >> >> >>> > the
> >> >> >>> > resulting byte[].  My code by all appearances is single
> threaded,
> >> >> >>> > but I
> >> >> >>> > am
> >> >> >>> > having strange bugs that on one particular machine running
> >> >> >>> > vmware,
> >> >> >>> > the
> >> >> >>> > digest result I am getting (for password hashing) appears not
> to
> >> >> >>> > be
> >> >> >>> > repeatable.
> >> >> >>> >
> >> >> >>> > Basically, I am wondering if another thread can execute the
> body
> >> >> >>> > of
> >> >> >>> > the
> >> >> >>> > constructor (or in the construction and use of the
> >> >> >>> > OutputStreamWriter,
> >> >> >>> > within my constructor) that could be causing a bug where memory
> >> >> >>> > written
> >> >> >>> > by
> >> >> >>> > the MessageDigest.update() function (triggered within the
> >> >> >>> > constructor
> >> >> >>> > by
> >> >> >>> > writing thru OutputStreamWriter) is not seen in the call to
> >> >> >>> > digest()
> >> >> >>> > on
> >> >> >>> > the
> >> >> >>> > newly created MessageDigest member after the constructor
> returns.
> >> >> >>> >
> >> >> >>> > Andy
> >> >> >>> >
> >> >> >>> > _______________________________________________
> >> >> >>> > Concurrency-interest mailing list
> >> >> >>> > Concurrency-interest at cs.oswego.edu
> >> >> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> >>> >
> >> >> >>> _______________________________________________
> >> >> >>> Concurrency-interest mailing list
> >> >> >>> Concurrency-interest at cs.oswego.edu
> >> >> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >> _______________________________________________
> >> >> >> Concurrency-interest mailing list
> >> >> >> Concurrency-interest at cs.oswego.edu
> >> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> >>
> >> >> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121003/3595ac20/attachment.html>

From zhong.j.yu at gmail.com  Wed Oct  3 16:40:08 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 3 Oct 2012 15:40:08 -0500
Subject: [concurrency-interest] do constructors ever involve threading
 under the covers?
In-Reply-To: <CAHjP37Gr4Swa2-ciwB8iahe22h5G_nDKyhjAN3vuvs-uhit4+w@mail.gmail.com>
References: <1349270673.39900.YahooMailNeo@web120301.mail.ne1.yahoo.com>
	<CACuKZqEPU2R=uf2Pw==Py7eY0zF29ypN7SdNJisX=bkdObwDgg@mail.gmail.com>
	<CAC2Zdp1igXAi1J-0yAUd1miq0yC17ZhgCqFjTJyGzmah2KCYMg@mail.gmail.com>
	<CAHjP37HxNqWi=-bO139uUb4rCv7J1FdJuR5mpW4W0GHsb=btxA@mail.gmail.com>
	<CACuKZqG_7Cnnm=CrjZdEo--Lgdw6BDediF7k4jk1-gFNiTQbUA@mail.gmail.com>
	<CAHjP37H0nHpxPK-Znu7NGW8uqsCt55EUzfJfd+WBk5vJ-JavPA@mail.gmail.com>
	<CACuKZqG4LsJMeuGbR1VCKWnREGGA4f5H-8VTo=Cq_=ubQZDn6A@mail.gmail.com>
	<CAHjP37F-ugJNtebBnnxABRFeOHrMujxiDjadANJ2nNdc8wYEbw@mail.gmail.com>
	<CACuKZqGT962h8sbUZqK1x_8boo2Sy1R1KuiYnqVDp8+iqoJsEw@mail.gmail.com>
	<CAHjP37Gr4Swa2-ciwB8iahe22h5G_nDKyhjAN3vuvs-uhit4+w@mail.gmail.com>
Message-ID: <CACuKZqGNVgfWXGC+-epEHsE-8jkXbnh_sVDEXz_W7Lc=3YXbuQ@mail.gmail.com>

It would be more intuitive to define the freeze action the same as the
write to the final field. I guess the authors wanted to be able to
freely reorder intra-constructor actions, regardless of final fields,
so freeze is postponed.

In this example

    ctor()
    {
        f = v; // final
        leaked = this;
    }

when another thread sees a non null `leaked`, it's not guaranteed to
see `leaked.f==v`, because of the possible reordering.

On Wed, Oct 3, 2012 at 3:10 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> I think Yuval and you are right.  I just looked at the JLS and example
> 17.5-1 shows that the StoreStore barrier doesn't extend to end of
> constructor automatically.  I guess the ThreeStooges.java example that
> Aleksey linked to earlier works, despite the final assignment occurring
> before the writes into the list, is because those writes are reachable via
> the final field and thus get included in the freeze action.
>
> Sent from my phone
>
> On Oct 3, 2012 3:32 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>> We may say a final field `f` protects an extended territory, anything
>> reachable from `f` is in the territory. Any write (before constructor
>> exit) into the territory cannot be reordered with publication of
>> `this`. Other writes are not protected by this treaty. In Yuval's
>> example, `a=1` can be reordered to an arbitrarily late place.
>>
>> On Wed, Oct 3, 2012 at 2:14 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>> > Right, but that's a different matter since final assignment is
>> > specifically
>> > the order between the final assignment in ctor and ref assignment rather
>> > than other surrounding operations.
>> >
>> > Sent from my phone
>> >
>> > On Oct 3, 2012 3:09 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>> >>
>> >> I guess the spec is deliberately weakened, so that for example
>> >>
>> >>     anInt = 1;
>> >>     anStr = new String(bytes);
>> >>
>> >> no ordering constraint is imposed; the 1st write can be reordered
>> >> after the 2nd, passing the constructor with final field writes.
>> >>
>> >> This seems unnecessarily sophisticated; too much for mortals.
>> >>
>> >> On Wed, Oct 3, 2012 at 1:58 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> >> wrote:
>> >> > This depends on what exactly is the scope of a final field
>> >> > assignment,
>> >> > as
>> >> > Aleksey and I have discussed here.  If the mere presence of a final
>> >> > assignment in the ctor, irrespective of its order with other local
>> >> > assignments, means there's a StoreStore barrier placed right before
>> >> > shared
>> >> > ref assignment, then the whole body of the ctor is visible if the
>> >> > shared
>> >> > ref
>> >> > is, and thus no such reordering can occur.
>> >> >
>> >> > If StoreStore is placed right after the final assignment only, then
>> >> > it
>> >> > can.
>> >> >
>> >> > Sent from my phone
>> >> >
>> >> > On Oct 3, 2012 2:52 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>> >> >>
>> >> >> On Wed, Oct 3, 2012 at 1:44 PM, Vitaly Davidovich
>> >> >> <vitalyd at gmail.com>
>> >> >> wrote:
>> >> >> > Final is stronger than volatile in terms of store operations
>> >> >> > inside
>> >> >> > ctor
>> >> >> > and
>> >> >> > subsequent assignment to the ref, which happens to enable the racy
>> >> >> > publication that still works; volatile wouldn't work.
>> >> >> >
>> >> >> > As for your example, it's not allowed.  In order for another
>> >> >> > thread
>> >> >> > to
>> >> >> > call
>> >> >> > verify(), they must have seen a non-null reference.  We also know
>> >> >> > that
>> >> >> > final
>> >> >> > assignment prevents reordering of ctor body with assignment to
>> >> >> > shared
>> >> >> > ref.
>> >> >>
>> >> >> If the compiler can prove that a write in ctor is to a location that
>> >> >> cannot be referenced through the final field, then the write can be
>> >> >> reordered, even after the write to shared ref.
>> >> >>
>> >> >> Such proof is probably difficult; unless the field is primitive.
>> >> >>
>> >> >> > I think I agree with Aleksey in that any final assignment in the
>> >> >> > ctor
>> >> >> > prevents the reordering.  Therefore, if thread sees non-null ref
>> >> >> > to
>> >> >> > call
>> >> >> > verify() on, it cannot see a == 0.
>> >> >> >
>> >> >> > Sent from my phone
>> >> >> >
>> >> >> > On Oct 3, 2012 1:51 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>> >> >> >>
>> >> >> >> Is that true? I was under the impression that final only has
>> >> >> >> memory
>> >> >> >> visibility implications for the final field itself, and anything
>> >> >> >> gotten
>> >> >> >> from
>> >> >> >> it. So for instance:
>> >> >> >>
>> >> >> >> class Foo {
>> >> >> >>     int a;
>> >> >> >>     final boolean ctorDone;
>> >> >> >>
>> >> >> >>     Foo() {
>> >> >> >>         a = 1;
>> >> >> >>         ctorDone = true;
>> >> >> >>     }
>> >> >> >>
>> >> >> >>     void verify() {
>> >> >> >>         while (!ctorDone) { /* spin */ }
>> >> >> >>         assert a == 1 : a;
>> >> >> >>     }
>> >> >> >> }
>> >> >> >>
>> >> >> >> My understanding is that (assuming unsafe publication and all
>> >> >> >> that)
>> >> >> >> the
>> >> >> >> JMM is allowed to have a == 0 in Foo.verify, because the memory
>> >> >> >> visibility
>> >> >> >> only applies to ctorDone. If ctorDone were a volatile, then
>> >> >> >> reading
>> >> >> >> it
>> >> >> >> would
>> >> >> >> ensure a full HB edge, and you'd be guaranteed to see a == 1.
>> >> >> >>
>> >> >> >> On Wed, Oct 3, 2012 at 1:32 PM, Zhong Yu <zhong.j.yu at gmail.com>
>> >> >> >> wrote:
>> >> >> >>>
>> >> >> >>> We may say `final` is stronger than `volatile`, it has all the
>> >> >> >>> semantics of `volatile', and more.
>> >> >> >>>
>> >> >> >>> `volatile` is not strong enough to build thread-safe immutable
>> >> >> >>> objects, `final` is.
>> >> >> >>>
>> >> >> >>> On Wed, Oct 3, 2012 at 8:24 AM, Andy Nuss
>> >> >> >>> <andrew_nuss at yahoo.com>
>> >> >> >>> wrote:
>> >> >> >>> > Hi,
>> >> >> >>> >
>> >> >> >>> > I have a class with a single member, a reference to a new
>> >> >> >>> > MessageDigest
>> >> >> >>> > obtained in the constructor based on the algorithm name passed
>> >> >> >>> > to
>> >> >> >>> > the
>> >> >> >>> > constructor.  The constructor also has a Reader argument and
>> >> >> >>> > reads
>> >> >> >>> > all
>> >> >> >>> > the
>> >> >> >>> > data from the Reader thru an OutputStreamWriter("UTF-8) and
>> >> >> >>> > passes
>> >> >> >>> > thru
>> >> >> >>> > to
>> >> >> >>> > the digest with my own OutputStream filter.  The call to the
>> >> >> >>> > constructor
>> >> >> >>> > then accesses the MessageDigest member and calls digest() to
>> >> >> >>> > get
>> >> >> >>> > the
>> >> >> >>> > resulting byte[].  My code by all appearances is single
>> >> >> >>> > threaded,
>> >> >> >>> > but I
>> >> >> >>> > am
>> >> >> >>> > having strange bugs that on one particular machine running
>> >> >> >>> > vmware,
>> >> >> >>> > the
>> >> >> >>> > digest result I am getting (for password hashing) appears not
>> >> >> >>> > to
>> >> >> >>> > be
>> >> >> >>> > repeatable.
>> >> >> >>> >
>> >> >> >>> > Basically, I am wondering if another thread can execute the
>> >> >> >>> > body
>> >> >> >>> > of
>> >> >> >>> > the
>> >> >> >>> > constructor (or in the construction and use of the
>> >> >> >>> > OutputStreamWriter,
>> >> >> >>> > within my constructor) that could be causing a bug where
>> >> >> >>> > memory
>> >> >> >>> > written
>> >> >> >>> > by
>> >> >> >>> > the MessageDigest.update() function (triggered within the
>> >> >> >>> > constructor
>> >> >> >>> > by
>> >> >> >>> > writing thru OutputStreamWriter) is not seen in the call to
>> >> >> >>> > digest()
>> >> >> >>> > on
>> >> >> >>> > the
>> >> >> >>> > newly created MessageDigest member after the constructor
>> >> >> >>> > returns.
>> >> >> >>> >
>> >> >> >>> > Andy
>> >> >> >>> >
>> >> >> >>> > _______________________________________________
>> >> >> >>> > Concurrency-interest mailing list
>> >> >> >>> > Concurrency-interest at cs.oswego.edu
>> >> >> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >> >>> >
>> >> >> >>> _______________________________________________
>> >> >> >>> Concurrency-interest mailing list
>> >> >> >>> Concurrency-interest at cs.oswego.edu
>> >> >> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >> _______________________________________________
>> >> >> >> Concurrency-interest mailing list
>> >> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >> >>
>> >> >> >

From softwarepravin2007 at gmail.com  Sat Oct  6 04:44:16 2012
From: softwarepravin2007 at gmail.com (Pravin Nawale)
Date: Sat, 6 Oct 2012 14:14:16 +0530
Subject: [concurrency-interest] Fork Join framework implementation in java
	1.6
Message-ID: <CAE6Z9ZkP=8BusfR5M7FJOD3E_QY9UUUxk2eFzQ7VYZaaMGAf8w@mail.gmail.com>

Hi ,

I implemented java fork and join framework (jdk 1.6 using jsr166.jar) in my
application. During user login or performing any operation, called fork and
join framework which perform 3-4 tasks in parallel ,gather data and return
it to the application.

Note : For each login request or operation  I am creating one fork/join

But facing major problem -

During 4-5 users  logging simultaneously , response swapped between users.
i.e. if user A,B,C,D,...logging in simultaneously then B's response send to
other user randomly. If I remove fork and join then it wirk fine.

Please suggest solution.

Thanks & Regards,
Pravin Nawale
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121006/b7f18748/attachment.html>

From gregg at cytetech.com  Sat Oct  6 12:58:03 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Sat, 06 Oct 2012 11:58:03 -0500
Subject: [concurrency-interest] Fork Join framework implementation in
 java 1.6
In-Reply-To: <CAE6Z9ZkP=8BusfR5M7FJOD3E_QY9UUUxk2eFzQ7VYZaaMGAf8w@mail.gmail.com>
References: <CAE6Z9ZkP=8BusfR5M7FJOD3E_QY9UUUxk2eFzQ7VYZaaMGAf8w@mail.gmail.com>
Message-ID: <5070631B.9070205@cytetech.com>

On 10/6/2012 3:44 AM, Pravin Nawale wrote:
> Hi ,
>
> I implemented java fork and join framework (jdk 1.6 using jsr166.jar) in my
> application. During user login or performing any operation, called fork and join
> framework which perform 3-4 tasks in parallel ,gather data and return it to the
> application.
>
> Note : For each login request or operation  I am creating one fork/join
>
> But facing major problem -
>
> During 4-5 users  logging simultaneously , response swapped between users. i.e.
> if user A,B,C,D,...logging in simultaneously then B's response send to other
> user randomly. If I remove fork and join then it wirk fine.

It sounds like your "login requests" do not have per user data items, but rather 
share some global data which you have a data race on the use of.

Gregg


From ach at quartetfs.com  Thu Oct 11 08:44:18 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Thu, 11 Oct 2012 14:44:18 +0200
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEFMIPAA.davidcholmes@aapt.net.au>
References: <4E42B3EB.2060206@oracle.com>
	<NFBBKALFDCPFIDBNKAPCGEFMIPAA.davidcholmes@aapt.net.au>
Message-ID: <CAJGQDwmkYpF=u_cxOh2si30rqYunV1KjN87oZmDZLrCZqcVZaA@mail.gmail.com>

After deploying the "ActivePivot" software (java in-memory analytics
solution) on a new server we discovered how inefficient a large heap java
application can be on NUMA system.

The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There are 4
NUMA nodes each with 8 cores and 128GB. ActivePivot loads large amounts of
data in memory (up to hundreds of GB) and then performs complex aggregation
queries over the entire data, using a global fork/join pool. Although the
data structures are partitioned, this partitioning is random with respect
to NUMA nodes and processors. There is a sharp performance drop compared to
smaller SMP servers.


We are considering launching several JVMs, each bound to NUMA nodes, and
communicating with each other. But that's an entire new layer of code, and
this won't be quite as performant as processor id partitioning in one JVM.

I think that's another use case for the processor id API. I hope this RFE
is making progress? Is there a chance to see it as part of JDK8?


Regards,
-Antoine CHAMBILLE
Quartet FS




On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au> wrote:

> **
> Aside: Just for the public record. I think an API to support use of
> Processor sets would be a useful addition to the platform to allow better
> partitioning of CPU resources. The Real-time Specification for Java 1.1
> under JSR-282 is looking at such an API primarily to work in with OS level
> processor sets. For our purposes, more locally within the JVM the
> processors made available to the JVM could be partitioned both internally
> (ie binding GC to a specific set of cores) and at the application/library
> level (such as allocating ForkJoinPools  disjoint sets of cores). The
> abiility to query the current processor ID is inherently needed and so I
> would make it part of the Processors class. This would provide the
> foundation API for ProcessortLocal.
>
> David Holmes
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Nathan Reynolds
> *Sent:* Thursday, 11 August 2011 2:38 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] ThreadLocal vs ProcessorLocal
>
> I would like to recommend that we stripe data structures using a
> ProcessorLocal instead of ThreadLocal.  ProcessorLocal (attached) is
> exactly like ThreadLocal except the stored objects keyed off of the
> processor instead of the thread.  In order to implement ProcessorLocal, it
> needs an API that returns the current processor id that the thread is
> running on.  The HotSpot team has filed an RFE and are planning on
> providing such an API.  (Many of you are already aware of this.)
>
> I would like to share a story and some results to further the discussion
> on processor striping (i.e. ProcessorLocal).
>
> A long time ago, we found that an Oracle C++ program bottlenecked on a
> reader/writer lock.  Threads couldn't read-acquire the lock fast enough.
> The problem was due to the contention on the cache line while executing the
> CAS instruction.  So, I striped the lock.  The code non-atomically
> incremented an int and masked it to select one of the reader/writer locks.
> Multiple threads could end up selecting the same reader/writer lock because
> the int was incremented in an unprotected manner.  If multiple threads
> selected the same reader/writer lock, the lock would handle the concurrency
> and the only negative was lock performance.  This optimization worked great
> until Intel released Nehalem-EX.
>
> A while ago, Intel found on Nehalem-EX that the same Oracle C++ program
> didn't scale to the 4?? Nehalem socket.  All of the processors/cores were
> 100% busy, but the throughput didn't improve by adding the 4?? Nehalem
> socket.  The problem was the cores were fighting to get the cache line
> holding the unprotected int!
>
> I tried 4 approaches to select the reader/writer lock.
>
> 1) Processor id - This performed the best.  The cache lines holding the
> reader/writer locks are almost never invalidated due to another core
> accessing the reader/writer lock.  In other words, almost 0 CAS contention.
> 2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to locks.  It
> required too many locks and the locks had to migrate with the threads.
> 3) Hash the stack pointer - Hashing the stack pointer caused some
> collisions but essentially randomly selected locks and this hurt cache
> performance.
> 4) Shift and mask the cycle counter (i.e. rdtsc) - Contention was rare but
> again it randomly selected the locks.
>
> Compared to non-atomically incrementing an int, processor id resulted in
> 15% more throughput.  The other 3 only showed 5% more throughput.
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121011/0992be5b/attachment.html>

From davidcholmes at aapt.net.au  Fri Oct 12 07:43:04 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 12 Oct 2012 21:43:04 +1000
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJGQDwmkYpF=u_cxOh2si30rqYunV1KjN87oZmDZLrCZqcVZaA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>

Hi Antoine,

I've not seen any sign that this has moved toward an actual API proposal so far. As the feature complete date for JDK 8 is January 31, I'd say the chances of any such API appearing in JDK 8 would be slim. But perhaps someone is fleshing this out quietly and will come forward with a fully worked out API design and implementation.

David
-------
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Antoine Chambille
  Sent: Thursday, 11 October 2012 10:44 PM
  To: Concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal


  After deploying the "ActivePivot" software (java in-memory analytics solution) on a new server we discovered how inefficient a large heap java application can be on NUMA system.


  The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads large amounts of data in memory (up to hundreds of GB) and then performs complex aggregation queries over the entire data, using a global fork/join pool. Although the data structures are partitioned, this partitioning is random with respect to NUMA nodes and processors. There is a sharp performance drop compared to smaller SMP servers.




  We are considering launching several JVMs, each bound to NUMA nodes, and communicating with each other. But that's an entire new layer of code, and this won't be quite as performant as processor id partitioning in one JVM.


  I think that's another use case for the processor id API. I hope this RFE is making progress? Is there a chance to see it as part of JDK8?




  Regards,
  -Antoine CHAMBILLE
  Quartet FS








  On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au> wrote:

    Aside: Just for the public record. I think an API to support use of Processor sets would be a useful addition to the platform to allow better partitioning of CPU resources. The Real-time Specification for Java 1.1 under JSR-282 is looking at such an API primarily to work in with OS level processor sets. For our purposes, more locally within the JVM the processors made available to the JVM could be partitioned both internally (ie binding GC to a specific set of cores) and at the application/library level (such as allocating ForkJoinPools  disjoint sets of cores). The abiility to query the current processor ID is inherently needed and so I would make it part of the Processors class. This would provide the foundation API for ProcessortLocal.

    David Holmes
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan Reynolds
      Sent: Thursday, 11 August 2011 2:38 AM
      To: concurrency-interest at cs.oswego.edu
      Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal


      I would like to recommend that we stripe data structures using a ProcessorLocal instead of ThreadLocal.  ProcessorLocal (attached) is exactly like ThreadLocal except the stored objects keyed off of the processor instead of the thread.  In order to implement ProcessorLocal, it needs an API that returns the current processor id that the thread is running on.  The HotSpot team has filed an RFE and are planning on providing such an API.  (Many of you are already aware of this.)

      I would like to share a story and some results to further the discussion on processor striping (i.e. ProcessorLocal).

      A long time ago, we found that an Oracle C++ program bottlenecked on a reader/writer lock.  Threads couldn't read-acquire the lock fast enough.  The problem was due to the contention on the cache line while executing the CAS instruction.  So, I striped the lock.  The code non-atomically incremented an int and masked it to select one of the reader/writer locks.  Multiple threads could end up selecting the same reader/writer lock because the int was incremented in an unprotected manner.  If multiple threads selected the same reader/writer lock, the lock would handle the concurrency and the only negative was lock performance.  This optimization worked great until Intel released Nehalem-EX.

      A while ago, Intel found on Nehalem-EX that the same Oracle C++ program didn't scale to the 4?? Nehalem socket.  All of the processors/cores were 100% busy, but the throughput didn't improve by adding the 4?? Nehalem socket.  The problem was the cores were fighting to get the cache line holding the unprotected int!

      I tried 4 approaches to select the reader/writer lock.

      1) Processor id - This performed the best.  The cache lines holding the reader/writer locks are almost never invalidated due to another core accessing the reader/writer lock.  In other words, almost 0 CAS contention.
      2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to locks.  It required too many locks and the locks had to migrate with the threads.
      3) Hash the stack pointer - Hashing the stack pointer caused some collisions but essentially randomly selected locks and this hurt cache performance.
      4) Shift and mask the cycle counter (i.e. rdtsc) - Contention was rare but again it randomly selected the locks.

      Compared to non-atomically incrementing an int, processor id resulted in 15% more throughput.  The other 3 only showed 5% more throughput.


      Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
      Oracle PSR Engineering | Server Technology 



    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest







  -- 
  Antoine CHAMBILLE
  R&D Director
  Quartet FS

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121012/9c99c6de/attachment.html>

From chris.hegarty at oracle.com  Fri Oct 12 08:30:33 2012
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Fri, 12 Oct 2012 13:30:33 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
Message-ID: <50780D69.1070608@oracle.com>

I am also not aware of any work being done on this, with respect to JDK8.

-Chris.

On 12/10/2012 12:43, David Holmes wrote:
> Hi Antoine,
> I've not seen any sign that this has moved toward an actual API proposal
> so far. As the feature complete date for JDK 8 is January 31, I'd say
> the chances of any such API appearing in JDK 8 would be slim. But
> perhaps someone is fleshing this out quietly and will come forward with
> a fully worked out API design and implementation.
> David
> -------
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Antoine Chambille
>     *Sent:* Thursday, 11 October 2012 10:44 PM
>     *To:* Concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>
>     After deploying the "ActivePivot" software (java in-memory analytics
>     solution) on a new server we discovered how inefficient a large heap
>     java application can be on NUMA system.
>
>     The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There
>     are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads
>     large amounts of data in memory (up to hundreds of GB) and then
>     performs complex aggregation queries over the entire data, using a
>     global fork/join pool. Although the data structures are partitioned,
>     this partitioning is random with respect to NUMA nodes and
>     processors. There is a sharp performance drop compared to smaller
>     SMP servers.
>
>
>     We are considering launching several JVMs, each bound to NUMA nodes,
>     and communicating with each other. But that's an entire new layer of
>     code, and this won't be quite as performant as processor id
>     partitioning in one JVM.
>
>     I think that's another use case for the processor id API. I hope
>     this RFE is making progress? Is there a chance to see it as part of
>     JDK8?
>
>
>     Regards,
>     -Antoine CHAMBILLE
>     Quartet FS
>
>
>
>
>     On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au
>     <mailto:davidcholmes at aapt.net.au>> wrote:
>
>         __
>         Aside: Just for the public record. I think an API to support use
>         of Processor sets would be a useful addition to the platform to
>         allow better partitioning of CPU resources. The Real-time
>         Specification for Java 1.1 under JSR-282 is looking at such an
>         API primarily to work in with OS level processor sets. For our
>         purposes, more locally within the JVM the processors made
>         available to the JVM could be partitioned both internally (ie
>         binding GC to a specific set of cores) and at the
>         application/library level (such as allocating ForkJoinPools
>         disjoint sets of cores). The abiility to query the current
>         processor ID is inherently needed and so I would make it part of
>         the Processors class. This would provide the foundation API for
>         ProcessortLocal.
>         David Holmes
>
>             -----Original Message-----
>             *From:* concurrency-interest-bounces at cs.oswego.edu
>             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>             [mailto:concurrency-interest-bounces at cs.oswego.edu
>             <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>             Behalf Of *Nathan Reynolds
>             *Sent:* Thursday, 11 August 2011 2:38 AM
>             *To:* concurrency-interest at cs.oswego.edu
>             <mailto:concurrency-interest at cs.oswego.edu>
>             *Subject:* [concurrency-interest] ThreadLocal vs ProcessorLocal
>
>             I would like to recommend that we stripe data structures
>             using a ProcessorLocal instead of ThreadLocal.
>             ProcessorLocal (attached) is exactly like ThreadLocal except
>             the stored objects keyed off of the processor instead of the
>             thread. In order to implement ProcessorLocal, it needs an
>             API that returns the current processor id that the thread is
>             running on. The HotSpot team has filed an RFE and are
>             planning on providing such an API. (Many of you are already
>             aware of this.)
>
>             I would like to share a story and some results to further
>             the discussion on processor striping (i.e. ProcessorLocal).
>
>             A long time ago, we found that an Oracle C++ program
>             bottlenecked on a reader/writer lock. Threads couldn't
>             read-acquire the lock fast enough. The problem was due to
>             the contention on the cache line while executing the CAS
>             instruction. So, I striped the lock. The code non-atomically
>             incremented an int and masked it to select one of the
>             reader/writer locks. Multiple threads could end up selecting
>             the same reader/writer lock because the int was incremented
>             in an unprotected manner. If multiple threads selected the
>             same reader/writer lock, the lock would handle the
>             concurrency and the only negative was lock performance. This
>             optimization worked great until Intel released Nehalem-EX.
>
>             A while ago, Intel found on Nehalem-EX that the same Oracle
>             C++ program didn't scale to the 4?? Nehalem socket. All of
>             the processors/cores were 100% busy, but the throughput
>             didn't improve by adding the 4?? Nehalem socket. The problem
>             was the cores were fighting to get the cache line holding
>             the unprotected int!
>
>             I tried 4 approaches to select the reader/writer lock.
>
>             1) Processor id - This performed the best. The cache lines
>             holding the reader/writer locks are almost never invalidated
>             due to another core accessing the reader/writer lock. In
>             other words, almost 0 CAS contention.
>             2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to
>             locks. It required too many locks and the locks had to
>             migrate with the threads.
>             3) Hash the stack pointer - Hashing the stack pointer caused
>             some collisions but essentially randomly selected locks and
>             this hurt cache performance.
>             4) Shift and mask the cycle counter (i.e. rdtsc) -
>             Contention was rare but again it randomly selected the locks.
>
>             Compared to non-atomically incrementing an int, processor id
>             resulted in 15% more throughput. The other 3 only showed 5%
>             more throughput.
>
>             Nathan Reynolds
>             <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>
>             | Consulting Member of Technical Staff | 602.333.9091
>             <tel:602.333.9091>
>             Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>             Technology
>
>
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>     --
>     Antoine CHAMBILLE
>     R&D Director
>     Quartet FS
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From aleksey.shipilev at oracle.com  Fri Oct 12 08:44:11 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 12 Oct 2012 16:44:11 +0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <50780D69.1070608@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
Message-ID: <5078109B.1080005@oracle.com>

I think we better ask Nathan if he feels enthusiastic enough to drive
this into JDK8. But as David notes, this is very close to
feature-completeness for JDK8.

-Aleksey.

On 10/12/2012 04:30 PM, Chris Hegarty wrote:
> I am also not aware of any work being done on this, with respect to JDK8.
> 
> -Chris.
> 
> On 12/10/2012 12:43, David Holmes wrote:
>> Hi Antoine,
>> I've not seen any sign that this has moved toward an actual API proposal
>> so far. As the feature complete date for JDK 8 is January 31, I'd say
>> the chances of any such API appearing in JDK 8 would be slim. But
>> perhaps someone is fleshing this out quietly and will come forward with
>> a fully worked out API design and implementation.
>> David
>> -------
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>     *Antoine Chambille
>>     *Sent:* Thursday, 11 October 2012 10:44 PM
>>     *To:* Concurrency-interest at cs.oswego.edu
>>     *Subject:* Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>>
>>     After deploying the "ActivePivot" software (java in-memory analytics
>>     solution) on a new server we discovered how inefficient a large heap
>>     java application can be on NUMA system.
>>
>>     The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There
>>     are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads
>>     large amounts of data in memory (up to hundreds of GB) and then
>>     performs complex aggregation queries over the entire data, using a
>>     global fork/join pool. Although the data structures are partitioned,
>>     this partitioning is random with respect to NUMA nodes and
>>     processors. There is a sharp performance drop compared to smaller
>>     SMP servers.
>>
>>
>>     We are considering launching several JVMs, each bound to NUMA nodes,
>>     and communicating with each other. But that's an entire new layer of
>>     code, and this won't be quite as performant as processor id
>>     partitioning in one JVM.
>>
>>     I think that's another use case for the processor id API. I hope
>>     this RFE is making progress? Is there a chance to see it as part of
>>     JDK8?
>>
>>
>>     Regards,
>>     -Antoine CHAMBILLE
>>     Quartet FS
>>
>>
>>
>>
>>     On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au
>>     <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>         __
>>         Aside: Just for the public record. I think an API to support use
>>         of Processor sets would be a useful addition to the platform to
>>         allow better partitioning of CPU resources. The Real-time
>>         Specification for Java 1.1 under JSR-282 is looking at such an
>>         API primarily to work in with OS level processor sets. For our
>>         purposes, more locally within the JVM the processors made
>>         available to the JVM could be partitioned both internally (ie
>>         binding GC to a specific set of cores) and at the
>>         application/library level (such as allocating ForkJoinPools
>>         disjoint sets of cores). The abiility to query the current
>>         processor ID is inherently needed and so I would make it part of
>>         the Processors class. This would provide the foundation API for
>>         ProcessortLocal.
>>         David Holmes
>>
>>             -----Original Message-----
>>             *From:* concurrency-interest-bounces at cs.oswego.edu
>>             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>             [mailto:concurrency-interest-bounces at cs.oswego.edu
>>             <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On
>>             Behalf Of *Nathan Reynolds
>>             *Sent:* Thursday, 11 August 2011 2:38 AM
>>             *To:* concurrency-interest at cs.oswego.edu
>>             <mailto:concurrency-interest at cs.oswego.edu>
>>             *Subject:* [concurrency-interest] ThreadLocal vs
>> ProcessorLocal
>>
>>             I would like to recommend that we stripe data structures
>>             using a ProcessorLocal instead of ThreadLocal.
>>             ProcessorLocal (attached) is exactly like ThreadLocal except
>>             the stored objects keyed off of the processor instead of the
>>             thread. In order to implement ProcessorLocal, it needs an
>>             API that returns the current processor id that the thread is
>>             running on. The HotSpot team has filed an RFE and are
>>             planning on providing such an API. (Many of you are already
>>             aware of this.)
>>
>>             I would like to share a story and some results to further
>>             the discussion on processor striping (i.e. ProcessorLocal).
>>
>>             A long time ago, we found that an Oracle C++ program
>>             bottlenecked on a reader/writer lock. Threads couldn't
>>             read-acquire the lock fast enough. The problem was due to
>>             the contention on the cache line while executing the CAS
>>             instruction. So, I striped the lock. The code non-atomically
>>             incremented an int and masked it to select one of the
>>             reader/writer locks. Multiple threads could end up selecting
>>             the same reader/writer lock because the int was incremented
>>             in an unprotected manner. If multiple threads selected the
>>             same reader/writer lock, the lock would handle the
>>             concurrency and the only negative was lock performance. This
>>             optimization worked great until Intel released Nehalem-EX.
>>
>>             A while ago, Intel found on Nehalem-EX that the same Oracle
>>             C++ program didn't scale to the 4?? Nehalem socket. All of
>>             the processors/cores were 100% busy, but the throughput
>>             didn't improve by adding the 4?? Nehalem socket. The problem
>>             was the cores were fighting to get the cache line holding
>>             the unprotected int!
>>
>>             I tried 4 approaches to select the reader/writer lock.
>>
>>             1) Processor id - This performed the best. The cache lines
>>             holding the reader/writer locks are almost never invalidated
>>             due to another core accessing the reader/writer lock. In
>>             other words, almost 0 CAS contention.
>>             2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to
>>             locks. It required too many locks and the locks had to
>>             migrate with the threads.
>>             3) Hash the stack pointer - Hashing the stack pointer caused
>>             some collisions but essentially randomly selected locks and
>>             this hurt cache performance.
>>             4) Shift and mask the cycle counter (i.e. rdtsc) -
>>             Contention was rare but again it randomly selected the locks.
>>
>>             Compared to non-atomically incrementing an int, processor id
>>             resulted in 15% more throughput. The other 3 only showed 5%
>>             more throughput.
>>
>>             Nathan Reynolds
>>            
>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>
>>             | Consulting Member of Technical Staff | 602.333.9091
>>             <tel:602.333.9091>
>>             Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>>             Technology
>>
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     --
>>     Antoine CHAMBILLE
>>     R&D Director
>>     Quartet FS
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From ach at quartetfs.com  Fri Oct 12 08:53:55 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Fri, 12 Oct 2012 14:53:55 +0200
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <50780D69.1070608@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
Message-ID: <CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>

Thanks for sharing.

This is a bit depressing though. The upcoming release of Java will probably
not have fine grained memory fences, neither support for processor affinity.

I am certainly to much focused on our own requirements (in-memory database,
TB heaps, tens of cores) but I feel that Java (once the best language in
the world for concurrent programming, when JDK5 was released) is not ready
for the many-cores era.


With respect to NUMA: in the medium term we will have to try exotic
deployments. For instance launching several JVMs, one per NUMA node, and
connect them with high-speed messaging. For messaging we are looking at
memory mapped buffers over files in a RAM drive (/dev/shm on Linux for
instance) or reusing a framework like "Chronicle" by Peter Lawrey (
https://github.com/peter-lawrey/Java-Chronicle).


-Antoine
Quartet FS



On 12 October 2012 14:30, Chris Hegarty <chris.hegarty at oracle.com> wrote:

> I am also not aware of any work being done on this, with respect to JDK8.
>
> -Chris.
>
>
> On 12/10/2012 12:43, David Holmes wrote:
>
>> Hi Antoine,
>> I've not seen any sign that this has moved toward an actual API proposal
>> so far. As the feature complete date for JDK 8 is January 31, I'd say
>> the chances of any such API appearing in JDK 8 would be slim. But
>> perhaps someone is fleshing this out quietly and will come forward with
>> a fully worked out API design and implementation.
>> David
>> -------
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces@**cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>>     [mailto:concurrency-interest-**bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>]*On
>> Behalf Of
>>     *Antoine Chambille
>>     *Sent:* Thursday, 11 October 2012 10:44 PM
>>     *To:* Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>     *Subject:* Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>>
>>
>>     After deploying the "ActivePivot" software (java in-memory analytics
>>     solution) on a new server we discovered how inefficient a large heap
>>     java application can be on NUMA system.
>>
>>     The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There
>>     are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads
>>     large amounts of data in memory (up to hundreds of GB) and then
>>     performs complex aggregation queries over the entire data, using a
>>     global fork/join pool. Although the data structures are partitioned,
>>     this partitioning is random with respect to NUMA nodes and
>>     processors. There is a sharp performance drop compared to smaller
>>     SMP servers.
>>
>>
>>     We are considering launching several JVMs, each bound to NUMA nodes,
>>     and communicating with each other. But that's an entire new layer of
>>     code, and this won't be quite as performant as processor id
>>     partitioning in one JVM.
>>
>>     I think that's another use case for the processor id API. I hope
>>     this RFE is making progress? Is there a chance to see it as part of
>>     JDK8?
>>
>>
>>     Regards,
>>     -Antoine CHAMBILLE
>>     Quartet FS
>>
>>
>>
>>
>>     On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au
>>     <mailto:davidcholmes at aapt.net.**au <davidcholmes at aapt.net.au>>>
>> wrote:
>>
>>         __
>>
>>         Aside: Just for the public record. I think an API to support use
>>         of Processor sets would be a useful addition to the platform to
>>         allow better partitioning of CPU resources. The Real-time
>>         Specification for Java 1.1 under JSR-282 is looking at such an
>>         API primarily to work in with OS level processor sets. For our
>>         purposes, more locally within the JVM the processors made
>>         available to the JVM could be partitioned both internally (ie
>>         binding GC to a specific set of cores) and at the
>>         application/library level (such as allocating ForkJoinPools
>>         disjoint sets of cores). The abiility to query the current
>>         processor ID is inherently needed and so I would make it part of
>>         the Processors class. This would provide the foundation API for
>>         ProcessortLocal.
>>         David Holmes
>>
>>             -----Original Message-----
>>             *From:* concurrency-interest-bounces@**cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>>             <mailto:concurrency-interest-**bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>> >
>>             [mailto:concurrency-interest-**bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>>             <mailto:concurrency-interest-**bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>> >]*On
>>             Behalf Of *Nathan Reynolds
>>             *Sent:* Thursday, 11 August 2011 2:38 AM
>>             *To:* concurrency-interest at cs.**oswego.edu<concurrency-interest at cs.oswego.edu>
>>             <mailto:concurrency-interest@**cs.oswego.edu<concurrency-interest at cs.oswego.edu>
>> >
>>             *Subject:* [concurrency-interest] ThreadLocal vs
>> ProcessorLocal
>>
>>
>>             I would like to recommend that we stripe data structures
>>             using a ProcessorLocal instead of ThreadLocal.
>>             ProcessorLocal (attached) is exactly like ThreadLocal except
>>             the stored objects keyed off of the processor instead of the
>>             thread. In order to implement ProcessorLocal, it needs an
>>             API that returns the current processor id that the thread is
>>             running on. The HotSpot team has filed an RFE and are
>>             planning on providing such an API. (Many of you are already
>>             aware of this.)
>>
>>             I would like to share a story and some results to further
>>             the discussion on processor striping (i.e. ProcessorLocal).
>>
>>             A long time ago, we found that an Oracle C++ program
>>             bottlenecked on a reader/writer lock. Threads couldn't
>>             read-acquire the lock fast enough. The problem was due to
>>             the contention on the cache line while executing the CAS
>>             instruction. So, I striped the lock. The code non-atomically
>>             incremented an int and masked it to select one of the
>>             reader/writer locks. Multiple threads could end up selecting
>>             the same reader/writer lock because the int was incremented
>>             in an unprotected manner. If multiple threads selected the
>>             same reader/writer lock, the lock would handle the
>>             concurrency and the only negative was lock performance. This
>>             optimization worked great until Intel released Nehalem-EX.
>>
>>             A while ago, Intel found on Nehalem-EX that the same Oracle
>>             C++ program didn't scale to the 4?? Nehalem socket. All of
>>             the processors/cores were 100% busy, but the throughput
>>             didn't improve by adding the 4?? Nehalem socket. The problem
>>             was the cores were fighting to get the cache line holding
>>             the unprotected int!
>>
>>             I tried 4 approaches to select the reader/writer lock.
>>
>>             1) Processor id - This performed the best. The cache lines
>>             holding the reader/writer locks are almost never invalidated
>>             due to another core accessing the reader/writer lock. In
>>             other words, almost 0 CAS contention.
>>             2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to
>>             locks. It required too many locks and the locks had to
>>             migrate with the threads.
>>             3) Hash the stack pointer - Hashing the stack pointer caused
>>             some collisions but essentially randomly selected locks and
>>             this hurt cache performance.
>>             4) Shift and mask the cycle counter (i.e. rdtsc) -
>>             Contention was rare but again it randomly selected the locks.
>>
>>             Compared to non-atomically incrementing an int, processor id
>>             resulted in 15% more throughput. The other 3 only showed 5%
>>             more throughput.
>>
>>             Nathan Reynolds
>>             <http://psr.us.oracle.com/**wiki/index.php/User:Nathan_**
>> Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>>
>>             | Consulting Member of Technical Staff | 602.333.9091
>>             <tel:602.333.9091>
>>             Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>>
>>             Technology
>>
>>
>>         ______________________________**_________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>         <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>
>>         http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>>     --
>>     Antoine CHAMBILLE
>>     R&D Director
>>     Quartet FS
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>


-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121012/c21ba4db/attachment.html>

From aleksey.shipilev at oracle.com  Fri Oct 12 09:07:03 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 12 Oct 2012 17:07:03 +0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
	<CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
Message-ID: <507815F7.4000307@oracle.com>

Depends on your definition of "Java", and your definition of "ready".
Nothing prevents you from using ProcessorLocal as the library, right?

Having the complete and ready library under liberal license will be the
major boost to include this into the JDK. Besides that, getting
something in the very popular platform is generally hard, and the
success stories from the frontier users of high-performance libraries
are certainly advocate the inclusion into JDK.

-Aleksey.

On 10/12/2012 04:53 PM, Antoine Chambille wrote:
> Thanks for sharing.
> 
> This is a bit depressing though. The upcoming release of Java will
> probably not have fine grained memory fences, neither support for
> processor affinity.
> 
> I am certainly to much focused on our own requirements (in-memory
> database, TB heaps, tens of cores) but I feel that Java (once the best
> language in the world for concurrent programming, when JDK5 was
> released) is not ready for the many-cores era.
> 
> 
> With respect to NUMA: in the medium term we will have to try exotic
> deployments. For instance launching several JVMs, one per NUMA node, and
> connect them with high-speed messaging. For messaging we are looking at
> memory mapped buffers over files in a RAM drive (/dev/shm on Linux for
> instance) or reusing a framework like "Chronicle" by Peter Lawrey
> (https://github.com/peter-lawrey/Java-Chronicle).
> 
> 
> -Antoine
> Quartet FS
> 
> 
> 
> On 12 October 2012 14:30, Chris Hegarty <chris.hegarty at oracle.com
> <mailto:chris.hegarty at oracle.com>> wrote:
> 
>     I am also not aware of any work being done on this, with respect to
>     JDK8.
> 
>     -Chris.
> 
> 
>     On 12/10/2012 12:43, David Holmes wrote:
> 
>         Hi Antoine,
>         I've not seen any sign that this has moved toward an actual API
>         proposal
>         so far. As the feature complete date for JDK 8 is January 31,
>         I'd say
>         the chances of any such API appearing in JDK 8 would be slim. But
>         perhaps someone is fleshing this out quietly and will come
>         forward with
>         a fully worked out API design and implementation.
>         David
>         -------
> 
>             -----Original Message-----
>             *From:* concurrency-interest-bounces at __cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>             [mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf Of
>             *Antoine Chambille
>             *Sent:* Thursday, 11 October 2012 10:44 PM
>             *To:* Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>             *Subject:* Re: [concurrency-interest] ThreadLocal vs
>         ProcessorLocal
> 
> 
>             After deploying the "ActivePivot" software (java in-memory
>         analytics
>             solution) on a new server we discovered how inefficient a
>         large heap
>             java application can be on NUMA system.
> 
>             The server has 4 sockets (8C Xeon CPU) with 512GB of memory.
>         There
>             are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads
>             large amounts of data in memory (up to hundreds of GB) and then
>             performs complex aggregation queries over the entire data,
>         using a
>             global fork/join pool. Although the data structures are
>         partitioned,
>             this partitioning is random with respect to NUMA nodes and
>             processors. There is a sharp performance drop compared to
>         smaller
>             SMP servers.
> 
> 
>             We are considering launching several JVMs, each bound to
>         NUMA nodes,
>             and communicating with each other. But that's an entire new
>         layer of
>             code, and this won't be quite as performant as processor id
>             partitioning in one JVM.
> 
>             I think that's another use case for the processor id API. I hope
>             this RFE is making progress? Is there a chance to see it as
>         part of
>             JDK8?
> 
> 
>             Regards,
>             -Antoine CHAMBILLE
>             Quartet FS
> 
> 
> 
> 
>             On 19 August 2011 01:22, David Holmes
>         <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>
>             <mailto:davidcholmes at aapt.net.__au
>         <mailto:davidcholmes at aapt.net.au>>> wrote:
> 
>                 __
> 
>                 Aside: Just for the public record. I think an API to
>         support use
>                 of Processor sets would be a useful addition to the
>         platform to
>                 allow better partitioning of CPU resources. The Real-time
>                 Specification for Java 1.1 under JSR-282 is looking at
>         such an
>                 API primarily to work in with OS level processor sets.
>         For our
>                 purposes, more locally within the JVM the processors made
>                 available to the JVM could be partitioned both
>         internally (ie
>                 binding GC to a specific set of cores) and at the
>                 application/library level (such as allocating ForkJoinPools
>                 disjoint sets of cores). The abiility to query the current
>                 processor ID is inherently needed and so I would make it
>         part of
>                 the Processors class. This would provide the foundation
>         API for
>                 ProcessortLocal.
>                 David Holmes
> 
>                     -----Original Message-----
>                     *From:* concurrency-interest-bounces at __cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>                     <mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>>
>                     [mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>                     <mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>>]*On
>                     Behalf Of *Nathan Reynolds
>                     *Sent:* Thursday, 11 August 2011 2:38 AM
>                     *To:* concurrency-interest at cs.__oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>
>                     <mailto:concurrency-interest at __cs.oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>>
>                     *Subject:* [concurrency-interest] ThreadLocal vs
>         ProcessorLocal
> 
> 
>                     I would like to recommend that we stripe data structures
>                     using a ProcessorLocal instead of ThreadLocal.
>                     ProcessorLocal (attached) is exactly like
>         ThreadLocal except
>                     the stored objects keyed off of the processor
>         instead of the
>                     thread. In order to implement ProcessorLocal, it
>         needs an
>                     API that returns the current processor id that the
>         thread is
>                     running on. The HotSpot team has filed an RFE and are
>                     planning on providing such an API. (Many of you are
>         already
>                     aware of this.)
> 
>                     I would like to share a story and some results to
>         further
>                     the discussion on processor striping (i.e.
>         ProcessorLocal).
> 
>                     A long time ago, we found that an Oracle C++ program
>                     bottlenecked on a reader/writer lock. Threads couldn't
>                     read-acquire the lock fast enough. The problem was
>         due to
>                     the contention on the cache line while executing the CAS
>                     instruction. So, I striped the lock. The code
>         non-atomically
>                     incremented an int and masked it to select one of the
>                     reader/writer locks. Multiple threads could end up
>         selecting
>                     the same reader/writer lock because the int was
>         incremented
>                     in an unprotected manner. If multiple threads
>         selected the
>                     same reader/writer lock, the lock would handle the
>                     concurrency and the only negative was lock
>         performance. This
>                     optimization worked great until Intel released
>         Nehalem-EX.
> 
>                     A while ago, Intel found on Nehalem-EX that the same
>         Oracle
>                     C++ program didn't scale to the 4?? Nehalem socket.
>         All of
>                     the processors/cores were 100% busy, but the throughput
>                     didn't improve by adding the 4?? Nehalem socket. The
>         problem
>                     was the cores were fighting to get the cache line
>         holding
>                     the unprotected int!
> 
>                     I tried 4 approaches to select the reader/writer lock.
> 
>                     1) Processor id - This performed the best. The cache
>         lines
>                     holding the reader/writer locks are almost never
>         invalidated
>                     due to another core accessing the reader/writer lock. In
>                     other words, almost 0 CAS contention.
>                     2) ThreadLocal - ThreadLocal had a 1:1 mapping of
>         threads to
>                     locks. It required too many locks and the locks had to
>                     migrate with the threads.
>                     3) Hash the stack pointer - Hashing the stack
>         pointer caused
>                     some collisions but essentially randomly selected
>         locks and
>                     this hurt cache performance.
>                     4) Shift and mask the cycle counter (i.e. rdtsc) -
>                     Contention was rare but again it randomly selected
>         the locks.
> 
>                     Compared to non-atomically incrementing an int,
>         processor id
>                     resulted in 15% more throughput. The other 3 only
>         showed 5%
>                     more throughput.
> 
>                     Nathan Reynolds
>                    
>         <http://psr.us.oracle.com/__wiki/index.php/User:Nathan___Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
> 
>                     | Consulting Member of Technical Staff |
>         602.333.9091 <tel:602.333.9091>
>                     <tel:602.333.9091 <tel:602.333.9091>>
>                     Oracle PSR Engineering <http://psr.us.oracle.com/> |
>         Server
> 
>                     Technology
> 
> 
>                 _________________________________________________
>                 Concurrency-interest mailing list
>                 Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>                 <mailto:Concurrency-interest at __cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>>
> 
>                
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> 
> 
>             --
>             Antoine CHAMBILLE
>             R&D Director
>             Quartet FS
> 
> 
> 
>         _________________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> 
> 
> -- 
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From gregg at cytetech.com  Fri Oct 12 10:13:13 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Fri, 12 Oct 2012 09:13:13 -0500
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
	<CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
Message-ID: <50782579.4050308@cytetech.com>

Why would you not go ahead an write your own JNI interface to the OS services 
for processor affinity just so that you could have the partitioning information? 
  From that point, it would seem that you could create the ProcessorLocal kind 
of functionality with some maps.

Gregg Wonderly

On 10/12/2012 7:53 AM, Antoine Chambille wrote:
> Thanks for sharing.
>
> This is a bit depressing though. The upcoming release of Java will probably not
> have fine grained memory fences, neither support for processor affinity.
>
> I am certainly to much focused on our own requirements (in-memory database, TB
> heaps, tens of cores) but I feel that Java (once the best language in the world
> for concurrent programming, when JDK5 was released) is not ready for the
> many-cores era.
>
>
> With respect to NUMA: in the medium term we will have to try exotic deployments.
> For instance launching several JVMs, one per NUMA node, and connect them with
> high-speed messaging. For messaging we are looking at memory mapped buffers over
> files in a RAM drive (/dev/shm on Linux for instance) or reusing a framework
> like "Chronicle" by Peter Lawrey (https://github.com/peter-lawrey/Java-Chronicle).
>
>
> -Antoine
> Quartet FS
>
>
>
> On 12 October 2012 14:30, Chris Hegarty <chris.hegarty at oracle.com
> <mailto:chris.hegarty at oracle.com>> wrote:
>
>     I am also not aware of any work being done on this, with respect to JDK8.
>
>     -Chris.
>
>
>     On 12/10/2012 12:43, David Holmes wrote:
>
>         Hi Antoine,
>         I've not seen any sign that this has moved toward an actual API proposal
>         so far. As the feature complete date for JDK 8 is January 31, I'd say
>         the chances of any such API appearing in JDK 8 would be slim. But
>         perhaps someone is fleshing this out quietly and will come forward with
>         a fully worked out API design and implementation.
>         David
>         -------
>
>              -----Original Message-----
>              *From:* concurrency-interest-bounces at __cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>              [mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>]*On Behalf Of
>              *Antoine Chambille
>              *Sent:* Thursday, 11 October 2012 10:44 PM
>              *To:* Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>              *Subject:* Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>
>
>              After deploying the "ActivePivot" software (java in-memory analytics
>              solution) on a new server we discovered how inefficient a large heap
>              java application can be on NUMA system.
>
>              The server has 4 sockets (8C Xeon CPU) with 512GB of memory. There
>              are 4 NUMA nodes each with 8 cores and 128GB. ActivePivot loads
>              large amounts of data in memory (up to hundreds of GB) and then
>              performs complex aggregation queries over the entire data, using a
>              global fork/join pool. Although the data structures are partitioned,
>              this partitioning is random with respect to NUMA nodes and
>              processors. There is a sharp performance drop compared to smaller
>              SMP servers.
>
>
>              We are considering launching several JVMs, each bound to NUMA nodes,
>              and communicating with each other. But that's an entire new layer of
>              code, and this won't be quite as performant as processor id
>              partitioning in one JVM.
>
>              I think that's another use case for the processor id API. I hope
>              this RFE is making progress? Is there a chance to see it as part of
>              JDK8?
>
>
>              Regards,
>              -Antoine CHAMBILLE
>              Quartet FS
>
>
>
>
>              On 19 August 2011 01:22, David Holmes <davidcholmes at aapt.net.au
>         <mailto:davidcholmes at aapt.net.au>
>              <mailto:davidcholmes at aapt.net.__au
>         <mailto:davidcholmes at aapt.net.au>>> wrote:
>
>                  __
>
>                  Aside: Just for the public record. I think an API to support use
>                  of Processor sets would be a useful addition to the platform to
>                  allow better partitioning of CPU resources. The Real-time
>                  Specification for Java 1.1 under JSR-282 is looking at such an
>                  API primarily to work in with OS level processor sets. For our
>                  purposes, more locally within the JVM the processors made
>                  available to the JVM could be partitioned both internally (ie
>                  binding GC to a specific set of cores) and at the
>                  application/library level (such as allocating ForkJoinPools
>                  disjoint sets of cores). The abiility to query the current
>                  processor ID is inherently needed and so I would make it part of
>                  the Processors class. This would provide the foundation API for
>                  ProcessortLocal.
>                  David Holmes
>
>                      -----Original Message-----
>                      *From:* concurrency-interest-bounces at __cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>                      <mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>>
>                      [mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>
>                      <mailto:concurrency-interest-__bounces at cs.oswego.edu
>         <mailto:concurrency-interest-bounces at cs.oswego.edu>>]*On
>                      Behalf Of *Nathan Reynolds
>                      *Sent:* Thursday, 11 August 2011 2:38 AM
>                      *To:* concurrency-interest at cs.__oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>
>                      <mailto:concurrency-interest at __cs.oswego.edu
>         <mailto:concurrency-interest at cs.oswego.edu>>
>                      *Subject:* [concurrency-interest] ThreadLocal vs ProcessorLocal
>
>
>                      I would like to recommend that we stripe data structures
>                      using a ProcessorLocal instead of ThreadLocal.
>                      ProcessorLocal (attached) is exactly like ThreadLocal except
>                      the stored objects keyed off of the processor instead of the
>                      thread. In order to implement ProcessorLocal, it needs an
>                      API that returns the current processor id that the thread is
>                      running on. The HotSpot team has filed an RFE and are
>                      planning on providing such an API. (Many of you are already
>                      aware of this.)
>
>                      I would like to share a story and some results to further
>                      the discussion on processor striping (i.e. ProcessorLocal).
>
>                      A long time ago, we found that an Oracle C++ program
>                      bottlenecked on a reader/writer lock. Threads couldn't
>                      read-acquire the lock fast enough. The problem was due to
>                      the contention on the cache line while executing the CAS
>                      instruction. So, I striped the lock. The code non-atomically
>                      incremented an int and masked it to select one of the
>                      reader/writer locks. Multiple threads could end up selecting
>                      the same reader/writer lock because the int was incremented
>                      in an unprotected manner. If multiple threads selected the
>                      same reader/writer lock, the lock would handle the
>                      concurrency and the only negative was lock performance. This
>                      optimization worked great until Intel released Nehalem-EX.
>
>                      A while ago, Intel found on Nehalem-EX that the same Oracle
>                      C++ program didn't scale to the 4?? Nehalem socket. All of
>                      the processors/cores were 100% busy, but the throughput
>                      didn't improve by adding the 4?? Nehalem socket. The problem
>                      was the cores were fighting to get the cache line holding
>                      the unprotected int!
>
>                      I tried 4 approaches to select the reader/writer lock.
>
>                      1) Processor id - This performed the best. The cache lines
>                      holding the reader/writer locks are almost never invalidated
>                      due to another core accessing the reader/writer lock. In
>                      other words, almost 0 CAS contention.
>                      2) ThreadLocal - ThreadLocal had a 1:1 mapping of threads to
>                      locks. It required too many locks and the locks had to
>                      migrate with the threads.
>                      3) Hash the stack pointer - Hashing the stack pointer caused
>                      some collisions but essentially randomly selected locks and
>                      this hurt cache performance.
>                      4) Shift and mask the cycle counter (i.e. rdtsc) -
>                      Contention was rare but again it randomly selected the locks.
>
>                      Compared to non-atomically incrementing an int, processor id
>                      resulted in 15% more throughput. The other 3 only showed 5%
>                      more throughput.
>
>                      Nathan Reynolds
>
>         <http://psr.us.oracle.com/__wiki/index.php/User:Nathan___Reynolds
>         <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>
>                      | Consulting Member of Technical Staff | 602.333.9091
>         <tel:602.333.9091>
>                      <tel:602.333.9091 <tel:602.333.9091>>
>                      Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>
>                      Technology
>
>
>                  _________________________________________________
>                  Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>                  <mailto:Concurrency-interest at __cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>>
>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
>              --
>              Antoine CHAMBILLE
>              R&D Director
>              Quartet FS
>
>
>
>         _________________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> --
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dl at cs.oswego.edu  Fri Oct 12 10:19:42 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 12 Oct 2012 10:19:42 -0400
Subject: [concurrency-interest] StampedLock
Message-ID: <507826FE.7010107@cs.oswego.edu>


As promised (several months ago) an initial version of
class jsr166e.StampedLock is now available. This is
a combined write/read/optimistic lock that has some nice
properties and good performance. For description, see
   http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html
And see the usual links from
   http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
for jsr166e jars and sources.

Reports about usage experiences would be very welcome!

SequenceLock is now moved to "jsr166e.extra" and no longer
a candidate for inclusion in JDK8.

-Doug

From dl at cs.oswego.edu  Fri Oct 12 11:57:03 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 12 Oct 2012 11:57:03 -0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
	<CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
Message-ID: <50783DCF.5070202@cs.oswego.edu>

On 10/12/12 08:53, Antoine Chambille wrote:

>
> I am certainly to much focused on our own requirements (in-memory database, TB
> heaps, tens of cores) but I feel that Java (once the best language in the world
> for concurrent programming, when JDK5 was released) is not ready for the
> many-cores era.

(JDK5 was back in the days where I could help implement new JVM support
(for atomics etc) and let it slip in under the radar because no one
else much cared about concurrency features.)


> With respect to NUMA: in the medium term we will have to try exotic deployments.

Even if you had NUMA information (for example, a distance metric among cores)
if all of your computations are fork/join-like, you'd also have to account
for the fact that some tasks (for example, sorting the upper half of an array)
are better off located further away (to reduce cache pollution) and some
(for example, reducing a sum) closer (to reduce traffic and exploit
cache sharing). Automating this is not easy. One approach that has
a chance of working reasonably well inside FJ is to associate affinity with
computation tree depth. But we don't yet have JVM support to try things
like this out.

In the mean time; the worst NUMA FJ effects I see on machines I test
on seem to be around 2X. A factor of two would be hard to make up for
using multiple JVMs, but might (depending on the OS and underlying
scheduling) be improved a bit by creating multiple FJPools,
and submitting affine tasks to each.

-Doug



From aleksey.shipilev at oracle.com  Fri Oct 12 12:11:06 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 12 Oct 2012 20:11:06 +0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507826FE.7010107@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu>
Message-ID: <5078411A.9060002@oracle.com>

On 10/12/2012 06:19 PM, Doug Lea wrote:
> 
> As promised (several months ago) an initial version of
> class jsr166e.StampedLock is now available. This is
> a combined write/read/optimistic lock that has some nice
> properties and good performance. For description, see
>  
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html
> 
> And see the usual links from
>   http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
> for jsr166e jars and sources.
> 
> Reports about usage experiences would be very welcome!

Not particularly a usage experience, but semantics question. What are
the memory semantics of SL methods? I would naively presume it dubs
usual RWLock semantics ("!hb" denotes the known "unspecified" cases):
   - unlock       hb readLock
   - unlockRead  !hb readLock
   - unlockWrite  hb readLock
   - unlock       hb tryOptimisticRead
   - unlockRead  !hb tryOptimisticRead
   - unlockWrite  hb tryOptimisticRead
   - unlock*      hb writeLock

Thanks,
Aleksey.



From dl at cs.oswego.edu  Fri Oct 12 12:29:33 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 12 Oct 2012 12:29:33 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <5078411A.9060002@oracle.com>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
Message-ID: <5078456D.5060500@cs.oswego.edu>

On 10/12/12 12:11, Aleksey Shipilev wrote:

> Not particularly a usage experience, but semantics question. What are
> the memory semantics of SL methods?

The effects are exactly the same as for the corresponding methods 
ReentrantReadWriteLock. They aren't fleshed out yet in the Javadoc
because cases involving OptimisticReads resist simple characterization
in JMMese. We'll find some way to do this, but in the mean time,
hopefully you can be comforted that they do what anyone would expect :-)

-Doug




From java at java4.info  Fri Oct 12 13:14:49 2012
From: java at java4.info (Florian Binder)
Date: Fri, 12 Oct 2012 19:14:49 +0200
Subject: [concurrency-interest] StampedLock
In-Reply-To: <5078456D.5060500@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu>
Message-ID: <50785009.9090404@java4.info>

In the Point example at [1] is it really necessary that x and y are 
volatile?
As far as I understand it if sl.validate(stamp) is true there must have 
been hb(sl.unlockWrite(stamp), sl.tryOptimisticRead (stamp)) and 
therefore the writes must have been visible. If it is not true we can 
not use currentX and currentY anyway and therefore it does not matter if 
the writes to the fields were treated as two separate writes.
Or do I miss something?

[1]: 
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html

-Flo



Am 12.10.2012 18:29, schrieb Doug Lea:
> On 10/12/12 12:11, Aleksey Shipilev wrote:
>
>> Not particularly a usage experience, but semantics question. What are
>> the memory semantics of SL methods?
>
> The effects are exactly the same as for the corresponding methods 
> ReentrantReadWriteLock. They aren't fleshed out yet in the Javadoc
> because cases involving OptimisticReads resist simple characterization
> in JMMese. We'll find some way to do this, but in the mean time,
> hopefully you can be comforted that they do what anyone would expect :-)
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121012/740b5230/attachment.html>

From dl at cs.oswego.edu  Fri Oct 12 13:39:21 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 12 Oct 2012 13:39:21 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <50785009.9090404@java4.info>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu> <50785009.9090404@java4.info>
Message-ID: <507855C9.3080409@cs.oswego.edu>

On 10/12/12 13:14, Florian Binder wrote:
> In the Point example at [1] is it really necessary that x and y are volatile?

No; thanks. Fixed.

In light of all the discussions on this list about fences, I should
note that the implementation currently uses an undocumented fact
about an unstandardized API (Unsafe) to get the effect of a load
fence in validate() and related methods. I am hoping that by
JDK8 release, it can instead use a documented method of Unsafe.

[1]: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html




-Doug



From zhong.j.yu at gmail.com  Fri Oct 12 16:17:54 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 12 Oct 2012 15:17:54 -0500
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507826FE.7010107@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu>
Message-ID: <CACuKZqFiX7jJQSE6niRBCTHeMgF0hVRtvoS3V-GLseJW5nGh+Q@mail.gmail.com>

The example calls optimisticRead()

   double distanceFromOriginV2() { // combines code paths
     for (long stamp = sl.optimisticRead(); ; stamp = sl.readLock()) {

but method optimisticRead() isn't defined?

On Fri, Oct 12, 2012 at 9:19 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>
> As promised (several months ago) an initial version of
> class jsr166e.StampedLock is now available. This is
> a combined write/read/optimistic lock that has some nice
> properties and good performance. For description, see
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html
> And see the usual links from
>   http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
> for jsr166e jars and sources.
>
> Reports about usage experiences would be very welcome!
>
> SequenceLock is now moved to "jsr166e.extra" and no longer
> a candidate for inclusion in JDK8.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Fri Oct 12 19:12:05 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 12 Oct 2012 19:12:05 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <CACuKZqFiX7jJQSE6niRBCTHeMgF0hVRtvoS3V-GLseJW5nGh+Q@mail.gmail.com>
References: <507826FE.7010107@cs.oswego.edu>
	<CACuKZqFiX7jJQSE6niRBCTHeMgF0hVRtvoS3V-GLseJW5nGh+Q@mail.gmail.com>
Message-ID: <5078A3C5.3040306@cs.oswego.edu>

On 10/12/12 16:17, Zhong Yu wrote:
> The example calls optimisticRead()
>
>     double distanceFromOriginV2() { // combines code paths
>       for (long stamp = sl.optimisticRead(); ; stamp = sl.readLock()) {
>

Thanks! This should be tryOptimisticRead(). Fixed.

-Doug

>>
>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html
>> And see the usual links from
>>    http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
>> for jsr166e jars and sources.
>>
>> Reports about usage experiences would be very welcome!


From martinrb at google.com  Sun Oct 14 15:45:01 2012
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 14 Oct 2012 12:45:01 -0700
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507826FE.7010107@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu>
Message-ID: <CA+kOe0__g8Y-dWCSGkRnqiE9FGKKp_u1Sq8vVNTmpkG_P-PG8Q@mail.gmail.com>

In tryConvertToWriteLock:

you are already checking that the WBITs match in

        while (((s = state) & SBITS) == (stamp & SBITS)) {

so the check  a < WBIT in

            else if (m == RUNIT && a != 0L && a < WBIT) {

can be removed.

---

Also, it would be more consistent with other methods to throw IMSE on
"impossible" stamps

E.g. here you just have a check for invalid stamps, but
                if (a != m)
                    break;
shouldn't you throw instead?

Alternatively, you could make this sharp knife even sharper and simply
assume all input stamps are always return stamps from a previous call, so
you never have both WBIT and RBITS.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121014/8fbf214e/attachment.html>

From ach at quartetfs.com  Mon Oct 15 04:28:33 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Mon, 15 Oct 2012 10:28:33 +0200
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <50783DCF.5070202@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
	<CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
	<50783DCF.5070202@cs.oswego.edu>
Message-ID: <CAJGQDwn2Sr=DDJ5Bbp14JB4uq0W0vfAK=AFfCibZ=kKNTOm+PA@mail.gmail.com>

Thanks for those explanations.

I agree that manually distributing JVMs on NUMA nodes won't magically
remove the NUMA effect (by the way I confirm that the performance drop we
measure with NUMA and a global fork/join pool is around 2X).

But for data stuctures that can be partitioned (an in-memory database is a
good candidate) and for which the computation workload can be expressed as
divide and conquer over those partitions, then I believe the performance
can be won back. An issue remains: the application deployment and
monitoring becomes much more complex.


Maybe Gregg is right, we should stop being shy and wrap a bit of JNI to
retrieve processor id or even better: set native thread affinity. I have
seen people doing it in relatively portable ways (
https://github.com/peter-lawrey/Java-Thread-Affinity ). That way within one
JVM we should be able to "physically" allocate one fork join pool per NUMA
node, partition the data, and make sure the pool that writes data to a
partition is also the pool that handles partial queries for it.


Oh and while on the subject of leveraging many cores, the newly released
StampedLock looks like a major contribution. Especially the
"Unsafe.getXVolatile" unofficial load fence disclosed by Doug that is an
important building block for software transactional memory and multiversion
data structures. That was a well-guarded secret ;)


-Antoine
Quartet FS




On 12 October 2012 17:57, Doug Lea <dl at cs.oswego.edu> wrote:

> On 10/12/12 08:53, Antoine Chambille wrote:
>
>
>> I am certainly to much focused on our own requirements (in-memory
>> database, TB
>> heaps, tens of cores) but I feel that Java (once the best language in the
>> world
>> for concurrent programming, when JDK5 was released) is not ready for the
>> many-cores era.
>>
>
> (JDK5 was back in the days where I could help implement new JVM support
> (for atomics etc) and let it slip in under the radar because no one
> else much cared about concurrency features.)
>
>
>
>  With respect to NUMA: in the medium term we will have to try exotic
>> deployments.
>>
>
> Even if you had NUMA information (for example, a distance metric among
> cores)
> if all of your computations are fork/join-like, you'd also have to account
> for the fact that some tasks (for example, sorting the upper half of an
> array)
> are better off located further away (to reduce cache pollution) and some
> (for example, reducing a sum) closer (to reduce traffic and exploit
> cache sharing). Automating this is not easy. One approach that has
> a chance of working reasonably well inside FJ is to associate affinity with
> computation tree depth. But we don't yet have JVM support to try things
> like this out.
>
> In the mean time; the worst NUMA FJ effects I see on machines I test
> on seem to be around 2X. A factor of two would be hard to make up for
> using multiple JVMs, but might (depending on the OS and underlying
> scheduling) be improved a bit by creating multiple FJPools,
> and submitting affine tasks to each.
>
> -Doug
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/4c29b055/attachment.html>

From aleksey.shipilev at oracle.com  Mon Oct 15 05:24:03 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Mon, 15 Oct 2012 13:24:03 +0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJGQDwn2Sr=DDJ5Bbp14JB4uq0W0vfAK=AFfCibZ=kKNTOm+PA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEFOJHAA.davidcholmes@aapt.net.au>
	<50780D69.1070608@oracle.com>
	<CAJGQDwmjWfBOcgG3ea3Y1RD+mUE6SQ3KR8G9Vey0MLvKQPf50A@mail.gmail.com>
	<50783DCF.5070202@cs.oswego.edu>
	<CAJGQDwn2Sr=DDJ5Bbp14JB4uq0W0vfAK=AFfCibZ=kKNTOm+PA@mail.gmail.com>
Message-ID: <507BD633.1000207@oracle.com>

On 10/15/2012 12:28 PM, Antoine Chambille wrote:
> I agree that manually distributing JVMs on NUMA nodes won't magically
> remove the NUMA effect (by the way I confirm that the performance drop
> we measure with NUMA and a global fork/join pool is around 2X).

Are you by any chance use old FJP which has the global submission lock?
Had you tried to do this with jsr166.jar bootclasspath'ed?

> Oh and while on the subject of leveraging many cores, the newly released
> StampedLock looks like a major contribution. Especially the
> "Unsafe.getXVolatile" unofficial load fence disclosed by Doug that is an
> important building block for software transactional memory and
> multiversion data structures. That was a well-guarded secret ;)

[Captain Obvious mode]
This is a huge can of worms. You should *NOT* rely on this lfence
semantics in production code. Doug is using that transitionally, until
the proper JVM support is provided for these cases.
[/Captain Obvious mode]

-Aleksey.

From rco at quartetfs.com  Mon Oct 15 05:38:02 2012
From: rco at quartetfs.com (Romain Colle)
Date: Mon, 15 Oct 2012 11:38:02 +0200
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507855C9.3080409@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu> <50785009.9090404@java4.info>
	<507855C9.3080409@cs.oswego.edu>
Message-ID: <CAJp3eRAmT9wWqLJOF+LMy-26TgNZ7k8MHePfac=n+TUeF3=WWA@mail.gmail.com>

Thanks for releasing this StampedLock, this looks great!

On Fri, Oct 12, 2012 at 7:39 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> In light of all the discussions on this list about fences, I should
> note that the implementation currently uses an undocumented fact
> about an unstandardized API (Unsafe) to get the effect of a load
> fence in validate() and related methods. I am hoping that by
> JDK8 release, it can instead use a documented method of Unsafe.
>

Out of curiosity, do you mean that a call to Unsafe.getXXVolatile() does
also issue a LoadLoad barrier before its read?
Are there any reasons why this is the case, in addition to the post-read
fence of a regular volatile read?

Thanks!

-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/c5f1f125/attachment.html>

From heinz at javaspecialists.eu  Mon Oct 15 06:51:06 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 15 Oct 2012 13:51:06 +0300
Subject: [concurrency-interest] StampedLock
In-Reply-To: <5078A3C5.3040306@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu>	<CACuKZqFiX7jJQSE6niRBCTHeMgF0hVRtvoS3V-GLseJW5nGh+Q@mail.gmail.com>
	<5078A3C5.3040306@cs.oswego.edu>
Message-ID: <507BEA9A.2010904@javaspecialists.eu>

A few more minor gotchas about the Point example.

We should probably make the class Point and its methods public.

Then, in distanceFromOriginV2(), the local variables currentX and 
currentY need to be initialized to zero, otherwise the compiler 
complains.  So distanceFromOriginV2() should probably be:

   public double distanceFromOriginV2() { // combines code paths
     for (long stamp = sl.tryOptimisticRead(); ; stamp = sl.readLock()) {
       double currentX=0, currentY=0;
       try {
         currentX = x;
         currentY = y;
       } finally {
         if (sl.tryConvertToOptimisticRead(stamp) != 0L) // unlock or 
validate
           return Math.sqrt(currentX * currentX + currentY * currentY);
       }
     }
   }

Lastly, in moveIfAtOrigin, we have another typo.  It should be

         long ws = sl.tryConvertToWriteLock(stamp);

instead of

         long ws = tryConvertToWriteLock(stamp);

These are all very minor issues.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz 



On 10/13/12 2:12 AM, Doug Lea wrote:
> On 10/12/12 16:17, Zhong Yu wrote:
>> The example calls optimisticRead()
>>
>>     double distanceFromOriginV2() { // combines code paths
>>       for (long stamp = sl.optimisticRead(); ; stamp = sl.readLock()) {
>>
>
> Thanks! This should be tryOptimisticRead(). Fixed.
>
> -Doug
>
>>>
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html 
>>>
>>> And see the usual links from
>>>    http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
>>> for jsr166e jars and sources.
>>>
>>> Reports about usage experiences would be very welcome!
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dl at cs.oswego.edu  Mon Oct 15 07:51:20 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Oct 2012 07:51:20 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <CA+kOe0__g8Y-dWCSGkRnqiE9FGKKp_u1Sq8vVNTmpkG_P-PG8Q@mail.gmail.com>
References: <507826FE.7010107@cs.oswego.edu>
	<CA+kOe0__g8Y-dWCSGkRnqiE9FGKKp_u1Sq8vVNTmpkG_P-PG8Q@mail.gmail.com>
Message-ID: <507BF8B8.2040002@cs.oswego.edu>

On 10/14/12 15:45, Martin Buchholz wrote:
> In tryConvertToWriteLock:
> so the check  a < WBIT in
>
>              else if (m == RUNIT && a != 0L && a < WBIT) {
>
> can be removed.
>

Thanks!

> ---
>
> Also, it would be more consistent with other methods to throw IMSE on
> "impossible" stamps

This is a borderline case but the convention in all try- methods is that
failure tells you nothing about the state of the lock or even the stamp.
We must do this for the sake of (not yet present) full memory specs.
We must not make promises about crazy "backwards"
usages where locked means go and unlocked means stop.
See Hans's http://www.hpl.hp.com/techreports/2005/HPL-2005-217R1.html

>
> Alternatively, you could make this sharp knife...

The knife is not very sharp at all when you use it
as an internal utility in the development of thread-safe
components. But is almost never useful otherwise. I reworked
javadocs to clarify this.

-Doug



From yechielf at gigaspaces.com  Mon Oct 15 08:19:26 2012
From: yechielf at gigaspaces.com (Yechiel Feffer)
Date: Mon, 15 Oct 2012 12:19:26 +0000
Subject: [concurrency-interest] regarding StampedLock
Message-ID: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>

Are the read & write locks more efficient than the ReentrantReadWriteLock mothods (in its non-fair mode) ? is there a reason to replace current ReentrantReadWriteLock with the stamped one ?

Thanks
Yechiel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/dc675602/attachment.html>

From dl at cs.oswego.edu  Mon Oct 15 08:22:37 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Oct 2012 08:22:37 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <CAJp3eRAmT9wWqLJOF+LMy-26TgNZ7k8MHePfac=n+TUeF3=WWA@mail.gmail.com>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu> <50785009.9090404@java4.info>
	<507855C9.3080409@cs.oswego.edu>
	<CAJp3eRAmT9wWqLJOF+LMy-26TgNZ7k8MHePfac=n+TUeF3=WWA@mail.gmail.com>
Message-ID: <507C000D.7050500@cs.oswego.edu>

On 10/15/12 05:38, Romain Colle wrote:
> Out of curiosity, do you mean that a call to Unsafe.getXXVolatile() does also
> issue a LoadLoad barrier before its read?
> Are there any reasons why this is the case, in addition to the post-read fence
> of a regular volatile read?
>

First, I'll echo Aleksey's plea for others to please not use this.
The effects rely on an undocumented property of an internal JVM
method that cannot even be formally spec'ed under the current JMM.
We hope to have a better solution by JDK8 release.
But for the curious: Because Unsafe.getXXVolatile does not know if
its argument is even declared as a volatile, in the absence
of magically powerful global analyses, it must conservatively
prevent reorderings in either direction. And at least in
OpenJDK hotspot, the implementation is aware of this fact and
acts accordingly.

-Doug




From dl at cs.oswego.edu  Mon Oct 15 08:34:12 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Oct 2012 08:34:12 -0400
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
Message-ID: <507C02C4.9030209@cs.oswego.edu>

On 10/15/12 08:19, Yechiel Feffer wrote:
> Are the read & write locks more efficient than the ReentrantReadWriteLockmothods
> (in its non-fair mode) ? is there a reason to replace current
> ReentrantReadWriteLock with the stamped one ?
>

Typically yes. For example, some tests protecting TreeMaps with
StampedLock vs RRWL run very noticeably faster under
most contention levels and method mixes.
This used Optimistic mode only for a few tiny methods
like size() -- as mentioned before, effective use of ANY
Read-Write lock requires that you know something about the
data, objects, and methods they protect. This is why we cannot
offer generic RW-based collection wrappers. For example, even
method get() is not side-effect-free in LinkedHashMap, so
you cannot use a read-lock around it.

While I'm at it: Thanks to all for on- and off-list suggestions,
most of which I incorporated:
http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/StampedLock.html
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/StampedLock.java?view=log

-Doug




From heinz at javaspecialists.eu  Mon Oct 15 11:34:12 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 15 Oct 2012 18:34:12 +0300
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C233D.4030107@cs.oswego.edu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
Message-ID: <507C2CF4.9080906@javaspecialists.eu>

On 10/15/12 5:52 PM, Doug Lea wrote:
> On 10/15/12 10:46, Dr Heinz M. Kabutz wrote:
>
>> On my little dual core laptop, there is not too much starvation of 
>> neither the
>> readers nor the writers.  But on my 8-core server, the writers are 
>> almost
>> totally starved when I have a lot of readers running.  I'll format 
>> the results
>> and send them to you.
>>
> It surprises me that the Phase-Fair antistarvation approximation is
> letting this happen. I don't see it in the tests I have for it,
> but if you sent me your code I could better check if this is
> a matter of improving the approximation or of a phenomenon somehow
> not covered by them.
Hi Doug,

my performance test is based on some starvation research I did in 2008 
regarding ReadWriteLock: http://www.javaspecialists.eu/archive/Issue165.html

However, this time I used your Point class, with a few modifications.  I 
removed the Math.sqrt() function, as I felt it might be too 
computationally significant.  Instead, I return some random 
multiplication that happens to always be zero.  However, it is not that 
obvious that it will always be zero, so I believe that the HotSpot 
compiler won't optimize it away.  It actually returns 1 if the test 
needed to resort to a pessimistic lock and 0 if it managed to read the 
values optimistically.  This way I can figure out how many of the reads 
were optimistically successful.

Big numbers mean high throughput and low numbers low throughput.  I 
basically try to call a reading and writing method from the given 
threads as often as I can within one second.

The performance results are interesting.  Reading always outperforms the 
ReadWriteLock, distanceFromOriginV2() approach, which I believe is how I 
would write the code.  It is the most elegant of the various options.

To those who were asking, yes, the reading was always more efficient in 
my tests than ReadWriteLock (third last column in my spreadsheet - 
StampedLock / ReadWriteLock read ratio).  In some cases it was almost 
4000x faster in the uncontended case.  That's a good reason to use it.

However, the writing it appears is not always faster.  If you look at 
the second last column in the spreadsheet (StampedLock / ReadWriteLock 
write ratio), you will see that if you have two readers and a lot of 
writers, then the ReadWriteLock is faster.  Since the StampedLock does 
not have a "fair" option (thank goodness for that!) we cannot compare 
those values, but they will definitely be worse than any of the values 
we see here (refer to 
http://www.javaspecialists.eu/archive/Issue165.html for a "fair" lock 
experiment).

A point to note here: These results are on my 8-core dual processor 
server running Linux that I run most of my performance tests on.  The 
writers do not degrade as badly on my dual core MacBook Pro.  So this 
might be a phenomenon of my particular hardware.

The last column is also interesting.  It shows how many of the 
optimistic writes were successful.  The worst case was when we had one 
reader and one writer thread.  Only 0.54% of the time did we manage to 
get the right values with the optimistic read.  The second-worst was 
with 7 readers and 1 writer.  We only managed 7.98%





-------------- next part --------------
A non-text attachment was scrubbed...
Name: performance_results.pdf
Type: application/pdf
Size: 36572 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/c19bfb21/attachment-0001.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: stampedlocktest.jar
Type: application/java-archive
Size: 14305 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/c19bfb21/attachment-0001.bin>

From stanimir at riflexo.com  Mon Oct 15 12:37:06 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Mon, 15 Oct 2012 19:37:06 +0300
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C2CF4.9080906@javaspecialists.eu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
	<507C2CF4.9080906@javaspecialists.eu>
Message-ID: <CAEJX8or7emRuRBuoKEXXUkUxp4zcR5s_SxTOm_j4Q2_rybg21Q@mail.gmail.com>

Few notes about the test:
- java.util.Random is thread safe and still uses one CAS per random int and
a double needs 2 ints. While the CAS will be uncontended the store buffers
are to be always empty while entering the "lock()". You may simplify the
test to use ints only.
- IMO, numberOfPessimisticReads/numberOfLockAcquisitions should not be
volatile either as they don't need so and writing them also flushes the CPU
buffers.

Stanimir

On Mon, Oct 15, 2012 at 6:34 PM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> On 10/15/12 5:52 PM, Doug Lea wrote:
>
>> On 10/15/12 10:46, Dr Heinz M. Kabutz wrote:
>>
>>  On my little dual core laptop, there is not too much starvation of
>>> neither the
>>> readers nor the writers.  But on my 8-core server, the writers are almost
>>> totally starved when I have a lot of readers running.  I'll format the
>>> results
>>> and send them to you.
>>>
>>>  It surprises me that the Phase-Fair antistarvation approximation is
>> letting this happen. I don't see it in the tests I have for it,
>> but if you sent me your code I could better check if this is
>> a matter of improving the approximation or of a phenomenon somehow
>> not covered by them.
>>
> Hi Doug,
>
> my performance test is based on some starvation research I did in 2008
> regarding ReadWriteLock: http://www.javaspecialists.eu/**
> archive/Issue165.html<http://www.javaspecialists.eu/archive/Issue165.html>
>
> However, this time I used your Point class, with a few modifications.  I
> removed the Math.sqrt() function, as I felt it might be too computationally
> significant.  Instead, I return some random multiplication that happens to
> always be zero.  However, it is not that obvious that it will always be
> zero, so I believe that the HotSpot compiler won't optimize it away.  It
> actually returns 1 if the test needed to resort to a pessimistic lock and 0
> if it managed to read the values optimistically.  This way I can figure out
> how many of the reads were optimistically successful.
>
> Big numbers mean high throughput and low numbers low throughput.  I
> basically try to call a reading and writing method from the given threads
> as often as I can within one second.
>
> The performance results are interesting.  Reading always outperforms the
> ReadWriteLock, distanceFromOriginV2() approach, which I believe is how I
> would write the code.  It is the most elegant of the various options.
>
> To those who were asking, yes, the reading was always more efficient in my
> tests than ReadWriteLock (third last column in my spreadsheet - StampedLock
> / ReadWriteLock read ratio).  In some cases it was almost 4000x faster in
> the uncontended case.  That's a good reason to use it.
>
> However, the writing it appears is not always faster.  If you look at the
> second last column in the spreadsheet (StampedLock / ReadWriteLock write
> ratio), you will see that if you have two readers and a lot of writers,
> then the ReadWriteLock is faster.  Since the StampedLock does not have a
> "fair" option (thank goodness for that!) we cannot compare those values,
> but they will definitely be worse than any of the values we see here (refer
> to http://www.javaspecialists.eu/**archive/Issue165.html<http://www.javaspecialists.eu/archive/Issue165.html>for a "fair" lock experiment).
>
> A point to note here: These results are on my 8-core dual processor server
> running Linux that I run most of my performance tests on.  The writers do
> not degrade as badly on my dual core MacBook Pro.  So this might be a
> phenomenon of my particular hardware.
>
> The last column is also interesting.  It shows how many of the optimistic
> writes were successful.  The worst case was when we had one reader and one
> writer thread.  Only 0.54% of the time did we manage to get the right
> values with the optimistic read.  The second-worst was with 7 readers and 1
> writer.  We only managed 7.98%
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/d7f75d13/attachment.html>

From heinz at javaspecialists.eu  Mon Oct 15 13:27:58 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 15 Oct 2012 20:27:58 +0300
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <CAEJX8or7emRuRBuoKEXXUkUxp4zcR5s_SxTOm_j4Q2_rybg21Q@mail.gmail.com>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>	<507C02C4.9030209@cs.oswego.edu>	<507C0716.8020801@javaspecialists.eu>	<507C0D13.3070508@cs.oswego.edu>	<507C21DE.8090502@javaspecialists.eu>	<507C233D.4030107@cs.oswego.edu>	<507C2CF4.9080906@javaspecialists.eu>
	<CAEJX8or7emRuRBuoKEXXUkUxp4zcR5s_SxTOm_j4Q2_rybg21Q@mail.gmail.com>
Message-ID: <507C479E.7000307@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/9d03dc84/attachment.html>

From heinz at javaspecialists.eu  Mon Oct 15 13:45:47 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 15 Oct 2012 20:45:47 +0300
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C479E.7000307@javaspecialists.eu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>	<507C02C4.9030209@cs.oswego.edu>	<507C0716.8020801@javaspecialists.eu>	<507C0D13.3070508@cs.oswego.edu>	<507C21DE.8090502@javaspecialists.eu>	<507C233D.4030107@cs.oswego.edu>	<507C2CF4.9080906@javaspecialists.eu>
	<CAEJX8or7emRuRBuoKEXXUkUxp4zcR5s_SxTOm_j4Q2_rybg21Q@mail.gmail.com>
	<507C479E.7000307@javaspecialists.eu>
Message-ID: <507C4BCB.2000702@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/c2cc090e/attachment-0001.html>

From dl at cs.oswego.edu  Mon Oct 15 14:38:19 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 15 Oct 2012 14:38:19 -0400
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C2CF4.9080906@javaspecialists.eu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
	<507C2CF4.9080906@javaspecialists.eu>
Message-ID: <507C581B.9050701@cs.oswego.edu>

Thanks!

On 10/15/12 11:34, Dr Heinz M. Kabutz wrote:
>
> The performance results are interesting.  Reading always outperforms the
> ReadWriteLock, distanceFromOriginV2() approach, which I believe is how I would
> write the code.  It is the most elegant of the various options.
>
> To those who were asking, yes, the reading was always more efficient in my tests
> than ReadWriteLock (third last column in my spreadsheet - StampedLock /
> ReadWriteLock read ratio).  In some cases it was almost 4000x faster in the
> uncontended case.  That's a good reason to use it.
>
> However, the writing it appears is not always faster.

... mainly due to writer starvation. (In writer-only tests, they are
always faster.) In your tests, the reader blocks are so quick that
lots of them can get in and out before writer queuing
stabilizes so that phase-fair rules can kick in, at which point the writer
will often hit an expensive context switch and have the lock stolen away
while it is in the process of waking up. There are some mechanics for
reducing/avoiding this that I'll put it.

-Doug


From david.dice at gmail.com  Mon Oct 15 16:03:07 2012
From: david.dice at gmail.com (David Dice)
Date: Mon, 15 Oct 2012 16:03:07 -0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
Message-ID: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>

> Message: 2
> Date: Mon, 15 Oct 2012 10:28:33 +0200
> From: Antoine Chambille <ach at quartetfs.com>
> To: concurrency-interest at cs.oswego.edu
> Cc: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
> Message-ID:
>         <CAJGQDwn2Sr=DDJ5Bbp14JB4uq0W0vfAK=AFfCibZ=
> kKNTOm+PA at mail.gmail.com>
> Content-Type: text/plain; charset="iso-8859-1"
>
> Thanks for those explanations.
>
> I agree that manually distributing JVMs on NUMA nodes won't magically
> remove the NUMA effect (by the way I confirm that the performance drop we
> measure with NUMA and a global fork/join pool is around 2X).
>
> But for data stuctures that can be partitioned (an in-memory database is a
> good candidate) and for which the computation workload can be expressed as
> divide and conquer over those partitions, then I believe the performance
> can be won back. An issue remains: the application deployment and
> monitoring becomes much more complex.
>
>
> Maybe Gregg is right, we should stop being shy and wrap a bit of JNI to
> retrieve processor id or even better: set native thread affinity. I have
> seen people doing it in relatively portable ways (
> https://github.com/peter-lawrey/Java-Thread-Affinity ). That way within
> one
> JVM we should be able to "physically" allocate one fork join pool per NUMA
> node, partition the data, and make sure the pool that writes data to a
> partition is also the pool that handles partial queries for it.
>
>
> Oh and while on the subject of leveraging many cores, the newly released
> StampedLock looks like a major contribution. Especially the
> "Unsafe.getXVolatile" unofficial load fence disclosed by Doug that is an
> important building block for software transactional memory and multiversion
> data structures. That was a well-guarded secret ;)
>
>
> -Antoine
> Quartet FS
>
>
An alternative to binding or otherwise forcing thread placement is to make
NUMA-aware data structures that tolerate ambient thread placement.
https://blogs.oracle.com/dave/resource/NUMA-aware-JUCExchanger.pdf gives a
brief sketch on how this was applied to JUC Exchanger, but it's applicable
to other constructs as well.

Regards
Dave

p.s., it's also easy to create NUMA-friendly locks :
https://blogs.oracle.com/dave/entry/lock_cohorting_to_appear_in
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121015/4d09f52a/attachment.html>

From hans.boehm at hp.com  Mon Oct 15 23:21:19 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Tue, 16 Oct 2012 03:21:19 +0000
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507C000D.7050500@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu> <50785009.9090404@java4.info>
	<507855C9.3080409@cs.oswego.edu>
	<CAJp3eRAmT9wWqLJOF+LMy-26TgNZ7k8MHePfac=n+TUeF3=WWA@mail.gmail.com>
	<507C000D.7050500@cs.oswego.edu>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235F8EAAA@G4W3296.americas.hpqcorp.net>

> From: Doug Lea
> 
> On 10/15/12 05:38, Romain Colle wrote:
> > Out of curiosity, do you mean that a call to Unsafe.getXXVolatile()
> does also
> > issue a LoadLoad barrier before its read?
> > Are there any reasons why this is the case, in addition to the post-
> read fence
> > of a regular volatile read?
> >
> 
> First, I'll echo Aleksey's plea for others to please not use this.
> The effects rely on an undocumented property of an internal JVM
> method that cannot even be formally spec'ed under the current JMM.
> We hope to have a better solution by JDK8 release.
> But for the curious: Because Unsafe.getXXVolatile does not know if
> its argument is even declared as a volatile, in the absence
> of magically powerful global analyses, it must conservatively
> prevent reorderings in either direction.
Doug -

I still don't understand the reasoning here.  Do you have an example where it matters whether the argument is declared as volatile?  I'm assuming the writing side must still use a corresponding (or volatile) access?

Thanks.

Hans

> And at least in
> OpenJDK hotspot, the implementation is aware of this fact and
> acts accordingly.
> 
> -Doug
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Tue Oct 16 16:27:31 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 16 Oct 2012 16:27:31 -0400
Subject: [concurrency-interest] StampedLock
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F8EAAA@G4W3296.americas.hpqcorp.net>
References: <507826FE.7010107@cs.oswego.edu> <5078411A.9060002@oracle.com>
	<5078456D.5060500@cs.oswego.edu> <50785009.9090404@java4.info>
	<507855C9.3080409@cs.oswego.edu>
	<CAJp3eRAmT9wWqLJOF+LMy-26TgNZ7k8MHePfac=n+TUeF3=WWA@mail.gmail.com>
	<507C000D.7050500@cs.oswego.edu>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F8EAAA@G4W3296.americas.hpqcorp.net>
Message-ID: <507DC333.7090908@cs.oswego.edu>

On 10/15/12 23:21, Boehm, Hans wrote:

>> But for the curious: Because Unsafe.getXXVolatile does not know if its
>> argument is even declared as a volatile, in the absence of magically
>> powerful global analyses, it must conservatively prevent reorderings in
>> either direction.

>
> I still don't understand the reasoning here.  Do you have an example where it
> matters whether the argument is declared as volatile?  I'm assuming the
> writing side must still use a corresponding (or volatile) access?
>

Yes, but a compiler could otherwise lose track of compiler reordering
constraints. Imagine the read inside a loop, so that non-volatile
reordering might mean moving out/up. The only reasonable path is to
treat it as non-reorderable all the way through. In any case
(reasonable or not :-) this is what they do.

-Doug



From dl at cs.oswego.edu  Tue Oct 16 18:56:16 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 16 Oct 2012 18:56:16 -0400
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C2CF4.9080906@javaspecialists.eu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
	<507C2CF4.9080906@javaspecialists.eu>
Message-ID: <507DE610.2060609@cs.oswego.edu>

On 10/15/12 11:34, Dr Heinz M. Kabutz wrote:

> my performance test is based on some starvation research I did in 2008 regarding
> ReadWriteLock: http://www.javaspecialists.eu/archive/Issue165.html
>

I'm still exploring some different policy options, but here's a quick
note on your test: If you report locks per thread, rather than total locks,
then starvation tendencies across varying numbers of readers vs writers
(keeping total the same) are easier to describe: For a writer, you expect
approximately the same lock rate whether the other locking threads are
readers vs writers. The overall rates may differ across different hold
times etc but for each choice, this property should hold for
starvation-avoiding RW Locks.  (A similar but less simple property
should hold for readers.)

-Doug



From heinz at javaspecialists.eu  Tue Oct 16 19:00:08 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 17 Oct 2012 02:00:08 +0300
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507DE610.2060609@cs.oswego.edu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
	<507C2CF4.9080906@javaspecialists.eu>
	<507DE610.2060609@cs.oswego.edu>
Message-ID: <CACLL95o8_w2MpLe=RwLvnkmmg00pParEVJ0fwe90G7UFLrHwRw@mail.gmail.com>

The readers are probably tag-teaming each other, just like they did in Java 5.

On 17/10/2012, Doug Lea <dl at cs.oswego.edu> wrote:
> On 10/15/12 11:34, Dr Heinz M. Kabutz wrote:
>
>> my performance test is based on some starvation research I did in 2008
>> regarding
>> ReadWriteLock: http://www.javaspecialists.eu/archive/Issue165.html
>>
>
> I'm still exploring some different policy options, but here's a quick
> note on your test: If you report locks per thread, rather than total locks,
> then starvation tendencies across varying numbers of readers vs writers
> (keeping total the same) are easier to describe: For a writer, you expect
> approximately the same lock rate whether the other locking threads are
> readers vs writers. The overall rates may differ across different hold
> times etc but for each choice, this property should hold for
> starvation-avoiding RW Locks.  (A similar but less simple property
> should hold for readers.)
>
> -Doug
>
>
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz

From kirk at kodewerk.com  Wed Oct 17 03:15:16 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 17 Oct 2012 08:15:16 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
Message-ID: <D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>

Hi David,

I wish that NUMA would handle this so that one wouldn't need to explicitly code in thread affinity but I fear that a working with a strong hint from a developer feels like a reasonable compromise.knowledge. In deed, Peter Lawrey has a project on github that makes some attempt at setting native thread affinity. That said, you comment about the dangers of making local decisions in the absence of global knowledge that are re-enforced in your CPUID blog posting are spot on. Since the CPU has that global view.....

SOT, right now we are using CPUID for a number of reasons. Very easy to get to on Linux as we can do this in pure Java. However other platforms require C++/assembler so having <gulp> an unsafe operation in the JVM would be a win from my POV.

Regards,
Kirk

On 2012-10-15, at 9:03 PM, David Dice <david.dice at gmail.com> wrote:

> 
> Message: 2
> Date: Mon, 15 Oct 2012 10:28:33 +0200
> From: Antoine Chambille <ach at quartetfs.com>
> To: concurrency-interest at cs.oswego.edu
> Cc: Doug Lea <dl at cs.oswego.edu>
> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
> Message-ID:
>         <CAJGQDwn2Sr=DDJ5Bbp14JB4uq0W0vfAK=AFfCibZ=kKNTOm+PA at mail.gmail.com>
> Content-Type: text/plain; charset="iso-8859-1"
> 
> Thanks for those explanations.
> 
> I agree that manually distributing JVMs on NUMA nodes won't magically
> remove the NUMA effect (by the way I confirm that the performance drop we
> measure with NUMA and a global fork/join pool is around 2X).
> 
> But for data stuctures that can be partitioned (an in-memory database is a
> good candidate) and for which the computation workload can be expressed as
> divide and conquer over those partitions, then I believe the performance
> can be won back. An issue remains: the application deployment and
> monitoring becomes much more complex.
> 
> 
> Maybe Gregg is right, we should stop being shy and wrap a bit of JNI to
> retrieve processor id or even better: set native thread affinity. I have
> seen people doing it in relatively portable ways (
> https://github.com/peter-lawrey/Java-Thread-Affinity ). That way within one
> JVM we should be able to "physically" allocate one fork join pool per NUMA
> node, partition the data, and make sure the pool that writes data to a
> partition is also the pool that handles partial queries for it.
> 
> 
> Oh and while on the subject of leveraging many cores, the newly released
> StampedLock looks like a major contribution. Especially the
> "Unsafe.getXVolatile" unofficial load fence disclosed by Doug that is an
> important building block for software transactional memory and multiversion
> data structures. That was a well-guarded secret ;)
> 
> 
> -Antoine
> Quartet FS
> 
> 
> An alternative to binding or otherwise forcing thread placement is to make NUMA-aware data structures that tolerate ambient thread placement.   https://blogs.oracle.com/dave/resource/NUMA-aware-JUCExchanger.pdf gives a brief sketch on how this was applied to JUC Exchanger, but it's applicable to other constructs as well.   
> 
> Regards
> Dave
> 
> p.s., it's also easy to create NUMA-friendly locks : https://blogs.oracle.com/dave/entry/lock_cohorting_to_appear_in
> 
> 
>  
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/cdc3bf96/attachment.html>

From rco at quartetfs.com  Wed Oct 17 04:05:38 2012
From: rco at quartetfs.com (Romain Colle)
Date: Wed, 17 Oct 2012 10:05:38 +0200
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
Message-ID: <CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>

On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com> wrote:

> SOT, right now we are using CPUID for a number of reasons. Very easy to
> get to on Linux as we can do this in pure Java. However other platforms
> require C++/assembler so having <gulp> an unsafe operation in the JVM would
> be a win from my POV.
>

I strongly second that. It is next to impossible to implement most
NUMA-aware algorithms without knowing on which NUMA node the current thread
is running.
Having this information available as a Java class (in Thread, Unsafe, ...)
would be a huge win for people like us that need NUMA-aware behavior.

Cheers,

-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/072fd7b5/attachment.html>

From heinz at javaspecialists.eu  Wed Oct 17 17:30:44 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 18 Oct 2012 00:30:44 +0300
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
Message-ID: <507F2384.9000404@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/6a82d76c/attachment.html>

From david.dice at gmail.com  Wed Oct 17 17:53:54 2012
From: david.dice at gmail.com (David Dice)
Date: Wed, 17 Oct 2012 17:53:54 -0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F2384.9000404@javaspecialists.eu>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
Message-ID: <CANbRUciLcR5hXbKLXWf_YfVvy0wqwe_LFxkr23QbPgAKgyjb5A@mail.gmail.com>

Most operating systems will migrate threads if there's a gross or
persistent imbalance in ready queue lengths.   Solaris uses both stealing
and dealing for instance.  And, at least in Solaris, there's no single
unitary scheduler, each of the CPUs is making local decisions that
contribute to the collective policy.    At that same time there's usually
back-pressure in the scheduling policies to try to reduce the migration
rate, at least between NUMA nodes.   (See "seance communication" :
http://dx.doi.org/10.1145/377769.377780).    To make it even more exciting
we can throw energy policies into the equation.    But migration is a fact
of life that we have to live with -- it's not uncommon.    It can also
occur when customers repartition resources on a running system.

Regards
Dave



On Wed, Oct 17, 2012 at 5:30 PM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
> [newbie question]
>     Is it possible for a thread to ever be moved between processors, if
> for example the is an idle processor and another that is really busy?  If
> not, then load balancing could be problematic.  If yes, then this means
> that we need to take this into consideration and not build static
> structures based on the value of which processor the thread is *currently*running on.
>
> Again, if no, then what is the guarantee that it won't be available on
> some VMs or some hardware architectures or operating systems?
> [/newbie question]
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>
> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com>wrote:
>
>>  SOT, right now we are using CPUID for a number of reasons. Very easy to
>> get to on Linux as we can do this in pure Java. However other platforms
>> require C++/assembler so having <gulp> an unsafe operation in the JVM would
>> be a win from my POV.
>>
>
>  I strongly second that. It is next to impossible to implement most
> NUMA-aware algorithms without knowing on which NUMA node the current thread
> is running.
> Having this information available as a Java class (in Thread, Unsafe, ...)
> would be a huge win for people like us that need NUMA-aware behavior.
>
>  Cheers,
>
>  --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/f8a437f8/attachment.html>

From jacyg at alumni.rice.edu  Wed Oct 17 17:55:50 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Wed, 17 Oct 2012 16:55:50 -0500
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F2384.9000404@javaspecialists.eu>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
Message-ID: <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>

Yes, definitely.  I've seen this happen.  One easy way you can see
this is System.nanoTime will suddenly start returning wildly different
values.  nanoTime is only consistent on a single processor, it can
vary widely between processors (at least on Linux).

I think what's really needed is a set of language level constructs for
really addressing the problem.  I know there are experimental projects
looking to do that (
https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
).  I am not sure to what extent it would be possible to build support
for the various constructs in the JVM; and then aside from that, how
you would add language support is another matter.

Jacy

On Wed, Oct 17, 2012 at 4:30 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> [newbie question]
>     Is it possible for a thread to ever be moved between processors, if for
> example the is an idle processor and another that is really busy?  If not,
> then load balancing could be problematic.  If yes, then this means that we
> need to take this into consideration and not build static structures based
> on the value of which processor the thread is currently running on.
>
> Again, if no, then what is the guarantee that it won't be available on some
> VMs or some hardware architectures or operating systems?
> [/newbie question]
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>
> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com> wrote:
>>
>> SOT, right now we are using CPUID for a number of reasons. Very easy to
>> get to on Linux as we can do this in pure Java. However other platforms
>> require C++/assembler so having <gulp> an unsafe operation in the JVM would
>> be a win from my POV.
>
>
> I strongly second that. It is next to impossible to implement most
> NUMA-aware algorithms without knowing on which NUMA node the current thread
> is running.
> Having this information available as a Java class (in Thread, Unsafe, ...)
> would be a huge win for people like us that need NUMA-aware behavior.
>
> Cheers,
>
> --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> ________________________________
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From david.lloyd at redhat.com  Wed Oct 17 17:58:54 2012
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Wed, 17 Oct 2012 16:58:54 -0500
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F2384.9000404@javaspecialists.eu>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
Message-ID: <507F2A1E.4040309@redhat.com>

Yes, the OS can and does move threads between CPUs.  The scarier 
question is: what do you do if/when a CPU is hot-plugged (i.e. 
enabled/disabled while the system is up)?

On 10/17/2012 04:30 PM, Dr Heinz M. Kabutz wrote:
> [newbie question]
>      Is it possible for a thread to ever be moved between processors, if
> for example the is an idle processor and another that is really busy? If
> not, then load balancing could be problematic.  If yes, then this means
> that we need to take this into consideration and not build static
> structures based on the value of which processor the thread is
> /currently/ running on.
>
> Again, if no, then what is the guarantee that it won't be available on
> some VMs or some hardware architectures or operating systems?
> [/newbie question]
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com
>> <mailto:kirk at kodewerk.com>> wrote:
>>
>>     SOT, right now we are using CPUID for a number of reasons. Very
>>     easy to get to on Linux as we can do this in pure Java. However
>>     other platforms require C++/assembler so having <gulp> an unsafe
>>     operation in the JVM would be a win from my POV.
>>
>>
>> I strongly second that. It is next to impossible to implement most
>> NUMA-aware algorithms without knowing on which NUMA node the current
>> thread is running.
>> Having this information available as a Java class (in Thread, Unsafe,
>> ...) would be a huge win for people like us that need NUMA-aware behavior.
>>
>> Cheers,
>>
>> --
>> Romain Colle
>> R&D Project Manager
>> QuartetFS
>> 2 rue Jean Lantier, 75001 Paris, France
>> http://www.quartetfs.com <http://www.quartetfs.com/>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
- DML

From mthornton at optrak.com  Wed Oct 17 18:26:06 2012
From: mthornton at optrak.com (Mark Thornton)
Date: Wed, 17 Oct 2012 23:26:06 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
	<CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
Message-ID: <507F307E.6000108@optrak.com>

On 17/10/12 22:55, Jacy Odin Grannis wrote:
> One easy way you can see
> this is System.nanoTime will suddenly start returning wildly different
> values.  nanoTime is only consistent on a single processor, it can
> vary widely between processors (at least on Linux).
I didn't think that was supposed to happen (on a properly configured 
machine). During the boot process on my systems the kernel checks to see 
if the TSC is consistent between cores before selecting it for use (and 
otherwise uses something else).

Mark


From nathan.reynolds at oracle.com  Wed Oct 17 19:06:07 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 17 Oct 2012 16:06:07 -0700
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F307E.6000108@optrak.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
	<CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
	<507F307E.6000108@optrak.com>
Message-ID: <507F39DF.7070805@oracle.com>

The Linux kernel will synchronize the TSC at boot.  The synchronization 
causes the TSC to appear identical.  I say appear because they can only 
synchronize to the point where communication latencies between 
processors makes the values appear to be identical.  You do have to run 
with a "modern" kernel.  Several different Oracle teams have asked the 
Intel architects to figure out a way to make sure TSC stays in sync.  It 
is a very difficult problem to solve cheaply.

Another problem is that older Intel processors would slow down the 
increment rate of TSC when the processor slowed down its frequency.  
This would cause the TSC to not be synchronized.  More recent processors 
have a "const TSC" so that processor frequency changes don't impact TSC 
increment rate.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
On 10/17/2012 3:26 PM, Mark Thornton wrote:
> On 17/10/12 22:55, Jacy Odin Grannis wrote:
>> One easy way you can see
>> this is System.nanoTime will suddenly start returning wildly different
>> values.  nanoTime is only consistent on a single processor, it can
>> vary widely between processors (at least on Linux).
> I didn't think that was supposed to happen (on a properly configured 
> machine). During the boot process on my systems the kernel checks to 
> see if the TSC is consistent between cores before selecting it for use 
> (and otherwise uses something else).
>
> Mark
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/c5e9cf41/attachment-0001.html>

From nathan.reynolds at oracle.com  Wed Oct 17 19:18:07 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 17 Oct 2012 16:18:07 -0700
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F2384.9000404@javaspecialists.eu>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
Message-ID: <507F3CAF.7000902@oracle.com>

Linux and Windows thread schedulers will migrate threads among cores on 
the same processor and to different processors very readily.  Solaris 
thread scheduler on Sparc really has to be pushed to move a thread to 
another processor.  The default for Xen virtual guests is to have the 
vCPUs assigned to a particular processor and the vCPUs can't migrate off 
that processor.  The vCPUs will bounce around the different cores on the 
same processor very readily, though.  Yes, load balancing can be 
problematic on Xen.  A test just bumped into that problem.

When building concurrent algorithms, data structures, locks, etc, one 
should definitely consider the core that the thread is currently running 
on.  However, the design should assume that the thread won't be running 
on that core or processor for very long.

When I built a NUMA-aware reader writer in C++, each reader acquires the 
lock tied to a particular core.  When the reader is done, it has to 
release that same lock even though it might be running on a different 
core.  This gave a huge scalability boost. We had 3 Nehalem processors 
100% utilized.  When we plugged in the 4^(t)^(h) Nehalem processor, it 
was 100% utilized but no increase in throughput.  When I make the reader 
writer lock NUMA-aware, then we got a significant boost in throughput 
from the 4^(t)^(h) Nehalem processor.

As for hot adding processors, this isn't too difficult.  Most data 
structures, locks, etc can handle it.  For example, simply add more 
leaves to the striping.  The changes don't have to be done efficiently 
or be concerned about scalability.  This is because hot adding 
processors should be a rare event in the lifetime of the process.

As for hot removing processors, this can be more difficult.  The only 
thing I could figure out is that the application has to notify the data 
structure when it is okay for it to deal with the removal.

For example, a NUMA-aware Exchanger wouldn't be bothered by hot plugged 
processors.  Sure, it will see an impact at the moment of the change, 
but it will then stabilize to the new processor configuration fairly 
quickly.  A NUMA-aware reader writer lock will require a bit more work 
but again it is doable.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
On 10/17/2012 2:30 PM, Dr Heinz M. Kabutz wrote:
> [newbie question]
>     Is it possible for a thread to ever be moved between processors, 
> if for example the is an idle processor and another that is really 
> busy? If not, then load balancing could be problematic.  If yes, then 
> this means that we need to take this into consideration and not build 
> static structures based on the value of which processor the thread is 
> /currently/ running on.
>
> Again, if no, then what is the guarantee that it won't be available on 
> some VMs or some hardware architectures or operating systems?
> [/newbie question]
> Regards
>
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com 
>> <mailto:kirk at kodewerk.com>> wrote:
>>
>>     SOT, right now we are using CPUID for a number of reasons. Very
>>     easy to get to on Linux as we can do this in pure Java. However
>>     other platforms require C++/assembler so having <gulp> an unsafe
>>     operation in the JVM would be a win from my POV.
>>
>>
>> I strongly second that. It is next to impossible to implement most 
>> NUMA-aware algorithms without knowing on which NUMA node the current 
>> thread is running.
>> Having this information available as a Java class (in Thread, Unsafe, 
>> ...) would be a huge win for people like us that need NUMA-aware 
>> behavior.
>>
>> Cheers,
>>
>> -- 
>> Romain Colle
>> R&D Project Manager
>> QuartetFS
>> 2 rue Jean Lantier, 75001 Paris, France
>> http://www.quartetfs.com <http://www.quartetfs.com/>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>    
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/46feaa41/attachment.html>

From stanimir at riflexo.com  Wed Oct 17 20:53:38 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 18 Oct 2012 03:53:38 +0300
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <507F2384.9000404@javaspecialists.eu>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
Message-ID: <CAEJX8oq4mLP4zEXow1x2=ncELXOLoDf4-+-9Knq1+601fN8KYQ@mail.gmail.com>

>>Is it possible for a thread to ever be moved between processors, if for
example the is an idle processor and another that is really busy?

Of course and it happens often. Threads in general are not pinned to cores,
so the OS is free to pick one.
While starting threads they can usually start on the same core and then be
moved to a different one.

Stanimir

On Thu, Oct 18, 2012 at 12:30 AM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

> **
> [newbie question]
>     Is it possible for a thread to ever be moved between processors, if
> for example the is an idle processor and another that is really busy?  If
> not, then load balancing could be problematic.  If yes, then this means
> that we need to take this into consideration and not build static
> structures based on the value of which processor the thread is *currently*running on.
>
> Again, if no, then what is the guarantee that it won't be available on
> some VMs or some hardware architectures or operating systems?
> [/newbie question]
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professionalhttp://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>
> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com>wrote:
>
>>  SOT, right now we are using CPUID for a number of reasons. Very easy to
>> get to on Linux as we can do this in pure Java. However other platforms
>> require C++/assembler so having <gulp> an unsafe operation in the JVM would
>> be a win from my POV.
>>
>
>  I strongly second that. It is next to impossible to implement most
> NUMA-aware algorithms without knowing on which NUMA node the current thread
> is running.
> Having this information available as a Java class (in Thread, Unsafe, ...)
> would be a huge win for people like us that need NUMA-aware behavior.
>
>  Cheers,
>
>  --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> ------------------------------
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/39f2c90c/attachment.html>

From david.dice at gmail.com  Wed Oct 17 22:11:27 2012
From: david.dice at gmail.com (David Dice)
Date: Wed, 17 Oct 2012 22:11:27 -0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
Message-ID: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>

Date: Wed, 17 Oct 2012 16:55:50 -0500
> From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
> To: "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
> Cc: concurrency-interest at cs.oswego.edu, David Dice
>         <david.dice at gmail.com>
> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
> Message-ID:
>         <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=
> Sh4g at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Yes, definitely.  I've seen this happen.  One easy way you can see
> this is System.nanoTime will suddenly start returning wildly different
> values.  nanoTime is only consistent on a single processor, it can
> vary widely between processors (at least on Linux).
>
> I think what's really needed is a set of language level constructs for
> really addressing the problem.  I know there are experimental projects
> looking to do that (
>
> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
> ).  I am not sure to what extent it would be possible to build support
> for the various constructs in the JVM; and then aside from that, how
> you would add language support is another matter.
>

The nanoTime() behavior sounds like a JVM bug.   nanoTime() values should
be non-retrograde and causal in the sense that if one thread calls nanoTime
and stores the observed value T into a variable, and then some 2nd thread
reads that variable and observes the store of T and then calls nanoTime and
sees value U, we should have U >= T.  (Volatiles are assumed, obviously).
  I first ran into this non-monotonic time problem on large SPARC systems
where the HW clock underlying the native gethrtime() API exhibited drift
between CPUs.   The drift was minimal as the kernel syncs the clocks
periodically, so we tracked the the maximum value returned by nanoTime()
and would return the maximum of that tracking value and the value we got
via gethrtime().   This works, but creates its own cache coherence hot-spot
as we're updating that variable frequently, which means that concurrent and
unrelated nanoTime() calls don't scale as well as we might like.   (There
are ways to avoid the coherence hot spot but they usually entail reduced
accuracy).

It's been years since I've looked at the code, but I think we use
CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
answer this part of the question regarding linux time sources).  But the
guards against returning a smaller value aren't in place in the linux
platform-specific code as they are on Solaris.

Regards
Dave
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/1d2dfe4f/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Oct 17 22:31:12 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 18 Oct 2012 12:31:12 +1000
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEHEJHAA.davidcholmes@aapt.net.au>

Well the nanoTime() behaviour is not a JVM bug, though the JVM can try to
account for the underlying buggy OS and/or configuration and/or hardware.
;-)

As Dave states on LInux we will use CLOCK_MONOTONIC if available (which is
pretty much always these days), else we fall back to gettimeofday. Now as
you can infer from the name CLOCK_MONOTONIC is supposed to be monotonic and
if it isn't that is a bug in the OS or a system configuration error (using
an unreliable clocksource such as the TSC on MP systems). In contrast we
make no pretense that gettimeofday is expected to be monotonic.

Also as Dave states we don't try to guard against a buggy CLOCK_MONOTONIC on
linux by ensuring it never reports a value less than any previous value
reported. We could, and probably should, but it is one of many things on a
long list.

But if you see big problems with nanoTime then either your system is using
the TSC as a clocksource when it should not, OR you are running in a virtual
environment and the host system is not providing a stable time source to the
guest OS.

Note: for the TSC to be usable it must be both stable (frequency invariant)
and synchronized across all "processors". While many processors now provide
a stable TSC they don't provide a synchronized TSC. For the OS to be able to
use the TSC as a monotonic clocksource it needs to do its own very accurate
synchronization. Solaris actually attempts this, where most operating
systems simply stopped using the TSC, but because of that there has been a
very long bug-tail on Solaris.

David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Dice
  Sent: Thursday, 18 October 2012 12:11 PM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal





    Date: Wed, 17 Oct 2012 16:55:50 -0500
    From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
    To: "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
    Cc: concurrency-interest at cs.oswego.edu, David Dice
            <david.dice at gmail.com>
    Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
    Message-ID:
            <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g at mail.gmail.
com>
    Content-Type: text/plain; charset=ISO-8859-1

    Yes, definitely.  I've seen this happen.  One easy way you can see
    this is System.nanoTime will suddenly start returning wildly different
    values.  nanoTime is only consistent on a single processor, it can
    vary widely between processors (at least on Linux).

    I think what's really needed is a set of language level constructs for
    really addressing the problem.  I know there are experimental projects
    looking to do that (
    https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Sof
tware+Research+Project
    ).  I am not sure to what extent it would be possible to build support
    for the various constructs in the JVM; and then aside from that, how
    you would add language support is another matter.



  The nanoTime() behavior sounds like a JVM bug.   nanoTime() values should
be non-retrograde and causal in the sense that if one thread calls nanoTime
and stores the observed value T into a variable, and then some 2nd thread
reads that variable and observes the store of T and then calls nanoTime and
sees value U, we should have U >= T.  (Volatiles are assumed, obviously).
I first ran into this non-monotonic time problem on large SPARC systems
where the HW clock underlying the native gethrtime() API exhibited drift
between CPUs.   The drift was minimal as the kernel syncs the clocks
periodically, so we tracked the the maximum value returned by nanoTime() and
would return the maximum of that tracking value and the value we got via
gethrtime().   This works, but creates its own cache coherence hot-spot as
we're updating that variable frequently, which means that concurrent and
unrelated nanoTime() calls don't scale as well as we might like.   (There
are ways to avoid the coherence hot spot but they usually entail reduced
accuracy).


  It's been years since I've looked at the code, but I think we use
CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
answer this part of the question regarding linux time sources).  But the
guards against returning a smaller value aren't in place in the linux
platform-specific code as they are on Solaris.


  Regards
  Dave

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/0c35c5c0/attachment.html>

From ariel at weisberg.ws  Wed Oct 17 22:48:52 2012
From: ariel at weisberg.ws (Ariel Weisberg)
Date: Wed, 17 Oct 2012 22:48:52 -0400
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
References: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
Message-ID: <1350528532.20478.140661142192677.713E07D1@webmail.messagingengine.com>

Hi,

[1]I would swear I have seen nanotime go backwards within a single
thread. Could be an application bug I suppose, but we were convinced.

I also saw performance issues with nanotime so I ended up only sampling
1 in 20 transactions.

Ariel
On Wed, Oct 17, 2012, at 10:11 PM, David Dice wrote:

  Date: Wed, 17 Oct 2012 16:55:50 -0500
  From: Jacy Odin Grannis <[2]jacyg at alumni.rice.edu>
  To: "Dr Heinz M. Kabutz" <[3]heinz at javaspecialists.eu>
  Cc: [4]concurrency-interest at cs.oswego.edu, David Dice
          <[5]david.dice at gmail.com>
  Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
  Message-ID:

  <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=[6]Sh4g at mail.gmail.c
  om>
  Content-Type: text/plain; charset=ISO-8859-1
  Yes, definitely.  I've seen this happen.  One easy way you can see
  this is System.nanoTime will suddenly start returning wildly
  different
  values.  nanoTime is only consistent on a single processor, it can
  vary widely between processors (at least on Linux).
  I think what's really needed is a set of language level constructs
  for
  really addressing the problem.  I know there are experimental
  projects
  looking to do that (
  [7]https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multic
  ore+Software+Research+Project
  ).  I am not sure to what extent it would be possible to build
  support
  for the various constructs in the JVM; and then aside from that, how
  you would add language support is another matter.


The nanoTime() behavior sounds like a JVM bug.   nanoTime() values
should be non-retrograde and causal in the sense that if one thread
calls nanoTime and stores the observed value T into a variable, and
then some 2nd thread reads that variable and observes the store of T
and then calls nanoTime and sees value U, we should have U >= T.
(Volatiles are assumed, obviously).     I first ran into this
non-monotonic time problem on large SPARC systems where the HW clock
underlying the native gethrtime() API exhibited drift between CPUs.
The drift was minimal as the kernel syncs the clocks periodically, so
we tracked the the maximum value returned by nanoTime() and would
return the maximum of that tracking value and the value we got via
gethrtime().   This works, but creates its own cache coherence hot-spot
as we're updating that variable frequently, which means that concurrent
and unrelated nanoTime() calls don't scale as well as we might like.
(There are ways to avoid the coherence hot spot but they usually entail
reduced accuracy).

It's been years since I've looked at the code, but I think we use
CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
answer this part of the question regarding linux time sources).  But
the guards against returning a smaller value aren't in place in the
linux platform-specific code as they are on Solaris.

Regards
Dave

_______________________________________________

Concurrency-interest mailing list

[8]Concurrency-interest at cs.oswego.edu

[9]http://cs.oswego.edu/mailman/listinfo/concurrency-interest

References

1. https://issues.voltdb.com/browse/ENG-1132
2. mailto:jacyg at alumni.rice.edu
3. mailto:heinz at javaspecialists.eu
4. mailto:concurrency-interest at cs.oswego.edu
5. mailto:david.dice at gmail.com
6. mailto:Sh4g at mail.gmail.com
7. https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
8. mailto:Concurrency-interest at cs.oswego.edu
9. http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121017/93f68834/attachment.html>

From davidcholmes at aapt.net.au  Wed Oct 17 23:18:22 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 18 Oct 2012 13:18:22 +1000
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <1350528532.20478.140661142192677.713E07D1@webmail.messagingengine.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEHFJHAA.davidcholmes@aapt.net.au>

You can see nanoTime go backwards in a single-thread if the thread changes
cores and the TSC on the second core has a smaller value than that on the
first.

David Holmes

  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ariel
Weisberg
  Sent: Thursday, 18 October 2012 12:49 PM
  To: David Dice; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal


  Hi,

  I would swear I have seen nanotime go backwards within a single thread.
Could be an application bug I suppose, but we were convinced.

  I also saw performance issues with nanotime so I ended up only sampling 1
in 20 transactions.

  Ariel
  On Wed, Oct 17, 2012, at 10:11 PM, David Dice wrote:



      Date: Wed, 17 Oct 2012 16:55:50 -0500
      From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
      To: "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
      Cc: concurrency-interest at cs.oswego.edu, David Dice
              <david.dice at gmail.com>
      Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
      Message-ID:
              <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g at mail.gmai
l.com>
      Content-Type: text/plain; charset=ISO-8859-1

      Yes, definitely.  I've seen this happen.  One easy way you can see
      this is System.nanoTime will suddenly start returning wildly different
      values.  nanoTime is only consistent on a single processor, it can
      vary widely between processors (at least on Linux).

      I think what's really needed is a set of language level constructs for
      really addressing the problem.  I know there are experimental projects
      looking to do that (
      https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+S
oftware+Research+Project
      ).  I am not sure to what extent it would be possible to build support
      for the various constructs in the JVM; and then aside from that, how
      you would add language support is another matter.

    The nanoTime() behavior sounds like a JVM bug.   nanoTime() values
should be non-retrograde and causal in the sense that if one thread calls
nanoTime and stores the observed value T into a variable, and then some 2nd
thread reads that variable and observes the store of T and then calls
nanoTime and sees value U, we should have U >= T.  (Volatiles are assumed,
obviously).     I first ran into this non-monotonic time problem on large
SPARC systems where the HW clock underlying the native gethrtime() API
exhibited drift between CPUs.   The drift was minimal as the kernel syncs
the clocks periodically, so we tracked the the maximum value returned by
nanoTime() and would return the maximum of that tracking value and the value
we got via gethrtime().   This works, but creates its own cache coherence
hot-spot as we're updating that variable frequently, which means that
concurrent and unrelated nanoTime() calls don't scale as well as we might
like.   (There are ways to avoid the coherence hot spot but they usually
entail reduced accuracy).

    It's been years since I've looked at the code, but I think we use
CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
answer this part of the question regarding linux time sources).  But the
guards against returning a smaller value aren't in place in the linux
platform-specific code as they are on Solaris.

    Regards
    Dave

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/c99fb242/attachment-0001.html>

From jacyg at alumni.rice.edu  Wed Oct 17 23:46:53 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Wed, 17 Oct 2012 22:46:53 -0500
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEHEJHAA.davidcholmes@aapt.net.au>
References: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEHEJHAA.davidcholmes@aapt.net.au>
Message-ID: <CAESiqEpKf6QhbpiGPzZY3fEixPqmOJJoVdeWGcDNRWNXY1Qr9A@mail.gmail.com>

So, when I'd seen this it was on Linux 2.6.9, Opteron 8384s, Java
1.6.0_16 (it was a couple years back).

Based on this:
http://juliusdavies.ca/posix_clocks/clock_realtime_linux_faq.html  it
would look like it could be that the kernel was buggy, as only 2.6.18
and up are solid.

However, I also found this link:
http://efreedom.com/Question/1-6814792/Clock-Gettime-Erratic  which
notes erratic behavior even on 2.6.26, when using an Opteron.
Somewhere in this thread
http://stackoverflow.com/questions/510462/is-system-nanotime-completely-useless
someone comments that when they used AMD before that there wasn't any
synchronization even across cores on the same die.  So, I'm going to
guess AMD was the source of the behavior I saw.  The values were
definitely very different, they would frequently be separated by
hundreds of thousands of "nanos" from one core to the next.  Makes for
funny outliers in your data set when you're trying to capture timings.
 Although my big concern wasn't the huge swings--those you can easily
discard--it was worry that I'd end up with noise I couldn't account
for if the timings were close but not quite in sync.

At any rate, hopefully that's helpful to someone if they're trying to
debug similarly strange results on an older machine.

Jacy

On Wed, Oct 17, 2012 at 9:31 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Well the nanoTime() behaviour is not a JVM bug, though the JVM can try to
> account for the underlying buggy OS and/or configuration and/or hardware.
> ;-)
>
> As Dave states on LInux we will use CLOCK_MONOTONIC if available (which is
> pretty much always these days), else we fall back to gettimeofday. Now as
> you can infer from the name CLOCK_MONOTONIC is supposed to be monotonic and
> if it isn't that is a bug in the OS or a system configuration error (using
> an unreliable clocksource such as the TSC on MP systems). In contrast we
> make no pretense that gettimeofday is expected to be monotonic.
>
> Also as Dave states we don't try to guard against a buggy CLOCK_MONOTONIC on
> linux by ensuring it never reports a value less than any previous value
> reported. We could, and probably should, but it is one of many things on a
> long list.
>
> But if you see big problems with nanoTime then either your system is using
> the TSC as a clocksource when it should not, OR you are running in a virtual
> environment and the host system is not providing a stable time source to the
> guest OS.
>
> Note: for the TSC to be usable it must be both stable (frequency invariant)
> and synchronized across all "processors". While many processors now provide
> a stable TSC they don't provide a synchronized TSC. For the OS to be able to
> use the TSC as a monotonic clocksource it needs to do its own very accurate
> synchronization. Solaris actually attempts this, where most operating
> systems simply stopped using the TSC, but because of that there has been a
> very long bug-tail on Solaris.
>
> David Holmes
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Dice
> Sent: Thursday, 18 October 2012 12:11 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>
>
>
>> Date: Wed, 17 Oct 2012 16:55:50 -0500
>> From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
>> To: "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
>> Cc: concurrency-interest at cs.oswego.edu, David Dice
>>         <david.dice at gmail.com>
>> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>> Message-ID:
>>
>> <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Yes, definitely.  I've seen this happen.  One easy way you can see
>> this is System.nanoTime will suddenly start returning wildly different
>> values.  nanoTime is only consistent on a single processor, it can
>> vary widely between processors (at least on Linux).
>>
>> I think what's really needed is a set of language level constructs for
>> really addressing the problem.  I know there are experimental projects
>> looking to do that (
>>
>> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
>> ).  I am not sure to what extent it would be possible to build support
>> for the various constructs in the JVM; and then aside from that, how
>> you would add language support is another matter.
>
>
> The nanoTime() behavior sounds like a JVM bug.   nanoTime() values should be
> non-retrograde and causal in the sense that if one thread calls nanoTime and
> stores the observed value T into a variable, and then some 2nd thread reads
> that variable and observes the store of T and then calls nanoTime and sees
> value U, we should have U >= T.  (Volatiles are assumed, obviously).     I
> first ran into this non-monotonic time problem on large SPARC systems where
> the HW clock underlying the native gethrtime() API exhibited drift between
> CPUs.   The drift was minimal as the kernel syncs the clocks periodically,
> so we tracked the the maximum value returned by nanoTime() and would return
> the maximum of that tracking value and the value we got via gethrtime().
> This works, but creates its own cache coherence hot-spot as we're updating
> that variable frequently, which means that concurrent and unrelated
> nanoTime() calls don't scale as well as we might like.   (There are ways to
> avoid the coherence hot spot but they usually entail reduced accuracy).
>
> It's been years since I've looked at the code, but I think we use
> CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
> answer this part of the question regarding linux time sources).  But the
> guards against returning a smaller value aren't in place in the linux
> platform-specific code as they are on Solaris.
>
> Regards
> Dave
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From kirk at kodewerk.com  Thu Oct 18 02:57:03 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Thu, 18 Oct 2012 07:57:03 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAESiqEpKf6QhbpiGPzZY3fEixPqmOJJoVdeWGcDNRWNXY1Qr9A@mail.gmail.com>
References: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEHEJHAA.davidcholmes@aapt.net.au>
	<CAESiqEpKf6QhbpiGPzZY3fEixPqmOJJoVdeWGcDNRWNXY1Qr9A@mail.gmail.com>
Message-ID: <25F5B47D-414E-4045-AB2F-4E40341B0D0C@kodewerk.com>

The problem with discarding outliers is that you don't really know if it's a clock problem or that something else is going on.

Regards,
Kirk

On 2012-10-18, at 4:46 AM, Jacy Odin Grannis <jacyg at alumni.rice.edu> wrote:

> So, when I'd seen this it was on Linux 2.6.9, Opteron 8384s, Java
> 1.6.0_16 (it was a couple years back).
> 
> Based on this:
> http://juliusdavies.ca/posix_clocks/clock_realtime_linux_faq.html  it
> would look like it could be that the kernel was buggy, as only 2.6.18
> and up are solid.
> 
> However, I also found this link:
> http://efreedom.com/Question/1-6814792/Clock-Gettime-Erratic  which
> notes erratic behavior even on 2.6.26, when using an Opteron.
> Somewhere in this thread
> http://stackoverflow.com/questions/510462/is-system-nanotime-completely-useless
> someone comments that when they used AMD before that there wasn't any
> synchronization even across cores on the same die.  So, I'm going to
> guess AMD was the source of the behavior I saw.  The values were
> definitely very different, they would frequently be separated by
> hundreds of thousands of "nanos" from one core to the next.  Makes for
> funny outliers in your data set when you're trying to capture timings.
> Although my big concern wasn't the huge swings--those you can easily
> discard--it was worry that I'd end up with noise I couldn't account
> for if the timings were close but not quite in sync.
> 
> At any rate, hopefully that's helpful to someone if they're trying to
> debug similarly strange results on an older machine.
> 
> Jacy
> 
> On Wed, Oct 17, 2012 at 9:31 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
>> Well the nanoTime() behaviour is not a JVM bug, though the JVM can try to
>> account for the underlying buggy OS and/or configuration and/or hardware.
>> ;-)
>> 
>> As Dave states on LInux we will use CLOCK_MONOTONIC if available (which is
>> pretty much always these days), else we fall back to gettimeofday. Now as
>> you can infer from the name CLOCK_MONOTONIC is supposed to be monotonic and
>> if it isn't that is a bug in the OS or a system configuration error (using
>> an unreliable clocksource such as the TSC on MP systems). In contrast we
>> make no pretense that gettimeofday is expected to be monotonic.
>> 
>> Also as Dave states we don't try to guard against a buggy CLOCK_MONOTONIC on
>> linux by ensuring it never reports a value less than any previous value
>> reported. We could, and probably should, but it is one of many things on a
>> long list.
>> 
>> But if you see big problems with nanoTime then either your system is using
>> the TSC as a clocksource when it should not, OR you are running in a virtual
>> environment and the host system is not providing a stable time source to the
>> guest OS.
>> 
>> Note: for the TSC to be usable it must be both stable (frequency invariant)
>> and synchronized across all "processors". While many processors now provide
>> a stable TSC they don't provide a synchronized TSC. For the OS to be able to
>> use the TSC as a monotonic clocksource it needs to do its own very accurate
>> synchronization. Solaris actually attempts this, where most operating
>> systems simply stopped using the TSC, but because of that there has been a
>> very long bug-tail on Solaris.
>> 
>> David Holmes
>> 
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Dice
>> Sent: Thursday, 18 October 2012 12:11 PM
>> To: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>> 
>> 
>> 
>>> Date: Wed, 17 Oct 2012 16:55:50 -0500
>>> From: Jacy Odin Grannis <jacyg at alumni.rice.edu>
>>> To: "Dr Heinz M. Kabutz" <heinz at javaspecialists.eu>
>>> Cc: concurrency-interest at cs.oswego.edu, David Dice
>>>        <david.dice at gmail.com>
>>> Subject: Re: [concurrency-interest] ThreadLocal vs ProcessorLocal
>>> Message-ID:
>>> 
>>> <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g at mail.gmail.com>
>>> Content-Type: text/plain; charset=ISO-8859-1
>>> 
>>> Yes, definitely.  I've seen this happen.  One easy way you can see
>>> this is System.nanoTime will suddenly start returning wildly different
>>> values.  nanoTime is only consistent on a single processor, it can
>>> vary widely between processors (at least on Linux).
>>> 
>>> I think what's really needed is a set of language level constructs for
>>> really addressing the problem.  I know there are experimental projects
>>> looking to do that (
>>> 
>>> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
>>> ).  I am not sure to what extent it would be possible to build support
>>> for the various constructs in the JVM; and then aside from that, how
>>> you would add language support is another matter.
>> 
>> 
>> The nanoTime() behavior sounds like a JVM bug.   nanoTime() values should be
>> non-retrograde and causal in the sense that if one thread calls nanoTime and
>> stores the observed value T into a variable, and then some 2nd thread reads
>> that variable and observes the store of T and then calls nanoTime and sees
>> value U, we should have U >= T.  (Volatiles are assumed, obviously).     I
>> first ran into this non-monotonic time problem on large SPARC systems where
>> the HW clock underlying the native gethrtime() API exhibited drift between
>> CPUs.   The drift was minimal as the kernel syncs the clocks periodically,
>> so we tracked the the maximum value returned by nanoTime() and would return
>> the maximum of that tracking value and the value we got via gethrtime().
>> This works, but creates its own cache coherence hot-spot as we're updating
>> that variable frequently, which means that concurrent and unrelated
>> nanoTime() calls don't scale as well as we might like.   (There are ways to
>> avoid the coherence hot spot but they usually entail reduced accuracy).
>> 
>> It's been years since I've looked at the code, but I think we use
>> CLOCK_MONOTONIC if it's available on linux.   (David Holmes could best
>> answer this part of the question regarding linux time sources).  But the
>> guards against returning a smaller value aren't in place in the linux
>> platform-specific code as they are on Solaris.
>> 
>> Regards
>> Dave
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



From mthornton at optrak.com  Thu Oct 18 03:36:48 2012
From: mthornton at optrak.com (Mark Thornton)
Date: Thu, 18 Oct 2012 08:36:48 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAESiqEpKf6QhbpiGPzZY3fEixPqmOJJoVdeWGcDNRWNXY1Qr9A@mail.gmail.com>
References: <CANbRUciU-Ogc2KhXjcP9qP7dLS=JCWDE_gGcDLdRUu1KhOjTSA@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEHEJHAA.davidcholmes@aapt.net.au>
	<CAESiqEpKf6QhbpiGPzZY3fEixPqmOJJoVdeWGcDNRWNXY1Qr9A@mail.gmail.com>
Message-ID: <507FB190.8030008@optrak.com>

On 18/10/12 04:46, Jacy Odin Grannis wrote:
> So, when I'd seen this it was on Linux 2.6.9, Opteron 8384s, Java
> 1.6.0_16 (it was a couple years back).
>
> Based on this:
> http://juliusdavies.ca/posix_clocks/clock_realtime_linux_faq.html  it
> would look like it could be that the kernel was buggy, as only 2.6.18
> and up are solid.
>
> However, I also found this link:
> http://efreedom.com/Question/1-6814792/Clock-Gettime-Erratic  which
> notes erratic behavior even on 2.6.26, when using an Opteron.
> Somewhere in this thread
> http://stackoverflow.com/questions/510462/is-system-nanotime-completely-useless
> someone comments that when they used AMD before that there wasn't any
> synchronization even across cores on the same die.
I seem to remember that when AMD first introduced per core control of 
the processor clock, the TSC counter on each core reflected the clock 
rate on that core. It took a while for operating systems to check for 
this behaviour, and subsequently the TSC was changed to tick at a 
constant rate regardless of power management.

Mark


From oleksandr.otenko at oracle.com  Thu Oct 18 10:00:15 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Thu, 18 Oct 2012 15:00:15 +0100
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
	<CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
Message-ID: <50800B6F.6050108@oracle.com>

How do you differentiate wildly different value on the same CPU after a 
context switch and a wildly different value on another CPU after a 
context switch?

Alex


On 17/10/2012 22:55, Jacy Odin Grannis wrote:
> Yes, definitely.  I've seen this happen.  One easy way you can see
> this is System.nanoTime will suddenly start returning wildly different
> values.  nanoTime is only consistent on a single processor, it can
> vary widely between processors (at least on Linux).
>
> I think what's really needed is a set of language level constructs for
> really addressing the problem.  I know there are experimental projects
> looking to do that (
> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
> ).  I am not sure to what extent it would be possible to build support
> for the various constructs in the JVM; and then aside from that, how
> you would add language support is another matter.
>
> Jacy
>
> On Wed, Oct 17, 2012 at 4:30 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu>  wrote:
>> [newbie question]
>>      Is it possible for a thread to ever be moved between processors, if for
>> example the is an idle processor and another that is really busy?  If not,
>> then load balancing could be problematic.  If yes, then this means that we
>> need to take this into consideration and not build static structures based
>> on the value of which processor the thread is currently running on.
>>
>> Again, if no, then what is the guarantee that it won't be available on some
>> VMs or some hardware architectures or operating systems?
>> [/newbie question]
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>>
>>
>>
>> On 10/17/12 11:05 AM, Romain Colle wrote:
>>
>> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine<kirk at kodewerk.com>  wrote:
>>> SOT, right now we are using CPUID for a number of reasons. Very easy to
>>> get to on Linux as we can do this in pure Java. However other platforms
>>> require C++/assembler so having<gulp>  an unsafe operation in the JVM would
>>> be a win from my POV.
>>
>> I strongly second that. It is next to impossible to implement most
>> NUMA-aware algorithms without knowing on which NUMA node the current thread
>> is running.
>> Having this information available as a Java class (in Thread, Unsafe, ...)
>> would be a huge win for people like us that need NUMA-aware behavior.
>>
>> Cheers,
>>
>> --
>> Romain Colle
>> R&D Project Manager
>> QuartetFS
>> 2 rue Jean Lantier, 75001 Paris, France
>> http://www.quartetfs.com
>>
>> ________________________________
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/b217b391/attachment-0001.html>

From jacyg at alumni.rice.edu  Thu Oct 18 10:16:08 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Thu, 18 Oct 2012 09:16:08 -0500
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <50800B6F.6050108@oracle.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
	<CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
	<50800B6F.6050108@oracle.com>
Message-ID: <CAESiqEqxh7agXhUDCH3E3V7p1CD4JsHYPZwAJ4GL8k8ebpJhqQ@mail.gmail.com>

In our case, we knew that the operations we were measuring weren't
taking hundreds of milliseconds (because the number of operations
completed in a given time frame precluded that being the case).  And
we also knew, with even more certainty, that the operations weren't
taking NEGATIVE hundreds of milliseconds to complete, because we were
unfortunately not clever enough to create systems that would do that.
Given that we expected values to be in the microsecond range, and we
had counts which backed that up, it was pretty easy to discount values
which were clearly out of range.  Although when we first encountered
the issue, we checked things by simply running a set of threads
getting nanoTime values and noting when the value would suddenly have
a large difference from the previous value, and log those values.  We
noted that the values logged varied significantly from one thread to
the other, and that a given thread would at times start reporting
values which matched up with values which had been reported by a
different thread (i.e. b/c it had been migrated to the core that other
thread had been running on).  We were a bit surprised at how often
even hot threads would migrate.  As far as context switches...yes,
those could be a confounder.  In our case, we knew what the system was
doing very well, and had a very limited number of active threads which
did not exceed our core count, and, as I mentioned, given that we'd
get elapsed time values occasionally which were +/- hundreds of millis
despite simple counts which would indicate that was impossible, well,
eliminating context switches as our issue was not too difficult.
However, as a general rule, no, you can't reject outliers out-of-hand,
you have to do some digging.

jacy

On Thu, Oct 18, 2012 at 9:00 AM, oleksandr otenko
<oleksandr.otenko at oracle.com> wrote:
> How do you differentiate wildly different value on the same CPU after a
> context switch and a wildly different value on another CPU after a context
> switch?
>
> Alex
>
>
> On 17/10/2012 22:55, Jacy Odin Grannis wrote:
>
> Yes, definitely.  I've seen this happen.  One easy way you can see
> this is System.nanoTime will suddenly start returning wildly different
> values.  nanoTime is only consistent on a single processor, it can
> vary widely between processors (at least on Linux).
>
> I think what's really needed is a set of language level constructs for
> really addressing the problem.  I know there are experimental projects
> looking to do that (
> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
> ).  I am not sure to what extent it would be possible to build support
> for the various constructs in the JVM; and then aside from that, how
> you would add language support is another matter.
>
> Jacy
>
> On Wed, Oct 17, 2012 at 4:30 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>
> [newbie question]
>     Is it possible for a thread to ever be moved between processors, if for
> example the is an idle processor and another that is really busy?  If not,
> then load balancing could be problematic.  If yes, then this means that we
> need to take this into consideration and not build static structures based
> on the value of which processor the thread is currently running on.
>
> Again, if no, then what is the guarantee that it won't be available on some
> VMs or some hardware architectures or operating systems?
> [/newbie question]
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> On 10/17/12 11:05 AM, Romain Colle wrote:
>
> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com> wrote:
>
> SOT, right now we are using CPUID for a number of reasons. Very easy to
> get to on Linux as we can do this in pure Java. However other platforms
> require C++/assembler so having <gulp> an unsafe operation in the JVM would
> be a win from my POV.
>
> I strongly second that. It is next to impossible to implement most
> NUMA-aware algorithms without knowing on which NUMA node the current thread
> is running.
> Having this information available as a Java class (in Thread, Unsafe, ...)
> would be a huge win for people like us that need NUMA-aware behavior.
>
> Cheers,
>
> --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> ________________________________
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From nathan.reynolds at oracle.com  Thu Oct 18 12:00:42 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 18 Oct 2012 09:00:42 -0700
Subject: [concurrency-interest] ThreadLocal vs ProcessorLocal
In-Reply-To: <CAESiqEqxh7agXhUDCH3E3V7p1CD4JsHYPZwAJ4GL8k8ebpJhqQ@mail.gmail.com>
References: <CANbRUcjN+s2Hu9==E-J8jj+fPG2caHb_T4L53BKEDgMBy2xAFA@mail.gmail.com>
	<D9A72301-99C8-4735-9FD8-71011AAEF3D4@kodewerk.com>
	<CAJp3eRAGBXQrQt5LXfQa26Bup_98f2yNEM+Y+twty1jbOx+0-w@mail.gmail.com>
	<507F2384.9000404@javaspecialists.eu>
	<CAESiqEqAteCAsCDLWXM-3-89bJS2nBRrLtOBmHrJkkcX2=Sh4g@mail.gmail.com>
	<50800B6F.6050108@oracle.com>
	<CAESiqEqxh7agXhUDCH3E3V7p1CD4JsHYPZwAJ4GL8k8ebpJhqQ@mail.gmail.com>
Message-ID: <508027AA.6010008@oracle.com>

GC typically has pauses in the millisecond range.  Couldn't some of 
these outliers be due to GC? I wouldn't claim that all of them are due 
to GC since you have negative milliseconds.

I have seen the same problem in C++ programs as well (no GC).  We 
figured out that TSC wasn't synced or running at a constant rate. Once 
the processor and OS were enhanced to resolve this, the problem went away.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
On 10/18/2012 7:16 AM, Jacy Odin Grannis wrote:
> In our case, we knew that the operations we were measuring weren't
> taking hundreds of milliseconds (because the number of operations
> completed in a given time frame precluded that being the case).  And
> we also knew, with even more certainty, that the operations weren't
> taking NEGATIVE hundreds of milliseconds to complete, because we were
> unfortunately not clever enough to create systems that would do that.
> Given that we expected values to be in the microsecond range, and we
> had counts which backed that up, it was pretty easy to discount values
> which were clearly out of range.  Although when we first encountered
> the issue, we checked things by simply running a set of threads
> getting nanoTime values and noting when the value would suddenly have
> a large difference from the previous value, and log those values.  We
> noted that the values logged varied significantly from one thread to
> the other, and that a given thread would at times start reporting
> values which matched up with values which had been reported by a
> different thread (i.e. b/c it had been migrated to the core that other
> thread had been running on).  We were a bit surprised at how often
> even hot threads would migrate.  As far as context switches...yes,
> those could be a confounder.  In our case, we knew what the system was
> doing very well, and had a very limited number of active threads which
> did not exceed our core count, and, as I mentioned, given that we'd
> get elapsed time values occasionally which were +/- hundreds of millis
> despite simple counts which would indicate that was impossible, well,
> eliminating context switches as our issue was not too difficult.
> However, as a general rule, no, you can't reject outliers out-of-hand,
> you have to do some digging.
>
> jacy
>
> On Thu, Oct 18, 2012 at 9:00 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com> wrote:
>> How do you differentiate wildly different value on the same CPU after a
>> context switch and a wildly different value on another CPU after a context
>> switch?
>>
>> Alex
>>
>>
>> On 17/10/2012 22:55, Jacy Odin Grannis wrote:
>>
>> Yes, definitely.  I've seen this happen.  One easy way you can see
>> this is System.nanoTime will suddenly start returning wildly different
>> values.  nanoTime is only consistent on a single processor, it can
>> vary widely between processors (at least on Linux).
>>
>> I think what's really needed is a set of language level constructs for
>> really addressing the problem.  I know there are experimental projects
>> looking to do that (
>> https://wiki.rice.edu/confluence/display/HABANERO/Habanero+Multicore+Software+Research+Project
>> ).  I am not sure to what extent it would be possible to build support
>> for the various constructs in the JVM; and then aside from that, how
>> you would add language support is another matter.
>>
>> Jacy
>>
>> On Wed, Oct 17, 2012 at 4:30 PM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu> wrote:
>>
>> [newbie question]
>>      Is it possible for a thread to ever be moved between processors, if for
>> example the is an idle processor and another that is really busy?  If not,
>> then load balancing could be problematic.  If yes, then this means that we
>> need to take this into consideration and not build static structures based
>> on the value of which processor the thread is currently running on.
>>
>> Again, if no, then what is the guarantee that it won't be available on some
>> VMs or some hardware architectures or operating systems?
>> [/newbie question]
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 75 595 262
>> Skype: kabutz
>>
>>
>>
>> On 10/17/12 11:05 AM, Romain Colle wrote:
>>
>> On Wed, Oct 17, 2012 at 9:15 AM, Kirk Pepperdine <kirk at kodewerk.com> wrote:
>>
>> SOT, right now we are using CPUID for a number of reasons. Very easy to
>> get to on Linux as we can do this in pure Java. However other platforms
>> require C++/assembler so having <gulp> an unsafe operation in the JVM would
>> be a win from my POV.
>>
>> I strongly second that. It is next to impossible to implement most
>> NUMA-aware algorithms without knowing on which NUMA node the current thread
>> is running.
>> Having this information available as a Java class (in Thread, Unsafe, ...)
>> would be a huge win for people like us that need NUMA-aware behavior.
>>
>> Cheers,
>>
>> --
>> Romain Colle
>> R&D Project Manager
>> QuartetFS
>> 2 rue Jean Lantier, 75001 Paris, France
>> http://www.quartetfs.com
>>
>> ________________________________
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121018/fe93d3b6/attachment.html>

From aleksey.shipilev at oracle.com  Fri Oct 19 04:32:15 2012
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 19 Oct 2012 12:32:15 +0400
Subject: [concurrency-interest] Java Concurrency torture tests: need your
	help
Message-ID: <5081100F.30602@oracle.com>

Hi guys,

Following up on May discussion on volatile bug [1], I had started the
project to collect the suite of concurrency tests which are to expose
concurrency bugs [2], hopefully much more thoroughly than JCK and other
targeted tests do.

It had been going for a while, and so far it tests only the basic things
about primitives, arrays, making the infamous singleton tests, etc. etc.
My plan is hook up this suite for OpenJDK nightly testing, so don't
forget make a pull requests for your changes ;)

Here's the call for action! I would appreciate your contributions,
including but not limited to:

  a) reviewing the test correctness. Doug had been lightly supervising
this before, but "given enough eyeballs all bugs are shallow". Please
reference the exact github revision when referencing the test.

  b) running the suite on interesting hardware. Even though the tests
are scarce, I would be happy to see the results from J9/PPC and various
ARM implementations. There are couple of negative tests against legal
races (i.e. UnsafeDCLSingletonTest), it will be comforting to see they
fail expectedly on non-x86 hardware. If you do run the tests, please zip
up the results/ folder and post it somewhere.

  c) brainstorming the coverage area: what areas are missing (there are
lots!), and what should be covered in the first place.

  d) proposing basic testcases and/or pointing out known regression
tests assorted over the Internet which should be included into the suite.

  e) raising the general suggestions about usability, reliability,
methodology, etc.

Will appreciate your help!

Thanks,
Aleksey.

[1] http://cs.oswego.edu/pipermail/concurrency-interest/2012-May/009440.html
[2] https://github.com/shipilev/java-concurrency-torture

From dl at cs.oswego.edu  Fri Oct 19 12:57:35 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 19 Oct 2012 12:57:35 -0400
Subject: [concurrency-interest] regarding StampedLock
In-Reply-To: <507C581B.9050701@cs.oswego.edu>
References: <DD7C17376B6B7E4BA23276B29408B7351D397301@AMSPRD0410MB373.eurprd04.prod.outlook.com>
	<507C02C4.9030209@cs.oswego.edu>
	<507C0716.8020801@javaspecialists.eu>
	<507C0D13.3070508@cs.oswego.edu>
	<507C21DE.8090502@javaspecialists.eu>
	<507C233D.4030107@cs.oswego.edu>
	<507C2CF4.9080906@javaspecialists.eu>
	<507C581B.9050701@cs.oswego.edu>
Message-ID: <5081867F.9030000@cs.oswego.edu>

On 10/15/12 14:38, Doug Lea wrote:
>  In your tests, the reader blocks are so quick that
> lots of them can get in and out before writer queuing
> stabilizes so that phase-fair rules can kick in, at which point the writer
> will often hit an expensive context switch and have the lock stolen away
> while it is in the process of waking up. There are some mechanics for
> reducing/avoiding this that I'll put in.
>

In case anyone is waiting for these updates, they won't happen
immediately. Adaptively bridging the factor-of-10,000 rate gap to
improve performance in some programs without hurting others is
an interesting challenge. I'll be out to OOPSLA/Splash most of
next week though, so probably won't commit updates for a while.

-Doug




From martinrb at google.com  Sun Oct 21 03:57:31 2012
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 21 Oct 2012 00:57:31 -0700
Subject: [concurrency-interest] StampedLock
In-Reply-To: <507826FE.7010107@cs.oswego.edu>
References: <507826FE.7010107@cs.oswego.edu>
Message-ID: <CA+kOe09=kSJfEwAKCwFADmt+V9-t2Lsp-RFBUKGoYiwhB-+Jog@mail.gmail.com>

I think a lot of people will want to use StampedLock as a high performance
replacement for code currently using RRWL.  To make this more discoverable,
the "read-write-lock" nature of this lock should be made more obvious.
 E.g. we could name this class StampedReadWriteLock (or even
SequenceReadWriteLock).

(Or perhaps you've already rejected such names because StampedLock doesn't
implement ReadWriteLock?)

Perhaps the class javadoc should have more marketing: who would be
interested in this class?

/**
 * A high-performance non-reentrant read-write lock with support for
optimistic reads.

The phrase "capability-based" is misleading (there's no actual security
here) and not especially useful for users (except that they have to learn a
different API from ReadWriteLock).

It's unfortunate that e.g. the writeLock method has different meanings
between RWL and StampedLock.  Can we find better names?  (I'm having
trouble with that myself)

Should StampedLock acquire AbstractOwnableSynchronizer machinery, gaining
safety at the cost of performance?  I don't know.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20121021/9959040a/attachment.html>

From forax at univ-mlv.fr  Sun Oct 21 06:04:00 2012
From: forax at univ-mlv.fr (Remi Forax)
Date: Sun, 21 Oct 2012 12:04:00 +0200
Subject: [concurrency-interest] StampedLock
In-Reply-To: <CA+kOe09=kSJfEwAKCwFADmt+V9-t2Lsp-RFBUKGoYiwhB-+Jog@mail.gmail.com>
References: <507826FE.7010107@cs.oswego.edu>
	<CA+kOe09=kSJfEwAKCwFADmt+V9-t2Lsp-RFBUKGoYiwhB-+Jog@mail.gmail.com>
Message-ID: <5083C890.3040500@univ-mlv.fr>

On 10/21/2012 09:57 AM, Martin Buchholz wrote:
> I think a lot of people will want to use StampedLock as a high 
> performance replacement for code currently using RRWL.  To make this 
> more discoverable, the "read-write-lock" nature of this lock should be 
> made more obvious.  E.g. we could name this class StampedReadWriteLock 
> (or even SequenceReadWriteLock).
>
> (Or perhaps you've already rejected such names because StampedLock 
> doesn't implement ReadWriteLock?)

BTW, using same argument, the name ReadWriteLock should not have been 
chosen because it's not a Lock.

>
> Perhaps the class javadoc should have more marketing: who would be 
> interested in this class?
>
> /**
>  * A high-performance non-reentrant read-write lock with support for 
> optimistic reads.
>
> The phrase "capability-based" is misleading (there's no actual 
> security here) and not especially useful for users (except that they 
> have to learn a different API from ReadWriteLock).
>
> It's unfortunate that e.g. the writeLock method has different meanings 
> between RWL and StampedLock.  Can we find better names?  (I'm having 
> trouble with that myself)
>
> Should StampedLock acquire AbstractOwnableSynchronizer machinery, 
> gaining safety at the cost of performance?  I don't know.

R?mi


From dl at cs.oswego.edu  Tue Oct 30 10:58:22 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 30 Oct 2012 10:58:22 -0400
Subject: [concurrency-interest] Introducing ForkJoinPool.commonPool
Message-ID: <508FEB0E.2080809@cs.oswego.edu>


Several converging considerations led to the introduction
of a (static) commonPool available in ForkJoinPool.
The common pool always exists (but takes up only around 100bytes
if never used), and is now the default target for any
invocation of ForkJoinTask.{fork, invoke} if the caller is
not itself executing in a given pool. In other words,
ForkJoinTask methods that before threw exceptions because
the caller was not operating in a pool now succeed, using
the commonPool. (This is a spec change, but an innocuous
and desirable one -- a previously illegal use is now legal.)

Among other niceties, this means you can use ForkJoinTasks
without even knowing about class ForkJoinPool. But you
can still of course always create your own pools and
explicitly submit to them if you need isolation or custom
parameters.

As indicated in the javadocs, you can set construction
parameters for the commonPool using Properties.

In addition to simplifying usage, introducing a commonPool
allows some internal optimizations (as well as a few
new support methods, for example CountedCompleter.helpComplete)
that could not be supported as well from outside of
the ForkJoinPool class.

It seems likely that bulk parallel operation support in
JDK8, Scala, etc., will change to use the commonPool.
The updated ConcurrentHashMap (JDK8 or V8) class already does so.

The updates are now in all packagings (jsr166y, jsr166e,
and JDK8 java.util.concurrent). See the usual links:

JDK8 java.util.concurrent:
     API specs: http://gee.cs.oswego.edu/dl/jsr166/dist/docs/
     jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166.jar
     Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/

jsr166e:
     API specs: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/
     jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166e.jar (compiled 
using Java7 javac).
     Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/

jsr166y:
     API specs: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166ydocs/
     jar file: http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166y.jar (compiled 
using Java6 javac).
     Browsable CVS sources: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166y/

