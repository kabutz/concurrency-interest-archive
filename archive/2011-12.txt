From blue at cs.oswego.edu  Thu Dec  1 05:38:01 2011
From: blue at cs.oswego.edu (blue at cs.oswego.edu)
Date: Thu, 1 Dec 2011 07:38:01 -0300
Subject: [concurrency-interest] Obtain a University Degree based on your
	professional experience.
Message-ID: <1617537679.E7BFVSAN626038@avsesxawpdnqk.dbtkw.ua>

AFFORDABLE ONLINE BACHEL0R'S, MASTER'S & DOCT0RATE DEGREES

Add Bache1or's, Master's or Doctorate Degrees to your resume in just a few weeks and open avenues to promotion and better jobs!

At your Own Pace!
At your Own Schedule!
At your Own Convenience!

No Examination!
No Study!
No Class!

Regardless of your age, sex, marital status, or location, you can receive a degree in your desired field. All you need is sufficient work, military, or life experience and you are already on your way to an instant degree in your relevant field.

Earn a recognized University Degree based on work or life experience within weeks!
Get your desired degree on the basis of your Prior Knowledge and Professional Experience.

Give us a call NOW!

1-404-549-4731

Please leave us your:
1) Your Name
3) Phone No. 

We will get back to you ASAP


From radhakrishnan.mohan at gmail.com  Mon Dec  5 02:01:59 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 5 Dec 2011 12:31:59 +0530
Subject: [concurrency-interest] Basic question about memory barriers
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEJEJBAA.davidcholmes@aapt.net.au>
References: <CAOoXFP-6mXv=Q_qNXU6TtDUt4RZBFhLkYYpS-7Sq4QWaPkvSfw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCMEJEJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAOoXFP9CcRidjrFhM0k6bYJg3+MSTz4Q4sqmgW791pTLLvca5g@mail.gmail.com>

I think this corresponds to  "8.2.2 Memory Ordering in P6 and
More Recent Processor Families" in Intel? 64 and IA-32 Architectures
Software Developer?s Manual ? They mention fence instructions there.

Thanks,
Mohan

On Mon, Nov 28, 2011 at 3:48 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Mohan Radhakrishnan writes:
>> ? ? ?1. Who issues the memory barriers ?
>
> In the context of Java it is the runtime support code of the JVM together
> with the code emitted by the JIT.
>
>> ? ? ?2. Can I look at memory barriers in machine code ? Is it done by
>> the processor ?
>
> The "barriers" depend on the architecture. They can be explicit
> synchronization instructions; modes applied to loads and stores; or specific
> instruction sequences (eg dependent loads) that produce the desired effect.
> See the Java Memory Model Cookbook for compiler writers to learn more:
>
> http://g.oswego.edu/dl/jmm/cookbook.html
>
> David Holmes
> -----------
>
>>
>> Thanks,
>> Mohan
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>


From cheremin at gmail.com  Wed Dec  7 05:57:26 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 7 Dec 2011 14:57:26 +0400
Subject: [concurrency-interest] AtomicReferenceFieldUpdater - methods set,
	get, compareAndSet semantics
Message-ID: <CAOwENi++BMTJREPzwNP_O985x7Lg6BypYBFLZ=oK8j1AdOE7rQ@mail.gmail.com>

There is an interesting discussion on stackoverflow
http://stackoverflow.com/questions/8262982/atomicreferencefieldupdater-methods-set-get-compareandset-semantics/
-- about j.u.c.ARFUpdater spec. The confusing part of spec is:

Note that the guarantees of the compareAndSet method in this class are
weaker than in other atomic classes. Because this class cannot ensure
that all uses of the field are appropriate for purposes of atomic
access, it can guarantee atomicity and volatile semantics only with
respect to other invocations of compareAndSet and set.

As one of users supposed, this part of spec is about atomics
implementation on platforms without hardware support for atomic
instructions. So, atomics there must be emulated with locks, and, to
preserve atomicity of CAS-like operations, all accesses must be done
throught ARFUpdater methods, and not via direct field access (for
stores, actually -- direct field loads seems to be OK).

This interpretation seems to be legal and consistent, but nobody can't
find direct authoritive sources, which support such interpretation.
Can somebody clearify the reasoning behind this part of spec?

----
Cheremin Ruslan

From davidcholmes at aapt.net.au  Wed Dec  7 07:00:36 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 7 Dec 2011 22:00:36 +1000
Subject: [concurrency-interest] AtomicReferenceFieldUpdater - methods
	set, get, compareAndSet semantics
In-Reply-To: <CAOwENi++BMTJREPzwNP_O985x7Lg6BypYBFLZ=oK8j1AdOE7rQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEMCJBAA.davidcholmes@aapt.net.au>

The user is correct. On implementations that require locks, none of the
field updater classes can guarantee atomicity except with regards to other
methods of the field updater.

In practice I'm only aware of AtomicLongFieldUpdater actually having a
lock-based implementation.

David Holmes
------------

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Ruslan
> Cheremin
> Sent: Wednesday, 7 December 2011 8:57 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] AtomicReferenceFieldUpdater - methods
> set,get, compareAndSet semantics
>
>
> There is an interesting discussion on stackoverflow
> http://stackoverflow.com/questions/8262982/atomicreferencefieldupd
ater-methods-set-get-compareandset-semantics/
-- about j.u.c.ARFUpdater spec. The confusing part of spec is:

Note that the guarantees of the compareAndSet method in this class are
weaker than in other atomic classes. Because this class cannot ensure
that all uses of the field are appropriate for purposes of atomic
access, it can guarantee atomicity and volatile semantics only with
respect to other invocations of compareAndSet and set.

As one of users supposed, this part of spec is about atomics
implementation on platforms without hardware support for atomic
instructions. So, atomics there must be emulated with locks, and, to
preserve atomicity of CAS-like operations, all accesses must be done
throught ARFUpdater methods, and not via direct field access (for
stores, actually -- direct field loads seems to be OK).

This interpretation seems to be legal and consistent, but nobody can't
find direct authoritive sources, which support such interpretation.
Can somebody clearify the reasoning behind this part of spec?

----
Cheremin Ruslan
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From madewael at vub.ac.be  Thu Dec  8 09:29:56 2011
From: madewael at vub.ac.be (Mattias De Wael)
Date: Thu, 8 Dec 2011 15:29:56 +0100
Subject: [concurrency-interest] Java ForkJoin demo applications
Message-ID: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>

Dear

In the paper of Doug Lea "A Java Fork/Join Framework" a battery of demo-apps is used to provide data about the performance of the framework. These demo-applications can be found on Doug Lea's Homepage. 
gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html
http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/taskDemo/demos.html

The demo code, however, is written for what seems to be a early version of the framework (Version 1.3.4 with FJTasks instead of ForkJoinTasks, FJRunnerGroups instead of ForkJoinPool, etc.)
Is anyone aware of an implementation of these demo-applications for the framework in its current state (JDK7), and where I can find them?

Thanks in advance,


Mattias De Wael
Vrije Universiteit Brussel
Faculty of Sciences, DINF - SOFT
Room 10F736, Pleinlaan 2, B-1050 Brussels, Belgium
e-mail: madewael at vub.ac.be

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111208/385346ed/attachment.html>

From adrian.tarau at gmail.com  Thu Dec  8 15:04:57 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Thu, 08 Dec 2011 15:04:57 -0500
Subject: [concurrency-interest] LongAdder in JDK?
Message-ID: <4EE11869.80500@gmail.com>

There are any plans to include LongAdder in JDK(I searched 
concurrency-interest at cs.oswego.edu on MarkMail but I coudn't find an 
answer to my question)? There are some good use cases for this 
structure, like holding a hit ratio? You might use a concurrent map but 
threads will block when updating atomic hits and misses counters, which 
happens in my case(16 threads).

Is this the stable version of the LongAdder? 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN

Thank you,
Adrian Tarau.

From heinz at javaspecialists.eu  Thu Dec  8 15:23:14 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 08 Dec 2011 22:23:14 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
Message-ID: <4EE11CB2.5060701@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111208/17f8c9a8/attachment.html>

From dl at cs.oswego.edu  Thu Dec  8 15:41:20 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 08 Dec 2011 15:41:20 -0500
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
Message-ID: <4EE120F0.7010108@cs.oswego.edu>

On 12/08/11 09:29, Mattias De Wael wrote:

> In the paper of Doug Lea "A Java Fork/Join Framework" a battery of demo-apps is
> used to provide data about the performance of the framework.

Variants of these and others are available in our misc
performance test directory
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

including: Integrate IntegrateGamma Fib LeftSpineFib DynamicFib
DynamicLeftSpineFib  DynamicAsyncFib ScalarLongSort BoxedLongSort
NQueensCS AsyncNQueensCS FJSums MatrixMultiply LU Microscope
TorusSpanningTree FJJacobi FJPhaserJacobi Heat

See near the bottom of
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
for  some notes about loops tests.

-Doug

From heinz at javaspecialists.eu  Thu Dec  8 15:54:39 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 08 Dec 2011 22:54:39 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE11CB2.5060701@javaspecialists.eu>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
	<4EE11CB2.5060701@javaspecialists.eu>
Message-ID: <4EE1240F.9060601@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111208/5428d2d0/attachment.html>

From heinz at javaspecialists.eu  Thu Dec  8 16:01:56 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 08 Dec 2011 23:01:56 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE120F0.7010108@cs.oswego.edu>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
	<4EE120F0.7010108@cs.oswego.edu>
Message-ID: <4EE125C4.20805@javaspecialists.eu>

Hi Doug,

in your Fib example: 
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/Fib.java?revision=1.5&view=markup

should "number" not be marked as volatile, as it is accessed from 
multiple threads?

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 12/8/11 10:41 PM, Doug Lea wrote:
> On 12/08/11 09:29, Mattias De Wael wrote:
>
>> In the paper of Doug Lea "A Java Fork/Join Framework" a battery of 
>> demo-apps is
>> used to provide data about the performance of the framework.
>
> Variants of these and others are available in our misc
> performance test directory
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/
>
> including: Integrate IntegrateGamma Fib LeftSpineFib DynamicFib
> DynamicLeftSpineFib  DynamicAsyncFib ScalarLongSort BoxedLongSort
> NQueensCS AsyncNQueensCS FJSums MatrixMultiply LU Microscope
> TorusSpanningTree FJJacobi FJPhaserJacobi Heat
>
> See near the bottom of
> http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
> for  some notes about loops tests.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From dl at cs.oswego.edu  Thu Dec  8 16:09:37 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 08 Dec 2011 16:09:37 -0500
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE125C4.20805@javaspecialists.eu>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
	<4EE120F0.7010108@cs.oswego.edu>
	<4EE125C4.20805@javaspecialists.eu>
Message-ID: <4EE12791.1060205@cs.oswego.edu>

On 12/08/11 16:01, Dr Heinz M. Kabutz wrote:
> Hi Doug,
>
> in your Fib example:
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/Fib.java?revision=1.5&view=markup
>
>
> should "number" not be marked as volatile, as it is accessed from multiple threads?
>

No. See The javadocs for some explanation. Pasting from the spec for 
ForkJoinTask.fork:

Subsequent modifications to the state of this task or any data it operates on 
are not necessarily consistently observable by any thread other than the one 
executing it unless preceded by a call to join()  or related methods, or a call 
to isDone()  returning true.

As far as memory effects go, reading the results of a joined
computation are basically the same as reading data after
reading a volatile "ready" flag. Usually (in both cases)
you do not need to declare the data itself volatile.

-Doug


From dl at cs.oswego.edu  Thu Dec  8 16:38:58 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 08 Dec 2011 16:38:58 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE11869.80500@gmail.com>
References: <4EE11869.80500@gmail.com>
Message-ID: <4EE12E72.7040803@cs.oswego.edu>

On 12/08/11 15:04, Adrian Tarau wrote:
> There are any plans to include LongAdder in JDK

Yes. Everything in package jsr166e is a candidate for JDK8.

> Is this the stable version of the LongAdder?
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN

Yes. Comments, experience reports, etc are welcome.

-Doug

From cdennis at terracottatech.com  Thu Dec  8 16:42:53 2011
From: cdennis at terracottatech.com (Chris Dennis)
Date: Thu, 8 Dec 2011 16:42:53 -0500
Subject: [concurrency-interest] ConcurrentMap consistency requirements
	confusion
Message-ID: <71F9947C-46E6-408A-B299-AE9E0CD02EED@terracottatech.com>

Hi All,

This question may be born out of an inability to parse the English language, fully understand the JVM, me being a pedant, or it may have an interesting story behind it.  I wondered if someone on this list could enlighten me regardless.

The javadoc for ConcurrentMap (the interface *not* CHM) states:

"Memory consistency effects: As with other concurrent collections, actions in a thread prior to placing an object into a ConcurrentMap as a key or value happen-before actions subsequent to the access or removal of that object from the ConcurrentMap in another thread."

This seems to imply to me by saying "...actions in a thread prior to placing an..." rather than "...actions in a thread prior to and including the action of placing an..." that there is no requirement in a ConcurrentMap for there to be a happens-before relationship between the action of putting the mapping in to the map and subsequently attempting to read that mapping.

Does that mean that a valid ConcurrentMap implementation could cause the following method to never terminate?

========================================
  public static void foreverRead(final ConcurrentMap<Boolean, Boolean> map) throws InterruptedException {
    Thread t = new Thread() {
      @Override
      public void run() {
        while (!map.containsKey(Boolean.TRUE));
      }
    };
    t.start();
    
    map.put(Boolean.TRUE, Boolean.TRUE);
    
    t.join();
  }
========================================

CHM obviously does terminate here due to it's implementation, as I imagine most (if not all) possible implementations would.

Thanks in advance for any information or education.  

Chris

From heinz at javaspecialists.eu  Thu Dec  8 17:30:58 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 09 Dec 2011 00:30:58 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE12791.1060205@cs.oswego.edu>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
	<4EE120F0.7010108@cs.oswego.edu>
	<4EE125C4.20805@javaspecialists.eu>
	<4EE12791.1060205@cs.oswego.edu>
Message-ID: <4EE13AA2.5060508@javaspecialists.eu>

Thanks Doug.  I had read that comment, but did not realize the 
implications.  Like most of the 10_000_000 Java programmers out there, 
I'm still new to Fork/Join.  For example, I found it interesting to 
discover that all the F/J threads are daemons.  Also that you cannot 
interrupt the threads using the standard cancel() mechanism.  This makes 
sense, of course, as F/J is meant to be used to do a calculation in 
parallel, not to call blocking methods.

I wrote a little class that demonstrates the visibility of state 
nicely.  If you run it, the compute() method forks two tasks.  f2 is 
reading running, which happens to be its own field.  As a result, the 
value is typically inlined and so changes are not visible anymore.  Task 
f1 sleeps for a second and then sets the field to "false".  The main 
task does a join on f1, so that thread sees the value change, as you 
explained.  The other thread, however, keeps on running forever.

The daemon threads make this whole exercise a bit deceptive.  Let's say 
we do not join() the thread that was forked.  That would probably be a 
coding mistake.  But if we did that, then the task would occupy one core 
at 100% and there would be no way to cancel it.

import java.util.concurrent.*;

/**
 * @author Heinz Kabutz
 */
public class ForkVisibility extends RecursiveAction {
  private static class ChangeRunningFlag extends RecursiveAction {
    private final WatchRunningFlag wrf;

    private ChangeRunningFlag(WatchRunningFlag wrf) {
      this.wrf = wrf;
    }

    protected void compute() {
      try {
        Thread.sleep(1000);
      } catch (InterruptedException e) {
        // not sure what to do with the interrupted exception here
        Thread.currentThread().interrupt();
      }
      wrf.running = false;
    }
  }

  private static class WatchRunningFlag extends RecursiveAction {
    private boolean running = true;

    protected void compute() {
      while (running) ;
      System.out.println("We have stopped running");
    }
  }

  protected void compute() {
    WatchRunningFlag f2 = new WatchRunningFlag();
    f2.fork();

    ChangeRunningFlag f1 = new ChangeRunningFlag(f2);
    f1.fork();

    f1.join();
    System.out.println("running = " + f2.running);

    System.out.println("Now let's wait for WatchRunningFlag");
    f2.join();
    System.out.println("f2.isDone() = " + f2.isDone());
  }

  public static void main(String[] args) throws InterruptedException {
    ForkJoinPool pool = new ForkJoinPool();
    ForkVisibility f = new ForkVisibility();
    pool.invoke(f);
    System.out.println(pool);
  }
}

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 12/8/11 11:09 PM, Doug Lea wrote:
> On 12/08/11 16:01, Dr Heinz M. Kabutz wrote:
>> Hi Doug,
>>
>> in your Fib example:
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/Fib.java?revision=1.5&view=markup 
>>
>>
>>
>> should "number" not be marked as volatile, as it is accessed from 
>> multiple threads?
>>
>
> No. See The javadocs for some explanation. Pasting from the spec for 
> ForkJoinTask.fork:
>
> Subsequent modifications to the state of this task or any data it 
> operates on are not necessarily consistently observable by any thread 
> other than the one executing it unless preceded by a call to join()  
> or related methods, or a call to isDone()  returning true.
>
> As far as memory effects go, reading the results of a joined
> computation are basically the same as reading data after
> reading a volatile "ready" flag. Usually (in both cases)
> you do not need to declare the data itself volatile.
>
> -Doug
>
>

From davidcholmes at aapt.net.au  Thu Dec  8 17:58:12 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 9 Dec 2011 08:58:12 +1000
Subject: [concurrency-interest] ConcurrentMap consistency
	requirementsconfusion
In-Reply-To: <71F9947C-46E6-408A-B299-AE9E0CD02EED@terracottatech.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEMJJBAA.davidcholmes@aapt.net.au>

Chris,

The ConcurrentMap itself must fulfill its basic function of being a
concurrently accessible map. If thread A adds an entry then thread B will
see that entry. The additional memory consistency docs are to clarify what
else you can infer once you have seen an entry put in by another thread.

Hope that clarifies things.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Chris
> Dennis
> Sent: Friday, 9 December 2011 7:43 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] ConcurrentMap consistency
> requirementsconfusion
>
>
> Hi All,
>
> This question may be born out of an inability to parse the
> English language, fully understand the JVM, me being a pedant, or
> it may have an interesting story behind it.  I wondered if
> someone on this list could enlighten me regardless.
>
> The javadoc for ConcurrentMap (the interface *not* CHM) states:
>
> "Memory consistency effects: As with other concurrent
> collections, actions in a thread prior to placing an object into
> a ConcurrentMap as a key or value happen-before actions
> subsequent to the access or removal of that object from the
> ConcurrentMap in another thread."
>
> This seems to imply to me by saying "...actions in a thread prior
> to placing an..." rather than "...actions in a thread prior to
> and including the action of placing an..." that there is no
> requirement in a ConcurrentMap for there to be a happens-before
> relationship between the action of putting the mapping in to the
> map and subsequently attempting to read that mapping.
>
> Does that mean that a valid ConcurrentMap implementation could
> cause the following method to never terminate?
>
> ========================================
>   public static void foreverRead(final ConcurrentMap<Boolean,
> Boolean> map) throws InterruptedException {
>     Thread t = new Thread() {
>       @Override
>       public void run() {
>         while (!map.containsKey(Boolean.TRUE));
>       }
>     };
>     t.start();
>
>     map.put(Boolean.TRUE, Boolean.TRUE);
>
>     t.join();
>   }
> ========================================
>
> CHM obviously does terminate here due to it's implementation, as
> I imagine most (if not all) possible implementations would.
>
> Thanks in advance for any information or education.
>
> Chris
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Thu Dec  8 18:07:36 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 9 Dec 2011 09:07:36 +1000
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE13AA2.5060508@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEMJJBAA.davidcholmes@aapt.net.au>

Heinz M. Kabutz writes:
> Thanks Doug.  I had read that comment, but did not realize the
> implications.  Like most of the 10_000_000 Java programmers out there,
> I'm still new to Fork/Join.  For example, I found it interesting to
> discover that all the F/J threads are daemons.  Also that you cannot
> interrupt the threads using the standard cancel() mechanism.  This makes
> sense, of course, as F/J is meant to be used to do a calculation in
> parallel, not to call blocking methods.
>
> I wrote a little class that demonstrates the visibility of state
> nicely.  If you run it, the compute() method forks two tasks.  f2 is
> reading running, which happens to be its own field.  As a result, the
> value is typically inlined and so changes are not visible anymore.  Task
> f1 sleeps for a second and then sets the field to "false".  The main
> task does a join on f1, so that thread sees the value change, as you
> explained.  The other thread, however, keeps on running forever.

So to be clear this is exactly as expected. There is no synchronization
action between the two tasks that causes a happens-before relationship
between the reads and writes of "running". So in this case "running" must be
a volatile field.

> The daemon threads make this whole exercise a bit deceptive.  Let's say
> we do not join() the thread that was forked.  That would probably be a
> coding mistake.  But if we did that, then the task would occupy one core
> at 100% and there would be no way to cancel it.

What has this got to do with the thread being a daemon ? The daemon state of
a thread only influences when the VM can terminate.

Any thread spinning in a tight infinite loop can not be cancelled as there
are no "cancellation points" in the loop. Your only recourse there would be
to try Thread.stop().

David
-----


> import java.util.concurrent.*;
>
> /**
>  * @author Heinz Kabutz
>  */
> public class ForkVisibility extends RecursiveAction {
>   private static class ChangeRunningFlag extends RecursiveAction {
>     private final WatchRunningFlag wrf;
>
>     private ChangeRunningFlag(WatchRunningFlag wrf) {
>       this.wrf = wrf;
>     }
>
>     protected void compute() {
>       try {
>         Thread.sleep(1000);
>       } catch (InterruptedException e) {
>         // not sure what to do with the interrupted exception here
>         Thread.currentThread().interrupt();
>       }
>       wrf.running = false;
>     }
>   }
>
>   private static class WatchRunningFlag extends RecursiveAction {
>     private boolean running = true;
>
>     protected void compute() {
>       while (running) ;
>       System.out.println("We have stopped running");
>     }
>   }
>
>   protected void compute() {
>     WatchRunningFlag f2 = new WatchRunningFlag();
>     f2.fork();
>
>     ChangeRunningFlag f1 = new ChangeRunningFlag(f2);
>     f1.fork();
>
>     f1.join();
>     System.out.println("running = " + f2.running);
>
>     System.out.println("Now let's wait for WatchRunningFlag");
>     f2.join();
>     System.out.println("f2.isDone() = " + f2.isDone());
>   }
>
>   public static void main(String[] args) throws InterruptedException {
>     ForkJoinPool pool = new ForkJoinPool();
>     ForkVisibility f = new ForkVisibility();
>     pool.invoke(f);
>     System.out.println(pool);
>   }
> }
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
>
> On 12/8/11 11:09 PM, Doug Lea wrote:
> > On 12/08/11 16:01, Dr Heinz M. Kabutz wrote:
> >> Hi Doug,
> >>
> >> in your Fib example:
> >>
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/Fib.java?
revision=1.5&view=markup
>>
>>
>>
>> should "number" not be marked as volatile, as it is accessed from
>> multiple threads?
>>
>
> No. See The javadocs for some explanation. Pasting from the spec for
> ForkJoinTask.fork:
>
> Subsequent modifications to the state of this task or any data it
> operates on are not necessarily consistently observable by any thread
> other than the one executing it unless preceded by a call to join()
> or related methods, or a call to isDone()  returning true.
>
> As far as memory effects go, reading the results of a joined
> computation are basically the same as reading data after
> reading a volatile "ready" flag. Usually (in both cases)
> you do not need to declare the data itself volatile.
>
> -Doug
>
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From heinz at javaspecialists.eu  Thu Dec  8 18:13:28 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 09 Dec 2011 01:13:28 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEMJJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMEMJJBAA.davidcholmes@aapt.net.au>
Message-ID: <4EE14498.6060808@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/a9134b9b/attachment.html>

From davidcholmes at aapt.net.au  Thu Dec  8 18:25:21 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 9 Dec 2011 09:25:21 +1000
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <4EE14498.6060808@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEMKJBAA.davidcholmes@aapt.net.au>

Sorry I can't answer inline with these mixed-mode html messages. :(

Yes any code that wants to be cancellable has to poll the cancellation
state. FJ is nohing special in this regard.

I see what you mean about the daemon state. Tricky. If they are not daemons
then lifecycle management for the FJPool becomes very problematic in real
apps (trivial in toy apps of course).

Cheers,
David
  -----Original Message-----
  From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
  Sent: Friday, 9 December 2011 9:13 AM
  To: dholmes at ieee.org
  Cc: Doug Lea; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Java ForkJoin demo applications




explained.  The other thread, however, keeps on running forever.

So to be clear this is exactly as expected. There is no synchronization
action between the two tasks that causes a happens-before relationship
between the reads and writes of "running". So in this case "running" must be
a volatile field.
  Yes, it is as I expected.

The daemon threads make this whole exercise a bit deceptive.  Let's say
we do not join() the thread that was forked.  That would probably be a
coding mistake.  But if we did that, then the task would occupy one core
at 100% and there would be no way to cancel it.

What has this got to do with the thread being a daemon ? The daemon state of
a thread only influences when the VM can terminate.

Any thread spinning in a tight infinite loop can not be cancelled as there
are no "cancellation points" in the loop. Your only recourse there would be
to try Thread.stop().
  Right, I'm still trying to figure out how this F/J works best.  This means
that any calculation that takes a while will need to regularly check the
isCanceled() flag.

  What I mean by deceptive is that if you run a toy example from your main()
method, it will terminate by simply killing the daemon threads, even if the
job has not actually finished.  If you then run this in a larger
application, you could end up with a problem.

  I do understand, I think, what's going on, but am just worried about the
9_999_970 "other" Java programmers who are not on this list ;-)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/a00c5022/attachment-0001.html>

From heinz at javaspecialists.eu  Thu Dec  8 18:30:47 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 09 Dec 2011 01:30:47 +0200
Subject: [concurrency-interest] Java ForkJoin demo applications
In-Reply-To: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
References: <691F081D-EF67-4894-BA0F-8428995D851B@vub.ac.be>
Message-ID: <4EE148A7.5030608@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/b6872277/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: MSort.java
Type: text/x-java
Size: 8508 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/b6872277/attachment.bin>

From hans.boehm at hp.com  Thu Dec  8 19:26:54 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Fri, 9 Dec 2011 00:26:54 +0000
Subject: [concurrency-interest] ConcurrentMap
	consistency	requirementsconfusion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEMJJBAA.davidcholmes@aapt.net.au>
References: <71F9947C-46E6-408A-B299-AE9E0CD02EED@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCCEMJJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1EC5@G4W3299.americas.hpqcorp.net>

Kind of.  The Java memory model makes very weak progress guarantees.  I do not believe that the program below is guaranteed to terminate.  For example, on a uniprocessor, the thread running the loop is allowed to get all the cycles, causing TRUE to never get added to the map.  The analogous statement would still be true if you just set and read a volatile rather than adding to a map.

My impression is that there exist JVMs for which this program may not terminate.  (When this was discussed as part of JSR133, I think execution of stored procedures in an Oracle DB was proposed as an example.  I have no idea whether that's still an issue, or possibly was even only hypothetical even at the time.  Old green threads JVMs are another, probably uninteresting, example.  Old Solaris-style mxn thread implementations may sometimes have similar issues.)

There are reasons for not making such guarantees, though they can be debated.  They include:

- In some special purpose contexts, a nonpreemptive thread implementation may be adequate.  (Some people even believe that's true in a general purpose context.  I don't, though I think I believe the special purpose claim.)

- I think we still have some open issues about whether all hardware guarantees that if you issue a store instruction, the result makes it out of the store buffer in a bounded amount of time.  Without such a guarantee, it's difficult for the implementation to guarantee any substantial progress guarantee.  Architecture manuals usually don't discuss this.

I don't think these are the only issues, but hopefully you get the idea ...

Hans

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> Sent: Thursday, December 08, 2011 2:58 PM
> To: Chris Dennis; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ConcurrentMap consistency
> requirementsconfusion
> 
> Chris,
> 
> The ConcurrentMap itself must fulfill its basic function of being a
> concurrently accessible map. If thread A adds an entry then thread B
> will
> see that entry. The additional memory consistency docs are to clarify
> what
> else you can infer once you have seen an entry put in by another
> thread.
> 
> Hope that clarifies things.
> 
> David Holmes
> 
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Chris
> > Dennis
> > Sent: Friday, 9 December 2011 7:43 AM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] ConcurrentMap consistency
> > requirementsconfusion
> >
> >
> > Hi All,
> >
> > This question may be born out of an inability to parse the
> > English language, fully understand the JVM, me being a pedant, or
> > it may have an interesting story behind it.  I wondered if
> > someone on this list could enlighten me regardless.
> >
> > The javadoc for ConcurrentMap (the interface *not* CHM) states:
> >
> > "Memory consistency effects: As with other concurrent
> > collections, actions in a thread prior to placing an object into
> > a ConcurrentMap as a key or value happen-before actions
> > subsequent to the access or removal of that object from the
> > ConcurrentMap in another thread."
> >
> > This seems to imply to me by saying "...actions in a thread prior
> > to placing an..." rather than "...actions in a thread prior to
> > and including the action of placing an..." that there is no
> > requirement in a ConcurrentMap for there to be a happens-before
> > relationship between the action of putting the mapping in to the
> > map and subsequently attempting to read that mapping.
> >
> > Does that mean that a valid ConcurrentMap implementation could
> > cause the following method to never terminate?
> >
> > ========================================
> >   public static void foreverRead(final ConcurrentMap<Boolean,
> > Boolean> map) throws InterruptedException {
> >     Thread t = new Thread() {
> >       @Override
> >       public void run() {
> >         while (!map.containsKey(Boolean.TRUE));
> >       }
> >     };
> >     t.start();
> >
> >     map.put(Boolean.TRUE, Boolean.TRUE);
> >
> >     t.join();
> >   }
> > ========================================
> >
> > CHM obviously does terminate here due to it's implementation, as
> > I imagine most (if not all) possible implementations would.
> >
> > Thanks in advance for any information or education.
> >
> > Chris
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From radhakrishnan.mohan at gmail.com  Thu Dec  8 19:33:52 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Fri, 9 Dec 2011 06:03:52 +0530
Subject: [concurrency-interest] CAS and synchronized
Message-ID: <CAOoXFP_zRDyLr9U0D6Yw-YJFCNXxTWnaGaMK4PJ9QrEwuZn1DA@mail.gmail.com>

Hi,
          I have read that CAS uses the processor's instruction set to
update memory values. Why is this more efficient than using
synchronized ? What is the locking overhead when we use synchronized ?


Seems it is a basic doubt again.

Thanks,
Mohan

From davidcholmes at aapt.net.au  Thu Dec  8 19:33:49 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 9 Dec 2011 10:33:49 +1000
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1EC5@G4W3299.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEMLJBAA.davidcholmes@aapt.net.au>

Hans,

I don't think scheduling pathologies were intended to be considered here.
The question was more on JMM visbility guarantees. Lets not muddy the waters
further. :)

Cheers,
David

> -----Original Message-----
> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> Sent: Friday, 9 December 2011 10:27 AM
> To: dholmes at ieee.org; Chris Dennis; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] ConcurrentMap
> consistencyrequirementsconfusion
>
>
> Kind of.  The Java memory model makes very weak progress
> guarantees.  I do not believe that the program below is
> guaranteed to terminate.  For example, on a uniprocessor, the
> thread running the loop is allowed to get all the cycles, causing
> TRUE to never get added to the map.  The analogous statement
> would still be true if you just set and read a volatile rather
> than adding to a map.
>
> My impression is that there exist JVMs for which this program may
> not terminate.  (When this was discussed as part of JSR133, I
> think execution of stored procedures in an Oracle DB was proposed
> as an example.  I have no idea whether that's still an issue, or
> possibly was even only hypothetical even at the time.  Old green
> threads JVMs are another, probably uninteresting, example.  Old
> Solaris-style mxn thread implementations may sometimes have
> similar issues.)
>
> There are reasons for not making such guarantees, though they can
> be debated.  They include:
>
> - In some special purpose contexts, a nonpreemptive thread
> implementation may be adequate.  (Some people even believe that's
> true in a general purpose context.  I don't, though I think I
> believe the special purpose claim.)
>
> - I think we still have some open issues about whether all
> hardware guarantees that if you issue a store instruction, the
> result makes it out of the store buffer in a bounded amount of
> time.  Without such a guarantee, it's difficult for the
> implementation to guarantee any substantial progress guarantee.
> Architecture manuals usually don't discuss this.
>
> I don't think these are the only issues, but hopefully you get
> the idea ...
>
> Hans
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> > interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> > Sent: Thursday, December 08, 2011 2:58 PM
> > To: Chris Dennis; concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] ConcurrentMap consistency
> > requirementsconfusion
> >
> > Chris,
> >
> > The ConcurrentMap itself must fulfill its basic function of being a
> > concurrently accessible map. If thread A adds an entry then thread B
> > will
> > see that entry. The additional memory consistency docs are to clarify
> > what
> > else you can infer once you have seen an entry put in by another
> > thread.
> >
> > Hope that clarifies things.
> >
> > David Holmes
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Chris
> > > Dennis
> > > Sent: Friday, 9 December 2011 7:43 AM
> > > To: concurrency-interest at cs.oswego.edu
> > > Subject: [concurrency-interest] ConcurrentMap consistency
> > > requirementsconfusion
> > >
> > >
> > > Hi All,
> > >
> > > This question may be born out of an inability to parse the
> > > English language, fully understand the JVM, me being a pedant, or
> > > it may have an interesting story behind it.  I wondered if
> > > someone on this list could enlighten me regardless.
> > >
> > > The javadoc for ConcurrentMap (the interface *not* CHM) states:
> > >
> > > "Memory consistency effects: As with other concurrent
> > > collections, actions in a thread prior to placing an object into
> > > a ConcurrentMap as a key or value happen-before actions
> > > subsequent to the access or removal of that object from the
> > > ConcurrentMap in another thread."
> > >
> > > This seems to imply to me by saying "...actions in a thread prior
> > > to placing an..." rather than "...actions in a thread prior to
> > > and including the action of placing an..." that there is no
> > > requirement in a ConcurrentMap for there to be a happens-before
> > > relationship between the action of putting the mapping in to the
> > > map and subsequently attempting to read that mapping.
> > >
> > > Does that mean that a valid ConcurrentMap implementation could
> > > cause the following method to never terminate?
> > >
> > > ========================================
> > >   public static void foreverRead(final ConcurrentMap<Boolean,
> > > Boolean> map) throws InterruptedException {
> > >     Thread t = new Thread() {
> > >       @Override
> > >       public void run() {
> > >         while (!map.containsKey(Boolean.TRUE));
> > >       }
> > >     };
> > >     t.start();
> > >
> > >     map.put(Boolean.TRUE, Boolean.TRUE);
> > >
> > >     t.join();
> > >   }
> > > ========================================
> > >
> > > CHM obviously does terminate here due to it's implementation, as
> > > I imagine most (if not all) possible implementations would.
> > >
> > > Thanks in advance for any information or education.
> > >
> > > Chris
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From davidcholmes at aapt.net.au  Thu Dec  8 19:49:58 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 9 Dec 2011 10:49:58 +1000
Subject: [concurrency-interest] CAS and synchronized
In-Reply-To: <CAOoXFP_zRDyLr9U0D6Yw-YJFCNXxTWnaGaMK4PJ9QrEwuZn1DA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEMMJBAA.davidcholmes@aapt.net.au>

Mohan,

>           I have read that CAS uses the processor's instruction set to
> update memory values. Why is this more efficient than using
> synchronized ? What is the locking overhead when we use synchronized ?

In simplified terms ...

Acquiring a monitor requires a CAS internally. To that you add all the
overhead pertaining to blocking, queuing, setting owner fields and recursion
counts etc. In the fastest case, with an uncontended lock, this can reduce
to little more than the CAS itself. But you still have to release the lock,
which in a good implementation does not require a CAS, but still involves
some computation. Once you introduce low contention then locks introduce
blocking and context-switching. As contention increases it can be better to
block threads rather than have a lot of retries in a CAS-loop.

HTH

David Holmes

>
> Seems it is a basic doubt again.
>
> Thanks,
> Mohan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From hans.boehm at hp.com  Thu Dec  8 20:06:24 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Fri, 9 Dec 2011 01:06:24 +0000
Subject: [concurrency-interest] ConcurrentMap
 consistencyrequirementsconfusion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEMLJBAA.davidcholmes@aapt.net.au>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1EC5@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCKEMLJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1F1E@G4W3299.americas.hpqcorp.net>

Agreed about muddying the waters.  And I should have been clearer.  The problem is that "scheduling pathologies" are somewhere between very hard and impossible to distinguish from the sort of question about progress guarantees that I think was really being asked here.

The original question claimed to be about happens-before and visibility, but I don't think it was really intended to be.  If you try to make it precise, the notion of "subsequently attempting to read" is not defined nor, I think, definable in this context.  I interpreted the question as really asking whether the put was guaranteed to eventually become visible to the first thread.   I think that question inherently has nothing to do with happens-before, and everything to do with progress guarantees.  The answer to that question is "no", for the reasons I gave.  But I may have misinterpreted the question.

Hans

> -----Original Message-----
> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> Sent: Thursday, December 08, 2011 4:34 PM
> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] ConcurrentMap
> consistencyrequirementsconfusion
> 
> Hans,
> 
> I don't think scheduling pathologies were intended to be considered
> here.
> The question was more on JMM visbility guarantees. Lets not muddy the
> waters
> further. :)
> 
> Cheers,
> David
> 
> > -----Original Message-----
> > From: Boehm, Hans [mailto:hans.boehm at hp.com]
> > Sent: Friday, 9 December 2011 10:27 AM
> > To: dholmes at ieee.org; Chris Dennis; concurrency-
> interest at cs.oswego.edu
> > Subject: RE: [concurrency-interest] ConcurrentMap
> > consistencyrequirementsconfusion
> >
> >
> > Kind of.  The Java memory model makes very weak progress
> > guarantees.  I do not believe that the program below is
> > guaranteed to terminate.  For example, on a uniprocessor, the
> > thread running the loop is allowed to get all the cycles, causing
> > TRUE to never get added to the map.  The analogous statement
> > would still be true if you just set and read a volatile rather
> > than adding to a map.
> >
> > My impression is that there exist JVMs for which this program may
> > not terminate.  (When this was discussed as part of JSR133, I
> > think execution of stored procedures in an Oracle DB was proposed
> > as an example.  I have no idea whether that's still an issue, or
> > possibly was even only hypothetical even at the time.  Old green
> > threads JVMs are another, probably uninteresting, example.  Old
> > Solaris-style mxn thread implementations may sometimes have
> > similar issues.)
> >
> > There are reasons for not making such guarantees, though they can
> > be debated.  They include:
> >
> > - In some special purpose contexts, a nonpreemptive thread
> > implementation may be adequate.  (Some people even believe that's
> > true in a general purpose context.  I don't, though I think I
> > believe the special purpose claim.)
> >
> > - I think we still have some open issues about whether all
> > hardware guarantees that if you issue a store instruction, the
> > result makes it out of the store buffer in a bounded amount of
> > time.  Without such a guarantee, it's difficult for the
> > implementation to guarantee any substantial progress guarantee.
> > Architecture manuals usually don't discuss this.
> >
> > I don't think these are the only issues, but hopefully you get
> > the idea ...
> >
> > Hans
> >
> > > -----Original Message-----
> > > From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-
> > > interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> > > Sent: Thursday, December 08, 2011 2:58 PM
> > > To: Chris Dennis; concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] ConcurrentMap consistency
> > > requirementsconfusion
> > >
> > > Chris,
> > >
> > > The ConcurrentMap itself must fulfill its basic function of being a
> > > concurrently accessible map. If thread A adds an entry then thread
> B
> > > will
> > > see that entry. The additional memory consistency docs are to
> clarify
> > > what
> > > else you can infer once you have seen an entry put in by another
> > > thread.
> > >
> > > Hope that clarifies things.
> > >
> > > David Holmes
> > >
> > > > -----Original Message-----
> > > > From: concurrency-interest-bounces at cs.oswego.edu
> > > > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> Chris
> > > > Dennis
> > > > Sent: Friday, 9 December 2011 7:43 AM
> > > > To: concurrency-interest at cs.oswego.edu
> > > > Subject: [concurrency-interest] ConcurrentMap consistency
> > > > requirementsconfusion
> > > >
> > > >
> > > > Hi All,
> > > >
> > > > This question may be born out of an inability to parse the
> > > > English language, fully understand the JVM, me being a pedant, or
> > > > it may have an interesting story behind it.  I wondered if
> > > > someone on this list could enlighten me regardless.
> > > >
> > > > The javadoc for ConcurrentMap (the interface *not* CHM) states:
> > > >
> > > > "Memory consistency effects: As with other concurrent
> > > > collections, actions in a thread prior to placing an object into
> > > > a ConcurrentMap as a key or value happen-before actions
> > > > subsequent to the access or removal of that object from the
> > > > ConcurrentMap in another thread."
> > > >
> > > > This seems to imply to me by saying "...actions in a thread prior
> > > > to placing an..." rather than "...actions in a thread prior to
> > > > and including the action of placing an..." that there is no
> > > > requirement in a ConcurrentMap for there to be a happens-before
> > > > relationship between the action of putting the mapping in to the
> > > > map and subsequently attempting to read that mapping.
> > > >
> > > > Does that mean that a valid ConcurrentMap implementation could
> > > > cause the following method to never terminate?
> > > >
> > > > ========================================
> > > >   public static void foreverRead(final ConcurrentMap<Boolean,
> > > > Boolean> map) throws InterruptedException {
> > > >     Thread t = new Thread() {
> > > >       @Override
> > > >       public void run() {
> > > >         while (!map.containsKey(Boolean.TRUE));
> > > >       }
> > > >     };
> > > >     t.start();
> > > >
> > > >     map.put(Boolean.TRUE, Boolean.TRUE);
> > > >
> > > >     t.join();
> > > >   }
> > > > ========================================
> > > >
> > > > CHM obviously does terminate here due to it's implementation, as
> > > > I imagine most (if not all) possible implementations would.
> > > >
> > > > Thanks in advance for any information or education.
> > > >
> > > > Chris
> > > > _______________________________________________
> > > > Concurrency-interest mailing list
> > > > Concurrency-interest at cs.oswego.edu
> > > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >
> > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >



From adrian.tarau at gmail.com  Thu Dec  8 20:51:05 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Thu, 08 Dec 2011 20:51:05 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE12E72.7040803@cs.oswego.edu>
References: <4EE11869.80500@gmail.com> <4EE12E72.7040803@cs.oswego.edu>
Message-ID: <4EE16989.3080202@gmail.com>

Thanks.

Any performance comparison between AtomicLong and LongAdder? If not, I 
will try to make one using Caliper <http://code.google.com/p/caliper/>

Adrian.

On 12/08/2011 04:38 PM, Doug Lea wrote:
> On 12/08/11 15:04, Adrian Tarau wrote:
>> There are any plans to include LongAdder in JDK
>
> Yes. Everything in package jsr166e is a candidate for JDK8.
>
>> Is this the stable version of the LongAdder?
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN 
>>
>
> Yes. Comments, experience reports, etc are welcome.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111208/cfaa8962/attachment.html>

From adrian.tarau at gmail.com  Fri Dec  9 11:00:46 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 09 Dec 2011 11:00:46 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE12E72.7040803@cs.oswego.edu>
References: <4EE11869.80500@gmail.com> <4EE12E72.7040803@cs.oswego.edu>
Message-ID: <4EE230AE.4000002@gmail.com>

This chart shows you why you should use JDK classes before thinking you 
can outsmart the default implementations :)
StrippedAtomicLong is my naive implementation of a LongAdder using a 
fixed number of AtomicLong instances and the masked thread id as the 
index(using 64 AtomicLongs - best performance, increasing this number 
doesn't help for maximum 20 threads).

This chart was created using Caliper <http://code.google.com/p/caliper>.



On 12/08/2011 04:38 PM, Doug Lea wrote:
> On 12/08/11 15:04, Adrian Tarau wrote:
>> There are any plans to include LongAdder in JDK
>
> Yes. Everything in package jsr166e is a candidate for JDK8.
>
>> Is this the stable version of the LongAdder?
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN 
>>
>
> Yes. Comments, experience reports, etc are welcome.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/77b72cfc/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: moz-screenshot.png
Type: image/png
Size: 89637 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/77b72cfc/attachment-0001.png>

From cdennis at terracottatech.com  Fri Dec  9 11:01:22 2011
From: cdennis at terracottatech.com (Chris Dennis)
Date: Fri, 9 Dec 2011 11:01:22 -0500
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1F1E@G4W3299.americas.hpqcorp.net>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1EC5@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCKEMLJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D1F1E@G4W3299.americas.hpqcorp.net>
Message-ID: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>

Although Hans' observations are interesting and I agree that pathological scheduling could prevent the code from ever terminating my question was intended to be explicitly about the JMM and exactly where the synchronizes-with edge must be placed in a spec compliant ConcurrentMap implementation.  As an example:

Thread A:
foo.bar = "baz";
map.put("key", value);

Thread B:
while (map.get("key") != value);
assert foo.bar == "baz";

What I'm trying to say (in a probably none too clear way) is that the spec seems to say there is a happens-before relationship between the action immediately preceding the installation of a mapping (the write to foo.bar in my example) and any actions occurring in a thread that accesses that mapping (the assert) but that the spec falls short of guaranteeing that the get in this case actually ever sees the value.  In my example it seems to me that the ConcurrentMap specification only enforces that the assert not fail *if* the mapping is observed, not that the mapping itself must be observed within any given timeframe (or at all).  While I understand David's sentiment that such a map would not be very useful - I don't see that the current specification actually excludes it.  ConcurrentHashMap actually elaborates in it's javadoc and includes the statement: "Retrievals reflect the results of the most recently completed update operations holding upon their onset.".

Maybe I'm splitting hairs with this argument, or maybe I'm just plain wrong, but the specification on ConcurrentMap imho seems to fall short of requiring the behavior that David (and I) would expect out of a sensible implementation.

Chris
  
On Dec 8, 2011, at 8:06 PM, Boehm, Hans wrote:

> Agreed about muddying the waters.  And I should have been clearer.  The problem is that "scheduling pathologies" are somewhere between very hard and impossible to distinguish from the sort of question about progress guarantees that I think was really being asked here.
> 
> The original question claimed to be about happens-before and visibility, but I don't think it was really intended to be.  If you try to make it precise, the notion of "subsequently attempting to read" is not defined nor, I think, definable in this context.  I interpreted the question as really asking whether the put was guaranteed to eventually become visible to the first thread.   I think that question inherently has nothing to do with happens-before, and everything to do with progress guarantees.  The answer to that question is "no", for the reasons I gave.  But I may have misinterpreted the question.
> 
> Hans
> 
>> -----Original Message-----
>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>> Sent: Thursday, December 08, 2011 4:34 PM
>> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
>> Subject: RE: [concurrency-interest] ConcurrentMap
>> consistencyrequirementsconfusion
>> 
>> Hans,
>> 
>> I don't think scheduling pathologies were intended to be considered
>> here.
>> The question was more on JMM visbility guarantees. Lets not muddy the
>> waters
>> further. :)
>> 
>> Cheers,
>> David
>> 
>>> -----Original Message-----
>>> From: Boehm, Hans [mailto:hans.boehm at hp.com]
>>> Sent: Friday, 9 December 2011 10:27 AM
>>> To: dholmes at ieee.org; Chris Dennis; concurrency-
>> interest at cs.oswego.edu
>>> Subject: RE: [concurrency-interest] ConcurrentMap
>>> consistencyrequirementsconfusion
>>> 
>>> 
>>> Kind of.  The Java memory model makes very weak progress
>>> guarantees.  I do not believe that the program below is
>>> guaranteed to terminate.  For example, on a uniprocessor, the
>>> thread running the loop is allowed to get all the cycles, causing
>>> TRUE to never get added to the map.  The analogous statement
>>> would still be true if you just set and read a volatile rather
>>> than adding to a map.
>>> 
>>> My impression is that there exist JVMs for which this program may
>>> not terminate.  (When this was discussed as part of JSR133, I
>>> think execution of stored procedures in an Oracle DB was proposed
>>> as an example.  I have no idea whether that's still an issue, or
>>> possibly was even only hypothetical even at the time.  Old green
>>> threads JVMs are another, probably uninteresting, example.  Old
>>> Solaris-style mxn thread implementations may sometimes have
>>> similar issues.)
>>> 
>>> There are reasons for not making such guarantees, though they can
>>> be debated.  They include:
>>> 
>>> - In some special purpose contexts, a nonpreemptive thread
>>> implementation may be adequate.  (Some people even believe that's
>>> true in a general purpose context.  I don't, though I think I
>>> believe the special purpose claim.)
>>> 
>>> - I think we still have some open issues about whether all
>>> hardware guarantees that if you issue a store instruction, the
>>> result makes it out of the store buffer in a bounded amount of
>>> time.  Without such a guarantee, it's difficult for the
>>> implementation to guarantee any substantial progress guarantee.
>>> Architecture manuals usually don't discuss this.
>>> 
>>> I don't think these are the only issues, but hopefully you get
>>> the idea ...
>>> 
>>> Hans
>>> 
>>>> -----Original Message-----
>>>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-
>>>> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
>>>> Sent: Thursday, December 08, 2011 2:58 PM
>>>> To: Chris Dennis; concurrency-interest at cs.oswego.edu
>>>> Subject: Re: [concurrency-interest] ConcurrentMap consistency
>>>> requirementsconfusion
>>>> 
>>>> Chris,
>>>> 
>>>> The ConcurrentMap itself must fulfill its basic function of being a
>>>> concurrently accessible map. If thread A adds an entry then thread
>> B
>>>> will
>>>> see that entry. The additional memory consistency docs are to
>> clarify
>>>> what
>>>> else you can infer once you have seen an entry put in by another
>>>> thread.
>>>> 
>>>> Hope that clarifies things.
>>>> 
>>>> David Holmes
>>>> 
>>>>> -----Original Message-----
>>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> Chris
>>>>> Dennis
>>>>> Sent: Friday, 9 December 2011 7:43 AM
>>>>> To: concurrency-interest at cs.oswego.edu
>>>>> Subject: [concurrency-interest] ConcurrentMap consistency
>>>>> requirementsconfusion
>>>>> 
>>>>> 
>>>>> Hi All,
>>>>> 
>>>>> This question may be born out of an inability to parse the
>>>>> English language, fully understand the JVM, me being a pedant, or
>>>>> it may have an interesting story behind it.  I wondered if
>>>>> someone on this list could enlighten me regardless.
>>>>> 
>>>>> The javadoc for ConcurrentMap (the interface *not* CHM) states:
>>>>> 
>>>>> "Memory consistency effects: As with other concurrent
>>>>> collections, actions in a thread prior to placing an object into
>>>>> a ConcurrentMap as a key or value happen-before actions
>>>>> subsequent to the access or removal of that object from the
>>>>> ConcurrentMap in another thread."
>>>>> 
>>>>> This seems to imply to me by saying "...actions in a thread prior
>>>>> to placing an..." rather than "...actions in a thread prior to
>>>>> and including the action of placing an..." that there is no
>>>>> requirement in a ConcurrentMap for there to be a happens-before
>>>>> relationship between the action of putting the mapping in to the
>>>>> map and subsequently attempting to read that mapping.
>>>>> 
>>>>> Does that mean that a valid ConcurrentMap implementation could
>>>>> cause the following method to never terminate?
>>>>> 
>>>>> ========================================
>>>>>  public static void foreverRead(final ConcurrentMap<Boolean,
>>>>> Boolean> map) throws InterruptedException {
>>>>>    Thread t = new Thread() {
>>>>>      @Override
>>>>>      public void run() {
>>>>>        while (!map.containsKey(Boolean.TRUE));
>>>>>      }
>>>>>    };
>>>>>    t.start();
>>>>> 
>>>>>    map.put(Boolean.TRUE, Boolean.TRUE);
>>>>> 
>>>>>    t.join();
>>>>>  }
>>>>> ========================================
>>>>> 
>>>>> CHM obviously does terminate here due to it's implementation, as
>>>>> I imagine most (if not all) possible implementations would.
>>>>> 
>>>>> Thanks in advance for any information or education.
>>>>> 
>>>>> Chris
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
> 



From rk at rkuhn.info  Fri Dec  9 11:50:28 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 9 Dec 2011 17:50:28 +0100
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20D1EC5@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCKEMLJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D1F1E@G4W3299.americas.hpqcorp.net>
	<0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
Message-ID: <EC295519-AD10-4BB9-ACC3-955361E8F514@rkuhn.info>


On Dec 9, 2011, at 17:01 , Chris Dennis wrote:

> Although Hans' observations are interesting and I agree that pathological scheduling could prevent the code from ever terminating my question was intended to be explicitly about the JMM and exactly where the synchronizes-with edge must be placed in a spec compliant ConcurrentMap implementation.  

There is a difference between a synchronization action and a happens-before relation: a synchronizes-with edge connects events in possibly different threads and implies happens-before relations, namely between all actions before the edge in thread A and all actions after the edge in thread B (since happens-before is transitive and intra-thread semantics have happens-before matching program order). So, the spec indirectly says that there is a synchronization edge between map.put and map.get somewhere, but the exact placement is irrelevant as all that matters is that everything that happened before the map.put in thread A happens-before everything that happens after the map.get in thread B.

BUT the spec cannot say anything about which put/get pairs are actually formed during execution of the program.

> As an example:
> 
> Thread A:
> foo.bar = "baz";
> map.put("key", value);
> 
> Thread B:
> while (map.get("key") != value);
> assert foo.bar == "baz";
> 
> What I'm trying to say (in a probably none too clear way) is that the spec seems to say there is a happens-before relationship between the action immediately preceding the installation of a mapping (the write to foo.bar in my example) and any actions occurring in a thread that accesses that mapping (the assert) but that the spec falls short of guaranteeing that the get in this case actually ever sees the value.  In my example it seems to me that the ConcurrentMap specification only enforces that the assert not fail *if* the mapping is observed, not that the mapping itself must be observed within any given timeframe (or at all).  While I understand David's sentiment that such a map would not be very useful - I don't see that the current specification actually excludes it.  ConcurrentHashMap actually elaborates in it's javadoc and includes the statement: "Retrievals reflect the results of the most recently completed update operations holding upon their onset.".
> 
I think you are interpreting the scope of the JMM too widely: the JMM is about ordering guarantees of actions between threads. Given such an ordering, the spec cannot guarantee that the program is actually executed: someone might just pull the plug. The only sensible thing to do is that map.put will publish the new information correctly (i.e. using a synchronization action), which will happen as soon as that code is actually executed, i.e. after map.put returns the rest of the world will see the new state. How this matches up with where other threads are currently in their code has nothing to do with the JMM. The JMM then only guarantees that IF someone sees the new map state, he will also see the right value in ?foo.bar?.

> Maybe I'm splitting hairs with this argument, or maybe I'm just plain wrong, but the specification on ConcurrentMap imho seems to fall short of requiring the behavior that David (and I) would expect out of a sensible implementation.
> 
As you might have guessed, I think it?s the former ;-)

Regards,

Roland

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)



From adrian.tarau at gmail.com  Fri Dec  9 14:06:11 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 09 Dec 2011 14:06:11 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE230AE.4000002@gmail.com>
References: <4EE11869.80500@gmail.com> <4EE12E72.7040803@cs.oswego.edu>
	<4EE230AE.4000002@gmail.com>
Message-ID: <4EE25C23.6050805@gmail.com>

Sorry, forgot to include some Coliper documentation about how to read 
these graphs: 
http://code.google.com/p/caliper/wiki/OnlineResults?show=content

Thanks,
Adrian Tarau.

On 12/09/2011 11:00 AM, Adrian Tarau wrote:
> This chart shows you why you should use JDK classes before thinking 
> you can outsmart the default implementations :)
> StrippedAtomicLong is my naive implementation of a LongAdder using a 
> fixed number of AtomicLong instances and the masked thread id as the 
> index(using 64 AtomicLongs - best performance, increasing this number 
> doesn't help for maximum 20 threads).
>
> This chart was created using Caliper <http://code.google.com/p/caliper>.
>
>
>
> On 12/08/2011 04:38 PM, Doug Lea wrote:
>> On 12/08/11 15:04, Adrian Tarau wrote:
>>> There are any plans to include LongAdder in JDK
>>
>> Yes. Everything in package jsr166e is a candidate for JDK8.
>>
>>> Is this the stable version of the LongAdder?
>>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN 
>>>
>>
>> Yes. Comments, experience reports, etc are welcome.
>>
>> -Doug
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/dc329215/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 89637 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/dc329215/attachment-0001.png>

From adrian.tarau at gmail.com  Fri Dec  9 14:12:57 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 09 Dec 2011 14:12:57 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE25C23.6050805@gmail.com>
References: <4EE11869.80500@gmail.com> <4EE12E72.7040803@cs.oswego.edu>
	<4EE230AE.4000002@gmail.com> <4EE25C23.6050805@gmail.com>
Message-ID: <4EE25DB9.3040804@gmail.com>

An just in case somebody wonders how is it the naive implementation, 
here is the code. Also the ns(timing) column is the median 
measurement(point 3), not really explained in the documentation.

Thanks,
Adrian Tarau.

/public abstract class ConcurrentAtomicLong {

     public static ConcurrentAtomicLong newInstance() {
         return new LongAdderImpl();
     }

     public abstract void increment();

     public abstract long get();

     protected static class StrippedAtomicLongImpl extends 
ConcurrentAtomicLong {

         private final static int THREAD_ID_BITS_USED = 5;
         private final static int THREAD_ID_BITS_SIZE = 1 << 
THREAD_ID_BITS_USED;
         private final static int THREAD_ID_BITS_MASK = 
THREAD_ID_BITS_SIZE - 1;

         private final AtomicLong[] instances = new 
AtomicLong[THREAD_ID_BITS_SIZE];

         {
             for (int index = 0; index < instances.length; index++) {
                 instances[index] = new AtomicLong(0);
             }
         }

         static int hash(int h) {
             h ^= (h >>> 20) ^ (h >>> 12);
             return h ^ (h >>> 7) ^ (h >>> 4);
         }

         @Override
         public void increment() {
             int bucket = hash((int) Thread.currentThread().getId()) & 
THREAD_ID_BITS_MASK;
             instances[bucket].incrementAndGet();
         }

         @Override
         public long get() {
             long sum = 0;
             for (AtomicLong instance : instances) {
                 sum += instance.get();
             }
             return sum;
         }
     }

     protected static class AtomicLongImpl extends ConcurrentAtomicLong {

         private final AtomicLong instance = new AtomicLong(0);

         @Override
         public void increment() {
             instance.incrementAndGet();
         }

         @Override
         public long get() {
             return instance.get();
         }
     }

     protected static class LongAdderImpl extends ConcurrentAtomicLong {

         private final LongAdder instance = new LongAdder();

         @Override
         public void increment() {
             instance.increment();
         }

         @Override
         public long get() {
             return instance.sum();
         }
     }
}/

On 12/09/2011 02:06 PM, Adrian Tarau wrote:
> Sorry, forgot to include some Coliper documentation about how to read 
> these graphs: 
> http://code.google.com/p/caliper/wiki/OnlineResults?show=content
>
> Thanks,
> Adrian Tarau.
>
> On 12/09/2011 11:00 AM, Adrian Tarau wrote:
>> This chart shows you why you should use JDK classes before thinking 
>> you can outsmart the default implementations :)
>> StrippedAtomicLong is my naive implementation of a LongAdder using a 
>> fixed number of AtomicLong instances and the masked thread id as the 
>> index(using 64 AtomicLongs - best performance, increasing this number 
>> doesn't help for maximum 20 threads).
>>
>> This chart was created using Caliper <http://code.google.com/p/caliper>.
>>
>>
>>
>> On 12/08/2011 04:38 PM, Doug Lea wrote:
>>> On 12/08/11 15:04, Adrian Tarau wrote:
>>>> There are any plans to include LongAdder in JDK
>>>
>>> Yes. Everything in package jsr166e is a candidate for JDK8.
>>>
>>>> Is this the stable version of the LongAdder?
>>>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN 
>>>>
>>>
>>> Yes. Comments, experience reports, etc are welcome.
>>>
>>> -Doug
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/c8af5e5d/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 89637 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/c8af5e5d/attachment-0001.png>

From adrian.tarau at gmail.com  Fri Dec  9 14:18:34 2011
From: adrian.tarau at gmail.com (Adrian Tarau)
Date: Fri, 09 Dec 2011 14:18:34 -0500
Subject: [concurrency-interest] LongAdder in JDK?
In-Reply-To: <4EE25DB9.3040804@gmail.com>
References: <4EE11869.80500@gmail.com> <4EE12E72.7040803@cs.oswego.edu>
	<4EE230AE.4000002@gmail.com> <4EE25C23.6050805@gmail.com>
	<4EE25DB9.3040804@gmail.com>
Message-ID: <4EE25F0A.3090200@gmail.com>

One more thing(somebody asked)...Lower is better since we measure avg 
time spent in increment().

Thanks,
Adrian Tarau.

On 12/09/2011 02:12 PM, Adrian Tarau wrote:
> An just in case somebody wonders how is it the naive implementation, 
> here is the code. Also the ns(timing) column is the median 
> measurement(point 3), not really explained in the documentation.
>
> Thanks,
> Adrian Tarau.
>
> /public abstract class ConcurrentAtomicLong {
>
>     public static ConcurrentAtomicLong newInstance() {
>         return new LongAdderImpl();
>     }
>
>     public abstract void increment();
>
>     public abstract long get();
>
>     protected static class StrippedAtomicLongImpl extends 
> ConcurrentAtomicLong {
>
>         private final static int THREAD_ID_BITS_USED = 5;
>         private final static int THREAD_ID_BITS_SIZE = 1 << 
> THREAD_ID_BITS_USED;
>         private final static int THREAD_ID_BITS_MASK = 
> THREAD_ID_BITS_SIZE - 1;
>
>         private final AtomicLong[] instances = new 
> AtomicLong[THREAD_ID_BITS_SIZE];
>
>         {
>             for (int index = 0; index < instances.length; index++) {
>                 instances[index] = new AtomicLong(0);
>             }
>         }
>
>         static int hash(int h) {
>             h ^= (h >>> 20) ^ (h >>> 12);
>             return h ^ (h >>> 7) ^ (h >>> 4);
>         }
>
>         @Override
>         public void increment() {
>             int bucket = hash((int) Thread.currentThread().getId()) & 
> THREAD_ID_BITS_MASK;
>             instances[bucket].incrementAndGet();
>         }
>
>         @Override
>         public long get() {
>             long sum = 0;
>             for (AtomicLong instance : instances) {
>                 sum += instance.get();
>             }
>             return sum;
>         }
>     }
>
>     protected static class AtomicLongImpl extends ConcurrentAtomicLong {
>
>         private final AtomicLong instance = new AtomicLong(0);
>
>         @Override
>         public void increment() {
>             instance.incrementAndGet();
>         }
>
>         @Override
>         public long get() {
>             return instance.get();
>         }
>     }
>
>     protected static class LongAdderImpl extends ConcurrentAtomicLong {
>
>         private final LongAdder instance = new LongAdder();
>
>         @Override
>         public void increment() {
>             instance.increment();
>         }
>
>         @Override
>         public long get() {
>             return instance.sum();
>         }
>     }
> }/
>
> On 12/09/2011 02:06 PM, Adrian Tarau wrote:
>> Sorry, forgot to include some Coliper documentation about how to read 
>> these graphs: 
>> http://code.google.com/p/caliper/wiki/OnlineResults?show=content
>>
>> Thanks,
>> Adrian Tarau.
>>
>> On 12/09/2011 11:00 AM, Adrian Tarau wrote:
>>> This chart shows you why you should use JDK classes before thinking 
>>> you can outsmart the default implementations :)
>>> StrippedAtomicLong is my naive implementation of a LongAdder using a 
>>> fixed number of AtomicLong instances and the masked thread id as the 
>>> index(using 64 AtomicLongs - best performance, increasing this 
>>> number doesn't help for maximum 20 threads).
>>>
>>> This chart was created using Caliper <http://code.google.com/p/caliper>.
>>>
>>>
>>>
>>> On 12/08/2011 04:38 PM, Doug Lea wrote:
>>>> On 12/08/11 15:04, Adrian Tarau wrote:
>>>>> There are any plans to include LongAdder in JDK
>>>>
>>>> Yes. Everything in package jsr166e is a candidate for JDK8.
>>>>
>>>>> Is this the stable version of the LongAdder?
>>>>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/jsr166e/?pathrev=MAIN 
>>>>>
>>>>
>>>> Yes. Comments, experience reports, etc are welcome.
>>>>
>>>> -Doug
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/36c77cf8/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 89637 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111209/36c77cf8/attachment-0001.png>

From davidcholmes at aapt.net.au  Sat Dec 10 01:51:56 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 10 Dec 2011 16:51:56 +1000
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>

Chris,

You do have a point but are also a little off-base. :)

I was wrong in my comments about it being a "concurrently accessible map" as
ConcurrentMap is not that at all. ConcurrentMap simply defines three
operations that must be performed atomically and adds the JMM constraint as
noted. To query whether your Thread A and B example "works" you have to look
at the actual implementation of the Map involved. So you need to examine the
specs for ConcurrentHashMap if that is the map you want to use in which case
a relevant statement (as you noted earlier) is:

"Retrievals reflect the results of the most recently completed update
operations holding upon their onset."

So that provides the basic guarantee that Thread B will see the item added
by Thread A (provided they both get a chance to execute the relevant code,
no thread C removes it in between, no one calls system.exit, the computer is
not rebooted, the universe does not end etc :) )

Cheers,
David

> -----Original Message-----
> From: Chris Dennis [mailto:cdennis at terracottatech.com]
> Sent: Saturday, 10 December 2011 2:01 AM
> To: Boehm, Hans
> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] ConcurrentMap
> consistencyrequirementsconfusion
>
>
> Although Hans' observations are interesting and I agree that
> pathological scheduling could prevent the code from ever
> terminating my question was intended to be explicitly about the
> JMM and exactly where the synchronizes-with edge must be placed
> in a spec compliant ConcurrentMap implementation.  As an example:
>
> Thread A:
> foo.bar = "baz";
> map.put("key", value);
>
> Thread B:
> while (map.get("key") != value);
> assert foo.bar == "baz";
>
> What I'm trying to say (in a probably none too clear way) is that
> the spec seems to say there is a happens-before relationship
> between the action immediately preceding the installation of a
> mapping (the write to foo.bar in my example) and any actions
> occurring in a thread that accesses that mapping (the assert) but
> that the spec falls short of guaranteeing that the get in this
> case actually ever sees the value.  In my example it seems to me
> that the ConcurrentMap specification only enforces that the
> assert not fail *if* the mapping is observed, not that the
> mapping itself must be observed within any given timeframe (or at
> all).  While I understand David's sentiment that such a map would
> not be very useful - I don't see that the current specification
> actually excludes it.  ConcurrentHashMap actually elaborates in
> it's javadoc and includes the statement: "Retrievals reflect the
> results of the most recently completed update operations holding
> upon their onset.".
>
> Maybe I'm splitting hairs with this argument, or maybe I'm just
> plain wrong, but the specification on ConcurrentMap imho seems to
> fall short of requiring the behavior that David (and I) would
> expect out of a sensible implementation.
>
> Chris
>
> On Dec 8, 2011, at 8:06 PM, Boehm, Hans wrote:
>
> > Agreed about muddying the waters.  And I should have been
> clearer.  The problem is that "scheduling pathologies" are
> somewhere between very hard and impossible to distinguish from
> the sort of question about progress guarantees that I think was
> really being asked here.
> >
> > The original question claimed to be about happens-before and
> visibility, but I don't think it was really intended to be.  If
> you try to make it precise, the notion of "subsequently
> attempting to read" is not defined nor, I think, definable in
> this context.  I interpreted the question as really asking
> whether the put was guaranteed to eventually become visible to
> the first thread.   I think that question inherently has nothing
> to do with happens-before, and everything to do with progress
> guarantees.  The answer to that question is "no", for the reasons
> I gave.  But I may have misinterpreted the question.
> >
> > Hans
> >
> >> -----Original Message-----
> >> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> >> Sent: Thursday, December 08, 2011 4:34 PM
> >> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
> >> Subject: RE: [concurrency-interest] ConcurrentMap
> >> consistencyrequirementsconfusion
> >>
> >> Hans,
> >>
> >> I don't think scheduling pathologies were intended to be considered
> >> here.
> >> The question was more on JMM visbility guarantees. Lets not muddy the
> >> waters
> >> further. :)
> >>
> >> Cheers,
> >> David
> >>
> >>> -----Original Message-----
> >>> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> >>> Sent: Friday, 9 December 2011 10:27 AM
> >>> To: dholmes at ieee.org; Chris Dennis; concurrency-
> >> interest at cs.oswego.edu
> >>> Subject: RE: [concurrency-interest] ConcurrentMap
> >>> consistencyrequirementsconfusion
> >>>
> >>>
> >>> Kind of.  The Java memory model makes very weak progress
> >>> guarantees.  I do not believe that the program below is
> >>> guaranteed to terminate.  For example, on a uniprocessor, the
> >>> thread running the loop is allowed to get all the cycles, causing
> >>> TRUE to never get added to the map.  The analogous statement
> >>> would still be true if you just set and read a volatile rather
> >>> than adding to a map.
> >>>
> >>> My impression is that there exist JVMs for which this program may
> >>> not terminate.  (When this was discussed as part of JSR133, I
> >>> think execution of stored procedures in an Oracle DB was proposed
> >>> as an example.  I have no idea whether that's still an issue, or
> >>> possibly was even only hypothetical even at the time.  Old green
> >>> threads JVMs are another, probably uninteresting, example.  Old
> >>> Solaris-style mxn thread implementations may sometimes have
> >>> similar issues.)
> >>>
> >>> There are reasons for not making such guarantees, though they can
> >>> be debated.  They include:
> >>>
> >>> - In some special purpose contexts, a nonpreemptive thread
> >>> implementation may be adequate.  (Some people even believe that's
> >>> true in a general purpose context.  I don't, though I think I
> >>> believe the special purpose claim.)
> >>>
> >>> - I think we still have some open issues about whether all
> >>> hardware guarantees that if you issue a store instruction, the
> >>> result makes it out of the store buffer in a bounded amount of
> >>> time.  Without such a guarantee, it's difficult for the
> >>> implementation to guarantee any substantial progress guarantee.
> >>> Architecture manuals usually don't discuss this.
> >>>
> >>> I don't think these are the only issues, but hopefully you get
> >>> the idea ...
> >>>
> >>> Hans
> >>>
> >>>> -----Original Message-----
> >>>> From: concurrency-interest-bounces at cs.oswego.edu
> >> [mailto:concurrency-
> >>>> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> >>>> Sent: Thursday, December 08, 2011 2:58 PM
> >>>> To: Chris Dennis; concurrency-interest at cs.oswego.edu
> >>>> Subject: Re: [concurrency-interest] ConcurrentMap consistency
> >>>> requirementsconfusion
> >>>>
> >>>> Chris,
> >>>>
> >>>> The ConcurrentMap itself must fulfill its basic function of being a
> >>>> concurrently accessible map. If thread A adds an entry then thread
> >> B
> >>>> will
> >>>> see that entry. The additional memory consistency docs are to
> >> clarify
> >>>> what
> >>>> else you can infer once you have seen an entry put in by another
> >>>> thread.
> >>>>
> >>>> Hope that clarifies things.
> >>>>
> >>>> David Holmes
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: concurrency-interest-bounces at cs.oswego.edu
> >>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> >> Chris
> >>>>> Dennis
> >>>>> Sent: Friday, 9 December 2011 7:43 AM
> >>>>> To: concurrency-interest at cs.oswego.edu
> >>>>> Subject: [concurrency-interest] ConcurrentMap consistency
> >>>>> requirementsconfusion
> >>>>>
> >>>>>
> >>>>> Hi All,
> >>>>>
> >>>>> This question may be born out of an inability to parse the
> >>>>> English language, fully understand the JVM, me being a pedant, or
> >>>>> it may have an interesting story behind it.  I wondered if
> >>>>> someone on this list could enlighten me regardless.
> >>>>>
> >>>>> The javadoc for ConcurrentMap (the interface *not* CHM) states:
> >>>>>
> >>>>> "Memory consistency effects: As with other concurrent
> >>>>> collections, actions in a thread prior to placing an object into
> >>>>> a ConcurrentMap as a key or value happen-before actions
> >>>>> subsequent to the access or removal of that object from the
> >>>>> ConcurrentMap in another thread."
> >>>>>
> >>>>> This seems to imply to me by saying "...actions in a thread prior
> >>>>> to placing an..." rather than "...actions in a thread prior to
> >>>>> and including the action of placing an..." that there is no
> >>>>> requirement in a ConcurrentMap for there to be a happens-before
> >>>>> relationship between the action of putting the mapping in to the
> >>>>> map and subsequently attempting to read that mapping.
> >>>>>
> >>>>> Does that mean that a valid ConcurrentMap implementation could
> >>>>> cause the following method to never terminate?
> >>>>>
> >>>>> ========================================
> >>>>>  public static void foreverRead(final ConcurrentMap<Boolean,
> >>>>> Boolean> map) throws InterruptedException {
> >>>>>    Thread t = new Thread() {
> >>>>>      @Override
> >>>>>      public void run() {
> >>>>>        while (!map.containsKey(Boolean.TRUE));
> >>>>>      }
> >>>>>    };
> >>>>>    t.start();
> >>>>>
> >>>>>    map.put(Boolean.TRUE, Boolean.TRUE);
> >>>>>
> >>>>>    t.join();
> >>>>>  }
> >>>>> ========================================
> >>>>>
> >>>>> CHM obviously does terminate here due to it's implementation, as
> >>>>> I imagine most (if not all) possible implementations would.
> >>>>>
> >>>>> Thanks in advance for any information or education.
> >>>>>
> >>>>> Chris
> >>>>> _______________________________________________
> >>>>> Concurrency-interest mailing list
> >>>>> Concurrency-interest at cs.oswego.edu
> >>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>>
> >>>>
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at cs.oswego.edu
> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >
>
>


From hans.boehm at hp.com  Sat Dec 10 13:21:48 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Sat, 10 Dec 2011 18:21:48 +0000
Subject: [concurrency-interest]
	ConcurrentMap	consistencyrequirementsconfusion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>

> From: David Holmes
> 
> Chris,
> 
> You do have a point but are also a little off-base. :)
> 
> I was wrong in my comments about it being a "concurrently accessible
> map" as
> ConcurrentMap is not that at all. ConcurrentMap simply defines three
> operations that must be performed atomically and adds the JMM
> constraint as
> noted. To query whether your Thread A and B example "works" you have to
> look
> at the actual implementation of the Map involved. So you need to
> examine the
> specs for ConcurrentHashMap if that is the map you want to use in which
> case
> a relevant statement (as you noted earlier) is:
> 
> "Retrievals reflect the results of the most recently completed update
> operations holding upon their onset."
My problem with this statement is that we don't really know what the "most recently completed" operation is.  In general, the only ordering we have on arbitrary Java actions is happens-before.  I suspect that that you really want CHM operations to participate in the synchronization order.  Are current implementations strong enough to make that correct?  If I encode Dekker's using CHMs, as in ("key" entries initially "0"):

Thread 1:
a.put("key","1");
r1 = b.get("key");

Thread 2:
b.put("key","1");
r2 = a.get("key");

Can I get r1 = r2 = "0"?  Presumably not.

Hans

> 
> So that provides the basic guarantee that Thread B will see the item
> added
> by Thread A (provided they both get a chance to execute the relevant
> code,
> no thread C removes it in between, no one calls system.exit, the
> computer is
> not rebooted, the universe does not end etc :) )
> 
> Cheers,
> David
> 
> > -----Original Message-----
> > From: Chris Dennis [mailto:cdennis at terracottatech.com]
> > Sent: Saturday, 10 December 2011 2:01 AM
> > To: Boehm, Hans
> > Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] ConcurrentMap
> > consistencyrequirementsconfusion
> >
> >
> > Although Hans' observations are interesting and I agree that
> > pathological scheduling could prevent the code from ever
> > terminating my question was intended to be explicitly about the
> > JMM and exactly where the synchronizes-with edge must be placed
> > in a spec compliant ConcurrentMap implementation.  As an example:
> >
> > Thread A:
> > foo.bar = "baz";
> > map.put("key", value);
> >
> > Thread B:
> > while (map.get("key") != value);
> > assert foo.bar == "baz";
> >
> > What I'm trying to say (in a probably none too clear way) is that
> > the spec seems to say there is a happens-before relationship
> > between the action immediately preceding the installation of a
> > mapping (the write to foo.bar in my example) and any actions
> > occurring in a thread that accesses that mapping (the assert) but
> > that the spec falls short of guaranteeing that the get in this
> > case actually ever sees the value.  In my example it seems to me
> > that the ConcurrentMap specification only enforces that the
> > assert not fail *if* the mapping is observed, not that the
> > mapping itself must be observed within any given timeframe (or at
> > all).  While I understand David's sentiment that such a map would
> > not be very useful - I don't see that the current specification
> > actually excludes it.  ConcurrentHashMap actually elaborates in
> > it's javadoc and includes the statement: "Retrievals reflect the
> > results of the most recently completed update operations holding
> > upon their onset.".
> >
> > Maybe I'm splitting hairs with this argument, or maybe I'm just
> > plain wrong, but the specification on ConcurrentMap imho seems to
> > fall short of requiring the behavior that David (and I) would
> > expect out of a sensible implementation.
> >
> > Chris
> >
> > On Dec 8, 2011, at 8:06 PM, Boehm, Hans wrote:
> >
> > > Agreed about muddying the waters.  And I should have been
> > clearer.  The problem is that "scheduling pathologies" are
> > somewhere between very hard and impossible to distinguish from
> > the sort of question about progress guarantees that I think was
> > really being asked here.
> > >
> > > The original question claimed to be about happens-before and
> > visibility, but I don't think it was really intended to be.  If
> > you try to make it precise, the notion of "subsequently
> > attempting to read" is not defined nor, I think, definable in
> > this context.  I interpreted the question as really asking
> > whether the put was guaranteed to eventually become visible to
> > the first thread.   I think that question inherently has nothing
> > to do with happens-before, and everything to do with progress
> > guarantees.  The answer to that question is "no", for the reasons
> > I gave.  But I may have misinterpreted the question.
> > >
> > > Hans
> > >
> > >> -----Original Message-----
> > >> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > >> Sent: Thursday, December 08, 2011 4:34 PM
> > >> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
> > >> Subject: RE: [concurrency-interest] ConcurrentMap
> > >> consistencyrequirementsconfusion
> > >>
> > >> Hans,
> > >>
> > >> I don't think scheduling pathologies were intended to be
> considered
> > >> here.
> > >> The question was more on JMM visbility guarantees. Lets not muddy
> the
> > >> waters
> > >> further. :)
> > >>
> > >> Cheers,
> > >> David
> > >>
> > >>> -----Original Message-----
> > >>> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> > >>> Sent: Friday, 9 December 2011 10:27 AM
> > >>> To: dholmes at ieee.org; Chris Dennis; concurrency-
> > >> interest at cs.oswego.edu
> > >>> Subject: RE: [concurrency-interest] ConcurrentMap
> > >>> consistencyrequirementsconfusion
> > >>>
> > >>>
> > >>> Kind of.  The Java memory model makes very weak progress
> > >>> guarantees.  I do not believe that the program below is
> > >>> guaranteed to terminate.  For example, on a uniprocessor, the
> > >>> thread running the loop is allowed to get all the cycles, causing
> > >>> TRUE to never get added to the map.  The analogous statement
> > >>> would still be true if you just set and read a volatile rather
> > >>> than adding to a map.
> > >>>
> > >>> My impression is that there exist JVMs for which this program may
> > >>> not terminate.  (When this was discussed as part of JSR133, I
> > >>> think execution of stored procedures in an Oracle DB was proposed
> > >>> as an example.  I have no idea whether that's still an issue, or
> > >>> possibly was even only hypothetical even at the time.  Old green
> > >>> threads JVMs are another, probably uninteresting, example.  Old
> > >>> Solaris-style mxn thread implementations may sometimes have
> > >>> similar issues.)
> > >>>
> > >>> There are reasons for not making such guarantees, though they can
> > >>> be debated.  They include:
> > >>>
> > >>> - In some special purpose contexts, a nonpreemptive thread
> > >>> implementation may be adequate.  (Some people even believe that's
> > >>> true in a general purpose context.  I don't, though I think I
> > >>> believe the special purpose claim.)
> > >>>
> > >>> - I think we still have some open issues about whether all
> > >>> hardware guarantees that if you issue a store instruction, the
> > >>> result makes it out of the store buffer in a bounded amount of
> > >>> time.  Without such a guarantee, it's difficult for the
> > >>> implementation to guarantee any substantial progress guarantee.
> > >>> Architecture manuals usually don't discuss this.
> > >>>
> > >>> I don't think these are the only issues, but hopefully you get
> > >>> the idea ...
> > >>>
> > >>> Hans
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: concurrency-interest-bounces at cs.oswego.edu
> > >> [mailto:concurrency-
> > >>>> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> > >>>> Sent: Thursday, December 08, 2011 2:58 PM
> > >>>> To: Chris Dennis; concurrency-interest at cs.oswego.edu
> > >>>> Subject: Re: [concurrency-interest] ConcurrentMap consistency
> > >>>> requirementsconfusion
> > >>>>
> > >>>> Chris,
> > >>>>
> > >>>> The ConcurrentMap itself must fulfill its basic function of
> being a
> > >>>> concurrently accessible map. If thread A adds an entry then
> thread
> > >> B
> > >>>> will
> > >>>> see that entry. The additional memory consistency docs are to
> > >> clarify
> > >>>> what
> > >>>> else you can infer once you have seen an entry put in by another
> > >>>> thread.
> > >>>>
> > >>>> Hope that clarifies things.
> > >>>>
> > >>>> David Holmes
> > >>>>
> > >>>>> -----Original Message-----
> > >>>>> From: concurrency-interest-bounces at cs.oswego.edu
> > >>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > >> Chris
> > >>>>> Dennis
> > >>>>> Sent: Friday, 9 December 2011 7:43 AM
> > >>>>> To: concurrency-interest at cs.oswego.edu
> > >>>>> Subject: [concurrency-interest] ConcurrentMap consistency
> > >>>>> requirementsconfusion
> > >>>>>
> > >>>>>
> > >>>>> Hi All,
> > >>>>>
> > >>>>> This question may be born out of an inability to parse the
> > >>>>> English language, fully understand the JVM, me being a pedant,
> or
> > >>>>> it may have an interesting story behind it.  I wondered if
> > >>>>> someone on this list could enlighten me regardless.
> > >>>>>
> > >>>>> The javadoc for ConcurrentMap (the interface *not* CHM) states:
> > >>>>>
> > >>>>> "Memory consistency effects: As with other concurrent
> > >>>>> collections, actions in a thread prior to placing an object
> into
> > >>>>> a ConcurrentMap as a key or value happen-before actions
> > >>>>> subsequent to the access or removal of that object from the
> > >>>>> ConcurrentMap in another thread."
> > >>>>>
> > >>>>> This seems to imply to me by saying "...actions in a thread
> prior
> > >>>>> to placing an..." rather than "...actions in a thread prior to
> > >>>>> and including the action of placing an..." that there is no
> > >>>>> requirement in a ConcurrentMap for there to be a happens-before
> > >>>>> relationship between the action of putting the mapping in to
> the
> > >>>>> map and subsequently attempting to read that mapping.
> > >>>>>
> > >>>>> Does that mean that a valid ConcurrentMap implementation could
> > >>>>> cause the following method to never terminate?
> > >>>>>
> > >>>>> ========================================
> > >>>>>  public static void foreverRead(final ConcurrentMap<Boolean,
> > >>>>> Boolean> map) throws InterruptedException {
> > >>>>>    Thread t = new Thread() {
> > >>>>>      @Override
> > >>>>>      public void run() {
> > >>>>>        while (!map.containsKey(Boolean.TRUE));
> > >>>>>      }
> > >>>>>    };
> > >>>>>    t.start();
> > >>>>>
> > >>>>>    map.put(Boolean.TRUE, Boolean.TRUE);
> > >>>>>
> > >>>>>    t.join();
> > >>>>>  }
> > >>>>> ========================================
> > >>>>>
> > >>>>> CHM obviously does terminate here due to it's implementation,
> as
> > >>>>> I imagine most (if not all) possible implementations would.
> > >>>>>
> > >>>>> Thanks in advance for any information or education.
> > >>>>>
> > >>>>> Chris
> > >>>>> _______________________________________________
> > >>>>> Concurrency-interest mailing list
> > >>>>> Concurrency-interest at cs.oswego.edu
> > >>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>>>>
> > >>>>
> > >>>> _______________________________________________
> > >>>> Concurrency-interest mailing list
> > >>>> Concurrency-interest at cs.oswego.edu
> > >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>>
> > >
> >
> >
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From rk at rkuhn.info  Sat Dec 10 15:53:39 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sat, 10 Dec 2011 21:53:39 +0100
Subject: [concurrency-interest]
	ConcurrentMap	consistencyrequirementsconfusion
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
Message-ID: <5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>


On Dec 10, 2011, at 19:21 , Boehm, Hans wrote:

>> From: David Holmes
>> 
>> Chris,
>> 
>> You do have a point but are also a little off-base. :)
>> 
>> I was wrong in my comments about it being a "concurrently accessible
>> map" as
>> ConcurrentMap is not that at all. ConcurrentMap simply defines three
>> operations that must be performed atomically and adds the JMM
>> constraint as
>> noted. To query whether your Thread A and B example "works" you have to
>> look
>> at the actual implementation of the Map involved. So you need to
>> examine the
>> specs for ConcurrentHashMap if that is the map you want to use in which
>> case
>> a relevant statement (as you noted earlier) is:
>> 
>> "Retrievals reflect the results of the most recently completed update
>> operations holding upon their onset."
> My problem with this statement is that we don't really know what the "most recently completed" operation is.

I take that to mean the same as on page 12 of jsr133.pdf: ?where subsequent is defined according to the synchronization order?, which page 17 defines as ?total order over all synchronizations in A?, where A are the actions within an execution E. There may exist several consistent but different executions with different synchronization orders for the same program, I assume.

>  In general, the only ordering we have on arbitrary Java actions is happens-before.  I suspect that that you really want CHM operations to participate in the synchronization order.  

Do I understand correctly that my above assumption/interpretation is not correct?

> Are current implementations strong enough to make that correct?  If I encode Dekker's using CHMs, as in ("key" entries initially "0"):
> 
> Thread 1:
> a.put("key","1");
> r1 = b.get("key");
> 
> Thread 2:
> b.put("key","1");
> r2 = a.get("key");
> 
I do not fully understand what you want to demonstrate here wrt. synchronization order; allow me to rephrase with volatile vars:

Thread 1:
A) a = 1;
B) r1 = b;

Thread 2:
C) b = 1;
D) r2 = a;

If I read the spec correctly, the following synchronization order would be consistent:

start -> r.b -> r.a -> w.a -> w.b -> stop

There are no synchronizes-with relations in here, and the only happens-before relations are between start and each read and between each write and stop, respectively.

There is no write where a following read sees a write which sw/hb the write. Intra-thread semantics do not add anything since the write and the read in each thread are not related.

> Can I get r1 = r2 = "0"?  Presumably not.
> 
Well, please correct my reasoning above, but I think it would be legal. And if it would be legal for volatile vars, why should it not be for CHMs?

Regards,

Roland

> Hans
> 
>> 
>> So that provides the basic guarantee that Thread B will see the item
>> added
>> by Thread A (provided they both get a chance to execute the relevant
>> code,
>> no thread C removes it in between, no one calls system.exit, the
>> computer is
>> not rebooted, the universe does not end etc :) )
>> 
>> Cheers,
>> David
>> 
>>> -----Original Message-----
>>> From: Chris Dennis [mailto:cdennis at terracottatech.com]
>>> Sent: Saturday, 10 December 2011 2:01 AM
>>> To: Boehm, Hans
>>> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] ConcurrentMap
>>> consistencyrequirementsconfusion
>>> 
>>> 
>>> Although Hans' observations are interesting and I agree that
>>> pathological scheduling could prevent the code from ever
>>> terminating my question was intended to be explicitly about the
>>> JMM and exactly where the synchronizes-with edge must be placed
>>> in a spec compliant ConcurrentMap implementation.  As an example:
>>> 
>>> Thread A:
>>> foo.bar = "baz";
>>> map.put("key", value);
>>> 
>>> Thread B:
>>> while (map.get("key") != value);
>>> assert foo.bar == "baz";
>>> 
>>> What I'm trying to say (in a probably none too clear way) is that
>>> the spec seems to say there is a happens-before relationship
>>> between the action immediately preceding the installation of a
>>> mapping (the write to foo.bar in my example) and any actions
>>> occurring in a thread that accesses that mapping (the assert) but
>>> that the spec falls short of guaranteeing that the get in this
>>> case actually ever sees the value.  In my example it seems to me
>>> that the ConcurrentMap specification only enforces that the
>>> assert not fail *if* the mapping is observed, not that the
>>> mapping itself must be observed within any given timeframe (or at
>>> all).  While I understand David's sentiment that such a map would
>>> not be very useful - I don't see that the current specification
>>> actually excludes it.  ConcurrentHashMap actually elaborates in
>>> it's javadoc and includes the statement: "Retrievals reflect the
>>> results of the most recently completed update operations holding
>>> upon their onset.".
>>> 
>>> Maybe I'm splitting hairs with this argument, or maybe I'm just
>>> plain wrong, but the specification on ConcurrentMap imho seems to
>>> fall short of requiring the behavior that David (and I) would
>>> expect out of a sensible implementation.
>>> 
>>> Chris
>>> 
>>> On Dec 8, 2011, at 8:06 PM, Boehm, Hans wrote:
>>> 
>>>> Agreed about muddying the waters.  And I should have been
>>> clearer.  The problem is that "scheduling pathologies" are
>>> somewhere between very hard and impossible to distinguish from
>>> the sort of question about progress guarantees that I think was
>>> really being asked here.
>>>> 
>>>> The original question claimed to be about happens-before and
>>> visibility, but I don't think it was really intended to be.  If
>>> you try to make it precise, the notion of "subsequently
>>> attempting to read" is not defined nor, I think, definable in
>>> this context.  I interpreted the question as really asking
>>> whether the put was guaranteed to eventually become visible to
>>> the first thread.   I think that question inherently has nothing
>>> to do with happens-before, and everything to do with progress
>>> guarantees.  The answer to that question is "no", for the reasons
>>> I gave.  But I may have misinterpreted the question.
>>>> 
>>>> Hans
>>>> 
>>>>> -----Original Message-----
>>>>> From: David Holmes [mailto:davidcholmes at aapt.net.au]
>>>>> Sent: Thursday, December 08, 2011 4:34 PM
>>>>> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
>>>>> Subject: RE: [concurrency-interest] ConcurrentMap
>>>>> consistencyrequirementsconfusion
>>>>> 
>>>>> Hans,
>>>>> 
>>>>> I don't think scheduling pathologies were intended to be
>> considered
>>>>> here.
>>>>> The question was more on JMM visbility guarantees. Lets not muddy
>> the
>>>>> waters
>>>>> further. :)
>>>>> 
>>>>> Cheers,
>>>>> David
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: Boehm, Hans [mailto:hans.boehm at hp.com]
>>>>>> Sent: Friday, 9 December 2011 10:27 AM
>>>>>> To: dholmes at ieee.org; Chris Dennis; concurrency-
>>>>> interest at cs.oswego.edu
>>>>>> Subject: RE: [concurrency-interest] ConcurrentMap
>>>>>> consistencyrequirementsconfusion
>>>>>> 
>>>>>> 
>>>>>> Kind of.  The Java memory model makes very weak progress
>>>>>> guarantees.  I do not believe that the program below is
>>>>>> guaranteed to terminate.  For example, on a uniprocessor, the
>>>>>> thread running the loop is allowed to get all the cycles, causing
>>>>>> TRUE to never get added to the map.  The analogous statement
>>>>>> would still be true if you just set and read a volatile rather
>>>>>> than adding to a map.
>>>>>> 
>>>>>> My impression is that there exist JVMs for which this program may
>>>>>> not terminate.  (When this was discussed as part of JSR133, I
>>>>>> think execution of stored procedures in an Oracle DB was proposed
>>>>>> as an example.  I have no idea whether that's still an issue, or
>>>>>> possibly was even only hypothetical even at the time.  Old green
>>>>>> threads JVMs are another, probably uninteresting, example.  Old
>>>>>> Solaris-style mxn thread implementations may sometimes have
>>>>>> similar issues.)
>>>>>> 
>>>>>> There are reasons for not making such guarantees, though they can
>>>>>> be debated.  They include:
>>>>>> 
>>>>>> - In some special purpose contexts, a nonpreemptive thread
>>>>>> implementation may be adequate.  (Some people even believe that's
>>>>>> true in a general purpose context.  I don't, though I think I
>>>>>> believe the special purpose claim.)
>>>>>> 
>>>>>> - I think we still have some open issues about whether all
>>>>>> hardware guarantees that if you issue a store instruction, the
>>>>>> result makes it out of the store buffer in a bounded amount of
>>>>>> time.  Without such a guarantee, it's difficult for the
>>>>>> implementation to guarantee any substantial progress guarantee.
>>>>>> Architecture manuals usually don't discuss this.
>>>>>> 
>>>>>> I don't think these are the only issues, but hopefully you get
>>>>>> the idea ...
>>>>>> 
>>>>>> Hans
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>>> [mailto:concurrency-
>>>>>>> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
>>>>>>> Sent: Thursday, December 08, 2011 2:58 PM
>>>>>>> To: Chris Dennis; concurrency-interest at cs.oswego.edu
>>>>>>> Subject: Re: [concurrency-interest] ConcurrentMap consistency
>>>>>>> requirementsconfusion
>>>>>>> 
>>>>>>> Chris,
>>>>>>> 
>>>>>>> The ConcurrentMap itself must fulfill its basic function of
>> being a
>>>>>>> concurrently accessible map. If thread A adds an entry then
>> thread
>>>>> B
>>>>>>> will
>>>>>>> see that entry. The additional memory consistency docs are to
>>>>> clarify
>>>>>>> what
>>>>>>> else you can infer once you have seen an entry put in by another
>>>>>>> thread.
>>>>>>> 
>>>>>>> Hope that clarifies things.
>>>>>>> 
>>>>>>> David Holmes
>>>>>>> 
>>>>>>>> -----Original Message-----
>>>>>>>> From: concurrency-interest-bounces at cs.oswego.edu
>>>>>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>>>> Chris
>>>>>>>> Dennis
>>>>>>>> Sent: Friday, 9 December 2011 7:43 AM
>>>>>>>> To: concurrency-interest at cs.oswego.edu
>>>>>>>> Subject: [concurrency-interest] ConcurrentMap consistency
>>>>>>>> requirementsconfusion
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Hi All,
>>>>>>>> 
>>>>>>>> This question may be born out of an inability to parse the
>>>>>>>> English language, fully understand the JVM, me being a pedant,
>> or
>>>>>>>> it may have an interesting story behind it.  I wondered if
>>>>>>>> someone on this list could enlighten me regardless.
>>>>>>>> 
>>>>>>>> The javadoc for ConcurrentMap (the interface *not* CHM) states:
>>>>>>>> 
>>>>>>>> "Memory consistency effects: As with other concurrent
>>>>>>>> collections, actions in a thread prior to placing an object
>> into
>>>>>>>> a ConcurrentMap as a key or value happen-before actions
>>>>>>>> subsequent to the access or removal of that object from the
>>>>>>>> ConcurrentMap in another thread."
>>>>>>>> 
>>>>>>>> This seems to imply to me by saying "...actions in a thread
>> prior
>>>>>>>> to placing an..." rather than "...actions in a thread prior to
>>>>>>>> and including the action of placing an..." that there is no
>>>>>>>> requirement in a ConcurrentMap for there to be a happens-before
>>>>>>>> relationship between the action of putting the mapping in to
>> the
>>>>>>>> map and subsequently attempting to read that mapping.
>>>>>>>> 
>>>>>>>> Does that mean that a valid ConcurrentMap implementation could
>>>>>>>> cause the following method to never terminate?
>>>>>>>> 
>>>>>>>> ========================================
>>>>>>>> public static void foreverRead(final ConcurrentMap<Boolean,
>>>>>>>> Boolean> map) throws InterruptedException {
>>>>>>>>   Thread t = new Thread() {
>>>>>>>>     @Override
>>>>>>>>     public void run() {
>>>>>>>>       while (!map.containsKey(Boolean.TRUE));
>>>>>>>>     }
>>>>>>>>   };
>>>>>>>>   t.start();
>>>>>>>> 
>>>>>>>>   map.put(Boolean.TRUE, Boolean.TRUE);
>>>>>>>> 
>>>>>>>>   t.join();
>>>>>>>> }
>>>>>>>> ========================================
>>>>>>>> 
>>>>>>>> CHM obviously does terminate here due to it's implementation,
>> as
>>>>>>>> I imagine most (if not all) possible implementations would.
>>>>>>>> 
>>>>>>>> Thanks in advance for any information or education.
>>>>>>>> 
>>>>>>>> Chris
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> 
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>> 
>>>> 
>>> 
>>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)



From joe.bowbeer at gmail.com  Sat Dec 10 17:01:58 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 10 Dec 2011 14:01:58 -0800
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
Message-ID: <CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>

Making all variables volatile should force sequentially consistent
execution over all, and program-order execution in each thread.

I think it's reasonable to model ConcurrentMap as having a separate lock or
volatile per cell, even though in practice the locks are striped.  Is the
CM spec even less constrained than this?

On Sat, Dec 10, 2011 at 12:53 PM, Roland Kuhn wrote:

> I do not fully understand what you want to demonstrate here wrt.
> synchronization order; allow me to rephrase with volatile vars:
>
> Thread 1:
> A) a = 1;
> B) r1 = b;
>
> Thread 2:
> C) b = 1;
> D) r2 = a;
>
> If I read the spec correctly, the following synchronization order would be
> consistent:
>
> start -> r.b -> r.a -> w.a -> w.b -> stop
>
> There are no synchronizes-with relations in here, and the only
> happens-before relations are between start and each read and between each
> write and stop, respectively.
>
> There is no write where a following read sees a write which sw/hb the
> write. Intra-thread semantics do not add anything since the write and the
> read in each thread are not related.
>
> > Can I get r1 = r2 = "0"?  Presumably not.
> >
> Well, please correct my reasoning above, but I think it would be legal.
> And if it would be legal for volatile vars, why should it not be for CHMs?
>
> Regards,
>
> Roland
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111210/43537e36/attachment.html>

From rk at rkuhn.info  Sat Dec 10 17:11:52 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sat, 10 Dec 2011 23:11:52 +0100
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
	<CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
Message-ID: <2A62AE88-DD4D-4227-A8E0-030D0598FE35@rkuhn.info>

Is the compiler not free to re-order the two statements in each thread? They do not depend on each other and volatile does not add anything that I can see: volatile writes may not be moved ?earlier? across other writes and volatile reads may not be moved ?later? across other reads. And of course a read of one variable may not be moved ?earlier? across a write to that variable. But none of the forbidden things is necessary to break this, or am I missing something?

On Dec 10, 2011, at 23:01 , Joe Bowbeer wrote:

> Making all variables volatile should force sequentially consistent execution over all, and program-order execution in each thread.
> 
> I think it's reasonable to model ConcurrentMap as having a separate lock or volatile per cell, even though in practice the locks are striped.  Is the CM spec even less constrained than this?
> 
> On Sat, Dec 10, 2011 at 12:53 PM, Roland Kuhn wrote:
> I do not fully understand what you want to demonstrate here wrt. synchronization order; allow me to rephrase with volatile vars:
> 
> Thread 1:
> A) a = 1;
> B) r1 = b;
> 
> Thread 2:
> C) b = 1;
> D) r2 = a;
> 
> If I read the spec correctly, the following synchronization order would be consistent:
> 
> start -> r.b -> r.a -> w.a -> w.b -> stop
> 
> There are no synchronizes-with relations in here, and the only happens-before relations are between start and each read and between each write and stop, respectively.
> 
> There is no write where a following read sees a write which sw/hb the write. Intra-thread semantics do not add anything since the write and the read in each thread are not related.
> 
> > Can I get r1 = r2 = "0"?  Presumably not.
> >
> Well, please correct my reasoning above, but I think it would be legal. And if it would be legal for volatile vars, why should it not be for CHMs?
> 
> Regards,
> 
> Roland
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111210/e1296ca3/attachment.html>

From joe.bowbeer at gmail.com  Sat Dec 10 17:32:22 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 10 Dec 2011 14:32:22 -0800
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <2A62AE88-DD4D-4227-A8E0-030D0598FE35@rkuhn.info>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
	<CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
	<2A62AE88-DD4D-4227-A8E0-030D0598FE35@rkuhn.info>
Message-ID: <CAHzJPEokCBtqJ4eLDbTaer-sHLjVDULGAurjGxBAUis3CAettQ@mail.gmail.com>

Volatile read/write is a synchronization action.  A synchronization order
is a total order over all of the synchronization actions of an execution.
 For each thread t, the synchronization order of the synchronization
actions in t is consistent with the program order of t.

http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#volatile

On Sat, Dec 10, 2011 at 2:11 PM, Roland Kuhn wrote:

> Is the compiler not free to re-order the two statements in each thread?
> They do not depend on each other and volatile does not add anything that I
> can see: volatile writes may not be moved ?earlier? across other writes and
> volatile reads may not be moved ?later? across other reads. And of course a
> read of one variable may not be moved ?earlier? across a write to that
> variable. But none of the forbidden things is necessary to break this, or
> am I missing something?
>
> On Dec 10, 2011, at 23:01 , Joe Bowbeer wrote:
>
> Making all variables volatile should force sequentially consistent
> execution over all, and program-order execution in each thread.
>
> I think it's reasonable to model ConcurrentMap as having a separate lock
> or volatile per cell, even though in practice the locks are striped.  Is
> the CM spec even less constrained than this?
>
> On Sat, Dec 10, 2011 at 12:53 PM, Roland Kuhn wrote:
>
>> I do not fully understand what you want to demonstrate here wrt.
>> synchronization order; allow me to rephrase with volatile vars:
>>
>> Thread 1:
>> A) a = 1;
>> B) r1 = b;
>>
>> Thread 2:
>> C) b = 1;
>> D) r2 = a;
>>
>> If I read the spec correctly, the following synchronization order would
>> be consistent:
>>
>> start -> r.b -> r.a -> w.a -> w.b -> stop
>>
>> There are no synchronizes-with relations in here, and the only
>> happens-before relations are between start and each read and between each
>> write and stop, respectively.
>>
>> There is no write where a following read sees a write which sw/hb the
>> write. Intra-thread semantics do not add anything since the write and the
>> read in each thread are not related.
>>
>> > Can I get r1 = r2 = "0"?  Presumably not.
>> >
>> Well, please correct my reasoning above, but I think it would be legal.
>> And if it would be legal for volatile vars, why should it not be for CHMs?
>>
>> Regards,
>>
>> Roland
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111210/a9769eae/attachment.html>

From joe.bowbeer at gmail.com  Sat Dec 10 17:51:20 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Sat, 10 Dec 2011 14:51:20 -0800
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <CAHzJPEokCBtqJ4eLDbTaer-sHLjVDULGAurjGxBAUis3CAettQ@mail.gmail.com>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
	<CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
	<2A62AE88-DD4D-4227-A8E0-030D0598FE35@rkuhn.info>
	<CAHzJPEokCBtqJ4eLDbTaer-sHLjVDULGAurjGxBAUis3CAettQ@mail.gmail.com>
Message-ID: <CAHzJPEpeRjr9wF0HQYPA_O5d5=X9MN2wT1LJRHsbKp8outAJtQ@mail.gmail.com>

By the way, the paragraph regarding synchronization actions and ordering
was cobbled together from sentences in the JMM spec:

http://java.sun.com/docs/books/jls/third_edition/html/memory.html

If the JMM were purely sequentially consistent then every action could be
viewed as a synchronization action.  And declaring all variables as
volatile is one (horrible) way to ensure this.

On Sat, Dec 10, 2011 at 2:32 PM, Joe Bowbeer wrote:

> Volatile read/write is a synchronization action.  A synchronization order
> is a total order over all of the synchronization actions of an execution.
>  For each thread t, the synchronization order of the synchronization
> actions in t is consistent with the program order of t.
>
> http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#volatile
>
> On Sat, Dec 10, 2011 at 2:11 PM, Roland Kuhn wrote:
>
> Is the compiler not free to re-order the two statements in each thread?
>> They do not depend on each other and volatile does not add anything that I
>> can see: volatile writes may not be moved ?earlier? across other writes and
>> volatile reads may not be moved ?later? across other reads. And of course a
>> read of one variable may not be moved ?earlier? across a write to that
>> variable. But none of the forbidden things is necessary to break this, or
>> am I missing something?
>>
>> On Dec 10, 2011, at 23:01 , Joe Bowbeer wrote:
>>
>> Making all variables volatile should force sequentially consistent
>> execution over all, and program-order execution in each thread.
>>
>> I think it's reasonable to model ConcurrentMap as having a separate lock
>> or volatile per cell, even though in practice the locks are striped.  Is
>> the CM spec even less constrained than this?
>>
>> On Sat, Dec 10, 2011 at 12:53 PM, Roland Kuhn wrote:
>>
>>> I do not fully understand what you want to demonstrate here wrt.
>>> synchronization order; allow me to rephrase with volatile vars:
>>>
>>> Thread 1:
>>> A) a = 1;
>>> B) r1 = b;
>>>
>>> Thread 2:
>>> C) b = 1;
>>> D) r2 = a;
>>>
>>> If I read the spec correctly, the following synchronization order would
>>> be consistent:
>>>
>>> start -> r.b -> r.a -> w.a -> w.b -> stop
>>>
>>> There are no synchronizes-with relations in here, and the only
>>> happens-before relations are between start and each read and between each
>>> write and stop, respectively.
>>>
>>> There is no write where a following read sees a write which sw/hb the
>>> write. Intra-thread semantics do not add anything since the write and the
>>> read in each thread are not related.
>>>
>>> > Can I get r1 = r2 = "0"?  Presumably not.
>>> >
>>> Well, please correct my reasoning above, but I think it would be legal.
>>> And if it would be legal for volatile vars, why should it not be for CHMs?
>>>
>>> Regards,
>>>
>>> Roland
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111210/6957cba5/attachment-0001.html>

From rk at rkuhn.info  Sat Dec 10 18:08:51 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sun, 11 Dec 2011 00:08:51 +0100
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <CAHzJPEpeRjr9wF0HQYPA_O5d5=X9MN2wT1LJRHsbKp8outAJtQ@mail.gmail.com>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
	<CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
	<2A62AE88-DD4D-4227-A8E0-030D0598FE35@rkuhn.info>
	<CAHzJPEokCBtqJ4eLDbTaer-sHLjVDULGAurjGxBAUis3CAettQ@mail.gmail.com>
	<CAHzJPEpeRjr9wF0HQYPA_O5d5=X9MN2wT1LJRHsbKp8outAJtQ@mail.gmail.com>
Message-ID: <12539A5E-66EE-40BA-9EA6-A70CF960B704@rkuhn.info>

Ah, sorry, I was confused by the possible absence of synchronizes-with edges: the actions alone are enough for 17.4.4 to mandate that volatile accesses of any kind may not be reordered. But the good thing is that I looked at the JVM spec again, which states this very clearly in section 8.7.

Sorry for the noise,

Roland

On Dec 10, 2011, at 23:51 , Joe Bowbeer wrote:

> By the way, the paragraph regarding synchronization actions and ordering was cobbled together from sentences in the JMM spec:
> 
> http://java.sun.com/docs/books/jls/third_edition/html/memory.html
> 
> If the JMM were purely sequentially consistent then every action could be viewed as a synchronization action.  And declaring all variables as volatile is one (horrible) way to ensure this.
> 
> On Sat, Dec 10, 2011 at 2:32 PM, Joe Bowbeer wrote:
> Volatile read/write is a synchronization action.  A synchronization order is a total order over all of the synchronization actions of an execution.  For each thread t, the synchronization order of the synchronization actions in t is consistent with the program order of t.
> 
> http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html#volatile
> 
> On Sat, Dec 10, 2011 at 2:11 PM, Roland Kuhn wrote:
> 
> Is the compiler not free to re-order the two statements in each thread? They do not depend on each other and volatile does not add anything that I can see: volatile writes may not be moved ?earlier? across other writes and volatile reads may not be moved ?later? across other reads. And of course a read of one variable may not be moved ?earlier? across a write to that variable. But none of the forbidden things is necessary to break this, or am I missing something?
> 
> On Dec 10, 2011, at 23:01 , Joe Bowbeer wrote:
> 
>> Making all variables volatile should force sequentially consistent execution over all, and program-order execution in each thread.
>> 
>> I think it's reasonable to model ConcurrentMap as having a separate lock or volatile per cell, even though in practice the locks are striped.  Is the CM spec even less constrained than this?
>> 
>> On Sat, Dec 10, 2011 at 12:53 PM, Roland Kuhn wrote:
>> I do not fully understand what you want to demonstrate here wrt. synchronization order; allow me to rephrase with volatile vars:
>> 
>> Thread 1:
>> A) a = 1;
>> B) r1 = b;
>> 
>> Thread 2:
>> C) b = 1;
>> D) r2 = a;
>> 
>> If I read the spec correctly, the following synchronization order would be consistent:
>> 
>> start -> r.b -> r.a -> w.a -> w.b -> stop
>> 
>> There are no synchronizes-with relations in here, and the only happens-before relations are between start and each read and between each write and stop, respectively.
>> 
>> There is no write where a following read sees a write which sw/hb the write. Intra-thread semantics do not add anything since the write and the read in each thread are not related.
>> 
>> > Can I get r1 = r2 = "0"?  Presumably not.
>> >
>> Well, please correct my reasoning above, but I think it would be legal. And if it would be legal for volatile vars, why should it not be for CHMs?
>> 
>> Regards,
>> 
>> Roland
>> 
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111211/789ae1cd/attachment.html>

From davidcholmes at aapt.net.au  Sat Dec 10 18:19:33 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 11 Dec 2011 09:19:33 +1000
Subject: [concurrency-interest]
	ConcurrentMapconsistencyrequirementsconfusion
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
Message-ID: <NFBBKALFDCPFIDBNKAPCAENEJBAA.davidcholmes@aapt.net.au>

Hans Boehm writes:
> > From: David Holmes
> > Chris,
> >
> > You do have a point but are also a little off-base. :)
> >
> > I was wrong in my comments about it being a "concurrently accessible
> > map" as
> > ConcurrentMap is not that at all. ConcurrentMap simply defines three
> > operations that must be performed atomically and adds the JMM
> > constraint as
> > noted. To query whether your Thread A and B example "works" you have to
> > look
> > at the actual implementation of the Map involved. So you need to
> > examine the
> > specs for ConcurrentHashMap if that is the map you want to use in which
> > case
> > a relevant statement (as you noted earlier) is:
> >
> > "Retrievals reflect the results of the most recently completed update
> > operations holding upon their onset."
> My problem with this statement is that we don't really know what
> the "most recently completed" operation is.  In general, the only
> ordering we have on arbitrary Java actions is happens-before.  I
> suspect that that you really want CHM operations to participate
> in the synchronization order.

We don't need to know (a priori) what the most recently completed operation
is. Given the code used to implement CHM and a particular scheduling of
threads performing various operations there comes a point where a put() by
one thread has executed to a stage that a get() by another thread will see
the result of the put(). At that point, assuming no other concurrent
operations, the put() is now the most recently completed operation.

The implementation of CHM must use whatever synchronization actions are
necessary to ensure that its JMM obligations are met.

> Are current implementations strong
> enough to make that correct?  If I encode Dekker's using CHMs, as
> in ("key" entries initially "0"):
>
> Thread 1:
> a.put("key","1");
> r1 = b.get("key");
>
> Thread 2:
> b.put("key","1");
> r2 = a.get("key");
>
> Can I get r1 = r2 = "0"?  Presumably not.

I would say you definitely should not else there is a significant bug in the
implementation.

But I fear this discussion is degenerating into the usual JMM chaos. Nothing
is guaranteed, nothing is provable so we might as well quit programming and
go home. ;-)

David
-----

> Hans
>
> >
> > So that provides the basic guarantee that Thread B will see the item
> > added
> > by Thread A (provided they both get a chance to execute the relevant
> > code,
> > no thread C removes it in between, no one calls system.exit, the
> > computer is
> > not rebooted, the universe does not end etc :) )
> >
> > Cheers,
> > David
> >
> > > -----Original Message-----
> > > From: Chris Dennis [mailto:cdennis at terracottatech.com]
> > > Sent: Saturday, 10 December 2011 2:01 AM
> > > To: Boehm, Hans
> > > Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> > > Subject: Re: [concurrency-interest] ConcurrentMap
> > > consistencyrequirementsconfusion
> > >
> > >
> > > Although Hans' observations are interesting and I agree that
> > > pathological scheduling could prevent the code from ever
> > > terminating my question was intended to be explicitly about the
> > > JMM and exactly where the synchronizes-with edge must be placed
> > > in a spec compliant ConcurrentMap implementation.  As an example:
> > >
> > > Thread A:
> > > foo.bar = "baz";
> > > map.put("key", value);
> > >
> > > Thread B:
> > > while (map.get("key") != value);
> > > assert foo.bar == "baz";
> > >
> > > What I'm trying to say (in a probably none too clear way) is that
> > > the spec seems to say there is a happens-before relationship
> > > between the action immediately preceding the installation of a
> > > mapping (the write to foo.bar in my example) and any actions
> > > occurring in a thread that accesses that mapping (the assert) but
> > > that the spec falls short of guaranteeing that the get in this
> > > case actually ever sees the value.  In my example it seems to me
> > > that the ConcurrentMap specification only enforces that the
> > > assert not fail *if* the mapping is observed, not that the
> > > mapping itself must be observed within any given timeframe (or at
> > > all).  While I understand David's sentiment that such a map would
> > > not be very useful - I don't see that the current specification
> > > actually excludes it.  ConcurrentHashMap actually elaborates in
> > > it's javadoc and includes the statement: "Retrievals reflect the
> > > results of the most recently completed update operations holding
> > > upon their onset.".
> > >
> > > Maybe I'm splitting hairs with this argument, or maybe I'm just
> > > plain wrong, but the specification on ConcurrentMap imho seems to
> > > fall short of requiring the behavior that David (and I) would
> > > expect out of a sensible implementation.
> > >
> > > Chris
> > >
> > > On Dec 8, 2011, at 8:06 PM, Boehm, Hans wrote:
> > >
> > > > Agreed about muddying the waters.  And I should have been
> > > clearer.  The problem is that "scheduling pathologies" are
> > > somewhere between very hard and impossible to distinguish from
> > > the sort of question about progress guarantees that I think was
> > > really being asked here.
> > > >
> > > > The original question claimed to be about happens-before and
> > > visibility, but I don't think it was really intended to be.  If
> > > you try to make it precise, the notion of "subsequently
> > > attempting to read" is not defined nor, I think, definable in
> > > this context.  I interpreted the question as really asking
> > > whether the put was guaranteed to eventually become visible to
> > > the first thread.   I think that question inherently has nothing
> > > to do with happens-before, and everything to do with progress
> > > guarantees.  The answer to that question is "no", for the reasons
> > > I gave.  But I may have misinterpreted the question.
> > > >
> > > > Hans
> > > >
> > > >> -----Original Message-----
> > > >> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> > > >> Sent: Thursday, December 08, 2011 4:34 PM
> > > >> To: Boehm, Hans; Chris Dennis; concurrency-interest at cs.oswego.edu
> > > >> Subject: RE: [concurrency-interest] ConcurrentMap
> > > >> consistencyrequirementsconfusion
> > > >>
> > > >> Hans,
> > > >>
> > > >> I don't think scheduling pathologies were intended to be
> > considered
> > > >> here.
> > > >> The question was more on JMM visbility guarantees. Lets not muddy
> > the
> > > >> waters
> > > >> further. :)
> > > >>
> > > >> Cheers,
> > > >> David
> > > >>
> > > >>> -----Original Message-----
> > > >>> From: Boehm, Hans [mailto:hans.boehm at hp.com]
> > > >>> Sent: Friday, 9 December 2011 10:27 AM
> > > >>> To: dholmes at ieee.org; Chris Dennis; concurrency-
> > > >> interest at cs.oswego.edu
> > > >>> Subject: RE: [concurrency-interest] ConcurrentMap
> > > >>> consistencyrequirementsconfusion
> > > >>>
> > > >>>
> > > >>> Kind of.  The Java memory model makes very weak progress
> > > >>> guarantees.  I do not believe that the program below is
> > > >>> guaranteed to terminate.  For example, on a uniprocessor, the
> > > >>> thread running the loop is allowed to get all the cycles, causing
> > > >>> TRUE to never get added to the map.  The analogous statement
> > > >>> would still be true if you just set and read a volatile rather
> > > >>> than adding to a map.
> > > >>>
> > > >>> My impression is that there exist JVMs for which this program may
> > > >>> not terminate.  (When this was discussed as part of JSR133, I
> > > >>> think execution of stored procedures in an Oracle DB was proposed
> > > >>> as an example.  I have no idea whether that's still an issue, or
> > > >>> possibly was even only hypothetical even at the time.  Old green
> > > >>> threads JVMs are another, probably uninteresting, example.  Old
> > > >>> Solaris-style mxn thread implementations may sometimes have
> > > >>> similar issues.)
> > > >>>
> > > >>> There are reasons for not making such guarantees, though they can
> > > >>> be debated.  They include:
> > > >>>
> > > >>> - In some special purpose contexts, a nonpreemptive thread
> > > >>> implementation may be adequate.  (Some people even believe that's
> > > >>> true in a general purpose context.  I don't, though I think I
> > > >>> believe the special purpose claim.)
> > > >>>
> > > >>> - I think we still have some open issues about whether all
> > > >>> hardware guarantees that if you issue a store instruction, the
> > > >>> result makes it out of the store buffer in a bounded amount of
> > > >>> time.  Without such a guarantee, it's difficult for the
> > > >>> implementation to guarantee any substantial progress guarantee.
> > > >>> Architecture manuals usually don't discuss this.
> > > >>>
> > > >>> I don't think these are the only issues, but hopefully you get
> > > >>> the idea ...
> > > >>>
> > > >>> Hans
> > > >>>
> > > >>>> -----Original Message-----
> > > >>>> From: concurrency-interest-bounces at cs.oswego.edu
> > > >> [mailto:concurrency-
> > > >>>> interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
> > > >>>> Sent: Thursday, December 08, 2011 2:58 PM
> > > >>>> To: Chris Dennis; concurrency-interest at cs.oswego.edu
> > > >>>> Subject: Re: [concurrency-interest] ConcurrentMap consistency
> > > >>>> requirementsconfusion
> > > >>>>
> > > >>>> Chris,
> > > >>>>
> > > >>>> The ConcurrentMap itself must fulfill its basic function of
> > being a
> > > >>>> concurrently accessible map. If thread A adds an entry then
> > thread
> > > >> B
> > > >>>> will
> > > >>>> see that entry. The additional memory consistency docs are to
> > > >> clarify
> > > >>>> what
> > > >>>> else you can infer once you have seen an entry put in by another
> > > >>>> thread.
> > > >>>>
> > > >>>> Hope that clarifies things.
> > > >>>>
> > > >>>> David Holmes
> > > >>>>
> > > >>>>> -----Original Message-----
> > > >>>>> From: concurrency-interest-bounces at cs.oswego.edu
> > > >>>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> > > >> Chris
> > > >>>>> Dennis
> > > >>>>> Sent: Friday, 9 December 2011 7:43 AM
> > > >>>>> To: concurrency-interest at cs.oswego.edu
> > > >>>>> Subject: [concurrency-interest] ConcurrentMap consistency
> > > >>>>> requirementsconfusion
> > > >>>>>
> > > >>>>>
> > > >>>>> Hi All,
> > > >>>>>
> > > >>>>> This question may be born out of an inability to parse the
> > > >>>>> English language, fully understand the JVM, me being a pedant,
> > or
> > > >>>>> it may have an interesting story behind it.  I wondered if
> > > >>>>> someone on this list could enlighten me regardless.
> > > >>>>>
> > > >>>>> The javadoc for ConcurrentMap (the interface *not* CHM) states:
> > > >>>>>
> > > >>>>> "Memory consistency effects: As with other concurrent
> > > >>>>> collections, actions in a thread prior to placing an object
> > into
> > > >>>>> a ConcurrentMap as a key or value happen-before actions
> > > >>>>> subsequent to the access or removal of that object from the
> > > >>>>> ConcurrentMap in another thread."
> > > >>>>>
> > > >>>>> This seems to imply to me by saying "...actions in a thread
> > prior
> > > >>>>> to placing an..." rather than "...actions in a thread prior to
> > > >>>>> and including the action of placing an..." that there is no
> > > >>>>> requirement in a ConcurrentMap for there to be a happens-before
> > > >>>>> relationship between the action of putting the mapping in to
> > the
> > > >>>>> map and subsequently attempting to read that mapping.
> > > >>>>>
> > > >>>>> Does that mean that a valid ConcurrentMap implementation could
> > > >>>>> cause the following method to never terminate?
> > > >>>>>
> > > >>>>> ========================================
> > > >>>>>  public static void foreverRead(final ConcurrentMap<Boolean,
> > > >>>>> Boolean> map) throws InterruptedException {
> > > >>>>>    Thread t = new Thread() {
> > > >>>>>      @Override
> > > >>>>>      public void run() {
> > > >>>>>        while (!map.containsKey(Boolean.TRUE));
> > > >>>>>      }
> > > >>>>>    };
> > > >>>>>    t.start();
> > > >>>>>
> > > >>>>>    map.put(Boolean.TRUE, Boolean.TRUE);
> > > >>>>>
> > > >>>>>    t.join();
> > > >>>>>  }
> > > >>>>> ========================================
> > > >>>>>
> > > >>>>> CHM obviously does terminate here due to it's implementation,
> > as
> > > >>>>> I imagine most (if not all) possible implementations would.
> > > >>>>>
> > > >>>>> Thanks in advance for any information or education.
> > > >>>>>
> > > >>>>> Chris
> > > >>>>> _______________________________________________
> > > >>>>> Concurrency-interest mailing list
> > > >>>>> Concurrency-interest at cs.oswego.edu
> > > >>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >>>>>
> > > >>>>
> > > >>>> _______________________________________________
> > > >>>> Concurrency-interest mailing list
> > > >>>> Concurrency-interest at cs.oswego.edu
> > > >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > > >>>
> > > >
> > >
> > >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From zhong.j.yu at gmail.com  Sat Dec 10 21:50:07 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sat, 10 Dec 2011 20:50:07 -0600
Subject: [concurrency-interest] ConcurrentMap
	consistencyrequirementsconfusion
In-Reply-To: <CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
References: <0F263C32-9873-4DCE-9BC5-66B7CBC9EB48@terracottatech.com>
	<NFBBKALFDCPFIDBNKAPCMENBJBAA.davidcholmes@aapt.net.au>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<5668BFCA-35EE-4946-BCB3-5317A5A4EF60@rkuhn.info>
	<CAHzJPEqGNte4dW7BgAQPA+QhAv4+KRyKwMfLdg7-G3bZ-YK=Fw@mail.gmail.com>
Message-ID: <CACuKZqGM3hQRRfgNUaQ-OKTVoDvLcE8LGbp9TKpQtPpdj0hyYQ@mail.gmail.com>

On Sat, Dec 10, 2011 at 4:01 PM, Joe Bowbeer <joe.bowbeer at gmail.com> wrote:
> Making all variables volatile should force sequentially consistent execution
> over all, and program-order execution in each thread.
>
> I think it's reasonable to model ConcurrentMap as having a separate lock or
> volatile per cell, even though in practice the locks are striped. ?Is the CM
> spec even less constrained than this?

That makes perfect sense to me. A map is basically a set of variables
with read/write operations; a concurrent map is a set of variables
with volatile read/write and cas operations on them.

Zhong Yu


From hans.boehm at hp.com  Sun Dec 11 01:01:20 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Sun, 11 Dec 2011 06:01:20 +0000
Subject: [concurrency-interest]
 ConcurrentMapconsistencyrequirementsconfusion
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAENEJBAA.davidcholmes@aapt.net.au>
References: <A3E67C2071F49C4CBC4F17E6D77CDDD20D241C@G4W3299.americas.hpqcorp.net>
	<NFBBKALFDCPFIDBNKAPCAENEJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D2592@G4W3299.americas.hpqcorp.net>

> From: David Holmes [mailto:davidcholmes at aapt.net.au]
> 
> Hans Boehm writes:
> > Are current implementations strong
> > enough to make that correct?  If I encode Dekker's using CHMs, as
> > in ("key" entries initially "0"):
> >
> > Thread 1:
> > a.put("key","1");
> > r1 = b.get("key");
> >
> > Thread 2:
> > b.put("key","1");
> > r2 = a.get("key");
> >
> > Can I get r1 = r2 = "0"?  Presumably not.
> 
> I would say you definitely should not else there is a significant bug
> in the
> implementation.
> 
> But I fear this discussion is degenerating into the usual JMM chaos.
> Nothing
> is guaranteed, nothing is provable so we might as well quit programming
> and
> go home. ;-)
> 
> David
> -----
I guess I'm more positive than you about the Java memory model.  My view is that in the absence of data races, i.e. for well-synchronized code, the Java memory model is well-defined and easy to use: It's sequential consistency.  The 2005 revision clarified that, and that part is perfectly sound and extremely useful.  Beyond that, there are a few statements we can make about racy programs, particularly in conjunction with final fields, but mostly I do think things are in need of repair.  But, aside from situations in which you need to tolerate sandboxed malicious code, or get the last few percent in performance, you can stay in the data-race-free subset, and life is good.

I think the questions we were addressing here all have to do with the race-free part, which is basically in good shape.  And I think you've confirmed that CHM plays by the intended rules.  I still don't think this is stated very well in the spec, but the intent seems to be that CHM get and put operations play by essentially the same rules as volatile variable accesses.  And I think the implementation is such that they do.  (It sounds like the implementation itself is also data-race-free, so it automatically has the right properties?)  All of that is good.  The documentation could be improved, but I think every concurrency library currently has similar issues.  You can find similar discussions on the C++ committee mailing list.

The JMM, I think with the sole exception of 17.4.9, gives you only partial correctness guarantees; it only promises what happens if your program finishes, not whether it does.  17.4.9 gives only very weak (and hard-to-decipher) progress guarantees.  When you ask questions about progress, you shouldn't expect too much of an answer from the JMM.  As I said earlier, that was by design, though it may need to be revisited at some point.

Hans



From forax at univ-mlv.fr  Sun Dec 11 09:13:24 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sun, 11 Dec 2011 15:13:24 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
Message-ID: <4EE4BA84.6080009@univ-mlv.fr>

Hi guys,
I'm trying to implement a fast multi-dispatch on top of invokedynamic.

If the callsite is megamorphic, I would like to implement a table based 
solutions
like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on the fact 
that it's possible
to associate an object or an int to a Class.

So I need to implement a kind concurrent map (Class -> int) but
I know that an entry will be never modified nor removed after being added
and I know that there will be a lot of get and very few updates.
In fact, the data structure acts more like a cache, i.e if I can't find
the value for a specific class, I have a way to find it based on the other
entries that are already in the map.

I've first written a class that use a lock for that, it works but as you 
can guess,
it's slow.
http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java

After, I've tried to remove the lock and use an array of array. The main 
array is an AtomicReferenceArray,
and the secondary arrays are the ones that store collisions and that use 
copy-on-write semantics
when they need to store a new key/value entry.
But because the main array also need to grow, the reference to the main 
array is also
a volatile field. So accessing to a value requires two volatiles reads.
This implementation is faster than the data structure that uses a lock
but still slow.

So I try to use a tries instead of a hashmap.
The idea is to have a persistent trie, like the one used in Clojure [4] 
so all mutations
re-create a new trie that share parts with the ole one and to use a 
volatile field
(and a CAS) to store the root of the tries.
http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java

This code is faster, but I'm not sure it is correct and I wonder if
there is a way to remove the volatile field because the data structure 
acts as a cache
so if another thread don't see the modification, it's not a big deal 
because it can always
process the value by using the already existing entries.

R?mi

[1] http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
[2] http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
[3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
[4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie


From mikeb01 at gmail.com  Sun Dec 11 10:20:43 2011
From: mikeb01 at gmail.com (Michael Barker)
Date: Sun, 11 Dec 2011 15:20:43 +0000
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <4EE4BA84.6080009@univ-mlv.fr>
References: <4EE4BA84.6080009@univ-mlv.fr>
Message-ID: <CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>

Hi Remi,

It would be worthwhile benchmarking your implementation against
ConcurrentHashMap.  I did something similar a while back, creating a
ConcurrentMap using a Bagwell-style tree.  The quantity of my
implementation notwithstanding, I was unable to bring the performance
up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
that a combination of memory throughput demands and garbage generated
by the array creation and copying when nodes were added was the main
performance cost.  It outweighed the costs of the volatile/CAS
operations.

Details are here:
http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html

Michael Barker.

On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax <forax at univ-mlv.fr> wrote:
> Hi guys,
> I'm trying to implement a fast multi-dispatch on top of invokedynamic.
>
> If the callsite is megamorphic, I would like to implement a table based
> solutions
> like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on the fact
> that it's possible
> to associate an object or an int to a Class.
>
> So I need to implement a kind concurrent map (Class -> int) but
> I know that an entry will be never modified nor removed after being added
> and I know that there will be a lot of get and very few updates.
> In fact, the data structure acts more like a cache, i.e if I can't find
> the value for a specific class, I have a way to find it based on the other
> entries that are already in the map.
>
> I've first written a class that use a lock for that, it works but as you can
> guess,
> it's slow.
> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
>
> After, I've tried to remove the lock and use an array of array. The main
> array is an AtomicReferenceArray,
> and the secondary arrays are the ones that store collisions and that use
> copy-on-write semantics
> when they need to store a new key/value entry.
> But because the main array also need to grow, the reference to the main
> array is also
> a volatile field. So accessing to a value requires two volatiles reads.
> This implementation is faster than the data structure that uses a lock
> but still slow.
>
> So I try to use a tries instead of a hashmap.
> The idea is to have a persistent trie, like the one used in Clojure [4] so
> all mutations
> re-create a new trie that share parts with the ole one and to use a volatile
> field
> (and a CAS) to store the root of the tries.
> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
>
> This code is faster, but I'm not sure it is correct and I wonder if
> there is a way to remove the volatile field because the data structure acts
> as a cache
> so if another thread don't see the modification, it's not a big deal because
> it can always
> process the value by using the already existing entries.
>
> R?mi
>
> [1] http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
> [2] http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
> [3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
> [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Sun Dec 11 12:18:05 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 11 Dec 2011 18:18:05 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
Message-ID: <CANPzfU9d+jdxbafmEK5wL4pUbg_Q1p7q-hd-k-2cJyz4VYtC_Q@mail.gmail.com>

Have you've seen Aleksander Prokopec and Phil Bagwells work on Ctries?

https://github.com/axel22/Ctries/tree/master/src

Cheers,
?

On Sun, Dec 11, 2011 at 4:20 PM, Michael Barker <mikeb01 at gmail.com> wrote:

> Hi Remi,
>
> It would be worthwhile benchmarking your implementation against
> ConcurrentHashMap.  I did something similar a while back, creating a
> ConcurrentMap using a Bagwell-style tree.  The quantity of my
> implementation notwithstanding, I was unable to bring the performance
> up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
> that a combination of memory throughput demands and garbage generated
> by the array creation and copying when nodes were added was the main
> performance cost.  It outweighed the costs of the volatile/CAS
> operations.
>
> Details are here:
>
> http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html
>
> Michael Barker.
>
> On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax <forax at univ-mlv.fr> wrote:
> > Hi guys,
> > I'm trying to implement a fast multi-dispatch on top of invokedynamic.
> >
> > If the callsite is megamorphic, I would like to implement a table based
> > solutions
> > like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on the fact
> > that it's possible
> > to associate an object or an int to a Class.
> >
> > So I need to implement a kind concurrent map (Class -> int) but
> > I know that an entry will be never modified nor removed after being added
> > and I know that there will be a lot of get and very few updates.
> > In fact, the data structure acts more like a cache, i.e if I can't find
> > the value for a specific class, I have a way to find it based on the
> other
> > entries that are already in the map.
> >
> > I've first written a class that use a lock for that, it works but as you
> can
> > guess,
> > it's slow.
> >
> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
> >
> > After, I've tried to remove the lock and use an array of array. The main
> > array is an AtomicReferenceArray,
> > and the secondary arrays are the ones that store collisions and that use
> > copy-on-write semantics
> > when they need to store a new key/value entry.
> > But because the main array also need to grow, the reference to the main
> > array is also
> > a volatile field. So accessing to a value requires two volatiles reads.
> > This implementation is faster than the data structure that uses a lock
> > but still slow.
> >
> > So I try to use a tries instead of a hashmap.
> > The idea is to have a persistent trie, like the one used in Clojure [4]
> so
> > all mutations
> > re-create a new trie that share parts with the ole one and to use a
> volatile
> > field
> > (and a CAS) to store the root of the tries.
> >
> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
> >
> > This code is faster, but I'm not sure it is correct and I wonder if
> > there is a way to remove the volatile field because the data structure
> acts
> > as a cache
> > so if another thread don't see the modification, it's not a big deal
> because
> > it can always
> > process the value by using the already existing entries.
> >
> > R?mi
> >
> > [1] http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
> > [2] http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
> > [3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
> > [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111211/5a4cf056/attachment.html>

From forax at univ-mlv.fr  Sun Dec 11 13:41:37 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sun, 11 Dec 2011 19:41:37 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
Message-ID: <4EE4F961.1040402@univ-mlv.fr>

On 12/11/2011 04:20 PM, Michael Barker wrote:
> Hi Remi,
>
> It would be worthwhile benchmarking your implementation against
> ConcurrentHashMap.  I did something similar a while back, creating a
> ConcurrentMap using a Bagwell-style tree.  The quantity of my
> implementation notwithstanding, I was unable to bring the performance
> up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
> that a combination of memory throughput demands and garbage generated
> by the array creation and copying when nodes were added was the main
> performance cost.  It outweighed the costs of the volatile/CAS
> operations.
>
> Details are here:
> http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html
>
> Michael Barker.,

Hi Michael,
I don't think my implementation is better/worst than ConcurrentHashMap
because it's not a replacement of ConcurrentHashMap :)

I need a data-structure that acts as a cache with no eviction (never !)
and where calls to lookup/get outnumber by a wide margin calls to
add/put (let say 10000/1).

The way I test my implementations is to replace all method calls of the 
DaCapo
benchmark by an invokedynamic that does the multi-dispatch
(in fact some aren't replaced because the algorithm isn't finished).
So I know if a data structure is better than the other
for my use case, not in general.

Now, reading your blog confirms my intuition,
if there is a lot of read and few write, a concurrent tries is perhaps 
better.
Also, about the possible virtual calls because of the different kinds of 
Node,
there is no ListNode in my implementation, so there is only two 
implementations
of Node that fits in the bimorphic inlining caches used by the VM
so the code is inlined :)

R?mi

>
> On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax<forax at univ-mlv.fr>  wrote:
>> Hi guys,
>> I'm trying to implement a fast multi-dispatch on top of invokedynamic.
>>
>> If the callsite is megamorphic, I would like to implement a table based
>> solutions
>> like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on the fact
>> that it's possible
>> to associate an object or an int to a Class.
>>
>> So I need to implement a kind concurrent map (Class ->  int) but
>> I know that an entry will be never modified nor removed after being added
>> and I know that there will be a lot of get and very few updates.
>> In fact, the data structure acts more like a cache, i.e if I can't find
>> the value for a specific class, I have a way to find it based on the other
>> entries that are already in the map.
>>
>> I've first written a class that use a lock for that, it works but as you can
>> guess,
>> it's slow.
>> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
>>
>> After, I've tried to remove the lock and use an array of array. The main
>> array is an AtomicReferenceArray,
>> and the secondary arrays are the ones that store collisions and that use
>> copy-on-write semantics
>> when they need to store a new key/value entry.
>> But because the main array also need to grow, the reference to the main
>> array is also
>> a volatile field. So accessing to a value requires two volatiles reads.
>> This implementation is faster than the data structure that uses a lock
>> but still slow.
>>
>> So I try to use a tries instead of a hashmap.
>> The idea is to have a persistent trie, like the one used in Clojure [4] so
>> all mutations
>> re-create a new trie that share parts with the ole one and to use a volatile
>> field
>> (and a CAS) to store the root of the tries.
>> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
>>
>> This code is faster, but I'm not sure it is correct and I wonder if
>> there is a way to remove the volatile field because the data structure acts
>> as a cache
>> so if another thread don't see the modification, it's not a big deal because
>> it can always
>> process the value by using the already existing entries.
>>
>> R?mi
>>
>> [1] http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
>> [2] http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
>> [3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
>> [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From forax at univ-mlv.fr  Sun Dec 11 13:54:15 2011
From: forax at univ-mlv.fr (=?UTF-8?B?UsOpbWkgRm9yYXg=?=)
Date: Sun, 11 Dec 2011 19:54:15 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <CANPzfU9d+jdxbafmEK5wL4pUbg_Q1p7q-hd-k-2cJyz4VYtC_Q@mail.gmail.com>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
	<CANPzfU9d+jdxbafmEK5wL4pUbg_Q1p7q-hd-k-2cJyz4VYtC_Q@mail.gmail.com>
Message-ID: <4EE4FC57.1040700@univ-mlv.fr>

On 12/11/2011 06:18 PM, ?iktor ?lang wrote:
> Have you've seen Aleksander Prokopec and Phil Bagwells work on Ctries?
>
> https://github.com/axel22/Ctries/tree/master/src
>
> Cheers,
> ?

I've read the wikipedia entry.
Compared to the implementation of Michael they insert a mutable node
in front of all bitmap node in order to avoid to propagate mutations
to more than one level.

I don't understand why it's a new kind of Node and not
the implementation of the bitmap node which is changed to used
a side object that will store the bitmap and the array and
be stored in a volatile variable used with a CAS.
It should avoid at least one virtual call.

Anyway, this data-structure will do one volatile read by level of the tries
so in my opinion, it like get is slow down to make the mutation more 
effective.
So it's not interesting for my cache.

R?mi

>
> On Sun, Dec 11, 2011 at 4:20 PM, Michael Barker <mikeb01 at gmail.com 
> <mailto:mikeb01 at gmail.com>> wrote:
>
>     Hi Remi,
>
>     It would be worthwhile benchmarking your implementation against
>     ConcurrentHashMap.  I did something similar a while back, creating a
>     ConcurrentMap using a Bagwell-style tree.  The quantity of my
>     implementation notwithstanding, I was unable to bring the performance
>     up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
>     that a combination of memory throughput demands and garbage generated
>     by the array creation and copying when nodes were added was the main
>     performance cost.  It outweighed the costs of the volatile/CAS
>     operations.
>
>     Details are here:
>     http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html
>
>     Michael Barker.
>
>     On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax <forax at univ-mlv.fr
>     <mailto:forax at univ-mlv.fr>> wrote:
>     > Hi guys,
>     > I'm trying to implement a fast multi-dispatch on top of
>     invokedynamic.
>     >
>     > If the callsite is megamorphic, I would like to implement a
>     table based
>     > solutions
>     > like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on
>     the fact
>     > that it's possible
>     > to associate an object or an int to a Class.
>     >
>     > So I need to implement a kind concurrent map (Class -> int) but
>     > I know that an entry will be never modified nor removed after
>     being added
>     > and I know that there will be a lot of get and very few updates.
>     > In fact, the data structure acts more like a cache, i.e if I
>     can't find
>     > the value for a specific class, I have a way to find it based on
>     the other
>     > entries that are already in the map.
>     >
>     > I've first written a class that use a lock for that, it works
>     but as you can
>     > guess,
>     > it's slow.
>     >
>     http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
>     >
>     > After, I've tried to remove the lock and use an array of array.
>     The main
>     > array is an AtomicReferenceArray,
>     > and the secondary arrays are the ones that store collisions and
>     that use
>     > copy-on-write semantics
>     > when they need to store a new key/value entry.
>     > But because the main array also need to grow, the reference to
>     the main
>     > array is also
>     > a volatile field. So accessing to a value requires two volatiles
>     reads.
>     > This implementation is faster than the data structure that uses
>     a lock
>     > but still slow.
>     >
>     > So I try to use a tries instead of a hashmap.
>     > The idea is to have a persistent trie, like the one used in
>     Clojure [4] so
>     > all mutations
>     > re-create a new trie that share parts with the ole one and to
>     use a volatile
>     > field
>     > (and a CAS) to store the root of the tries.
>     >
>     http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
>     >
>     > This code is faster, but I'm not sure it is correct and I wonder if
>     > there is a way to remove the volatile field because the data
>     structure acts
>     > as a cache
>     > so if another thread don't see the modification, it's not a big
>     deal because
>     > it can always
>     > process the value by using the already existing entries.
>     >
>     > R?mi
>     >
>     > [1]
>     http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
>     <http://www.ifs.uni-linz.ac.at/%7Eecoop/cd/papers/1628/16280304.pdf>
>     > [2]
>     http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
>     <http://webdocs.cs.ualberta.ca/%7Epaullu/Papers/COOTS2001-HTML/mdj.html>
>     > [3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
>     > [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
>     >
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/>- Enterprise-Grade Scala from the 
> Experts
>
> Twitter: @viktorklang
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111211/ae48c6e1/attachment-0001.html>

From karmazilla at gmail.com  Sun Dec 11 16:53:50 2011
From: karmazilla at gmail.com (Christian Vest Hansen)
Date: Sun, 11 Dec 2011 22:53:50 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <4EE4FC57.1040700@univ-mlv.fr>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
	<CANPzfU9d+jdxbafmEK5wL4pUbg_Q1p7q-hd-k-2cJyz4VYtC_Q@mail.gmail.com>
	<4EE4FC57.1040700@univ-mlv.fr>
Message-ID: <CACyP5Pc9T8_kBReFthXhSpDKiLYVo90Y4AGiJnSa3wAdwtTYug@mail.gmail.com>

This is just an idea, and I don't know enough to tell whether it's any
good, but here goes...
If the cache is a pointer to some persistent map, where persistent implies
immutable as in all fields are final (so it cannot be unsafely published) *
and* you can always compensate for a miss (an implied property of a cache) *
and* you never delete or overwrite entries; then perhaps the pointer field
need not be volatile at all? You might miss a lot of updates until the
cache is warm, but these misses can always be compensated for, as far as I
understand it.

2011/12/11 R?mi Forax <forax at univ-mlv.fr>

>  On 12/11/2011 06:18 PM, ?iktor ?lang wrote:
>
> Have you've seen Aleksander Prokopec and Phil Bagwells work on Ctries?
>
> https://github.com/axel22/Ctries/tree/master/src
>
> Cheers,
> ?
>
>
> I've read the wikipedia entry.
> Compared to the implementation of Michael they insert a mutable node
> in front of all bitmap node in order to avoid to propagate mutations
> to more than one level.
>
> I don't understand why it's a new kind of Node and not
> the implementation of the bitmap node which is changed to used
> a side object that will store the bitmap and the array and
> be stored in a volatile variable used with a CAS.
> It should avoid at least one virtual call.
>
> Anyway, this data-structure will do one volatile read by level of the tries
> so in my opinion, it like get is slow down to make the mutation more
> effective.
> So it's not interesting for my cache.
>
> R?mi
>
>
>
>  On Sun, Dec 11, 2011 at 4:20 PM, Michael Barker <mikeb01 at gmail.com>wrote:
>
>> Hi Remi,
>>
>> It would be worthwhile benchmarking your implementation against
>> ConcurrentHashMap.  I did something similar a while back, creating a
>> ConcurrentMap using a Bagwell-style tree.  The quantity of my
>> implementation notwithstanding, I was unable to bring the performance
>> up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
>> that a combination of memory throughput demands and garbage generated
>> by the array creation and copying when nodes were added was the main
>> performance cost.  It outweighed the costs of the volatile/CAS
>> operations.
>>
>> Details are here:
>>
>> http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html
>>
>> Michael Barker.
>>
>> On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax <forax at univ-mlv.fr> wrote:
>> > Hi guys,
>> > I'm trying to implement a fast multi-dispatch on top of invokedynamic.
>> >
>> > If the callsite is megamorphic, I would like to implement a table based
>> > solutions
>> > like MRD [1], SRP [2] or TABA [3]. All these algorithms rely on the fact
>> > that it's possible
>> > to associate an object or an int to a Class.
>> >
>> > So I need to implement a kind concurrent map (Class -> int) but
>> > I know that an entry will be never modified nor removed after being
>> added
>> > and I know that there will be a lot of get and very few updates.
>> > In fact, the data structure acts more like a cache, i.e if I can't find
>> > the value for a specific class, I have a way to find it based on the
>> other
>> > entries that are already in the map.
>> >
>> > I've first written a class that use a lock for that, it works but as
>> you can
>> > guess,
>> > it's slow.
>> >
>> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
>> >
>> > After, I've tried to remove the lock and use an array of array. The main
>> > array is an AtomicReferenceArray,
>> > and the secondary arrays are the ones that store collisions and that use
>> > copy-on-write semantics
>> > when they need to store a new key/value entry.
>> > But because the main array also need to grow, the reference to the main
>> > array is also
>> > a volatile field. So accessing to a value requires two volatiles reads.
>> > This implementation is faster than the data structure that uses a lock
>> > but still slow.
>> >
>> > So I try to use a tries instead of a hashmap.
>> > The idea is to have a persistent trie, like the one used in Clojure [4]
>> so
>> > all mutations
>> > re-create a new trie that share parts with the ole one and to use a
>> volatile
>> > field
>> > (and a CAS) to store the root of the tries.
>> >
>> http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
>> >
>> > This code is faster, but I'm not sure it is correct and I wonder if
>> > there is a way to remove the volatile field because the data structure
>> acts
>> > as a cache
>> > so if another thread don't see the modification, it's not a big deal
>> because
>> > it can always
>> > process the value by using the already existing entries.
>> >
>> > R?mi
>> >
>> > [1] http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
>> > [2]
>> http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
>> > [3] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
>> > [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Viktor Klang
>
> Akka Tech Lead
> Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
> Experts
>
> Twitter: @viktorklang
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Venlig hilsen / Kind regards,
Christian Vest Hansen.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111211/3b38a019/attachment.html>

From forax at univ-mlv.fr  Mon Dec 12 05:43:11 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 12 Dec 2011 11:43:11 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <4EE4F961.1040402@univ-mlv.fr>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
	<4EE4F961.1040402@univ-mlv.fr>
Message-ID: <4EE5DABF.1040909@univ-mlv.fr>

On 12/11/2011 07:41 PM, R?mi Forax wrote:
> On 12/11/2011 04:20 PM, Michael Barker wrote:
>> Hi Remi,
>>
>> It would be worthwhile benchmarking your implementation against
>> ConcurrentHashMap.  I did something similar a while back, creating a
>> ConcurrentMap using a Bagwell-style tree.  The quantity of my
>> implementation notwithstanding, I was unable to bring the performance
>> up above ConcurrentHashMap.  Profiling was inconclusive, but suggested
>> that a combination of memory throughput demands and garbage generated
>> by the array creation and copying when nodes were added was the main
>> performance cost.  It outweighed the costs of the volatile/CAS
>> operations.
>>
>> Details are here:
>> http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html 
>>
>>
>> Michael Barker.,
>
> Hi Michael,
> I don't think my implementation is better/worst than ConcurrentHashMap
> because it's not a replacement of ConcurrentHashMap :)
>
> I need a data-structure that acts as a cache with no eviction (never !)
> and where calls to lookup/get outnumber by a wide margin calls to
> add/put (let say 10000/1).
>
> The way I test my implementations is to replace all method calls of 
> the DaCapo
> benchmark by an invokedynamic that does the multi-dispatch
> (in fact some aren't replaced because the algorithm isn't finished).
> So I know if a data structure is better than the other
> for my use case, not in general.
>
> Now, reading your blog confirms my intuition,
> if there is a lot of read and few write, a concurrent tries is perhaps 
> better.
> Also, about the possible virtual calls because of the different kinds 
> of Node,
> there is no ListNode in my implementation, so there is only two 
> implementations
> of Node that fits in the bimorphic inlining caches used by the VM
> so the code is inlined :)
>
> R?mi

Michael,
I've taken a look to the code written by Aleksander Prokopec (thanks 
Victor),
in Scala and he uses TCO (tail call optimization) done by the scala compiler
to avoid virtual calls (in fact there is no call anymore).

I've done exactly the same thing in Java [1] (so it's more readable :)
and it's clearly faster. Perhaps you should try the same optimization
on your tries.

I have also tried to merge the entry node and the array node in one
but perf was not great, I think it's because the memory consumption was
too big to fit in on level of the hardware cache (or cache line).

R?mi
[1] 
https://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries3.java







From forax at univ-mlv.fr  Mon Dec 12 05:55:50 2011
From: forax at univ-mlv.fr (=?UTF-8?B?UsOpbWkgRm9yYXg=?=)
Date: Mon, 12 Dec 2011 11:55:50 +0100
Subject: [concurrency-interest] Concurrent tries as a cache
In-Reply-To: <CACyP5Pc9T8_kBReFthXhSpDKiLYVo90Y4AGiJnSa3wAdwtTYug@mail.gmail.com>
References: <4EE4BA84.6080009@univ-mlv.fr>
	<CALwNKeSKEgYueHu5iWH5d7EW1ns+8peCsK7wTrOiJrFPqJeunQ@mail.gmail.com>
	<CANPzfU9d+jdxbafmEK5wL4pUbg_Q1p7q-hd-k-2cJyz4VYtC_Q@mail.gmail.com>
	<4EE4FC57.1040700@univ-mlv.fr>
	<CACyP5Pc9T8_kBReFthXhSpDKiLYVo90Y4AGiJnSa3wAdwtTYug@mail.gmail.com>
Message-ID: <4EE5DDB6.6050701@univ-mlv.fr>

On 12/11/2011 10:53 PM, Christian Vest Hansen wrote:
> This is just an idea, and I don't know enough to tell whether it's any 
> good, but here goes...
> If the cache is a pointer to some persistent map, where persistent 
> implies immutable as in all fields are final (so it cannot be unsafely 
> published) /and/ you can always compensate for a miss (an implied 
> property of a cache) /and/ you never delete or overwrite entries; then 
> perhaps the pointer field need not be volatile at all? You might miss 
> a lot of updates until the cache is warm, but these misses can always 
> be compensated for, as far as I understand it.

Hi Christian.
That's a good question, I think it's ok but I'm not a concurrency guru.

In fact, I don't even miss a lot of updates in this case, at least with 
Hotspot.
Hotspot compiles the method lookup but generate a call to the interpreter
in case an update is needed because the update method is not called often
(and is too big).
So the generated code, always read the head of the tries from the RAM
and always write it into the RAM even if the variable is not tagged as 
volatile.
So I only miss updates that are truly concurrent (that happen at the 
same time
on different cores).
It's very Hotspot specific but it's fun to know that.

R?mi

>
> 2011/12/11 R?mi Forax <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>>
>
>     On 12/11/2011 06:18 PM, ?iktor ?lang wrote:
>>     Have you've seen Aleksander Prokopec and Phil Bagwells work on
>>     Ctries?
>>
>>     https://github.com/axel22/Ctries/tree/master/src
>>
>>     Cheers,
>>     ?
>
>     I've read the wikipedia entry.
>     Compared to the implementation of Michael they insert a mutable node
>     in front of all bitmap node in order to avoid to propagate mutations
>     to more than one level.
>
>     I don't understand why it's a new kind of Node and not
>     the implementation of the bitmap node which is changed to used
>     a side object that will store the bitmap and the array and
>     be stored in a volatile variable used with a CAS.
>     It should avoid at least one virtual call.
>
>     Anyway, this data-structure will do one volatile read by level of
>     the tries
>     so in my opinion, it like get is slow down to make the mutation
>     more effective.
>     So it's not interesting for my cache.
>
>     R?mi
>
>
>>
>>     On Sun, Dec 11, 2011 at 4:20 PM, Michael Barker
>>     <mikeb01 at gmail.com <mailto:mikeb01 at gmail.com>> wrote:
>>
>>         Hi Remi,
>>
>>         It would be worthwhile benchmarking your implementation against
>>         ConcurrentHashMap.  I did something similar a while back,
>>         creating a
>>         ConcurrentMap using a Bagwell-style tree.  The quantity of my
>>         implementation notwithstanding, I was unable to bring the
>>         performance
>>         up above ConcurrentHashMap.  Profiling was inconclusive, but
>>         suggested
>>         that a combination of memory throughput demands and garbage
>>         generated
>>         by the array creation and copying when nodes were added was
>>         the main
>>         performance cost.  It outweighed the costs of the volatile/CAS
>>         operations.
>>
>>         Details are here:
>>         http://mikes-tech.blogspot.com/2011/02/non-blocking-concurrenthashmaptrie.html
>>
>>         Michael Barker.
>>
>>         On Sun, Dec 11, 2011 at 2:13 PM, R?mi Forax
>>         <forax at univ-mlv.fr <mailto:forax at univ-mlv.fr>> wrote:
>>         > Hi guys,
>>         > I'm trying to implement a fast multi-dispatch on top of
>>         invokedynamic.
>>         >
>>         > If the callsite is megamorphic, I would like to implement a
>>         table based
>>         > solutions
>>         > like MRD [1], SRP [2] or TABA [3]. All these algorithms
>>         rely on the fact
>>         > that it's possible
>>         > to associate an object or an int to a Class.
>>         >
>>         > So I need to implement a kind concurrent map (Class -> int) but
>>         > I know that an entry will be never modified nor removed
>>         after being added
>>         > and I know that there will be a lot of get and very few
>>         updates.
>>         > In fact, the data structure acts more like a cache, i.e if
>>         I can't find
>>         > the value for a specific class, I have a way to find it
>>         based on the other
>>         > entries that are already in the map.
>>         >
>>         > I've first written a class that use a lock for that, it
>>         works but as you can
>>         > guess,
>>         > it's slow.
>>         >
>>         http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/SmallClassBitMap.java
>>         >
>>         > After, I've tried to remove the lock and use an array of
>>         array. The main
>>         > array is an AtomicReferenceArray,
>>         > and the secondary arrays are the ones that store collisions
>>         and that use
>>         > copy-on-write semantics
>>         > when they need to store a new key/value entry.
>>         > But because the main array also need to grow, the reference
>>         to the main
>>         > array is also
>>         > a volatile field. So accessing to a value requires two
>>         volatiles reads.
>>         > This implementation is faster than the data structure that
>>         uses a lock
>>         > but still slow.
>>         >
>>         > So I try to use a tries instead of a hashmap.
>>         > The idea is to have a persistent trie, like the one used in
>>         Clojure [4] so
>>         > all mutations
>>         > re-create a new trie that share parts with the ole one and
>>         to use a volatile
>>         > field
>>         > (and a CAS) to store the root of the tries.
>>         >
>>         http://code.google.com/p/jsr292-cookbook/source/browse/trunk/multi-dispatch/src/jsr292/cookbook/mdispatch/util/ConcurrentTries.java
>>         >
>>         > This code is faster, but I'm not sure it is correct and I
>>         wonder if
>>         > there is a way to remove the volatile field because the
>>         data structure acts
>>         > as a cache
>>         > so if another thread don't see the modification, it's not a
>>         big deal because
>>         > it can always
>>         > process the value by using the already existing entries.
>>         >
>>         > R?mi
>>         >
>>         > [1]
>>         http://www.ifs.uni-linz.ac.at/~ecoop/cd/papers/1628/16280304.pdf
>>         <http://www.ifs.uni-linz.ac.at/%7Eecoop/cd/papers/1628/16280304.pdf>
>>         > [2]
>>         http://webdocs.cs.ualberta.ca/~paullu/Papers/COOTS2001-HTML/mdj.html
>>         <http://webdocs.cs.ualberta.ca/%7Epaullu/Papers/COOTS2001-HTML/mdj.html>
>>         > [3]
>>         http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.7337
>>         > [4] https://en.wikipedia.org/wiki/Hash_array_mapped_trie
>>         >
>>         > _______________________________________________
>>         > Concurrency-interest mailing list
>>         > Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>     -- 
>>     Viktor Klang
>>
>>     Akka Tech Lead
>>     Typesafe <http://www.typesafe.com/>- Enterprise-Grade Scala from
>>     the Experts
>>
>>     Twitter: @viktorklang
>>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Venlig hilsen / Kind regards,
> Christian Vest Hansen.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111212/458cb194/attachment-0001.html>

From yshavit at akiban.com  Thu Dec 15 16:10:13 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 15 Dec 2011 16:10:13 -0500
Subject: [concurrency-interest] synchronized constructors
Message-ID: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>

Hi all,

This came up a few days ago on stackoverflow.com -- I forget the exact
post, but someone referenced the JLS section concerning why constructors
can't be synchronized:

There is no practical need for a constructor to be synchronized, because it
> would lock the object under construction, which is normally not made
> available to other threads until all constructors for the object have
> completed their work.


If synchronization were only about mutual exclusion, this would make sense;
but it also has memory visibility guarantees. For instance, say I have this
really simple class:

    public class MyPoint {
        private int x;
        private int y;

        public MyPoint() {
            x = -1; // init to (-1,-1) for some reason
            y = -1;
        }

        public synchronized void setX(int x, int y) {
            this.x = x;
            this.y = y;
        }

        @Override
        public synchronized String toString() {
            return "(" + x + ", " + y + ")";
        }
    }

There's a thread safety issue there, right? There was no synchronization
during construction time, and thus no happens-before between ctor ending
and toString() starting, so with reordering etc, you could observe the
initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could
get around this by calling setX from the constructor, but if setX is
non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?

Thanks,
Yuval
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/a23bacb8/attachment.html>

From rsk at moocat.org  Thu Dec 15 16:19:01 2011
From: rsk at moocat.org (R Samuel Klatchko)
Date: Thu, 15 Dec 2011 13:19:01 -0800
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
Message-ID: <CAM6f_1m182jUfDuvNkTzX6UMRc_TVfi+JDd2JYW8-UewnDK14A@mail.gmail.com>

The issue you are describing is only possible if the constructor is called
in one thread and toString is called in a different thread.

If you are doing that, your code will want to take care of the
happens-before edge as part of sending the reference from the thread that
constructs the object to the thread that uses the object.

samuel

On Thu, Dec 15, 2011 at 1:10 PM, Yuval Shavit <yshavit at akiban.com> wrote:

> Hi all,
>
> This came up a few days ago on stackoverflow.com -- I forget the exact
> post, but someone referenced the JLS section concerning why constructors
> can't be synchronized:
>
> There is no practical need for a constructor to be synchronized, because
>> it would lock the object under construction, which is normally not made
>> available to other threads until all constructors for the object have
>> completed their work.
>
>
> If synchronization were only about mutual exclusion, this would make
> sense; but it also has memory visibility guarantees. For instance, say I
> have this really simple class:
>
>     public class MyPoint {
>         private int x;
>         private int y;
>
>         public MyPoint() {
>             x = -1; // init to (-1,-1) for some reason
>             y = -1;
>         }
>
>         public synchronized void setX(int x, int y) {
>             this.x = x;
>             this.y = y;
>         }
>
>         @Override
>         public synchronized String toString() {
>             return "(" + x + ", " + y + ")";
>         }
>     }
>
> There's a thread safety issue there, right? There was no synchronization
> during construction time, and thus no happens-before between ctor ending
> and toString() starting, so with reordering etc, you could observe the
> initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could
> get around this by calling setX from the constructor, but if setX is
> non-final, that has its own issues. You could also put the x and y
> initialization within a synchronized (this) { ... } -- but at that point,
> why not just allow the constructor to be synchronized?
>
> Thanks,
> Yuval
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/0102892d/attachment.html>

From nathan.reynolds at oracle.com  Thu Dec 15 16:30:03 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 15 Dec 2011 14:30:03 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
Message-ID: <4EEA66DB.60002@oracle.com>

How is the MyPoint instance going to become shared with another thread?  
The thread calling the constructor has to execute some sort of 
synchronization to share the reference to the MyPoint instance.  The 
synchronization will cause a happens-before edge to be created.  For 
example, this code assigns a volatile field.  Writing to the volatile 
will ensure the proper values of x and y will be visible.

public volatile MyPoint point = new MyPoint();

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:10 PM, Yuval Shavit wrote:
> Hi all,
>
> This came up a few days ago on stackoverflow.com 
> <http://stackoverflow.com> -- I forget the exact post, but someone 
> referenced the JLS section concerning why constructors can't be 
> synchronized:
>
>     There is no practical need for a constructor to be synchronized,
>     because it would lock the object under construction, which is
>     normally not made available to other threads until all
>     constructors for the object have completed their work.
>
>
> If synchronization were only about mutual exclusion, this would make 
> sense; but it also has memory visibility guarantees. For instance, say 
> I have this really simple class:
>
>     public class MyPoint {
>         private int x;
>         private int y;
>         public MyPoint() {
>             x = -1; // init to (-1,-1) for some reason
>             y = -1;
>         }
>
>         public synchronized void setX(int x, int y) {
>             this.x = x;
>             this.y = y;
>         }
>
>         @Override
>         public synchronized String toString() {
>             return "(" + x + ", " + y + ")";
>         }
>     }
>
> There's a thread safety issue there, right? There was no 
> synchronization during construction time, and thus no happens-before 
> between ctor ending and toString() starting, so with reordering etc, 
> you could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" 
> or "(-1, 0)".  You could get around this by calling setX from the 
> constructor, but if setX is non-final, that has its own issues. You 
> could also put the x and y initialization within a synchronized (this) 
> { ... } -- but at that point, why not just allow the constructor to be 
> synchronized?
>
> Thanks,
> Yuval
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/0e856b00/attachment.html>

From cheremin at gmail.com  Thu Dec 15 16:41:17 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Fri, 16 Dec 2011 00:41:17 +0300
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEA66DB.60002@oracle.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
Message-ID: <CAOwENi+8hEQQyu6ZPuLWSNPb0WfEEByqAywqRPc0FBuggLGTRA@mail.gmail.com>

But I can pass reference between threads without any kind of
synchronization. Just assign it to shared variable in initializing
thread, and spinning while(haredRef==null){}?in another, hoping on
best. This, sure, will be a data race, with all demons behind it, and
second thread can get reference to partially initialized object -- but
who will care, if constructor would be synchronized, and all
accessors/mutators too?

2011/12/16 Nathan Reynolds <nathan.reynolds at oracle.com>:
> How is the MyPoint instance going to become shared with another thread?? The
> thread calling the constructor has to execute some sort of synchronization
> to share the reference to the MyPoint instance.? The synchronization will
> cause a happens-before edge to be created.? For example, this code assigns a
> volatile field.? Writing to the volatile will ensure the proper values of x
> and y will be visible.
>
> public volatile MyPoint point = new MyPoint();
>
> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering | Server Technology
>
> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>
> Hi all,
>
> This came up a few days ago on stackoverflow.com -- I forget the exact post,
> but someone referenced the JLS section concerning why constructors can't be
> synchronized:
>
>> There is no practical need for a constructor to be synchronized, because
>> it would lock the object under construction, which is normally not made
>> available to other threads until all constructors for the object have
>> completed their work.
>
>
> If synchronization were only about mutual exclusion, this would make sense;
> but it also has memory visibility guarantees. For instance, say I have this
> really simple class:
>
> ? ? public class MyPoint {
> ? ? ? ? private int x;
> ? ? ? ? private int y;
>
> ? ? ? ? public MyPoint() {
> ? ? ? ? ? ? x = -1; // init to (-1,-1) for some reason
> ? ? ? ? ? ? y = -1;
> ? ? ? ? }
>
> ? ? ? ? public synchronized void setX(int x, int y) {
> ? ? ? ? ? ? this.x = x;
> ? ? ? ? ? ? this.y = y;
> ? ? ? ? }
>
> ? ? ? ? @Override
> ? ? ? ? public synchronized String toString() {
> ? ? ? ? ? ? return "(" + x + ", " + y + ")";
> ? ? ? ? }
> ? ? }
>
> There's a thread safety issue there, right? There was no synchronization
> during construction time, and thus no happens-before between ctor ending and
> toString() starting, so with reordering etc, you could observe the initial
> state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)". ?You could get around
> this by calling setX from the constructor, but if setX is non-final, that
> has its own issues. You could also put the x and y initialization within a
> synchronized (this) { ... } -- but at that point, why not just allow the
> constructor to be synchronized?
>
> Thanks,
> Yuval
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From dhanji at gmail.com  Thu Dec 15 16:42:30 2011
From: dhanji at gmail.com (dhanji at gmail.com)
Date: Thu, 15 Dec 2011 21:42:30 +0000 (UTC)
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
Message-ID: <-1442414943.0.13443ad30f1.c@fluent.io>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/f9dc0c02/attachment.html>

From yshavit at akiban.com  Thu Dec 15 16:43:02 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 15 Dec 2011 16:43:02 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEA66DB.60002@oracle.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
Message-ID: <CAC2Zdp0f5Cw84LfQCAhQvOQz1sv_c=d=AxJYX=f1r2hfpjUwcw@mail.gmail.com>

So is the assumption that safe initial publication to other threads is
always required, and thread safety guarantees only kick in once that's been
done?

I could imagine someone assigning their MyPoint to a non-volatile static
and creating a new instance if that static is null:

public static MyPoint myPoint;

MyPoint getAnyOldPoint() {
    if (myPoint == null)
        myPoint = new MyPoint();
    return myPoint;
}

The person who writes that code (not me! :)  ) says, "I don't care which
MyPoint I get -- I don't care if it's the same one another thread sees or
not. All I care is that there is one, and that it's thread-safe. And I got
one (didn't have to instantiate it in this method), but it wasn't thread
safe: I saw "(0,-1)" even though no thread could have possibly set such a
state. I must have seen the initial state of a MyPoint, but it wasn't
thread safe."

Now, I would love to tell them "sure it's thread safe, you're just doing
stupid things." But would they be wrong in telling me that no, my class is
only *partially* thread safe?

Yuval


On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  How is the MyPoint instance going to become shared with another thread?
> The thread calling the constructor has to execute some sort of
> synchronization to share the reference to the MyPoint instance.  The
> synchronization will cause a happens-before edge to be created.  For
> example, this code assigns a volatile field.  Writing to the volatile will
> ensure the proper values of x and y will be visible.
>
> public volatile MyPoint point = new MyPoint();
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>
> Hi all,
>
>  This came up a few days ago on stackoverflow.com -- I forget the exact
> post, but someone referenced the JLS section concerning why constructors
> can't be synchronized:
>
>  There is no practical need for a constructor to be synchronized, because
>> it would lock the object under construction, which is normally not made
>> available to other threads until all constructors for the object have
>> completed their work.
>
>
>  If synchronization were only about mutual exclusion, this would make
> sense; but it also has memory visibility guarantees. For instance, say I
> have this really simple class:
>
>       public class MyPoint {
>         private int x;
>         private int y;
>
>         public MyPoint() {
>             x = -1; // init to (-1,-1) for some reason
>             y = -1;
>         }
>
>          public synchronized void setX(int x, int y) {
>             this.x = x;
>             this.y = y;
>         }
>
>          @Override
>         public synchronized String toString() {
>             return "(" + x + ", " + y + ")";
>         }
>     }
>
>  There's a thread safety issue there, right? There was no synchronization
> during construction time, and thus no happens-before between ctor ending
> and toString() starting, so with reordering etc, you could observe the
> initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could
> get around this by calling setX from the constructor, but if setX is
> non-final, that has its own issues. You could also put the x and y
> initialization within a synchronized (this) { ... } -- but at that point,
> why not just allow the constructor to be synchronized?
>
>  Thanks,
> Yuval
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/65d68cc3/attachment.html>

From nathan.reynolds at oracle.com  Thu Dec 15 16:49:45 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 15 Dec 2011 14:49:45 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAOwENi+8hEQQyu6ZPuLWSNPb0WfEEByqAywqRPc0FBuggLGTRA@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
	<CAOwENi+8hEQQyu6ZPuLWSNPb0WfEEByqAywqRPc0FBuggLGTRA@mail.gmail.com>
Message-ID: <4EEA6B79.3080000@oracle.com>

If sharedRef is non-volatile, then there are no guarantees that the 
thread spinning on sharedRef will ever see a non-null value.  You assume 
that because a thread writes to a memory location that all other threads 
eventually will see the update.  This is not true according to the Java 
Memory Model.  The JMM requires a happens-before relationship to be 
created in order for other threads to see the update.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:41 PM, Ruslan Cheremin wrote:
> But I can pass reference between threads without any kind of
> synchronization. Just assign it to shared variable in initializing
> thread, and spinning while(haredRef==null){} in another, hoping on
> best. This, sure, will be a data race, with all demons behind it, and
> second thread can get reference to partially initialized object -- but
> who will care, if constructor would be synchronized, and all
> accessors/mutators too?
>
> 2011/12/16 Nathan Reynolds<nathan.reynolds at oracle.com>:
>> How is the MyPoint instance going to become shared with another thread?  The
>> thread calling the constructor has to execute some sort of synchronization
>> to share the reference to the MyPoint instance.  The synchronization will
>> cause a happens-before edge to be created.  For example, this code assigns a
>> volatile field.  Writing to the volatile will ensure the proper values of x
>> and y will be visible.
>>
>> public volatile MyPoint point = new MyPoint();
>>
>> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering | Server Technology
>>
>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>
>> Hi all,
>>
>> This came up a few days ago on stackoverflow.com -- I forget the exact post,
>> but someone referenced the JLS section concerning why constructors can't be
>> synchronized:
>>
>>> There is no practical need for a constructor to be synchronized, because
>>> it would lock the object under construction, which is normally not made
>>> available to other threads until all constructors for the object have
>>> completed their work.
>>
>> If synchronization were only about mutual exclusion, this would make sense;
>> but it also has memory visibility guarantees. For instance, say I have this
>> really simple class:
>>
>>      public class MyPoint {
>>          private int x;
>>          private int y;
>>
>>          public MyPoint() {
>>              x = -1; // init to (-1,-1) for some reason
>>              y = -1;
>>          }
>>
>>          public synchronized void setX(int x, int y) {
>>              this.x = x;
>>              this.y = y;
>>          }
>>
>>          @Override
>>          public synchronized String toString() {
>>              return "(" + x + ", " + y + ")";
>>          }
>>      }
>>
>> There's a thread safety issue there, right? There was no synchronization
>> during construction time, and thus no happens-before between ctor ending and
>> toString() starting, so with reordering etc, you could observe the initial
>> state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could get around
>> this by calling setX from the constructor, but if setX is non-final, that
>> has its own issues. You could also put the x and y initialization within a
>> synchronized (this) { ... } -- but at that point, why not just allow the
>> constructor to be synchronized?
>>
>> Thanks,
>> Yuval
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/39442243/attachment.html>

From nathan.reynolds at oracle.com  Thu Dec 15 16:52:35 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 15 Dec 2011 14:52:35 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp0f5Cw84LfQCAhQvOQz1sv_c=d=AxJYX=f1r2hfpjUwcw@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
	<CAC2Zdp0f5Cw84LfQCAhQvOQz1sv_c=d=AxJYX=f1r2hfpjUwcw@mail.gmail.com>
Message-ID: <4EEA6C23.5040502@oracle.com>

This smells like double-checked locking.  Without a volatile or 
synchronized, then this is definitely not going to work correctly and is 
not thread-safe.  Look up double-checked locking on the web to see why 
it is not thread-safe.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:43 PM, Yuval Shavit wrote:
> So is the assumption that safe initial publication to other threads is 
> always required, and thread safety guarantees only kick in once that's 
> been done?
>
> I could imagine someone assigning their MyPoint to a non-volatile 
> static and creating a new instance if that static is null:
>
> public static MyPoint myPoint;
>
> MyPoint getAnyOldPoint() {
>     if (myPoint == null)
>         myPoint = new MyPoint();
>     return myPoint;
> }
>
> The person who writes that code (not me! :)  ) says, "I don't care 
> which MyPoint I get -- I don't care if it's the same one another 
> thread sees or not. All I care is that there is one, and that it's 
> thread-safe. And I got one (didn't have to instantiate it in this 
> method), but it wasn't thread safe: I saw "(0,-1)" even though no 
> thread could have possibly set such a state. I must have seen the 
> initial state of a MyPoint, but it wasn't thread safe."
>
> Now, I would love to tell them "sure it's thread safe, you're just 
> doing stupid things." But would they be wrong in telling me that no, 
> my class is only *partially* thread safe?
>
> Yuval
>
>
> On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     How is the MyPoint instance going to become shared with another
>     thread?  The thread calling the constructor has to execute some
>     sort of synchronization to share the reference to the MyPoint
>     instance.  The synchronization will cause a happens-before edge to
>     be created.  For example, this code assigns a volatile field. 
>     Writing to the volatile will ensure the proper values of x and y
>     will be visible.
>
>     public volatile MyPoint point = new MyPoint();
>
>     Nathan Reynolds
>     <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>     Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>     Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
>     On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>     Hi all,
>>
>>     This came up a few days ago on stackoverflow.com
>>     <http://stackoverflow.com> -- I forget the exact post, but
>>     someone referenced the JLS section concerning why constructors
>>     can't be synchronized:
>>
>>         There is no practical need for a constructor to be
>>         synchronized, because it would lock the object under
>>         construction, which is normally not made available to other
>>         threads until all constructors for the object have completed
>>         their work.
>>
>>
>>     If synchronization were only about mutual exclusion, this would
>>     make sense; but it also has memory visibility guarantees. For
>>     instance, say I have this really simple class:
>>
>>         public class MyPoint {
>>             private int x;
>>             private int y;
>>             public MyPoint() {
>>                 x = -1; // init to (-1,-1) for some reason
>>                 y = -1;
>>             }
>>
>>             public synchronized void setX(int x, int y) {
>>                 this.x = x;
>>                 this.y = y;
>>             }
>>
>>             @Override
>>             public synchronized String toString() {
>>                 return "(" + x + ", " + y + ")";
>>             }
>>         }
>>
>>     There's a thread safety issue there, right? There was no
>>     synchronization during construction time, and thus no
>>     happens-before between ctor ending and toString() starting, so
>>     with reordering etc, you could observe the initial state as "(0,
>>     0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could get around
>>     this by calling setX from the constructor, but if setX is
>>     non-final, that has its own issues. You could also put the x and
>>     y initialization within a synchronized (this) { ... } -- but at
>>     that point, why not just allow the constructor to be synchronized?
>>
>>     Thanks,
>>     Yuval
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/a40f7961/attachment-0001.html>

From yshavit at akiban.com  Thu Dec 15 16:59:45 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 15 Dec 2011 16:59:45 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEA6C23.5040502@oracle.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
	<CAC2Zdp0f5Cw84LfQCAhQvOQz1sv_c=d=AxJYX=f1r2hfpjUwcw@mail.gmail.com>
	<4EEA6C23.5040502@oracle.com>
Message-ID: <CAC2Zdp1rjkX8DMMnKyyyh_o_eNnX_eg0xjEo=JKzfg-rRgB02A@mail.gmail.com>

Oh, I totally understand why it's a bad idea -- and I was about to reply to
your reply to Ruslan, saying that my version was basically a poor man's
double-checked lock. It's actually not even a real DCL, because that
pattern at least tries to ensure that only one thread will instantiate the
object, whereas my code will happily create multiple instances, each living
in its own place on some CPU's cache. The hypothetical author of that code
might even say that's intentional, because he wants to shard or something.
Like I said, I fully understand it's a bad pattern. On the other hand, it
seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}, this broken sharding/DCL would work: either you
instantiate the object yourself (and thus see it fully instantiated) or
you'll hit a synchronized(this) block on toString(), which will establish
that the constructor's synchronized(this) happened-before toString's.

On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  This smells like double-checked locking.  Without a volatile or
> synchronized, then this is definitely not going to work correctly and is
> not thread-safe.  Look up double-checked locking on the web to see why it
> is not thread-safe.
>
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>
> So is the assumption that safe initial publication to other threads is
> always required, and thread safety guarantees only kick in once that's been
> done?
>
>  I could imagine someone assigning their MyPoint to a non-volatile static
> and creating a new instance if that static is null:
>
>  public static MyPoint myPoint;
>
>  MyPoint getAnyOldPoint() {
>     if (myPoint == null)
>         myPoint = new MyPoint();
>     return myPoint;
>  }
>
>  The person who writes that code (not me! :)  ) says, "I don't care which
> MyPoint I get -- I don't care if it's the same one another thread sees or
> not. All I care is that there is one, and that it's thread-safe. And I got
> one (didn't have to instantiate it in this method), but it wasn't thread
> safe: I saw "(0,-1)" even though no thread could have possibly set such a
> state. I must have seen the initial state of a MyPoint, but it wasn't
> thread safe."
>
>  Now, I would love to tell them "sure it's thread safe, you're just doing
> stupid things." But would they be wrong in telling me that no, my class is
> only *partially* thread safe?
>
>  Yuval
>
>
>  On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>>  How is the MyPoint instance going to become shared with another thread?
>> The thread calling the constructor has to execute some sort of
>> synchronization to share the reference to the MyPoint instance.  The
>> synchronization will cause a happens-before edge to be created.  For
>> example, this code assigns a volatile field.  Writing to the volatile will
>> ensure the proper values of x and y will be visible.
>>
>> public volatile MyPoint point = new MyPoint();
>>
>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>> 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>
>>  Hi all,
>>
>>  This came up a few days ago on stackoverflow.com -- I forget the exact
>> post, but someone referenced the JLS section concerning why constructors
>> can't be synchronized:
>>
>>  There is no practical need for a constructor to be synchronized,
>>> because it would lock the object under construction, which is normally not
>>> made available to other threads until all constructors for the object have
>>> completed their work.
>>
>>
>>  If synchronization were only about mutual exclusion, this would make
>> sense; but it also has memory visibility guarantees. For instance, say I
>> have this really simple class:
>>
>>       public class MyPoint {
>>         private int x;
>>         private int y;
>>
>>         public MyPoint() {
>>             x = -1; // init to (-1,-1) for some reason
>>             y = -1;
>>         }
>>
>>          public synchronized void setX(int x, int y) {
>>             this.x = x;
>>             this.y = y;
>>         }
>>
>>          @Override
>>         public synchronized String toString() {
>>             return "(" + x + ", " + y + ")";
>>         }
>>     }
>>
>>  There's a thread safety issue there, right? There was no
>> synchronization during construction time, and thus no happens-before
>> between ctor ending and toString() starting, so with reordering etc, you
>> could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1,
>> 0)".  You could get around this by calling setX from the constructor, but
>> if setX is non-final, that has its own issues. You could also put the x and
>> y initialization within a synchronized (this) { ... } -- but at that point,
>> why not just allow the constructor to be synchronized?
>>
>>  Thanks,
>> Yuval
>>
>>
>>   _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/ee26bc39/attachment.html>

From nathan.reynolds at oracle.com  Thu Dec 15 17:20:11 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 15 Dec 2011 15:20:11 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp1rjkX8DMMnKyyyh_o_eNnX_eg0xjEo=JKzfg-rRgB02A@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<4EEA66DB.60002@oracle.com>
	<CAC2Zdp0f5Cw84LfQCAhQvOQz1sv_c=d=AxJYX=f1r2hfpjUwcw@mail.gmail.com>
	<4EEA6C23.5040502@oracle.com>
	<CAC2Zdp1rjkX8DMMnKyyyh_o_eNnX_eg0xjEo=JKzfg-rRgB02A@mail.gmail.com>
Message-ID: <4EEA729B.8010705@oracle.com>

 > it seems to me that if all of the constructor had been wrapped in a 
synchronized (this) {...}

One could also add a final field in the class or have the constructor 
write to a volatile at the end of the method.  Both of these would add a 
happens-before.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:59 PM, Yuval Shavit wrote:
> Oh, I totally understand why it's a bad idea -- and I was about to 
> reply to your reply to Ruslan, saying that my version was basically a 
> poor man's double-checked lock. It's actually not even a real DCL, 
> because that pattern at least tries to ensure that only one thread 
> will instantiate the object, whereas my code will happily create 
> multiple instances, each living in its own place on some CPU's cache. 
> The hypothetical author of that code might even say that's 
> intentional, because he wants to shard or something. Like I said, I 
> fully understand it's a bad pattern. On the other hand, it seems to me 
> that if all of the constructor had been wrapped in a synchronized 
> (this) {...}, this broken sharding/DCL would work: either you 
> instantiate the object yourself (and thus see it fully instantiated) 
> or you'll hit a synchronized(this) block on toString(), which will 
> establish that the constructor's synchronized(this) happened-before 
> toString's.
>
> On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds 
> <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     This smells like double-checked locking.  Without a volatile or
>     synchronized, then this is definitely not going to work correctly
>     and is not thread-safe.  Look up double-checked locking on the web
>     to see why it is not thread-safe.
>
>
>     Nathan Reynolds
>     <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>     Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>     Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
>     On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>>     So is the assumption that safe initial publication to other
>>     threads is always required, and thread safety guarantees only
>>     kick in once that's been done?
>>
>>     I could imagine someone assigning their MyPoint to a non-volatile
>>     static and creating a new instance if that static is null:
>>
>>     public static MyPoint myPoint;
>>
>>     MyPoint getAnyOldPoint() {
>>         if (myPoint == null)
>>             myPoint = new MyPoint();
>>         return myPoint;
>>     }
>>
>>     The person who writes that code (not me! :)  ) says, "I don't
>>     care which MyPoint I get -- I don't care if it's the same one
>>     another thread sees or not. All I care is that there is one, and
>>     that it's thread-safe. And I got one (didn't have to instantiate
>>     it in this method), but it wasn't thread safe: I saw "(0,-1)"
>>     even though no thread could have possibly set such a state. I
>>     must have seen the initial state of a MyPoint, but it wasn't
>>     thread safe."
>>
>>     Now, I would love to tell them "sure it's thread safe, you're
>>     just doing stupid things." But would they be wrong in telling me
>>     that no, my class is only *partially* thread safe?
>>
>>     Yuval
>>
>>
>>     On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
>>     <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>>
>>     wrote:
>>
>>         How is the MyPoint instance going to become shared with
>>         another thread?  The thread calling the constructor has to
>>         execute some sort of synchronization to share the reference
>>         to the MyPoint instance.  The synchronization will cause a
>>         happens-before edge to be created.  For example, this code
>>         assigns a volatile field.  Writing to the volatile will
>>         ensure the proper values of x and y will be visible.
>>
>>         public volatile MyPoint point = new MyPoint();
>>
>>         Nathan Reynolds
>>         <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>>         Consulting Member of Technical Staff | 602.333.9091
>>         <tel:602.333.9091>
>>         Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>>         Technology
>>
>>         On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>>         Hi all,
>>>
>>>         This came up a few days ago on stackoverflow.com
>>>         <http://stackoverflow.com> -- I forget the exact post, but
>>>         someone referenced the JLS section concerning why
>>>         constructors can't be synchronized:
>>>
>>>             There is no practical need for a constructor to be
>>>             synchronized, because it would lock the object under
>>>             construction, which is normally not made available to
>>>             other threads until all constructors for the object have
>>>             completed their work.
>>>
>>>
>>>         If synchronization were only about mutual exclusion, this
>>>         would make sense; but it also has memory visibility
>>>         guarantees. For instance, say I have this really simple class:
>>>
>>>             public class MyPoint {
>>>                 private int x;
>>>                 private int y;
>>>                 public MyPoint() {
>>>                     x = -1; // init to (-1,-1) for some reason
>>>                     y = -1;
>>>                 }
>>>
>>>                 public synchronized void setX(int x, int y) {
>>>                     this.x = x;
>>>                     this.y = y;
>>>                 }
>>>
>>>                 @Override
>>>                 public synchronized String toString() {
>>>                     return "(" + x + ", " + y + ")";
>>>                 }
>>>             }
>>>
>>>         There's a thread safety issue there, right? There was no
>>>         synchronization during construction time, and thus no
>>>         happens-before between ctor ending and toString() starting,
>>>         so with reordering etc, you could observe the initial state
>>>         as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could
>>>         get around this by calling setX from the constructor, but if
>>>         setX is non-final, that has its own issues. You could also
>>>         put the x and y initialization within a synchronized (this)
>>>         { ... } -- but at that point, why not just allow the
>>>         constructor to be synchronized?
>>>
>>>         Thanks,
>>>         Yuval
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/0b4bb739/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Dec 15 17:21:02 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 16 Dec 2011 08:21:02 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp1rjkX8DMMnKyyyh_o_eNnX_eg0xjEo=JKzfg-rRgB02A@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEOEJBAA.davidcholmes@aapt.net.au>

Generally speaking the thread-safety of a class pertains to the use of an
instance of that class once it has been shared between threads. The sharing,
in general, requires safe-publication, which is something normally under the
control of the code doing the sharing not the code of the object that was
shared. Sometime a class needs to add some protection against
unsafe-publication that might violate important semantic guarantees of the
object - like sharing Strings in a way that might make the string appear to
have different values hence String uses final fields and we have the JMM's
final field semantics.

It is rare that you need to synchronize a constructor, or that having a
synchronized constructor addresses your needs. But in the case where it does
then you can use a synchronized block within the constructor.

I would not be surprised that when the prohibition against synchronizing a
constructor was created, visibility and safe-publication were not
considerations.

Cheers,
David Holmes
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Yuval Shavit
  Sent: Friday, 16 December 2011 8:00 AM
  To: Nathan Reynolds
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] synchronized constructors


  Oh, I totally understand why it's a bad idea -- and I was about to reply
to your reply to Ruslan, saying that my version was basically a poor man's
double-checked lock. It's actually not even a real DCL, because that pattern
at least tries to ensure that only one thread will instantiate the object,
whereas my code will happily create multiple instances, each living in its
own place on some CPU's cache. The hypothetical author of that code might
even say that's intentional, because he wants to shard or something. Like I
said, I fully understand it's a bad pattern. On the other hand, it seems to
me that if all of the constructor had been wrapped in a synchronized (this)
{...}, this broken sharding/DCL would work: either you instantiate the
object yourself (and thus see it fully instantiated) or you'll hit a
synchronized(this) block on toString(), which will establish that the
constructor's synchronized(this) happened-before toString's.


  On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

    This smells like double-checked locking.  Without a volatile or
synchronized, then this is definitely not going to work correctly and is not
thread-safe.  Look up double-checked locking on the web to see why it is not
thread-safe.



    Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
    Oracle PSR Engineering | Server Technology



    On 12/15/2011 2:43 PM, Yuval Shavit wrote:
      So is the assumption that safe initial publication to other threads is
always required, and thread safety guarantees only kick in once that's been
done?


      I could imagine someone assigning their MyPoint to a non-volatile
static and creating a new instance if that static is null:


      public static MyPoint myPoint;


      MyPoint getAnyOldPoint() {
          if (myPoint == null)
              myPoint = new MyPoint();
          return myPoint;
      }


      The person who writes that code (not me! :)  ) says, "I don't care
which MyPoint I get -- I don't care if it's the same one another thread sees
or not. All I care is that there is one, and that it's thread-safe. And I
got one (didn't have to instantiate it in this method), but it wasn't thread
safe: I saw "(0,-1)" even though no thread could have possibly set such a
state. I must have seen the initial state of a MyPoint, but it wasn't thread
safe."


      Now, I would love to tell them "sure it's thread safe, you're just
doing stupid things." But would they be wrong in telling me that no, my
class is only *partially* thread safe?


      Yuval




      On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

        How is the MyPoint instance going to become shared with another
thread?  The thread calling the constructor has to execute some sort of
synchronization to share the reference to the MyPoint instance.  The
synchronization will cause a happens-before edge to be created.  For
example, this code assigns a volatile field.  Writing to the volatile will
ensure the proper values of x and y will be visible.

        public volatile MyPoint point = new MyPoint();


        Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
        Oracle PSR Engineering | Server Technology


        On 12/15/2011 2:10 PM, Yuval Shavit wrote:
          Hi all,


          This came up a few days ago on stackoverflow.com -- I forget the
exact post, but someone referenced the JLS section concerning why
constructors can't be synchronized:


            There is no practical need for a constructor to be synchronized,
because it would lock the object under construction, which is normally not
made available to other threads until all constructors for the object have
completed their work.


          If synchronization were only about mutual exclusion, this would
make sense; but it also has memory visibility guarantees. For instance, say
I have this really simple class:


              public class MyPoint {
                  private int x;
                  private int y;

                  public MyPoint() {
                      x = -1; // init to (-1,-1) for some reason
                      y = -1;
                  }


                  public synchronized void setX(int x, int y) {
                      this.x = x;
                      this.y = y;
                  }


                  @Override
                  public synchronized String toString() {
                      return "(" + x + ", " + y + ")";
                  }
              }


          There's a thread safety issue there, right? There was no
synchronization during construction time, and thus no happens-before between
ctor ending and toString() starting, so with reordering etc, you could
observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".
You could get around this by calling setX from the constructor, but if setX
is non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?


          Thanks,
          Yuval



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/ebb16e8a/attachment.html>

From davidcholmes at aapt.net.au  Thu Dec 15 17:25:25 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 16 Dec 2011 08:25:25 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEA729B.8010705@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>

final field yes. Write to a volatile no.

The volatile only works if the other thread reads the volatile and sees the
written value.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
  Sent: Friday, 16 December 2011 8:20 AM
  To: Yuval Shavit
  Cc: concurrency-interest
  Subject: Re: [concurrency-interest] synchronized constructors


  > it seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}

  One could also add a final field in the class or have the constructor
write to a volatile at the end of the method.  Both of these would add a
happens-before.


  Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
  Oracle PSR Engineering | Server Technology


  On 12/15/2011 2:59 PM, Yuval Shavit wrote:
    Oh, I totally understand why it's a bad idea -- and I was about to reply
to your reply to Ruslan, saying that my version was basically a poor man's
double-checked lock. It's actually not even a real DCL, because that pattern
at least tries to ensure that only one thread will instantiate the object,
whereas my code will happily create multiple instances, each living in its
own place on some CPU's cache. The hypothetical author of that code might
even say that's intentional, because he wants to shard or something. Like I
said, I fully understand it's a bad pattern. On the other hand, it seems to
me that if all of the constructor had been wrapped in a synchronized (this)
{...}, this broken sharding/DCL would work: either you instantiate the
object yourself (and thus see it fully instantiated) or you'll hit a
synchronized(this) block on toString(), which will establish that the
constructor's synchronized(this) happened-before toString's.


    On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

      This smells like double-checked locking.  Without a volatile or
synchronized, then this is definitely not going to work correctly and is not
thread-safe.  Look up double-checked locking on the web to see why it is not
thread-safe.



      Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
      Oracle PSR Engineering | Server Technology



      On 12/15/2011 2:43 PM, Yuval Shavit wrote:
        So is the assumption that safe initial publication to other threads
is always required, and thread safety guarantees only kick in once that's
been done?


        I could imagine someone assigning their MyPoint to a non-volatile
static and creating a new instance if that static is null:


        public static MyPoint myPoint;


        MyPoint getAnyOldPoint() {
            if (myPoint == null)
                myPoint = new MyPoint();
            return myPoint;
        }


        The person who writes that code (not me! :)  ) says, "I don't care
which MyPoint I get -- I don't care if it's the same one another thread sees
or not. All I care is that there is one, and that it's thread-safe. And I
got one (didn't have to instantiate it in this method), but it wasn't thread
safe: I saw "(0,-1)" even though no thread could have possibly set such a
state. I must have seen the initial state of a MyPoint, but it wasn't thread
safe."


        Now, I would love to tell them "sure it's thread safe, you're just
doing stupid things." But would they be wrong in telling me that no, my
class is only *partially* thread safe?


        Yuval




        On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

          How is the MyPoint instance going to become shared with another
thread?  The thread calling the constructor has to execute some sort of
synchronization to share the reference to the MyPoint instance.  The
synchronization will cause a happens-before edge to be created.  For
example, this code assigns a volatile field.  Writing to the volatile will
ensure the proper values of x and y will be visible.

          public volatile MyPoint point = new MyPoint();


          Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
          Oracle PSR Engineering | Server Technology


          On 12/15/2011 2:10 PM, Yuval Shavit wrote:
            Hi all,


            This came up a few days ago on stackoverflow.com -- I forget the
exact post, but someone referenced the JLS section concerning why
constructors can't be synchronized:


              There is no practical need for a constructor to be
synchronized, because it would lock the object under construction, which is
normally not made available to other threads until all constructors for the
object have completed their work.


            If synchronization were only about mutual exclusion, this would
make sense; but it also has memory visibility guarantees. For instance, say
I have this really simple class:


                public class MyPoint {
                    private int x;
                    private int y;

                    public MyPoint() {
                        x = -1; // init to (-1,-1) for some reason
                        y = -1;
                    }


                    public synchronized void setX(int x, int y) {
                        this.x = x;
                        this.y = y;
                    }


                    @Override
                    public synchronized String toString() {
                        return "(" + x + ", " + y + ")";
                    }
                }


            There's a thread safety issue there, right? There was no
synchronization during construction time, and thus no happens-before between
ctor ending and toString() starting, so with reordering etc, you could
observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".
You could get around this by calling setX from the constructor, but if setX
is non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?


            Thanks,
            Yuval



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/65841a93/attachment-0001.html>

From yshavit at akiban.com  Thu Dec 15 17:36:29 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 15 Dec 2011 17:36:29 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>

Wouldn't the final field only establish that reads to *that field* see at
least the state it was in at end of construction? That is, if you had two
fields:

final int a;
int b;

And your constructor were:
    a = 1;
    b = a;

Then, in the absence of correct publication, couldn't another thread still
see a = 1, b = 0?

On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> final field yes. Write to a volatile no.
>
> The volatile only works if the other thread reads the volatile and sees
> the written value.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Nathan Reynolds
> *Sent:* Friday, 16 December 2011 8:20 AM
> *To:* Yuval Shavit
> *Cc:* concurrency-interest
> *Subject:* Re: [concurrency-interest] synchronized constructors
>
> > it seems to me that if all of the constructor had been wrapped in a
> synchronized (this) {...}
>
> One could also add a final field in the class or have the constructor
> write to a volatile at the end of the method.  Both of these would add a
> happens-before.
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/15/2011 2:59 PM, Yuval Shavit wrote:
>
> Oh, I totally understand why it's a bad idea -- and I was about to reply
> to your reply to Ruslan, saying that my version was basically a poor man's
> double-checked lock. It's actually not even a real DCL, because that
> pattern at least tries to ensure that only one thread will instantiate the
> object, whereas my code will happily create multiple instances, each living
> in its own place on some CPU's cache. The hypothetical author of that code
> might even say that's intentional, because he wants to shard or something.
> Like I said, I fully understand it's a bad pattern. On the other hand, it
> seems to me that if all of the constructor had been wrapped in a
> synchronized (this) {...}, this broken sharding/DCL would work: either you
> instantiate the object yourself (and thus see it fully instantiated) or
> you'll hit a synchronized(this) block on toString(), which will establish
> that the constructor's synchronized(this) happened-before toString's.
>
> On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <
> nathan.reynolds at oracle.com> wrote:
>
>> This smells like double-checked locking.  Without a volatile or
>> synchronized, then this is definitely not going to work correctly and is
>> not thread-safe.  Look up double-checked locking on the web to see why it
>> is not thread-safe.
>>
>>
>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>> 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>>  On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>>
>> So is the assumption that safe initial publication to other threads is
>> always required, and thread safety guarantees only kick in once that's been
>> done?
>>
>> I could imagine someone assigning their MyPoint to a non-volatile static
>> and creating a new instance if that static is null:
>>
>> public static MyPoint myPoint;
>>
>> MyPoint getAnyOldPoint() {
>>     if (myPoint == null)
>>         myPoint = new MyPoint();
>>     return myPoint;
>> }
>>
>> The person who writes that code (not me! :)  ) says, "I don't care which
>> MyPoint I get -- I don't care if it's the same one another thread sees or
>> not. All I care is that there is one, and that it's thread-safe. And I got
>> one (didn't have to instantiate it in this method), but it wasn't thread
>> safe: I saw "(0,-1)" even though no thread could have possibly set such a
>> state. I must have seen the initial state of a MyPoint, but it wasn't
>> thread safe."
>>
>> Now, I would love to tell them "sure it's thread safe, you're just doing
>> stupid things." But would they be wrong in telling me that no, my class is
>> only *partially* thread safe?
>>
>> Yuval
>>
>>
>>  On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <
>> nathan.reynolds at oracle.com> wrote:
>>
>>> How is the MyPoint instance going to become shared with another thread?
>>> The thread calling the constructor has to execute some sort of
>>> synchronization to share the reference to the MyPoint instance.  The
>>> synchronization will cause a happens-before edge to be created.  For
>>> example, this code assigns a volatile field.  Writing to the volatile will
>>> ensure the proper values of x and y will be visible.
>>>
>>> public volatile MyPoint point = new MyPoint();
>>>
>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>> 602.333.9091
>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>>
>>>  Hi all,
>>>
>>> This came up a few days ago on stackoverflow.com -- I forget the exact
>>> post, but someone referenced the JLS section concerning why constructors
>>> can't be synchronized:
>>>
>>> There is no practical need for a constructor to be synchronized, because
>>>> it would lock the object under construction, which is normally not made
>>>> available to other threads until all constructors for the object have
>>>> completed their work.
>>>
>>>
>>> If synchronization were only about mutual exclusion, this would make
>>> sense; but it also has memory visibility guarantees. For instance, say I
>>> have this really simple class:
>>>
>>>      public class MyPoint {
>>>         private int x;
>>>         private int y;
>>>
>>>         public MyPoint() {
>>>             x = -1; // init to (-1,-1) for some reason
>>>             y = -1;
>>>         }
>>>
>>>         public synchronized void setX(int x, int y) {
>>>             this.x = x;
>>>             this.y = y;
>>>         }
>>>
>>>         @Override
>>>         public synchronized String toString() {
>>>             return "(" + x + ", " + y + ")";
>>>         }
>>>     }
>>>
>>> There's a thread safety issue there, right? There was no synchronization
>>> during construction time, and thus no happens-before between ctor ending
>>> and toString() starting, so with reordering etc, you could observe the
>>> initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could
>>> get around this by calling setX from the constructor, but if setX is
>>> non-final, that has its own issues. You could also put the x and y
>>> initialization within a synchronized (this) { ... } -- but at that point,
>>> why not just allow the constructor to be synchronized?
>>>
>>> Thanks,
>>> Yuval
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/c34a618b/attachment.html>

From davidcholmes at aapt.net.au  Thu Dec 15 17:41:52 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 16 Dec 2011 08:41:52 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEOGJBAA.davidcholmes@aapt.net.au>

No - final fields have special semantics in the JMM. See "Final Fields" at

http://g.oswego.edu/dl/jmm/cookbook.html

David
  -----Original Message-----
  From: Yuval Shavit [mailto:yshavit at akiban.com]
  Sent: Friday, 16 December 2011 8:36 AM
  To: dholmes at ieee.org
  Cc: Nathan Reynolds; concurrency-interest
  Subject: Re: [concurrency-interest] synchronized constructors


  Wouldn't the final field only establish that reads to *that field* see at
least the state it was in at end of construction? That is, if you had two
fields:


  final int a;
  int b;


  And your constructor were:
      a = 1;
      b = a;


  Then, in the absence of correct publication, couldn't another thread still
see a = 1, b = 0?


  On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

    final field yes. Write to a volatile no.

    The volatile only works if the other thread reads the volatile and sees
the written value.

    David
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
      Sent: Friday, 16 December 2011 8:20 AM
      To: Yuval Shavit
      Cc: concurrency-interest
      Subject: Re: [concurrency-interest] synchronized constructors


      > it seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}

      One could also add a final field in the class or have the constructor
write to a volatile at the end of the method.  Both of these would add a
happens-before.


      Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
      Oracle PSR Engineering | Server Technology


      On 12/15/2011 2:59 PM, Yuval Shavit wrote:
        Oh, I totally understand why it's a bad idea -- and I was about to
reply to your reply to Ruslan, saying that my version was basically a poor
man's double-checked lock. It's actually not even a real DCL, because that
pattern at least tries to ensure that only one thread will instantiate the
object, whereas my code will happily create multiple instances, each living
in its own place on some CPU's cache. The hypothetical author of that code
might even say that's intentional, because he wants to shard or something.
Like I said, I fully understand it's a bad pattern. On the other hand, it
seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}, this broken sharding/DCL would work: either you
instantiate the object yourself (and thus see it fully instantiated) or
you'll hit a synchronized(this) block on toString(), which will establish
that the constructor's synchronized(this) happened-before toString's.


        On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

          This smells like double-checked locking.  Without a volatile or
synchronized, then this is definitely not going to work correctly and is not
thread-safe.  Look up double-checked locking on the web to see why it is not
thread-safe.



          Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
          Oracle PSR Engineering | Server Technology



          On 12/15/2011 2:43 PM, Yuval Shavit wrote:
            So is the assumption that safe initial publication to other
threads is always required, and thread safety guarantees only kick in once
that's been done?


            I could imagine someone assigning their MyPoint to a
non-volatile static and creating a new instance if that static is null:


            public static MyPoint myPoint;


            MyPoint getAnyOldPoint() {
                if (myPoint == null)
                    myPoint = new MyPoint();
                return myPoint;
            }


            The person who writes that code (not me! :)  ) says, "I don't
care which MyPoint I get -- I don't care if it's the same one another thread
sees or not. All I care is that there is one, and that it's thread-safe. And
I got one (didn't have to instantiate it in this method), but it wasn't
thread safe: I saw "(0,-1)" even though no thread could have possibly set
such a state. I must have seen the initial state of a MyPoint, but it wasn't
thread safe."


            Now, I would love to tell them "sure it's thread safe, you're
just doing stupid things." But would they be wrong in telling me that no, my
class is only *partially* thread safe?


            Yuval




            On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

              How is the MyPoint instance going to become shared with
another thread?  The thread calling the constructor has to execute some sort
of synchronization to share the reference to the MyPoint instance.  The
synchronization will cause a happens-before edge to be created.  For
example, this code assigns a volatile field.  Writing to the volatile will
ensure the proper values of x and y will be visible.

              public volatile MyPoint point = new MyPoint();


              Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
              Oracle PSR Engineering | Server Technology


              On 12/15/2011 2:10 PM, Yuval Shavit wrote:
                Hi all,


                This came up a few days ago on stackoverflow.com -- I forget
the exact post, but someone referenced the JLS section concerning why
constructors can't be synchronized:


                  There is no practical need for a constructor to be
synchronized, because it would lock the object under construction, which is
normally not made available to other threads until all constructors for the
object have completed their work.


                If synchronization were only about mutual exclusion, this
would make sense; but it also has memory visibility guarantees. For
instance, say I have this really simple class:


                    public class MyPoint {
                        private int x;
                        private int y;

                        public MyPoint() {
                            x = -1; // init to (-1,-1) for some reason
                            y = -1;
                        }


                        public synchronized void setX(int x, int y) {
                            this.x = x;
                            this.y = y;
                        }


                        @Override
                        public synchronized String toString() {
                            return "(" + x + ", " + y + ")";
                        }
                    }


                There's a thread safety issue there, right? There was no
synchronization during construction time, and thus no happens-before between
ctor ending and toString() starting, so with reordering etc, you could
observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".
You could get around this by calling setX from the constructor, but if setX
is non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?


                Thanks,
                Yuval



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/1276b3e6/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Dec 15 17:44:41 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 16 Dec 2011 08:44:41 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEOGJBAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEOGJBAA.davidcholmes@aapt.net.au>

No I take that back. final field semantics are more subtle than that. I'm
unsure if writing to a final would suffice.

David
  -----Original Message-----
  From: David Holmes [mailto:davidcholmes at aapt.net.au]
  Sent: Friday, 16 December 2011 8:42 AM
  To: Yuval Shavit
  Cc: Nathan Reynolds; concurrency-interest
  Subject: RE: [concurrency-interest] synchronized constructors


  No - final fields have special semantics in the JMM. See "Final Fields" at

  http://g.oswego.edu/dl/jmm/cookbook.html

  David
    -----Original Message-----
    From: Yuval Shavit [mailto:yshavit at akiban.com]
    Sent: Friday, 16 December 2011 8:36 AM
    To: dholmes at ieee.org
    Cc: Nathan Reynolds; concurrency-interest
    Subject: Re: [concurrency-interest] synchronized constructors


    Wouldn't the final field only establish that reads to *that field* see
at least the state it was in at end of construction? That is, if you had two
fields:


    final int a;
    int b;


    And your constructor were:
        a = 1;
        b = a;


    Then, in the absence of correct publication, couldn't another thread
still see a = 1, b = 0?


    On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

      final field yes. Write to a volatile no.

      The volatile only works if the other thread reads the volatile and
sees the written value.

      David
        -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
        Sent: Friday, 16 December 2011 8:20 AM
        To: Yuval Shavit
        Cc: concurrency-interest
        Subject: Re: [concurrency-interest] synchronized constructors


        > it seems to me that if all of the constructor had been wrapped in
a synchronized (this) {...}

        One could also add a final field in the class or have the
constructor write to a volatile at the end of the method.  Both of these
would add a happens-before.


        Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
        Oracle PSR Engineering | Server Technology


        On 12/15/2011 2:59 PM, Yuval Shavit wrote:
          Oh, I totally understand why it's a bad idea -- and I was about to
reply to your reply to Ruslan, saying that my version was basically a poor
man's double-checked lock. It's actually not even a real DCL, because that
pattern at least tries to ensure that only one thread will instantiate the
object, whereas my code will happily create multiple instances, each living
in its own place on some CPU's cache. The hypothetical author of that code
might even say that's intentional, because he wants to shard or something.
Like I said, I fully understand it's a bad pattern. On the other hand, it
seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}, this broken sharding/DCL would work: either you
instantiate the object yourself (and thus see it fully instantiated) or
you'll hit a synchronized(this) block on toString(), which will establish
that the constructor's synchronized(this) happened-before toString's.


          On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

            This smells like double-checked locking.  Without a volatile or
synchronized, then this is definitely not going to work correctly and is not
thread-safe.  Look up double-checked locking on the web to see why it is not
thread-safe.



            Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
            Oracle PSR Engineering | Server Technology



            On 12/15/2011 2:43 PM, Yuval Shavit wrote:
              So is the assumption that safe initial publication to other
threads is always required, and thread safety guarantees only kick in once
that's been done?


              I could imagine someone assigning their MyPoint to a
non-volatile static and creating a new instance if that static is null:


              public static MyPoint myPoint;


              MyPoint getAnyOldPoint() {
                  if (myPoint == null)
                      myPoint = new MyPoint();
                  return myPoint;
              }


              The person who writes that code (not me! :)  ) says, "I don't
care which MyPoint I get -- I don't care if it's the same one another thread
sees or not. All I care is that there is one, and that it's thread-safe. And
I got one (didn't have to instantiate it in this method), but it wasn't
thread safe: I saw "(0,-1)" even though no thread could have possibly set
such a state. I must have seen the initial state of a MyPoint, but it wasn't
thread safe."


              Now, I would love to tell them "sure it's thread safe, you're
just doing stupid things." But would they be wrong in telling me that no, my
class is only *partially* thread safe?


              Yuval




              On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

                How is the MyPoint instance going to become shared with
another thread?  The thread calling the constructor has to execute some sort
of synchronization to share the reference to the MyPoint instance.  The
synchronization will cause a happens-before edge to be created.  For
example, this code assigns a volatile field.  Writing to the volatile will
ensure the proper values of x and y will be visible.

                public volatile MyPoint point = new MyPoint();


                Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
                Oracle PSR Engineering | Server Technology


                On 12/15/2011 2:10 PM, Yuval Shavit wrote:
                  Hi all,


                  This came up a few days ago on stackoverflow.com -- I
forget the exact post, but someone referenced the JLS section concerning why
constructors can't be synchronized:


                    There is no practical need for a constructor to be
synchronized, because it would lock the object under construction, which is
normally not made available to other threads until all constructors for the
object have completed their work.


                  If synchronization were only about mutual exclusion, this
would make sense; but it also has memory visibility guarantees. For
instance, say I have this really simple class:


                      public class MyPoint {
                          private int x;
                          private int y;

                          public MyPoint() {
                              x = -1; // init to (-1,-1) for some reason
                              y = -1;
                          }


                          public synchronized void setX(int x, int y) {
                              this.x = x;
                              this.y = y;
                          }


                          @Override
                          public synchronized String toString() {
                              return "(" + x + ", " + y + ")";
                          }
                      }


                  There's a thread safety issue there, right? There was no
synchronization during construction time, and thus no happens-before between
ctor ending and toString() starting, so with reordering etc, you could
observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".
You could get around this by calling setX from the constructor, but if setX
is non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?


                  Thanks,
                  Yuval



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/1a4badf2/attachment.html>

From vitalyd at gmail.com  Thu Dec 15 17:46:50 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 17:46:50 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
Message-ID: <CAHjP37HfmZpM5JERwztOYE6+gsKYUd8ck3SPc4VG1Vp0RJSo=g@mail.gmail.com>

No that would violate data dependency.
On Dec 15, 2011 5:38 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> Wouldn't the final field only establish that reads to *that field* see at
> least the state it was in at end of construction? That is, if you had two
> fields:
>
> final int a;
> int b;
>
> And your constructor were:
>     a = 1;
>     b = a;
>
> Then, in the absence of correct publication, couldn't another thread still
> see a = 1, b = 0?
>
> On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>> **
>> final field yes. Write to a volatile no.
>>
>> The volatile only works if the other thread reads the volatile and sees
>> the written value.
>>
>> David
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Nathan Reynolds
>> *Sent:* Friday, 16 December 2011 8:20 AM
>> *To:* Yuval Shavit
>> *Cc:* concurrency-interest
>> *Subject:* Re: [concurrency-interest] synchronized constructors
>>
>> > it seems to me that if all of the constructor had been wrapped in a
>> synchronized (this) {...}
>>
>> One could also add a final field in the class or have the constructor
>> write to a volatile at the end of the method.  Both of these would add a
>> happens-before.
>>
>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>> 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 12/15/2011 2:59 PM, Yuval Shavit wrote:
>>
>> Oh, I totally understand why it's a bad idea -- and I was about to reply
>> to your reply to Ruslan, saying that my version was basically a poor man's
>> double-checked lock. It's actually not even a real DCL, because that
>> pattern at least tries to ensure that only one thread will instantiate the
>> object, whereas my code will happily create multiple instances, each living
>> in its own place on some CPU's cache. The hypothetical author of that code
>> might even say that's intentional, because he wants to shard or something.
>> Like I said, I fully understand it's a bad pattern. On the other hand, it
>> seems to me that if all of the constructor had been wrapped in a
>> synchronized (this) {...}, this broken sharding/DCL would work: either you
>> instantiate the object yourself (and thus see it fully instantiated) or
>> you'll hit a synchronized(this) block on toString(), which will establish
>> that the constructor's synchronized(this) happened-before toString's.
>>
>> On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <
>> nathan.reynolds at oracle.com> wrote:
>>
>>> This smells like double-checked locking.  Without a volatile or
>>> synchronized, then this is definitely not going to work correctly and is
>>> not thread-safe.  Look up double-checked locking on the web to see why it
>>> is not thread-safe.
>>>
>>>
>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>> 602.333.9091
>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>>  On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>>>
>>> So is the assumption that safe initial publication to other threads is
>>> always required, and thread safety guarantees only kick in once that's been
>>> done?
>>>
>>> I could imagine someone assigning their MyPoint to a non-volatile static
>>> and creating a new instance if that static is null:
>>>
>>> public static MyPoint myPoint;
>>>
>>> MyPoint getAnyOldPoint() {
>>>     if (myPoint == null)
>>>         myPoint = new MyPoint();
>>>     return myPoint;
>>> }
>>>
>>> The person who writes that code (not me! :)  ) says, "I don't care which
>>> MyPoint I get -- I don't care if it's the same one another thread sees or
>>> not. All I care is that there is one, and that it's thread-safe. And I got
>>> one (didn't have to instantiate it in this method), but it wasn't thread
>>> safe: I saw "(0,-1)" even though no thread could have possibly set such a
>>> state. I must have seen the initial state of a MyPoint, but it wasn't
>>> thread safe."
>>>
>>> Now, I would love to tell them "sure it's thread safe, you're just doing
>>> stupid things." But would they be wrong in telling me that no, my class is
>>> only *partially* thread safe?
>>>
>>> Yuval
>>>
>>>
>>>  On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <
>>> nathan.reynolds at oracle.com> wrote:
>>>
>>>> How is the MyPoint instance going to become shared with another
>>>> thread?  The thread calling the constructor has to execute some sort of
>>>> synchronization to share the reference to the MyPoint instance.  The
>>>> synchronization will cause a happens-before edge to be created.  For
>>>> example, this code assigns a volatile field.  Writing to the volatile will
>>>> ensure the proper values of x and y will be visible.
>>>>
>>>> public volatile MyPoint point = new MyPoint();
>>>>
>>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>>> 602.333.9091
>>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>>
>>>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>>>
>>>>  Hi all,
>>>>
>>>> This came up a few days ago on stackoverflow.com -- I forget the exact
>>>> post, but someone referenced the JLS section concerning why constructors
>>>> can't be synchronized:
>>>>
>>>> There is no practical need for a constructor to be synchronized,
>>>>> because it would lock the object under construction, which is normally not
>>>>> made available to other threads until all constructors for the object have
>>>>> completed their work.
>>>>
>>>>
>>>> If synchronization were only about mutual exclusion, this would make
>>>> sense; but it also has memory visibility guarantees. For instance, say I
>>>> have this really simple class:
>>>>
>>>>      public class MyPoint {
>>>>         private int x;
>>>>         private int y;
>>>>
>>>>         public MyPoint() {
>>>>             x = -1; // init to (-1,-1) for some reason
>>>>             y = -1;
>>>>         }
>>>>
>>>>         public synchronized void setX(int x, int y) {
>>>>             this.x = x;
>>>>             this.y = y;
>>>>         }
>>>>
>>>>         @Override
>>>>         public synchronized String toString() {
>>>>             return "(" + x + ", " + y + ")";
>>>>         }
>>>>     }
>>>>
>>>> There's a thread safety issue there, right? There was no
>>>> synchronization during construction time, and thus no happens-before
>>>> between ctor ending and toString() starting, so with reordering etc, you
>>>> could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1,
>>>> 0)".  You could get around this by calling setX from the constructor, but
>>>> if setX is non-final, that has its own issues. You could also put the x and
>>>> y initialization within a synchronized (this) { ... } -- but at that point,
>>>> why not just allow the constructor to be synchronized?
>>>>
>>>> Thanks,
>>>> Yuval
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/cc8a3d01/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Dec 15 17:52:26 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 16 Dec 2011 08:52:26 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37HfmZpM5JERwztOYE6+gsKYUd8ck3SPc4VG1Vp0RJSo=g@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEOHJBAA.davidcholmes@aapt.net.au>

I'm not aware of any "data dependency" rules in the JMM.

Yuval's example could be reordered to:

a = 1;
publish ref
b = a;

allowing another thread to see b==0.

The "Final Field" section of the JMM cookbook end with this caution:

"These rules imply that reliable use of final fields by Java programmers
requires that the load of a shared reference to an object with a final field
itself be synchronized, volatile, or final, or derived from such a load,
thus ultimately ordering the initializing stores in constructors with
subsequent uses outside constructors. "

David
  -----Original Message-----
  From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
  Sent: Friday, 16 December 2011 8:47 AM
  To: Yuval Shavit
  Cc: dholmes at ieee.org; concurrency-interest
  Subject: Re: [concurrency-interest] synchronized constructors


  No that would violate data dependency.

  On Dec 15, 2011 5:38 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

    Wouldn't the final field only establish that reads to *that field* see
at least the state it was in at end of construction? That is, if you had two
fields:


    final int a;
    int b;


    And your constructor were:
        a = 1;
        b = a;


    Then, in the absence of correct publication, couldn't another thread
still see a = 1, b = 0?


    On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

      final field yes. Write to a volatile no.

      The volatile only works if the other thread reads the volatile and
sees the written value.

      David
        -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
        Sent: Friday, 16 December 2011 8:20 AM
        To: Yuval Shavit
        Cc: concurrency-interest
        Subject: Re: [concurrency-interest] synchronized constructors


        > it seems to me that if all of the constructor had been wrapped in
a synchronized (this) {...}

        One could also add a final field in the class or have the
constructor write to a volatile at the end of the method.  Both of these
would add a happens-before.


        Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
        Oracle PSR Engineering | Server Technology


        On 12/15/2011 2:59 PM, Yuval Shavit wrote:
          Oh, I totally understand why it's a bad idea -- and I was about to
reply to your reply to Ruslan, saying that my version was basically a poor
man's double-checked lock. It's actually not even a real DCL, because that
pattern at least tries to ensure that only one thread will instantiate the
object, whereas my code will happily create multiple instances, each living
in its own place on some CPU's cache. The hypothetical author of that code
might even say that's intentional, because he wants to shard or something.
Like I said, I fully understand it's a bad pattern. On the other hand, it
seems to me that if all of the constructor had been wrapped in a
synchronized (this) {...}, this broken sharding/DCL would work: either you
instantiate the object yourself (and thus see it fully instantiated) or
you'll hit a synchronized(this) block on toString(), which will establish
that the constructor's synchronized(this) happened-before toString's.


          On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

            This smells like double-checked locking.  Without a volatile or
synchronized, then this is definitely not going to work correctly and is not
thread-safe.  Look up double-checked locking on the web to see why it is not
thread-safe.



            Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
            Oracle PSR Engineering | Server Technology



            On 12/15/2011 2:43 PM, Yuval Shavit wrote:
              So is the assumption that safe initial publication to other
threads is always required, and thread safety guarantees only kick in once
that's been done?


              I could imagine someone assigning their MyPoint to a
non-volatile static and creating a new instance if that static is null:


              public static MyPoint myPoint;


              MyPoint getAnyOldPoint() {
                  if (myPoint == null)
                      myPoint = new MyPoint();
                  return myPoint;
              }


              The person who writes that code (not me! :)  ) says, "I don't
care which MyPoint I get -- I don't care if it's the same one another thread
sees or not. All I care is that there is one, and that it's thread-safe. And
I got one (didn't have to instantiate it in this method), but it wasn't
thread safe: I saw "(0,-1)" even though no thread could have possibly set
such a state. I must have seen the initial state of a MyPoint, but it wasn't
thread safe."


              Now, I would love to tell them "sure it's thread safe, you're
just doing stupid things." But would they be wrong in telling me that no, my
class is only *partially* thread safe?


              Yuval




              On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds
<nathan.reynolds at oracle.com> wrote:

                How is the MyPoint instance going to become shared with
another thread?  The thread calling the constructor has to execute some sort
of synchronization to share the reference to the MyPoint instance.  The
synchronization will cause a happens-before edge to be created.  For
example, this code assigns a volatile field.  Writing to the volatile will
ensure the proper values of x and y will be visible.

                public volatile MyPoint point = new MyPoint();


                Nathan Reynolds | Consulting Member of Technical Staff |
602.333.9091
                Oracle PSR Engineering | Server Technology


                On 12/15/2011 2:10 PM, Yuval Shavit wrote:
                  Hi all,


                  This came up a few days ago on stackoverflow.com -- I
forget the exact post, but someone referenced the JLS section concerning why
constructors can't be synchronized:


                    There is no practical need for a constructor to be
synchronized, because it would lock the object under construction, which is
normally not made available to other threads until all constructors for the
object have completed their work.


                  If synchronization were only about mutual exclusion, this
would make sense; but it also has memory visibility guarantees. For
instance, say I have this really simple class:


                      public class MyPoint {
                          private int x;
                          private int y;

                          public MyPoint() {
                              x = -1; // init to (-1,-1) for some reason
                              y = -1;
                          }


                          public synchronized void setX(int x, int y) {
                              this.x = x;
                              this.y = y;
                          }


                          @Override
                          public synchronized String toString() {
                              return "(" + x + ", " + y + ")";
                          }
                      }


                  There's a thread safety issue there, right? There was no
synchronization during construction time, and thus no happens-before between
ctor ending and toString() starting, so with reordering etc, you could
observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".
You could get around this by calling setX from the constructor, but if setX
is non-final, that has its own issues. You could also put the x and y
initialization within a synchronized (this) { ... } -- but at that point,
why not just allow the constructor to be synchronized?


                  Thanks,
                  Yuval



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest







    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/31c6fe0b/attachment-0001.html>

From vitalyd at gmail.com  Thu Dec 15 17:53:00 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 17:53:00 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEOGJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEOGJBAA.davidcholmes@aapt.net.au>
	<NFBBKALFDCPFIDBNKAPCKEOGJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37EskXXP7SjC7J-kxTqAUHN2EUt4JzdiqkPZtA3FXDvaUA@mail.gmail.com>

Final in constructor disallows reordering of assignment to a reference with
subsequent instructions in the constructor of that instance.  I think in
practice the compiler will simply issue a storestore after the constructor
and before assignment to the reference - I don't think it tracks the order
of field writes in the constructor itself (I.e. whether final is written
before or after a non-final field).
On Dec 15, 2011 5:46 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> No I take that back. final field semantics are more subtle than that. I'm
> unsure if writing to a final would suffice.
>
> David
>
> -----Original Message-----
> *From:* David Holmes [mailto:davidcholmes at aapt.net.au]
> *Sent:* Friday, 16 December 2011 8:42 AM
> *To:* Yuval Shavit
> *Cc:* Nathan Reynolds; concurrency-interest
> *Subject:* RE: [concurrency-interest] synchronized constructors
>
> No - final fields have special semantics in the JMM. See "Final Fields" at
>
> http://g.oswego.edu/dl/jmm/cookbook.html
>
> David
>
> -----Original Message-----
> *From:* Yuval Shavit [mailto:yshavit at akiban.com]
> *Sent:* Friday, 16 December 2011 8:36 AM
> *To:* dholmes at ieee.org
> *Cc:* Nathan Reynolds; concurrency-interest
> *Subject:* Re: [concurrency-interest] synchronized constructors
>
> Wouldn't the final field only establish that reads to *that field* see at
> least the state it was in at end of construction? That is, if you had two
> fields:
>
> final int a;
> int b;
>
> And your constructor were:
>     a = 1;
>     b = a;
>
> Then, in the absence of correct publication, couldn't another thread still
> see a = 1, b = 0?
>
> On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>wrote:
>
>> **
>> final field yes. Write to a volatile no.
>>
>> The volatile only works if the other thread reads the volatile and sees
>> the written value.
>>
>> David
>>
>>  -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Nathan Reynolds
>> *Sent:* Friday, 16 December 2011 8:20 AM
>> *To:* Yuval Shavit
>> *Cc:* concurrency-interest
>> *Subject:* Re: [concurrency-interest] synchronized constructors
>>
>>  > it seems to me that if all of the constructor had been wrapped in a
>> synchronized (this) {...}
>>
>> One could also add a final field in the class or have the constructor
>> write to a volatile at the end of the method.  Both of these would add a
>> happens-before.
>>
>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>> 602.333.9091
>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>> On 12/15/2011 2:59 PM, Yuval Shavit wrote:
>>
>> Oh, I totally understand why it's a bad idea -- and I was about to reply
>> to your reply to Ruslan, saying that my version was basically a poor man's
>> double-checked lock. It's actually not even a real DCL, because that
>> pattern at least tries to ensure that only one thread will instantiate the
>> object, whereas my code will happily create multiple instances, each living
>> in its own place on some CPU's cache. The hypothetical author of that code
>> might even say that's intentional, because he wants to shard or something.
>> Like I said, I fully understand it's a bad pattern. On the other hand, it
>> seems to me that if all of the constructor had been wrapped in a
>> synchronized (this) {...}, this broken sharding/DCL would work: either you
>> instantiate the object yourself (and thus see it fully instantiated) or
>> you'll hit a synchronized(this) block on toString(), which will establish
>> that the constructor's synchronized(this) happened-before toString's.
>>
>> On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <
>> nathan.reynolds at oracle.com> wrote:
>>
>>> This smells like double-checked locking.  Without a volatile or
>>> synchronized, then this is definitely not going to work correctly and is
>>> not thread-safe.  Look up double-checked locking on the web to see why it
>>> is not thread-safe.
>>>
>>>
>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>> 602.333.9091
>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>>  On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>>>
>>> So is the assumption that safe initial publication to other threads is
>>> always required, and thread safety guarantees only kick in once that's been
>>> done?
>>>
>>> I could imagine someone assigning their MyPoint to a non-volatile static
>>> and creating a new instance if that static is null:
>>>
>>> public static MyPoint myPoint;
>>>
>>> MyPoint getAnyOldPoint() {
>>>     if (myPoint == null)
>>>         myPoint = new MyPoint();
>>>     return myPoint;
>>> }
>>>
>>> The person who writes that code (not me! :)  ) says, "I don't care which
>>> MyPoint I get -- I don't care if it's the same one another thread sees or
>>> not. All I care is that there is one, and that it's thread-safe. And I got
>>> one (didn't have to instantiate it in this method), but it wasn't thread
>>> safe: I saw "(0,-1)" even though no thread could have possibly set such a
>>> state. I must have seen the initial state of a MyPoint, but it wasn't
>>> thread safe."
>>>
>>> Now, I would love to tell them "sure it's thread safe, you're just doing
>>> stupid things." But would they be wrong in telling me that no, my class is
>>> only *partially* thread safe?
>>>
>>> Yuval
>>>
>>>
>>>  On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <
>>> nathan.reynolds at oracle.com> wrote:
>>>
>>>> How is the MyPoint instance going to become shared with another
>>>> thread?  The thread calling the constructor has to execute some sort of
>>>> synchronization to share the reference to the MyPoint instance.  The
>>>> synchronization will cause a happens-before edge to be created.  For
>>>> example, this code assigns a volatile field.  Writing to the volatile will
>>>> ensure the proper values of x and y will be visible.
>>>>
>>>> public volatile MyPoint point = new MyPoint();
>>>>
>>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>>> 602.333.9091
>>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>>
>>>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>>>
>>>>  Hi all,
>>>>
>>>> This came up a few days ago on stackoverflow.com -- I forget the exact
>>>> post, but someone referenced the JLS section concerning why constructors
>>>> can't be synchronized:
>>>>
>>>> There is no practical need for a constructor to be synchronized,
>>>>> because it would lock the object under construction, which is normally not
>>>>> made available to other threads until all constructors for the object have
>>>>> completed their work.
>>>>
>>>>
>>>> If synchronization were only about mutual exclusion, this would make
>>>> sense; but it also has memory visibility guarantees. For instance, say I
>>>> have this really simple class:
>>>>
>>>>      public class MyPoint {
>>>>         private int x;
>>>>         private int y;
>>>>
>>>>         public MyPoint() {
>>>>             x = -1; // init to (-1,-1) for some reason
>>>>             y = -1;
>>>>         }
>>>>
>>>>         public synchronized void setX(int x, int y) {
>>>>             this.x = x;
>>>>             this.y = y;
>>>>         }
>>>>
>>>>         @Override
>>>>         public synchronized String toString() {
>>>>             return "(" + x + ", " + y + ")";
>>>>         }
>>>>     }
>>>>
>>>> There's a thread safety issue there, right? There was no
>>>> synchronization during construction time, and thus no happens-before
>>>> between ctor ending and toString() starting, so with reordering etc, you
>>>> could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1,
>>>> 0)".  You could get around this by calling setX from the constructor, but
>>>> if setX is non-final, that has its own issues. You could also put the x and
>>>> y initialization within a synchronized (this) { ... } -- but at that point,
>>>> why not just allow the constructor to be synchronized?
>>>>
>>>> Thanks,
>>>> Yuval
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/f646449d/attachment.html>

From dhanji at gmail.com  Thu Dec 15 17:53:33 2011
From: dhanji at gmail.com (dhanji at gmail.com)
Date: Thu, 15 Dec 2011 22:53:33 +0000 (UTC)
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
Message-ID: <-1442414943.0.13443ee39d2.c@fluent.io>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/8ea115bd/attachment-0001.html>

From vitalyd at gmail.com  Thu Dec 15 17:58:42 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 17:58:42 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEOHJBAA.davidcholmes@aapt.net.au>
References: <CAHjP37HfmZpM5JERwztOYE6+gsKYUd8ck3SPc4VG1Vp0RJSo=g@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIEOHJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37FgnM9JwAdE0qpUAXcwELmwpSsK-FKOVCVQa4ULKosrDw@mail.gmail.com>

That's not what I thought was being asked - it sounds like the question was
whether another CPU can observe the reordering of store to a and store to b
without a publication in between.  Of course if you publish in between
anything goes.
On Dec 15, 2011 5:52 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> I'm not aware of any "data dependency" rules in the JMM.
>
> Yuval's example could be reordered to:
>
> a = 1;
> publish ref
> b = a;
>
> allowing another thread to see b==0.
>
> The "Final Field" section of the JMM cookbook end with this caution:
>
> "These rules imply that reliable use of final fields by Java programmers
> requires that the load of a shared reference to an object with a final
> field itself be synchronized, volatile, or final, or derived from such a
> load, thus ultimately ordering the initializing stores in constructors with
> subsequent uses outside constructors. "
>
> David
>
> -----Original Message-----
> *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com]
> *Sent:* Friday, 16 December 2011 8:47 AM
> *To:* Yuval Shavit
> *Cc:* dholmes at ieee.org; concurrency-interest
> *Subject:* Re: [concurrency-interest] synchronized constructors
>
> No that would violate data dependency.
> On Dec 15, 2011 5:38 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>
>> Wouldn't the final field only establish that reads to *that field* see at
>> least the state it was in at end of construction? That is, if you had two
>> fields:
>>
>> final int a;
>> int b;
>>
>> And your constructor were:
>>     a = 1;
>>     b = a;
>>
>> Then, in the absence of correct publication, couldn't another thread
>> still see a = 1, b = 0?
>>
>> On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au>wrote:
>>
>>> **
>>> final field yes. Write to a volatile no.
>>>
>>> The volatile only works if the other thread reads the volatile and sees
>>> the written value.
>>>
>>> David
>>>
>>>  -----Original Message-----
>>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Nathan
>>> Reynolds
>>> *Sent:* Friday, 16 December 2011 8:20 AM
>>> *To:* Yuval Shavit
>>> *Cc:* concurrency-interest
>>> *Subject:* Re: [concurrency-interest] synchronized constructors
>>>
>>>  > it seems to me that if all of the constructor had been wrapped in a
>>> synchronized (this) {...}
>>>
>>> One could also add a final field in the class or have the constructor
>>> write to a volatile at the end of the method.  Both of these would add a
>>> happens-before.
>>>
>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>> 602.333.9091
>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>> On 12/15/2011 2:59 PM, Yuval Shavit wrote:
>>>
>>> Oh, I totally understand why it's a bad idea -- and I was about to reply
>>> to your reply to Ruslan, saying that my version was basically a poor man's
>>> double-checked lock. It's actually not even a real DCL, because that
>>> pattern at least tries to ensure that only one thread will instantiate the
>>> object, whereas my code will happily create multiple instances, each living
>>> in its own place on some CPU's cache. The hypothetical author of that code
>>> might even say that's intentional, because he wants to shard or something.
>>> Like I said, I fully understand it's a bad pattern. On the other hand, it
>>> seems to me that if all of the constructor had been wrapped in a
>>> synchronized (this) {...}, this broken sharding/DCL would work: either you
>>> instantiate the object yourself (and thus see it fully instantiated) or
>>> you'll hit a synchronized(this) block on toString(), which will establish
>>> that the constructor's synchronized(this) happened-before toString's.
>>>
>>> On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <
>>> nathan.reynolds at oracle.com> wrote:
>>>
>>>> This smells like double-checked locking.  Without a volatile or
>>>> synchronized, then this is definitely not going to work correctly and is
>>>> not thread-safe.  Look up double-checked locking on the web to see why it
>>>> is not thread-safe.
>>>>
>>>>
>>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>>> 602.333.9091
>>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>>
>>>>  On 12/15/2011 2:43 PM, Yuval Shavit wrote:
>>>>
>>>> So is the assumption that safe initial publication to other threads is
>>>> always required, and thread safety guarantees only kick in once that's been
>>>> done?
>>>>
>>>> I could imagine someone assigning their MyPoint to a non-volatile
>>>> static and creating a new instance if that static is null:
>>>>
>>>> public static MyPoint myPoint;
>>>>
>>>> MyPoint getAnyOldPoint() {
>>>>     if (myPoint == null)
>>>>         myPoint = new MyPoint();
>>>>     return myPoint;
>>>> }
>>>>
>>>> The person who writes that code (not me! :)  ) says, "I don't care
>>>> which MyPoint I get -- I don't care if it's the same one another thread
>>>> sees or not. All I care is that there is one, and that it's thread-safe.
>>>> And I got one (didn't have to instantiate it in this method), but it wasn't
>>>> thread safe: I saw "(0,-1)" even though no thread could have possibly set
>>>> such a state. I must have seen the initial state of a MyPoint, but it
>>>> wasn't thread safe."
>>>>
>>>> Now, I would love to tell them "sure it's thread safe, you're just
>>>> doing stupid things." But would they be wrong in telling me that no, my
>>>> class is only *partially* thread safe?
>>>>
>>>> Yuval
>>>>
>>>>
>>>>  On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <
>>>> nathan.reynolds at oracle.com> wrote:
>>>>
>>>>> How is the MyPoint instance going to become shared with another
>>>>> thread?  The thread calling the constructor has to execute some sort of
>>>>> synchronization to share the reference to the MyPoint instance.  The
>>>>> synchronization will cause a happens-before edge to be created.  For
>>>>> example, this code assigns a volatile field.  Writing to the volatile will
>>>>> ensure the proper values of x and y will be visible.
>>>>>
>>>>> public volatile MyPoint point = new MyPoint();
>>>>>
>>>>> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
>>>>> 602.333.9091
>>>>> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>>>
>>>>> On 12/15/2011 2:10 PM, Yuval Shavit wrote:
>>>>>
>>>>>  Hi all,
>>>>>
>>>>> This came up a few days ago on stackoverflow.com -- I forget the
>>>>> exact post, but someone referenced the JLS section concerning why
>>>>> constructors can't be synchronized:
>>>>>
>>>>> There is no practical need for a constructor to be synchronized,
>>>>>> because it would lock the object under construction, which is normally not
>>>>>> made available to other threads until all constructors for the object have
>>>>>> completed their work.
>>>>>
>>>>>
>>>>> If synchronization were only about mutual exclusion, this would make
>>>>> sense; but it also has memory visibility guarantees. For instance, say I
>>>>> have this really simple class:
>>>>>
>>>>>      public class MyPoint {
>>>>>         private int x;
>>>>>         private int y;
>>>>>
>>>>>         public MyPoint() {
>>>>>             x = -1; // init to (-1,-1) for some reason
>>>>>             y = -1;
>>>>>         }
>>>>>
>>>>>         public synchronized void setX(int x, int y) {
>>>>>             this.x = x;
>>>>>             this.y = y;
>>>>>         }
>>>>>
>>>>>         @Override
>>>>>         public synchronized String toString() {
>>>>>             return "(" + x + ", " + y + ")";
>>>>>         }
>>>>>     }
>>>>>
>>>>> There's a thread safety issue there, right? There was no
>>>>> synchronization during construction time, and thus no happens-before
>>>>> between ctor ending and toString() starting, so with reordering etc, you
>>>>> could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1,
>>>>> 0)".  You could get around this by calling setX from the constructor, but
>>>>> if setX is non-final, that has its own issues. You could also put the x and
>>>>> y initialization within a synchronized (this) { ... } -- but at that point,
>>>>> why not just allow the constructor to be synchronized?
>>>>>
>>>>> Thanks,
>>>>> Yuval
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/0ee2b194/attachment-0001.html>

From hans.boehm at hp.com  Thu Dec 15 17:58:52 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Thu, 15 Dec 2011 22:58:52 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEOGJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEOGJBAA.davidcholmes@aapt.net.au>
	<NFBBKALFDCPFIDBNKAPCKEOGJBAA.davidcholmes@aapt.net.au>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D53F4@G4W3299.americas.hpqcorp.net>

Declaring x and y final would solve the problem if you had safe publication, but racy communication of the MyPoint reference across threads, which I think is the scenario under discussion here.  But you wouldn't be able to implement setX.  Other than that, I don't see how final fields help.

Some of us (myself included IIRC)  actually argued during the Java memory model deliberations that synchronized constructors should be allowed.  Now I could go either way on it.  Client code shouldn't use races to communicate the reference, so it shouldn't matter.  But if you don't trust the clients of MyPoint, I think synchronized constructors could possibly be useful.  And that was much of the reasoning behind final field semantics.  Except at that point you're in uncharted waters anyway, because we don't believe the Java memory model anymore when it comes to racy code.

As David said, you can use synchronized blocks.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
Sent: Thursday, December 15, 2011 2:45 PM
To: Yuval Shavit
Cc: concurrency-interest
Subject: Re: [concurrency-interest] synchronized constructors

No I take that back. final field semantics are more subtle than that. I'm unsure if writing to a final would suffice.

David
-----Original Message-----
From: David Holmes [mailto:davidcholmes at aapt.net.au]
Sent: Friday, 16 December 2011 8:42 AM
To: Yuval Shavit
Cc: Nathan Reynolds; concurrency-interest
Subject: RE: [concurrency-interest] synchronized constructors
No - final fields have special semantics in the JMM. See "Final Fields" at

http://g.oswego.edu/dl/jmm/cookbook.html

David
-----Original Message-----
From: Yuval Shavit [mailto:yshavit at akiban.com]
Sent: Friday, 16 December 2011 8:36 AM
To: dholmes at ieee.org
Cc: Nathan Reynolds; concurrency-interest
Subject: Re: [concurrency-interest] synchronized constructors
Wouldn't the final field only establish that reads to *that field* see at least the state it was in at end of construction? That is, if you had two fields:

final int a;
int b;

And your constructor were:
    a = 1;
    b = a;

Then, in the absence of correct publication, couldn't another thread still see a = 1, b = 0?

On Thu, Dec 15, 2011 at 5:25 PM, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:
final field yes. Write to a volatile no.

The volatile only works if the other thread reads the volatile and sees the written value.

David
-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu>]On Behalf Of Nathan Reynolds
Sent: Friday, 16 December 2011 8:20 AM
To: Yuval Shavit
Cc: concurrency-interest
Subject: Re: [concurrency-interest] synchronized constructors
> it seems to me that if all of the constructor had been wrapped in a synchronized (this) {...}

One could also add a final field in the class or have the constructor write to a volatile at the end of the method.  Both of these would add a happens-before.
Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | Consulting Member of Technical Staff | 602.333.9091<tel:602.333.9091>
Oracle PSR Engineering<http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:59 PM, Yuval Shavit wrote:
Oh, I totally understand why it's a bad idea -- and I was about to reply to your reply to Ruslan, saying that my version was basically a poor man's double-checked lock. It's actually not even a real DCL, because that pattern at least tries to ensure that only one thread will instantiate the object, whereas my code will happily create multiple instances, each living in its own place on some CPU's cache. The hypothetical author of that code might even say that's intentional, because he wants to shard or something. Like I said, I fully understand it's a bad pattern. On the other hand, it seems to me that if all of the constructor had been wrapped in a synchronized (this) {...}, this broken sharding/DCL would work: either you instantiate the object yourself (and thus see it fully instantiated) or you'll hit a synchronized(this) block on toString(), which will establish that the constructor's synchronized(this) happened-before toString's.
On Thu, Dec 15, 2011 at 4:52 PM, Nathan Reynolds <nathan.reynolds at oracle.com<mailto:nathan.reynolds at oracle.com>> wrote:
This smells like double-checked locking.  Without a volatile or synchronized, then this is definitely not going to work correctly and is not thread-safe.  Look up double-checked locking on the web to see why it is not thread-safe.

Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | Consulting Member of Technical Staff | 602.333.9091<tel:602.333.9091>
Oracle PSR Engineering<http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:43 PM, Yuval Shavit wrote:
So is the assumption that safe initial publication to other threads is always required, and thread safety guarantees only kick in once that's been done?

I could imagine someone assigning their MyPoint to a non-volatile static and creating a new instance if that static is null:

public static MyPoint myPoint;

MyPoint getAnyOldPoint() {
    if (myPoint == null)
        myPoint = new MyPoint();
    return myPoint;
}

The person who writes that code (not me! :)  ) says, "I don't care which MyPoint I get -- I don't care if it's the same one another thread sees or not. All I care is that there is one, and that it's thread-safe. And I got one (didn't have to instantiate it in this method), but it wasn't thread safe: I saw "(0,-1)" even though no thread could have possibly set such a state. I must have seen the initial state of a MyPoint, but it wasn't thread safe."

Now, I would love to tell them "sure it's thread safe, you're just doing stupid things." But would they be wrong in telling me that no, my class is only *partially* thread safe?

Yuval


On Thu, Dec 15, 2011 at 4:30 PM, Nathan Reynolds <nathan.reynolds at oracle.com<mailto:nathan.reynolds at oracle.com>> wrote:
How is the MyPoint instance going to become shared with another thread?  The thread calling the constructor has to execute some sort of synchronization to share the reference to the MyPoint instance.  The synchronization will cause a happens-before edge to be created.  For example, this code assigns a volatile field.  Writing to the volatile will ensure the proper values of x and y will be visible.

public volatile MyPoint point = new MyPoint();
Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | Consulting Member of Technical Staff | 602.333.9091<tel:602.333.9091>
Oracle PSR Engineering<http://psr.us.oracle.com/> | Server Technology

On 12/15/2011 2:10 PM, Yuval Shavit wrote:
Hi all,

This came up a few days ago on stackoverflow.com<http://stackoverflow.com> -- I forget the exact post, but someone referenced the JLS section concerning why constructors can't be synchronized:

There is no practical need for a constructor to be synchronized, because it would lock the object under construction, which is normally not made available to other threads until all constructors for the object have completed their work.

If synchronization were only about mutual exclusion, this would make sense; but it also has memory visibility guarantees. For instance, say I have this really simple class:

    public class MyPoint {
        private int x;
        private int y;

        public MyPoint() {
            x = -1; // init to (-1,-1) for some reason
            y = -1;
        }

        public synchronized void setX(int x, int y) {
            this.x = x;
            this.y = y;
        }

        @Override
        public synchronized String toString() {
            return "(" + x + ", " + y + ")";
        }
    }

There's a thread safety issue there, right? There was no synchronization during construction time, and thus no happens-before between ctor ending and toString() starting, so with reordering etc, you could observe the initial state as "(0, 0)", "(-1, 0)", "(-1, -1)" or "(-1, 0)".  You could get around this by calling setX from the constructor, but if setX is non-final, that has its own issues. You could also put the x and y initialization within a synchronized (this) { ... } -- but at that point, why not just allow the constructor to be synchronized?

Thanks,
Yuval



_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/bc4e24e3/attachment-0001.html>

From vitalyd at gmail.com  Thu Dec 15 18:20:07 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 18:20:07 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <-1442414943.0.13443ee39d2.c@fluent.io>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
Message-ID: <CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>

I think I misinterpreted the question.  Yes if you publish in the middle of
construction then anything goes - final won't help.  If the question is
about unsafe publication after the constructor, then I think in practice it
works because the compiler will issue one storestore after the constructor
and before publishing (regardless of order of final field store in the
constructor ).  In that case, if another thread reads a non-null instance
it should see all writes done inside the constructor.  Presumably though, a
compiler could only issue a storestore after the final field, move the
publishing assignment ahead of the non-final field write, and then a
non-null read on the other thread doesn't guarantee anything about the
non-final field.  I don't think JMM precludes this scenario.

Sorry for the dense text I'm on my phone :).
On Dec 15, 2011 5:53 PM, <dhanji at gmail.com> wrote:

> From a cursory glance, it could happen if the b's value (=a) is sitting in
> a cache line in the CPU for instance. I don't think there is any guarantee
> that b is published correctly. The semantics depend on the publication of
> the container object and participating threads.
>
> I've seen similar things happen in the 64-bit JVM.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/4779c50d/attachment.html>

From yshavit at akiban.com  Thu Dec 15 18:53:53 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Thu, 15 Dec 2011 18:53:53 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
	<CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
Message-ID: <CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>

>From my cursory reading of the JLS and the cookbook that David linked to, I
think you're right. The JMM would allow such a reordering, but it sounds
like you'd need to actively work on it if you wanted the compiler to honor
final field semantics but allow the reordering that would result in the 0
being seen.

What if you just had a final field that you wrote but didn't use?

    final int a;
    int b;

    MyConstructor() {
        a = 1;
        b = 2;
    }

I believe this was the original suggestion to replace the
synchronized(this) in the ctor (Natha's email that starts, "One could also
add a final field in the class..."). Would that more readily exploit seeing
b == 0? And would it be different if the assignments had happened in
reverse order (b = 2; a = 1) ?

On Thu, Dec 15, 2011 at 6:20 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> I think I misinterpreted the question.  Yes if you publish in the middle
> of construction then anything goes - final won't help.  If the question is
> about unsafe publication after the constructor, then I think in practice it
> works because the compiler will issue one storestore after the constructor
> and before publishing (regardless of order of final field store in the
> constructor ).  In that case, if another thread reads a non-null instance
> it should see all writes done inside the constructor.  Presumably though, a
> compiler could only issue a storestore after the final field, move the
> publishing assignment ahead of the non-final field write, and then a
> non-null read on the other thread doesn't guarantee anything about the
> non-final field.  I don't think JMM precludes this scenario.
>
> Sorry for the dense text I'm on my phone :).
> On Dec 15, 2011 5:53 PM, <dhanji at gmail.com> wrote:
>
>> From a cursory glance, it could happen if the b's value (=a) is sitting
>> in a cache line in the CPU for instance. I don't think there is any
>> guarantee that b is published correctly. The semantics depend on the
>> publication of the container object and participating threads.
>>
>> I've seen similar things happen in the 64-bit JVM.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/f2e6795a/attachment.html>

From vitalyd at gmail.com  Thu Dec 15 19:13:35 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 19:13:35 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
	<CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
	<CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>
Message-ID: <CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>

I think in practice having at least one final field assignment in the
constructor, irrespective of order, will cause the storestore to be emitted
after the constructor and before publishing assignment (at least in
hotspot,  to my knowledge).  Relying on this though is probably not
prudent.  If you realize that a constructor is just a method (albeit
special) which can get inlined then you can see how operations can be
reordered because placement of final field assignment is more obvious
(people tend to think of constructors as some "atomic" block of code, which
isn't right IMHO).

However, I find it hard to believe that even though this behavior is
implementation specific that Oracle would change this such that order of
final field assignment matters - this could break massive amounts of code,
especially as we're getting more and more concurrency in commodity hardware.

Outside of a purely "academic" discussion here, the main point is avoid
data racy code :).
On Dec 15, 2011 6:54 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:

> From my cursory reading of the JLS and the cookbook that David linked to,
> I think you're right. The JMM would allow such a reordering, but it sounds
> like you'd need to actively work on it if you wanted the compiler to honor
> final field semantics but allow the reordering that would result in the 0
> being seen.
>
> What if you just had a final field that you wrote but didn't use?
>
>     final int a;
>     int b;
>
>     MyConstructor() {
>         a = 1;
>         b = 2;
>     }
>
> I believe this was the original suggestion to replace the
> synchronized(this) in the ctor (Natha's email that starts, "One could also
> add a final field in the class..."). Would that more readily exploit seeing
> b == 0? And would it be different if the assignments had happened in
> reverse order (b = 2; a = 1) ?
>
> On Thu, Dec 15, 2011 at 6:20 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> I think I misinterpreted the question.  Yes if you publish in the middle
>> of construction then anything goes - final won't help.  If the question is
>> about unsafe publication after the constructor, then I think in practice it
>> works because the compiler will issue one storestore after the constructor
>> and before publishing (regardless of order of final field store in the
>> constructor ).  In that case, if another thread reads a non-null instance
>> it should see all writes done inside the constructor.  Presumably though, a
>> compiler could only issue a storestore after the final field, move the
>> publishing assignment ahead of the non-final field write, and then a
>> non-null read on the other thread doesn't guarantee anything about the
>> non-final field.  I don't think JMM precludes this scenario.
>>
>> Sorry for the dense text I'm on my phone :).
>> On Dec 15, 2011 5:53 PM, <dhanji at gmail.com> wrote:
>>
>>> From a cursory glance, it could happen if the b's value (=a) is sitting
>>> in a cache line in the CPU for instance. I don't think there is any
>>> guarantee that b is published correctly. The semantics depend on the
>>> publication of the container object and participating threads.
>>>
>>> I've seen similar things happen in the 64-bit JVM.
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/49dead5a/attachment.html>

From forax at univ-mlv.fr  Thu Dec 15 19:43:57 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Fri, 16 Dec 2011 01:43:57 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
	<CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
	<CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>
	<CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>
Message-ID: <4EEA944D.3000100@univ-mlv.fr>

On 12/16/2011 01:13 AM, Vitaly Davidovich wrote:
>
> I think in practice having at least one final field assignment in the 
> constructor, irrespective of order, will cause the storestore to be 
> emitted after the constructor and before publishing assignment (at 
> least in hotspot,  to my knowledge).  Relying on this though is 
> probably not prudent.  If you realize that a constructor is just a 
> method (albeit special) which can get inlined then you can see how 
> operations can be reordered because placement of final field 
> assignment is more obvious (people tend to think of constructors as 
> some "atomic" block of code, which isn't right IMHO).
>
> However, I find it hard to believe that even though this behavior is 
> implementation specific that Oracle would change this such that order 
> of final field assignment matters - this could break massive amounts 
> of code, especially as we're getting more and more concurrency in 
> commodity hardware.
>
> Outside of a purely "academic" discussion here, the main point is 
> avoid data racy code :).
>

In practice programs without final/synchronized in the constructor works
because on x86/x64 and modern sparc a storestore is a no-op,
so all codes works until you try to run them on arm ...

R?mi

> On Dec 15, 2011 6:54 PM, "Yuval Shavit" <yshavit at akiban.com 
> <mailto:yshavit at akiban.com>> wrote:
>
>     From my cursory reading of the JLS and the cookbook that David
>     linked to, I think you're right. The JMM would allow such a
>     reordering, but it sounds like you'd need to actively work on it
>     if you wanted the compiler to honor final field semantics but
>     allow the reordering that would result in the 0 being seen.
>
>     What if you just had a final field that you wrote but didn't use?
>
>         final int a;
>         int b;
>
>         MyConstructor() {
>             a = 1;
>             b = 2;
>         }
>
>     I believe this was the original suggestion to replace the
>     synchronized(this) in the ctor (Natha's email that starts, "One
>     could also add a final field in the class..."). Would that more
>     readily exploit seeing b == 0? And would it be different if the
>     assignments had happened in reverse order (b = 2; a = 1) ?
>
>     On Thu, Dec 15, 2011 at 6:20 PM, Vitaly Davidovich
>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>
>         I think I misinterpreted the question.  Yes if you publish in
>         the middle of construction then anything goes - final won't
>         help.  If the question is about unsafe publication after the
>         constructor, then I think in practice it works because the
>         compiler will issue one storestore after the constructor and
>         before publishing (regardless of order of final field store in
>         the constructor ).  In that case, if another thread reads a
>         non-null instance it should see all writes done inside the
>         constructor.  Presumably though, a compiler could only issue a
>         storestore after the final field, move the publishing
>         assignment ahead of the non-final field write, and then a
>         non-null read on the other thread doesn't guarantee anything
>         about the non-final field.  I don't think JMM precludes this
>         scenario.
>
>         Sorry for the dense text I'm on my phone :).
>
>         On Dec 15, 2011 5:53 PM, <dhanji at gmail.com
>         <mailto:dhanji at gmail.com>> wrote:
>
>             From a cursory glance, it could happen if the b's value
>             (=a) is sitting in a cache line in the CPU for instance. I
>             don't think there is any guarantee that b is published
>             correctly. The semantics depend on the publication of the
>             container object and participating threads.
>
>             I've seen similar things happen in the 64-bit JVM.
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/bc70063d/attachment-0001.html>

From vitalyd at gmail.com  Thu Dec 15 19:50:41 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 15 Dec 2011 19:50:41 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEA944D.3000100@univ-mlv.fr>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
	<CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
	<CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>
	<CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>
	<4EEA944D.3000100@univ-mlv.fr>
Message-ID: <CAHjP37Ff0jSufKc8XBZJpY1mYg3TDUsDL-ktnKjhG9_OfXMj=g@mail.gmail.com>

You're assuming compiler instruction scheduling/optimizations doesn't
shuffle things around.
On Dec 15, 2011 7:48 PM, "R?mi Forax" <forax at univ-mlv.fr> wrote:

>  On 12/16/2011 01:13 AM, Vitaly Davidovich wrote:
>
> I think in practice having at least one final field assignment in the
> constructor, irrespective of order, will cause the storestore to be emitted
> after the constructor and before publishing assignment (at least in
> hotspot,  to my knowledge).  Relying on this though is probably not
> prudent.  If you realize that a constructor is just a method (albeit
> special) which can get inlined then you can see how operations can be
> reordered because placement of final field assignment is more obvious
> (people tend to think of constructors as some "atomic" block of code, which
> isn't right IMHO).
>
> However, I find it hard to believe that even though this behavior is
> implementation specific that Oracle would change this such that order of
> final field assignment matters - this could break massive amounts of code,
> especially as we're getting more and more concurrency in commodity hardware.
>
> Outside of a purely "academic" discussion here, the main point is avoid
> data racy code :).
>
>
> In practice programs without final/synchronized in the constructor works
> because on x86/x64 and modern sparc a storestore is a no-op,
> so all codes works until you try to run them on arm ...
>
> R?mi
>
>  On Dec 15, 2011 6:54 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>
>> From my cursory reading of the JLS and the cookbook that David linked to,
>> I think you're right. The JMM would allow such a reordering, but it sounds
>> like you'd need to actively work on it if you wanted the compiler to honor
>> final field semantics but allow the reordering that would result in the 0
>> being seen.
>>
>>  What if you just had a final field that you wrote but didn't use?
>>
>>      final int a;
>>     int b;
>>
>>      MyConstructor() {
>>         a = 1;
>>         b = 2;
>>     }
>>
>> I believe this was the original suggestion to replace the
>> synchronized(this) in the ctor (Natha's email that starts, "One could also
>> add a final field in the class..."). Would that more readily exploit seeing
>> b == 0? And would it be different if the assignments had happened in
>> reverse order (b = 2; a = 1) ?
>>
>> On Thu, Dec 15, 2011 at 6:20 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>
>>> I think I misinterpreted the question.  Yes if you publish in the middle
>>> of construction then anything goes - final won't help.  If the question is
>>> about unsafe publication after the constructor, then I think in practice it
>>> works because the compiler will issue one storestore after the constructor
>>> and before publishing (regardless of order of final field store in the
>>> constructor ).  In that case, if another thread reads a non-null instance
>>> it should see all writes done inside the constructor.  Presumably though, a
>>> compiler could only issue a storestore after the final field, move the
>>> publishing assignment ahead of the non-final field write, and then a
>>> non-null read on the other thread doesn't guarantee anything about the
>>> non-final field.  I don't think JMM precludes this scenario.
>>>
>>> Sorry for the dense text I'm on my phone :).
>>>  On Dec 15, 2011 5:53 PM, <dhanji at gmail.com> wrote:
>>>
>>>> From a cursory glance, it could happen if the b's value (=a) is sitting
>>>> in a cache line in the CPU for instance. I don't think there is any
>>>> guarantee that b is published correctly. The semantics depend on the
>>>> publication of the container object and participating threads.
>>>>
>>>> I've seen similar things happen in the 64-bit JVM.
>>>>
>>>
>>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111215/f8c19663/attachment.html>

From cheremin at gmail.com  Fri Dec 16 01:43:46 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Fri, 16 Dec 2011 09:43:46 +0300
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>
References: <4EEA729B.8010705@oracle.com>
	<NFBBKALFDCPFIDBNKAPCCEOFJBAA.davidcholmes@aapt.net.au>
	<CAC2Zdp16Y_4i73y-3i+6ABmbH9m-B4Fo78z-M+nMgVQhjXsRsw@mail.gmail.com>
	<-1442414943.0.13443ee39d2.c@fluent.io>
	<CAHjP37FT5=bqCYdFRwZTuBv4cGC3pt0CjRCkFObL=_bd=e0X_Q@mail.gmail.com>
	<CAC2Zdp3isyxSQR7HRuBXd3s8=mhwwSsTEV3gvvuDCKcgSW58gQ@mail.gmail.com>
	<CAHjP37G7E-GpG26rtgi7-vXdnaAzQjtb8X0iC=F10yWrQdcnsw@mail.gmail.com>
Message-ID: <CAOwENiL0mO9C4jAgrUpP_MyYiNyQrm4LMcRgNKgjwLCFeW9d6w@mail.gmail.com>

In practice -- yes, it seems to be true. But formally JMM does not
guarantee anything for non-final fields in this context. As far, as I
understand this part of spec, bulletproof guaratee for visibility even
in case data race based publication is done only for final field
itself, of something, reachable from it. I think, it is not a good
thing to piggyback on specific implementation of final fields
semantic, which _may_ use "global" storestore, but not have to.

2011/12/16 Vitaly Davidovich <vitalyd at gmail.com>:
> I think in practice having at least one final field assignment in the
> constructor, irrespective of order, will cause the storestore to be emitted
> after the constructor and before publishing assignment (at least in
> hotspot,? to my knowledge).? Relying on this though is probably not
> prudent.? If you realize that a constructor is just a method (albeit
> special) which can get inlined then you can see how operations can be
> reordered because placement of final field assignment is more obvious
> (people tend to think of constructors as some "atomic" block of code, which
> isn't right IMHO).
>
> However, I find it hard to believe that even though this behavior is
> implementation specific that Oracle would change this such that order of
> final field assignment matters - this could break massive amounts of code,
> especially as we're getting more and more concurrency in commodity hardware.
>
> Outside of a purely "academic" discussion here, the main point is avoid data
> racy code :).
>
> On Dec 15, 2011 6:54 PM, "Yuval Shavit" <yshavit at akiban.com> wrote:
>>
>> From my cursory reading of the JLS and the cookbook that David linked to,
>> I think you're right. The JMM would allow such a reordering, but it sounds
>> like you'd need to actively work on it if you wanted the compiler to honor
>> final field semantics but allow the reordering that would result in the 0
>> being seen.
>>
>> What if you just had a final field that you wrote but didn't use?
>>
>> ? ? final int a;
>> ? ? int b;
>>
>> ? ? MyConstructor() {
>> ? ? ? ? a = 1;
>> ? ? ? ? b = 2;
>> ? ? }
>>
>> I believe this was the original suggestion to replace the
>> synchronized(this) in the ctor (Natha's email that starts, "One could also
>> add a final field in the class..."). Would that more readily exploit seeing
>> b == 0? And would it be different if the assignments had happened in reverse
>> order (b = 2; a = 1) ?
>>
>> On Thu, Dec 15, 2011 at 6:20 PM, Vitaly Davidovich <vitalyd at gmail.com>
>> wrote:
>>>
>>> I think I misinterpreted the question.? Yes if you publish in the middle
>>> of construction then anything goes - final won't help.? If the question is
>>> about unsafe publication after the constructor, then I think in practice it
>>> works because the compiler will issue one storestore after the constructor
>>> and before publishing (regardless of order of final field store in the
>>> constructor ).? In that case, if another thread reads a non-null instance it
>>> should see all writes done inside the constructor.? Presumably though, a
>>> compiler could only issue a storestore after the final field, move the
>>> publishing assignment ahead of the non-final field write, and then a
>>> non-null read on the other thread doesn't guarantee anything about the
>>> non-final field.? I don't think JMM precludes this scenario.
>>>
>>> Sorry for the dense text I'm on my phone :).
>>>
>>> On Dec 15, 2011 5:53 PM, <dhanji at gmail.com> wrote:
>>>>
>>>> From a cursory glance, it could happen if the b's value (=a) is sitting
>>>> in a cache line in the CPU for instance. I don't think there is any
>>>> guarantee that b is published correctly. The semantics depend on the
>>>> publication of the container object and participating threads.
>>>>
>>>> I've seen similar things happen in the 64-bit JVM.
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From zhong.j.yu at gmail.com  Fri Dec 16 02:58:50 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 16 Dec 2011 01:58:50 -0600
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
Message-ID: <CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>

I'm totally sympathetic to this design goal - if an object claims to
be thread safe, it should survive unsafe publication without problems.
I believe all java.util.concurrent classes have this property.

However, `synchronized` constructor cannot help to reach that goal.

    foo = new Foo();

is roughly equivalent to

    [A]    tmp = allocate memory space for sizeof(Foo)
    [B]    zero the space. (this may occur before [A])
    [1]    tmp.Foo(); // as if the constructor is an instance method
    [2]    foo = tmp;

[2] can be reordered before [1], so other threads may observe
blank/partial state through `foo` reference. This reordering is
allowed even if `Foo()` is synchronized.

This problem affects some "thread safe" classes like java.util.Vector.
If a Vector object is unsafely published, program can crash
unexpectedly. I bet that's a huge surprise to most Java programmers.

But I don't think the "unenlightened mass" are to blame. We have this
strong intuition that an object comes to existence only after
construction. Nobody outside of construction should observe a
partially constructed object (unless `this` is leaked during
construction).

If JMM has this simple "whole-birth" guarantee, many man-hours of
anguish will be saved. You can innocently do a double checked locking,
and nobody is going to yell at your naivety.

Unfortunately JMM doesn't have this guarantee. Allegedly such
guarantee carries a performance penalty. The only work around is
through `final` fields. Neither `synchronized` nor `volatile` is
useful for this purpose (many people are mistaken on this point; it is
due to their whole-birth intuition, subconsciously adding a
synchronization order from end of constructor to begin of instance
methods)

We are encouraged to use `final` fields whenever we can. One crucial
reason is for the memory effect guarantee. However, using `final`
fields will incur the same performance penalty of whole-birth
guarantee. We have a great contradiction here. Either `final` is not
cheap, so we should avoid `final` fields if we can; or `final` is
cheap, so whole-birth guarantee can be established cheaply, yielding
`final` unnecessary.

JMM does guarantee that [2] cannot be reordered before [B], otherwise
other threads can observe garbage state. Let's call this the "blank"
guarantee. It's also a mystery to me why whole-birth guarantee can be
fundamentally more expensive than blank guarantee.

Note that not everybody promotes the use of `final` though. We can
sense how reserved David Holmes is through his words: " #Sometime# a
class needs to add #some# protection against unsafe-publication that
might violate #important# semantic guarantees of the object"

(We had a similar discussion in a September thread titled "Interesting
anti-pattern with volatile"; however I cannot find it on the mailing
list archive, so no link.)

Zhong Yu

P.S. a "fix" to Vector's vulnerability to unsafe publication

class Vector

    final Params ctorParams;

    Vector(params)
        ctorParams = new Params(params);

    boolean initDone;

    void ensureInit()
        if(!initDone)
            initialize this with ctorParams ...
            initDone = true;

    synchronized
    public Foo anyOtherMethod(Bar)
        ensureInit();
        actual work...

Of course, this solution sucks. The role of constructor is severely weakened.

From rk at rkuhn.info  Fri Dec 16 04:48:46 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 16 Dec 2011 10:48:46 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
Message-ID: <5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>

As I was recently made aware: the rules for write reordering are not as weak as you think.

http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#24432

Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a ?lock? operation. This means that a synchronized {} in the constructor solves the issue.

Regards,

Roland

On Dec 16, 2011, at 08:58 , Zhong Yu wrote:

> I'm totally sympathetic to this design goal - if an object claims to
> be thread safe, it should survive unsafe publication without problems.
> I believe all java.util.concurrent classes have this property.
> 
> However, `synchronized` constructor cannot help to reach that goal.
> 
>    foo = new Foo();
> 
> is roughly equivalent to
> 
>    [A]    tmp = allocate memory space for sizeof(Foo)
>    [B]    zero the space. (this may occur before [A])
>    [1]    tmp.Foo(); // as if the constructor is an instance method
>    [2]    foo = tmp;
> 
> [2] can be reordered before [1], so other threads may observe
> blank/partial state through `foo` reference. This reordering is
> allowed even if `Foo()` is synchronized.
> 
> This problem affects some "thread safe" classes like java.util.Vector.
> If a Vector object is unsafely published, program can crash
> unexpectedly. I bet that's a huge surprise to most Java programmers.
> 
> But I don't think the "unenlightened mass" are to blame. We have this
> strong intuition that an object comes to existence only after
> construction. Nobody outside of construction should observe a
> partially constructed object (unless `this` is leaked during
> construction).
> 
> If JMM has this simple "whole-birth" guarantee, many man-hours of
> anguish will be saved. You can innocently do a double checked locking,
> and nobody is going to yell at your naivety.
> 
> Unfortunately JMM doesn't have this guarantee. Allegedly such
> guarantee carries a performance penalty. The only work around is
> through `final` fields. Neither `synchronized` nor `volatile` is
> useful for this purpose (many people are mistaken on this point; it is
> due to their whole-birth intuition, subconsciously adding a
> synchronization order from end of constructor to begin of instance
> methods)
> 
> We are encouraged to use `final` fields whenever we can. One crucial
> reason is for the memory effect guarantee. However, using `final`
> fields will incur the same performance penalty of whole-birth
> guarantee. We have a great contradiction here. Either `final` is not
> cheap, so we should avoid `final` fields if we can; or `final` is
> cheap, so whole-birth guarantee can be established cheaply, yielding
> `final` unnecessary.
> 
> JMM does guarantee that [2] cannot be reordered before [B], otherwise
> other threads can observe garbage state. Let's call this the "blank"
> guarantee. It's also a mystery to me why whole-birth guarantee can be
> fundamentally more expensive than blank guarantee.
> 
> Note that not everybody promotes the use of `final` though. We can
> sense how reserved David Holmes is through his words: " #Sometime# a
> class needs to add #some# protection against unsafe-publication that
> might violate #important# semantic guarantees of the object"
> 
> (We had a similar discussion in a September thread titled "Interesting
> anti-pattern with volatile"; however I cannot find it on the mailing
> list archive, so no link.)
> 
> Zhong Yu
> 
> P.S. a "fix" to Vector's vulnerability to unsafe publication
> 
> class Vector
> 
>    final Params ctorParams;
> 
>    Vector(params)
>        ctorParams = new Params(params);
> 
>    boolean initDone;
> 
>    void ensureInit()
>        if(!initDone)
>            initialize this with ctorParams ...
>            initDone = true;
> 
>    synchronized
>    public Foo anyOtherMethod(Bar)
>        ensureInit();
>        actual work...
> 
> Of course, this solution sucks. The role of constructor is severely weakened.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038



From Joe.Kearney at gsacapital.com  Fri Dec 16 04:59:11 2011
From: Joe.Kearney at gsacapital.com (Kearney, Joe)
Date: Fri, 16 Dec 2011 09:59:11 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
Message-ID: <9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>

How much of that locking is allowed to be elided away?

If you call synchronized(this) {} in a constructor, I would argue that provably no other thread can acquire the lock yet. So can the locking be compiled away, even though the induced fence would need to stay?

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Roland Kuhn
Sent: 16 December 2011 09:49
To: Zhong Yu
Cc: concurrency-interest
Subject: Re: [concurrency-interest] synchronized constructors

As I was recently made aware: the rules for write reordering are not as weak as you think.

http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#24432

Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a "lock" operation. This means that a synchronized {} in the constructor solves the issue.

Regards,

Roland

On Dec 16, 2011, at 08:58 , Zhong Yu wrote:

> I'm totally sympathetic to this design goal - if an object claims to 
> be thread safe, it should survive unsafe publication without problems.
> I believe all java.util.concurrent classes have this property.
> 
> However, `synchronized` constructor cannot help to reach that goal.
> 
>    foo = new Foo();
> 
> is roughly equivalent to
> 
>    [A]    tmp = allocate memory space for sizeof(Foo)
>    [B]    zero the space. (this may occur before [A])
>    [1]    tmp.Foo(); // as if the constructor is an instance method
>    [2]    foo = tmp;
> 
> [2] can be reordered before [1], so other threads may observe 
> blank/partial state through `foo` reference. This reordering is 
> allowed even if `Foo()` is synchronized.
> 
> This problem affects some "thread safe" classes like java.util.Vector.
> If a Vector object is unsafely published, program can crash 
> unexpectedly. I bet that's a huge surprise to most Java programmers.
> 
> But I don't think the "unenlightened mass" are to blame. We have this 
> strong intuition that an object comes to existence only after 
> construction. Nobody outside of construction should observe a 
> partially constructed object (unless `this` is leaked during 
> construction).
> 
> If JMM has this simple "whole-birth" guarantee, many man-hours of 
> anguish will be saved. You can innocently do a double checked locking, 
> and nobody is going to yell at your naivety.
> 
> Unfortunately JMM doesn't have this guarantee. Allegedly such 
> guarantee carries a performance penalty. The only work around is 
> through `final` fields. Neither `synchronized` nor `volatile` is 
> useful for this purpose (many people are mistaken on this point; it is 
> due to their whole-birth intuition, subconsciously adding a 
> synchronization order from end of constructor to begin of instance
> methods)
> 
> We are encouraged to use `final` fields whenever we can. One crucial 
> reason is for the memory effect guarantee. However, using `final` 
> fields will incur the same performance penalty of whole-birth 
> guarantee. We have a great contradiction here. Either `final` is not 
> cheap, so we should avoid `final` fields if we can; or `final` is 
> cheap, so whole-birth guarantee can be established cheaply, yielding 
> `final` unnecessary.
> 
> JMM does guarantee that [2] cannot be reordered before [B], otherwise 
> other threads can observe garbage state. Let's call this the "blank"
> guarantee. It's also a mystery to me why whole-birth guarantee can be 
> fundamentally more expensive than blank guarantee.
> 
> Note that not everybody promotes the use of `final` though. We can 
> sense how reserved David Holmes is through his words: " #Sometime# a 
> class needs to add #some# protection against unsafe-publication that 
> might violate #important# semantic guarantees of the object"
> 
> (We had a similar discussion in a September thread titled "Interesting 
> anti-pattern with volatile"; however I cannot find it on the mailing 
> list archive, so no link.)
> 
> Zhong Yu
> 
> P.S. a "fix" to Vector's vulnerability to unsafe publication
> 
> class Vector
> 
>    final Params ctorParams;
> 
>    Vector(params)
>        ctorParams = new Params(params);
> 
>    boolean initDone;
> 
>    void ensureInit()
>        if(!initDone)
>            initialize this with ctorParams ...
>            initDone = true;
> 
>    synchronized
>    public Foo anyOtherMethod(Bar)
>        ensureInit();
>        actual work...
> 
> Of course, this solution sucks. The role of constructor is severely weakened.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From cheremin at gmail.com  Fri Dec 16 05:00:13 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Fri, 16 Dec 2011 14:00:13 +0400
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
Message-ID: <CAOwENi+1Ajuxcbun4WXitjDqU+NC0JMkhhCpX9TLFtAX7FHeYw@mail.gmail.com>

> so other threads may observe blank/partial state through `foo` reference. This reordering is
> allowed even if `Foo()` is synchronized.

It's a very good explanation. Only to note -- if constructor is
synchronized, as all other accessors, "partial" state can't be seen.
But, sure, blank state -- can be.

> JMM does guarantee that [2] cannot be reordered before [B], otherwise
> other threads can observe garbage state. Let's call this the "blank"
> guarantee. It's also a mystery to me why whole-birth guarantee can be
> fundamentally more expensive than blank guarantee.

As far, as I understand, blank guarantee is cheeper since it can be
implemented in batch. AFAIK, it is GC who blanking reclaimed memory,
so it can be done megabytes at once, and publishing reclaimed and
zeroed memory also can be done at one shot. So, the cost is greatly
amortized. But store-store barrier at the end of constructor, which
seems to be required for your whole-birth guarantee can't  be
amortized.

From rk at rkuhn.info  Fri Dec 16 05:18:12 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 16 Dec 2011 11:18:12 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
Message-ID: <08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>

I don?t see anything in chapter 8 which allows synchronized to be elided at all. Viewed from a single thread, the main guarantees of synchronized are ?fresh reads after lock? and ?writes flushed before unlock?, and these cannot be elided. If the VM sees that nobody else is ever locking on the same object, I would assume that the ?mutual exclusion? part may be elided, but not the memory effects.

Would someone more knowledgeable with VM implementations please comment?

On Dec 16, 2011, at 10:59 , Kearney, Joe wrote:

> How much of that locking is allowed to be elided away?
> 
> If you call synchronized(this) {} in a constructor, I would argue that provably no other thread can acquire the lock yet. So can the locking be compiled away, even though the induced fence would need to stay?
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Roland Kuhn
> Sent: 16 December 2011 09:49
> To: Zhong Yu
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] synchronized constructors
> 
> As I was recently made aware: the rules for write reordering are not as weak as you think.
> 
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#24432
> 
> Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a "lock" operation. This means that a synchronized {} in the constructor solves the issue.
> 
> Regards,
> 
> Roland
> 
> On Dec 16, 2011, at 08:58 , Zhong Yu wrote:
> 
>> I'm totally sympathetic to this design goal - if an object claims to 
>> be thread safe, it should survive unsafe publication without problems.
>> I believe all java.util.concurrent classes have this property.
>> 
>> However, `synchronized` constructor cannot help to reach that goal.
>> 
>>   foo = new Foo();
>> 
>> is roughly equivalent to
>> 
>>   [A]    tmp = allocate memory space for sizeof(Foo)
>>   [B]    zero the space. (this may occur before [A])
>>   [1]    tmp.Foo(); // as if the constructor is an instance method
>>   [2]    foo = tmp;
>> 
>> [2] can be reordered before [1], so other threads may observe 
>> blank/partial state through `foo` reference. This reordering is 
>> allowed even if `Foo()` is synchronized.
>> 
>> This problem affects some "thread safe" classes like java.util.Vector.
>> If a Vector object is unsafely published, program can crash 
>> unexpectedly. I bet that's a huge surprise to most Java programmers.
>> 
>> But I don't think the "unenlightened mass" are to blame. We have this 
>> strong intuition that an object comes to existence only after 
>> construction. Nobody outside of construction should observe a 
>> partially constructed object (unless `this` is leaked during 
>> construction).
>> 
>> If JMM has this simple "whole-birth" guarantee, many man-hours of 
>> anguish will be saved. You can innocently do a double checked locking, 
>> and nobody is going to yell at your naivety.
>> 
>> Unfortunately JMM doesn't have this guarantee. Allegedly such 
>> guarantee carries a performance penalty. The only work around is 
>> through `final` fields. Neither `synchronized` nor `volatile` is 
>> useful for this purpose (many people are mistaken on this point; it is 
>> due to their whole-birth intuition, subconsciously adding a 
>> synchronization order from end of constructor to begin of instance
>> methods)
>> 
>> We are encouraged to use `final` fields whenever we can. One crucial 
>> reason is for the memory effect guarantee. However, using `final` 
>> fields will incur the same performance penalty of whole-birth 
>> guarantee. We have a great contradiction here. Either `final` is not 
>> cheap, so we should avoid `final` fields if we can; or `final` is 
>> cheap, so whole-birth guarantee can be established cheaply, yielding 
>> `final` unnecessary.
>> 
>> JMM does guarantee that [2] cannot be reordered before [B], otherwise 
>> other threads can observe garbage state. Let's call this the "blank"
>> guarantee. It's also a mystery to me why whole-birth guarantee can be 
>> fundamentally more expensive than blank guarantee.
>> 
>> Note that not everybody promotes the use of `final` though. We can 
>> sense how reserved David Holmes is through his words: " #Sometime# a 
>> class needs to add #some# protection against unsafe-publication that 
>> might violate #important# semantic guarantees of the object"
>> 
>> (We had a similar discussion in a September thread titled "Interesting 
>> anti-pattern with volatile"; however I cannot find it on the mailing 
>> list archive, so no link.)
>> 
>> Zhong Yu
>> 
>> P.S. a "fix" to Vector's vulnerability to unsafe publication
>> 
>> class Vector
>> 
>>   final Params ctorParams;
>> 
>>   Vector(params)
>>       ctorParams = new Params(params);
>> 
>>   boolean initDone;
>> 
>>   void ensureInit()
>>       if(!initDone)
>>           initialize this with ctorParams ...
>>           initDone = true;
>> 
>>   synchronized
>>   public Foo anyOtherMethod(Bar)
>>       ensureInit();
>>       actual work...
>> 
>> Of course, this solution sucks. The role of constructor is severely weakened.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra



From rk at rkuhn.info  Fri Dec 16 05:34:39 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 16 Dec 2011 11:34:39 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
Message-ID: <1FA87377-98BB-4703-9DAD-EA164E3E29A2@rkuhn.info>


On Dec 16, 2011, at 10:59 , Kearney, Joe wrote:

> How much of that locking is allowed to be elided away?
> 
> If you call synchronized(this) {} in a constructor, I would argue that


> provably no other thread can acquire the lock yet

This is not true: the constructor might write ?this? to a static volatile field, thereby correctly publishing it to another thread, which might want to acquire the same lock and would have to block. And since the JVM is Turing complete, it is impossible to prove in the general case that this cannot happen (there may be very specific constructors which allow this, though, and you could argue that all of the IDE auto-generated ones fall into this category).

> . So can the locking be compiled away, even though the induced fence would need to stay?
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Roland Kuhn
> Sent: 16 December 2011 09:49
> To: Zhong Yu
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] synchronized constructors
> 
> As I was recently made aware: the rules for write reordering are not as weak as you think.
> 
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#24432
> 
> Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a "lock" operation. This means that a synchronized {} in the constructor solves the issue.
> 
> Regards,
> 
> Roland
> 
> On Dec 16, 2011, at 08:58 , Zhong Yu wrote:
> 
>> I'm totally sympathetic to this design goal - if an object claims to 
>> be thread safe, it should survive unsafe publication without problems.
>> I believe all java.util.concurrent classes have this property.
>> 
>> However, `synchronized` constructor cannot help to reach that goal.
>> 
>>   foo = new Foo();
>> 
>> is roughly equivalent to
>> 
>>   [A]    tmp = allocate memory space for sizeof(Foo)
>>   [B]    zero the space. (this may occur before [A])
>>   [1]    tmp.Foo(); // as if the constructor is an instance method
>>   [2]    foo = tmp;
>> 
>> [2] can be reordered before [1], so other threads may observe 
>> blank/partial state through `foo` reference. This reordering is 
>> allowed even if `Foo()` is synchronized.
>> 
>> This problem affects some "thread safe" classes like java.util.Vector.
>> If a Vector object is unsafely published, program can crash 
>> unexpectedly. I bet that's a huge surprise to most Java programmers.
>> 
>> But I don't think the "unenlightened mass" are to blame. We have this 
>> strong intuition that an object comes to existence only after 
>> construction. Nobody outside of construction should observe a 
>> partially constructed object (unless `this` is leaked during 
>> construction).
>> 
>> If JMM has this simple "whole-birth" guarantee, many man-hours of 
>> anguish will be saved. You can innocently do a double checked locking, 
>> and nobody is going to yell at your naivety.
>> 
>> Unfortunately JMM doesn't have this guarantee. Allegedly such 
>> guarantee carries a performance penalty. The only work around is 
>> through `final` fields. Neither `synchronized` nor `volatile` is 
>> useful for this purpose (many people are mistaken on this point; it is 
>> due to their whole-birth intuition, subconsciously adding a 
>> synchronization order from end of constructor to begin of instance
>> methods)
>> 
>> We are encouraged to use `final` fields whenever we can. One crucial 
>> reason is for the memory effect guarantee. However, using `final` 
>> fields will incur the same performance penalty of whole-birth 
>> guarantee. We have a great contradiction here. Either `final` is not 
>> cheap, so we should avoid `final` fields if we can; or `final` is 
>> cheap, so whole-birth guarantee can be established cheaply, yielding 
>> `final` unnecessary.
>> 
>> JMM does guarantee that [2] cannot be reordered before [B], otherwise 
>> other threads can observe garbage state. Let's call this the "blank"
>> guarantee. It's also a mystery to me why whole-birth guarantee can be 
>> fundamentally more expensive than blank guarantee.
>> 
>> Note that not everybody promotes the use of `final` though. We can 
>> sense how reserved David Holmes is through his words: " #Sometime# a 
>> class needs to add #some# protection against unsafe-publication that 
>> might violate #important# semantic guarantees of the object"
>> 
>> (We had a similar discussion in a September thread titled "Interesting 
>> anti-pattern with volatile"; however I cannot find it on the mailing 
>> list archive, so no link.)
>> 
>> Zhong Yu
>> 
>> P.S. a "fix" to Vector's vulnerability to unsafe publication
>> 
>> class Vector
>> 
>>   final Params ctorParams;
>> 
>>   Vector(params)
>>       ctorParams = new Params(params);
>> 
>>   boolean initDone;
>> 
>>   void ensureInit()
>>       if(!initDone)
>>           initialize this with ctorParams ...
>>           initDone = true;
>> 
>>   synchronized
>>   public Foo anyOtherMethod(Bar)
>>       ensureInit();
>>       actual work...
>> 
>> Of course, this solution sucks. The role of constructor is severely weakened.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra



From Joe.Kearney at gsacapital.com  Fri Dec 16 05:45:11 2011
From: Joe.Kearney at gsacapital.com (Kearney, Joe)
Date: Fri, 16 Dec 2011 10:45:11 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <1FA87377-98BB-4703-9DAD-EA164E3E29A2@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<1FA87377-98BB-4703-9DAD-EA164E3E29A2@rkuhn.info>
Message-ID: <9319F360221C65428EA819A4E8DC34ED037966AAD9@OPMBOX21UK.options-it.com>

Of course, and I would never argue with Mr Turing. I meant this only in the simple case where it's easy to deduce that no other thread sees the monitor, in such cases where the JVM can prove it.

-----Original Message-----
From: Roland Kuhn [mailto:rk at rkuhn.info] 
Sent: 16 December 2011 10:35
To: Kearney, Joe
Cc: Zhong Yu; concurrency-interest
Subject: Re: [concurrency-interest] synchronized constructors


On Dec 16, 2011, at 10:59 , Kearney, Joe wrote:

> How much of that locking is allowed to be elided away?
> 
> If you call synchronized(this) {} in a constructor, I would argue that


> provably no other thread can acquire the lock yet

This is not true: the constructor might write "this" to a static volatile field, thereby correctly publishing it to another thread, which might want to acquire the same lock and would have to block. And since the JVM is Turing complete, it is impossible to prove in the general case that this cannot happen (there may be very specific constructors which allow this, though, and you could argue that all of the IDE auto-generated ones fall into this category).

> . So can the locking be compiled away, even though the induced fence would need to stay?
> 
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of 
> Roland Kuhn
> Sent: 16 December 2011 09:49
> To: Zhong Yu
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] synchronized constructors
> 
> As I was recently made aware: the rules for write reordering are not as weak as you think.
> 
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.ht
> ml#24432
> 
> Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a "lock" operation. This means that a synchronized {} in the constructor solves the issue.
> 
> Regards,
> 
> Roland
> 
> On Dec 16, 2011, at 08:58 , Zhong Yu wrote:
> 
>> I'm totally sympathetic to this design goal - if an object claims to 
>> be thread safe, it should survive unsafe publication without problems.
>> I believe all java.util.concurrent classes have this property.
>> 
>> However, `synchronized` constructor cannot help to reach that goal.
>> 
>>   foo = new Foo();
>> 
>> is roughly equivalent to
>> 
>>   [A]    tmp = allocate memory space for sizeof(Foo)
>>   [B]    zero the space. (this may occur before [A])
>>   [1]    tmp.Foo(); // as if the constructor is an instance method
>>   [2]    foo = tmp;
>> 
>> [2] can be reordered before [1], so other threads may observe 
>> blank/partial state through `foo` reference. This reordering is 
>> allowed even if `Foo()` is synchronized.
>> 
>> This problem affects some "thread safe" classes like java.util.Vector.
>> If a Vector object is unsafely published, program can crash 
>> unexpectedly. I bet that's a huge surprise to most Java programmers.
>> 
>> But I don't think the "unenlightened mass" are to blame. We have this 
>> strong intuition that an object comes to existence only after 
>> construction. Nobody outside of construction should observe a 
>> partially constructed object (unless `this` is leaked during 
>> construction).
>> 
>> If JMM has this simple "whole-birth" guarantee, many man-hours of 
>> anguish will be saved. You can innocently do a double checked 
>> locking, and nobody is going to yell at your naivety.
>> 
>> Unfortunately JMM doesn't have this guarantee. Allegedly such 
>> guarantee carries a performance penalty. The only work around is 
>> through `final` fields. Neither `synchronized` nor `volatile` is 
>> useful for this purpose (many people are mistaken on this point; it 
>> is due to their whole-birth intuition, subconsciously adding a 
>> synchronization order from end of constructor to begin of instance
>> methods)
>> 
>> We are encouraged to use `final` fields whenever we can. One crucial 
>> reason is for the memory effect guarantee. However, using `final` 
>> fields will incur the same performance penalty of whole-birth 
>> guarantee. We have a great contradiction here. Either `final` is not 
>> cheap, so we should avoid `final` fields if we can; or `final` is 
>> cheap, so whole-birth guarantee can be established cheaply, yielding 
>> `final` unnecessary.
>> 
>> JMM does guarantee that [2] cannot be reordered before [B], otherwise 
>> other threads can observe garbage state. Let's call this the "blank"
>> guarantee. It's also a mystery to me why whole-birth guarantee can be 
>> fundamentally more expensive than blank guarantee.
>> 
>> Note that not everybody promotes the use of `final` though. We can 
>> sense how reserved David Holmes is through his words: " #Sometime# a 
>> class needs to add #some# protection against unsafe-publication that 
>> might violate #important# semantic guarantees of the object"
>> 
>> (We had a similar discussion in a September thread titled 
>> "Interesting anti-pattern with volatile"; however I cannot find it on 
>> the mailing list archive, so no link.)
>> 
>> Zhong Yu
>> 
>> P.S. a "fix" to Vector's vulnerability to unsafe publication
>> 
>> class Vector
>> 
>>   final Params ctorParams;
>> 
>>   Vector(params)
>>       ctorParams = new Params(params);
>> 
>>   boolean initDone;
>> 
>>   void ensureInit()
>>       if(!initDone)
>>           initialize this with ctorParams ...
>>           initDone = true;
>> 
>>   synchronized
>>   public Foo anyOtherMethod(Bar)
>>       ensureInit();
>>       actual work...
>> 
>> Of course, this solution sucks. The role of constructor is severely weakened.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 
> 2038
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra



From cheremin at gmail.com  Fri Dec 16 06:52:42 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Fri, 16 Dec 2011 15:52:42 +0400
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
Message-ID: <CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>

>>> I don?t see anything in chapter 8 which allows synchronized to be elided at all. Viewed from a single thread, the main guarantees of synchronized are ?fresh reads after lock? and ?writes flushed before unlock?, and these cannot be elided. If the VM sees that nobody else is ever locking on the same object, I would assume that the ?mutual exclusion? part may be elided, but not the memory effects.
>>
>> Main guarantee of synchronized is ordering (HB edges). So, if
>> happens-before edges it creates is subset of already exists
>> happens-before edges -- such synchronization can be elided. For
>> example, if lock used by only one thread -- it ca be proved, that HB
>> edges it creates is subset of HB edges which just simple program order
>> creates.So -- it can be elided. And HotSpot actually do such
>> optimization in several cases, when it can prove monitor not leaving
>> single thread.
>>
>> Biased locking optimization is another example.
>
>
> The JVM spec is very clear on prescient writes, and there is no constraint there wrt. lock eliding. This means that IF locks are elided, this cannot weaken memory consistency guarantees. Please provide pointers to the spec where this is allowed in case I?m wrong.

Yes, sure, IF lock are elided memory consistency effect still must be
the same, as if it still here. But JMM does not specify memory effects
of locking as ?fresh reads after lock? or ?writes flushed before
unlock? -- memory effects specified in terms of HB-edges lock/unlock
creates. And if such edges are redundant -- they are still exists even
without specific lock, since, for example, the same edges are created
by program order -- the lock can be thrown out, and this does not
change memory semantics (full set of HB edges in execution will not be
changed). This is one of the greatest benefits of new JMM, which
allows kind of optimization I've noted (lock ellision/biased locking).



> Regards,
>
> Roland
>
> --
> Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
> ?-- Dijkstra
>


From rk at rkuhn.info  Fri Dec 16 07:09:40 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 16 Dec 2011 13:09:40 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
Message-ID: <DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>


On Dec 16, 2011, at 12:52 , Ruslan Cheremin wrote:

>>>> I don?t see anything in chapter 8 which allows synchronized to be elided at all. Viewed from a single thread, the main guarantees of synchronized are ?fresh reads after lock? and ?writes flushed before unlock?, and these cannot be elided. If the VM sees that nobody else is ever locking on the same object, I would assume that the ?mutual exclusion? part may be elided, but not the memory effects.
>>> 
>>> Main guarantee of synchronized is ordering (HB edges). So, if
>>> happens-before edges it creates is subset of already exists
>>> happens-before edges -- such synchronization can be elided. For
>>> example, if lock used by only one thread -- it ca be proved, that HB
>>> edges it creates is subset of HB edges which just simple program order
>>> creates.So -- it can be elided. And HotSpot actually do such
>>> optimization in several cases, when it can prove monitor not leaving
>>> single thread.
>>> 
>>> Biased locking optimization is another example.
>> 
>> 
>> The JVM spec is very clear on prescient writes, and there is no constraint there wrt. lock eliding. This means that IF locks are elided, this cannot weaken memory consistency guarantees. Please provide pointers to the spec where this is allowed in case I?m wrong.
> 
> Yes, sure, IF lock are elided memory consistency effect still must be
> the same, as if it still here.

Okay, then JVM spec 8.8 says that no ?lock? operation can take place between a relocated ?store? and its ?assign?, so we are safe here, i.e. synchronized {} within constructor makes even unsafe publication impossible before the lock is entered. The remaining problem is that without acquiring the lock from the other thread, that thread may see partially initialized state. So to make sure that everything is okay, is it enough to have one final field which forces publication to happen after the constructor finishes?

> But JMM does not specify memory effects
> of locking as ?fresh reads after lock? or ?writes flushed before
> unlock? -- memory effects specified in terms of HB-edges lock/unlock
> creates. And if such edges are redundant -- they are still exists even
> without specific lock, since, for example, the same edges are created
> by program order -- the lock can be thrown out, and this does not
> change memory semantics (full set of HB edges in execution will not be
> changed). This is one of the greatest benefits of new JMM, which
> allows kind of optimization I've noted (lock ellision/biased locking).
> 
Yes, certainly. Unless it becomes impossible to create a mutable object which has the same memory visibility guarantees wrt. construction as compared to one which has only final fields.

Regards,

Roland

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)



From cheremin at gmail.com  Fri Dec 16 07:24:12 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Fri, 16 Dec 2011 16:24:12 +0400
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
Message-ID: <CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>

> Okay, then JVM spec 8.8 says that no ?lock? operation can take place between a relocated ?store? and its ?assign?, so we are safe here, i.e. synchronized {} within constructor makes even unsafe publication impossible before the lock is entered.

It seems like good point, althought I still does not sure about this
reasoning. I need some time for more formal proof.

>The remaining problem is that without acquiring the lock from the other thread, that thread may see partially initialized state. So to make sure that everything is okay, is it enough to have one final field which forces publication to happen after the constructor finishes?

As far, as I understand, topic starter does not want to elide locks
from other threads. Contrary, he wants to protect _all_ methods of his
object with locks -- making them completely thread-safe, even in case
of data-race-based publication. And he asks, is protecting constructor
does this job, and if it is - why synchronized constructor is
prohibited in JLS?

By the way -- one final field does not enough. Final field is not a
magic for everybody -- it's magic is for itself (and its dereference
chain) only. Although it seems like most of actual implementation use
global StoreStore barrier (if any) as freeze, making _all_ previous
write published, such global barrier does not required by formal JMM
final field semantic. And JMM does not prevent JIT to move some
non-final-fields write _after_ freeze.

>> But JMM does not specify memory effects
>> of locking as ?fresh reads after lock? or ?writes flushed before
>> unlock? -- memory effects specified in terms of HB-edges lock/unlock
>> creates. And if such edges are redundant -- they are still exists even
>> without specific lock, since, for example, the same edges are created
>> by program order -- the lock can be thrown out, and this does not
>> change memory semantics (full set of HB edges in execution will not be
>> changed). This is one of the greatest benefits of new JMM, which
>> allows kind of optimization I've noted (lock ellision/biased locking).
>>
> Yes, certainly. Unless it becomes impossible to create a mutable object which has the same memory visibility guarantees wrt. construction as compared to one which has only final fields.

It seems like it is. Seems like the only way to work with data races
and got some predictable results is to use final fields.



> Regards,
>
> Roland
>
> --
> I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
> ? ?- Sheldon Cooper (The Big Bang Theory)
>


From yshavit at akiban.com  Fri Dec 16 09:38:19 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Fri, 16 Dec 2011 09:38:19 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
Message-ID: <CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>

On Fri, Dec 16, 2011 at 7:24 AM, Ruslan Cheremin <cheremin at gmail.com> wrote:

> As far, as I understand, topic starter does not want to elide locks
> from other threads. Contrary, he wants to protect _all_ methods of his
> object with locks -- making them completely thread-safe, even in case
> of data-race-based publication. And he asks, is protecting constructor
> does this job, and if it is - why synchronized constructor is
> prohibited in JLS?
>

Yes, exactly.

Several people have made the claim that you could see partially initialized
state even if the constructor were synchronized, and I don't see how this
could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
finishes -- but if you ever tried to *use* myUnsafeRef, you would run into
a synchronized block which would then ensure that the constructor
happened-before whatever method you're writing. Seems to me you should see
the fully-thread-safe, not-partially-initialized object at that point.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/7a3641d8/attachment.html>

From nathan.reynolds at oracle.com  Fri Dec 16 11:31:48 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 16 Dec 2011 09:31:48 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAOwENi+1Ajuxcbun4WXitjDqU+NC0JMkhhCpX9TLFtAX7FHeYw@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<CAOwENi+1Ajuxcbun4WXitjDqU+NC0JMkhhCpX9TLFtAX7FHeYw@mail.gmail.com>
Message-ID: <4EEB7274.6070605@oracle.com>

I am not sure about HotSpot, but JRockit doesn't zero a piece of memory 
until allocation time.  The JRockit team found that zeroing memory at 
the time of allocation takes advantage of caching.  Zeroing memory in GC 
causes the memory to be loaded into cache, evicted and reloaded at 
allocation time.  Zeroing memory at allocation causes the memory to 
loaded into cache while being zeroed and then get an extra cache hit.

JRockit does its best to avoid writing zeros to a memory location that 
will be overwritten with an initialized value.  JRockit checks for the 
"this" reference escaping the constructor and other such problems.  For 
example, in this code it will zero m_field2 but probably not m_field1.  
Why waste cycles and memory bandwidth zeroing m_field1 when it will be 
overwritten a few instructions later?

private final int m_field1, m_field2;

public MyObject()
{
    m_field1 = 5;
    someMethod();
    m_field2 = 10;
}

public void someMethod()
{
     System.out.println(m_field2);
}

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/16/2011 3:00 AM, Ruslan Cheremin wrote:
>> so other threads may observe blank/partial state through `foo` reference. This reordering is
>> allowed even if `Foo()` is synchronized.
> It's a very good explanation. Only to note -- if constructor is
> synchronized, as all other accessors, "partial" state can't be seen.
> But, sure, blank state -- can be.
>
>> JMM does guarantee that [2] cannot be reordered before [B], otherwise
>> other threads can observe garbage state. Let's call this the "blank"
>> guarantee. It's also a mystery to me why whole-birth guarantee can be
>> fundamentally more expensive than blank guarantee.
> As far, as I understand, blank guarantee is cheeper since it can be
> implemented in batch. AFAIK, it is GC who blanking reclaimed memory,
> so it can be done megabytes at once, and publishing reclaimed and
> zeroed memory also can be done at one shot. So, the cost is greatly
> amortized. But store-store barrier at the end of constructor, which
> seems to be required for your whole-birth guarantee can't  be
> amortized.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/59fd79db/attachment.html>

From nathan.reynolds at oracle.com  Fri Dec 16 11:38:55 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 16 Dec 2011 09:38:55 -0700
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
Message-ID: <4EEB741F.9090302@oracle.com>

Check out the Final Fields section in 
http://g.oswego.edu/dl/jmm/cookbook.html.  The first example is exactly 
what we need.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/16/2011 5:24 AM, Ruslan Cheremin wrote:
>> Okay, then JVM spec 8.8 says that no ?lock? operation can take place between a relocated ?store? and its ?assign?, so we are safe here, i.e. synchronized {} within constructor makes even unsafe publication impossible before the lock is entered.
> It seems like good point, althought I still does not sure about this
> reasoning. I need some time for more formal proof.
>
>> The remaining problem is that without acquiring the lock from the other thread, that thread may see partially initialized state. So to make sure that everything is okay, is it enough to have one final field which forces publication to happen after the constructor finishes?
> As far, as I understand, topic starter does not want to elide locks
> from other threads. Contrary, he wants to protect _all_ methods of his
> object with locks -- making them completely thread-safe, even in case
> of data-race-based publication. And he asks, is protecting constructor
> does this job, and if it is - why synchronized constructor is
> prohibited in JLS?
>
> By the way -- one final field does not enough. Final field is not a
> magic for everybody -- it's magic is for itself (and its dereference
> chain) only. Although it seems like most of actual implementation use
> global StoreStore barrier (if any) as freeze, making _all_ previous
> write published, such global barrier does not required by formal JMM
> final field semantic. And JMM does not prevent JIT to move some
> non-final-fields write _after_ freeze.
>
>>> But JMM does not specify memory effects
>>> of locking as ?fresh reads after lock? or ?writes flushed before
>>> unlock? -- memory effects specified in terms of HB-edges lock/unlock
>>> creates. And if such edges are redundant -- they are still exists even
>>> without specific lock, since, for example, the same edges are created
>>> by program order -- the lock can be thrown out, and this does not
>>> change memory semantics (full set of HB edges in execution will not be
>>> changed). This is one of the greatest benefits of new JMM, which
>>> allows kind of optimization I've noted (lock ellision/biased locking).
>>>
>> Yes, certainly. Unless it becomes impossible to create a mutable object which has the same memory visibility guarantees wrt. construction as compared to one which has only final fields.
> It seems like it is. Seems like the only way to work with data races
> and got some predictable results is to use final fields.
>
>
>
>> Regards,
>>
>> Roland
>>
>> --
>> I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
>>     - Sheldon Cooper (The Big Bang Theory)
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/d9986ca4/attachment-0001.html>

From vitalyd at gmail.com  Fri Dec 16 11:39:17 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 16 Dec 2011 11:39:17 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <4EEB7274.6070605@oracle.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<CAOwENi+1Ajuxcbun4WXitjDqU+NC0JMkhhCpX9TLFtAX7FHeYw@mail.gmail.com>
	<4EEB7274.6070605@oracle.com>
Message-ID: <CAHjP37FOiE5GJn4RzT4s_fqsCqTdQENUi2RwuVfNQ78s=CzNyA@mail.gmail.com>

hotspot also does zeroing on demand.  There was an email to one of the
other openjdk groups recently where a group built a prototype that mixed
block zeroing with on demand and found some improvement.
On Dec 16, 2011 11:33 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  I am not sure about HotSpot, but JRockit doesn't zero a piece of memory
> until allocation time.  The JRockit team found that zeroing memory at the
> time of allocation takes advantage of caching.  Zeroing memory in GC causes
> the memory to be loaded into cache, evicted and reloaded at allocation
> time.  Zeroing memory at allocation causes the memory to loaded into cache
> while being zeroed and then get an extra cache hit.
>
> JRockit does its best to avoid writing zeros to a memory location that
> will be overwritten with an initialized value.  JRockit checks for the
> "this" reference escaping the constructor and other such problems.  For
> example, in this code it will zero m_field2 but probably not m_field1.  Why
> waste cycles and memory bandwidth zeroing m_field1 when it will be
> overwritten a few instructions later?
>
> private final int m_field1, m_field2;
>
> public MyObject()
> {
>    m_field1 = 5;
>    someMethod();
>    m_field2 = 10;
> }
>
> public void someMethod()
> {
>     System.out.println(m_field2);
> }
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/16/2011 3:00 AM, Ruslan Cheremin wrote:
>
>  so other threads may observe blank/partial state through `foo` reference. This reordering is
> allowed even if `Foo()` is synchronized.
>
>
> It's a very good explanation. Only to note -- if constructor is
> synchronized, as all other accessors, "partial" state can't be seen.
> But, sure, blank state -- can be.
>
>
>  JMM does guarantee that [2] cannot be reordered before [B], otherwise
> other threads can observe garbage state. Let's call this the "blank"
> guarantee. It's also a mystery to me why whole-birth guarantee can be
> fundamentally more expensive than blank guarantee.
>
>
> As far, as I understand, blank guarantee is cheeper since it can be
> implemented in batch. AFAIK, it is GC who blanking reclaimed memory,
> so it can be done megabytes at once, and publishing reclaimed and
> zeroed memory also can be done at one shot. So, the cost is greatly
> amortized. But store-store barrier at the end of constructor, which
> seems to be required for your whole-birth guarantee can't  be
> amortized.
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/393f8182/attachment.html>

From zhong.j.yu at gmail.com  Fri Dec 16 14:03:36 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 16 Dec 2011 13:03:36 -0600
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
Message-ID: <CACuKZqFA6huBdhttr8maxq1VcjVeBtDbd7fe=EwswBvCW+fxpQ@mail.gmail.com>

I can only reason concurrency based on JMM (as in the Java Language
Spec); beyond that I have no idea.

My understanding is that JMM allows such reordering (in effect)

Zhong Yu

On Fri, Dec 16, 2011 at 3:48 AM, Roland Kuhn <rk at rkuhn.info> wrote:
> As I was recently made aware: the rules for write reordering are not as weak as you think.
>
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.html#24432
>
> Section 8.8 of the JVM spec requires that a write cannot be moved earlier across a ?lock? operation. This means that a synchronized {} in the constructor solves the issue.
>
> Regards,
>
> Roland


From zhong.j.yu at gmail.com  Fri Dec 16 14:10:25 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 16 Dec 2011 13:10:25 -0600
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
Message-ID: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>

On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
> Several people have made the claim that you could see partially initialized
> state even if the constructor were synchronized, and I don't see how this
> could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
> synchronized block which would then ensure that the constructor
> happened-before whatever method you're writing. Seems to me you should see
> the fully-thread-safe, not-partially-initialized object at that point.

If the reference is unsafely published, another thread can get the
reference early; it then calls an instance method which may obtain the
lock before the creation thread can obtain the lock for the
constructor. Therefore the other thread can observe the blank state.
As Ruslan corrected me, no partial state can be observed though.

Zhong Yu

From yshavit at akiban.com  Fri Dec 16 14:59:21 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Fri, 16 Dec 2011 14:59:21 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
Message-ID: <CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>

On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
> > Several people have made the claim that you could see partially
> initialized
> > state even if the constructor were synchronized, and I don't see how this
> > could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> > finishes -- but if you ever tried to *use* myUnsafeRef, you would run
> into a
> > synchronized block which would then ensure that the constructor
> > happened-before whatever method you're writing. Seems to me you should
> see
> > the fully-thread-safe, not-partially-initialized object at that point.
>
> If the reference is unsafely published, another thread can get the
> reference early; it then calls an instance method which may obtain the
> lock before the creation thread can obtain the lock for the
> constructor. Therefore the other thread can observe the blank state.
> As Ruslan corrected me, no partial state can be observed though.


Ah yes, I hadn't thought of that.

So now, in order to have my class be over-achievingly thread safe, I need
to replace my synchronized methods with a latch that waits for construction
to finish and *then* a synchronized (this) {...}. But I probably decide
that this is really going far out of my way to support a bad usage pattern,
so I throw up my arms and say "you'll see either totally blank or
post-initialization state, but not partial initialization."  But that means
I have to guard against uninitialized state in each method, so I probably
throw up my arms again and say "just publish the darn object safely!"  And
then the JLS people come to me and say, "well if that's your requirement,
why do you want a synchronized constructor?"  And suddenly the whole thing
makes sense.

This has been an interesting discussion for me! Thanks everyone. :)

-Yuval
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/b98cd5e7/attachment.html>

From hans.boehm at hp.com  Fri Dec 16 16:33:07 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Fri, 16 Dec 2011 21:33:07 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqFA6huBdhttr8maxq1VcjVeBtDbd7fe=EwswBvCW+fxpQ@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<CACuKZqFA6huBdhttr8maxq1VcjVeBtDbd7fe=EwswBvCW+fxpQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D59B8@G4W3299.americas.hpqcorp.net>

As far as I can tell from the copyright notice and content, the memory model spec in that book hasn't been updated since the 2005 memory model revision.  I believe it should be ignored for this discussion.

Hans

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-
> interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
> Sent: Friday, December 16, 2011 11:04 AM
> To: Roland Kuhn
> Cc: concurrency-interest
> Subject: Re: [concurrency-interest] synchronized constructors
> 
> I can only reason concurrency based on JMM (as in the Java Language
> Spec); beyond that I have no idea.
> 
> My understanding is that JMM allows such reordering (in effect)
> 
> Zhong Yu
> 
> On Fri, Dec 16, 2011 at 3:48 AM, Roland Kuhn <rk at rkuhn.info> wrote:
> > As I was recently made aware: the rules for write reordering are not
> as weak as you think.
> >
> >
> http://java.sun.com/docs/books/jvms/second_edition/html/Threads.doc.htm
> l#24432
> >
> > Section 8.8 of the JVM spec requires that a write cannot be moved
> earlier across a "lock" operation. This means that a synchronized {} in
> the constructor solves the issue.
> >
> > Regards,
> >
> > Roland
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From hans.boehm at hp.com  Fri Dec 16 16:49:01 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Fri, 16 Dec 2011 21:49:01 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>

Just to be clear: Safe publication for final fields requires that you do not make a pointer to the object available to other threads (publish it) before the constructor finishes.  "Safe publication" as used below is a slightly stronger property; you also should not communicate the pointer post-construction to another thread via a data race.  Avoiding them both is great advice, but the second one may be difficult to avoid if you need to give a reference to your object to code you don't trust.  Malicious code could always pass the object to a third thread through a race, hoping that the third thread, which has no happens-before relationship to the other two, would find your object in an inconsistent state.  My intuition is that this is a rare case, but one that does occur.  When it does occur, the odds of an actual security hole are probably small, but so are the odds of proving security properties without addressing the issue.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yuval Shavit
Sent: Friday, December 16, 2011 11:59 AM
To: Zhong Yu
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] synchronized constructors

On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com<mailto:zhong.j.yu at gmail.com>> wrote:
On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com<mailto:yshavit at akiban.com>> wrote:
> Several people have made the claim that you could see partially initialized
> state even if the constructor were synchronized, and I don't see how this
> could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
> synchronized block which would then ensure that the constructor
> happened-before whatever method you're writing. Seems to me you should see
> the fully-thread-safe, not-partially-initialized object at that point.
If the reference is unsafely published, another thread can get the
reference early; it then calls an instance method which may obtain the
lock before the creation thread can obtain the lock for the
constructor. Therefore the other thread can observe the blank state.
As Ruslan corrected me, no partial state can be observed though.

Ah yes, I hadn't thought of that.

So now, in order to have my class be over-achievingly thread safe, I need to replace my synchronized methods with a latch that waits for construction to finish and *then* a synchronized (this) {...}. But I probably decide that this is really going far out of my way to support a bad usage pattern, so I throw up my arms and say "you'll see either totally blank or post-initialization state, but not partial initialization."  But that means I have to guard against uninitialized state in each method, so I probably throw up my arms again and say "just publish the darn object safely!"  And then the JLS people come to me and say, "well if that's your requirement, why do you want a synchronized constructor?"  And suddenly the whole thing makes sense.

This has been an interesting discussion for me! Thanks everyone. :)

-Yuval
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/392e56d6/attachment-0001.html>

From rk at rkuhn.info  Fri Dec 16 17:52:38 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Fri, 16 Dec 2011 23:52:38 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
Message-ID: <5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>

This sounds like it is impossible to construct a mutable object in a way so that it is immune against improper publication. If the aforementioned is wrong?which I hope?then would you please tell me what the cheapest way is of achieving this goal? One thing I could think of is just putting all non-final fields in another class and have a reference to that be held in a final field; if this works, it would be quite expensive, so any better solution would be welcome.

You might ask, why have a non-final field without proper synchronization, so let me add that the background to this question is that in my case the construction of the object needs to proceed in two phases because of other inter-dependencies, which requires certain fields to be written to after the constructor has finished; they will be written to only exactly once, and this happens before ?untrusted? client code obtains the reference (in program order).

Thanks in advance,

Roland

On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:

> Just to be clear: Safe publication for final fields requires that you do not make a pointer to the object available to other threads (publish it) before the constructor finishes.  ?Safe publication? as used below is a slightly stronger property; you also should not communicate the pointer post-construction to another thread via a data race.  Avoiding them both is great advice, but the second one may be difficult to avoid if you need to give a reference to your object to code you don?t trust.  Malicious code could always pass the object to a third thread through a race, hoping that the third thread, which has no happens-before relationship to the other two, would find your object in an inconsistent state.  My intuition is that this is a rare case, but one that does occur.  When it does occur, the odds of an actual security hole are probably small, but so are the odds of proving security properties without addressing the issue.
>  
> Hans
>  
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yuval Shavit
> Sent: Friday, December 16, 2011 11:59 AM
> To: Zhong Yu
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] synchronized constructors
>  
> On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
> > Several people have made the claim that you could see partially initialized
> > state even if the constructor were synchronized, and I don't see how this
> > could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> > finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
> > synchronized block which would then ensure that the constructor
> > happened-before whatever method you're writing. Seems to me you should see
> > the fully-thread-safe, not-partially-initialized object at that point.
> 
> If the reference is unsafely published, another thread can get the
> reference early; it then calls an instance method which may obtain the
> lock before the creation thread can obtain the lock for the
> constructor. Therefore the other thread can observe the blank state.
> As Ruslan corrected me, no partial state can be observed though.
>  
> Ah yes, I hadn't thought of that.
>  
> So now, in order to have my class be over-achievingly thread safe, I need to replace my synchronized methods with a latch that waits for construction to finish and *then* a synchronized (this) {...}. But I probably decide that this is really going far out of my way to support a bad usage pattern, so I throw up my arms and say "you'll see either totally blank or post-initialization state, but not partial initialization."  But that means I have to guard against uninitialized state in each method, so I probably throw up my arms again and say "just publish the darn object safely!"  And then the JLS people come to me and say, "well if that's your requirement, why do you want a synchronized constructor?"  And suddenly the whole thing makes sense.
>  
> This has been an interesting discussion for me! Thanks everyone. :)
>  
> -Yuval
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/6d7f1d06/attachment.html>

From vitalyd at gmail.com  Fri Dec 16 18:44:02 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 16 Dec 2011 18:44:02 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
	<5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
Message-ID: <CAHjP37EsTEAMQW5pMcV7QxsGkvugXHS9di=9Xh--5qMwCSFcyQ@mail.gmail.com>

Sounds like you control publishing ... cheapest for you would be to wrap
your object in AtomicReference and lazySet it before publishing the
reference.
On Dec 16, 2011 5:57 PM, "Roland Kuhn" <rk at rkuhn.info> wrote:

> This sounds like it is impossible to construct a mutable object in a way
> so that it is immune against improper publication. If the aforementioned is
> wrong?which I hope?then would you please tell me what the cheapest way is
> of achieving this goal? One thing I could think of is just putting all
> non-final fields in another class and have a reference to that be held in a
> final field; if this works, it would be quite expensive, so any better
> solution would be welcome.
>
> You might ask, why have a non-final field without proper synchronization,
> so let me add that the background to this question is that in my case the
> construction of the object needs to proceed in two phases because of other
> inter-dependencies, which requires certain fields to be written to after
> the constructor has finished; they will be written to only exactly once,
> and this happens before ?untrusted? client code obtains the reference (in
> program order).
>
> Thanks in advance,
>
> Roland
>
> On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:
>
> Just to be clear: Safe publication for final fields requires that you do
> not make a pointer to the object available to other threads (publish it)
> before the constructor finishes.  ?Safe publication? as used below is a
> slightly stronger property; you also should not communicate the pointer
> post-construction to another thread via a data race.  Avoiding them both is
> great advice, but the second one may be difficult to avoid if you need to
> give a reference to your object to code you don?t trust.  Malicious code
> could always pass the object to a third thread through a race, hoping that
> the third thread, which has no happens-before relationship to the other
> two, would find your object in an inconsistent state.  My intuition is that
> this is a rare case, but one that does occur.  When it does occur, the odds
> of an actual security hole are probably small, but so are the odds of
> proving security properties without addressing the issue.****
> ** **
> Hans****
> ** **
>  *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Yuval Shavit
> *Sent:* Friday, December 16, 2011 11:59 AM
> *To:* Zhong Yu
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] synchronized constructors****
> ** **
> On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:***
> *
>
> On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
> > Several people have made the claim that you could see partially
> initialized
> > state even if the constructor were synchronized, and I don't see how this
> > could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> > finishes -- but if you ever tried to *use* myUnsafeRef, you would run
> into a
> > synchronized block which would then ensure that the constructor
> > happened-before whatever method you're writing. Seems to me you should
> see
> > the fully-thread-safe, not-partially-initialized object at that point.**
> **
> If the reference is unsafely published, another thread can get the
> reference early; it then calls an instance method which may obtain the
> lock before the creation thread can obtain the lock for the
> constructor. Therefore the other thread can observe the blank state.
> As Ruslan corrected me, no partial state can be observed though.****
> ** **
> Ah yes, I hadn't thought of that.****
> ** **
> So now, in order to have my class be over-achievingly thread safe, I need
> to replace my synchronized methods with a latch that waits for construction
> to finish and *then* a synchronized (this) {...}. But I probably decide
> that this is really going far out of my way to support a bad usage pattern,
> so I throw up my arms and say "you'll see either totally blank or
> post-initialization state, but not partial initialization."  But that means
> I have to guard against uninitialized state in each method, so I probably
> throw up my arms again and say "just publish the darn object safely!"  And
> then the JLS people come to me and say, "well if that's your requirement,
> why do you want a synchronized constructor?"  And suddenly the whole thing
> makes sense.****
> ** **
> This has been an interesting discussion for me! Thanks everyone. :)****
> ** **
> -Yuval****
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>  --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/ab30b784/attachment-0001.html>

From rk at rkuhn.info  Fri Dec 16 19:00:12 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sat, 17 Dec 2011 01:00:12 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37EsTEAMQW5pMcV7QxsGkvugXHS9di=9Xh--5qMwCSFcyQ@mail.gmail.com>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
	<5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
	<CAHjP37EsTEAMQW5pMcV7QxsGkvugXHS9d
	i=9Xh--5qMwCSFcyQ@mail.gmail.com>
Message-ID: <9723B278-A1F0-4544-B241-E38B4043BFDA@rkuhn.info>

That does not seem to address the issue: lazySet may be reordered with later writes, according to the j.u.c package docs, the potential data race publication by untrusted code being just such a write. Also, the object I need to return must implement a specific interface, so it is not clear to me what you mean by ?wrapping?. Subclassing AtomicReference also does not work because of single inheritance.

On Dec 17, 2011, at 00:44 , Vitaly Davidovich wrote:
> Sounds like you control publishing ... cheapest for you would be to wrap your object in AtomicReference and lazySet it before publishing the reference.
> 
> On Dec 16, 2011 5:57 PM, "Roland Kuhn" <rk at rkuhn.info> wrote:
> This sounds like it is impossible to construct a mutable object in a way so that it is immune against improper publication. If the aforementioned is wrong?which I hope?then would you please tell me what the cheapest way is of achieving this goal? One thing I could think of is just putting all non-final fields in another class and have a reference to that be held in a final field; if this works, it would be quite expensive, so any better solution would be welcome.
> 
> You might ask, why have a non-final field without proper synchronization, so let me add that the background to this question is that in my case the construction of the object needs to proceed in two phases because of other inter-dependencies, which requires certain fields to be written to after the constructor has finished; they will be written to only exactly once, and this happens before ?untrusted? client code obtains the reference (in program order).
> 
> Thanks in advance,
> 
> Roland
> 
> On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:
> 
>> Just to be clear: Safe publication for final fields requires that you do not make a pointer to the object available to other threads (publish it) before the constructor finishes.  ?Safe publication? as used below is a slightly stronger property; you also should not communicate the pointer post-construction to another thread via a data race.  Avoiding them both is great advice, but the second one may be difficult to avoid if you need to give a reference to your object to code you don?t trust.  Malicious code could always pass the object to a third thread through a race, hoping that the third thread, which has no happens-before relationship to the other two, would find your object in an inconsistent state.  My intuition is that this is a rare case, but one that does occur.  When it does occur, the odds of an actual security hole are probably small, but so are the odds of proving security properties without addressing the issue.
>>  
>> Hans
>>  
>> From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yuval Shavit
>> Sent: Friday, December 16, 2011 11:59 AM
>> To: Zhong Yu
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] synchronized constructors
>>  
>> On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
>> > Several people have made the claim that you could see partially initialized
>> > state even if the constructor were synchronized, and I don't see how this
>> > could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
>> > finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
>> > synchronized block which would then ensure that the constructor
>> > happened-before whatever method you're writing. Seems to me you should see
>> > the fully-thread-safe, not-partially-initialized object at that point.
>> 
>> If the reference is unsafely published, another thread can get the
>> reference early; it then calls an instance method which may obtain the
>> lock before the creation thread can obtain the lock for the
>> constructor. Therefore the other thread can observe the blank state.
>> As Ruslan corrected me, no partial state can be observed though.
>>  
>> Ah yes, I hadn't thought of that.
>>  
>> So now, in order to have my class be over-achievingly thread safe, I need to replace my synchronized methods with a latch that waits for construction to finish and *then* a synchronized (this) {...}. But I probably decide that this is really going far out of my way to support a bad usage pattern, so I throw up my arms and say "you'll see either totally blank or post-initialization state, but not partial initialization."  But that means I have to guard against uninitialized state in each method, so I probably throw up my arms again and say "just publish the darn object safely!"  And then the JLS people come to me and say, "well if that's your requirement, why do you want a synchronized constructor?"  And suddenly the whole thing makes sense.
>>  
>> This has been an interesting discussion for me! Thanks everyone. :)
>>  
>> -Yuval
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> --
> [scala-debate on 2009/10/2]
> Viktor Klang: When will the days of numerical overflow be gone?
> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/a7392ae3/attachment.html>

From vitalyd at gmail.com  Fri Dec 16 19:06:09 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 16 Dec 2011 19:06:09 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <9723B278-A1F0-4544-B241-E38B4043BFDA@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
	<5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
	<CAHjP37EsTEAMQW5pMcV7QxsGkvugXHS9di=9Xh--5qMwCSFcyQ@mail.gmail.com>
	<9723B278-A1F0-4544-B241-E38B4043BFDA@rkuhn.info>
Message-ID: <CAHjP37Hhc2ymT2eFOs1O=BHphdaG0c88e+UDBzv6RDA1CRVVog@mail.gmail.com>

my point is that lazySet  ensures that prior writes are visible if get()
returns non null, which covers your concern about writes done after
construction but before publication.

By wrap I meant instead of publishing FooClass you publish
AtomicReference<FooClass>.
On Dec 16, 2011 7:00 PM, "Roland Kuhn" <rk at rkuhn.info> wrote:

> That does not seem to address the issue: lazySet may be reordered with
> later writes, according to the j.u.c package docs, the potential data race
> publication by untrusted code being just such a write. Also, the object I
> need to return must implement a specific interface, so it is not clear to
> me what you mean by ?wrapping?. Subclassing AtomicReference also does not
> work because of single inheritance.
>
> On Dec 17, 2011, at 00:44 , Vitaly Davidovich wrote:
>
> Sounds like you control publishing ... cheapest for you would be to wrap
> your object in AtomicReference and lazySet it before publishing the
> reference.
> On Dec 16, 2011 5:57 PM, "Roland Kuhn" <rk at rkuhn.info> wrote:
>
>> This sounds like it is impossible to construct a mutable object in a way
>> so that it is immune against improper publication. If the aforementioned is
>> wrong?which I hope?then would you please tell me what the cheapest way is
>> of achieving this goal? One thing I could think of is just putting all
>> non-final fields in another class and have a reference to that be held in a
>> final field; if this works, it would be quite expensive, so any better
>> solution would be welcome.
>>
>> You might ask, why have a non-final field without proper synchronization,
>> so let me add that the background to this question is that in my case the
>> construction of the object needs to proceed in two phases because of other
>> inter-dependencies, which requires certain fields to be written to after
>> the constructor has finished; they will be written to only exactly once,
>> and this happens before ?untrusted? client code obtains the reference (in
>> program order).
>>
>> Thanks in advance,
>>
>> Roland
>>
>> On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:
>>
>> Just to be clear: Safe publication for final fields requires that you do
>> not make a pointer to the object available to other threads (publish it)
>> before the constructor finishes.  ?Safe publication? as used below is a
>> slightly stronger property; you also should not communicate the pointer
>> post-construction to another thread via a data race.  Avoiding them both is
>> great advice, but the second one may be difficult to avoid if you need to
>> give a reference to your object to code you don?t trust.  Malicious code
>> could always pass the object to a third thread through a race, hoping that
>> the third thread, which has no happens-before relationship to the other
>> two, would find your object in an inconsistent state.  My intuition is that
>> this is a rare case, but one that does occur.  When it does occur, the odds
>> of an actual security hole are probably small, but so are the odds of
>> proving security properties without addressing the issue.****
>> ** **
>> Hans****
>> ** **
>>  *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Yuval Shavit
>> *Sent:* Friday, December 16, 2011 11:59 AM
>> *To:* Zhong Yu
>> *Cc:* concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] synchronized constructors****
>> ** **
>> On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:**
>> **
>>
>> On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com> wrote:
>> > Several people have made the claim that you could see partially
>> initialized
>> > state even if the constructor were synchronized, and I don't see how
>> this
>> > could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
>> > finishes -- but if you ever tried to *use* myUnsafeRef, you would run
>> into a
>> > synchronized block which would then ensure that the constructor
>> > happened-before whatever method you're writing. Seems to me you should
>> see
>> > the fully-thread-safe, not-partially-initialized object at that point.*
>> ***
>> If the reference is unsafely published, another thread can get the
>> reference early; it then calls an instance method which may obtain the
>> lock before the creation thread can obtain the lock for the
>> constructor. Therefore the other thread can observe the blank state.
>> As Ruslan corrected me, no partial state can be observed though.****
>> ** **
>> Ah yes, I hadn't thought of that.****
>> ** **
>> So now, in order to have my class be over-achievingly thread safe, I need
>> to replace my synchronized methods with a latch that waits for construction
>> to finish and *then* a synchronized (this) {...}. But I probably decide
>> that this is really going far out of my way to support a bad usage pattern,
>> so I throw up my arms and say "you'll see either totally blank or
>> post-initialization state, but not partial initialization."  But that means
>> I have to guard against uninitialized state in each method, so I probably
>> throw up my arms again and say "just publish the darn object safely!"  And
>> then the JLS people come to me and say, "well if that's your requirement,
>> why do you want a synchronized constructor?"  And suddenly the whole thing
>> makes sense.****
>> ** **
>> This has been an interesting discussion for me! Thanks everyone. :)****
>> ** **
>> -Yuval****
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>  --
>> [scala-debate on 2009/10/2]
>> Viktor Klang: When will the days of numerical overflow be gone?
>> Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> --
> I'm a physicist: I have a basic working knowledge of the universe and
> everything it contains!
>     - Sheldon Cooper (The Big Bang Theory)
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/a9dd943d/attachment-0001.html>

From hans.boehm at hp.com  Fri Dec 16 20:01:36 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Sat, 17 Dec 2011 01:01:36 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
	<5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D5F11@G4W3299.americas.hpqcorp.net>

Interesting question, though I'm not sure I understand the problem correctly.  It seems to me that synchronized(this) in the constructor, and a synchronized second initialization phase ensure that all clients see either one of

1) the zero initialized object
2) the fully constructed object, pre-phase-2 initialization object, or
3) the fully initialized object

I don't see any way to prevent untrusted code running in multiple other threads from getting a hold of a reference to the object without establishing a happens-before relationship to ensure that it sees the object fully initialized.  Thus to be fully safe, I suspect other methods have to be prepared to find an object in any of those states.  Presumably they could explicitly check which one applies.  That doesn't seem like an entirely satisfactory answer, but ...

Hans

From: Roland Kuhn [mailto:rk at rkuhn.info]
Sent: Friday, December 16, 2011 2:53 PM
To: Boehm, Hans
Cc: Yuval Shavit; Zhong Yu; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] synchronized constructors

This sounds like it is impossible to construct a mutable object in a way so that it is immune against improper publication. If the aforementioned is wrong-which I hope-then would you please tell me what the cheapest way is of achieving this goal? One thing I could think of is just putting all non-final fields in another class and have a reference to that be held in a final field; if this works, it would be quite expensive, so any better solution would be welcome.

You might ask, why have a non-final field without proper synchronization, so let me add that the background to this question is that in my case the construction of the object needs to proceed in two phases because of other inter-dependencies, which requires certain fields to be written to after the constructor has finished; they will be written to only exactly once, and this happens before "untrusted" client code obtains the reference (in program order).

Thanks in advance,

Roland

On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:


Just to be clear: Safe publication for final fields requires that you do not make a pointer to the object available to other threads (publish it) before the constructor finishes.  "Safe publication" as used below is a slightly stronger property; you also should not communicate the pointer post-construction to another thread via a data race.  Avoiding them both is great advice, but the second one may be difficult to avoid if you need to give a reference to your object to code you don't trust.  Malicious code could always pass the object to a third thread through a race, hoping that the third thread, which has no happens-before relationship to the other two, would find your object in an inconsistent state.  My intuition is that this is a rare case, but one that does occur.  When it does occur, the odds of an actual security hole are probably small, but so are the odds of proving security properties without addressing the issue.

Hans

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yuval Shavit
Sent: Friday, December 16, 2011 11:59 AM
To: Zhong Yu
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] synchronized constructors

On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com<mailto:zhong.j.yu at gmail.com>> wrote:
On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com<mailto:yshavit at akiban.com>> wrote:
> Several people have made the claim that you could see partially initialized
> state even if the constructor were synchronized, and I don't see how this
> could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
> synchronized block which would then ensure that the constructor
> happened-before whatever method you're writing. Seems to me you should see
> the fully-thread-safe, not-partially-initialized object at that point.
If the reference is unsafely published, another thread can get the
reference early; it then calls an instance method which may obtain the
lock before the creation thread can obtain the lock for the
constructor. Therefore the other thread can observe the blank state.
As Ruslan corrected me, no partial state can be observed though.

Ah yes, I hadn't thought of that.

So now, in order to have my class be over-achievingly thread safe, I need to replace my synchronized methods with a latch that waits for construction to finish and *then* a synchronized (this) {...}. But I probably decide that this is really going far out of my way to support a bad usage pattern, so I throw up my arms and say "you'll see either totally blank or post-initialization state, but not partial initialization."  But that means I have to guard against uninitialized state in each method, so I probably throw up my arms again and say "just publish the darn object safely!"  And then the JLS people come to me and say, "well if that's your requirement, why do you want a synchronized constructor?"  And suddenly the whole thing makes sense.

This has been an interesting discussion for me! Thanks everyone. :)

-Yuval
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/3f5d49c6/attachment.html>

From davidcholmes at aapt.net.au  Fri Dec 16 20:52:06 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 17 Dec 2011 11:52:06 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
> If the reference is unsafely published, another thread can get the
> reference early; it then calls an instance method which may obtain the
> lock before the creation thread can obtain the lock for the
> constructor. Therefore the other thread can observe the blank state.
> As Ruslan corrected me, no partial state can be observed though.

The only way this can happen, if you synchronize the whole constructor body,
is if a super class constructor does the unsafe publishing. But in that case
there is no such thing as safe-publishing because the object can escape
before the subclass constructor does any initialization.

To summarize a long and garbled thread. If the constructor body is
synchronized, there is no accessible state and all methods are synchronized,
then no external user of the class can publish a reference in a way that is
unsafe. If the constructor does the publishing within the synchronized
block, it is still safe. Only if the superclass does it can it possibly be
unsafe.

Also to address an other point: lock elision is allowed (eg using escape
analysis) but the memory synchronization effects must remain (you can lose
enforced mutual exclusion [as you don't need it], but not happens-before
edges).

Constructors can't be synchronized simply because back in 1995 no one
realized there could be a need for it. It can be mostly worked around by
using a synchronized block. But you can't synchronize the invocation of the
super constructor.

End of story :)

Cheers,
David


From yshavit at akiban.com  Fri Dec 16 22:51:31 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Fri, 16 Dec 2011 22:51:31 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>
References: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAC2Zdp0jhbTekPXG7OvjZxC1zS0qLWSabteKt_SzYN=Qp9D-0A@mail.gmail.com>

I think you can ensure the ctor has finished even in the face of the
unsafest of unsafe sharing, just not with a synchronized block -- you just
need to set some sort of barrier. A CountDownLatch would do it, but
probably simpler would be a volatile boolean isInitialized. Set that to
true as the last action of your constructor, and check that it's true as
the first action of every subsequent method. I wonder if this would be an
appropriate time for a spin -- while (!isInitialized) {} -- since you
expect that in 99.9% of cases you'll loop 0 times, and in that rare case of
a safely unpublished reference being reordered relative to the constructor,
you might spin once or twice.

Of course, to do that, you would have to check isInitialized at the start
of *every* method. That implies your class (or at least all its method) has
to be final, or subclasses could easily break that invariant.

On Fri, Dec 16, 2011 at 8:52 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> Zhong Yu writes:
> > If the reference is unsafely published, another thread can get the
> > reference early; it then calls an instance method which may obtain the
> > lock before the creation thread can obtain the lock for the
> > constructor. Therefore the other thread can observe the blank state.
> > As Ruslan corrected me, no partial state can be observed though.
>
> The only way this can happen, if you synchronize the whole constructor
> body,
> is if a super class constructor does the unsafe publishing. But in that
> case
> there is no such thing as safe -publishing because the object can escape
> before the subclass constructor does any initialization.
>
> To summarize a long and garbled thread. If the constructor body is
> synchronized, there is no accessible state and all methods are
> synchronized,
> then no external user of the class can publish a reference in a way that is
> unsafe. If the constructor does the publishing within the synchronized
> block, it is still safe. Only if the superclass does it can it possibly be
> unsafe.
>
> Also to address an other point: lock elision is allowed (eg using escape
> analysis) but the memory synchronization effects must remain (you can lose
> enforced mutual exclusion [as you don't need it], but not happens-before
> edges).
>
> Constructors can't be synchronized simply because back in 1995 no one
> realized there could be a need for it. It can be mostly worked around by
> using a synchronized block. But you can't synchronize the invocation of the
> super constructor.
>
> End of story :)
>
> Cheers,
> David
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111216/d8255a5d/attachment-0001.html>

From zhong.j.yu at gmail.com  Sat Dec 17 00:11:25 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 16 Dec 2011 23:11:25 -0600
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>
References: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>

Suppose constructor java.util.Vector() is synchronized

    static Vector v;

    // thread 1
    v = new Vector();

    // thread 2
    Vector r = v;
    if(r!=null)
      r.add(x);

The last line can throw exception, because thread 2 can observe the
blank state of the object, yet Vector.add() presumes a
post-construction state.

Zhong Yu

On Fri, Dec 16, 2011 at 7:52 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Zhong Yu writes:
>> If the reference is unsafely published, another thread can get the
>> reference early; it then calls an instance method which may obtain the
>> lock before the creation thread can obtain the lock for the
>> constructor. Therefore the other thread can observe the blank state.
>> As Ruslan corrected me, no partial state can be observed though.
>
> The only way this can happen, if you synchronize the whole constructor body,
> is if a super class constructor does the unsafe publishing. But in that case
> there is no such thing as safe-publishing because the object can escape
> before the subclass constructor does any initialization.
>
> To summarize a long and garbled thread. If the constructor body is
> synchronized, there is no accessible state and all methods are synchronized,
> then no external user of the class can publish a reference in a way that is
> unsafe. If the constructor does the publishing within the synchronized
> block, it is still safe. Only if the superclass does it can it possibly be
> unsafe.
>
> Also to address an other point: lock elision is allowed (eg using escape
> analysis) but the memory synchronization effects must remain (you can lose
> enforced mutual exclusion [as you don't need it], but not happens-before
> edges).
>
> Constructors can't be synchronized simply because back in 1995 no one
> realized there could be a need for it. It can be mostly worked around by
> using a synchronized block. But you can't synchronize the invocation of the
> super constructor.
>
> End of story :)
>
> Cheers,
> David
>

From vitalyd at gmail.com  Sat Dec 17 01:32:18 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sat, 17 Dec 2011 01:32:18 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>
References: <CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEOOJBAA.davidcholmes@aapt.net.au>
	<CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>
Message-ID: <CAHjP37EesWkS5crU+qARnnv6_6SyGvjAWRB_prWkp2xGDQ3BXg@mail.gmail.com>

It cannot.  Let me try to explain ...

If we inline the constructor, then that sequence looks like this:
Vector tmp = alloc();
lock(tmp);
// some state initialization here ...
unlock(tmp);
v = tmp;

By roach motel semantics, v = tmp is a normal write, so it can move inside
the critical section.  lock(), however, has volatile read like semantics,
which means nothing after it can move before it, so we know v = tmp cannot
move above lock(), so it stays somewhere inside the critical section.  So
now we have two outcomes:

1.  v = tmp moved inside the critical section
2.  v = tmp stayed after the lock was released

Since Vector.add() is synchronized on itself, if #1 happens, add() blocks
and once it acquires the lock, it's guaranteed to see the writes.  If #2
happens, it's fine too since that's your regular lock scenario.

On Sat, Dec 17, 2011 at 12:11 AM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> Suppose constructor java.util.Vector() is synchronized
>
>    static Vector v;
>
>    // thread 1
>    v = new Vector();
>
>    // thread 2
>    Vector r = v;
>    if(r!=null)
>      r.add(x);
>
> The last line can throw exception, because thread 2 can observe the
> blank state of the object, yet Vector.add() presumes a
> post-construction state.
>
> Zhong Yu
>
> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> > Zhong Yu writes:
> >> If the reference is unsafely published, another thread can get the
> >> reference early; it then calls an instance method which may obtain the
> >> lock before the creation thread can obtain the lock for the
> >> constructor. Therefore the other thread can observe the blank state.
> >> As Ruslan corrected me, no partial state can be observed though.
> >
> > The only way this can happen, if you synchronize the whole constructor
> body,
> > is if a super class constructor does the unsafe publishing. But in that
> case
> > there is no such thing as safe-publishing because the object can escape
> > before the subclass constructor does any initialization.
> >
> > To summarize a long and garbled thread. If the constructor body is
> > synchronized, there is no accessible state and all methods are
> synchronized,
> > then no external user of the class can publish a reference in a way that
> is
> > unsafe. If the constructor does the publishing within the synchronized
> > block, it is still safe. Only if the superclass does it can it possibly
> be
> > unsafe.
> >
> > Also to address an other point: lock elision is allowed (eg using escape
> > analysis) but the memory synchronization effects must remain (you can
> lose
> > enforced mutual exclusion [as you don't need it], but not happens-before
> > edges).
> >
> > Constructors can't be synchronized simply because back in 1995 no one
> > realized there could be a need for it. It can be mostly worked around by
> > using a synchronized block. But you can't synchronize the invocation of
> the
> > super constructor.
> >
> > End of story :)
> >
> > Cheers,
> > David
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/765dc043/attachment.html>

From hans.boehm at hp.com  Sat Dec 17 02:29:23 2011
From: hans.boehm at hp.com (Boehm, Hans)
Date: Sat, 17 Dec 2011 07:29:23 +0000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD20D5F11@G4W3299.americas.hpqcorp.net>
References: <CAC2Zdp3_KFga6hyMzKtDww4gNGgc4jO1Uy-vNjaEVkwEnLZQig@mail.gmail.com>
	<CACuKZqFpxVutmgrk6pPaU97MLGG+iFMAtu0F5w0M6W9oVD1p1w@mail.gmail.com>
	<5AE501BD-18AB-41C2-8F5D-6D995CD2B83B@rkuhn.info>
	<9319F360221C65428EA819A4E8DC34ED037966AAAF@OPMBOX21UK.options-it.com>
	<08F07B8B-F044-4160-B69A-F7CE7D07C57E@rkuhn.info>
	<CAOwENiKeAStTDxocoC1M_aBo__MQxV3+P-9-FAvTr3eQYsF-aQ@mail.gmail.com>
	<AD0C68FA-5044-4B28-BFC3-4544BB815D46@rkuhn.info>
	<CAOwENi+1s7JLd5F4v=T3xBdXGk_dPVd9_rgx6e82iybL5tSzXg@mail.gmail.com>
	<DEC34F1E-7D37-4ACD-803E-BDAC4FF5F540@rkuhn.info>
	<CAOwENi+FJTfi-LPO3cW-ntpU_hvi6J8-r-T_OhdfsPweDx8VVA@mail.gmail.com>
	<CAC2Zdp1XRbnmoe=CWAUJN_JRiy0FuzLbm8fyPG5hvpSGf3YqMQ@mail.gmail.com>
	<CACuKZqG8HvZ5ZB1ZrLuj_e3byOsVGcT=oqmtcWeUtpBB4Uheqw@mail.gmail.com>
	<CAC2Zdp0oZyy4Y4wVi8_z=pSBThzCzRmv4-crh+Y-uZCQKn8cKQ@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D59D8@G4W3299.americas.hpqcorp.net>
	<5F6252CB-94B7-43AD-8842-D06450D4EE6E@rkuhn.info>
	<A3E67C2071F49C4CBC4F17E6D77CDDD20D5F11@G4W3299.americas.hpqcorp.net>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD20D603E@G4W3299.americas.hpqcorp.net>

As others have indirectly pointed out, my answers and concerns here were of course wrong.  So long as the racy publication happens after the object is initialized, and all accesses including the constructor are synchronized, you should be fine.  If another synchronized method runs e.g. before the constructor critical section, it can't possibly see the published reference, even if it's published through an ordinary variable.  The lock ensures that the publication happens after the other access.

I should have spent a bit more time thinking about this.  This stuff is confusing ...

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Boehm, Hans
Sent: Friday, December 16, 2011 5:02 PM
To: Roland Kuhn
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] synchronized constructors

Interesting question, though I'm not sure I understand the problem correctly.  It seems to me that synchronized(this) in the constructor, and a synchronized second initialization phase ensure that all clients see either one of

1) the zero initialized object
2) the fully constructed object, pre-phase-2 initialization object, or
3) the fully initialized object

I don't see any way to prevent untrusted code running in multiple other threads from getting a hold of a reference to the object without establishing a happens-before relationship to ensure that it sees the object fully initialized.  Thus to be fully safe, I suspect other methods have to be prepared to find an object in any of those states.  Presumably they could explicitly check which one applies.  That doesn't seem like an entirely satisfactory answer, but ...

Hans

From: Roland Kuhn [mailto:rk at rkuhn.info]<mailto:[mailto:rk at rkuhn.info]>
Sent: Friday, December 16, 2011 2:53 PM
To: Boehm, Hans
Cc: Yuval Shavit; Zhong Yu; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] synchronized constructors

This sounds like it is impossible to construct a mutable object in a way so that it is immune against improper publication. If the aforementioned is wrong-which I hope-then would you please tell me what the cheapest way is of achieving this goal? One thing I could think of is just putting all non-final fields in another class and have a reference to that be held in a final field; if this works, it would be quite expensive, so any better solution would be welcome.

You might ask, why have a non-final field without proper synchronization, so let me add that the background to this question is that in my case the construction of the object needs to proceed in two phases because of other inter-dependencies, which requires certain fields to be written to after the constructor has finished; they will be written to only exactly once, and this happens before "untrusted" client code obtains the reference (in program order).

Thanks in advance,

Roland

On Dec 16, 2011, at 22:49 , Boehm, Hans wrote:

Just to be clear: Safe publication for final fields requires that you do not make a pointer to the object available to other threads (publish it) before the constructor finishes.  "Safe publication" as used below is a slightly stronger property; you also should not communicate the pointer post-construction to another thread via a data race.  Avoiding them both is great advice, but the second one may be difficult to avoid if you need to give a reference to your object to code you don't trust.  Malicious code could always pass the object to a third thread through a race, hoping that the third thread, which has no happens-before relationship to the other two, would find your object in an inconsistent state.  My intuition is that this is a rare case, but one that does occur.  When it does occur, the odds of an actual security hole are probably small, but so are the odds of proving security properties without addressing the issue.

Hans

From: concurrency-interest-bounces at cs.oswego.edu<mailto:concurrency-interest-bounces at cs.oswego.edu> [mailto:concurrency-interest-bounces at cs.oswego.edu]<mailto:[mailto:concurrency-interest-bounces at cs.oswego.edu]> On Behalf Of Yuval Shavit
Sent: Friday, December 16, 2011 11:59 AM
To: Zhong Yu
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] synchronized constructors

On Fri, Dec 16, 2011 at 2:10 PM, Zhong Yu <zhong.j.yu at gmail.com<mailto:zhong.j.yu at gmail.com>> wrote:
On Fri, Dec 16, 2011 at 8:38 AM, Yuval Shavit <yshavit at akiban.com<mailto:yshavit at akiban.com>> wrote:
> Several people have made the claim that you could see partially initialized
> state even if the constructor were synchronized, and I don't see how this
> could be. Yes, you could assign MyPoint myUnsafeRef before MyPoint()
> finishes -- but if you ever tried to *use* myUnsafeRef, you would run into a
> synchronized block which would then ensure that the constructor
> happened-before whatever method you're writing. Seems to me you should see
> the fully-thread-safe, not-partially-initialized object at that point.
If the reference is unsafely published, another thread can get the
reference early; it then calls an instance method which may obtain the
lock before the creation thread can obtain the lock for the
constructor. Therefore the other thread can observe the blank state.
As Ruslan corrected me, no partial state can be observed though.

Ah yes, I hadn't thought of that.

So now, in order to have my class be over-achievingly thread safe, I need to replace my synchronized methods with a latch that waits for construction to finish and *then* a synchronized (this) {...}. But I probably decide that this is really going far out of my way to support a bad usage pattern, so I throw up my arms and say "you'll see either totally blank or post-initialization state, but not partial initialization."  But that means I have to guard against uninitialized state in each method, so I probably throw up my arms again and say "just publish the darn object safely!"  And then the JLS people come to me and say, "well if that's your requirement, why do you want a synchronized constructor?"  And suddenly the whole thing makes sense.

This has been an interesting discussion for me! Thanks everyone. :)

-Yuval
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
[scala-debate on 2009/10/2]
Viktor Klang: When will the days of numerical overflow be gone?
Ricky Clarkson: One second after 03:14:07 UTC on Tuesday, 19 January 2038

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/66be0732/attachment-0001.html>

From davidcholmes at aapt.net.au  Sat Dec 17 03:49:30 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 17 Dec 2011 18:49:30 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPAJBAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
> Suppose constructor java.util.Vector() is synchronized
>
>     static Vector v;
>
>     // thread 1
>     v = new Vector();
>
>     // thread 2
>     Vector r = v;
>     if(r!=null)
>       r.add(x);
>
> The last line can throw exception, because thread 2 can observe the
> blank state of the object

No it can not. Completion of the constructor happens-before the reference is
published. The acquiring of the monitor in add() can only happen when the
monitor is released by the constructor. The release of the monitor in thread
1 happens-before the acquire of the monitor by thread 2. All the constructor
actions happen-before the release of the monitor.

The publishing of the Vector can not be moved prior to the acquisition of
the monitor in the constructor ("roach motel semantics").

David
-----


> , yet Vector.add() presumes a> post-construction state.

> Zhong Yu
>
> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > Zhong Yu writes:
> >> If the reference is unsafely published, another thread can get the
> >> reference early; it then calls an instance method which may obtain the
> >> lock before the creation thread can obtain the lock for the
> >> constructor. Therefore the other thread can observe the blank state.
> >> As Ruslan corrected me, no partial state can be observed though.
> >
> > The only way this can happen, if you synchronize the whole
> constructor body,
> > is if a super class constructor does the unsafe publishing. But
> in that case
> > there is no such thing as safe-publishing because the object can escape
> > before the subclass constructor does any initialization.
> >
> > To summarize a long and garbled thread. If the constructor body is
> > synchronized, there is no accessible state and all methods are
> synchronized,
> > then no external user of the class can publish a reference in a
> way that is
> > unsafe. If the constructor does the publishing within the synchronized
> > block, it is still safe. Only if the superclass does it can it
> possibly be
> > unsafe.
> >
> > Also to address an other point: lock elision is allowed (eg using escape
> > analysis) but the memory synchronization effects must remain
> (you can lose
> > enforced mutual exclusion [as you don't need it], but not happens-before
> > edges).
> >
> > Constructors can't be synchronized simply because back in 1995 no one
> > realized there could be a need for it. It can be mostly worked around by
> > using a synchronized block. But you can't synchronize the
> invocation of the
> > super constructor.
> >
> > End of story :)
> >
> > Cheers,
> > David
> >
>


From davidcholmes at aapt.net.au  Sat Dec 17 03:57:30 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 17 Dec 2011 18:57:30 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEPAJBAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEPBJBAA.davidcholmes@aapt.net.au>

Correction ...
I wrote:
> Zhong Yu writes:
> > Suppose constructor java.util.Vector() is synchronized
> >
> >     static Vector v;
> >
> >     // thread 1
> >     v = new Vector();
> >
> >     // thread 2
> >     Vector r = v;
> >     if(r!=null)
> >       r.add(x);
> >
> > The last line can throw exception, because thread 2 can observe the
> > blank state of the object
>
> No it can not.
> Completion of the constructor happens-before the reference is published.

Delete this sentence. It's wrong but not relevant to the argument.

David
-----


> The acquiring of the monitor in add() can only happen when the
> monitor is released by the constructor. The release of the
> monitor in thread
> 1 happens-before the acquire of the monitor by thread 2. All the
> constructor
> actions happen-before the release of the monitor.
>
> The publishing of the Vector can not be moved prior to the acquisition of
> the monitor in the constructor ("roach motel semantics").
>
> David
> -----
>
>
> > , yet Vector.add() presumes a> post-construction state.
>
> > Zhong Yu
> >
> > On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> > <davidcholmes at aapt.net.au> wrote:
> > > Zhong Yu writes:
> > >> If the reference is unsafely published, another thread can get the
> > >> reference early; it then calls an instance method which may
> obtain the
> > >> lock before the creation thread can obtain the lock for the
> > >> constructor. Therefore the other thread can observe the blank state.
> > >> As Ruslan corrected me, no partial state can be observed though.
> > >
> > > The only way this can happen, if you synchronize the whole
> > constructor body,
> > > is if a super class constructor does the unsafe publishing. But
> > in that case
> > > there is no such thing as safe-publishing because the object
> can escape
> > > before the subclass constructor does any initialization.
> > >
> > > To summarize a long and garbled thread. If the constructor body is
> > > synchronized, there is no accessible state and all methods are
> > synchronized,
> > > then no external user of the class can publish a reference in a
> > way that is
> > > unsafe. If the constructor does the publishing within the synchronized
> > > block, it is still safe. Only if the superclass does it can it
> > possibly be
> > > unsafe.
> > >
> > > Also to address an other point: lock elision is allowed (eg
> using escape
> > > analysis) but the memory synchronization effects must remain
> > (you can lose
> > > enforced mutual exclusion [as you don't need it], but not
> happens-before
> > > edges).
> > >
> > > Constructors can't be synchronized simply because back in 1995 no one
> > > realized there could be a need for it. It can be mostly
> worked around by
> > > using a synchronized block. But you can't synchronize the
> > invocation of the
> > > super constructor.
> > >
> > > End of story :)
> > >
> > > Cheers,
> > > David
> > >
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From zhong.j.yu at gmail.com  Sat Dec 17 04:47:17 2011
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sat, 17 Dec 2011 03:47:17 -0600
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEPAJBAA.davidcholmes@aapt.net.au>
References: <CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEPAJBAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqHufsA432hAG-1ju6dpk6bPyPJL=veXrAcQT6oqxUc+9Q@mail.gmail.com>

You guys are totally right, thanks. I apologize, especially to Yuval.

For the execution I described to occur where blank state is observed
by thread 2, sync{} in thread 2 must be ordered before sync{} in
thread 1; this makes read(v) in thread 2 happens-before write(v) in
thread 1. The execution also has the read see the write. Therefore the
execution is not "happens-before consistent", therefore not
well-formed.

Zhong Yu

On Sat, Dec 17, 2011 at 2:49 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Zhong Yu writes:
>> Suppose constructor java.util.Vector() is synchronized
>>
>> ? ? static Vector v;
>>
>> ? ? // thread 1
>> ? ? v = new Vector();
>>
>> ? ? // thread 2
>> ? ? Vector r = v;
>> ? ? if(r!=null)
>> ? ? ? r.add(x);
>>
>> The last line can throw exception, because thread 2 can observe the
>> blank state of the object
>
> No it can not. Completion of the constructor happens-before the reference is
> published. The acquiring of the monitor in add() can only happen when the
> monitor is released by the constructor. The release of the monitor in thread
> 1 happens-before the acquire of the monitor by thread 2. All the constructor
> actions happen-before the release of the monitor.
>
> The publishing of the Vector can not be moved prior to the acquisition of
> the monitor in the constructor ("roach motel semantics").
>
> David
> -----
>
>
>> , yet Vector.add() presumes a> post-construction state.
>
>> Zhong Yu
>>
>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
>> <davidcholmes at aapt.net.au> wrote:
>> > Zhong Yu writes:
>> >> If the reference is unsafely published, another thread can get the
>> >> reference early; it then calls an instance method which may obtain the
>> >> lock before the creation thread can obtain the lock for the
>> >> constructor. Therefore the other thread can observe the blank state.
>> >> As Ruslan corrected me, no partial state can be observed though.
>> >
>> > The only way this can happen, if you synchronize the whole
>> constructor body,
>> > is if a super class constructor does the unsafe publishing. But
>> in that case
>> > there is no such thing as safe-publishing because the object can escape
>> > before the subclass constructor does any initialization.
>> >
>> > To summarize a long and garbled thread. If the constructor body is
>> > synchronized, there is no accessible state and all methods are
>> synchronized,
>> > then no external user of the class can publish a reference in a
>> way that is
>> > unsafe. If the constructor does the publishing within the synchronized
>> > block, it is still safe. Only if the superclass does it can it
>> possibly be
>> > unsafe.
>> >
>> > Also to address an other point: lock elision is allowed (eg using escape
>> > analysis) but the memory synchronization effects must remain
>> (you can lose
>> > enforced mutual exclusion [as you don't need it], but not happens-before
>> > edges).
>> >
>> > Constructors can't be synchronized simply because back in 1995 no one
>> > realized there could be a need for it. It can be mostly worked around by
>> > using a synchronized block. But you can't synchronize the
>> invocation of the
>> > super constructor.
>> >
>> > End of story :)
>> >
>> > Cheers,
>> > David
>> >
>>
>


From yshavit at akiban.com  Sat Dec 17 08:35:15 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Sat, 17 Dec 2011 08:35:15 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CACuKZqHufsA432hAG-1ju6dpk6bPyPJL=veXrAcQT6oqxUc+9Q@mail.gmail.com>
References: <CACuKZqEP5wrW-Y5BOfLS6RP-2VdJnyO7a_mOgpRzc0KThE9GQQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCGEPAJBAA.davidcholmes@aapt.net.au>
	<CACuKZqHufsA432hAG-1ju6dpk6bPyPJL=veXrAcQT6oqxUc+9Q@mail.gmail.com>
Message-ID: <CAC2Zdp1tUjkTuRogBObELPrS=i0qfBCt_J+PGp98gOe-kEfTqQ@mail.gmail.com>

No need to apologize to me! But in that case, it gets us back to a
synchronized constructor being possibly useful, iff we want to easily
support the "unsafe publication via un-volatile static reference" pattern.
Which I'm not at all saying we do want to do. :)

On Sat, Dec 17, 2011 at 4:47 AM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> You guys are totally right, thanks. I apologize, especially to Yuval.
>
> For the execution I described to occur where blank state is observed
> by thread 2, sync{} in thread 2 must be ordered before sync{} in
> thread 1; this makes read(v) in thread 2 happens-before write(v) in
> thread 1. The execution also has the read see the write. Therefore the
> execution is not "happens-before consistent", therefore not
> well-formed.
>
> Zhong Yu
>
> On Sat, Dec 17, 2011 at 2:49 AM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> > Zhong Yu writes:
> >> Suppose constructor java.util.Vector() is synchronized
> >>
> >>     static Vector v;
> >>
> >>     // thread 1
> >>     v = new Vector();
> >>
> >>     // thread 2
> >>     Vector r = v;
> >>     if(r!=null)
> >>       r.add(x);
> >>
> >> The last line can throw exception, because thread 2 can observe the
> >> blank state of the object
> >
> > No it can not. Completion of the constructor happens-before the
> reference is
> > published. The acquiring of the monitor in add() can only happen when the
> > monitor is released by the constructor. The release of the monitor in
> thread
> > 1 happens-before the acquire of the monitor by thread 2. All the
> constructor
> > actions happen-before the release of the monitor.
> >
> > The publishing of the Vector can not be moved prior to the acquisition of
> > the monitor in the constructor ("roach motel semantics").
> >
> > David
> > -----
> >
> >
> >> , yet Vector.add() presumes a> post-construction state.
> >
> >> Zhong Yu
> >>
> >> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> >> <davidcholmes at aapt.net.au> wrote:
> >> > Zhong Yu writes:
> >> >> If the reference is unsafely published, another thread can get the
> >> >> reference early; it then calls an instance method which may obtain
> the
> >> >> lock before the creation thread can obtain the lock for the
> >> >> constructor. Therefore the other thread can observe the blank state.
> >> >> As Ruslan corrected me, no partial state can be observed though.
> >> >
> >> > The only way this can happen, if you synchronize the whole
> >> constructor body,
> >> > is if a super class constructor does the unsafe publishing. But
> >> in that case
> >> > there is no such thing as safe-publishing because the object can
> escape
> >> > before the subclass constructor does any initialization.
> >> >
> >> > To summarize a long and garbled thread. If the constructor body is
> >> > synchronized, there is no accessible state and all methods are
> >> synchronized,
> >> > then no external user of the class can publish a reference in a
> >> way that is
> >> > unsafe. If the constructor does the publishing within the synchronized
> >> > block, it is still safe. Only if the superclass does it can it
> >> possibly be
> >> > unsafe.
> >> >
> >> > Also to address an other point: lock elision is allowed (eg using
> escape
> >> > analysis) but the memory synchronization effects must remain
> >> (you can lose
> >> > enforced mutual exclusion [as you don't need it], but not
> happens-before
> >> > edges).
> >> >
> >> > Constructors can't be synchronized simply because back in 1995 no one
> >> > realized there could be a need for it. It can be mostly worked around
> by
> >> > using a synchronized block. But you can't synchronize the
> >> invocation of the
> >> > super constructor.
> >> >
> >> > End of story :)
> >> >
> >> > Cheers,
> >> > David
> >> >
> >>
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/e9548877/attachment.html>

From rk at rkuhn.info  Sat Dec 17 10:46:26 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sat, 17 Dec 2011 16:46:26 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEPBJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEPBJBAA.davidcholmes@aapt.net.au>
Message-ID: <412C5CB1-7BFA-47F4-8A74-928C216AF0DD@rkuhn.info>

Thank you, David and Hans, for clarifying these semantics. The OP?s question has been answered, and I think I can also derive an answer for my question. I?ll try to wrap it up below, please correct or confirm:

class IAmSafe {
  private volatile int x;
  IAmSafe() {
    x = 5;
    synchronized(this) {}
  }
  public int getX() {
    return x;
  }
}

Assuming that the java.lang.Object constructor is well-behaved, it should be impossible under any circumstances (barring reflective modification) that a call to getX() returns anything but 5, right?

If this is true, then the cheapest solution to my multi-stage construction problem?where I completely control the program flow up to the point where I consider the object initialization finished?on x86 processors looks like this:

class ComplexDeps {
  final int someValue;
  ComplexDeps(int someValue) {
    this.someValue = someValue;
  }
  // stage 2
  private volatile OtherThing thing;
  public void init(OtherThing thing) {
    this.thing = thing;
    synchronized {}
  }
  // other stuff which reads someValue & ?thing?, never writes to ?thing? and runs only after init() in program order
}

IIUC, there will be a (half-way) expensive fence-like instruction emitted at the end of init(), but apart from that all read accesses after construction should be cheap. Any nobody will ever see ?thing? uninitialized.

Regards,

Roland

On Dec 17, 2011, at 09:57 , David Holmes wrote:

> Correction ...
> I wrote:
>> Zhong Yu writes:
>>> Suppose constructor java.util.Vector() is synchronized
>>> 
>>>    static Vector v;
>>> 
>>>    // thread 1
>>>    v = new Vector();
>>> 
>>>    // thread 2
>>>    Vector r = v;
>>>    if(r!=null)
>>>      r.add(x);
>>> 
>>> The last line can throw exception, because thread 2 can observe the
>>> blank state of the object
>> 
>> No it can not.
>> Completion of the constructor happens-before the reference is published.
> 
> Delete this sentence. It's wrong but not relevant to the argument.
> 
> David
> -----
> 
> 
>> The acquiring of the monitor in add() can only happen when the
>> monitor is released by the constructor. The release of the
>> monitor in thread
>> 1 happens-before the acquire of the monitor by thread 2. All the
>> constructor
>> actions happen-before the release of the monitor.
>> 
>> The publishing of the Vector can not be moved prior to the acquisition of
>> the monitor in the constructor ("roach motel semantics").
>> 
>> David
>> -----
>> 
>> 
>>> , yet Vector.add() presumes a> post-construction state.
>> 
>>> Zhong Yu
>>> 
>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
>>> <davidcholmes at aapt.net.au> wrote:
>>>> Zhong Yu writes:
>>>>> If the reference is unsafely published, another thread can get the
>>>>> reference early; it then calls an instance method which may
>> obtain the
>>>>> lock before the creation thread can obtain the lock for the
>>>>> constructor. Therefore the other thread can observe the blank state.
>>>>> As Ruslan corrected me, no partial state can be observed though.
>>>> 
>>>> The only way this can happen, if you synchronize the whole
>>> constructor body,
>>>> is if a super class constructor does the unsafe publishing. But
>>> in that case
>>>> there is no such thing as safe-publishing because the object
>> can escape
>>>> before the subclass constructor does any initialization.
>>>> 
>>>> To summarize a long and garbled thread. If the constructor body is
>>>> synchronized, there is no accessible state and all methods are
>>> synchronized,
>>>> then no external user of the class can publish a reference in a
>>> way that is
>>>> unsafe. If the constructor does the publishing within the synchronized
>>>> block, it is still safe. Only if the superclass does it can it
>>> possibly be
>>>> unsafe.
>>>> 
>>>> Also to address an other point: lock elision is allowed (eg
>> using escape
>>>> analysis) but the memory synchronization effects must remain
>>> (you can lose
>>>> enforced mutual exclusion [as you don't need it], but not
>> happens-before
>>>> edges).
>>>> 
>>>> Constructors can't be synchronized simply because back in 1995 no one
>>>> realized there could be a need for it. It can be mostly
>> worked around by
>>>> using a synchronized block. But you can't synchronize the
>>> invocation of the
>>>> super constructor.
>>>> 
>>>> End of story :)
>>>> 
>>>> Cheers,
>>>> David
>>>> 
>>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra



From forax at univ-mlv.fr  Sat Dec 17 13:33:48 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Sat, 17 Dec 2011 19:33:48 +0100
Subject: [concurrency-interest] JSR 292 Goodness: Almost static final field
Message-ID: <4EECE08C.3020203@univ-mlv.fr>

I've written a blog entry about how to write a static volatile final 
variable, i.e. a variable which is considered as constant
by the compiler (the JIT) and if the variable changes, the JITed code is 
deoptimized and
jump back in interpreter mode to eventually optimize it again later.

http://weblogs.java.net/blog/forax/archive/2011/12/17/jsr-292-goodness-almost-static-final-field

The code is a little bit more convoluted than it should because there is 
no invokedynamic
in Java but you can emulate it.

R?mi


From davidcholmes at aapt.net.au  Sat Dec 17 18:40:26 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sun, 18 Dec 2011 09:40:26 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <412C5CB1-7BFA-47F4-8A74-928C216AF0DD@rkuhn.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>

Roland,

An empty synchronized block in a constructor, when there are no other
synchronized regions of code, gains you nothing under the JMM as there are
no happens-before edges established. Are you
relying on the implementation of synchronized to issue specific memory
barriers here?

David

> -----Original Message-----
> From: Roland Kuhn [mailto:rk at rkuhn.info]
> Sent: Sunday, 18 December 2011 1:46 AM
> To: dholmes at ieee.org
> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] synchronized constructors
>
>
> Thank you, David and Hans, for clarifying these semantics. The
> OP?s question has been answered, and I think I can also derive an
> answer for my question. I?ll try to wrap it up below, please
> correct or confirm:
>
> class IAmSafe {
>   private volatile int x;
>   IAmSafe() {
>     x = 5;
>     synchronized(this) {}
>   }
>   public int getX() {
>     return x;
>   }
> }
>
> Assuming that the java.lang.Object constructor is well-behaved,
> it should be impossible under any circumstances (barring
> reflective modification) that a call to getX() returns anything
> but 5, right?
>
> If this is true, then the cheapest solution to my multi-stage
> construction problem?where I completely control the program flow
> up to the point where I consider the object initialization
> finished?on x86 processors looks like this:
>
> class ComplexDeps {
>   final int someValue;
>   ComplexDeps(int someValue) {
>     this.someValue = someValue;
>   }
>   // stage 2
>   private volatile OtherThing thing;
>   public void init(OtherThing thing) {
>     this.thing = thing;
>     synchronized {}
>   }
>   // other stuff which reads someValue & ?thing?, never writes to
> ?thing? and runs only after init() in program order
> }
>
> IIUC, there will be a (half-way) expensive fence-like instruction
> emitted at the end of init(), but apart from that all read
> accesses after construction should be cheap. Any nobody will ever
> see ?thing? uninitialized.
>
> Regards,
>
> Roland
>
> On Dec 17, 2011, at 09:57 , David Holmes wrote:
>
> > Correction ...
> > I wrote:
> >> Zhong Yu writes:
> >>> Suppose constructor java.util.Vector() is synchronized
> >>>
> >>>    static Vector v;
> >>>
> >>>    // thread 1
> >>>    v = new Vector();
> >>>
> >>>    // thread 2
> >>>    Vector r = v;
> >>>    if(r!=null)
> >>>      r.add(x);
> >>>
> >>> The last line can throw exception, because thread 2 can observe the
> >>> blank state of the object
> >>
> >> No it can not.
> >> Completion of the constructor happens-before the reference is
> published.
> >
> > Delete this sentence. It's wrong but not relevant to the argument.
> >
> > David
> > -----
> >
> >
> >> The acquiring of the monitor in add() can only happen when the
> >> monitor is released by the constructor. The release of the
> >> monitor in thread
> >> 1 happens-before the acquire of the monitor by thread 2. All the
> >> constructor
> >> actions happen-before the release of the monitor.
> >>
> >> The publishing of the Vector can not be moved prior to the
> acquisition of
> >> the monitor in the constructor ("roach motel semantics").
> >>
> >> David
> >> -----
> >>
> >>
> >>> , yet Vector.add() presumes a> post-construction state.
> >>
> >>> Zhong Yu
> >>>
> >>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> >>> <davidcholmes at aapt.net.au> wrote:
> >>>> Zhong Yu writes:
> >>>>> If the reference is unsafely published, another thread can get the
> >>>>> reference early; it then calls an instance method which may
> >> obtain the
> >>>>> lock before the creation thread can obtain the lock for the
> >>>>> constructor. Therefore the other thread can observe the blank state.
> >>>>> As Ruslan corrected me, no partial state can be observed though.
> >>>>
> >>>> The only way this can happen, if you synchronize the whole
> >>> constructor body,
> >>>> is if a super class constructor does the unsafe publishing. But
> >>> in that case
> >>>> there is no such thing as safe-publishing because the object
> >> can escape
> >>>> before the subclass constructor does any initialization.
> >>>>
> >>>> To summarize a long and garbled thread. If the constructor body is
> >>>> synchronized, there is no accessible state and all methods are
> >>> synchronized,
> >>>> then no external user of the class can publish a reference in a
> >>> way that is
> >>>> unsafe. If the constructor does the publishing within the
> synchronized
> >>>> block, it is still safe. Only if the superclass does it can it
> >>> possibly be
> >>>> unsafe.
> >>>>
> >>>> Also to address an other point: lock elision is allowed (eg
> >> using escape
> >>>> analysis) but the memory synchronization effects must remain
> >>> (you can lose
> >>>> enforced mutual exclusion [as you don't need it], but not
> >> happens-before
> >>>> edges).
> >>>>
> >>>> Constructors can't be synchronized simply because back in 1995 no one
> >>>> realized there could be a need for it. It can be mostly
> >> worked around by
> >>>> using a synchronized block. But you can't synchronize the
> >>> invocation of the
> >>>> super constructor.
> >>>>
> >>>> End of story :)
> >>>>
> >>>> Cheers,
> >>>> David
> >>>>
> >>>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> --
> Simplicity and elegance are unpopular because they require hard
> work and discipline to achieve and education to be appreciated.
>   -- Dijkstra
>
>



From yshavit at akiban.com  Sat Dec 17 21:14:56 2011
From: yshavit at akiban.com (Yuval Shavit)
Date: Sat, 17 Dec 2011 21:14:56 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
References: <412C5CB1-7BFA-47F4-8A74-928C216AF0DD@rkuhn.info>
	<NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
Message-ID: <CAC2Zdp2eAaB5XvmPEvS20i3zMZzT7teG6wV531=Yfy3XXa33jA@mail.gmail.com>

That's what I would have thought too, by reading the standard "if a field
is ever guarded by a given monitor, it should always be" advice. But in
this case, I would think roach motel semantics would give you some
benefits. Wouldn't it mean that the write to the reference would have to
happen after the empty synchronized block (and thus after the interesting
bits of the constructor), and that there'd be a happens-before relative to
any subsequent synchronized methods?

On Sat, Dec 17, 2011 at 6:40 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> Roland,
>
> An empty synchronized block in a constructor, when there are no other
> synchronized regions of code, gains you nothing under the JMM as there are
> no happens-before edges established. Are you
> relying on the implementation of synchronized to issue specific memory
> barriers here?
>
> David
>
> > -----Original Message-----
> > From: Roland Kuhn [mailto:rk at rkuhn.info]
> > Sent: Sunday, 18 December 2011 1:46 AM
> > To: dholmes at ieee.org
> > Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] synchronized constructors
> >
> >
> > Thank you, David and Hans, for clarifying these semantics. The
> > OP?s question has been answered, and I think I can also derive an
> > answer for my question. I?ll try to wrap it up below, please
> > correct or confirm:
> >
> > class IAmSafe {
> >   private volatile int x;
> >   IAmSafe() {
> >     x = 5;
> >     synchronized(this) {}
> >   }
> >   public int getX() {
> >     return x;
> >   }
> > }
> >
> > Assuming that the java.lang.Object constructor is well-behaved,
> > it should be impossible under any circumstances (barring
> > reflective modification) that a call to getX() returns anything
> > but 5, right?
> >
> > If this is true, then the cheapest solution to my multi-stage
> > construction problem?where I completely control the program flow
> > up to the point where I consider the object initialization
> > finished?on x86 processors looks like this:
> >
> > class ComplexDeps {
> >   final int someValue;
> >   ComplexDeps(int someValue) {
> >     this.someValue = someValue;
> >   }
> >   // stage 2
> >   private volatile OtherThing thing;
> >   public void init(OtherThing thing) {
> >     this.thing = thing;
> >     synchronized {}
> >   }
> >   // other stuff which reads someValue & ?thing?, never writes to
> > ?thing? and runs only after init() in program order
> > }
> >
> > IIUC, there will be a (half-way) expensive fence-like instruction
> > emitted at the end of init(), but apart from that all read
> > accesses after construction should be cheap. Any nobody will ever
> > see ?thing? uninitialized.
> >
> > Regards,
> >
> > Roland
> >
> > On Dec 17, 2011, at 09:57 , David Holmes wrote:
> >
> > > Correction ...
> > > I wrote:
> > >> Zhong Yu writes:
> > >>> Suppose constructor java.util.Vector() is synchronized
> > >>>
> > >>>    static Vector v;
> > >>>
> > >>>    // thread 1
> > >>>    v = new Vector();
> > >>>
> > >>>    // thread 2
> > >>>    Vector r = v;
> > >>>    if(r!=null)
> > >>>      r.add(x);
> > >>>
> > >>> The last line can throw exception, because thread 2 can observe the
> > >>> blank state of the object
> > >>
> > >> No it can not.
> > >> Completion of the constructor happens-before the reference is
> > published.
> > >
> > > Delete this sentence. It's wrong but not relevant to the argument.
> > >
> > > David
> > > -----
> > >
> > >
> > >> The acquiring of the monitor in add() can only happen when the
> > >> monitor is released by the constructor. The release of the
> > >> monitor in thread
> > >> 1 happens-before the acquire of the monitor by thread 2. All the
> > >> constructor
> > >> actions happen-before the release of the monitor.
> > >>
> > >> The publishing of the Vector can not be moved prior to the
> > acquisition of
> > >> the monitor in the constructor ("roach motel semantics").
> > >>
> > >> David
> > >> -----
> > >>
> > >>
> > >>> , yet Vector.add() presumes a> post-construction state.
> > >>
> > >>> Zhong Yu
> > >>>
> > >>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> > >>> <davidcholmes at aapt.net.au> wrote:
> > >>>> Zhong Yu writes:
> > >>>>> If the reference is unsafely published, another thread can get the
> > >>>>> reference early; it then calls an instance method which may
> > >> obtain the
> > >>>>> lock before the creation thread can obtain the lock for the
> > >>>>> constructor. Therefore the other thread can observe the blank
> state.
> > >>>>> As Ruslan corrected me, no partial state can be observed though.
> > >>>>
> > >>>> The only way this can happen, if you synchronize the whole
> > >>> constructor body,
> > >>>> is if a super class constructor does the unsafe publishing. But
> > >>> in that case
> > >>>> there is no such thing as safe-publishing because the object
> > >> can escape
> > >>>> before the subclass constructor does any initialization.
> > >>>>
> > >>>> To summarize a long and garbled thread. If the constructor body is
> > >>>> synchronized, there is no accessible state and all methods are
> > >>> synchronized,
> > >>>> then no external user of the class can publish a reference in a
> > >>> way that is
> > >>>> unsafe. If the constructor does the publishing within the
> > synchronized
> > >>>> block, it is still safe. Only if the superclass does it can it
> > >>> possibly be
> > >>>> unsafe.
> > >>>>
> > >>>> Also to address an other point: lock elision is allowed (eg
> > >> using escape
> > >>>> analysis) but the memory synchronization effects must remain
> > >>> (you can lose
> > >>>> enforced mutual exclusion [as you don't need it], but not
> > >> happens-before
> > >>>> edges).
> > >>>>
> > >>>> Constructors can't be synchronized simply because back in 1995 no
> one
> > >>>> realized there could be a need for it. It can be mostly
> > >> worked around by
> > >>>> using a synchronized block. But you can't synchronize the
> > >>> invocation of the
> > >>>> super constructor.
> > >>>>
> > >>>> End of story :)
> > >>>>
> > >>>> Cheers,
> > >>>> David
> > >>>>
> > >>>
> > >>
> > >> _______________________________________________
> > >> Concurrency-interest mailing list
> > >> Concurrency-interest at cs.oswego.edu
> > >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> > >>
> > >
> > > _______________________________________________
> > > Concurrency-interest mailing list
> > > Concurrency-interest at cs.oswego.edu
> > > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > --
> > Simplicity and elegance are unpopular because they require hard
> > work and discipline to achieve and education to be appreciated.
> >   -- Dijkstra
> >
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111217/b32d7980/attachment.html>

From rk at rkuhn.info  Sun Dec 18 10:09:33 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sun, 18 Dec 2011 16:09:33 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
Message-ID: <DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>

Yes, inspired by the JSR-133 cookbook I was alluding to roach motel semantics: the synchronized is just there to ensure that the volatile write has happened before the possibly non-volatile write of the newly constructed object?s reference to a possibly shared location is actually performed. This would mean that nobody can obtain a reference before initialization is done. And then I would like to arrive at the conclusion that the volatile read of ?x? from a different thread must synchronize-with the initial write.

Does this work?

Roland

On Dec 18, 2011, at 00:40 , David Holmes wrote:

> Roland,
> 
> An empty synchronized block in a constructor, when there are no other
> synchronized regions of code, gains you nothing under the JMM as there are
> no happens-before edges established. Are you
> relying on the implementation of synchronized to issue specific memory
> barriers here?
> 
> David
> 
>> -----Original Message-----
>> From: Roland Kuhn [mailto:rk at rkuhn.info]
>> Sent: Sunday, 18 December 2011 1:46 AM
>> To: dholmes at ieee.org
>> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] synchronized constructors
>> 
>> 
>> Thank you, David and Hans, for clarifying these semantics. The
>> OP?s question has been answered, and I think I can also derive an
>> answer for my question. I?ll try to wrap it up below, please
>> correct or confirm:
>> 
>> class IAmSafe {
>>  private volatile int x;
>>  IAmSafe() {
>>    x = 5;
>>    synchronized(this) {}
>>  }
>>  public int getX() {
>>    return x;
>>  }
>> }
>> 
>> Assuming that the java.lang.Object constructor is well-behaved,
>> it should be impossible under any circumstances (barring
>> reflective modification) that a call to getX() returns anything
>> but 5, right?
>> 
>> If this is true, then the cheapest solution to my multi-stage
>> construction problem?where I completely control the program flow
>> up to the point where I consider the object initialization
>> finished?on x86 processors looks like this:
>> 
>> class ComplexDeps {
>>  final int someValue;
>>  ComplexDeps(int someValue) {
>>    this.someValue = someValue;
>>  }
>>  // stage 2
>>  private volatile OtherThing thing;
>>  public void init(OtherThing thing) {
>>    this.thing = thing;
>>    synchronized {}
>>  }
>>  // other stuff which reads someValue & ?thing?, never writes to
>> ?thing? and runs only after init() in program order
>> }
>> 
>> IIUC, there will be a (half-way) expensive fence-like instruction
>> emitted at the end of init(), but apart from that all read
>> accesses after construction should be cheap. Any nobody will ever
>> see ?thing? uninitialized.
>> 
>> Regards,
>> 
>> Roland
>> 
>> On Dec 17, 2011, at 09:57 , David Holmes wrote:
>> 
>>> Correction ...
>>> I wrote:
>>>> Zhong Yu writes:
>>>>> Suppose constructor java.util.Vector() is synchronized
>>>>> 
>>>>>   static Vector v;
>>>>> 
>>>>>   // thread 1
>>>>>   v = new Vector();
>>>>> 
>>>>>   // thread 2
>>>>>   Vector r = v;
>>>>>   if(r!=null)
>>>>>     r.add(x);
>>>>> 
>>>>> The last line can throw exception, because thread 2 can observe the
>>>>> blank state of the object
>>>> 
>>>> No it can not.
>>>> Completion of the constructor happens-before the reference is
>> published.
>>> 
>>> Delete this sentence. It's wrong but not relevant to the argument.
>>> 
>>> David
>>> -----
>>> 
>>> 
>>>> The acquiring of the monitor in add() can only happen when the
>>>> monitor is released by the constructor. The release of the
>>>> monitor in thread
>>>> 1 happens-before the acquire of the monitor by thread 2. All the
>>>> constructor
>>>> actions happen-before the release of the monitor.
>>>> 
>>>> The publishing of the Vector can not be moved prior to the
>> acquisition of
>>>> the monitor in the constructor ("roach motel semantics").
>>>> 
>>>> David
>>>> -----
>>>> 
>>>> 
>>>>> , yet Vector.add() presumes a> post-construction state.
>>>> 
>>>>> Zhong Yu
>>>>> 
>>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
>>>>> <davidcholmes at aapt.net.au> wrote:
>>>>>> Zhong Yu writes:
>>>>>>> If the reference is unsafely published, another thread can get the
>>>>>>> reference early; it then calls an instance method which may
>>>> obtain the
>>>>>>> lock before the creation thread can obtain the lock for the
>>>>>>> constructor. Therefore the other thread can observe the blank state.
>>>>>>> As Ruslan corrected me, no partial state can be observed though.
>>>>>> 
>>>>>> The only way this can happen, if you synchronize the whole
>>>>> constructor body,
>>>>>> is if a super class constructor does the unsafe publishing. But
>>>>> in that case
>>>>>> there is no such thing as safe-publishing because the object
>>>> can escape
>>>>>> before the subclass constructor does any initialization.
>>>>>> 
>>>>>> To summarize a long and garbled thread. If the constructor body is
>>>>>> synchronized, there is no accessible state and all methods are
>>>>> synchronized,
>>>>>> then no external user of the class can publish a reference in a
>>>>> way that is
>>>>>> unsafe. If the constructor does the publishing within the
>> synchronized
>>>>>> block, it is still safe. Only if the superclass does it can it
>>>>> possibly be
>>>>>> unsafe.
>>>>>> 
>>>>>> Also to address an other point: lock elision is allowed (eg
>>>> using escape
>>>>>> analysis) but the memory synchronization effects must remain
>>>>> (you can lose
>>>>>> enforced mutual exclusion [as you don't need it], but not
>>>> happens-before
>>>>>> edges).
>>>>>> 
>>>>>> Constructors can't be synchronized simply because back in 1995 no one
>>>>>> realized there could be a need for it. It can be mostly
>>>> worked around by
>>>>>> using a synchronized block. But you can't synchronize the
>>>>> invocation of the
>>>>>> super constructor.
>>>>>> 
>>>>>> End of story :)
>>>>>> 
>>>>>> Cheers,
>>>>>> David
>>>>>> 
>>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> --
>> Simplicity and elegance are unpopular because they require hard
>> work and discipline to achieve and education to be appreciated.
>>  -- Dijkstra
>> 
>> 
> 

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)



From vitalyd at gmail.com  Sun Dec 18 15:42:15 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 18 Dec 2011 15:42:15 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
Message-ID: <CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>

Hi Roland,

I think David's point is that you're relying on implementation details
rather than JMM to ensure correctness.  According to JMM, your code does
not create any happens-before edge because your getX() does not synchronize
on the same lock, so there's no happens-before edge between the write and
the read.  In practice though, it'll work since the compiler does not track
edges to this extent.

In your case, I still think it's better to either use an AtomicReference
with lazySet/get to ensure initializing writes are visible or you can use
Unsafe.putOrderedObject if you can't use AtomicReference.  On TSO archs,
this is the cheapest fence since it's actually a no-op at the assembly
level, and only a compiler barrier.

I'm not sure if you actually have code that needs to work like this, but I
would strongly recommend that you use "normal" safe publication approaches
and not engage in these gymnastics.  If you have 3rd party code that
requires jumping through these hoops, you should ask them to correct their
implementation.

As a personal aside, I feel that something like the new C++11 memory model
is the right way to go forward in allowing developers finer grained control
over fences.  Instead of having special provisions for final and volatile
members, it makes you specify the consistency/order at the callsite rather
than at variable declaration.  If you think about it, a field being
"volatile" doesn't really make sense -- it's not the field that's volatile,
it's certain reads/writes from/to it that need certain order guarantees,
and not all callsites require the same level of these.  Joe Duffy had a
similar blog on this for C#:
http://www.bluebytesoftware.com/blog/2010/12/04/SayonaraVolatile.aspx

Vitaly

On Sun, Dec 18, 2011 at 10:09 AM, Roland Kuhn <rk at rkuhn.info> wrote:

> Yes, inspired by the JSR-133 cookbook I was alluding to roach motel
> semantics: the synchronized is just there to ensure that the volatile write
> has happened before the possibly non-volatile write of the newly
> constructed object?s reference to a possibly shared location is actually
> performed. This would mean that nobody can obtain a reference before
> initialization is done. And then I would like to arrive at the conclusion
> that the volatile read of ?x? from a different thread must synchronize-with
> the initial write.
>
> Does this work?
>
> Roland
>
> On Dec 18, 2011, at 00:40 , David Holmes wrote:
>
> > Roland,
> >
> > An empty synchronized block in a constructor, when there are no other
> > synchronized regions of code, gains you nothing under the JMM as there
> are
> > no happens-before edges established. Are you
> > relying on the implementation of synchronized to issue specific memory
> > barriers here?
> >
> > David
> >
> >> -----Original Message-----
> >> From: Roland Kuhn [mailto:rk at rkuhn.info]
> >> Sent: Sunday, 18 December 2011 1:46 AM
> >> To: dholmes at ieee.org
> >> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] synchronized constructors
> >>
> >>
> >> Thank you, David and Hans, for clarifying these semantics. The
> >> OP?s question has been answered, and I think I can also derive an
> >> answer for my question. I?ll try to wrap it up below, please
> >> correct or confirm:
> >>
> >> class IAmSafe {
> >>  private volatile int x;
> >>  IAmSafe() {
> >>    x = 5;
> >>    synchronized(this) {}
> >>  }
> >>  public int getX() {
> >>    return x;
> >>  }
> >> }
> >>
> >> Assuming that the java.lang.Object constructor is well-behaved,
> >> it should be impossible under any circumstances (barring
> >> reflective modification) that a call to getX() returns anything
> >> but 5, right?
> >>
> >> If this is true, then the cheapest solution to my multi-stage
> >> construction problem?where I completely control the program flow
> >> up to the point where I consider the object initialization
> >> finished?on x86 processors looks like this:
> >>
> >> class ComplexDeps {
> >>  final int someValue;
> >>  ComplexDeps(int someValue) {
> >>    this.someValue = someValue;
> >>  }
> >>  // stage 2
> >>  private volatile OtherThing thing;
> >>  public void init(OtherThing thing) {
> >>    this.thing = thing;
> >>    synchronized {}
> >>  }
> >>  // other stuff which reads someValue & ?thing?, never writes to
> >> ?thing? and runs only after init() in program order
> >> }
> >>
> >> IIUC, there will be a (half-way) expensive fence-like instruction
> >> emitted at the end of init(), but apart from that all read
> >> accesses after construction should be cheap. Any nobody will ever
> >> see ?thing? uninitialized.
> >>
> >> Regards,
> >>
> >> Roland
> >>
> >> On Dec 17, 2011, at 09:57 , David Holmes wrote:
> >>
> >>> Correction ...
> >>> I wrote:
> >>>> Zhong Yu writes:
> >>>>> Suppose constructor java.util.Vector() is synchronized
> >>>>>
> >>>>>   static Vector v;
> >>>>>
> >>>>>   // thread 1
> >>>>>   v = new Vector();
> >>>>>
> >>>>>   // thread 2
> >>>>>   Vector r = v;
> >>>>>   if(r!=null)
> >>>>>     r.add(x);
> >>>>>
> >>>>> The last line can throw exception, because thread 2 can observe the
> >>>>> blank state of the object
> >>>>
> >>>> No it can not.
> >>>> Completion of the constructor happens-before the reference is
> >> published.
> >>>
> >>> Delete this sentence. It's wrong but not relevant to the argument.
> >>>
> >>> David
> >>> -----
> >>>
> >>>
> >>>> The acquiring of the monitor in add() can only happen when the
> >>>> monitor is released by the constructor. The release of the
> >>>> monitor in thread
> >>>> 1 happens-before the acquire of the monitor by thread 2. All the
> >>>> constructor
> >>>> actions happen-before the release of the monitor.
> >>>>
> >>>> The publishing of the Vector can not be moved prior to the
> >> acquisition of
> >>>> the monitor in the constructor ("roach motel semantics").
> >>>>
> >>>> David
> >>>> -----
> >>>>
> >>>>
> >>>>> , yet Vector.add() presumes a> post-construction state.
> >>>>
> >>>>> Zhong Yu
> >>>>>
> >>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> >>>>> <davidcholmes at aapt.net.au> wrote:
> >>>>>> Zhong Yu writes:
> >>>>>>> If the reference is unsafely published, another thread can get the
> >>>>>>> reference early; it then calls an instance method which may
> >>>> obtain the
> >>>>>>> lock before the creation thread can obtain the lock for the
> >>>>>>> constructor. Therefore the other thread can observe the blank
> state.
> >>>>>>> As Ruslan corrected me, no partial state can be observed though.
> >>>>>>
> >>>>>> The only way this can happen, if you synchronize the whole
> >>>>> constructor body,
> >>>>>> is if a super class constructor does the unsafe publishing. But
> >>>>> in that case
> >>>>>> there is no such thing as safe-publishing because the object
> >>>> can escape
> >>>>>> before the subclass constructor does any initialization.
> >>>>>>
> >>>>>> To summarize a long and garbled thread. If the constructor body is
> >>>>>> synchronized, there is no accessible state and all methods are
> >>>>> synchronized,
> >>>>>> then no external user of the class can publish a reference in a
> >>>>> way that is
> >>>>>> unsafe. If the constructor does the publishing within the
> >> synchronized
> >>>>>> block, it is still safe. Only if the superclass does it can it
> >>>>> possibly be
> >>>>>> unsafe.
> >>>>>>
> >>>>>> Also to address an other point: lock elision is allowed (eg
> >>>> using escape
> >>>>>> analysis) but the memory synchronization effects must remain
> >>>>> (you can lose
> >>>>>> enforced mutual exclusion [as you don't need it], but not
> >>>> happens-before
> >>>>>> edges).
> >>>>>>
> >>>>>> Constructors can't be synchronized simply because back in 1995 no
> one
> >>>>>> realized there could be a need for it. It can be mostly
> >>>> worked around by
> >>>>>> using a synchronized block. But you can't synchronize the
> >>>>> invocation of the
> >>>>>> super constructor.
> >>>>>>
> >>>>>> End of story :)
> >>>>>>
> >>>>>> Cheers,
> >>>>>> David
> >>>>>>
> >>>>>
> >>>>
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at cs.oswego.edu
> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >> --
> >> Simplicity and elegance are unpopular because they require hard
> >> work and discipline to achieve and education to be appreciated.
> >>  -- Dijkstra
> >>
> >>
> >
>
> --
> I'm a physicist: I have a basic working knowledge of the universe and
> everything it contains!
>    - Sheldon Cooper (The Big Bang Theory)
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111218/2d5677da/attachment.html>

From rk at rkuhn.info  Sun Dec 18 16:02:18 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Sun, 18 Dec 2011 22:02:18 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
	<CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
Message-ID: <5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>

Hi Vitaly,

On Dec 18, 2011, at 21:42 , Vitaly Davidovich wrote:

> I think David's point is that you're relying on implementation details rather than JMM to ensure correctness.  According to JMM, your code does not create any happens-before edge because your getX() does not synchronize on the same lock, so there's no happens-before edge between the write and the read.  In practice though, it'll work since the compiler does not track edges to this extent.
> 
I don?t know from where in the JMM this comes (if at all), but I am relying on the JVM spec, which forbids a prescient write to cross a ?lock? operation.

> In your case, I still think it's better to either use an AtomicReference with lazySet/get to ensure initializing writes are visible or you can use Unsafe.putOrderedObject if you can't use AtomicReference.  On TSO archs, this is the cheapest fence since it's actually a no-op at the assembly level, and only a compiler barrier.
> 
The question was about whether creation of extra objects (which is a rather high cost) can be avoided. And I am not sure that a lazySet would achieve what I describe above.

> I'm not sure if you actually have code that needs to work like this, but I would strongly recommend that you use "normal" safe publication approaches and not engage in these gymnastics.  If you have 3rd party code that requires jumping through these hoops, you should ask them to correct their implementation.
> 
Well, the problem is a different one: imagine you are a library writer, actually a pretty widely used library, and you have to introduce a non-final field in a class which did not ever have one before. This changes the class from ?totally safe? to ?must use safe publication?, which is a silent change of semantics. Now, how do I make that object with the non-final field as safe as the previous version, which had only final fields?

So, I still think that my code below does the trick, unless someone points me to the glaring hole in it.

> As a personal aside, I feel that something like the new C++11 memory model is the right way to go forward in allowing developers finer grained control over fences.  Instead of having special provisions for final and volatile members, it makes you specify the consistency/order at the callsite rather than at variable declaration.  If you think about it, a field being "volatile" doesn't really make sense -- it's not the field that's volatile, it's certain reads/writes from/to it that need certain order guarantees, and not all callsites require the same level of these.  Joe Duffy had a similar blog on this for C#:  http://www.bluebytesoftware.com/blog/2010/12/04/SayonaraVolatile.aspx 
> 
Yes, I would very much welcome a simple way achieving a fence, as you might imagine ;-)

Regards,

Roland

> Vitaly
> 
> On Sun, Dec 18, 2011 at 10:09 AM, Roland Kuhn <rk at rkuhn.info> wrote:
> Yes, inspired by the JSR-133 cookbook I was alluding to roach motel semantics: the synchronized is just there to ensure that the volatile write has happened before the possibly non-volatile write of the newly constructed object?s reference to a possibly shared location is actually performed. This would mean that nobody can obtain a reference before initialization is done. And then I would like to arrive at the conclusion that the volatile read of ?x? from a different thread must synchronize-with the initial write.
> 
> Does this work?
> 
> Roland
> 
> On Dec 18, 2011, at 00:40 , David Holmes wrote:
> 
> > Roland,
> >
> > An empty synchronized block in a constructor, when there are no other
> > synchronized regions of code, gains you nothing under the JMM as there are
> > no happens-before edges established. Are you
> > relying on the implementation of synchronized to issue specific memory
> > barriers here?
> >
> > David
> >
> >> -----Original Message-----
> >> From: Roland Kuhn [mailto:rk at rkuhn.info]
> >> Sent: Sunday, 18 December 2011 1:46 AM
> >> To: dholmes at ieee.org
> >> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] synchronized constructors
> >>
> >>
> >> Thank you, David and Hans, for clarifying these semantics. The
> >> OP?s question has been answered, and I think I can also derive an
> >> answer for my question. I?ll try to wrap it up below, please
> >> correct or confirm:
> >>
> >> class IAmSafe {
> >>  private volatile int x;
> >>  IAmSafe() {
> >>    x = 5;
> >>    synchronized(this) {}
> >>  }
> >>  public int getX() {
> >>    return x;
> >>  }
> >> }
> >>
> >> Assuming that the java.lang.Object constructor is well-behaved,
> >> it should be impossible under any circumstances (barring
> >> reflective modification) that a call to getX() returns anything
> >> but 5, right?
> >>
> >> If this is true, then the cheapest solution to my multi-stage
> >> construction problem?where I completely control the program flow
> >> up to the point where I consider the object initialization
> >> finished?on x86 processors looks like this:
> >>
> >> class ComplexDeps {
> >>  final int someValue;
> >>  ComplexDeps(int someValue) {
> >>    this.someValue = someValue;
> >>  }
> >>  // stage 2
> >>  private volatile OtherThing thing;
> >>  public void init(OtherThing thing) {
> >>    this.thing = thing;
> >>    synchronized {}
> >>  }
> >>  // other stuff which reads someValue & ?thing?, never writes to
> >> ?thing? and runs only after init() in program order
> >> }
> >>
> >> IIUC, there will be a (half-way) expensive fence-like instruction
> >> emitted at the end of init(), but apart from that all read
> >> accesses after construction should be cheap. Any nobody will ever
> >> see ?thing? uninitialized.
> >>
> >> Regards,
> >>
> >> Roland
> >>
> >> On Dec 17, 2011, at 09:57 , David Holmes wrote:
> >>
> >>> Correction ...
> >>> I wrote:
> >>>> Zhong Yu writes:
> >>>>> Suppose constructor java.util.Vector() is synchronized
> >>>>>
> >>>>>   static Vector v;
> >>>>>
> >>>>>   // thread 1
> >>>>>   v = new Vector();
> >>>>>
> >>>>>   // thread 2
> >>>>>   Vector r = v;
> >>>>>   if(r!=null)
> >>>>>     r.add(x);
> >>>>>
> >>>>> The last line can throw exception, because thread 2 can observe the
> >>>>> blank state of the object
> >>>>
> >>>> No it can not.
> >>>> Completion of the constructor happens-before the reference is
> >> published.
> >>>
> >>> Delete this sentence. It's wrong but not relevant to the argument.
> >>>
> >>> David
> >>> -----
> >>>
> >>>
> >>>> The acquiring of the monitor in add() can only happen when the
> >>>> monitor is released by the constructor. The release of the
> >>>> monitor in thread
> >>>> 1 happens-before the acquire of the monitor by thread 2. All the
> >>>> constructor
> >>>> actions happen-before the release of the monitor.
> >>>>
> >>>> The publishing of the Vector can not be moved prior to the
> >> acquisition of
> >>>> the monitor in the constructor ("roach motel semantics").
> >>>>
> >>>> David
> >>>> -----
> >>>>
> >>>>
> >>>>> , yet Vector.add() presumes a> post-construction state.
> >>>>
> >>>>> Zhong Yu
> >>>>>
> >>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> >>>>> <davidcholmes at aapt.net.au> wrote:
> >>>>>> Zhong Yu writes:
> >>>>>>> If the reference is unsafely published, another thread can get the
> >>>>>>> reference early; it then calls an instance method which may
> >>>> obtain the
> >>>>>>> lock before the creation thread can obtain the lock for the
> >>>>>>> constructor. Therefore the other thread can observe the blank state.
> >>>>>>> As Ruslan corrected me, no partial state can be observed though.
> >>>>>>
> >>>>>> The only way this can happen, if you synchronize the whole
> >>>>> constructor body,
> >>>>>> is if a super class constructor does the unsafe publishing. But
> >>>>> in that case
> >>>>>> there is no such thing as safe-publishing because the object
> >>>> can escape
> >>>>>> before the subclass constructor does any initialization.
> >>>>>>
> >>>>>> To summarize a long and garbled thread. If the constructor body is
> >>>>>> synchronized, there is no accessible state and all methods are
> >>>>> synchronized,
> >>>>>> then no external user of the class can publish a reference in a
> >>>>> way that is
> >>>>>> unsafe. If the constructor does the publishing within the
> >> synchronized
> >>>>>> block, it is still safe. Only if the superclass does it can it
> >>>>> possibly be
> >>>>>> unsafe.
> >>>>>>
> >>>>>> Also to address an other point: lock elision is allowed (eg
> >>>> using escape
> >>>>>> analysis) but the memory synchronization effects must remain
> >>>>> (you can lose
> >>>>>> enforced mutual exclusion [as you don't need it], but not
> >>>> happens-before
> >>>>>> edges).
> >>>>>>
> >>>>>> Constructors can't be synchronized simply because back in 1995 no one
> >>>>>> realized there could be a need for it. It can be mostly
> >>>> worked around by
> >>>>>> using a synchronized block. But you can't synchronize the
> >>>>> invocation of the
> >>>>>> super constructor.
> >>>>>>
> >>>>>> End of story :)
> >>>>>>
> >>>>>> Cheers,
> >>>>>> David
> >>>>>>
> >>>>>
> >>>>
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at cs.oswego.edu
> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >> --
> >> Simplicity and elegance are unpopular because they require hard
> >> work and discipline to achieve and education to be appreciated.
> >>  -- Dijkstra
> >>
> >>
> >
> 
> --
> I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
>    - Sheldon Cooper (The Big Bang Theory)
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> -- 
> Vitaly
> 617-548-7007 (mobile)

--
Simplicity and elegance are unpopular because they require hard work and discipline to achieve and education to be appreciated.
  -- Dijkstra

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111218/67f87fe0/attachment-0001.html>

From martinrb at google.com  Sun Dec 18 16:22:55 2011
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 18 Dec 2011 13:22:55 -0800
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
	<CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
	<5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
Message-ID: <CA+kOe09wVpPpbsZLx9i8c2durVpmkfKPdiEGVcLiHyNX7NF-ow@mail.gmail.com>

On Sun, Dec 18, 2011 at 13:02, Roland Kuhn <rk at rkuhn.info> wrote:

> Yes, I would very much welcome a simple way achieving a fence, as you
> might imagine ;-)
>

Many of us here would like to see a way to safely publish an object.

---

Here's a solution no one has mentioned, but ought to be bullet-proof:

public class MutableSafePublication {
    private int i;
    private Object x;
    private final MutableSafePublication safePublicationThis;
    private int i() { return safePublicationThis.i; }
    private Object x() { return safePublicationThis.x; }
    public MutableSafePublication() {
        i = 42;
        x = new Object();
        safePublicationThis = this;
    }
    // use i() and x() consistently in the implementation
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111218/d308bf4d/attachment.html>

From vitalyd at gmail.com  Sun Dec 18 16:54:19 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 18 Dec 2011 16:54:19 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
	<CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
	<5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
Message-ID: <CAHjP37H6aJmD2Xfm29xB1Gq_vr95wNjduCyRmWsZTDOj0Yz3sg@mail.gmail.com>

On Sun, Dec 18, 2011 at 4:02 PM, Roland Kuhn <rk at rkuhn.info> wrote:

> Hi Vitaly,
>
> On Dec 18, 2011, at 21:42 , Vitaly Davidovich wrote:
>
> I think David's point is that you're relying on implementation details
> rather than JMM to ensure correctness.  According to JMM, your code does
> not create any happens-before edge because your getX() does not synchronize
> on the same lock, so there's no happens-before edge between the write and
> the read.  In practice though, it'll work since the compiler does not track
> edges to this extent.
>
> I don?t know from where in the JMM this comes (if at all), but I am
> relying on the JVM spec, which forbids a prescient write to cross a ?lock?
> operation.
>

You mentioned that you were looking at the JSR compiler cookbook; yes, that
cookbook is meant to, amongst other things, provide suggestions to compiler
writers how to achieve the memory effects of the JMM.  The
recommendations/examples there do fulfill the JMM requirements, but they're
stronger than what JMM describes -- that's my point about you relying on
implementation details vs JMM.  The JMM is described in terms of
happens-before edges, and in your example, you do not have a happens-before
edge between the write and read as defined by the JMM; the JVM impl of the
JMM provides stronger ordering, but that's an implementation details.
 That's what I believe David was telling you.


>
> In your case, I still think it's better to either use an AtomicReference
> with lazySet/get to ensure initializing writes are visible or you can use
> Unsafe.putOrderedObject if you can't use AtomicReference.  On TSO archs,
> this is the cheapest fence since it's actually a no-op at the assembly
> level, and only a compiler barrier.
>
> The question was about whether creation of extra objects (which is a
> rather high cost) can be avoided. And I am not sure that a lazySet would
> achieve what I describe above.
>

What extra objects? The AtomicReference? Yes, you'd pay the standard JVM
object overhead of having an additional reference in your class.  If that's
a concern, you can use Unsafe.putOrderedObject instead.
 AtomicReference.lazySet and Unsafe.putOrderedObject are essentially a
StoreStore fence, which is what final gives you.  Since you cannot use
final in your case, this is the other "workaround" and it would work.  Can
you explain why you think it doesn't achieve what you describe? If "final"
in the constructor achieves what you want, then these should as well.


>
> I'm not sure if you actually have code that needs to work like this, but I
> would strongly recommend that you use "normal" safe publication approaches
> and not engage in these gymnastics.  If you have 3rd party code that
> requires jumping through these hoops, you should ask them to correct their
> implementation.
>
> Well, the problem is a different one: imagine you are a library writer,
> actually a pretty widely used library, and you have to introduce a
> non-final field in a class which did not ever have one before. This changes
> the class from ?totally safe? to ?must use safe publication?, which is a
> silent change of semantics. Now, how do I make that object with the
> non-final field as safe as the previous version, which had only final
> fields?
>

This is only if you're publishing objects with a data race (i.e. a store to
an ordinary shared field).  If you publish safely (i.e. use volatile, use
datastructures that are provided for inter-thread communication, etc), then
you don't have these problems.  The point is use proper handoff/publishing
mechanisms rather than relying on very subtle implementation details (such
as all fields are final today).


>
> So, I still think that my code below does the trick, unless someone points
> me to the glaring hole in it.
>
> As a personal aside, I feel that something like the new C++11 memory model
> is the right way to go forward in allowing developers finer grained control
> over fences.  Instead of having special provisions for final and volatile
> members, it makes you specify the consistency/order at the callsite rather
> than at variable declaration.  If you think about it, a field being
> "volatile" doesn't really make sense -- it's not the field that's volatile,
> it's certain reads/writes from/to it that need certain order guarantees,
> and not all callsites require the same level of these.  Joe Duffy had a
> similar blog on this for C#:
> http://www.bluebytesoftware.com/blog/2010/12/04/SayonaraVolatile.aspx
>
> Yes, I would very much welcome a simple way achieving a fence, as you
> might imagine ;-)
>
> Regards,
>
> Roland
>
> Vitaly
>
> On Sun, Dec 18, 2011 at 10:09 AM, Roland Kuhn <rk at rkuhn.info> wrote:
>
>> Yes, inspired by the JSR-133 cookbook I was alluding to roach motel
>> semantics: the synchronized is just there to ensure that the volatile write
>> has happened before the possibly non-volatile write of the newly
>> constructed object?s reference to a possibly shared location is actually
>> performed. This would mean that nobody can obtain a reference before
>> initialization is done. And then I would like to arrive at the conclusion
>> that the volatile read of ?x? from a different thread must synchronize-with
>> the initial write.
>>
>> Does this work?
>>
>> Roland
>>
>> On Dec 18, 2011, at 00:40 , David Holmes wrote:
>>
>> > Roland,
>> >
>> > An empty synchronized block in a constructor, when there are no other
>> > synchronized regions of code, gains you nothing under the JMM as there
>> are
>> > no happens-before edges established. Are you
>> > relying on the implementation of synchronized to issue specific memory
>> > barriers here?
>> >
>> > David
>> >
>> >> -----Original Message-----
>> >> From: Roland Kuhn [mailto:rk at rkuhn.info]
>> >> Sent: Sunday, 18 December 2011 1:46 AM
>> >> To: dholmes at ieee.org
>> >> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
>> >> Subject: Re: [concurrency-interest] synchronized constructors
>> >>
>> >>
>> >> Thank you, David and Hans, for clarifying these semantics. The
>> >> OP?s question has been answered, and I think I can also derive an
>> >> answer for my question. I?ll try to wrap it up below, please
>> >> correct or confirm:
>> >>
>> >> class IAmSafe {
>> >>  private volatile int x;
>> >>  IAmSafe() {
>> >>    x = 5;
>> >>    synchronized(this) {}
>> >>  }
>> >>  public int getX() {
>> >>    return x;
>> >>  }
>> >> }
>> >>
>> >> Assuming that the java.lang.Object constructor is well-behaved,
>> >> it should be impossible under any circumstances (barring
>> >> reflective modification) that a call to getX() returns anything
>> >> but 5, right?
>> >>
>> >> If this is true, then the cheapest solution to my multi-stage
>> >> construction problem?where I completely control the program flow
>> >> up to the point where I consider the object initialization
>> >> finished?on x86 processors looks like this:
>> >>
>> >> class ComplexDeps {
>> >>  final int someValue;
>> >>  ComplexDeps(int someValue) {
>> >>    this.someValue = someValue;
>> >>  }
>> >>  // stage 2
>> >>  private volatile OtherThing thing;
>> >>  public void init(OtherThing thing) {
>> >>    this.thing = thing;
>> >>    synchronized {}
>> >>  }
>> >>  // other stuff which reads someValue & ?thing?, never writes to
>> >> ?thing? and runs only after init() in program order
>> >> }
>> >>
>> >> IIUC, there will be a (half-way) expensive fence-like instruction
>> >> emitted at the end of init(), but apart from that all read
>> >> accesses after construction should be cheap. Any nobody will ever
>> >> see ?thing? uninitialized.
>> >>
>> >> Regards,
>> >>
>> >> Roland
>> >>
>> >> On Dec 17, 2011, at 09:57 , David Holmes wrote:
>> >>
>> >>> Correction ...
>> >>> I wrote:
>> >>>> Zhong Yu writes:
>> >>>>> Suppose constructor java.util.Vector() is synchronized
>> >>>>>
>> >>>>>   static Vector v;
>> >>>>>
>> >>>>>   // thread 1
>> >>>>>   v = new Vector();
>> >>>>>
>> >>>>>   // thread 2
>> >>>>>   Vector r = v;
>> >>>>>   if(r!=null)
>> >>>>>     r.add(x);
>> >>>>>
>> >>>>> The last line can throw exception, because thread 2 can observe the
>> >>>>> blank state of the object
>> >>>>
>> >>>> No it can not.
>> >>>> Completion of the constructor happens-before the reference is
>> >> published.
>> >>>
>> >>> Delete this sentence. It's wrong but not relevant to the argument.
>> >>>
>> >>> David
>> >>> -----
>> >>>
>> >>>
>> >>>> The acquiring of the monitor in add() can only happen when the
>> >>>> monitor is released by the constructor. The release of the
>> >>>> monitor in thread
>> >>>> 1 happens-before the acquire of the monitor by thread 2. All the
>> >>>> constructor
>> >>>> actions happen-before the release of the monitor.
>> >>>>
>> >>>> The publishing of the Vector can not be moved prior to the
>> >> acquisition of
>> >>>> the monitor in the constructor ("roach motel semantics").
>> >>>>
>> >>>> David
>> >>>> -----
>> >>>>
>> >>>>
>> >>>>> , yet Vector.add() presumes a> post-construction state.
>> >>>>
>> >>>>> Zhong Yu
>> >>>>>
>> >>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
>> >>>>> <davidcholmes at aapt.net.au> wrote:
>> >>>>>> Zhong Yu writes:
>> >>>>>>> If the reference is unsafely published, another thread can get the
>> >>>>>>> reference early; it then calls an instance method which may
>> >>>> obtain the
>> >>>>>>> lock before the creation thread can obtain the lock for the
>> >>>>>>> constructor. Therefore the other thread can observe the blank
>> state.
>> >>>>>>> As Ruslan corrected me, no partial state can be observed though.
>> >>>>>>
>> >>>>>> The only way this can happen, if you synchronize the whole
>> >>>>> constructor body,
>> >>>>>> is if a super class constructor does the unsafe publishing. But
>> >>>>> in that case
>> >>>>>> there is no such thing as safe-publishing because the object
>> >>>> can escape
>> >>>>>> before the subclass constructor does any initialization.
>> >>>>>>
>> >>>>>> To summarize a long and garbled thread. If the constructor body is
>> >>>>>> synchronized, there is no accessible state and all methods are
>> >>>>> synchronized,
>> >>>>>> then no external user of the class can publish a reference in a
>> >>>>> way that is
>> >>>>>> unsafe. If the constructor does the publishing within the
>> >> synchronized
>> >>>>>> block, it is still safe. Only if the superclass does it can it
>> >>>>> possibly be
>> >>>>>> unsafe.
>> >>>>>>
>> >>>>>> Also to address an other point: lock elision is allowed (eg
>> >>>> using escape
>> >>>>>> analysis) but the memory synchronization effects must remain
>> >>>>> (you can lose
>> >>>>>> enforced mutual exclusion [as you don't need it], but not
>> >>>> happens-before
>> >>>>>> edges).
>> >>>>>>
>> >>>>>> Constructors can't be synchronized simply because back in 1995 no
>> one
>> >>>>>> realized there could be a need for it. It can be mostly
>> >>>> worked around by
>> >>>>>> using a synchronized block. But you can't synchronize the
>> >>>>> invocation of the
>> >>>>>> super constructor.
>> >>>>>>
>> >>>>>> End of story :)
>> >>>>>>
>> >>>>>> Cheers,
>> >>>>>> David
>> >>>>>>
>> >>>>>
>> >>>>
>> >>>> _______________________________________________
>> >>>> Concurrency-interest mailing list
>> >>>> Concurrency-interest at cs.oswego.edu
>> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>>>
>> >>>
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >> --
>> >> Simplicity and elegance are unpopular because they require hard
>> >> work and discipline to achieve and education to be appreciated.
>> >>  -- Dijkstra
>> >>
>> >>
>> >
>>
>> --
>> I'm a physicist: I have a basic working knowledge of the universe and
>> everything it contains!
>>    - Sheldon Cooper (The Big Bang Theory)
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> --
> Vitaly
> 617-548-7007 (mobile)
>
>
> --
> Simplicity and elegance are unpopular because they require hard work and
> discipline to achieve and education to be appreciated.
>   -- Dijkstra
>
>


-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111218/1250aa1b/attachment-0001.html>

From vitalyd at gmail.com  Sun Dec 18 16:56:23 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Sun, 18 Dec 2011 16:56:23 -0500
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CA+kOe09wVpPpbsZLx9i8c2durVpmkfKPdiEGVcLiHyNX7NF-ow@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
	<CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
	<5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
	<CA+kOe09wVpPpbsZLx9i8c2durVpmkfKPdiEGVcLiHyNX7NF-ow@mail.gmail.com>
Message-ID: <CAHjP37GncijTfWtWpvOvz8WQDc=wJ9ONsGtY_MMjRTHZs5-+ug@mail.gmail.com>

Hi Martin,

This seems a bit dubious since you can just mark your fields final.  What's
the advantage of the dummy assignment? In Roland's case, he couldn't assign
one of the fields in the constructor because it has to be done via a setter
post construction but before publishing.

Regards,

Vitaly

On Sun, Dec 18, 2011 at 4:22 PM, Martin Buchholz <martinrb at google.com>wrote:

>
>
> On Sun, Dec 18, 2011 at 13:02, Roland Kuhn <rk at rkuhn.info> wrote:
>
>> Yes, I would very much welcome a simple way achieving a fence, as you
>> might imagine ;-)
>>
>
> Many of us here would like to see a way to safely publish an object.
>
> ---
>
> Here's a solution no one has mentioned, but ought to be bullet-proof:
>
> public class MutableSafePublication {
>     private int i;
>     private Object x;
>     private final MutableSafePublication safePublicationThis;
>     private int i() { return safePublicationThis.i; }
>     private Object x() { return safePublicationThis.x; }
>     public MutableSafePublication() {
>         i = 42;
>         x = new Object();
>         safePublicationThis = this;
>     }
>     // use i() and x() consistently in the implementation
> }
>
>


-- 
Vitaly
617-548-7007 (mobile)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111218/834f7d0b/attachment.html>

From davidcholmes at aapt.net.au  Sun Dec 18 17:29:41 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 19 Dec 2011 08:29:41 +1000
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEPFJBAA.davidcholmes@aapt.net.au>

Roland,

"roach motel" are informal semantics - they roughly describe the effects of
the rules but they do not define actual rules. Your reference back to the
JVMS is to JVMS 2nd edition, Chapter 8 and that is obsolete - it dates back
to Java 1.2 if I recall correctly and describes the old Java Memory Model.
The new JMM came out for Java 5 and updates JLS 3rd Edition Chapter 17 and
replaces JVMS Chapter 8 (which was just a duplicate of the JLS chapter).

In the "new" JMM you have to establish that a happens-before ordering exists
between two actions - eg for a read to see a specific value that was
written, you must establish that the write happens-before the read. This is
not a simple temporal relationship (that the write happened to occur prior
to the read as seen by an external observer) but a very formal one: if there
is no happens-before edge between a write and a read then the read need not
see the value that was written (even if it physically occurred afterwards).

"roach motel" basically describes the effects of the happens-before rules as
they apply to actions on volatiles and action on monitors. If actions can
move in, it is because there is no happens-before ordering to prevent it;
while actions can not move out because there is a happens-before ordering
that prevents it.

So in your code you can not use the empty synchronized block to enforce an
ordering constraint across threads because no other thread ever acquires the
same monitor and so there is no happens-before relationship anywhere.

In practice you will get whatever synchronization artefacts the VM inserts,
but this is not something you should be relying on. Lock-elision, as already
discussed, must preserve happens-before orderings, but here there are none,
so lock-elision can completely remove all traces of the synchronized block.

Hope that clarifies things.

David
-----

> -----Original Message-----
> From: Roland Kuhn [mailto:rk at rkuhn.info]
> Sent: Monday, 19 December 2011 1:10 AM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] synchronized constructors
>
>
> Yes, inspired by the JSR-133 cookbook I was alluding to roach
> motel semantics: the synchronized is just there to ensure that
> the volatile write has happened before the possibly non-volatile
> write of the newly constructed object?s reference to a possibly
> shared location is actually performed. This would mean that
> nobody can obtain a reference before initialization is done. And
> then I would like to arrive at the conclusion that the volatile
> read of ?x? from a different thread must synchronize-with the
> initial write.
>
> Does this work?
>
> Roland
>
> On Dec 18, 2011, at 00:40 , David Holmes wrote:
>
> > Roland,
> >
> > An empty synchronized block in a constructor, when there are no other
> > synchronized regions of code, gains you nothing under the JMM
> as there are
> > no happens-before edges established. Are you
> > relying on the implementation of synchronized to issue specific memory
> > barriers here?
> >
> > David
> >
> >> -----Original Message-----
> >> From: Roland Kuhn [mailto:rk at rkuhn.info]
> >> Sent: Sunday, 18 December 2011 1:46 AM
> >> To: dholmes at ieee.org
> >> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] synchronized constructors
> >>
> >>
> >> Thank you, David and Hans, for clarifying these semantics. The
> >> OP?s question has been answered, and I think I can also derive an
> >> answer for my question. I?ll try to wrap it up below, please
> >> correct or confirm:
> >>
> >> class IAmSafe {
> >>  private volatile int x;
> >>  IAmSafe() {
> >>    x = 5;
> >>    synchronized(this) {}
> >>  }
> >>  public int getX() {
> >>    return x;
> >>  }
> >> }
> >>
> >> Assuming that the java.lang.Object constructor is well-behaved,
> >> it should be impossible under any circumstances (barring
> >> reflective modification) that a call to getX() returns anything
> >> but 5, right?
> >>
> >> If this is true, then the cheapest solution to my multi-stage
> >> construction problem?where I completely control the program flow
> >> up to the point where I consider the object initialization
> >> finished?on x86 processors looks like this:
> >>
> >> class ComplexDeps {
> >>  final int someValue;
> >>  ComplexDeps(int someValue) {
> >>    this.someValue = someValue;
> >>  }
> >>  // stage 2
> >>  private volatile OtherThing thing;
> >>  public void init(OtherThing thing) {
> >>    this.thing = thing;
> >>    synchronized {}
> >>  }
> >>  // other stuff which reads someValue & ?thing?, never writes to
> >> ?thing? and runs only after init() in program order
> >> }
> >>
> >> IIUC, there will be a (half-way) expensive fence-like instruction
> >> emitted at the end of init(), but apart from that all read
> >> accesses after construction should be cheap. Any nobody will ever
> >> see ?thing? uninitialized.
> >>
> >> Regards,
> >>
> >> Roland
> >>
> >> On Dec 17, 2011, at 09:57 , David Holmes wrote:
> >>
> >>> Correction ...
> >>> I wrote:
> >>>> Zhong Yu writes:
> >>>>> Suppose constructor java.util.Vector() is synchronized
> >>>>>
> >>>>>   static Vector v;
> >>>>>
> >>>>>   // thread 1
> >>>>>   v = new Vector();
> >>>>>
> >>>>>   // thread 2
> >>>>>   Vector r = v;
> >>>>>   if(r!=null)
> >>>>>     r.add(x);
> >>>>>
> >>>>> The last line can throw exception, because thread 2 can observe the
> >>>>> blank state of the object
> >>>>
> >>>> No it can not.
> >>>> Completion of the constructor happens-before the reference is
> >> published.
> >>>
> >>> Delete this sentence. It's wrong but not relevant to the argument.
> >>>
> >>> David
> >>> -----
> >>>
> >>>
> >>>> The acquiring of the monitor in add() can only happen when the
> >>>> monitor is released by the constructor. The release of the
> >>>> monitor in thread
> >>>> 1 happens-before the acquire of the monitor by thread 2. All the
> >>>> constructor
> >>>> actions happen-before the release of the monitor.
> >>>>
> >>>> The publishing of the Vector can not be moved prior to the
> >> acquisition of
> >>>> the monitor in the constructor ("roach motel semantics").
> >>>>
> >>>> David
> >>>> -----
> >>>>
> >>>>
> >>>>> , yet Vector.add() presumes a> post-construction state.
> >>>>
> >>>>> Zhong Yu
> >>>>>
> >>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
> >>>>> <davidcholmes at aapt.net.au> wrote:
> >>>>>> Zhong Yu writes:
> >>>>>>> If the reference is unsafely published, another thread can get the
> >>>>>>> reference early; it then calls an instance method which may
> >>>> obtain the
> >>>>>>> lock before the creation thread can obtain the lock for the
> >>>>>>> constructor. Therefore the other thread can observe the
> blank state.
> >>>>>>> As Ruslan corrected me, no partial state can be observed though.
> >>>>>>
> >>>>>> The only way this can happen, if you synchronize the whole
> >>>>> constructor body,
> >>>>>> is if a super class constructor does the unsafe publishing. But
> >>>>> in that case
> >>>>>> there is no such thing as safe-publishing because the object
> >>>> can escape
> >>>>>> before the subclass constructor does any initialization.
> >>>>>>
> >>>>>> To summarize a long and garbled thread. If the constructor body is
> >>>>>> synchronized, there is no accessible state and all methods are
> >>>>> synchronized,
> >>>>>> then no external user of the class can publish a reference in a
> >>>>> way that is
> >>>>>> unsafe. If the constructor does the publishing within the
> >> synchronized
> >>>>>> block, it is still safe. Only if the superclass does it can it
> >>>>> possibly be
> >>>>>> unsafe.
> >>>>>>
> >>>>>> Also to address an other point: lock elision is allowed (eg
> >>>> using escape
> >>>>>> analysis) but the memory synchronization effects must remain
> >>>>> (you can lose
> >>>>>> enforced mutual exclusion [as you don't need it], but not
> >>>> happens-before
> >>>>>> edges).
> >>>>>>
> >>>>>> Constructors can't be synchronized simply because back in
> 1995 no one
> >>>>>> realized there could be a need for it. It can be mostly
> >>>> worked around by
> >>>>>> using a synchronized block. But you can't synchronize the
> >>>>> invocation of the
> >>>>>> super constructor.
> >>>>>>
> >>>>>> End of story :)
> >>>>>>
> >>>>>> Cheers,
> >>>>>> David
> >>>>>>
> >>>>>
> >>>>
> >>>> _______________________________________________
> >>>> Concurrency-interest mailing list
> >>>> Concurrency-interest at cs.oswego.edu
> >>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >> --
> >> Simplicity and elegance are unpopular because they require hard
> >> work and discipline to achieve and education to be appreciated.
> >>  -- Dijkstra
> >>
> >>
> >
>
> --
> I'm a physicist: I have a basic working knowledge of the universe
> and everything it contains!
>     - Sheldon Cooper (The Big Bang Theory)
>
>



From rk at rkuhn.info  Sun Dec 18 18:15:53 2011
From: rk at rkuhn.info (Roland Kuhn)
Date: Mon, 19 Dec 2011 00:15:53 +0100
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEPFJBAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEPFJBAA.davidcholmes@aapt.net.au>
Message-ID: <06A5A2C9-B8BB-4011-9B49-EE101267EDDA@rkuhn.info>

Thank you, David, that clarifies a lot, including which references NOT to read ;-) Back to the drawing board, then. 


Regards,

Roland Kuhn
Typesafe ? Enterprise-Grade Scala from the Experts
twitter: @rolandkuhn

On 18 dec 2011, at 23:29, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> Roland,
> 
> "roach motel" are informal semantics - they roughly describe the effects of
> the rules but they do not define actual rules. Your reference back to the
> JVMS is to JVMS 2nd edition, Chapter 8 and that is obsolete - it dates back
> to Java 1.2 if I recall correctly and describes the old Java Memory Model.
> The new JMM came out for Java 5 and updates JLS 3rd Edition Chapter 17 and
> replaces JVMS Chapter 8 (which was just a duplicate of the JLS chapter).
> 
> In the "new" JMM you have to establish that a happens-before ordering exists
> between two actions - eg for a read to see a specific value that was
> written, you must establish that the write happens-before the read. This is
> not a simple temporal relationship (that the write happened to occur prior
> to the read as seen by an external observer) but a very formal one: if there
> is no happens-before edge between a write and a read then the read need not
> see the value that was written (even if it physically occurred afterwards).
> 
> "roach motel" basically describes the effects of the happens-before rules as
> they apply to actions on volatiles and action on monitors. If actions can
> move in, it is because there is no happens-before ordering to prevent it;
> while actions can not move out because there is a happens-before ordering
> that prevents it.
> 
> So in your code you can not use the empty synchronized block to enforce an
> ordering constraint across threads because no other thread ever acquires the
> same monitor and so there is no happens-before relationship anywhere.
> 
> In practice you will get whatever synchronization artefacts the VM inserts,
> but this is not something you should be relying on. Lock-elision, as already
> discussed, must preserve happens-before orderings, but here there are none,
> so lock-elision can completely remove all traces of the synchronized block.
> 
> Hope that clarifies things.
> 
> David
> -----
> 
>> -----Original Message-----
>> From: Roland Kuhn [mailto:rk at rkuhn.info]
>> Sent: Monday, 19 December 2011 1:10 AM
>> To: dholmes at ieee.org
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] synchronized constructors
>> 
>> 
>> Yes, inspired by the JSR-133 cookbook I was alluding to roach
>> motel semantics: the synchronized is just there to ensure that
>> the volatile write has happened before the possibly non-volatile
>> write of the newly constructed object?s reference to a possibly
>> shared location is actually performed. This would mean that
>> nobody can obtain a reference before initialization is done. And
>> then I would like to arrive at the conclusion that the volatile
>> read of ?x? from a different thread must synchronize-with the
>> initial write.
>> 
>> Does this work?
>> 
>> Roland
>> 
>> On Dec 18, 2011, at 00:40 , David Holmes wrote:
>> 
>>> Roland,
>>> 
>>> An empty synchronized block in a constructor, when there are no other
>>> synchronized regions of code, gains you nothing under the JMM
>> as there are
>>> no happens-before edges established. Are you
>>> relying on the implementation of synchronized to issue specific memory
>>> barriers here?
>>> 
>>> David
>>> 
>>>> -----Original Message-----
>>>> From: Roland Kuhn [mailto:rk at rkuhn.info]
>>>> Sent: Sunday, 18 December 2011 1:46 AM
>>>> To: dholmes at ieee.org
>>>> Cc: Zhong Yu; concurrency-interest at cs.oswego.edu
>>>> Subject: Re: [concurrency-interest] synchronized constructors
>>>> 
>>>> 
>>>> Thank you, David and Hans, for clarifying these semantics. The
>>>> OP?s question has been answered, and I think I can also derive an
>>>> answer for my question. I?ll try to wrap it up below, please
>>>> correct or confirm:
>>>> 
>>>> class IAmSafe {
>>>> private volatile int x;
>>>> IAmSafe() {
>>>>   x = 5;
>>>>   synchronized(this) {}
>>>> }
>>>> public int getX() {
>>>>   return x;
>>>> }
>>>> }
>>>> 
>>>> Assuming that the java.lang.Object constructor is well-behaved,
>>>> it should be impossible under any circumstances (barring
>>>> reflective modification) that a call to getX() returns anything
>>>> but 5, right?
>>>> 
>>>> If this is true, then the cheapest solution to my multi-stage
>>>> construction problem?where I completely control the program flow
>>>> up to the point where I consider the object initialization
>>>> finished?on x86 processors looks like this:
>>>> 
>>>> class ComplexDeps {
>>>> final int someValue;
>>>> ComplexDeps(int someValue) {
>>>>   this.someValue = someValue;
>>>> }
>>>> // stage 2
>>>> private volatile OtherThing thing;
>>>> public void init(OtherThing thing) {
>>>>   this.thing = thing;
>>>>   synchronized {}
>>>> }
>>>> // other stuff which reads someValue & ?thing?, never writes to
>>>> ?thing? and runs only after init() in program order
>>>> }
>>>> 
>>>> IIUC, there will be a (half-way) expensive fence-like instruction
>>>> emitted at the end of init(), but apart from that all read
>>>> accesses after construction should be cheap. Any nobody will ever
>>>> see ?thing? uninitialized.
>>>> 
>>>> Regards,
>>>> 
>>>> Roland
>>>> 
>>>> On Dec 17, 2011, at 09:57 , David Holmes wrote:
>>>> 
>>>>> Correction ...
>>>>> I wrote:
>>>>>> Zhong Yu writes:
>>>>>>> Suppose constructor java.util.Vector() is synchronized
>>>>>>> 
>>>>>>>  static Vector v;
>>>>>>> 
>>>>>>>  // thread 1
>>>>>>>  v = new Vector();
>>>>>>> 
>>>>>>>  // thread 2
>>>>>>>  Vector r = v;
>>>>>>>  if(r!=null)
>>>>>>>    r.add(x);
>>>>>>> 
>>>>>>> The last line can throw exception, because thread 2 can observe the
>>>>>>> blank state of the object
>>>>>> 
>>>>>> No it can not.
>>>>>> Completion of the constructor happens-before the reference is
>>>> published.
>>>>> 
>>>>> Delete this sentence. It's wrong but not relevant to the argument.
>>>>> 
>>>>> David
>>>>> -----
>>>>> 
>>>>> 
>>>>>> The acquiring of the monitor in add() can only happen when the
>>>>>> monitor is released by the constructor. The release of the
>>>>>> monitor in thread
>>>>>> 1 happens-before the acquire of the monitor by thread 2. All the
>>>>>> constructor
>>>>>> actions happen-before the release of the monitor.
>>>>>> 
>>>>>> The publishing of the Vector can not be moved prior to the
>>>> acquisition of
>>>>>> the monitor in the constructor ("roach motel semantics").
>>>>>> 
>>>>>> David
>>>>>> -----
>>>>>> 
>>>>>> 
>>>>>>> , yet Vector.add() presumes a> post-construction state.
>>>>>> 
>>>>>>> Zhong Yu
>>>>>>> 
>>>>>>> On Fri, Dec 16, 2011 at 7:52 PM, David Holmes
>>>>>>> <davidcholmes at aapt.net.au> wrote:
>>>>>>>> Zhong Yu writes:
>>>>>>>>> If the reference is unsafely published, another thread can get the
>>>>>>>>> reference early; it then calls an instance method which may
>>>>>> obtain the
>>>>>>>>> lock before the creation thread can obtain the lock for the
>>>>>>>>> constructor. Therefore the other thread can observe the
>> blank state.
>>>>>>>>> As Ruslan corrected me, no partial state can be observed though.
>>>>>>>> 
>>>>>>>> The only way this can happen, if you synchronize the whole
>>>>>>> constructor body,
>>>>>>>> is if a super class constructor does the unsafe publishing. But
>>>>>>> in that case
>>>>>>>> there is no such thing as safe-publishing because the object
>>>>>> can escape
>>>>>>>> before the subclass constructor does any initialization.
>>>>>>>> 
>>>>>>>> To summarize a long and garbled thread. If the constructor body is
>>>>>>>> synchronized, there is no accessible state and all methods are
>>>>>>> synchronized,
>>>>>>>> then no external user of the class can publish a reference in a
>>>>>>> way that is
>>>>>>>> unsafe. If the constructor does the publishing within the
>>>> synchronized
>>>>>>>> block, it is still safe. Only if the superclass does it can it
>>>>>>> possibly be
>>>>>>>> unsafe.
>>>>>>>> 
>>>>>>>> Also to address an other point: lock elision is allowed (eg
>>>>>> using escape
>>>>>>>> analysis) but the memory synchronization effects must remain
>>>>>>> (you can lose
>>>>>>>> enforced mutual exclusion [as you don't need it], but not
>>>>>> happens-before
>>>>>>>> edges).
>>>>>>>> 
>>>>>>>> Constructors can't be synchronized simply because back in
>> 1995 no one
>>>>>>>> realized there could be a need for it. It can be mostly
>>>>>> worked around by
>>>>>>>> using a synchronized block. But you can't synchronize the
>>>>>>> invocation of the
>>>>>>>> super constructor.
>>>>>>>> 
>>>>>>>> End of story :)
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> David
>>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>>> --
>>>> Simplicity and elegance are unpopular because they require hard
>>>> work and discipline to achieve and education to be appreciated.
>>>> -- Dijkstra
>>>> 
>>>> 
>>> 
>> 
>> --
>> I'm a physicist: I have a basic working knowledge of the universe
>> and everything it contains!
>>    - Sheldon Cooper (The Big Bang Theory)
>> 
>> 
> 


From forax at univ-mlv.fr  Mon Dec 19 13:28:15 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Mon, 19 Dec 2011 19:28:15 +0100
Subject: [concurrency-interest] CAS using a MethodHandle
Message-ID: <4EEF823F.50600@univ-mlv.fr>

Hi all,
Some time ago, I said that we should try to use a MethodHandle instead 
of an Atomic*FieldUpdater and let the VM inline the method handle so 
there should be no cost (or a little one) compared to directly calling 
unsafe.compareAndSwapObject.

The following code does exactly that, I have also include a small test 
that just demonstrates that it works.
Because I'm neither a benchmark expert nor an assembler expert, I've 
just checked that the method handle is fully inlined by the JIT and that 
the generated code seems to don't have more code than it should.

I know there is a lot of experts on this list, so experts am i wrong ?

cheers,
R?mi

----------------------------------------------------------------------------------------
package java.util.concurrent.atomic;

import java.lang.invoke.MethodHandle;
import java.lang.invoke.MethodHandles;
import java.lang.invoke.MethodType;
import java.lang.reflect.Field;
import java.lang.reflect.Modifier;

import sun.misc.Unsafe;

public class Volatiles {
   private static final Unsafe unsafe = Unsafe.getUnsafe();

   private static final MethodHandle CAS_OBJECT;
   static {
     try {
       CAS_OBJECT = MethodHandles.publicLookup().bind(unsafe, 
"compareAndSwapObject",
           MethodType.methodType(boolean.class, Object.class, 
long.class, Object.class, Object.class));
     } catch (NoSuchMethodException|IllegalAccessException e) {
       throw new AssertionError(e.getMessage(), e);
     }
   }

   public static MethodHandle compareAnSet(Class<?> declaringClass, 
String fieldName) {
       Field field;
       int modifiers;
       try {
         field = declaringClass.getDeclaredField(fieldName);
         Class<?> caller = sun.reflect.Reflection.getCallerClass(2);
         modifiers = field.getModifiers();
         sun.reflect.misc.ReflectUtil.ensureMemberAccess(
             caller, declaringClass, null, modifiers);
         sun.reflect.misc.ReflectUtil.checkPackageAccess(declaringClass);
       } catch (NoSuchFieldException|IllegalAccessException e) {
         throw new IllegalArgumentException(e);
       }

       if (Modifier.isStatic(modifiers)) {
         throw new IllegalArgumentException("Field must not be static");
       }
       if (!Modifier.isVolatile(modifiers)) {
         throw new IllegalArgumentException("Field must be volatile");
       }

       long offset = unsafe.objectFieldOffset(field);
       MethodHandle mh = MethodHandles.insertArguments(CAS_OBJECT, 1, 
offset);
       Class<?> fieldType = field.getType();
       return mh.asType(MethodType.methodType(boolean.class, 
declaringClass, fieldType, fieldType));
   }
}

-------------------------------------------------------------------
import java.lang.invoke.MethodHandle;
import java.util.concurrent.atomic.Volatiles;


public class CASTest {
   static class Link<E> {
     final E element;
     final Link<E> next;

     Link(E element, Link<E> next) {
       this.element = element;
       this.next = next;
     }
   }

   static class LinkedLink<E> {
     private volatile Link<E> head;

     private static final MethodHandle headCAS = 
Volatiles.compareAnSet(LinkedLink.class, "head");

     public void add(E element) {
       try {
         for(;;) {
           Link<E> head = this.head;
           Link<E> link = new Link<>(element, head);
           if ((boolean)headCAS.invokeExact(this, head, link)) {
             return;
           }
         }
       } catch (Throwable e) {
         throw new AssertionError(e.getMessage(), e);
       }
     }

     @Override
     public String toString() {
       StringBuilder builder = new StringBuilder().append('[');
       for(Link<?> l = head; l!= null; l = l.next) {
         builder.append(l.element).append(", ");
       }
       int length = builder.length();
       if (length != 0) {
         builder.setLength(length - 2);
       }
       return builder.append(']').toString();
     }
   }


   public static void main(String[] args) {
     LinkedLink<String> list = new LinkedLink<>();

     for(int i=0; i<100000; i++) {
       list.add(Integer.toString(i));
     }

     //System.out.println(list);
   }
}




From viktor.klang at gmail.com  Mon Dec 19 13:57:28 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 19 Dec 2011 19:57:28 +0100
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <4EEF823F.50600@univ-mlv.fr>
References: <4EEF823F.50600@univ-mlv.fr>
Message-ID: <CANPzfU9T-9-_rPABPgNzb14kXCokeMcEWr2hT91uzihrDF+tJA@mail.gmail.com>

Hi R?mi,

if this works then it sure has a lot of promise!

Cheers,
?

On Mon, Dec 19, 2011 at 7:28 PM, R?mi Forax <forax at univ-mlv.fr> wrote:

> Hi all,
> Some time ago, I said that we should try to use a MethodHandle instead of
> an Atomic*FieldUpdater and let the VM inline the method handle so there
> should be no cost (or a little one) compared to directly calling
> unsafe.compareAndSwapObject.
>
> The following code does exactly that, I have also include a small test
> that just demonstrates that it works.
> Because I'm neither a benchmark expert nor an assembler expert, I've just
> checked that the method handle is fully inlined by the JIT and that the
> generated code seems to don't have more code than it should.
>
> I know there is a lot of experts on this list, so experts am i wrong ?
>
> cheers,
> R?mi
>
> ------------------------------**------------------------------**
> ----------------------------
> package java.util.concurrent.atomic;
>
> import java.lang.invoke.MethodHandle;
> import java.lang.invoke.**MethodHandles;
> import java.lang.invoke.MethodType;
> import java.lang.reflect.Field;
> import java.lang.reflect.Modifier;
>
> import sun.misc.Unsafe;
>
> public class Volatiles {
>  private static final Unsafe unsafe = Unsafe.getUnsafe();
>
>  private static final MethodHandle CAS_OBJECT;
>  static {
>    try {
>      CAS_OBJECT = MethodHandles.publicLookup().**bind(unsafe,
> "compareAndSwapObject",
>          MethodType.methodType(boolean.**class, Object.class, long.class,
> Object.class, Object.class));
>    } catch (NoSuchMethodException|**IllegalAccessException e) {
>      throw new AssertionError(e.getMessage(), e);
>    }
>  }
>
>  public static MethodHandle compareAnSet(Class<?> declaringClass, String
> fieldName) {
>      Field field;
>      int modifiers;
>      try {
>        field = declaringClass.**getDeclaredField(fieldName);
>        Class<?> caller = sun.reflect.Reflection.**getCallerClass(2);
>        modifiers = field.getModifiers();
>        sun.reflect.misc.ReflectUtil.**ensureMemberAccess(
>            caller, declaringClass, null, modifiers);
>        sun.reflect.misc.ReflectUtil.**checkPackageAccess(**
> declaringClass);
>      } catch (NoSuchFieldException|**IllegalAccessException e) {
>        throw new IllegalArgumentException(e);
>      }
>
>      if (Modifier.isStatic(modifiers)) {
>        throw new IllegalArgumentException("**Field must not be static");
>      }
>      if (!Modifier.isVolatile(**modifiers)) {
>        throw new IllegalArgumentException("**Field must be volatile");
>      }
>
>      long offset = unsafe.objectFieldOffset(**field);
>      MethodHandle mh = MethodHandles.insertArguments(**CAS_OBJECT, 1,
> offset);
>      Class<?> fieldType = field.getType();
>      return mh.asType(MethodType.**methodType(boolean.class,
> declaringClass, fieldType, fieldType));
>  }
> }
>
> ------------------------------**------------------------------**-------
> import java.lang.invoke.MethodHandle;
> import java.util.concurrent.atomic.**Volatiles;
>
>
> public class CASTest {
>  static class Link<E> {
>    final E element;
>    final Link<E> next;
>
>    Link(E element, Link<E> next) {
>      this.element = element;
>      this.next = next;
>    }
>  }
>
>  static class LinkedLink<E> {
>    private volatile Link<E> head;
>
>    private static final MethodHandle headCAS = Volatiles.compareAnSet(**LinkedLink.class,
> "head");
>
>    public void add(E element) {
>      try {
>        for(;;) {
>          Link<E> head = this.head;
>          Link<E> link = new Link<>(element, head);
>          if ((boolean)headCAS.invokeExact(**this, head, link)) {
>            return;
>          }
>        }
>      } catch (Throwable e) {
>        throw new AssertionError(e.getMessage(), e);
>      }
>    }
>
>    @Override
>    public String toString() {
>      StringBuilder builder = new StringBuilder().append('[');
>      for(Link<?> l = head; l!= null; l = l.next) {
>        builder.append(l.element).**append(", ");
>      }
>      int length = builder.length();
>      if (length != 0) {
>        builder.setLength(length - 2);
>      }
>      return builder.append(']').toString()**;
>    }
>  }
>
>
>  public static void main(String[] args) {
>    LinkedLink<String> list = new LinkedLink<>();
>
>    for(int i=0; i<100000; i++) {
>      list.add(Integer.toString(i));
>    }
>
>    //System.out.println(list);
>  }
> }
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111219/ce74ed48/attachment.html>

From dl at cs.oswego.edu  Mon Dec 19 14:15:38 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 19 Dec 2011 14:15:38 -0500
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <4EEF823F.50600@univ-mlv.fr>
References: <4EEF823F.50600@univ-mlv.fr>
Message-ID: <4EEF8D5A.9020202@cs.oswego.edu>

On 12/19/11 13:28, R?mi Forax wrote:
> Hi all,
> Some time ago, I said that we should try to use a MethodHandle instead of an
> Atomic*FieldUpdater and let the VM inline the method handle so there should be
> no cost (or a little one) compared to directly calling unsafe.compareAndSwapObject.
>
> The following code does exactly that, I have also include a small test that just
> demonstrates that it works.
> Because I'm neither a benchmark expert nor an assembler expert, I've just
> checked that the method handle is fully inlined by the JIT and that the
> generated code seems to don't have more code than it should.

Thanks! This is potentially better than FieldUpdaters since it avoids
some of the dynamic type checks.  The checks inside your MethodHandle
returning method look either identical or compatible with updaters.

And on jdk7u2 (but not 1.7.0)  performance seems better.

I'll try experimenting with using this approach on the other various forms
(scalars; stores/loads; maybe somehow arrays) and contemplate a
general factory API that when put in place could be used instead
of updaters (and if all goes well, might even lead to deprecating them).

-Doug






From viktor.klang at gmail.com  Mon Dec 19 14:35:00 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 19 Dec 2011 20:35:00 +0100
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <4EEF8D5A.9020202@cs.oswego.edu>
References: <4EEF823F.50600@univ-mlv.fr>
	<4EEF8D5A.9020202@cs.oswego.edu>
Message-ID: <CANPzfU_QnFAV7kN5DTEtjS33RuASguPPq3kP2c136Z0nF5cXCQ@mail.gmail.com>

Excellent!
On Dec 19, 2011 8:19 PM, "Doug Lea" <dl at cs.oswego.edu> wrote:

> On 12/19/11 13:28, R?mi Forax wrote:
>
>> Hi all,
>> Some time ago, I said that we should try to use a MethodHandle instead of
>> an
>> Atomic*FieldUpdater and let the VM inline the method handle so there
>> should be
>> no cost (or a little one) compared to directly calling
>> unsafe.compareAndSwapObject.
>>
>> The following code does exactly that, I have also include a small test
>> that just
>> demonstrates that it works.
>> Because I'm neither a benchmark expert nor an assembler expert, I've just
>> checked that the method handle is fully inlined by the JIT and that the
>> generated code seems to don't have more code than it should.
>>
>
> Thanks! This is potentially better than FieldUpdaters since it avoids
> some of the dynamic type checks.  The checks inside your MethodHandle
> returning method look either identical or compatible with updaters.
>
> And on jdk7u2 (but not 1.7.0)  performance seems better.
>
> I'll try experimenting with using this approach on the other various forms
> (scalars; stores/loads; maybe somehow arrays) and contemplate a
> general factory API that when put in place could be used instead
> of updaters (and if all goes well, might even lead to deprecating them).
>
> -Doug
>
>
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111219/6318a12b/attachment.html>

From martinrb at google.com  Mon Dec 19 16:40:56 2011
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 19 Dec 2011 13:40:56 -0800
Subject: [concurrency-interest] synchronized constructors
In-Reply-To: <CAHjP37GncijTfWtWpvOvz8WQDc=wJ9ONsGtY_MMjRTHZs5-+ug@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIEPCJBAA.davidcholmes@aapt.net.au>
	<DF5B937E-7E15-4DCA-95A8-ABF3FFC630A1@rkuhn.info>
	<CAHjP37Gcq0P6KTd1=jcMEdyzSFHMjWBejt8jWNn6jpNzXW4OTw@mail.gmail.com>
	<5EC315E8-BC90-48E1-8A43-99DDF72D3C19@rkuhn.info>
	<CA+kOe09wVpPpbsZLx9i8c2durVpmkfKPdiEGVcLiHyNX7NF-ow@mail.gmail.com>
	<CAHjP37GncijTfWtWpvOvz8WQDc=wJ9ONsGtY_MMjRTHZs5-+ug@mail.gmail.com>
Message-ID: <CA+kOe0-aXFNYg1T3qOoS=qXyejm-gmnCo7q89zQVBs97r=5bCg@mail.gmail.com>

On Sun, Dec 18, 2011 at 13:56, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> Hi Martin,
>
> This seems a bit dubious since you can just mark your fields final.
>  What's the advantage of the dummy assignment? In Roland's case, he
> couldn't assign one of the fields in the constructor because it has to be
> done via a setter post construction but before publishing.
>
>
The idea is to prevent readers from ever observing the state of any of the
fields before the constructor completes.  For example, this can be used to
guarantee that the Object x in my example is never null.  Mutation after
construction is permitted (for example, all methods might be synchronized).

This is more of a thought experiment than a practical technique.  Most
people are OK with writing code that is incorrect, but never observed to
fail in practice, especially when there's safety in numbers.

Martin


> Regards,
>
> Vitaly
>
> On Sun, Dec 18, 2011 at 4:22 PM, Martin Buchholz <martinrb at google.com>wrote:
>
>>
>>
>> On Sun, Dec 18, 2011 at 13:02, Roland Kuhn <rk at rkuhn.info> wrote:
>>
>>> Yes, I would very much welcome a simple way achieving a fence, as you
>>> might imagine ;-)
>>>
>>
>> Many of us here would like to see a way to safely publish an object.
>>
>> ---
>>
>> Here's a solution no one has mentioned, but ought to be bullet-proof:
>>
>> public class MutableSafePublication {
>>     private int i;
>>     private Object x;
>>     private final MutableSafePublication safePublicationThis;
>>     private int i() { return safePublicationThis.i; }
>>     private Object x() { return safePublicationThis.x; }
>>     public MutableSafePublication() {
>>         i = 42;
>>         x = new Object();
>>         safePublicationThis = this;
>>     }
>>     // use i() and x() consistently in the implementation
>> }
>>
>>
>
>
> --
> Vitaly
> 617-548-7007 (mobile)
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111219/f66caa33/attachment-0001.html>

From elizarov at devexperts.com  Mon Dec 19 17:14:49 2011
From: elizarov at devexperts.com (Roman Elizarov)
Date: Mon, 19 Dec 2011 22:14:49 +0000
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <4EEF8D5A.9020202@cs.oswego.edu>
References: <4EEF823F.50600@univ-mlv.fr> <4EEF8D5A.9020202@cs.oswego.edu>
Message-ID: <C248BCD79E2CBC4B93C0AE3B1E77E9A80ACAA2BD@RAVEN.office.devexperts.com>

Is it possible to implement Atomic*FieldUpdater on top of the MethodHandle to Unsafe?
That is, place all checks in Atomic*FieldUpdater factory method, keep method handle(s) in final fields of updater and trivially implement CAS and other updater methods via method handle(s)? Can we thus get the best of two worlds -- type-safe and backwards-compatible API and better performance? // I assume, that HotSpot will be able to inline it all the way through, will not it? 

-----Original Message-----
From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Doug Lea
Sent: Monday, December 19, 2011 11:16 PM
To: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] CAS using a MethodHandle

On 12/19/11 13:28, R?mi Forax wrote:
> Hi all,
> Some time ago, I said that we should try to use a MethodHandle instead of an
> Atomic*FieldUpdater and let the VM inline the method handle so there should be
> no cost (or a little one) compared to directly calling unsafe.compareAndSwapObject.
>
> The following code does exactly that, I have also include a small test that just
> demonstrates that it works.
> Because I'm neither a benchmark expert nor an assembler expert, I've just
> checked that the method handle is fully inlined by the JIT and that the
> generated code seems to don't have more code than it should.

Thanks! This is potentially better than FieldUpdaters since it avoids
some of the dynamic type checks.  The checks inside your MethodHandle
returning method look either identical or compatible with updaters.

And on jdk7u2 (but not 1.7.0)  performance seems better.

I'll try experimenting with using this approach on the other various forms
(scalars; stores/loads; maybe somehow arrays) and contemplate a
general factory API that when put in place could be used instead
of updaters (and if all goes well, might even lead to deprecating them).

-Doug





_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From headius at headius.com  Mon Dec 19 18:54:10 2011
From: headius at headius.com (Charles Oliver Nutter)
Date: Mon, 19 Dec 2011 17:54:10 -0600
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <CAE-f1xSz_Sd60=NA1o7ZrT-p4ykdUm3+wKOjiR7mXJno=Dkfxg@mail.gmail.com>
References: <4EEF823F.50600@univ-mlv.fr>
	<CAE-f1xSz_Sd60=NA1o7ZrT-p4ykdUm3+wKOjiR7mXJno=Dkfxg@mail.gmail.com>
Message-ID: <CAE-f1xTMKiUQAW9nYN3aK-GHq_6TGdagG7xDpQR00_0O4VRqxA@mail.gmail.com>

Oops, this went only to R?mi...re-copying conc list.

 On Mon, Dec 19, 2011 at 12:28 PM, R?mi Forax <forax at univ-mlv.fr> wrote:
> Hi all,
> Some time ago, I said that we should try to use a MethodHandle instead of an
> Atomic*FieldUpdater and let the VM inline the method handle so there should
> be no cost (or a little one) compared to directly calling
> unsafe.compareAndSwapObject.
>
> The following code does exactly that, I have also include a small test that
> just demonstrates that it works.
> Because I'm neither a benchmark expert nor an assembler expert, I've just
> checked that the method handle is fully inlined by the JIT and that the
> generated code seems to don't have more code than it should.

FWIW, JRuby's using this pattern heavily to optimize several
volatile/atomic operations:

* When a class is modified, any code that has cached methods from that
class gets deoptimized. This avoids repeatedly pinging a volatile
serial number.
* When a constant is defined anywhere in the system, code that has
cached constants is deoptimized. This makes Ruby's constants
*actually* perform like constants...and in fact, they're faster and
optimize better than finals.

SwitchPoint is an incredibly sharp tool, but R?mi's example shows it
can do things that were previously impossible. I actually mocked up my
own SwitchPoint-based atomic updater last week...it's fun to play with
:)

- Charlie


From headius at headius.com  Mon Dec 19 18:58:40 2011
From: headius at headius.com (Charles Oliver Nutter)
Date: Mon, 19 Dec 2011 17:58:40 -0600
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <C248BCD79E2CBC4B93C0AE3B1E77E9A80ACAA2BD@RAVEN.office.devexperts.com>
References: <4EEF823F.50600@univ-mlv.fr> <4EEF8D5A.9020202@cs.oswego.edu>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80ACAA2BD@RAVEN.office.devexperts.com>
Message-ID: <CAE-f1xS1ebyGM486v4dYQWW2dZtnGmnpCNY_mfpW53j0A2jk7w@mail.gmail.com>

On Mon, Dec 19, 2011 at 4:14 PM, Roman Elizarov <elizarov at devexperts.com> wrote:
> Is it possible to implement Atomic*FieldUpdater on top of the MethodHandle to Unsafe?
> That is, place all checks in Atomic*FieldUpdater factory method, keep method handle(s) in final fields of updater and trivially implement CAS and other updater methods via method handle(s)? Can we thus get the best of two worlds -- type-safe and backwards-compatible API and better performance? // I assume, that HotSpot will be able to inline it all the way through, will not it?

It wouldn't necessarily inline, since the code inside
AtomicReferenceFieldUpdater would be polymorphic (i.e. a different
MethodHandle for each updater, but all called through the same path).

If it were possible to emit an invokedynamic into the Java code,
though, you could have an inlinable path:

invokedynamic -> MH for CAS -> Unsafe.CAS

Another option would be adding a method to AtomicReferenceFieldUpdater
that returns a MethodHandle for some of those opeerations...something
like

MethodHandle handle = ARFU.getCompareAndSwapHandle();
...
boolean result = (boolean)handle.invokeExact(this, expected, value);

I believe that would inline all the way through to Unsafe.

- Charlie


From headius at headius.com  Mon Dec 19 19:07:37 2011
From: headius at headius.com (Charles Oliver Nutter)
Date: Mon, 19 Dec 2011 18:07:37 -0600
Subject: [concurrency-interest] Why not expose array entry atomic/volatile
	operations directly?
Message-ID: <CAE-f1xR2V0xJ6EJCjofXLC9zvZnpmkQDinPnuHaUjJcuaTg77g@mail.gmail.com>

Maybe this has been beaten to death...feel free to tell me to shove
off and find the relevant FAQ or thread.

I was experimenting last week with making Ruby objects' instance
variables 100% volatile, mostly to see what sort of performance impact
would result. In the process, I tried two approaches:

* Replacing the variable table (Object[]) with an AtomicReferenceArray.

This worked as expected, but I saw more overhead than I would have
liked due to the additional object allocation and indirection through
ARA.

* Hand-copy the Unsafe logic from ARA into the Ruby Object base class,
avoiding the extra object and indirection.

This was still a larger perf hit than I'd want, but it did reduce the
overhead and object cost.

What surprised me was that a plain old array could be magically
treated as having volatile entries just by "cheating" and going
directly to unsafe. So my question is this...why isn't there an
AtomicReferenceArrayUpdater or similar "external" way to get
volatile/atomic behavior against array entries?

- Charlie

From headius at headius.com  Mon Dec 19 19:08:25 2011
From: headius at headius.com (Charles Oliver Nutter)
Date: Mon, 19 Dec 2011 18:08:25 -0600
Subject: [concurrency-interest] Why not expose array entry
	atomic/volatile operations directly?
In-Reply-To: <CAE-f1xR2V0xJ6EJCjofXLC9zvZnpmkQDinPnuHaUjJcuaTg77g@mail.gmail.com>
References: <CAE-f1xR2V0xJ6EJCjofXLC9zvZnpmkQDinPnuHaUjJcuaTg77g@mail.gmail.com>
Message-ID: <CAE-f1xRJJFGOp5y3jy6j1PnDNygyw82HdKRnEmD3AEJnFY9EFg@mail.gmail.com>

FWIW, here's the two approaches in patch form for JRuby:
https://gist.github.com/1490893

- Charlie

On Mon, Dec 19, 2011 at 6:07 PM, Charles Oliver Nutter
<headius at headius.com> wrote:
> Maybe this has been beaten to death...feel free to tell me to shove
> off and find the relevant FAQ or thread.
>
> I was experimenting last week with making Ruby objects' instance
> variables 100% volatile, mostly to see what sort of performance impact
> would result. In the process, I tried two approaches:
>
> * Replacing the variable table (Object[]) with an AtomicReferenceArray.
>
> This worked as expected, but I saw more overhead than I would have
> liked due to the additional object allocation and indirection through
> ARA.
>
> * Hand-copy the Unsafe logic from ARA into the Ruby Object base class,
> avoiding the extra object and indirection.
>
> This was still a larger perf hit than I'd want, but it did reduce the
> overhead and object cost.
>
> What surprised me was that a plain old array could be magically
> treated as having volatile entries just by "cheating" and going
> directly to unsafe. So my question is this...why isn't there an
> AtomicReferenceArrayUpdater or similar "external" way to get
> volatile/atomic behavior against array entries?
>
> - Charlie

From forax at univ-mlv.fr  Mon Dec 19 19:49:20 2011
From: forax at univ-mlv.fr (=?ISO-8859-1?Q?R=E9mi_Forax?=)
Date: Tue, 20 Dec 2011 01:49:20 +0100
Subject: [concurrency-interest] CAS using a MethodHandle
In-Reply-To: <CAE-f1xS1ebyGM486v4dYQWW2dZtnGmnpCNY_mfpW53j0A2jk7w@mail.gmail.com>
References: <4EEF823F.50600@univ-mlv.fr> <4EEF8D5A.9020202@cs.oswego.edu>
	<C248BCD79E2CBC4B93C0AE3B1E77E9A80ACAA2BD@RAVEN.office.devexperts.com>
	<CAE-f1xS1ebyGM486v4dYQWW2dZtnGmnpCNY_mfpW53j0A2jk7w@mail.gmail.com>
Message-ID: <4EEFDB90.3030101@univ-mlv.fr>

On 12/20/2011 12:58 AM, Charles Oliver Nutter wrote:
> On Mon, Dec 19, 2011 at 4:14 PM, Roman Elizarov<elizarov at devexperts.com>  wrote:
>> Is it possible to implement Atomic*FieldUpdater on top of the MethodHandle to Unsafe?
>> That is, place all checks in Atomic*FieldUpdater factory method, keep method handle(s) in final fields of updater and trivially implement CAS and other updater methods via method handle(s)? Can we thus get the best of two worlds -- type-safe and backwards-compatible API and better performance? // I assume, that HotSpot will be able to inline it all the way through, will not it?
> It wouldn't necessarily inline, since the code inside
> AtomicReferenceFieldUpdater would be polymorphic (i.e. a different
> MethodHandle for each updater, but all called through the same path).
>
> If it were possible to emit an invokedynamic into the Java code,
> though, you could have an inlinable path:
>
> invokedynamic ->  MH for CAS ->  Unsafe.CAS

If we had a way to tell the compiler to generate an invokedynamic 
instead of an invokesomething,
then we will be able to control more closely how the things are optimized.
It will simplify an insane number of problem like proxies, aop, O/R 
mapping, SQL mapping*, etc.

* you can by example create the SQL statement corresponding to a String 
and inject it in place of the string
   if the string is constant.

>
> Another option would be adding a method to AtomicReferenceFieldUpdater
> that returns a MethodHandle for some of those opeerations...something
> like
>
> MethodHandle handle = ARFU.getCompareAndSwapHandle();
> ...
> boolean result = (boolean)handle.invokeExact(this, expected, value);
>
> I believe that would inline all the way through to Unsafe.

if the two lines of code are part of the same inlining blob, which is 
sometimes not easy to predict.
I also think that there is perhaps still a perf bug in this case with 
the current version of Hotspot
because the escape analysis may not see through invokeExact.

>
> - Charlie

R?mi


From howard.lovatt at gmail.com  Mon Dec 19 21:09:26 2011
From: howard.lovatt at gmail.com (Howard Lovatt)
Date: Tue, 20 Dec 2011 13:09:26 +1100
Subject: [concurrency-interest] Low latency queue of length 1
Message-ID: <CACR_FB6g72nr4bdXTRmSP9SPMD+vh9zqxFsaOueqXcknH8BH1w@mail.gmail.com>

Hi,

I saw this post:

http://vanillajava.blogspot.com/2011/11/java-puzzle-low-latency-queue.html

and experimented myself with various implementations of a producer consumer
queue (which I have an interest in for passing arguments to methods run in
parallel). My test code is:

public final class HangingTest {
  private static final long loops = 1000 * 1000;

  private static final long poison = 0;

  public static void main( final String... notUsed ) throws
InterruptedException {
    test( new SynchronousPT(), true );
    test( new SynchronousPT(), false );
    test( new BlockingPT(), true );
    test( new BlockingPT(), false );
    test( new AtomicPT(), true );
    test( new AtomicPT(), false );
    test( new VolatilePT(), true );
    test( new VolatilePT(), false );
    test( new NothingPT(), true );
    test( new NothingPT(), false );
  }

  private static void test( final AbstractPT pT, final boolean noError )
      throws InterruptedException {
    System.gc();
    System.gc();
    final class Put implements Callable<Void> {
      final boolean isMax;
      Put( final boolean isMax ) { this.isMax = isMax; }
      @Override public Void call() throws InterruptedException {
        if ( !noError ) { pT.put( poison ); }
        for ( long l = poison + 1; l < loops; l++ ) {
          pT.put( isMax ? l : -l );
        }
        return null;
      }
    }

    final class Take implements Callable<Void> {
      @Override public Void call() throws InterruptedException,
IllegalStateException {
        for ( long max = poison, min = poison;; ) {
          final long value = pT.take();
          if ( value >= 0 ) {
            if ( value <= max ) { throw new IllegalStateException(); }
            max = value;
          } else {
            if ( value >= min ) { throw new IllegalStateException(); }
            min = value;
          }
        }
      }
    }
    final ExecutorService pool = Executors.newCachedThreadPool();
    final long start = System.nanoTime();
    try {
//      pool.invokeAny( Arrays.asList( ... ) ); // Does not work!
      myInvokeAny( pool, new Put( true ), new Put( false ), new Take(), new
Take() );
    } catch ( final ExecutionException e ) {
      System.err.println( e );
    }
    final long finish = System.nanoTime();
    System.out.println( pT.toString() + " (" + noError + ")" + " took on
average " +
                            ( ( finish - start ) / loops ) + " ns" );
    pool.shutdown();
  }

  // Not same semantics as ExecutorService invokeAny!
  @SafeVarargs private static void myInvokeAny( final ExecutorService pool,
                                                final Callable<Void>...
callables )
      throws InterruptedException, ExecutionException {
    final List<Future<Void>> futures = new ArrayList<Future<Void>>();
    for ( final Callable<Void> callable : callables ) {
      futures.add( pool.submit( callable ) );
    }
    for ( ;; ) {
      for ( final Future<Void> future : futures ) {
        if ( future.isDone() ) {
          for ( final Future<Void> toCancel : futures ) {
            toCancel.cancel( true );
          }
          for ( final Future<Void> toTest : futures ) {
            if ( !toTest.isCancelled() ) {
              toTest.get(); // Test for any exceptions
            }
          }
          return;
        }
      }
      Thread.sleep( 0 ); // Wait for other threads
    }
  }

  private abstract static class AbstractPT {
    abstract void put( final long value ) throws InterruptedException;

    abstract long take() throws InterruptedException;

    @Override public final String toString() { return
getClass().getSimpleName(); }
  }

  private static final class SynchronousPT extends AbstractPT {
    final BlockingQueue<Long> queue = new SynchronousQueue<Long>();

    @Override void put( final long value ) throws InterruptedException {
queue.put( value ); }

    @Override long take() throws InterruptedException { return
queue.take(); }
  }

  private static final class BlockingPT extends AbstractPT {
    final BlockingQueue<Long> queue = new ArrayBlockingQueue<Long>( 1 );

    @Override void put( final long value ) throws InterruptedException {
queue.put( value ); }

    @Override long take() throws InterruptedException { return
queue.take(); }
  }

  private static final class AtomicPT extends AbstractPT {
    final AtomicReference<Long> queue = new AtomicReference<Long>();

    @Override void put( final long value ) throws InterruptedException {
      while ( !queue.compareAndSet( null, value ) ) {
        Thread.sleep( 0 ); // Wait for other thread
      }
    }

    @Override long take() throws InterruptedException {
      Long t;
      do {
        Thread.sleep( 0 ); // Wait for other thread
        t = queue.getAndSet( null );
      } while ( t == null );
      return t;
    }
  }

  private static final class VolatilePT extends AbstractPT {
    volatile Long queue = null;

    @Override void put( final long value ) throws InterruptedException {
      while ( queue != null ) {
        Thread.sleep( 0 ); // Wait for other thread
      }
      queue = value;
    }

    @Override long take() throws InterruptedException {
      Long t;
      do {
        Thread.sleep( 0 ); // Wait for other thread
        t = queue;
      } while ( t == null );
      queue = null;
      return t;
    }
  }

  private static final class NothingPT extends AbstractPT {
    Long queue = null;

    @Override void put( final long value ) throws InterruptedException {
      while ( queue != null ) {
        Thread.sleep( 0 ); // Wait for other thread
      }
      queue = value;
    }

    @Override long take() throws InterruptedException {
      Long t;
      do {
        Thread.sleep( 0 ); // Wait for other thread
        t = queue;
      } while ( t == null );
      queue = null;
      return t;
    }
  }
}

The above gives:

SynchronousPT (true) took on average 2759 ns
SynchronousPT (false) took on average 0 ns
java.util.concurrent.ExecutionException: java.lang.IllegalStateException
BlockingPT (true) took on average 16203 ns
BlockingPT (false) took on average 0 ns
java.util.concurrent.ExecutionException: java.lang.IllegalStateException
AtomicPT (true) took on average 562 ns
AtomicPT (false) took on average 0 ns
java.util.concurrent.ExecutionException: java.lang.IllegalStateException
VolatilePT (true) took on average 492 ns
VolatilePT (false) took on average 0 ns
java.util.concurrent.ExecutionException: java.lang.IllegalStateException
NothingPT (true) took on average 549 ns
NothingPT (false) took on average 0 ns
java.util.concurrent.ExecutionException: java.lang.IllegalStateException
BUILD SUCCESSFUL (total time: 21 seconds)

when run from Netbeans via Ant on my quad core MacBookPro running a 64 bit
server JVM (JDK7).

I noticed that:

   1. Atomic, Volatile, and Nothing were all about the same time. I was
   surprised that Nothing wasn't quicker than the others (also see next point)?
   2. I don't no why Volatile and Nothing work! There is
   no synchronisation or similar?
   3. I don't no why sleep is needed to prevent hanging? If I remove any of
   the calls to sleep in the above code the program hangs.
   4. I don't no why ExecutorService.invokeAny didn't work? It hung.
   5. Why is Synchronous so slow?
   6. Why is Blocking even slower?

Can anyone shed light on the above notes? Do you get the same results on
your machine?

Thanks in advance for any words of wisdom,

  -- Howard.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111220/3f42edaf/attachment-0001.html>

From Johannes.Lichtenberger at uni-konstanz.de  Tue Dec 20 14:33:04 2011
From: Johannes.Lichtenberger at uni-konstanz.de (Johannes.Lichtenberger)
Date: Tue, 20 Dec 2011 20:33:04 +0100
Subject: [concurrency-interest] Concurrent axis steps in a tree-structure
Message-ID: <4EF0E2F0.1020202@uni-konstanz.de>

Already posted on stackoverflow and the Akka (akka.io) mailinglist.

We are researching a secure tree-based cloud storage system. We have
for instance several Axis-implementations (all XPath-Axis and a
LevelOrderAxis, PostOrderAxis..., NestedAxis, FilterAxis...).
I want to rewrite our axis-implementations sometime in the first
quarter next year to use multithreading. I'm currently not sure if I
would really gain any benefit, but as it most likely involves I/O if
nothing is in the cache (which might be almost everytime during an axis
step) even though the nodes can be get from pages through a simple
offset it will involve I/ O for each node similar to a directory
traversal in the Filesystem. Furthermore I've added visitor support for
our DescendantAxis which is traversing a tree in preorder.
I've copy/pasted the following code from hasNext() (Iterator
implementation):

http://www.heypasteit.com/clip/05IJ

I think it should be pretty self-explanatory, the transaction is more
or less a cursor traversing the tree-structure. Now I'm not sure how I
should divide the work and if it really makes sense. For example on
level 1 split the task for all second nodes. But it might be that the
tree is deep, even though regarding XML it seems most trees are rather
"wide" instead of deep. The idea is if we can speed up the traversal
such that we don't have to implement Path-/Element-/ and Text-Indexes
(as well as incremental updates thereof) as our main goal is to provide
an open source secure framework for tree-structured data which evolves
over time (through snapshots) for the Cloud (research project).
Furthermore besides considering if it really makes sense for very
large trees (1GB on disk and much more) I'm considering using either
Java7 fork/join or Akka actors. What do you think? How should I split
the task, as we currently don't save the descendant-count of each
node (which might also be added, as we provide and update hashes for
the integrity and could as well add/change the descendant count for
each modification to the tree).

It's just a simple idea that one must not implement indexes, but I
don't know (indexes are for sure faster if they can be used, but I
suppose also much more work considering that we optimized everything
for updates/modifications of the tree -- and it would need incremental
Path-/Element-/Value-indexes plus we don't intend to win any
performance benchmarks ;-)). Furthermore it would support our Saxon
integration (to support XPath 2.0, XQuery 1.0 and XSLT 2.0) as Saxon
uses it's own indexes (if at all) and just makes use of our axis and
other method-implementations.

I think it also pretty much now depends on the visitor, which can be
plugged in optionally, if the axis is fast or not. As such I just wanted
to learn the new Fork-/Join-Framework or maybe even Akka, as I'm
interested in learning newer concurrency aspects as for instance the
Fork-/Join-Framework and STM/Actors on the JVM. That said I'm not sure
if the axis are the right thing to use concurrency. Maybe other aspects
of a persistent tree-storage system would benefit much more. I'm
interested in any use cases ;-)

The main benefit I suppose would be on very large trees, where we have
to find specific nodes, that is we really traverse the whole tree.

best regards,
Johannes

From navin.jha at citi.com  Wed Dec 21 10:45:28 2011
From: navin.jha at citi.com (Jha, Navin )
Date: Wed, 21 Dec 2011 09:45:28 -0600
Subject: [concurrency-interest] general performance question
Message-ID: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>

Is there an advantage to do:

someMethod(...) {
        synchronized(this) {
                ................
                ................
                ................
        }
}

instead of:
synchronized someMethod(...) {
................
................
................
}

Even when the entire method needs to be synchronized? I understand in general it is a good practice to use synchronized blocks since more often than not only certain lines need to be synchronized.

-Navin


From nathan.reynolds at oracle.com  Wed Dec 21 11:45:35 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 21 Dec 2011 09:45:35 -0700
Subject: [concurrency-interest] general performance question
In-Reply-To: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
Message-ID: <4EF20D2F.1030409@oracle.com>

Use javap to check the bytecode output from both.  From a performance 
perspective, I don't think it shouldn't matter.  However, from an API 
perspective it matters.  Let's say you derive the class and implement 
someMethod.  If the synchronized keyword is on the method, then Eclipse 
or FindBugs could be configured to warn you that the overridden method 
doesn't declare synchronized.  The tool suggests that this means the 
overridden method is not correctly synchronized.  On the other hand, 
"synchronized(this)" will trigger Eclipse or FindBugs to warn you that 
the code is synchronizing on a publicly accessible object.  This means 
that if another piece of code synchronizes on the object then there 
might be an unintended scalability problem.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/21/2011 8:45 AM, Jha, Navin wrote:
> Is there an advantage to do:
>
> someMethod(...) {
>          synchronized(this) {
>                  ................
>                  ................
>                  ................
>          }
> }
>
> instead of:
> synchronized someMethod(...) {
> ................
> ................
> ................
> }
>
> Even when the entire method needs to be synchronized? I understand in general it is a good practice to use synchronized blocks since more often than not only certain lines need to be synchronized.
>
> -Navin
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/3ca7d25a/attachment.html>

From vitalyd at gmail.com  Wed Dec 21 12:33:39 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 21 Dec 2011 12:33:39 -0500
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF20D2F.1030409@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
Message-ID: <CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>

IIRC, synch on method generates less bytecode but that would only matter if
the method was on the bytecode size boundary for inlining (I believe
default is 35 byte codes), but i think synchronization already prevents
inlining as a heuristic.
On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  Use javap to check the bytecode output from both.  From a performance
> perspective, I don't think it shouldn't matter.  However, from an API
> perspective it matters.  Let's say you derive the class and implement
> someMethod.  If the synchronized keyword is on the method, then Eclipse or
> FindBugs could be configured to warn you that the overridden method doesn't
> declare synchronized.  The tool suggests that this means the overridden
> method is not correctly synchronized.  On the other hand,
> "synchronized(this)" will trigger Eclipse or FindBugs to warn you that the
> code is synchronizing on a publicly accessible object.  This means that if
> another piece of code synchronizes on the object then there might be an
> unintended scalability problem.
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/21/2011 8:45 AM, Jha, Navin wrote:
>
> Is there an advantage to do:
>
> someMethod(...) {
>         synchronized(this) {
>                 ................
>                 ................
>                 ................
>         }
> }
>
> instead of:
> synchronized someMethod(...) {
> ................
> ................
> ................
> }
>
> Even when the entire method needs to be synchronized? I understand in general it is a good practice to use synchronized blocks since more often than not only certain lines need to be synchronized.
>
> -Navin
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/013a3284/attachment.html>

From cheremin at gmail.com  Wed Dec 21 12:42:01 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Wed, 21 Dec 2011 21:42:01 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
Message-ID: <CAOwENiKcMtjJRQMZJ-X4Kc67MdVGgn4uuLO=kEUe-oDrodChVw@mail.gmail.com>

I've heard about this issue before, but I can't believe it is still
actual -- doesn't modern JIT smart enough to count inlining threshold
by generated machine code instructions (which I believe will be the
same in both cases), and not on source bytecodes?

2011/12/21 Vitaly Davidovich <vitalyd at gmail.com>:
> IIRC, synch on method generates less bytecode but that would only matter if
> the method was on the bytecode size boundary for inlining (I believe default
> is 35 byte codes), but i think synchronization already prevents inlining as
> a heuristic.
>
> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
> wrote:
>>
>> Use javap to check the bytecode output from both.? From a performance
>> perspective, I don't think it shouldn't matter.? However, from an API
>> perspective it matters.? Let's say you derive the class and implement
>> someMethod.? If the synchronized keyword is on the method, then Eclipse or
>> FindBugs could be configured to warn you that the overridden method doesn't
>> declare synchronized.? The tool suggests that this means the overridden
>> method is not correctly synchronized.? On the other hand,
>> "synchronized(this)" will trigger Eclipse or FindBugs to warn you that the
>> code is synchronizing on a publicly accessible object.? This means that if
>> another piece of code synchronizes on the object then there might be an
>> unintended scalability problem.
>>
>> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering | Server Technology
>>
>> On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>
>> Is there an advantage to do:
>>
>> someMethod(...) {
>>         synchronized(this) {
>>                 ................
>>                 ................
>>                 ................
>>         }
>> }
>>
>> instead of:
>> synchronized someMethod(...) {
>> ................
>> ................
>> ................
>> }
>>
>> Even when the entire method needs to be synchronized? I understand in
>> general it is a good practice to use synchronized blocks since more often
>> than not only certain lines need to be synchronized.
>>
>> -Navin
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From bmeike at speakeasy.net  Wed Dec 21 13:04:11 2011
From: bmeike at speakeasy.net (Blake Meike)
Date: Wed, 21 Dec 2011 10:04:11 -0800
Subject: [concurrency-interest] Concurrency in Android
Message-ID: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>

Hi,
  I'd be interested to know if there is anyone is looking, specifically, at the concurrency picture in Android.  I understand that this is somewhat off-topic, in a group that tends to the theoretical and Java.  Android has many similarities to Java, though, including the source language, a JVM and a JIT and is surely in fruitful topic for concurrency-interest.

  I had a discussion, a few months ago, with frequent contributor here, Joe Bowbeer, about shared concerns for the interaction of the Android managed application model and its AsyncTask framework.  I came away from that discussion convinced that it is all but impossible to use the framework in a thread-safe way.  I'd be interested in hearing about (and participating in!) any other evaluation of the Android platform, from a concurrency perspective.

Thanks
  -blake

From vitalyd at gmail.com  Wed Dec 21 13:09:09 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 21 Dec 2011 13:09:09 -0500
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAOwENiKcMtjJRQMZJ-X4Kc67MdVGgn4uuLO=kEUe-oDrodChVw@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<CAOwENiKcMtjJRQMZJ-X4Kc67MdVGgn4uuLO=kEUe-oDrodChVw@mail.gmail.com>
Message-ID: <CAHjP37H8D8N+ehH5ETvX=B-fLqMU9qZbsMD+KMS7gdtzny3kSQ@mail.gmail.com>

I agree that it's unfortunate but I think it's still the case today (so
even adding dummy locals/temps that will surely optimize out may bump a
method out of inlining).

My guess is that this is done to reduce compilation time.  Since
compilation is done on a method at a time basis, the compiler has to decide
quickly whether to inline or not and it's of course faster if it uses
simple (I.e. quick) heuristics rather than potentially generating two
different flavors (inlined callee and not) and pitching one away.

Having said that, would be great to know the real reason from someone on
the compiler team.
On Dec 21, 2011 12:42 PM, "Ruslan Cheremin" <cheremin at gmail.com> wrote:

> I've heard about this issue before, but I can't believe it is still
> actual -- doesn't modern JIT smart enough to count inlining threshold
> by generated machine code instructions (which I believe will be the
> same in both cases), and not on source bytecodes?
>
> 2011/12/21 Vitaly Davidovich <vitalyd at gmail.com>:
> > IIRC, synch on method generates less bytecode but that would only matter
> if
> > the method was on the bytecode size boundary for inlining (I believe
> default
> > is 35 byte codes), but i think synchronization already prevents inlining
> as
> > a heuristic.
> >
> > On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
> > wrote:
> >>
> >> Use javap to check the bytecode output from both.  From a performance
> >> perspective, I don't think it shouldn't matter.  However, from an API
> >> perspective it matters.  Let's say you derive the class and implement
> >> someMethod.  If the synchronized keyword is on the method, then Eclipse
> or
> >> FindBugs could be configured to warn you that the overridden method
> doesn't
> >> declare synchronized.  The tool suggests that this means the overridden
> >> method is not correctly synchronized.  On the other hand,
> >> "synchronized(this)" will trigger Eclipse or FindBugs to warn you that
> the
> >> code is synchronizing on a publicly accessible object.  This means that
> if
> >> another piece of code synchronizes on the object then there might be an
> >> unintended scalability problem.
> >>
> >> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
> >> Oracle PSR Engineering | Server Technology
> >>
> >> On 12/21/2011 8:45 AM, Jha, Navin wrote:
> >>
> >> Is there an advantage to do:
> >>
> >> someMethod(...) {
> >>         synchronized(this) {
> >>                 ................
> >>                 ................
> >>                 ................
> >>         }
> >> }
> >>
> >> instead of:
> >> synchronized someMethod(...) {
> >> ................
> >> ................
> >> ................
> >> }
> >>
> >> Even when the entire method needs to be synchronized? I understand in
> >> general it is a good practice to use synchronized blocks since more
> often
> >> than not only certain lines need to be synchronized.
> >>
> >> -Navin
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/61e81b18/attachment.html>

From viktor.klang at gmail.com  Wed Dec 21 13:40:09 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 21 Dec 2011 19:40:09 +0100
Subject: [concurrency-interest] Concurrency in Android
In-Reply-To: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
References: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
Message-ID: <CANPzfU9Zavu+gMhod+Dt0VwD5T_154n5LzVW94kJ_wbtOd2b-w@mail.gmail.com>

Hi Blake,

We've heard that people are using Akka on Android.
Feel free to take it for a spin,

Cheers,
?

On Wed, Dec 21, 2011 at 7:04 PM, Blake Meike <bmeike at speakeasy.net> wrote:

> Hi,
>  I'd be interested to know if there is anyone is looking, specifically, at
> the concurrency picture in Android.  I understand that this is somewhat
> off-topic, in a group that tends to the theoretical and Java.  Android has
> many similarities to Java, though, including the source language, a JVM and
> a JIT and is surely in fruitful topic for concurrency-interest.
>
>  I had a discussion, a few months ago, with frequent contributor here, Joe
> Bowbeer, about shared concerns for the interaction of the Android managed
> application model and its AsyncTask framework.  I came away from that
> discussion convinced that it is all but impossible to use the framework in
> a thread-safe way.  I'd be interested in hearing about (and participating
> in!) any other evaluation of the Android platform, from a concurrency
> perspective.
>
> Thanks
>  -blake
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/25fdb9d7/attachment-0001.html>

From viktor.klang at gmail.com  Wed Dec 21 13:43:06 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 21 Dec 2011 19:43:06 +0100
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAHjP37H8D8N+ehH5ETvX=B-fLqMU9qZbsMD+KMS7gdtzny3kSQ@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<CAOwENiKcMtjJRQMZJ-X4Kc67MdVGgn4uuLO=kEUe-oDrodChVw@mail.gmail.com>
	<CAHjP37H8D8N+ehH5ETvX=B-fLqMU9qZbsMD+KMS7gdtzny3kSQ@mail.gmail.com>
Message-ID: <CANPzfU9WeNdek3G6t9MRvjFLyykV76jT3mnwX4b1fzBVtrL4mg@mail.gmail.com>

Would be nice to allow for:

synchronized class Foo {
 ...constructor + all non-private methods are synchronized.
}

On Wed, Dec 21, 2011 at 7:09 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> I agree that it's unfortunate but I think it's still the case today (so
> even adding dummy locals/temps that will surely optimize out may bump a
> method out of inlining).
>
> My guess is that this is done to reduce compilation time.  Since
> compilation is done on a method at a time basis, the compiler has to decide
> quickly whether to inline or not and it's of course faster if it uses
> simple (I.e. quick) heuristics rather than potentially generating two
> different flavors (inlined callee and not) and pitching one away.
>
> Having said that, would be great to know the real reason from someone on
> the compiler team.
> On Dec 21, 2011 12:42 PM, "Ruslan Cheremin" <cheremin at gmail.com> wrote:
>
>> I've heard about this issue before, but I can't believe it is still
>> actual -- doesn't modern JIT smart enough to count inlining threshold
>> by generated machine code instructions (which I believe will be the
>> same in both cases), and not on source bytecodes?
>>
>> 2011/12/21 Vitaly Davidovich <vitalyd at gmail.com>:
>> > IIRC, synch on method generates less bytecode but that would only
>> matter if
>> > the method was on the bytecode size boundary for inlining (I believe
>> default
>> > is 35 byte codes), but i think synchronization already prevents
>> inlining as
>> > a heuristic.
>> >
>> > On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>> >
>> > wrote:
>> >>
>> >> Use javap to check the bytecode output from both.  From a performance
>> >> perspective, I don't think it shouldn't matter.  However, from an API
>> >> perspective it matters.  Let's say you derive the class and implement
>> >> someMethod.  If the synchronized keyword is on the method, then
>> Eclipse or
>> >> FindBugs could be configured to warn you that the overridden method
>> doesn't
>> >> declare synchronized.  The tool suggests that this means the overridden
>> >> method is not correctly synchronized.  On the other hand,
>> >> "synchronized(this)" will trigger Eclipse or FindBugs to warn you that
>> the
>> >> code is synchronizing on a publicly accessible object.  This means
>> that if
>> >> another piece of code synchronizes on the object then there might be an
>> >> unintended scalability problem.
>> >>
>> >> Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
>> >> Oracle PSR Engineering | Server Technology
>> >>
>> >> On 12/21/2011 8:45 AM, Jha, Navin wrote:
>> >>
>> >> Is there an advantage to do:
>> >>
>> >> someMethod(...) {
>> >>         synchronized(this) {
>> >>                 ................
>> >>                 ................
>> >>                 ................
>> >>         }
>> >> }
>> >>
>> >> instead of:
>> >> synchronized someMethod(...) {
>> >> ................
>> >> ................
>> >> ................
>> >> }
>> >>
>> >> Even when the entire method needs to be synchronized? I understand in
>> >> general it is a good practice to use synchronized blocks since more
>> often
>> >> than not only certain lines need to be synchronized.
>> >>
>> >> -Navin
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/f47bb406/attachment.html>

From heinz at javaspecialists.eu  Wed Dec 21 14:18:56 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 21 Dec 2011 21:18:56 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
Message-ID: <4EF23120.60004@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/cca2cb9a/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen shot 2011-12-21 at 9.16.07 PM.png
Type: image/png
Size: 166279 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/cca2cb9a/attachment-0001.png>

From joe.bowbeer at gmail.com  Wed Dec 21 15:36:58 2011
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Wed, 21 Dec 2011 12:36:58 -0800
Subject: [concurrency-interest] Concurrency in Android
In-Reply-To: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
References: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
Message-ID: <CAHzJPEo5T+OrfPjJ+vYRWN1fNb3+VoxdZ=WMqHDKN2PiEti3=A@mail.gmail.com>

Hi Blake!

Android's AsyncTask corresponds to Java SE's SwingWorker.  Both are
designed for subclassing, with one abstract method that executes on a
managed background thread and a second method that executes on the main
application thread.  Android's AsyncTask is made more complicated by the
fact that the UI context is blown away (by default) every time the handset
rotates.  SwingWorker is not often discussed on this list, but whenever it
is I usually plug my old article "The Last Word in Swing Threads".  Cool
title.  Anyway, I'd be happy to continue our discussion on this list if
there's interest.  I should also mention, in case it's not clear to
everyone, that Android includes all of java.util.concurrent, unmodified as
far as I know, and I believe a j.u.c. ThreadPoolExecutor is powering the
AsyncTask executions, right?

Joe

On Wed, Dec 21, 2011 at 10:04 AM, Blake Meike wrote:

> Hi,
>  I'd be interested to know if there is anyone is looking, specifically, at
> the concurrency picture in Android.  I understand that this is somewhat
> off-topic, in a group that tends to the theoretical and Java.  Android has
> many similarities to Java, though, including the source language, a JVM and
> a JIT and is surely in fruitful topic for concurrency-interest.
>
>  I had a discussion, a few months ago, with frequent contributor here, Joe
> Bowbeer, about shared concerns for the interaction of the Android managed
> application model and its AsyncTask framework.  I came away from that
> discussion convinced that it is all but impossible to use the framework in
> a thread-safe way.  I'd be interested in hearing about (and participating
> in!) any other evaluation of the Android platform, from a concurrency
> perspective.
>
> Thanks
>  -blake
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/55bb612c/attachment.html>

From kumpera at gmail.com  Wed Dec 21 15:59:19 2011
From: kumpera at gmail.com (Rodrigo Kumpera)
Date: Wed, 21 Dec 2011 18:59:19 -0200
Subject: [concurrency-interest] Concurrency in Android
In-Reply-To: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
References: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
Message-ID: <CACmR+BAmwpfJK4dv4+jBGy_0pCT1hSB2VhQw9bXD1MN5=Z_iRw@mail.gmail.com>

Beware that Android doesn't follow the JMM on arm devices.
It implements acquire/release semantics for volatiles, which is not the
same as the JMM.


On Wed, Dec 21, 2011 at 4:04 PM, Blake Meike <bmeike at speakeasy.net> wrote:

> Hi,
>  I'd be interested to know if there is anyone is looking, specifically, at
> the concurrency picture in Android.  I understand that this is somewhat
> off-topic, in a group that tends to the theoretical and Java.  Android has
> many similarities to Java, though, including the source language, a JVM and
> a JIT and is surely in fruitful topic for concurrency-interest.
>
>  I had a discussion, a few months ago, with frequent contributor here, Joe
> Bowbeer, about shared concerns for the interaction of the Android managed
> application model and its AsyncTask framework.  I came away from that
> discussion convinced that it is all but impossible to use the framework in
> a thread-safe way.  I'd be interested in hearing about (and participating
> in!) any other evaluation of the Android platform, from a concurrency
> perspective.
>
> Thanks
>  -blake
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/41b796d5/attachment.html>

From vladimir.x.ivanov at oracle.com  Wed Dec 21 16:37:00 2011
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Thu, 22 Dec 2011 01:37:00 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
Message-ID: <4EF2517C.90702@oracle.com>

Vitaly,

No, synchronized attribute doesn't prevent method from being inlined by 
JIT compiler in Hotspot. Lock coarsening(redundant lock elimination) 
optimization [1] [2] in C2 greatly benefits from this.

Best regards,
Vladimir Ivanov

[1] 
http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2
[2] 
http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213

On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
> IIRC, synch on method generates less bytecode but that would only matter
> if the method was on the bytecode size boundary for inlining (I believe
> default is 35 byte codes), but i think synchronization already prevents
> inlining as a heuristic.
>
> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
> <mailto:nathan.reynolds at oracle.com>> wrote:
>
>     Use javap to check the bytecode output from both.  From a
>     performance perspective, I don't think it shouldn't matter.
>     However, from an API perspective it matters.  Let's say you derive
>     the class and implement someMethod.  If the synchronized keyword is
>     on the method, then Eclipse or FindBugs could be configured to warn
>     you that the overridden method doesn't declare synchronized.  The
>     tool suggests that this means the overridden method is not correctly
>     synchronized.  On the other hand, "synchronized(this)" will trigger
>     Eclipse or FindBugs to warn you that the code is synchronizing on a
>     publicly accessible object.  This means that if another piece of
>     code synchronizes on the object then there might be an unintended
>     scalability problem.
>
>     Nathan Reynolds
>     <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>     Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>     Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
>     On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>     Is there an advantage to do:
>>
>>     someMethod(...) {
>>              synchronized(this) {
>>                      ................
>>                      ................
>>                      ................
>>              }
>>     }
>>
>>     instead of:
>>     synchronized someMethod(...) {
>>     ................
>>     ................
>>     ................
>>     }
>>
>>     Even when the entire method needs to be synchronized? I understand in general it is a good practice to use synchronized blocks since more often than not only certain lines need to be synchronized.
>>
>>     -Navin
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From heinz at javaspecialists.eu  Wed Dec 21 17:27:41 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 22 Dec 2011 00:27:41 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2517C.90702@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>	<4EF20D2F.1030409@oracle.com>	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
Message-ID: <4EF25D5D.4040507@javaspecialists.eu>

My benchmark shows in most cases a small performance gain when you use 
an inner synchronized block.  However, the difference is really very 
small and is only in contended locks.  Uncontended locks are optimized 
away, so that does not count.

On my 8-core machine, I call the methods lots of times with random 
values from a pre-filled array to stop the HotSpot compiler from 
eliminating my code.

If the synchronized block is inside the method, we have the following 
test duration in average and standard deviation.  Times are in ms.  
Small numbers are good, large numbers bad.  High standard deviation 
means the results are all over the place.

1 Thread:        20 (1.8)
2 Threads:    465 (53)
4 Threads:    889 (170)
8 Threads:    958 (137)
16 Threads:  629 (69)
32 Threads:  578 (66)

When the whole method is synchronized:

1 Thread:        20 (0.5)
2 Threads:    488 (45)
4 Threads:    920 (145)
8 Threads:    1037 (90)
16 Threads:  612 (70)
32 Threads:  645 (74)

However, as much as I would love these results to prove that my initial 
theoretical explanation was right, I think it's too close to call.  
Neither is great.  If you want good scalability (which is the *only* 
performance reason you'd care about this) then you want to rather try to 
avoid locking altogether and use non-blocking synchronization constructs.

I hope this helped.  My test code and raw results are available on demand.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 12/21/11 11:37 PM, Vladimir Ivanov wrote:
> Vitaly,
>
> No, synchronized attribute doesn't prevent method from being inlined 
> by JIT compiler in Hotspot. Lock coarsening(redundant lock 
> elimination) optimization [1] [2] in C2 greatly benefits from this.
>
> Best regards,
> Vladimir Ivanov
>
> [1] 
> http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2 
>
> [2] 
> http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213 
>
>
> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>> IIRC, synch on method generates less bytecode but that would only matter
>> if the method was on the bytecode size boundary for inlining (I believe
>> default is 35 byte codes), but i think synchronization already prevents
>> inlining as a heuristic.
>>
>> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>> <mailto:nathan.reynolds at oracle.com>> wrote:
>>
>>     Use javap to check the bytecode output from both.  From a
>>     performance perspective, I don't think it shouldn't matter.
>>     However, from an API perspective it matters.  Let's say you derive
>>     the class and implement someMethod.  If the synchronized keyword is
>>     on the method, then Eclipse or FindBugs could be configured to warn
>>     you that the overridden method doesn't declare synchronized.  The
>>     tool suggests that this means the overridden method is not correctly
>>     synchronized.  On the other hand, "synchronized(this)" will trigger
>>     Eclipse or FindBugs to warn you that the code is synchronizing on a
>>     publicly accessible object.  This means that if another piece of
>>     code synchronizes on the object then there might be an unintended
>>     scalability problem.
>>
>>     Nathan Reynolds
>>     <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>>     Consulting Member of Technical Staff | 602.333.9091 
>> <tel:602.333.9091>
>>     Oracle PSR Engineering <http://psr.us.oracle.com/> | Server 
>> Technology
>>
>>     On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>>     Is there an advantage to do:
>>>
>>>     someMethod(...) {
>>>              synchronized(this) {
>>>                      ................
>>>                      ................
>>>                      ................
>>>              }
>>>     }
>>>
>>>     instead of:
>>>     synchronized someMethod(...) {
>>>     ................
>>>     ................
>>>     ................
>>>     }
>>>
>>>     Even when the entire method needs to be synchronized? I 
>>> understand in general it is a good practice to use synchronized 
>>> blocks since more often than not only certain lines need to be 
>>> synchronized.
>>>
>>>     -Navin
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu  
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From hanson.char at gmail.com  Wed Dec 21 18:03:44 2011
From: hanson.char at gmail.com (Hanson Char)
Date: Wed, 21 Dec 2011 15:03:44 -0800
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2517C.90702@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
Message-ID: <CABWgujYn=r2BojXFfxWrF2nuzF1btA=d5jT-iq1SWpXPE2o1gg@mail.gmail.com>

Interesting.  Is there a .../7_performance.html equivalent page ?

Regards,
Hanson

On Wed, Dec 21, 2011 at 1:37 PM, Vladimir Ivanov <
vladimir.x.ivanov at oracle.com> wrote:

> Vitaly,
>
> No, synchronized attribute doesn't prevent method from being inlined by
> JIT compiler in Hotspot. Lock coarsening(redundant lock elimination)
> optimization [1] [2] in C2 greatly benefits from this.
>
> Best regards,
> Vladimir Ivanov
>
> [1] http://java.sun.com/**performance/reference/**
> whitepapers/6_performance.**html#2.1.2<http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2>
> [2] http://www.google.com/**codesearch#Y_pa0sa9c2w/src/**
> share/vm/opto/callnode.cpp&l=**1213<http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213>
>
>
> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>
>> IIRC, synch on method generates less bytecode but that would only matter
>> if the method was on the bytecode size boundary for inlining (I believe
>> default is 35 byte codes), but i think synchronization already prevents
>> inlining as a heuristic.
>>
>> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>> <mailto:nathan.reynolds@**oracle.com <nathan.reynolds at oracle.com>>>
>> wrote:
>>
>>    Use javap to check the bytecode output from both.  From a
>>    performance perspective, I don't think it shouldn't matter.
>>    However, from an API perspective it matters.  Let's say you derive
>>    the class and implement someMethod.  If the synchronized keyword is
>>    on the method, then Eclipse or FindBugs could be configured to warn
>>    you that the overridden method doesn't declare synchronized.  The
>>    tool suggests that this means the overridden method is not correctly
>>    synchronized.  On the other hand, "synchronized(this)" will trigger
>>    Eclipse or FindBugs to warn you that the code is synchronizing on a
>>    publicly accessible object.  This means that if another piece of
>>    code synchronizes on the object then there might be an unintended
>>    scalability problem.
>>
>>    Nathan Reynolds
>>    <http://psr.us.oracle.com/**wiki/index.php/User:Nathan_**Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>> |
>>    Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>>    Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>>
>>    On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>
>>>    Is there an advantage to do:
>>>
>>>    someMethod(...) {
>>>             synchronized(this) {
>>>                     ................
>>>                     ................
>>>                     ................
>>>             }
>>>    }
>>>
>>>    instead of:
>>>    synchronized someMethod(...) {
>>>    ................
>>>    ................
>>>    ................
>>>    }
>>>
>>>    Even when the entire method needs to be synchronized? I understand in
>>> general it is a good practice to use synchronized blocks since more often
>>> than not only certain lines need to be synchronized.
>>>
>>>    -Navin
>>>
>>>    ______________________________**_________________
>>>    Concurrency-interest mailing list
>>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu> <mailto:
>>> Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> >
>>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>
>>    ______________________________**_________________
>>    Concurrency-interest mailing list
>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>    <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>
>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/ab04555c/attachment-0001.html>

From vitalyd at gmail.com  Wed Dec 21 18:23:13 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 21 Dec 2011 18:23:13 -0500
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2517C.90702@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
Message-ID: <CAHjP37Eox33TyCH+0A0nnfwjOBMZ0gBJ1+cwRo6S9130Siq6xA@mail.gmail.com>

Thanks Vladimir, good to know.  Curiously, has this been the case for a
long time or something more or less recent? Was it added as part of lock
elimination/coarsening work?
On Dec 21, 2011 4:37 PM, "Vladimir Ivanov" <vladimir.x.ivanov at oracle.com>
wrote:

> Vitaly,
>
> No, synchronized attribute doesn't prevent method from being inlined by
> JIT compiler in Hotspot. Lock coarsening(redundant lock elimination)
> optimization [1] [2] in C2 greatly benefits from this.
>
> Best regards,
> Vladimir Ivanov
>
> [1] http://java.sun.com/**performance/reference/**
> whitepapers/6_performance.**html#2.1.2<http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2>
> [2] http://www.google.com/**codesearch#Y_pa0sa9c2w/src/**
> share/vm/opto/callnode.cpp&l=**1213<http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213>
>
> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>
>> IIRC, synch on method generates less bytecode but that would only matter
>> if the method was on the bytecode size boundary for inlining (I believe
>> default is 35 byte codes), but i think synchronization already prevents
>> inlining as a heuristic.
>>
>> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>> <mailto:nathan.reynolds@**oracle.com <nathan.reynolds at oracle.com>>>
>> wrote:
>>
>>    Use javap to check the bytecode output from both.  From a
>>    performance perspective, I don't think it shouldn't matter.
>>    However, from an API perspective it matters.  Let's say you derive
>>    the class and implement someMethod.  If the synchronized keyword is
>>    on the method, then Eclipse or FindBugs could be configured to warn
>>    you that the overridden method doesn't declare synchronized.  The
>>    tool suggests that this means the overridden method is not correctly
>>    synchronized.  On the other hand, "synchronized(this)" will trigger
>>    Eclipse or FindBugs to warn you that the code is synchronizing on a
>>    publicly accessible object.  This means that if another piece of
>>    code synchronizes on the object then there might be an unintended
>>    scalability problem.
>>
>>    Nathan Reynolds
>>    <http://psr.us.oracle.com/**wiki/index.php/User:Nathan_**Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>> |
>>    Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>>    Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>
>>    On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>
>>>    Is there an advantage to do:
>>>
>>>    someMethod(...) {
>>>             synchronized(this) {
>>>                     ................
>>>                     ................
>>>                     ................
>>>             }
>>>    }
>>>
>>>    instead of:
>>>    synchronized someMethod(...) {
>>>    ................
>>>    ................
>>>    ................
>>>    }
>>>
>>>    Even when the entire method needs to be synchronized? I understand in
>>> general it is a good practice to use synchronized blocks since more often
>>> than not only certain lines need to be synchronized.
>>>
>>>    -Navin
>>>
>>>    ______________________________**_________________
>>>    Concurrency-interest mailing list
>>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu> <mailto:
>>> Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> >
>>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>
>>    ______________________________**_________________
>>    Concurrency-interest mailing list
>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>    <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/8d9ba712/attachment.html>

From vitalyd at gmail.com  Wed Dec 21 18:31:59 2011
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 21 Dec 2011 18:31:59 -0500
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAHjP37Eox33TyCH+0A0nnfwjOBMZ0gBJ1+cwRo6S9130Siq6xA@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
	<CAHjP37Eox33TyCH+0A0nnfwjOBMZ0gBJ1+cwRo6S9130Siq6xA@mail.gmail.com>
Message-ID: <CAHjP37G7q=U6c5hg5JrX2q=jwRTXhjeSiNRBJr0ui3RQMF6QJw@mail.gmail.com>

Also I thought inlining heuristics were in bytecodeInfo.cpp? And at a
cursory glance I don't see anything related to synch blocks - nice! I guess
that makes the different byte code emitted difference possibly significant.
On Dec 21, 2011 6:23 PM, "Vitaly Davidovich" <vitalyd at gmail.com> wrote:

> Thanks Vladimir, good to know.  Curiously, has this been the case for a
> long time or something more or less recent? Was it added as part of lock
> elimination/coarsening work?
> On Dec 21, 2011 4:37 PM, "Vladimir Ivanov" <vladimir.x.ivanov at oracle.com>
> wrote:
>
>> Vitaly,
>>
>> No, synchronized attribute doesn't prevent method from being inlined by
>> JIT compiler in Hotspot. Lock coarsening(redundant lock elimination)
>> optimization [1] [2] in C2 greatly benefits from this.
>>
>> Best regards,
>> Vladimir Ivanov
>>
>> [1] http://java.sun.com/**performance/reference/**
>> whitepapers/6_performance.**html#2.1.2<http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2>
>> [2] http://www.google.com/**codesearch#Y_pa0sa9c2w/src/**
>> share/vm/opto/callnode.cpp&l=**1213<http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213>
>>
>> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>>
>>> IIRC, synch on method generates less bytecode but that would only matter
>>> if the method was on the bytecode size boundary for inlining (I believe
>>> default is 35 byte codes), but i think synchronization already prevents
>>> inlining as a heuristic.
>>>
>>> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>>> <mailto:nathan.reynolds@**oracle.com <nathan.reynolds at oracle.com>>>
>>> wrote:
>>>
>>>    Use javap to check the bytecode output from both.  From a
>>>    performance perspective, I don't think it shouldn't matter.
>>>    However, from an API perspective it matters.  Let's say you derive
>>>    the class and implement someMethod.  If the synchronized keyword is
>>>    on the method, then Eclipse or FindBugs could be configured to warn
>>>    you that the overridden method doesn't declare synchronized.  The
>>>    tool suggests that this means the overridden method is not correctly
>>>    synchronized.  On the other hand, "synchronized(this)" will trigger
>>>    Eclipse or FindBugs to warn you that the code is synchronizing on a
>>>    publicly accessible object.  This means that if another piece of
>>>    code synchronizes on the object then there might be an unintended
>>>    scalability problem.
>>>
>>>    Nathan Reynolds
>>>    <http://psr.us.oracle.com/**wiki/index.php/User:Nathan_**Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>>> |
>>>    Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091
>>> >
>>>    Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>>> Technology
>>>
>>>    On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>>
>>>>    Is there an advantage to do:
>>>>
>>>>    someMethod(...) {
>>>>             synchronized(this) {
>>>>                     ................
>>>>                     ................
>>>>                     ................
>>>>             }
>>>>    }
>>>>
>>>>    instead of:
>>>>    synchronized someMethod(...) {
>>>>    ................
>>>>    ................
>>>>    ................
>>>>    }
>>>>
>>>>    Even when the entire method needs to be synchronized? I understand
>>>> in general it is a good practice to use synchronized blocks since more
>>>> often than not only certain lines need to be synchronized.
>>>>
>>>>    -Navin
>>>>
>>>>    ______________________________**_________________
>>>>    Concurrency-interest mailing list
>>>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu> <mailto:
>>>> Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>>>> >
>>>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>
>>>
>>>    ______________________________**_________________
>>>    Concurrency-interest mailing list
>>>    Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>>    <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> >
>>>    http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>>
>>>
>>> ______________________________**_________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/ed1ce896/attachment.html>

From bmeike at speakeasy.net  Wed Dec 21 18:42:25 2011
From: bmeike at speakeasy.net (Blake Meike)
Date: Wed, 21 Dec 2011 15:42:25 -0800
Subject: [concurrency-interest] Concurrency in Android
In-Reply-To: <CAHzJPEo5T+OrfPjJ+vYRWN1fNb3+VoxdZ=WMqHDKN2PiEti3=A@mail.gmail.com>
References: <6097E1A0-A82A-4A9A-B1BB-46F8ECEE406C@speakeasy.net>
	<CAHzJPEo5T+OrfPjJ+vYRWN1fNb3+VoxdZ=WMqHDKN2PiEti3=A@mail.gmail.com>
Message-ID: <F88CC0B6-D867-4649-AAE5-82956FE8E470@speakeasy.net>


On Dec 21, 2011, at 12:36 PM, Joe Bowbeer wrote:

Hey Joe,

> I believe a j.u.c. ThreadPoolExecutor is powering the AsyncTask executions, right?

Yes, that's correct.  I believe that the number of threads in the pool has been changed, recently, from some small number, to 1.

I would like to encourage this discussion.  It seems like a logical extension of the conversation in this list, if not of direct interest.  It is my opinion that, until recently, the mobile environment was a pretty safe place, concurrency-wise.  There wasn't a lot of optimization (the Android JIT is about a year old) and there weren't many cores on the processors.  That's about to change, dramatically.  I think the wisdom I've seen here would be a huge help, applied to the Android community.

-blake

From nathan.reynolds at oracle.com  Thu Dec 22 00:29:36 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Wed, 21 Dec 2011 22:29:36 -0700
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF23120.60004@javaspecialists.eu>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF23120.60004@javaspecialists.eu>
Message-ID: <4EF2C040.1060208@oracle.com>

Thanks for the information.  What does the serial portion include?  Is 
it only the bottlenecked lock?  Or does it include the other locks 
involved in processing the input?

I would guess it only includes the bottlenecked lock.  In my experience 
of fixing locks, we have to fix the most contended lock before we can 
see what is the next bottlenecked lock to fix.  If we were to fix the 
next bottlenecked lock first, then the throughput increases minimally.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/21/2011 12:18 PM, Dr Heinz M. Kabutz wrote:
> Hi Navin,
>
> Little's Law tells us that throughput is inversely proportional to 
> single-threaded wait time.  Thus the shorter your wait time, the 
> better your throughput will be.  Amdahl's law also tells us that the 
> serial portion of a piece of parallel code will tend to dominate and 
> restrict our scalability.
>
> Thus the first will probably have a slightly shorter serial path and 
> thus your performance from a scalability perspective will be most 
> probably better.  I will verify this with a little benchmark for you, 
> but in the meantime here is a graph from my new concurrency course 
> that shows how even a small amount of serial portion (0.25%) limits 
> the ability to scale beyond 400 cores.
>
>
> Regards
>
> Heinz
> -- 
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 12/21/11 5:45 PM, Jha, Navin wrote:
>> Is there an advantage to do:
>>
>> someMethod(...) {
>>          synchronized(this) {
>>                  ................
>>                  ................
>>                  ................
>>          }
>> }
>>
>> instead of:
>> synchronized someMethod(...) {
>> ................
>> ................
>> ................
>> }
>>
>> Even when the entire method needs to be synchronized? I understand in general it is a good practice to use synchronized blocks since more often than not only certain lines need to be synchronized.
>>
>> -Navin
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>    
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/10035d05/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 166279 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111221/10035d05/attachment-0001.png>

From heinz at javaspecialists.eu  Thu Dec 22 00:35:18 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 22 Dec 2011 07:35:18 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2C040.1060208@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF23120.60004@javaspecialists.eu> <4EF2C040.1060208@oracle.com>
Message-ID: <CACLL95raNdhb-fy=qrfbcFJ9BeaZPMo=ZCeFOgDX+t41Fbg8CA@mail.gmail.com>

It contains a += on a long by a random int which is pulled from a pre
filled array.

On 22/12/2011, Nathan Reynolds <nathan.reynolds at oracle.com> wrote:
> Thanks for the information.  What does the serial portion include?  Is
> it only the bottlenecked lock?  Or does it include the other locks
> involved in processing the input?
>
> I would guess it only includes the bottlenecked lock.  In my experience
> of fixing locks, we have to fix the most contended lock before we can
> see what is the next bottlenecked lock to fix.  If we were to fix the
> next bottlenecked lock first, then the throughput increases minimally.
>
> Nathan Reynolds
> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> Consulting Member of Technical Staff | 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/21/2011 12:18 PM, Dr Heinz M. Kabutz wrote:
>> Hi Navin,
>>
>> Little's Law tells us that throughput is inversely proportional to
>> single-threaded wait time.  Thus the shorter your wait time, the
>> better your throughput will be.  Amdahl's law also tells us that the
>> serial portion of a piece of parallel code will tend to dominate and
>> restrict our scalability.
>>
>> Thus the first will probably have a slightly shorter serial path and
>> thus your performance from a scalability perspective will be most
>> probably better.  I will verify this with a little benchmark for you,
>> but in the meantime here is a graph from my new concurrency course
>> that shows how even a small amount of serial portion (0.25%) limits
>> the ability to scale beyond 400 cores.
>>
>>
>> Regards
>>
>> Heinz
>> --
>> Dr Heinz M. Kabutz (PhD CompSci)
>> Author of "The Java(tm) Specialists' Newsletter"
>> Sun Java Champion
>> IEEE Certified Software Development Professional
>> http://www.javaspecialists.eu
>> Tel: +30 69 72 850 460
>> Skype: kabutz
>>
>>
>> On 12/21/11 5:45 PM, Jha, Navin wrote:
>>> Is there an advantage to do:
>>>
>>> someMethod(...) {
>>>          synchronized(this) {
>>>                  ................
>>>                  ................
>>>                  ................
>>>          }
>>> }
>>>
>>> instead of:
>>> synchronized someMethod(...) {
>>> ................
>>> ................
>>> ................
>>> }
>>>
>>> Even when the entire method needs to be synchronized? I understand in
>>> general it is a good practice to use synchronized blocks since more often
>>> than not only certain lines need to be synchronized.
>>>
>>> -Navin
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz

From vladimir.x.ivanov at oracle.com  Thu Dec 22 02:54:59 2011
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Thu, 22 Dec 2011 11:54:59 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <CABWgujYn=r2BojXFfxWrF2nuzF1btA=d5jT-iq1SWpXPE2o1gg@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
	<CABWgujYn=r2BojXFfxWrF2nuzF1btA=d5jT-iq1SWpXPE2o1gg@mail.gmail.com>
Message-ID: <4EF2E253.3060705@oracle.com>

Hanson,

No, at least I'm not aware about it :) There is [1], but most of the 
features are present in 6u as well.

Digressing from the main topic and considering Hotspot Express model, 6u 
releases featured latest Hotspot with all performance enhancements until 
recently(HS20). 7-specific(HS21/22) compiler features are 
JSR292/invokedynamic support and tiered compilation right now.

Best regards,
Vladimir Ivanov

[1] 
http://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html

On 12/22/11 3:03 AM, Hanson Char wrote:
> Interesting.  Is there a .../7_performance.html equivalent page ?
>
> Regards,
> Hanson
>
> On Wed, Dec 21, 2011 at 1:37 PM, Vladimir Ivanov
> <vladimir.x.ivanov at oracle.com <mailto:vladimir.x.ivanov at oracle.com>> wrote:
>
>     Vitaly,
>
>     No, synchronized attribute doesn't prevent method from being inlined
>     by JIT compiler in Hotspot. Lock coarsening(redundant lock
>     elimination) optimization [1] [2] in C2 greatly benefits from this.
>
>     Best regards,
>     Vladimir Ivanov
>
>     [1]
>     http://java.sun.com/__performance/reference/__whitepapers/6_performance.__html#2.1.2
>     <http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2>
>     [2]
>     http://www.google.com/__codesearch#Y_pa0sa9c2w/src/__share/vm/opto/callnode.cpp&l=__1213
>     <http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213>
>
>
>     On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>
>         IIRC, synch on method generates less bytecode but that would
>         only matter
>         if the method was on the bytecode size boundary for inlining (I
>         believe
>         default is 35 byte codes), but i think synchronization already
>         prevents
>         inlining as a heuristic.
>
>         On Dec 21, 2011 11:48 AM, "Nathan Reynolds"
>         <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>
>         <mailto:nathan.reynolds at __oracle.com
>         <mailto:nathan.reynolds at oracle.com>>> wrote:
>
>             Use javap to check the bytecode output from both.  From a
>             performance perspective, I don't think it shouldn't matter.
>             However, from an API perspective it matters.  Let's say you
>         derive
>             the class and implement someMethod.  If the synchronized
>         keyword is
>             on the method, then Eclipse or FindBugs could be configured
>         to warn
>             you that the overridden method doesn't declare synchronized.
>           The
>             tool suggests that this means the overridden method is not
>         correctly
>             synchronized.  On the other hand, "synchronized(this)" will
>         trigger
>             Eclipse or FindBugs to warn you that the code is
>         synchronizing on a
>             publicly accessible object.  This means that if another piece of
>             code synchronizes on the object then there might be an
>         unintended
>             scalability problem.
>
>             Nathan Reynolds
>         <http://psr.us.oracle.com/__wiki/index.php/User:Nathan___Reynolds <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>         |
>             Consulting Member of Technical Staff | 602.333.9091
>         <tel:602.333.9091> <tel:602.333.9091 <tel:602.333.9091>>
>             Oracle PSR Engineering <http://psr.us.oracle.com/> | Server
>         Technology
>
>
>             On 12/21/2011 8:45 AM, Jha, Navin wrote:
>
>                 Is there an advantage to do:
>
>                 someMethod(...) {
>                          synchronized(this) {
>                                  ................
>                                  ................
>                                  ................
>                          }
>                 }
>
>                 instead of:
>                 synchronized someMethod(...) {
>                 ................
>                 ................
>                 ................
>                 }
>
>                 Even when the entire method needs to be synchronized? I
>             understand in general it is a good practice to use
>             synchronized blocks since more often than not only certain
>             lines need to be synchronized.
>
>                 -Navin
>
>                 _________________________________________________
>                 Concurrency-interest mailing list
>             Concurrency-interest at cs.__oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             <mailto:Concurrency-interest at __cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>>
>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>             _________________________________________________
>             Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         <mailto:Concurrency-interest at __cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>>
>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>         _________________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.__oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>         <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>     _________________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.__oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>

From skuksenko at gmail.com  Thu Dec 22 03:19:56 2011
From: skuksenko at gmail.com (Sergey Kuksenko)
Date: Thu, 22 Dec 2011 12:19:56 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF25D5D.4040507@javaspecialists.eu>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com> <4EF25D5D.4040507@javaspecialists.eu>
Message-ID: <CAOBqY9Baed=gHK=4CnCR7DjBvevfmjANGEbWEGGXA488bbf+Lg@mail.gmail.com>

You may look at slides 32-34 here
http://people.apache.org/~shade/talks/j1-Oct2011-21682-benchmarking.pdf


On Thu, Dec 22, 2011 at 2:27 AM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> My benchmark shows in most cases a small performance gain when you use an
> inner synchronized block. ?However, the difference is really very small and
> is only in contended locks. ?Uncontended locks are optimized away, so that
> does not count.
>
> On my 8-core machine, I call the methods lots of times with random values
> from a pre-filled array to stop the HotSpot compiler from eliminating my
> code.
>
> If the synchronized block is inside the method, we have the following test
> duration in average and standard deviation. ?Times are in ms. ?Small numbers
> are good, large numbers bad. ?High standard deviation means the results are
> all over the place.
>
> 1 Thread: ? ? ? ?20 (1.8)
> 2 Threads: ? ?465 (53)
> 4 Threads: ? ?889 (170)
> 8 Threads: ? ?958 (137)
> 16 Threads: ?629 (69)
> 32 Threads: ?578 (66)
>
> When the whole method is synchronized:
>
> 1 Thread: ? ? ? ?20 (0.5)
> 2 Threads: ? ?488 (45)
> 4 Threads: ? ?920 (145)
> 8 Threads: ? ?1037 (90)
> 16 Threads: ?612 (70)
> 32 Threads: ?645 (74)
>
> However, as much as I would love these results to prove that my initial
> theoretical explanation was right, I think it's too close to call. ?Neither
> is great. ?If you want good scalability (which is the *only* performance
> reason you'd care about this) then you want to rather try to avoid locking
> altogether and use non-blocking synchronization constructs.
>
> I hope this helped. ?My test code and raw results are available on demand.
>
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 12/21/11 11:37 PM, Vladimir Ivanov wrote:
>>
>> Vitaly,
>>
>> No, synchronized attribute doesn't prevent method from being inlined by
>> JIT compiler in Hotspot. Lock coarsening(redundant lock elimination)
>> optimization [1] [2] in C2 greatly benefits from this.
>>
>> Best regards,
>> Vladimir Ivanov
>>
>> [1]
>> http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2
>> [2]
>> http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213
>>
>> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>>>
>>> IIRC, synch on method generates less bytecode but that would only matter
>>> if the method was on the bytecode size boundary for inlining (I believe
>>> default is 35 byte codes), but i think synchronization already prevents
>>> inlining as a heuristic.
>>>
>>> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
>>> <mailto:nathan.reynolds at oracle.com>> wrote:
>>>
>>> ? ?Use javap to check the bytecode output from both. ?From a
>>> ? ?performance perspective, I don't think it shouldn't matter.
>>> ? ?However, from an API perspective it matters. ?Let's say you derive
>>> ? ?the class and implement someMethod. ?If the synchronized keyword is
>>> ? ?on the method, then Eclipse or FindBugs could be configured to warn
>>> ? ?you that the overridden method doesn't declare synchronized. ?The
>>> ? ?tool suggests that this means the overridden method is not correctly
>>> ? ?synchronized. ?On the other hand, "synchronized(this)" will trigger
>>> ? ?Eclipse or FindBugs to warn you that the code is synchronizing on a
>>> ? ?publicly accessible object. ?This means that if another piece of
>>> ? ?code synchronizes on the object then there might be an unintended
>>> ? ?scalability problem.
>>>
>>> ? ?Nathan Reynolds
>>> ? ?<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
>>> ? ?Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
>>> ? ?Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>>>
>>> ? ?On 12/21/2011 8:45 AM, Jha, Navin wrote:
>>>>
>>>> ? ?Is there an advantage to do:
>>>>
>>>> ? ?someMethod(...) {
>>>> ? ? ? ? ? ? synchronized(this) {
>>>> ? ? ? ? ? ? ? ? ? ? ................
>>>> ? ? ? ? ? ? ? ? ? ? ................
>>>> ? ? ? ? ? ? ? ? ? ? ................
>>>> ? ? ? ? ? ? }
>>>> ? ?}
>>>>
>>>> ? ?instead of:
>>>> ? ?synchronized someMethod(...) {
>>>> ? ?................
>>>> ? ?................
>>>> ? ?................
>>>> ? ?}
>>>>
>>>> ? ?Even when the entire method needs to be synchronized? I understand in
>>>> general it is a good practice to use synchronized blocks since more often
>>>> than not only certain lines need to be synchronized.
>>>>
>>>> ? ?-Navin
>>>>
>>>> ? ?_______________________________________________
>>>> ? ?Concurrency-interest mailing list
>>>> ? ?Concurrency-interest at cs.oswego.edu
>>>> ?<mailto:Concurrency-interest at cs.oswego.edu>
>>>> ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> ? ?_______________________________________________
>>> ? ?Concurrency-interest mailing list
>>> ? ?Concurrency-interest at cs.oswego.edu
>>> ? ?<mailto:Concurrency-interest at cs.oswego.edu>
>>> ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-- 
Best regards,
Sergey Kuksenko


From heinz at javaspecialists.eu  Thu Dec 22 03:24:50 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 22 Dec 2011 10:24:50 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAOBqY9Baed=gHK=4CnCR7DjBvevfmjANGEbWEGGXA488bbf+Lg@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>	<4EF20D2F.1030409@oracle.com>	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>	<4EF2517C.90702@oracle.com>	<4EF25D5D.4040507@javaspecialists.eu>
	<CAOBqY9Baed=gHK=4CnCR7DjBvevfmjANGEbWEGGXA488bbf+Lg@mail.gmail.com>
Message-ID: <4EF2E952.5040702@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111222/05836ad4/attachment-0001.html>

From skuksenko at gmail.com  Thu Dec 22 03:39:58 2011
From: skuksenko at gmail.com (Sergey Kuksenko)
Date: Thu, 22 Dec 2011 12:39:58 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2E952.5040702@javaspecialists.eu>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com> <4EF25D5D.4040507@javaspecialists.eu>
	<CAOBqY9Baed=gHK=4CnCR7DjBvevfmjANGEbWEGGXA488bbf+Lg@mail.gmail.com>
	<4EF2E952.5040702@javaspecialists.eu>
Message-ID: <CAOBqY9BVMABGTCyvN_MsmQfUsfW64KGS8wpG-y5smnCLBCvaNg@mail.gmail.com>

The question is not about contended/uncontended.
The question is how do you perform measurement (and the presentation
is about that).
As for me - I am expecting the same JITted code in both cases and
don't beleive in difference.
Slightly later, I will find time for looking into code and will write you.

On Thu, Dec 22, 2011 at 12:24 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> As I said, an uncontended lock is obviously the same.? But what about a
> contended lock?? You don't have tests for that in your slides.
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
>
> On 12/22/11 10:19 AM, Sergey Kuksenko wrote:
>
> You may look at slides 32-34 here
> http://people.apache.org/~shade/talks/j1-Oct2011-21682-benchmarking.pdf
>
>
> On Thu, Dec 22, 2011 at 2:27 AM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>
>
> My benchmark shows in most cases a small performance gain when you use an
> inner synchronized block. ?However, the difference is really very small and
> is only in contended locks. ?Uncontended locks are optimized away, so that
> does not count.
>
> On my 8-core machine, I call the methods lots of times with random values
> from a pre-filled array to stop the HotSpot compiler from eliminating my
> code.
>
> If the synchronized block is inside the method, we have the following test
> duration in average and standard deviation. ?Times are in ms. ?Small numbers
> are good, large numbers bad. ?High standard deviation means the results are
> all over the place.
>
> 1 Thread: ? ? ? ?20 (1.8)
> 2 Threads: ? ?465 (53)
> 4 Threads: ? ?889 (170)
> 8 Threads: ? ?958 (137)
> 16 Threads: ?629 (69)
> 32 Threads: ?578 (66)
>
> When the whole method is synchronized:
>
> 1 Thread: ? ? ? ?20 (0.5)
> 2 Threads: ? ?488 (45)
> 4 Threads: ? ?920 (145)
> 8 Threads: ? ?1037 (90)
> 16 Threads: ?612 (70)
> 32 Threads: ?645 (74)
>
> However, as much as I would love these results to prove that my initial
> theoretical explanation was right, I think it's too close to call. ?Neither
> is great. ?If you want good scalability (which is the *only* performance
> reason you'd care about this) then you want to rather try to avoid locking
> altogether and use non-blocking synchronization constructs.
>
> I hope this helped. ?My test code and raw results are available on demand.
>
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Sun Java Champion
> IEEE Certified Software Development Professional
> http://www.javaspecialists.eu
> Tel: +30 69 72 850 460
> Skype: kabutz
>
>
> On 12/21/11 11:37 PM, Vladimir Ivanov wrote:
>
>
> Vitaly,
>
> No, synchronized attribute doesn't prevent method from being inlined by
> JIT compiler in Hotspot. Lock coarsening(redundant lock elimination)
> optimization [1] [2] in C2 greatly benefits from this.
>
> Best regards,
> Vladimir Ivanov
>
> [1]
> http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2
> [2]
> http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213
>
> On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>
>
> IIRC, synch on method generates less bytecode but that would only matter
> if the method was on the bytecode size boundary for inlining (I believe
> default is 35 byte codes), but i think synchronization already prevents
> inlining as a heuristic.
>
> On Dec 21, 2011 11:48 AM, "Nathan Reynolds" <nathan.reynolds at oracle.com
> <mailto:nathan.reynolds at oracle.com>> wrote:
>
> ? ?Use javap to check the bytecode output from both. ?From a
> ? ?performance perspective, I don't think it shouldn't matter.
> ? ?However, from an API perspective it matters. ?Let's say you derive
> ? ?the class and implement someMethod. ?If the synchronized keyword is
> ? ?on the method, then Eclipse or FindBugs could be configured to warn
> ? ?you that the overridden method doesn't declare synchronized. ?The
> ? ?tool suggests that this means the overridden method is not correctly
> ? ?synchronized. ?On the other hand, "synchronized(this)" will trigger
> ? ?Eclipse or FindBugs to warn you that the code is synchronizing on a
> ? ?publicly accessible object. ?This means that if another piece of
> ? ?code synchronizes on the object then there might be an unintended
> ? ?scalability problem.
>
> ? ?Nathan Reynolds
> ? ?<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> |
> ? ?Consulting Member of Technical Staff | 602.333.9091 <tel:602.333.9091>
> ? ?Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> ? ?On 12/21/2011 8:45 AM, Jha, Navin wrote:
>
>
> ? ?Is there an advantage to do:
>
> ? ?someMethod(...) {
> ? ? ? ? ? ? synchronized(this) {
> ? ? ? ? ? ? ? ? ? ? ................
> ? ? ? ? ? ? ? ? ? ? ................
> ? ? ? ? ? ? ? ? ? ? ................
> ? ? ? ? ? ? }
> ? ?}
>
> ? ?instead of:
> ? ?synchronized someMethod(...) {
> ? ?................
> ? ?................
> ? ?................
> ? ?}
>
> ? ?Even when the entire method needs to be synchronized? I understand in
> general it is a good practice to use synchronized blocks since more often
> than not only certain lines need to be synchronized.
>
> ? ?-Navin
>
> ? ?_______________________________________________
> ? ?Concurrency-interest mailing list
> ? ?Concurrency-interest at cs.oswego.edu
> ?<mailto:Concurrency-interest at cs.oswego.edu>
> ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> ? ?_______________________________________________
> ? ?Concurrency-interest mailing list
> ? ?Concurrency-interest at cs.oswego.edu
> ? ?<mailto:Concurrency-interest at cs.oswego.edu>
> ? ?http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>



-- 
Best regards,
Sergey Kuksenko


From vladimir.x.ivanov at oracle.com  Thu Dec 22 03:47:29 2011
From: vladimir.x.ivanov at oracle.com (Vladimir Ivanov)
Date: Thu, 22 Dec 2011 12:47:29 +0400
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAHjP37G7q=U6c5hg5JrX2q=jwRTXhjeSiNRBJr0ui3RQMF6QJw@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>
	<4EF2517C.90702@oracle.com>
	<CAHjP37Eox33TyCH+0A0nnfwjOBMZ0gBJ1+cwRo6S9130Siq6xA@mail.gmail.com>
	<CAHjP37G7q=U6c5hg5JrX2q=jwRTXhjeSiNRBJr0ui3RQMF6QJw@mail.gmail.com>
Message-ID: <4EF2EEA1.9070205@oracle.com>

Vitaly,

Yes, for C2 it's bytecodeInfo.cpp. And for C1 it's 
src/share/vm/c1/c1_GraphBuilder.cpp [1]. Surprisingly, there's 
C1-specific flag called InlineSynchronizedMethods (btw, true by default) :)

I did some brief source code archeology study (starting from 1.5) and 
didn't find any changes in how sync methods are inlined. So I expect it 
worked the same in Hotspot early days.

Regarding significance of byte code size on performance, I can't comment 
- I don't have any representative numbers ;-)

Best regards,
Vladimir Ivanov

[1] 
http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/c1/c1_GraphBuilder.cpp&q=src/share/vm/c1/c1_GraphBuilder.cpp&exact_package=http://hg.openjdk.java.net/jdk7/build/hotspot&l=3441


On 12/22/11 3:31 AM, Vitaly Davidovich wrote:
> Also I thought inlining heuristics were in bytecodeInfo.cpp? And at a
> cursory glance I don't see anything related to synch blocks - nice! I
> guess that makes the different byte code emitted difference possibly
> significant.
>
> On Dec 21, 2011 6:23 PM, "Vitaly Davidovich" <vitalyd at gmail.com
> <mailto:vitalyd at gmail.com>> wrote:
>
>     Thanks Vladimir, good to know.  Curiously, has this been the case
>     for a long time or something more or less recent? Was it added as
>     part of lock elimination/coarsening work?
>
>     On Dec 21, 2011 4:37 PM, "Vladimir Ivanov"
>     <vladimir.x.ivanov at oracle.com <mailto:vladimir.x.ivanov at oracle.com>>
>     wrote:
>
>         Vitaly,
>
>         No, synchronized attribute doesn't prevent method from being
>         inlined by JIT compiler in Hotspot. Lock coarsening(redundant
>         lock elimination) optimization [1] [2] in C2 greatly benefits
>         from this.
>
>         Best regards,
>         Vladimir Ivanov
>
>         [1]
>         http://java.sun.com/__performance/reference/__whitepapers/6_performance.__html#2.1.2
>         <http://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.2>
>         [2]
>         http://www.google.com/__codesearch#Y_pa0sa9c2w/src/__share/vm/opto/callnode.cpp&l=__1213
>         <http://www.google.com/codesearch#Y_pa0sa9c2w/src/share/vm/opto/callnode.cpp&l=1213>
>
>         On 12/21/11 9:33 PM, Vitaly Davidovich wrote:
>
>             IIRC, synch on method generates less bytecode but that would
>             only matter
>             if the method was on the bytecode size boundary for inlining
>             (I believe
>             default is 35 byte codes), but i think synchronization
>             already prevents
>             inlining as a heuristic.
>
>             On Dec 21, 2011 11:48 AM, "Nathan Reynolds"
>             <nathan.reynolds at oracle.com <mailto:nathan.reynolds at oracle.com>
>             <mailto:nathan.reynolds at __oracle.com
>             <mailto:nathan.reynolds at oracle.com>>> wrote:
>
>                 Use javap to check the bytecode output from both.  From a
>                 performance perspective, I don't think it shouldn't matter.
>                 However, from an API perspective it matters.  Let's say
>             you derive
>                 the class and implement someMethod.  If the synchronized
>             keyword is
>                 on the method, then Eclipse or FindBugs could be
>             configured to warn
>                 you that the overridden method doesn't declare
>             synchronized.  The
>                 tool suggests that this means the overridden method is
>             not correctly
>                 synchronized.  On the other hand, "synchronized(this)"
>             will trigger
>                 Eclipse or FindBugs to warn you that the code is
>             synchronizing on a
>                 publicly accessible object.  This means that if another
>             piece of
>                 code synchronizes on the object then there might be an
>             unintended
>                 scalability problem.
>
>                 Nathan Reynolds
>             <http://psr.us.oracle.com/__wiki/index.php/User:Nathan___Reynolds
>             <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>>
>             |
>                 Consulting Member of Technical Staff | 602.333.9091
>             <tel:602.333.9091> <tel:602.333.9091 <tel:602.333.9091>>
>                 Oracle PSR Engineering <http://psr.us.oracle.com/> |
>             Server Technology
>
>                 On 12/21/2011 8:45 AM, Jha, Navin wrote:
>
>                     Is there an advantage to do:
>
>                     someMethod(...) {
>                              synchronized(this) {
>                                      ................
>                                      ................
>                                      ................
>                              }
>                     }
>
>                     instead of:
>                     synchronized someMethod(...) {
>                     ................
>                     ................
>                     ................
>                     }
>
>                     Even when the entire method needs to be
>                 synchronized? I understand in general it is a good
>                 practice to use synchronized blocks since more often
>                 than not only certain lines need to be synchronized.
>
>                     -Navin
>
>                     _________________________________________________
>                     Concurrency-interest mailing list
>                 Concurrency-interest at cs.__oswego.edu
>                 <mailto:Concurrency-interest at cs.oswego.edu>
>                 <mailto:Concurrency-interest at __cs.oswego.edu
>                 <mailto:Concurrency-interest at cs.oswego.edu>>
>                 http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>                 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>                 _________________________________________________
>                 Concurrency-interest mailing list
>             Concurrency-interest at cs.__oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             <mailto:Concurrency-interest at __cs.oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>>
>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>             _________________________________________________
>             Concurrency-interest mailing list
>             Concurrency-interest at cs.__oswego.edu
>             <mailto:Concurrency-interest at cs.oswego.edu>
>             http://cs.oswego.edu/mailman/__listinfo/concurrency-interest
>             <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>

From heinz at javaspecialists.eu  Thu Dec 22 04:08:13 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 22 Dec 2011 11:08:13 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <CAOBqY9BVMABGTCyvN_MsmQfUsfW64KGS8wpG-y5smnCLBCvaNg@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>	<4EF20D2F.1030409@oracle.com>	<CAHjP37HG4sCAARm0qp2r3KOQYAk++rG_bamNPgJqZ1OcdOchyQ@mail.gmail.com>	<4EF2517C.90702@oracle.com>	<4EF25D5D.4040507@javaspecialists.eu>	<CAOBqY9Baed=gHK=4CnCR7DjBvevfmjANGEbWEGGXA488bbf+Lg@mail.gmail.com>	<4EF2E952.5040702@javaspecialists.eu>
	<CAOBqY9BVMABGTCyvN_MsmQfUsfW64KGS8wpG-y5smnCLBCvaNg@mail.gmail.com>
Message-ID: <4EF2F37D.3010407@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111222/e6d83f37/attachment-0001.html>

From r.spilker at topdesk.com  Thu Dec 22 04:32:28 2011
From: r.spilker at topdesk.com (Roel Spilker)
Date: Thu, 22 Dec 2011 10:32:28 +0100
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF20D2F.1030409@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com>
Message-ID: <4EF2F92C.2050404@topdesk.com>

You can use http://projectlombok.org/features/Synchronized.html as a way 
to use a private lock object AND (potentially) have static analysis.

Can anyone explain to me why an overridden method should be synchronized 
as well?

Roel

Disclosure: I'm involved in Project Lombok

On 21-12-2011 17:45, Nathan Reynolds wrote:
> On the other hand, "synchronized(this)" will trigger Eclipse or 
> FindBugs to warn you that the code is synchronizing on a publicly 
> accessible object.  This means that if another piece of code 
> synchronizes on the object then there might be an unintended 
> scalability problem.

From davidcholmes at aapt.net.au  Thu Dec 22 04:38:42 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 22 Dec 2011 19:38:42 +1000
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2F92C.2050404@topdesk.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEAFJCAA.davidcholmes@aapt.net.au>

Roel Spilker writes:
> You can use http://projectlombok.org/features/Synchronized.html as a way
> to use a private lock object AND (potentially) have static analysis.
>
> Can anyone explain to me why an overridden method should be synchronized
> as well?

Generally the overridden method needs to conform to the synchronization
protocol employed by the base class. It would be rare to override a
synchronized method and not also need to be synchronized.

David
-----

> Roel
>
> Disclosure: I'm involved in Project Lombok
>
> On 21-12-2011 17:45, Nathan Reynolds wrote:
> > On the other hand, "synchronized(this)" will trigger Eclipse or
> > FindBugs to warn you that the code is synchronizing on a publicly
> > accessible object.  This means that if another piece of code
> > synchronizes on the object then there might be an unintended
> > scalability problem.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From gregg at cytetech.com  Thu Dec 22 09:21:18 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 22 Dec 2011 08:21:18 -0600
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2F92C.2050404@topdesk.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com> <4EF2F92C.2050404@topdesk.com>
Message-ID: <4EF33CDE.7040300@cytetech.com>

On 12/22/2011 3:32 AM, Roel Spilker wrote:
> You can use http://projectlombok.org/features/Synchronized.html as a way to use
> a private lock object AND (potentially) have static analysis.
>
> Can anyone explain to me why an overridden method should be synchronized as well?

It really depends on what the overridden method does.  Sometimes, what I do, is 
create a subclass and do something like the following to investigate contention. 
  In this case, I want every thread instance to enter, unblocked, so that I can 
count who all is waiting.

public class SubFoo extends Foo {
	AtomicInteger ecnt = new AtomicInteger(0);

	public void fooMethod() {
		int mine = ecnt.incrementAndGet();
		// track max value here too, and log when it grows.
		try {
			super.fooMethod();
		} finally {
			ecnt.decrementAndGet();
		}
	}
}

> Roel
>
> Disclosure: I'm involved in Project Lombok

As an aside...  On the @Synchronized page, the example shown, uses

	Object lock = new Object[0];

which could also be

	Serializable lock = new Serializable(){};

to make serialization work as well.  This documents, with code, what the desired 
attribute really is.  The anonymous inner class, of course will create extra 
compiler output in the form of class files, and extend the number of classes 
loaded, etc.

Regarding serialVersionUID changing, you could use an additional annotation that 
created a single field for all locks stored in a Map so that there was only a 
single "field" present for lock support.  Then, you'd have to remove that 
annotation to "change" the serialVersionUID, and the number of locks would not 
affect or change serialVersionUID. All the synchronized() use would now be 
synchronized(map.get(lockKey)) instead.

What this facilitates, is that now you have a functional interface to managing 
lock access, and you can add some telemetry as well, by generating code such as

	synchronized( map.get(lockKey) ) {
		try {
			...users code...
			map.entered( lockKey );
		} finally {
			map.exited( lockKet );
		}
	}

You can provide a lot of extra features once the lock access happens through an 
object that has keyed access.

Also, does lombok work in netbeans?

Gregg Wonderly

> On 21-12-2011 17:45, Nathan Reynolds wrote:
>> On the other hand, "synchronized(this)" will trigger Eclipse or FindBugs to
>> warn you that the code is synchronizing on a publicly accessible object. This
>> means that if another piece of code synchronizes on the object then there
>> might be an unintended scalability problem.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From gregg at cytetech.com  Thu Dec 22 09:22:02 2011
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 22 Dec 2011 08:22:02 -0600
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF2F92C.2050404@topdesk.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF20D2F.1030409@oracle.com> <4EF2F92C.2050404@topdesk.com>
Message-ID: <4EF33D0A.7060105@cytetech.com>

On 12/22/2011 3:32 AM, Roel Spilker wrote:
> You can use http://projectlombok.org/features/Synchronized.html as a way to use
> a private lock object AND (potentially) have static analysis.
>
> Can anyone explain to me why an overridden method should be synchronized as well?

It really depends on what the overridden method does.  Sometimes, what I do, is 
create a subclass and do something like the following to investigate contention. 
  In this case, I want every thread instance to enter, unblocked, so that I can 
count who all is waiting.

public class SubFoo extends Foo {
	AtomicInteger ecnt = new AtomicInteger(0);

	public void fooMethod() {
		int mine = ecnt.incrementAndGet();
		// track max value here too, and log when it grows.
		try {
			super.fooMethod();
		} finally {
			ecnt.decrementAndGet();
		}
	}
}

> Roel
>
> Disclosure: I'm involved in Project Lombok

As an aside...  On the @Synchronized page, the example shown, uses

	Object lock = new Object[0];

which could also be

	Serializable lock = new Serializable(){};

to make serialization work as well.  This documents, with code, what the desired 
attribute really is.  The anonymous inner class, of course will create extra 
compiler output in the form of class files, and extend the number of classes 
loaded, etc.

Regarding serialVersionUID changing, you could use an additional annotation that 
created a single field for all locks stored in a Map so that there was only a 
single "field" present for lock support.  Then, you'd have to remove that 
annotation to "change" the serialVersionUID, and the number of locks would not 
affect or change serialVersionUID. All the synchronized() use would now be 
synchronized(map.get(lockKey)) instead.

What this facilitates, is that now you have a functional interface to managing 
lock access, and you can add some telemetry as well, by generating code such as

	synchronized( map.get(lockKey) ) {
		try {
			map.entered( lockKey );

			...users code...

		} finally {
			map.exited( lockKey );
		}
	}

You can provide a lot of extra features once the lock access happens through an 
object that has keyed access.

Also, does lombok work in netbeans?

Gregg Wonderly

> On 21-12-2011 17:45, Nathan Reynolds wrote:
>> On the other hand, "synchronized(this)" will trigger Eclipse or FindBugs to
>> warn you that the code is synchronizing on a publicly accessible object. This
>> means that if another piece of code synchronizes on the object then there
>> might be an unintended scalability problem.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From nathan.reynolds at oracle.com  Thu Dec 22 11:51:16 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 22 Dec 2011 09:51:16 -0700
Subject: [concurrency-interest] general performance question
In-Reply-To: <CACLL95raNdhb-fy=qrfbcFJ9BeaZPMo=ZCeFOgDX+t41Fbg8CA@mail.gmail.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF23120.60004@javaspecialists.eu> <4EF2C040.1060208@oracle.com>
	<CACLL95raNdhb-fy=qrfbcFJ9BeaZPMo=ZCeFOgDX+t41Fbg8CA@mail.gmail.com>
Message-ID: <4EF36004.8000102@oracle.com>

Thanks for the information.  Now, what about theoretically?  Does the 
serial portion include only the protected region of the bottlenecked 
lock or does it include the protected regions of all accessed locks?

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/21/2011 10:35 PM, Dr Heinz M. Kabutz wrote:
> It contains a += on a long by a random int which is pulled from a pre
> filled array.
>
> On 22/12/2011, Nathan Reynolds<nathan.reynolds at oracle.com>  wrote:
>> Thanks for the information.  What does the serial portion include?  Is
>> it only the bottlenecked lock?  Or does it include the other locks
>> involved in processing the input?
>>
>> I would guess it only includes the bottlenecked lock.  In my experience
>> of fixing locks, we have to fix the most contended lock before we can
>> see what is the next bottlenecked lock to fix.  If we were to fix the
>> next bottlenecked lock first, then the throughput increases minimally.
>>
>> Nathan Reynolds
>> <http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>  |
>> Consulting Member of Technical Staff | 602.333.9091
>> Oracle PSR Engineering<http://psr.us.oracle.com/>  | Server Technology
>>
>> On 12/21/2011 12:18 PM, Dr Heinz M. Kabutz wrote:
>>> Hi Navin,
>>>
>>> Little's Law tells us that throughput is inversely proportional to
>>> single-threaded wait time.  Thus the shorter your wait time, the
>>> better your throughput will be.  Amdahl's law also tells us that the
>>> serial portion of a piece of parallel code will tend to dominate and
>>> restrict our scalability.
>>>
>>> Thus the first will probably have a slightly shorter serial path and
>>> thus your performance from a scalability perspective will be most
>>> probably better.  I will verify this with a little benchmark for you,
>>> but in the meantime here is a graph from my new concurrency course
>>> that shows how even a small amount of serial portion (0.25%) limits
>>> the ability to scale beyond 400 cores.
>>>
>>>
>>> Regards
>>>
>>> Heinz
>>> --
>>> Dr Heinz M. Kabutz (PhD CompSci)
>>> Author of "The Java(tm) Specialists' Newsletter"
>>> Sun Java Champion
>>> IEEE Certified Software Development Professional
>>> http://www.javaspecialists.eu
>>> Tel: +30 69 72 850 460
>>> Skype: kabutz
>>>
>>>
>>> On 12/21/11 5:45 PM, Jha, Navin wrote:
>>>> Is there an advantage to do:
>>>>
>>>> someMethod(...) {
>>>>           synchronized(this) {
>>>>                   ................
>>>>                   ................
>>>>                   ................
>>>>           }
>>>> }
>>>>
>>>> instead of:
>>>> synchronized someMethod(...) {
>>>> ................
>>>> ................
>>>> ................
>>>> }
>>>>
>>>> Even when the entire method needs to be synchronized? I understand in
>>>> general it is a good practice to use synchronized blocks since more often
>>>> than not only certain lines need to be synchronized.
>>>>
>>>> -Navin
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111222/e636ae7a/attachment.html>

From heinz at javaspecialists.eu  Thu Dec 22 11:57:44 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 22 Dec 2011 18:57:44 +0200
Subject: [concurrency-interest] general performance question
In-Reply-To: <4EF36004.8000102@oracle.com>
References: <D9DBF389E2FB1B45B7A495B716C4775A047C158E4D@extxmb38.nam.nsroot.net>
	<4EF23120.60004@javaspecialists.eu> <4EF2C040.1060208@oracle.com>
	<CACLL95raNdhb-fy=qrfbcFJ9BeaZPMo=ZCeFOgDX+t41Fbg8CA@mail.gmail.com>
	<4EF36004.8000102@oracle.com>
Message-ID: <4EF36188.8070301@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111222/1cbff65f/attachment-0001.html>

From heinz at javaspecialists.eu  Fri Dec 23 09:36:25 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 23 Dec 2011 16:36:25 +0200
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <4E8ED773.9020508@cs.oswego.edu>
References: <4E5A95E0.1080309@cs.oswego.edu>	<4E68AAC9.9070800@cs.oswego.edu>	<4E85F532.1040808@redhat.com>	<4E88E5D3.6070502@cs.oswego.edu>	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>	<4E89BE04.7060907@cs.oswego.edu>	<4E8C5775.8090805@cs.oswego.edu>	<4E8CDADB.7030205@redhat.com>	<4E8D9138.8080501@cs.oswego.edu>
	<4E8E2002.7090905@redhat.com> <4E8ED773.9020508@cs.oswego.edu>
Message-ID: <4EF491E9.7020508@javaspecialists.eu>

I would like to run some performance tests comparing CHMv8 to the CHM in 
Java 7 and to Cliff Click's non-blocking hash map implementation.  
However, I do not have access to hardware that will do the test 
justice.  Would any of you be able to run some tests for me on machines 
in excess of 50 cores?  The more the better.  If so, please contact me 
directly.

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Sun Java Champion
IEEE Certified Software Development Professional
http://www.javaspecialists.eu
Tel: +30 69 72 850 460
Skype: kabutz 



On 10/7/11 1:41 PM, Doug Lea wrote:
> On 10/06/11 17:39, David M. Lloyd wrote:
>> -- we add some
>>> time/space overhead to entrySet operations just to imperfectly
>>> reinforce the questionable intuition that methods operate
>>> directly on internal Entry objects that don't actually exist
>>> (and need not actually exist wrt any other aspects of Map specs).
>>
>> But if the Entry actually *did* reflect the actual physical entry, 
>> then the
>> contract for the Entry interface makes a lot more sense. You can 
>> retrieve the
>> key always, and the value if it hasn't been removed (if it has you 
>> could give
>> IllegalStateException as is allowed by spec).
>
> We considered and rejected this approach back in JDK5 when deciding
> upon iterator semantics for concurrent collections. If you allow
> hasNext() to lie, claiming that an element exists but then throwing
> an exception in next() because it no longer exists, then most
> client iterator usages break. So instead we ensure that if
> hasNext saw a valid element, then it is snapshotted as the one
> returned in next(). Since these elements can concurrently come
> and go at any time, receiving this (weakly consistent) snapshot
> is as much as you can expect anyway. Even if you exported
> a "live" entry, it could disappear as soon as client reads it
> but before it acts upon it.
>
> The underlying problem is that the non-atomic hasNext()/next()
> pairing in Iterator is inherently concurrency-hostile.
> But we didn't want to replace it with something else.
> However, with upcoming lambdas and bulk operations, I'm
> considering creating a variant of CHM that does not support
> iterators at all, but instead several variants of
> method forEach(entry -> action) etc.
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From nathan.reynolds at oracle.com  Fri Dec 23 11:08:19 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 23 Dec 2011 09:08:19 -0700
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <4EF491E9.7020508@javaspecialists.eu>
References: <4E5A95E0.1080309@cs.oswego.edu>	<4E68AAC9.9070800@cs.oswego.edu>	<4E85F532.1040808@redhat.com>	<4E88E5D3.6070502@cs.oswego.edu>	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>	<4E89BE04.7060907@cs.oswego.edu>	<4E8C5775.8090805@cs.oswego.edu>	<4E8CDADB.7030205@redhat.com>	<4E8D9138.8080501@cs.oswego.edu>
	<4E8E2002.7090905@redhat.com> <4E8ED773.9020508@cs.oswego.edu>
	<4EF491E9.7020508@javaspecialists.eu>
Message-ID: <4EF4A773.2070109@oracle.com>

I've been thinking about running such a test on a dual Westmere system 
with a total of 24 logical cores.  I've been thinking about doing this 
for a long time so I wouldn't hold your breath.  I am definitely 
interested in your results.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/23/2011 7:36 AM, Dr Heinz M. Kabutz wrote:
> I would like to run some performance tests comparing CHMv8 to the CHM 
> in Java 7 and to Cliff Click's non-blocking hash map implementation.  
> However, I do not have access to hardware that will do the test 
> justice.  Would any of you be able to run some tests for me on 
> machines in excess of 50 cores?  The more the better.  If so, please 
> contact me directly.
>
> Regards
>
> Heinz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/41ebe65f/attachment.html>

From viktor.klang at gmail.com  Fri Dec 23 11:23:35 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Fri, 23 Dec 2011 17:23:35 +0100
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <4EF4A773.2070109@oracle.com>
References: <4E5A95E0.1080309@cs.oswego.edu> <4E68AAC9.9070800@cs.oswego.edu>
	<4E85F532.1040808@redhat.com> <4E88E5D3.6070502@cs.oswego.edu>
	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>
	<4E89BE04.7060907@cs.oswego.edu> <4E8C5775.8090805@cs.oswego.edu>
	<4E8CDADB.7030205@redhat.com> <4E8D9138.8080501@cs.oswego.edu>
	<4E8E2002.7090905@redhat.com> <4E8ED773.9020508@cs.oswego.edu>
	<4EF491E9.7020508@javaspecialists.eu> <4EF4A773.2070109@oracle.com>
Message-ID: <CANPzfU_P8HKnYqUNfr+BY_cG97TsXEAJgnzfwJaXsd8TDqnUgw@mail.gmail.com>

We have a 48-core box (4 x Magny Cours)

Cheers,
?

On Fri, Dec 23, 2011 at 5:08 PM, Nathan Reynolds <nathan.reynolds at oracle.com
> wrote:

>  I've been thinking about running such a test on a dual Westmere system
> with a total of 24 logical cores.  I've been thinking about doing this for
> a long time so I wouldn't hold your breath.  I am definitely interested in
> your results.
>
> Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>
> On 12/23/2011 7:36 AM, Dr Heinz M. Kabutz wrote:
>
> I would like to run some performance tests comparing CHMv8 to the CHM in
> Java 7 and to Cliff Click's non-blocking hash map implementation.  However,
> I do not have access to hardware that will do the test justice.  Would any
> of you be able to run some tests for me on machines in excess of 50 cores?
> The more the better.  If so, please contact me directly.
>
> Regards
>
> Heinz
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/4b12c35c/attachment.html>

From heinz at javaspecialists.eu  Fri Dec 23 12:51:08 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Fri, 23 Dec 2011 19:51:08 +0200
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <CANPzfU_P8HKnYqUNfr+BY_cG97TsXEAJgnzfwJaXsd8TDqnUgw@mail.gmail.com>
References: <4E5A95E0.1080309@cs.oswego.edu>	<4E68AAC9.9070800@cs.oswego.edu>	<4E85F532.1040808@redhat.com>	<4E88E5D3.6070502@cs.oswego.edu>	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>	<4E89BE04.7060907@cs.oswego.edu>	<4E8C5775.8090805@cs.oswego.edu>	<4E8CDADB.7030205@redhat.com>	<4E8D9138.8080501@cs.oswego.edu>	<4E8E2002.7090905@redhat.com>	<4E8ED773.9020508@cs.oswego.edu>	<4EF491E9.7020508@javaspecialists.eu>	<4EF4A773.2070109@oracle.com>
	<CANPzfU_P8HKnYqUNfr+BY_cG97TsXEAJgnzfwJaXsd8TDqnUgw@mail.gmail.com>
Message-ID: <4EF4BF8C.5030406@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/ca1b5c58/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: clifftest.tgz
Type: application/x-gzip
Size: 158518 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/ca1b5c58/attachment-0001.bin>

From rahul.jan83 at gmail.com  Fri Dec 23 14:57:24 2011
From: rahul.jan83 at gmail.com (Rahul Saksena)
Date: Fri, 23 Dec 2011 14:57:24 -0500
Subject: [concurrency-interest] To Hyper-Thread or not
Message-ID: <CAHOyS0enLaA8z6MLqJ=NB9mRYYTr1zsYhbY5r3ey2YOn_2CpRw@mail.gmail.com>

Assuming we have 8 physical cores (intel xeon SMP) and the java process has
more than 12 threads running  through out its life cycle (no shared
variables),

Would you enable hyperthreading and have 16 logical cores?
Does enabling hyperthreading result in far less number of context switches
in this case?
Does the jvm recognize that these threads have no shared data/contention
and pin/bind it to different cores?

Thanks,
Rahul.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/4c7d5662/attachment.html>

From nathan.reynolds at oracle.com  Fri Dec 23 15:40:48 2011
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Fri, 23 Dec 2011 13:40:48 -0700
Subject: [concurrency-interest] To Hyper-Thread or not
In-Reply-To: <CAHOyS0enLaA8z6MLqJ=NB9mRYYTr1zsYhbY5r3ey2YOn_2CpRw@mail.gmail.com>
References: <CAHOyS0enLaA8z6MLqJ=NB9mRYYTr1zsYhbY5r3ey2YOn_2CpRw@mail.gmail.com>
Message-ID: <4EF4E750.2090707@oracle.com>

Intel has said that older hyper-threaded cores sometimes showed a gain 
and sometimes showed a loss in throughput.  They also said that newer 
hyper-threaded cores show a 30-50% gain in throughput for the workloads 
they tested.  I am not sure where the older vs newer line is.  A Nehalem 
and Westmere CPU is definitely in the newer category.

I am not sure of the impact of hyperthreading on context switches.

I don't think JRockit or HotSpot do any thread scheduling or pinning.  I 
think the kernel scheduler determines where each thread runs.  JRockit 
Virtual Edition does thread scheduling since it is a thin "kernel" for 
running JRockit as a virtualization guest.

As for detecting shared data/contention, that was the point of 
@Contended email chain on this list a while back.  Intel and Oracle have 
worked on a solution for true/false sharing.  The current Intel CPUs 
don't quite expose enough information for a fully automated solution.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology

On 12/23/2011 12:57 PM, Rahul Saksena wrote:
> Assuming we have 8 physical cores (intel xeon SMP) and the java 
> process has more than 12 threads running  through out its life cycle 
> (no shared variables),
>
> Would you enable hyperthreading and have 16 logical cores?
> Does enabling hyperthreading result in far less number of context 
> switches in this case?
> Does the jvm recognize that these threads have no shared 
> data/contention and pin/bind it to different cores?
>
> Thanks,
> Rahul.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111223/075bc91d/attachment.html>

From davidcholmes at aapt.net.au  Fri Dec 23 17:20:08 2011
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 24 Dec 2011 08:20:08 +1000
Subject: [concurrency-interest] To Hyper-Thread or not
In-Reply-To: <CAHOyS0enLaA8z6MLqJ=NB9mRYYTr1zsYhbY5r3ey2YOn_2CpRw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEBIJCAA.davidcholmes@aapt.net.au>

The hotspot JVM does no pinning/binding of any kind. The OS provides the
illusion of an entity called a "processor", which appear to be equivalent to
the JVM but in practice a thread is not a core is not a socket. The OS does
all the scheduling and will generally use locality heuristics and prefer to
run threads on the same entity they last ran on. But it varies.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Rahul
Saksena
  Sent: Saturday, 24 December 2011 5:57 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] To Hyper-Thread or not


  Assuming we have 8 physical cores (intel xeon SMP) and the java process
has more than 12 threads running  through out its life cycle (no shared
variables),


  Would you enable hyperthreading and have 16 logical cores?
  Does enabling hyperthreading result in far less number of context switches
in this case?
  Does the jvm recognize that these threads have no shared data/contention
and pin/bind it to different cores?


  Thanks,
  Rahul.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111224/5969f771/attachment.html>

From heinz at javaspecialists.eu  Sat Dec 24 15:09:27 2011
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Sat, 24 Dec 2011 22:09:27 +0200
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <4EF4BF8C.5030406@javaspecialists.eu>
References: <4E5A95E0.1080309@cs.oswego.edu>	<4E68AAC9.9070800@cs.oswego.edu>	<4E85F532.1040808@redhat.com>	<4E88E5D3.6070502@cs.oswego.edu>	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>	<4E89BE04.7060907@cs.oswego.edu>	<4E8C5775.8090805@cs.oswego.edu>	<4E8CDADB.7030205@redhat.com>	<4E8D9138.8080501@cs.oswego.edu>	<4E8E2002.7090905@redhat.com>	<4E8ED773.9020508@cs.oswego.edu>	<4EF491E9.7020508@javaspecialists.eu>	<4EF4A773.2070109@oracle.com>
	<CANPzfU_P8HKnYqUNfr+BY_cG97TsXEAJgnzfwJaXsd8TDqnUgw@mail.gmail.com>
	<4EF4BF8C.5030406@javaspecialists.eu>
Message-ID: <4EF63177.3050404@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111224/f444e0da/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: JavaConcurrency-v0.1-11.PerformanceAndScalability.pdf
Type: application/pdf
Size: 1123192 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111224/f444e0da/attachment-0001.pdf>

From viktor.klang at gmail.com  Sun Dec 25 11:55:47 2011
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Sun, 25 Dec 2011 17:55:47 +0100
Subject: [concurrency-interest] To Hyper-Thread or not
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEBIJCAA.davidcholmes@aapt.net.au>
References: <CAHOyS0enLaA8z6MLqJ=NB9mRYYTr1zsYhbY5r3ey2YOn_2CpRw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEBIJCAA.davidcholmes@aapt.net.au>
Message-ID: <CANPzfU_tNZ_-Z=0t0Ge8eQhfzJFip8A4eNPvuF6by-YqPxhJ5w@mail.gmail.com>

Definitely makes a lot of different for Akka's performance.

Cheers,
?

On Fri, Dec 23, 2011 at 11:20 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> The hotspot JVM does no pinning/binding of any kind. The OS provides the
> illusion of an entity called a "processor", which appear to be equivalent
> to the JVM but in practice a thread is not a core is not a socket. The OS
> does all the scheduling and will generally use locality heuristics and
> prefer to run threads on the same entity they last ran on. But it varies.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Rahul Saksena
> *Sent:* Saturday, 24 December 2011 5:57 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] To Hyper-Thread or not
>
> Assuming we have 8 physical cores (intel xeon SMP) and the java process
> has more than 12 threads running  through out its life cycle (no shared
> variables),
>
> Would you enable hyperthreading and have 16 logical cores?
> Does enabling hyperthreading result in far less number of context switches
> in this case?
> Does the jvm recognize that these threads have no shared data/contention
> and pin/bind it to different cores?
>
> Thanks,
> Rahul.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Viktor Klang

Akka Tech Lead
Typesafe <http://www.typesafe.com/> - Enterprise-Grade Scala from the
Experts

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111225/89b5e21c/attachment.html>

From radhakrishnan.mohan at gmail.com  Mon Dec 26 05:21:30 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 26 Dec 2011 15:51:30 +0530
Subject: [concurrency-interest] 3 rules of final field semantics
Message-ID: <CAOoXFP_SO8zSuyRUxqKiehs2vsGC=rmiRMOJ6HDsxsKttsFCPQ@mail.gmail.com>

After the recent discussion about final fields I decided to look up
the rules in the JMM.

It looks like rule 1 is in 17.5 Final Field Semantics with an example.

Do the programs shown below exemplfify rule 2 and 3 assuming one
thread calls writer and the other calls reader? The sentences
describing the rules are a little bit complex.


Similarly, you cannot reorder either of the first two with the third
assignment in:
      v.afield = 1; x.finalField = v; ... ; sharedRef = x;

(e.g)

public class FinalRule2 {

        private final V finalField;

        private V v;

        public static FinalRule2 rule2;

        public FinalRule2() {

        	v.afield = 1;

        	finalField = v;

        }

        public static void writer(){
        	
        	rule2 = new FinalRule2(); //sharedRef
        }

        public static void reader(){
		if( null != rule2 ){
			System.out.println( rule2.v.afield );
		}
        }
}

class V{
	int afield;
}


The initial load (i.e., the very first encounter by a thread) of a
final field cannot be reordered with the initial load of the reference
to the object containing the final field. This comes into play in:
      x = sharedRef; ... ; i = x.finalField;


(e.g)

public class FinalRule3 {

        private final int finalField;

        private int i;

        public static FinalRule3 rule3;

        private FinalRule3 x;

        public FinalRule3(){
        	
        	finalField = 1;
        }

        public static void writer(){
        	
        	rule3 = new FinalRule3();
        	x = rule3;                  //sharedRef
        }

        public static void reader(){
			if( null != rule3 ){
				int i = x.finalField;
				System.out.println( i );
			}
        }
}

Thanks,
Mohan

From cheremin at gmail.com  Mon Dec 26 05:46:16 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Mon, 26 Dec 2011 14:46:16 +0400
Subject: [concurrency-interest] 3 rules of final field semantics
In-Reply-To: <CAOwENi+3gCor4MrK2HSxHL7NiP=ehWsGxnhT9eEwGc4pZ=DHCQ@mail.gmail.com>
References: <CAOoXFP_SO8zSuyRUxqKiehs2vsGC=rmiRMOJ6HDsxsKttsFCPQ@mail.gmail.com>
	<CAOwENi+3gCor4MrK2HSxHL7NiP=ehWsGxnhT9eEwGc4pZ=DHCQ@mail.gmail.com>
Message-ID: <CAOwENiJd7KG9F2XLyH3=nRLRsdCsLud9pMSQY52684PZ+hahhw@mail.gmail.com>

It seems for me that your first example (rule 2) is incorrect. Final
field itself does not make any additional ordering guarantee for class
it contains in -- it gives ordering guarantee only for read going
through this final field.

Here

v.afield = 1; x.finalField = v; ... ; sharedRef = x;

you really can't reorder first two assignments with reference
publication. But your case is more complex actually:

local _v = new V(); _v.afield=1; x.finalField=_v; x.v=_v;sharedRef=x;

It seems for me that nothing prevent JIT to reorder (x.v = _x) after
(sharedRef=x) -- so you still can see ?rule2.v = null, or even (not
sure about it) rule2.v.afield=0(default value)



2011/12/26 Mohan Radhakrishnan <radhakrishnan.mohan at gmail.com>:
> After the recent discussion about final fields I decided to look up
> the rules in the JMM.
>
> It looks like rule 1 is in 17.5 Final Field Semantics with an example.
>
> Do the programs shown below exemplfify rule 2 and 3 assuming one
> thread calls writer and the other calls reader? The sentences
> describing the rules are a little bit complex.
>
>
> Similarly, you cannot reorder either of the first two with the third
> assignment in:
> ? ? ?v.afield = 1; x.finalField = v; ... ; sharedRef = x;
>
> (e.g)
>
> public class FinalRule2 {
>
> ? ? ? ?private final V finalField;
>
> ? ? ? ?private V v;
>
> ? ? ? ?public static FinalRule2 rule2;
>
> ? ? ? ?public FinalRule2() {
>
> ? ? ? ? ? ? ? ?v.afield = 1;
>
> ? ? ? ? ? ? ? ?finalField = v;
>
> ? ? ? ?}
>
> ? ? ? ?public static void writer(){
>
> ? ? ? ? ? ? ? ?rule2 = new FinalRule2(); //sharedRef
> ? ? ? ?}
>
> ? ? ? ?public static void reader(){
> ? ? ? ? ? ? ? ?if( null != rule2 ){
> ? ? ? ? ? ? ? ? ? ? ? ?System.out.println( rule2.v.afield );
> ? ? ? ? ? ? ? ?}
> ? ? ? ?}
> }
>
> class V{
> ? ? ? ?int afield;
> }
>
>
> The initial load (i.e., the very first encounter by a thread) of a
> final field cannot be reordered with the initial load of the reference
> to the object containing the final field. This comes into play in:
> ? ? ?x = sharedRef; ... ; i = x.finalField;
>
>
> (e.g)
>
> public class FinalRule3 {
>
> ? ? ? ?private final int finalField;
>
> ? ? ? ?private int i;
>
> ? ? ? ?public static FinalRule3 rule3;
>
> ? ? ? ?private FinalRule3 x;
>
> ? ? ? ?public FinalRule3(){
>
> ? ? ? ? ? ? ? ?finalField = 1;
> ? ? ? ?}
>
> ? ? ? ?public static void writer(){
>
> ? ? ? ? ? ? ? ?rule3 = new FinalRule3();
> ? ? ? ? ? ? ? ?x = rule3; ? ? ? ? ? ? ? ? ?//sharedRef
> ? ? ? ?}
>
> ? ? ? ?public static void reader(){
> ? ? ? ? ? ? ? ? ? ? ? ?if( null != rule3 ){
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?int i = x.finalField;
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?System.out.println( i );
> ? ? ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ?}
> }
>
> Thanks,
> Mohan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Mon Dec 26 10:58:17 2011
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 26 Dec 2011 10:58:17 -0500
Subject: [concurrency-interest] ConcurrentHashMapV8
In-Reply-To: <4EF63177.3050404@javaspecialists.eu>
References: <4E5A95E0.1080309@cs.oswego.edu>	<4E68AAC9.9070800@cs.oswego.edu>	<4E85F532.1040808@redhat.com>	<4E88E5D3.6070502@cs.oswego.edu>	<CANPzfU8MaAyA5rB+XDgCfiWLOZK1hBhkA0REjMqDbrVF7GXOvQ@mail.gmail.com>	<4E89BE04.7060907@cs.oswego.edu>	<4E8C5775.8090805@cs.oswego.edu>	<4E8CDADB.7030205@redhat.com>	<4E8D9138.8080501@cs.oswego.edu>	<4E8E2002.7090905@redhat.com>	<4E8ED773.9020508@cs.oswego.edu>	<4EF491E9.7020508@javaspecialists.eu>	<4EF4A773.2070109@oracle.com>
	<CANPzfU_P8HKnYqUNfr+BY_cG97TsXEAJgnzfwJaXsd8TDqnUgw@mail.gmail.com>
	<4EF4BF8C.5030406@javaspecialists.eu>
	<4EF63177.3050404@javaspecialists.eu>
Message-ID: <4EF89999.60609@cs.oswego.edu>

On 12/24/11 15:09, Dr Heinz M. Kabutz wrote:
>  >From my first tests on my little 8-core system, it seems that for small table
> sizes, CHM v8 is the clear winner.
>
> But if the table is a bit larger, say 1000000 entries, then Cliff Click's
> NonBlockingHashMap takes the lead.

This is consistent with what I see. We have 6 test machines, 2 each
Intel, AMD, and Sparc, ranging from 8 to 128 hardware threads, that
we regularly run most of the approx 100 performance checks in
our CVS src/test/loops. (Plus accounts on other machines out there
for less frequent tests.) See near the end of
http://gee.cs.oswego.edu/dl/concurrency-interest/index.html
for notes on getting and using these. Cliff Click's test (that was the basis
of yours) isn't in our CVS but we occasionally run it too.

Testing performance of hash tables requires care.
There are many reasons that a single test program can be
uninformative. For example, some tests just amount to
measuring a platform's memory system throughput under
constant cache misses. Some have key types,
locality/non-locality of key or value use, or operation mixes that
are not representative of most uses.  For NON-concurrent hash table
benchmarks, there seems to be enough rough consensus about
what makes for representativeness that we put together
MapMicroBenchmark (in test/loops) that we mostly believe.
For concurrent ones, there still seems to be too much diversity
to treat any particular test program as definitive.
In general though, I've found that CHMV8 does better than
NonBlockingHashMap except in two cases: (1) When the table
is large and there is little locality of key use -- here,
NonBlockingHashMap's more compact key array representation
pays off; and (2) when the table needs to expand rapidly due
to insertions by multiple threads -- here, NonBlockingHashMap's
help-out approach can work better than CHMV8's approach of
a single resizer while the old table is concurrently usable.
Neither of these scenarios seems common enough to outweigh
the CHMV8's advantages in other cases.


> Seems that for empty maps, the standard CHM with 4096 would need *16544* bytes
> and for the Version 8 of CHM would need *72* bytes.  It would be interesting to
> try out how the Version 8 CHM grows as we add more elements :-)

It averages approximately 8 * N words (where N is number of elements),
with a large variance because table size expands only at powers of two.

It is worth noting though that probably the most consistent
finding across all sorts of performance tests for all sorts of
hash tables (and across all sorts of languages)
is that providing a good size estimate in constructor arguments
is the single best thing users can do to improve performance.
We employ many clever techniques to cope when there are no
estimates, but none of them are as effective as good user guidance.

-Doug



From ted_yu at yahoo.com  Mon Dec 26 23:00:15 2011
From: ted_yu at yahoo.com (Ted Yu)
Date: Mon, 26 Dec 2011 20:00:15 -0800 (PST)
Subject: [concurrency-interest] concurrency issue on SoftValueSortedMap
In-Reply-To: <mailman.1.1324832400.19235.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1324832400.19235.concurrency-interest@cs.oswego.edu>
Message-ID: <1324958415.31754.YahooMailNeo@web30802.mail.mud.yahoo.com>

Hi,
I want to hear experts' comment on this issue:
https://issues.apache.org/jira/browse/HBASE-5088

See if the stack trace is familiar to any of you:
https://issues.apache.org/jira/browse/HBASE-5088?focusedCommentId=13174606&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13174606

JVM version is 1.6.0_22

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20111226/8d991699/attachment.html>

From radhakrishnan.mohan at gmail.com  Tue Dec 27 04:10:56 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Tue, 27 Dec 2011 14:40:56 +0530
Subject: [concurrency-interest] 3 rules of final field semantics
In-Reply-To: <CAOwENiJd7KG9F2XLyH3=nRLRsdCsLud9pMSQY52684PZ+hahhw@mail.gmail.com>
References: <CAOoXFP_SO8zSuyRUxqKiehs2vsGC=rmiRMOJ6HDsxsKttsFCPQ@mail.gmail.com>
	<CAOwENi+3gCor4MrK2HSxHL7NiP=ehWsGxnhT9eEwGc4pZ=DHCQ@mail.gmail.com>
	<CAOwENiJd7KG9F2XLyH3=nRLRsdCsLud9pMSQY52684PZ+hahhw@mail.gmail.com>
Message-ID: <CAOoXFP8PrXRPzUYdOO8-OzUoVexShRJwPgM+2EGazMUruGFJyQ@mail.gmail.com>

I was thinking that this

        	v.afield = 1;

        	finalField = v;
        	
        	rule2 = new FinalRule2(); //sharedref

is equivalent to

v.afield = 1; x.finalField = v; ... ; sharedRef = x;

Earlier I was thinking that we are not concerned with patterns like
this because Java takes care of it !

Thanks,
Mohan

From cheremin at gmail.com  Tue Dec 27 05:23:28 2011
From: cheremin at gmail.com (Ruslan Cheremin)
Date: Tue, 27 Dec 2011 14:23:28 +0400
Subject: [concurrency-interest] 3 rules of final field semantics
In-Reply-To: <CAOoXFP8PrXRPzUYdOO8-OzUoVexShRJwPgM+2EGazMUruGFJyQ@mail.gmail.com>
References: <CAOoXFP_SO8zSuyRUxqKiehs2vsGC=rmiRMOJ6HDsxsKttsFCPQ@mail.gmail.com>
	<CAOwENi+3gCor4MrK2HSxHL7NiP=ehWsGxnhT9eEwGc4pZ=DHCQ@mail.gmail.com>
	<CAOwENiJd7KG9F2XLyH3=nRLRsdCsLud9pMSQY52684PZ+hahhw@mail.gmail.com>
	<CAOoXFP8PrXRPzUYdOO8-OzUoVexShRJwPgM+2EGazMUruGFJyQ@mail.gmail.com>
Message-ID: <CAOwENiLB6EBi2HkgYE8uPrs5SzoKc0FB3Sztuf7E2xvADGLpoQ@mail.gmail.com>

My point was about this: final fields semantic is very precise.
Additional happens-before edges it brings into JMM are guaranteed only
for very specific kind of usages. Moreover, such HB edges are _not
transitive_ -- so you can't spread ordering them gives you farther by
merging them with program-order HB edges, and other ones (as it
usually can be done with ordinary HB -- which _are_ transitive).

So far, final field semantic (as far, as I do understand them)
guarantee you what if you have object A with final field f, and:
 1) You publish reference to A "correctly" -- which, here means "
'this' does not escape from A's constructor"
 1) You have got reference to A in some other thread
 2) Then, going through reference chain _starting from A.f_ (this is
important!) you'll guaranteed to see any stores, finished before A's
constructor completed (before freeze).

In your rele 2 example you trying to see stores, finished before
freeze, but you trying to see them through non-final A's field. AFAIK,
JMM gives you no additional guarantee in this case.



2011/12/27 Mohan Radhakrishnan <radhakrishnan.mohan at gmail.com>:
> I was thinking that this
>
> ? ? ? ? ? ? ? ?v.afield = 1;
>
> ? ? ? ? ? ? ? ?finalField = v;
>
> ? ? ? ? ? ? ? ?rule2 = new FinalRule2(); //sharedref
>
> is equivalent to
>
> v.afield = 1; x.finalField = v; ... ; sharedRef = x;
>
> Earlier I was thinking that we are not concerned with patterns like
> this because Java takes care of it !
>
> Thanks,
> Mohan
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From radhakrishnan.mohan at gmail.com  Fri Dec 30 00:14:54 2011
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Fri, 30 Dec 2011 10:44:54 +0530
Subject: [concurrency-interest] 3 rules of final field semantics
In-Reply-To: <CAOwENiLB6EBi2HkgYE8uPrs5SzoKc0FB3Sztuf7E2xvADGLpoQ@mail.gmail.com>
References: <CAOoXFP_SO8zSuyRUxqKiehs2vsGC=rmiRMOJ6HDsxsKttsFCPQ@mail.gmail.com>
	<CAOwENi+3gCor4MrK2HSxHL7NiP=ehWsGxnhT9eEwGc4pZ=DHCQ@mail.gmail.com>
	<CAOwENiJd7KG9F2XLyH3=nRLRsdCsLud9pMSQY52684PZ+hahhw@mail.gmail.com>
	<CAOoXFP8PrXRPzUYdOO8-OzUoVexShRJwPgM+2EGazMUruGFJyQ@mail.gmail.com>
	<CAOwENiLB6EBi2HkgYE8uPrs5SzoKc0FB3Sztuf7E2xvADGLpoQ@mail.gmail.com>
Message-ID: <CAOoXFP_Wtj4pneQHbC8iK9==e1oNy_WHrNUPnxCXCQ3skdnGPQ@mail.gmail.com>

Ok. I got the point about traversal through a reference chain starting
with a final field and not a non-final field.

Mohan

On Tue, Dec 27, 2011 at 3:53 PM, Ruslan Cheremin <cheremin at gmail.com> wrote:
> My point was about this: final fields semantic is very precise.
> Additional happens-before edges it brings into JMM are guaranteed only
> for very specific kind of usages. Moreover, such HB edges are _not
> transitive_ -- so you can't spread ordering them gives you farther by
> merging them with program-order HB edges, and other ones (as it
> usually can be done with ordinary HB -- which _are_ transitive).
>
> So far, final field semantic (as far, as I do understand them)
> guarantee you what if you have object A with final field f, and:
> ?1) You publish reference to A "correctly" -- which, here means "
> 'this' does not escape from A's constructor"
> ?1) You have got reference to A in some other thread
> ?2) Then, going through reference chain _starting from A.f_ (this is
> important!) you'll guaranteed to see any stores, finished before A's
> constructor completed (before freeze).
>
> In your rele 2 example you trying to see stores, finished before
> freeze, but you trying to see them through non-final A's field. AFAIK,
> JMM gives you no additional guarantee in this case.
>
>
>
> 2011/12/27 Mohan Radhakrishnan <radhakrishnan.mohan at gmail.com>:
>> I was thinking that this
>>
>> ? ? ? ? ? ? ? ?v.afield = 1;
>>
>> ? ? ? ? ? ? ? ?finalField = v;
>>
>> ? ? ? ? ? ? ? ?rule2 = new FinalRule2(); //sharedref
>>
>> is equivalent to
>>
>> v.afield = 1; x.finalField = v; ... ; sharedRef = x;
>>
>> Earlier I was thinking that we are not concerned with patterns like
>> this because Java takes care of it !
>>
>> Thanks,
>> Mohan
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


