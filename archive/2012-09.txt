From andreas.lochbihler at kit.edu  Mon Sep  3 03:34:38 2012
From: andreas.lochbihler at kit.edu (Andreas Lochbihler)
Date: Mon, 03 Sep 2012 09:34:38 +0200
Subject: [concurrency-interest] Interruption after notification
Message-ID: <50445D8E.1020009@kit.edu>

Dear all,

I am wondering whether a thread may reverse the order of notification and 
interruption when it is waiting. In the following example, thread 1 waits on 
some shared monitor m, while thread 2 first notifies thread 1 in m's wait set 
and then interrupts it.

Thread 1:
synchronized (m) { m.wait(); }

Thread 2:
synchronized (m) { m.notify(); }
t1.interrupt(); // t1 references the object for thread 1

I am unsure whether Java allows that the call to wait in thread 1 returns with 
an InterruptedException if there are no other threads around. I have tried 
various OpenJDK versions, but was never able to observe the thrown 
InterruptedException.

However, the JLS (17.8.1) mentions that every thread itself may determine an 
order over the events that cause it to be removed from m's wait set - and this 
order need not be consistent with other orders. I read that as follows: If there 
are at least two threads concurrently notifying and interupting another thread, 
it is up to the implementation to choose the order. Even if the threads 
synchronize themselves, the thread that is notified and interrupted does not 
have to respect this.
However, can this be stretched as far as in this example where it is a single 
thread that notifies and interrupts?

Andreas

-- 
Karlsruher Institut f?r Technologie
IPD Snelting

Andreas Lochbihler
wissenschaftlicher Mitarbeiter
Am Fasanengarten 5, Geb. 50.34, Raum 025
76131 Karlsruhe

Telefon: +49 721 608-47399
Fax: +49 721 608-48457
E-Mail: andreas.lochbihler at kit.edu
http://pp.info.uni-karlsruhe.de
KIT - Universit?t des Landes Baden-W?rttemberg und nationales Forschungszentrum 
in der Helmholtz-Gemeinschaft

From davidcholmes at aapt.net.au  Mon Sep  3 04:50:43 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 3 Sep 2012 18:50:43 +1000
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <50445D8E.1020009@kit.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEJCJGAA.davidcholmes@aapt.net.au>

The simple answer is yes. If a thread is notified then detects it is also
interrupted then it can throw IE instead.

The only restriction is that the notify() can not be lost - if two threads
are waiting and there is one notify and one interrupt then both threads must
stop waiting.

David Holmes

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andreas
> Lochbihler
> Sent: Monday, 3 September 2012 5:35 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Interruption after notification
>
>
> Dear all,
>
> I am wondering whether a thread may reverse the order of notification and
> interruption when it is waiting. In the following example, thread
> 1 waits on
> some shared monitor m, while thread 2 first notifies thread 1 in
> m's wait set
> and then interrupts it.
>
> Thread 1:
> synchronized (m) { m.wait(); }
>
> Thread 2:
> synchronized (m) { m.notify(); }
> t1.interrupt(); // t1 references the object for thread 1
>
> I am unsure whether Java allows that the call to wait in thread 1
> returns with
> an InterruptedException if there are no other threads around. I
> have tried
> various OpenJDK versions, but was never able to observe the thrown
> InterruptedException.
>
> However, the JLS (17.8.1) mentions that every thread itself may
> determine an
> order over the events that cause it to be removed from m's wait
> set - and this
> order need not be consistent with other orders. I read that as
> follows: If there
> are at least two threads concurrently notifying and interupting
> another thread,
> it is up to the implementation to choose the order. Even if the threads
> synchronize themselves, the thread that is notified and
> interrupted does not
> have to respect this.
> However, can this be stretched as far as in this example where it
> is a single
> thread that notifies and interrupts?
>
> Andreas
>
> --
> Karlsruher Institut f?r Technologie
> IPD Snelting
>
> Andreas Lochbihler
> wissenschaftlicher Mitarbeiter
> Am Fasanengarten 5, Geb. 50.34, Raum 025
> 76131 Karlsruhe
>
> Telefon: +49 721 608-47399
> Fax: +49 721 608-48457
> E-Mail: andreas.lochbihler at kit.edu
> http://pp.info.uni-karlsruhe.de
> KIT - Universit?t des Landes Baden-W?rttemberg und nationales
> Forschungszentrum
> in der Helmholtz-Gemeinschaft
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From davidcholmes at aapt.net.au  Mon Sep  3 07:03:55 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 3 Sep 2012 21:03:55 +1000
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEJCJGAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>

Note to self: don't send quick emails when running out the door :)

I wrote:
>
> The simple answer is yes. If a thread is notified then detects it is also
> interrupted then it can throw IE instead.
>
> The only restriction is that the notify() can not be lost - if two threads
> are waiting and there is one notify and one interrupt then both
> threads must stop waiting.

That last part is not correct of course as the interrupted thread can return
normally leaving the other thread still waiting.

The point is that you can not have one thread throw IE and have the other
remain waiting.

David


>
> David Holmes
>
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andreas
> > Lochbihler
> > Sent: Monday, 3 September 2012 5:35 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Interruption after notification
> >
> >
> > Dear all,
> >
> > I am wondering whether a thread may reverse the order of
> notification and
> > interruption when it is waiting. In the following example, thread
> > 1 waits on
> > some shared monitor m, while thread 2 first notifies thread 1 in
> > m's wait set
> > and then interrupts it.
> >
> > Thread 1:
> > synchronized (m) { m.wait(); }
> >
> > Thread 2:
> > synchronized (m) { m.notify(); }
> > t1.interrupt(); // t1 references the object for thread 1
> >
> > I am unsure whether Java allows that the call to wait in thread 1
> > returns with
> > an InterruptedException if there are no other threads around. I
> > have tried
> > various OpenJDK versions, but was never able to observe the thrown
> > InterruptedException.
> >
> > However, the JLS (17.8.1) mentions that every thread itself may
> > determine an
> > order over the events that cause it to be removed from m's wait
> > set - and this
> > order need not be consistent with other orders. I read that as
> > follows: If there
> > are at least two threads concurrently notifying and interupting
> > another thread,
> > it is up to the implementation to choose the order. Even if the threads
> > synchronize themselves, the thread that is notified and
> > interrupted does not
> > have to respect this.
> > However, can this be stretched as far as in this example where it
> > is a single
> > thread that notifies and interrupts?
> >
> > Andreas
> >
> > --
> > Karlsruher Institut f?r Technologie
> > IPD Snelting
> >
> > Andreas Lochbihler
> > wissenschaftlicher Mitarbeiter
> > Am Fasanengarten 5, Geb. 50.34, Raum 025
> > 76131 Karlsruhe
> >
> > Telefon: +49 721 608-47399
> > Fax: +49 721 608-48457
> > E-Mail: andreas.lochbihler at kit.edu
> > http://pp.info.uni-karlsruhe.de
> > KIT - Universit?t des Landes Baden-W?rttemberg und nationales
> > Forschungszentrum
> > in der Helmholtz-Gemeinschaft
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



From heinz at javaspecialists.eu  Mon Sep  3 07:17:23 2012
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 03 Sep 2012 14:17:23 +0300
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>
Message-ID: <504491C3.1020702@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120903/fa44edb4/attachment.html>

From davidcholmes at aapt.net.au  Mon Sep  3 07:30:50 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 3 Sep 2012 21:30:50 +1000
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <504491C3.1020702@javaspecialists.eu>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEJDJGAA.davidcholmes@aapt.net.au>

Hi Heinz,

Originally it was not defined and you will see that all of Doug's earlier
implementations would re-notify if they threw IE to make sure the notify
didn't get lost. I considered that untenable and pushed for it to be fixed,
which it was for Java 5 - JLS 17.8.4 Interactions of Waits, Notifications
and Interruptions.

The Javadoc for Object.wait is not quite as clear as I would like but the
wording is that the thread waits "until one of four tings happens", implying
there is only a single reason for leaving the wait and that you can't report
a different reason. That isn't quite true of course you can report a
different reason (ie throw IE when originally notified) provided 17.8.4 is
obeyed and no notification can be lost.

Why do I have a feeling this is about to start another of these mammoth
email discussions ... :)

David
  -----Original Message-----
  From: Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
  Sent: Monday, 3 September 2012 9:17 PM
  To: dholmes at ieee.org
  Cc: Andreas Lochbihler; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Interruption after notification



  On 9/3/12 2:03 PM, David Holmes wrote:
Note to self: don't send quick emails when running out the door :)

I wrote:
  The simple answer is yes. If a thread is notified then detects it is also
interrupted then it can throw IE instead.

The only restriction is that the notify() can not be lost - if two threads
are waiting and there is one notify and one interrupt then both
threads must stop waiting.

That last part is not correct of course as the interrupted thread can return
normally leaving the other thread still waiting.

The point is that you can not have one thread throw IE and have the other
remain waiting.
  Where is this defined?  In Doug Lea's book (from 1999), it does seem to be
possible that a thread might consume the notify() and then throw the
InterruptedException, which is where this pattern came from:

  try {
    wait();
  } catch(InterruptedException ex) {
    notify();
    throw ex;
  }

  I don't have Doug's book in front of me, but will dig out the section if
necessary.

  From an earlier email exchange I understood that this behaviour was not
possible with the ReentrantLock implementation, but even the Lock interface
seems to allow it.

  Kind regards

  Heinz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120903/dff48e91/attachment.html>

From dl at cs.oswego.edu  Mon Sep  3 08:01:24 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 03 Sep 2012 08:01:24 -0400
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <504491C3.1020702@javaspecialists.eu>
References: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>
	<504491C3.1020702@javaspecialists.eu>
Message-ID: <50449C14.1090903@cs.oswego.edu>

On 09/03/12 07:17, Dr Heinz M. Kabutz wrote:

> Where is this defined?  In Doug Lea's book (from 1999), it does seem to be
> possible that a thread might consume the notify() and then throw the
> InterruptedException, which is where this pattern came from:
>

This was clarified in the JSR133 revisions to JLS chapter 17 -- see
http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.2
This is reflected in David's reply. Things are not much
more deterministic than pre-JSR133 specs, but at least it
is clear that "losing" events is not allowed.

-Doug


From andreas.lochbihler at kit.edu  Mon Sep  3 08:43:02 2012
From: andreas.lochbihler at kit.edu (Andreas Lochbihler)
Date: Mon, 03 Sep 2012 14:43:02 +0200
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCOEJCJGAA.davidcholmes@aapt.net.au>
Message-ID: <5044A5D6.20706@kit.edu>

Hi David,

thanks for the clarification. Let me slightly extend my example such that thread 
2 now calls m.wait() in the end.

Thread 1:
synchronized (m) { m.wait(); }

Thread 2:
synchronized (m) { m.notify(); }
t1.interrupt(); // t1 references the object for thread 1
synchronized (m) { m.wait(); }

If I understood you correctly, thread 1 could decide to throw IE in spite of 
having been removed due to the notify, provided it notifies another waiting 
thread (if there's one). Hence, in the above example, thread 2 could return from 
m's wait set because of its own notification before. That looks very strange to 
me. Am I wrong?

Andreas

Am 03.09.2012 13:03, schrieb David Holmes:
> Note to self: don't send quick emails when running out the door :)
>
> I wrote:
>>
>> The simple answer is yes. If a thread is notified then detects it is also
>> interrupted then it can throw IE instead.
>>
>> The only restriction is that the notify() can not be lost - if two threads
>> are waiting and there is one notify and one interrupt then both
>> threads must stop waiting.
>
> That last part is not correct of course as the interrupted thread can return
> normally leaving the other thread still waiting.
>
> The point is that you can not have one thread throw IE and have the other
> remain waiting.
>
> David
>
>
>>
>> David Holmes
>>
>>> -----Original Message-----
>>> From: concurrency-interest-bounces at cs.oswego.edu
>>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andreas
>>> Lochbihler
>>> Sent: Monday, 3 September 2012 5:35 PM
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: [concurrency-interest] Interruption after notification
>>>
>>>
>>> Dear all,
>>>
>>> I am wondering whether a thread may reverse the order of
>> notification and
>>> interruption when it is waiting. In the following example, thread
>>> 1 waits on
>>> some shared monitor m, while thread 2 first notifies thread 1 in
>>> m's wait set
>>> and then interrupts it.
>>>
>>> Thread 1:
>>> synchronized (m) { m.wait(); }
>>>
>>> Thread 2:
>>> synchronized (m) { m.notify(); }
>>> t1.interrupt(); // t1 references the object for thread 1
>>>
>>> I am unsure whether Java allows that the call to wait in thread 1
>>> returns with
>>> an InterruptedException if there are no other threads around. I
>>> have tried
>>> various OpenJDK versions, but was never able to observe the thrown
>>> InterruptedException.
>>>
>>> However, the JLS (17.8.1) mentions that every thread itself may
>>> determine an
>>> order over the events that cause it to be removed from m's wait
>>> set - and this
>>> order need not be consistent with other orders. I read that as
>>> follows: If there
>>> are at least two threads concurrently notifying and interupting
>>> another thread,
>>> it is up to the implementation to choose the order. Even if the threads
>>> synchronize themselves, the thread that is notified and
>>> interrupted does not
>>> have to respect this.
>>> However, can this be stretched as far as in this example where it
>>> is a single
>>> thread that notifies and interrupts?
>>>
>>> Andreas
>>>
>>> --
>>> Karlsruher Institut f?r Technologie
>>> IPD Snelting
>>>
>>> Andreas Lochbihler
>>> wissenschaftlicher Mitarbeiter
>>> Am Fasanengarten 5, Geb. 50.34, Raum 025
>>> 76131 Karlsruhe
>>>
>>> Telefon: +49 721 608-47399
>>> Fax: +49 721 608-48457
>>> E-Mail: andreas.lochbihler at kit.edu
>>> http://pp.info.uni-karlsruhe.de
>>> KIT - Universit?t des Landes Baden-W?rttemberg und nationales
>>> Forschungszentrum
>>> in der Helmholtz-Gemeinschaft
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

-- 
Karlsruher Institut f?r Technologie
IPD Snelting

Andreas Lochbihler
wissenschaftlicher Mitarbeiter
Am Fasanengarten 5, Geb. 50.34, Raum 025
76131 Karlsruhe

Telefon: +49 721 608-47399
Fax: +49 721 608-48457
E-Mail: andreas.lochbihler at kit.edu
http://pp.info.uni-karlsruhe.de
KIT - Universit?t des Landes Baden-W?rttemberg und nationales Forschungszentrum 
in der Helmholtz-Gemeinschaft

From oleksandr.otenko at oracle.com  Mon Sep  3 08:45:25 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Mon, 03 Sep 2012 13:45:25 +0100
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEJDJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEJDJGAA.davidcholmes@aapt.net.au>
Message-ID: <5044A665.2000802@oracle.com>

Interesting, how to interpret "no action is lost" wrt "each action is 
signalled once *and only* once".

For example, the pattern of "try{wait();}catch(...){ notify() }" will 
signal one notify more than once, and will behave very much like 
park/unpark.

Alex


On 03/09/2012 12:30, David Holmes wrote:
> Hi Heinz,
> Originally it was not defined and you will see that all of Doug's 
> earlier implementations would re-notify if they threw IE to make sure 
> the notify didn't get lost. I considered that untenable and pushed for 
> it to be fixed, which it was for Java 5 - JLS 17.8.4 Interactions of 
> Waits, Notifications and Interruptions.
> The Javadoc for Object.wait is not quite as clear as I would like but 
> the wording is that the thread waits "until one of four tings 
> happens", implying there is only a single reason for leaving the wait 
> and that you can't report a different reason. That isn't quite true of 
> course you can report a different reason (ie throw IE when originally 
> notified) provided 17.8.4 is obeyed and no notification can be lost.
> Why do I have a feeling this is about to start another of these 
> mammoth email discussions ... :)
> David
>
>     -----Original Message-----
>     *From:* Dr Heinz M. Kabutz [mailto:heinz at javaspecialists.eu]
>     *Sent:* Monday, 3 September 2012 9:17 PM
>     *To:* dholmes at ieee.org
>     *Cc:* Andreas Lochbihler; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Interruption after notification
>
>
>     On 9/3/12 2:03 PM, David Holmes wrote:
>>     Note to self: don't send quick emails when running out the door :)
>>
>>     I wrote:
>>        
>>>     The simple answer is yes. If a thread is notified then detects it is also
>>>     interrupted then it can throw IE instead.
>>>
>>>     The only restriction is that the notify() can not be lost - if two threads
>>>     are waiting and there is one notify and one interrupt then both
>>>     threads must stop waiting.
>>>          
>>
>>     That last part is not correct of course as the interrupted thread can return
>>     normally leaving the other thread still waiting.
>>
>>     The point is that you can not have one thread throw IE and have the other
>>     remain waiting.
>>        
>     Where is this defined?  In Doug Lea's book (from 1999), it does
>     seem to be possible that a thread might consume the notify() and
>     then throw the InterruptedException, which is where this pattern
>     came from:
>
>     try {
>       wait();
>     } catch(InterruptedException ex) {
>       notify();
>       throw ex;
>     }
>
>     I don't have Doug's book in front of me, but will dig out the
>     section if necessary.
>
>     From an earlier email exchange I understood that this behaviour
>     was not possible with the ReentrantLock implementation, but even
>     the Lock interface seems to allow it.
>
>     Kind regards
>
>     Heinz
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120903/26c88747/attachment.html>

From davidcholmes at aapt.net.au  Mon Sep  3 16:19:18 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 4 Sep 2012 06:19:18 +1000
Subject: [concurrency-interest] Interruption after notification
In-Reply-To: <5044A5D6.20706@kit.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEJEJGAA.davidcholmes@aapt.net.au>

Hi Andreas,

Notification is stateless, if there is no thread to notify then nothing
happens, otherwise a thread in the wait-set is selected to be notified - the
thread doing the notify can't be in the wait-set hence you can not notify
yourself. (Of course you may return anyway due to spurious wakeup.)

David

> -----Original Message-----
> From: Andreas Lochbihler [mailto:andreas.lochbihler at kit.edu]
> Sent: Monday, 3 September 2012 10:43 PM
> To: David Holmes
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Interruption after notification
>
>
> Hi David,
>
> thanks for the clarification. Let me slightly extend my example
> such that thread 2 now calls m.wait() in the end.
>
> Thread 1:
> synchronized (m) { m.wait(); }
>
> Thread 2:
> synchronized (m) { m.notify(); }
> t1.interrupt(); // t1 references the object for thread 1
> synchronized (m) { m.wait(); }
>
> If I understood you correctly, thread 1 could decide to throw IE
> in spite of
> having been removed due to the notify, provided it notifies
> another waiting
> thread (if there's one). Hence, in the above example, thread 2
> could return from
> m's wait set because of its own notification before. That looks
> very strange to me. Am I wrong?
>
> Andreas
>
> Am 03.09.2012 13:03, schrieb David Holmes:
> > Note to self: don't send quick emails when running out the door :)
> >
> > I wrote:
> >>
> >> The simple answer is yes. If a thread is notified then detects
> it is also
> >> interrupted then it can throw IE instead.
> >>
> >> The only restriction is that the notify() can not be lost - if
> two threads
> >> are waiting and there is one notify and one interrupt then both
> >> threads must stop waiting.
> >
> > That last part is not correct of course as the interrupted
> thread can return
> > normally leaving the other thread still waiting.
> >
> > The point is that you can not have one thread throw IE and have
> the other
> > remain waiting.
> >
> > David
> >
> >
> >>
> >> David Holmes
> >>
> >>> -----Original Message-----
> >>> From: concurrency-interest-bounces at cs.oswego.edu
> >>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf
> Of Andreas
> >>> Lochbihler
> >>> Sent: Monday, 3 September 2012 5:35 PM
> >>> To: concurrency-interest at cs.oswego.edu
> >>> Subject: [concurrency-interest] Interruption after notification
> >>>
> >>>
> >>> Dear all,
> >>>
> >>> I am wondering whether a thread may reverse the order of
> >> notification and
> >>> interruption when it is waiting. In the following example, thread
> >>> 1 waits on
> >>> some shared monitor m, while thread 2 first notifies thread 1 in
> >>> m's wait set
> >>> and then interrupts it.
> >>>
> >>> Thread 1:
> >>> synchronized (m) { m.wait(); }
> >>>
> >>> Thread 2:
> >>> synchronized (m) { m.notify(); }
> >>> t1.interrupt(); // t1 references the object for thread 1
> >>>
> >>> I am unsure whether Java allows that the call to wait in thread 1
> >>> returns with
> >>> an InterruptedException if there are no other threads around. I
> >>> have tried
> >>> various OpenJDK versions, but was never able to observe the thrown
> >>> InterruptedException.
> >>>
> >>> However, the JLS (17.8.1) mentions that every thread itself may
> >>> determine an
> >>> order over the events that cause it to be removed from m's wait
> >>> set - and this
> >>> order need not be consistent with other orders. I read that as
> >>> follows: If there
> >>> are at least two threads concurrently notifying and interupting
> >>> another thread,
> >>> it is up to the implementation to choose the order. Even if
> the threads
> >>> synchronize themselves, the thread that is notified and
> >>> interrupted does not
> >>> have to respect this.
> >>> However, can this be stretched as far as in this example where it
> >>> is a single
> >>> thread that notifies and interrupts?
> >>>
> >>> Andreas
> >>>
> >>> --
> >>> Karlsruher Institut f?r Technologie
> >>> IPD Snelting
> >>>
> >>> Andreas Lochbihler
> >>> wissenschaftlicher Mitarbeiter
> >>> Am Fasanengarten 5, Geb. 50.34, Raum 025
> >>> 76131 Karlsruhe
> >>>
> >>> Telefon: +49 721 608-47399
> >>> Fax: +49 721 608-48457
> >>> E-Mail: andreas.lochbihler at kit.edu
> >>> http://pp.info.uni-karlsruhe.de
> >>> KIT - Universit?t des Landes Baden-W?rttemberg und nationales
> >>> Forschungszentrum
> >>> in der Helmholtz-Gemeinschaft
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
>
> --
> Karlsruher Institut f?r Technologie
> IPD Snelting
>
> Andreas Lochbihler
> wissenschaftlicher Mitarbeiter
> Am Fasanengarten 5, Geb. 50.34, Raum 025
> 76131 Karlsruhe
>
> Telefon: +49 721 608-47399
> Fax: +49 721 608-48457
> E-Mail: andreas.lochbihler at kit.edu
> http://pp.info.uni-karlsruhe.de
> KIT - Universit?t des Landes Baden-W?rttemberg und nationales
> Forschungszentrum
> in der Helmholtz-Gemeinschaft
>



From aarong at cs.cmu.edu  Tue Sep  4 10:46:49 2012
From: aarong at cs.cmu.edu (Aaron Greenhouse)
Date: Tue, 4 Sep 2012 10:46:49 -0400
Subject: [concurrency-interest] Thread safety of elements in ThreadSafe
	collections
Message-ID: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>

I have a question about something that I'm surprised I haven't seen discussed anywhere before.  If I have a thread safe collection, such as a CopyOnWriteArrayList, what are the thread safety requirements of the elements I put in the collection?  It seems to me that any object put into a thread safe collection must be of a type that is also thread safe due to

(1) the fact that the equals, toString, and hashCode methods are going to be invoked on it

(2) possibly from several threads, possibly from a thread distinct from the one that put the element into the collection (or why else is a thread safe collection being used?)

Alternatively, the class of the object must NOT override hashCode() and equals(), and use reference identity preserving implementations from java.lang.Object.

But I've never seen these requirements implicitly or explicitly discussed any where before.  I cooked up a an example this afternoon where by putting a non-thread safe object into a CopyOnWriteArrayList, I can make the hashCode() method of the list violate its invariants.

public class BreakIt {
public static void main(String[] args) {
  // Precalculate the expected hash values
  final List<Element> list = new ArrayList<Element>();
  list.add(new Element(10, 20, 30));
  list.add(new Element(30, 15, 1));
  final int hc1 = list.hashCode();

  list.clear();
  list.add(new Element(10, 20, 30));
  list.add(new Element(99, 37, 17));
  final int hc2 = list.hashCode();

  list.clear();

  System.out.println("Hashcode should be " + hc1 + " or " + hc2);

  final List<Element> safeList = new CopyOnWriteArrayList<Element>();
  final Element e1 = new Element(10, 20, 30);
  final Element e2 = new Element(30, 15, 1);
  safeList.add(e1);
  safeList.add(e2);

  final Executor exec = Executors.newFixedThreadPool(6);
  for (int i = 0; i < 5; i++) {
    exec.execute(new ReaderTask(hc1, hc2, safeList));
  }
  exec.execute(new Fiddler(e2));
}
}

final class ReaderTask implements Runnable {
private final int hc1;
private final int hc2;
private final List<Element> list;

public ReaderTask(int v1, int v2, List<Element> l) {
  hc1 = v1;
  hc2 = v2;
  list = l;
}

@Override
public void run() {
  int good = 0;
  while (true) {
    final int h = list.hashCode();
    if (h != hc1 && h != hc2) {
      System.out.println("After " + good + " tries, got bad hashcode: " + h);
      good = 0;
    } else {
      good += 1;
    }      
  }
}
}

final class Fiddler implements Runnable {
private final Element elt;

public Fiddler(Element e) {
  elt = e;
}

@Override
public void run() {
  while (true) {
    elt.set(30, 15, 1);
    try {
      Thread.sleep(10);
    } catch (InterruptedException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }
    elt.set(99, 37, 17);
  }
}
}


final class Element {
private int x;
private int y;
private int z;


public Element(int a, int b, int c) {
  x = a;
  y = b;
  z = c;
}

public void set(int a, int b, int c) {
  x = a;
  y = b;
  z = c;
}

@Override
public int hashCode() {
  int hc = 17;
  hc = 31 * hc + x;
  hc = 31 * hc + y;
  hc = 31 * hc + z;
  return hc;
}

@Override
public boolean equals(final Object o) {
  if (o == this) {
    return true;
  } else if (o instanceof Element) {
    final Element other = (Element) o;
    return x == other.x && y == other.y && z == other.z;
  }
  return false;
}

@Override
public String toString() {
  return "<" + x + ", " + y + ", " + z + ">";
}
}

When I run this, I immediately observe breakages:

Hashcode should be 16554621 or 16621628
After 227690 tries, got bad hashcode: 16620930
After 379544 tries, got bad hashcode: 16620930
After 232377 tries, got bad hashcode: 16620930
After 206754 tries, got bad hashcode: 16620930
After 98116 tries, got bad hashcode: 16620930
After 90573 tries, got bad hashcode: 16620930
After 90503 tries, got bad hashcode: 16620930
After 505897 tries, got bad hashcode: 16620930
After 529645 tries, got bad hashcode: 16621612
After 497268 tries, got bad hashcode: 16620930
After 1155576 tries, got bad hashcode: 16620930
After 949490 tries, got bad hashcode: 16620930
After 314761 tries, got bad hashcode: 16620930
After 800675 tries, got bad hashcode: 16620930
After 281174 tries, got bad hashcode: 16620930
After 358146 tries, got bad hashcode: 16620930
After 346746 tries, got bad hashcode: 16621612
After 465604 tries, got bad hashcode: 16620930
(and so on)

Obviously, the equal() and toString() methods of the list could be forced to observe an intermediate state of an Element object too.

So, why the silence on this issue?  Seems like this is something even experienced programmers are bound to mess up, never mind programmers new to concurrency.


On a related note, but not specifically a concurrency observation, it seems to be pretty much a very very bad idea to override hashCode() on a mutable object (even though the collection classes do it).  But I've never seen this mentioned anywhere either.  Certainly I've never seen any one say don't modify an object after you stick in a collection.  If you put an object in a set or map and then change its state in such a way that affects its hash code, you have broken the set or map that you put it in because the object is still indexed by its original hash code.  You can see this with this example where I use an ArrayList has an element of other collections.

public class Test {
public static void main(String[] s) {
  final List<String> element = new ArrayList<String>();
  final Set<List<? extends Object>> hashSet = new HashSet<List<? extends Object>>();
  final List<List<? extends Object>> arrayList = new ArrayList<List<? extends Object>>();
  final List<List<? extends Object>> linkedList = new LinkedList<List<? extends Object>>();

  element.add("a");
  element.add("b");
  System.out.println("Element is " + element);
  System.out.println("Element has hashcode " + element.hashCode());

  hashSet.add(element);
  System.out.println("Hash set is " + hashSet);
  System.out.println("Hash set has hashcode " + hashSet.hashCode());
  System.out.println("Hash set contains element? " + hashSet.contains(element));

  arrayList.add(element);
  System.out.println("Array list is " + arrayList);
  System.out.println("Array list has hashcode " + arrayList.hashCode());
  System.out.println("Array list contains element? " + arrayList.contains(element));

  linkedList.add(element);
  System.out.println("Linked list is " + linkedList);
  System.out.println("Linked list has hashcode " + linkedList.hashCode());
  System.out.println("Linked list contains element? " + linkedList.contains(element));


  System.out.println();
  System.out.println("=== Adding c and d to element ===");
  element.add("c");
  element.add("d");

  System.out.println("Element is " + element);
  System.out.println("Element has hashcode " + element.hashCode());

  System.out.println("Set is " + hashSet);
  System.out.println("Set has hashcode " + hashSet.hashCode());
  System.out.println("Set contains element? " + hashSet.contains(element));

  System.out.println("Array list is " + arrayList);
  System.out.println("Array list has hashcode " + arrayList.hashCode());
  System.out.println("Array list contains element? " + arrayList.contains(element));

  System.out.println("Linked list is " + linkedList);
  System.out.println("Linked list has hashcode " + linkedList.hashCode());
  System.out.println("Linked list contains element? " + linkedList.contains(element));
}
}

I get the output

Element is [a, b]
Element has hashcode 4066
Hash set is [[a, b]]
Hash set has hashcode 4066
Hash set contains element? true
Array list is [[a, b]]
Array list has hashcode 4097
Array list contains element? true
Linked list is [[a, b]]
Linked list has hashcode 4097
Linked list contains element? true

=== Adding c and d to element ===
Element is [a, b, c, d]
Element has hashcode 3910595
Set is [[a, b, c, d]]
Set has hashcode 3910595
Set contains element? false
Array list is [[a, b, c, d]]
Array list has hashcode 3910626
Array list contains element? true
Linked list is [[a, b, c, d]]
Linked list has hashcode 3910626
Linked list contains element? true

Of note is that after adding "c" and "d" to the element list, set.contains() returns the wrong value.

--Aaron Greenhouse


From david.dice at gmail.com  Tue Sep  4 13:06:54 2012
From: david.dice at gmail.com (David Dice)
Date: Tue, 4 Sep 2012 13:06:54 -0400
Subject: [concurrency-interest] Subject: Re: Interruption after notification
Message-ID: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>

As an aside, in the current implementation in hotspot if we have a both a
pending notification and interrupt, we return from wait() leaving the
interrupt pending.

Dave
https://blogs.oracle.com/dave/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/0caf2f77/attachment.html>

From vitalyd at gmail.com  Tue Sep  4 13:35:44 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 13:35:44 -0400
Subject: [concurrency-interest] Subject: Re: Interruption after
	notification
In-Reply-To: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>
References: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>
Message-ID: <CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>

Dave,

I can see why one may want to leave interrupt pending (thread may complete
without checking interrupt status) but I can also see an argument in favor
of delivering the interrupt in such a case (I.e. deliver the "inevitable"
sooner, assuming thread will notice the interrupt soon thereafter).

So just curious - what's the rationale for choosing notification over
interrupt here?

Thanks

Sent from my phone
On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:

> As an aside, in the current implementation in hotspot if we have a both a
> pending notification and interrupt, we return from wait() leaving the
> interrupt pending.
>
> Dave
> https://blogs.oracle.com/dave/
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/a6657050/attachment.html>

From david.dice at gmail.com  Tue Sep  4 14:21:35 2012
From: david.dice at gmail.com (David Dice)
Date: Tue, 4 Sep 2012 14:21:35 -0400
Subject: [concurrency-interest] Subject: Re: Interruption after
	notification
In-Reply-To: <CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>
References: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>
	<CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>
Message-ID: <CANbRUcjW0a-pZFJb5coySjBi8dT24ufSFGhES3e2PoMGoA+nhw@mail.gmail.com>

On Tue, Sep 4, 2012 at 1:35 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:

> I can see why one may want to leave interrupt pending (thread may complete
> without checking interrupt status) but I can also see an argument in favor
> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
> sooner, assuming thread will notice the interrupt soon thereafter).
>
> So just curious - what's the rationale for choosing notification over
> interrupt here
>
Hi Vitaly,

Thankfully the spec gives implementors considerable latitude & license in
this regard.  Interrupt, like notify, will unpark the target thread as
necessary.   As control unwinds out of wait() -- after the internal park
call returns -- we try to differentiate notification vs interrupt.   This
triage is performed rather late, and without regard as to which occurred
1st.   For expediency, it's easier to return "notification" rather than
"interruption" as I don't have to repost and be otherwise concerned with
lost notifications.   Reposting is conceptually simple, but in practice
more difficult than you might expect because of interactions with the
monitoring & management hooks.   So ultimately it's far simpler to just
defer the interrupt.   I don't have SCCS history in front of me, but I
think I changed to the policy to the current state in the 1.4 timeframe.

Regards
Dave
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/9bcd71fe/attachment.html>

From oleksandr.otenko at oracle.com  Tue Sep  4 14:42:34 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Tue, 04 Sep 2012 19:42:34 +0100
Subject: [concurrency-interest] Subject: Re: Interruption after
	notification
In-Reply-To: <CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>
References: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>
	<CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>
Message-ID: <50464B9A.3020900@oracle.com>

If these two events arrive concurrently, there is no ordering between 
them. So preferring interruption over notification doesn't change the 
correctness.

Does JLS specify what the application _should_ do upon receiving 
InterruptedException?

Alex


On 04/09/2012 18:35, Vitaly Davidovich wrote:
>
> Dave,
>
> I can see why one may want to leave interrupt pending (thread may 
> complete without checking interrupt status) but I can also see an 
> argument in favor of delivering the interrupt in such a case (I.e. 
> deliver the "inevitable" sooner, assuming thread will notice the 
> interrupt soon thereafter).
>
> So just curious - what's the rationale for choosing notification over 
> interrupt here?
>
> Thanks
>
> Sent from my phone
>
> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com 
> <mailto:david.dice at gmail.com>> wrote:
>
>     As an aside, in the current implementation in hotspot if we have a
>     both a pending notification and interrupt, we return from wait()
>     leaving the interrupt pending.
>
>     Dave
>     https://blogs.oracle.com/dave/
>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/1d03ed8b/attachment.html>

From vitalyd at gmail.com  Tue Sep  4 15:09:42 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 15:09:42 -0400
Subject: [concurrency-interest] Subject: Re: Interruption after
	notification
In-Reply-To: <CANbRUcjW0a-pZFJb5coySjBi8dT24ufSFGhES3e2PoMGoA+nhw@mail.gmail.com>
References: <CANbRUchwzUxvwj4cfStrBXT44PRX_yPqkVnqDhAVscgHQvFv0w@mail.gmail.com>
	<CAHjP37EUGJ_Fvs3=kvDYCLJ3rnNVU=xmPTjv60_+Y2r7PO8-TA@mail.gmail.com>
	<CANbRUcjW0a-pZFJb5coySjBi8dT24ufSFGhES3e2PoMGoA+nhw@mail.gmail.com>
Message-ID: <CAHjP37FB2POJpyZV_tP8zsULNnSm0x8Y_RtTkemGwuu+q5Oi9w@mail.gmail.com>

Hi Dave,

Thanks for the insight - I see what you're saying.

Alex, my interest was purely in why notification was picked over interrupt
- I'm not questioning correctness since, as you say, order is not
necessarily clear and/or absolute.

Cheers

Sent from my phone
On Sep 4, 2012 2:21 PM, "David Dice" <david.dice at gmail.com> wrote:

>
>
> On Tue, Sep 4, 2012 at 1:35 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> I can see why one may want to leave interrupt pending (thread may
>> complete without checking interrupt status) but I can also see an argument
>> in favor of delivering the interrupt in such a case (I.e. deliver the
>> "inevitable" sooner, assuming thread will notice the interrupt soon
>> thereafter).
>>
>> So just curious - what's the rationale for choosing notification over
>> interrupt here
>>
> Hi Vitaly,
>
> Thankfully the spec gives implementors considerable latitude & license in
> this regard.  Interrupt, like notify, will unpark the target thread as
> necessary.   As control unwinds out of wait() -- after the internal park
> call returns -- we try to differentiate notification vs interrupt.   This
> triage is performed rather late, and without regard as to which occurred
> 1st.   For expediency, it's easier to return "notification" rather than
> "interruption" as I don't have to repost and be otherwise concerned with
> lost notifications.   Reposting is conceptually simple, but in practice
> more difficult than you might expect because of interactions with the
> monitoring & management hooks.   So ultimately it's far simpler to just
> defer the interrupt.   I don't have SCCS history in front of me, but I
> think I changed to the policy to the current state in the 1.4 timeframe.
>
> Regards
> Dave
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/03e2d976/attachment.html>

From davidcholmes at aapt.net.au  Tue Sep  4 18:37:03 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 08:37:03 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50464B9A.3020900@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>

The JLS doesn't say anything about what applications should do. All the
application knows when the IE is thrown is that the thread was interrupted
and the interrupt state is now clear. It is up to the application to respond
to the interruption in an appropriate manner.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
otenko
  Sent: Wednesday, 5 September 2012 4:43 AM
  To: Vitaly Davidovich
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


  If these two events arrive concurrently, there is no ordering between
them. So preferring interruption over notification doesn't change the
correctness.

  Does JLS specify what the application _should_ do upon receiving
InterruptedException?

  Alex


  On 04/09/2012 18:35, Vitaly Davidovich wrote:
    Dave,

    I can see why one may want to leave interrupt pending (thread may
complete without checking interrupt status) but I can also see an argument
in favor of delivering the interrupt in such a case (I.e. deliver the
"inevitable" sooner, assuming thread will notice the interrupt soon
thereafter).

    So just curious - what's the rationale for choosing notification over
interrupt here?

    Thanks

    Sent from my phone

    On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:

      As an aside, in the current implementation in hotspot if we have a
both a pending notification and interrupt, we return from wait() leaving the
interrupt pending.


      Dave
      https://blogs.oracle.com/dave/





      _______________________________________________
      Concurrency-interest mailing list
      Concurrency-interest at cs.oswego.edu
      http://cs.oswego.edu/mailman/listinfo/concurrency-interest





_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/26d9cb6c/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Sep  4 18:44:19 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 08:44:19 +1000
Subject: [concurrency-interest] Thread safety of elements in
	ThreadSafecollections
In-Reply-To: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEJLJGAA.davidcholmes@aapt.net.au>

This is mixing a number of different things. There are general disclaimers
with concurrent collections that objects should not be being mutated while
placed into the collection. If you have an object with a non-constant
hashcode or equals then it is going to be very hard to use correctly with
many collections - even if only one thread is involved - so the general
advice is "don't do that". Beyond that whether the object needs to be
thread-safe depends on whether it will be concurrently used.

David Holmes



> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Aaron
> Greenhouse
> Sent: Wednesday, 5 September 2012 12:47 AM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Thread safety of elements in
> ThreadSafecollections
>
>
> I have a question about something that I'm surprised I haven't
> seen discussed anywhere before.  If I have a thread safe
> collection, such as a CopyOnWriteArrayList, what are the thread
> safety requirements of the elements I put in the collection?  It
> seems to me that any object put into a thread safe collection
> must be of a type that is also thread safe due to
>
> (1) the fact that the equals, toString, and hashCode methods are
> going to be invoked on it
>
> (2) possibly from several threads, possibly from a thread
> distinct from the one that put the element into the collection
> (or why else is a thread safe collection being used?)
>
> Alternatively, the class of the object must NOT override
> hashCode() and equals(), and use reference identity preserving
> implementations from java.lang.Object.
>
> But I've never seen these requirements implicitly or explicitly
> discussed any where before.  I cooked up a an example this
> afternoon where by putting a non-thread safe object into a
> CopyOnWriteArrayList, I can make the hashCode() method of the
> list violate its invariants.
>
> public class BreakIt {
> public static void main(String[] args) {
>   // Precalculate the expected hash values
>   final List<Element> list = new ArrayList<Element>();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(30, 15, 1));
>   final int hc1 = list.hashCode();
>
>   list.clear();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(99, 37, 17));
>   final int hc2 = list.hashCode();
>
>   list.clear();
>
>   System.out.println("Hashcode should be " + hc1 + " or " + hc2);
>
>   final List<Element> safeList = new CopyOnWriteArrayList<Element>();
>   final Element e1 = new Element(10, 20, 30);
>   final Element e2 = new Element(30, 15, 1);
>   safeList.add(e1);
>   safeList.add(e2);
>
>   final Executor exec = Executors.newFixedThreadPool(6);
>   for (int i = 0; i < 5; i++) {
>     exec.execute(new ReaderTask(hc1, hc2, safeList));
>   }
>   exec.execute(new Fiddler(e2));
> }
> }
>
> final class ReaderTask implements Runnable {
> private final int hc1;
> private final int hc2;
> private final List<Element> list;
>
> public ReaderTask(int v1, int v2, List<Element> l) {
>   hc1 = v1;
>   hc2 = v2;
>   list = l;
> }
>
> @Override
> public void run() {
>   int good = 0;
>   while (true) {
>     final int h = list.hashCode();
>     if (h != hc1 && h != hc2) {
>       System.out.println("After " + good + " tries, got bad
> hashcode: " + h);
>       good = 0;
>     } else {
>       good += 1;
>     }
>   }
> }
> }
>
> final class Fiddler implements Runnable {
> private final Element elt;
>
> public Fiddler(Element e) {
>   elt = e;
> }
>
> @Override
> public void run() {
>   while (true) {
>     elt.set(30, 15, 1);
>     try {
>       Thread.sleep(10);
>     } catch (InterruptedException e) {
>       // TODO Auto-generated catch block
>       e.printStackTrace();
>     }
>     elt.set(99, 37, 17);
>   }
> }
> }
>
>
> final class Element {
> private int x;
> private int y;
> private int z;
>
>
> public Element(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> public void set(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> @Override
> public int hashCode() {
>   int hc = 17;
>   hc = 31 * hc + x;
>   hc = 31 * hc + y;
>   hc = 31 * hc + z;
>   return hc;
> }
>
> @Override
> public boolean equals(final Object o) {
>   if (o == this) {
>     return true;
>   } else if (o instanceof Element) {
>     final Element other = (Element) o;
>     return x == other.x && y == other.y && z == other.z;
>   }
>   return false;
> }
>
> @Override
> public String toString() {
>   return "<" + x + ", " + y + ", " + z + ">";
> }
> }
>
> When I run this, I immediately observe breakages:
>
> Hashcode should be 16554621 or 16621628
> After 227690 tries, got bad hashcode: 16620930
> After 379544 tries, got bad hashcode: 16620930
> After 232377 tries, got bad hashcode: 16620930
> After 206754 tries, got bad hashcode: 16620930
> After 98116 tries, got bad hashcode: 16620930
> After 90573 tries, got bad hashcode: 16620930
> After 90503 tries, got bad hashcode: 16620930
> After 505897 tries, got bad hashcode: 16620930
> After 529645 tries, got bad hashcode: 16621612
> After 497268 tries, got bad hashcode: 16620930
> After 1155576 tries, got bad hashcode: 16620930
> After 949490 tries, got bad hashcode: 16620930
> After 314761 tries, got bad hashcode: 16620930
> After 800675 tries, got bad hashcode: 16620930
> After 281174 tries, got bad hashcode: 16620930
> After 358146 tries, got bad hashcode: 16620930
> After 346746 tries, got bad hashcode: 16621612
> After 465604 tries, got bad hashcode: 16620930
> (and so on)
>
> Obviously, the equal() and toString() methods of the list could
> be forced to observe an intermediate state of an Element object too.
>
> So, why the silence on this issue?  Seems like this is something
> even experienced programmers are bound to mess up, never mind
> programmers new to concurrency.
>
>
> On a related note, but not specifically a concurrency
> observation, it seems to be pretty much a very very bad idea to
> override hashCode() on a mutable object (even though the
> collection classes do it).  But I've never seen this mentioned
> anywhere either.  Certainly I've never seen any one say don't
> modify an object after you stick in a collection.  If you put an
> object in a set or map and then change its state in such a way
> that affects its hash code, you have broken the set or map that
> you put it in because the object is still indexed by its original
> hash code.  You can see this with this example where I use an
> ArrayList has an element of other collections.
>
> public class Test {
> public static void main(String[] s) {
>   final List<String> element = new ArrayList<String>();
>   final Set<List<? extends Object>> hashSet = new HashSet<List<?
> extends Object>>();
>   final List<List<? extends Object>> arrayList = new
> ArrayList<List<? extends Object>>();
>   final List<List<? extends Object>> linkedList = new
> LinkedList<List<? extends Object>>();
>
>   element.add("a");
>   element.add("b");
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   hashSet.add(element);
>   System.out.println("Hash set is " + hashSet);
>   System.out.println("Hash set has hashcode " + hashSet.hashCode());
>   System.out.println("Hash set contains element? " +
> hashSet.contains(element));
>
>   arrayList.add(element);
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " +
> arrayList.contains(element));
>
>   linkedList.add(element);
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " +
> linkedList.contains(element));
>
>
>   System.out.println();
>   System.out.println("=== Adding c and d to element ===");
>   element.add("c");
>   element.add("d");
>
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   System.out.println("Set is " + hashSet);
>   System.out.println("Set has hashcode " + hashSet.hashCode());
>   System.out.println("Set contains element? " +
> hashSet.contains(element));
>
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " +
> arrayList.contains(element));
>
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " +
> linkedList.contains(element));
> }
> }
>
> I get the output
>
> Element is [a, b]
> Element has hashcode 4066
> Hash set is [[a, b]]
> Hash set has hashcode 4066
> Hash set contains element? true
> Array list is [[a, b]]
> Array list has hashcode 4097
> Array list contains element? true
> Linked list is [[a, b]]
> Linked list has hashcode 4097
> Linked list contains element? true
>
> === Adding c and d to element ===
> Element is [a, b, c, d]
> Element has hashcode 3910595
> Set is [[a, b, c, d]]
> Set has hashcode 3910595
> Set contains element? false
> Array list is [[a, b, c, d]]
> Array list has hashcode 3910626
> Array list contains element? true
> Linked list is [[a, b, c, d]]
> Linked list has hashcode 3910626
> Linked list contains element? true
>
> Of note is that after adding "c" and "d" to the element list,
> set.contains() returns the wrong value.
>
> --Aaron Greenhouse
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From vitalyd at gmail.com  Tue Sep  4 18:58:50 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 18:58:50 -0400
Subject: [concurrency-interest] Thread safety of elements in ThreadSafe
	collections
In-Reply-To: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
References: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
Message-ID: <CAHjP37FscygVgcDAJKmrnT6N7eWFods4+dqOcfaNXGWD8=K8mQ@mail.gmail.com>

I think the point of the concurrent collections is that they themselves are
thread safe and maintain their invariants during concurrent access - they
don't stipulate anything about classes you put in them as it depends on use
case, as David mentions (they do, however, typically state what
ordering/happens-before edges are created).

Presumably for the common case you'll want the contained classes to be
thread safe as well, but I'm personally OK with not having that spelled out
explicitly.

Sent from my phone
On Sep 4, 2012 10:52 AM, "Aaron Greenhouse" <aarong at cs.cmu.edu> wrote:

> I have a question about something that I'm surprised I haven't seen
> discussed anywhere before.  If I have a thread safe collection, such as a
> CopyOnWriteArrayList, what are the thread safety requirements of the
> elements I put in the collection?  It seems to me that any object put into
> a thread safe collection must be of a type that is also thread safe due to
>
> (1) the fact that the equals, toString, and hashCode methods are going to
> be invoked on it
>
> (2) possibly from several threads, possibly from a thread distinct from
> the one that put the element into the collection (or why else is a thread
> safe collection being used?)
>
> Alternatively, the class of the object must NOT override hashCode() and
> equals(), and use reference identity preserving implementations from
> java.lang.Object.
>
> But I've never seen these requirements implicitly or explicitly discussed
> any where before.  I cooked up a an example this afternoon where by putting
> a non-thread safe object into a CopyOnWriteArrayList, I can make the
> hashCode() method of the list violate its invariants.
>
> public class BreakIt {
> public static void main(String[] args) {
>   // Precalculate the expected hash values
>   final List<Element> list = new ArrayList<Element>();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(30, 15, 1));
>   final int hc1 = list.hashCode();
>
>   list.clear();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(99, 37, 17));
>   final int hc2 = list.hashCode();
>
>   list.clear();
>
>   System.out.println("Hashcode should be " + hc1 + " or " + hc2);
>
>   final List<Element> safeList = new CopyOnWriteArrayList<Element>();
>   final Element e1 = new Element(10, 20, 30);
>   final Element e2 = new Element(30, 15, 1);
>   safeList.add(e1);
>   safeList.add(e2);
>
>   final Executor exec = Executors.newFixedThreadPool(6);
>   for (int i = 0; i < 5; i++) {
>     exec.execute(new ReaderTask(hc1, hc2, safeList));
>   }
>   exec.execute(new Fiddler(e2));
> }
> }
>
> final class ReaderTask implements Runnable {
> private final int hc1;
> private final int hc2;
> private final List<Element> list;
>
> public ReaderTask(int v1, int v2, List<Element> l) {
>   hc1 = v1;
>   hc2 = v2;
>   list = l;
> }
>
> @Override
> public void run() {
>   int good = 0;
>   while (true) {
>     final int h = list.hashCode();
>     if (h != hc1 && h != hc2) {
>       System.out.println("After " + good + " tries, got bad hashcode: " +
> h);
>       good = 0;
>     } else {
>       good += 1;
>     }
>   }
> }
> }
>
> final class Fiddler implements Runnable {
> private final Element elt;
>
> public Fiddler(Element e) {
>   elt = e;
> }
>
> @Override
> public void run() {
>   while (true) {
>     elt.set(30, 15, 1);
>     try {
>       Thread.sleep(10);
>     } catch (InterruptedException e) {
>       // TODO Auto-generated catch block
>       e.printStackTrace();
>     }
>     elt.set(99, 37, 17);
>   }
> }
> }
>
>
> final class Element {
> private int x;
> private int y;
> private int z;
>
>
> public Element(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> public void set(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> @Override
> public int hashCode() {
>   int hc = 17;
>   hc = 31 * hc + x;
>   hc = 31 * hc + y;
>   hc = 31 * hc + z;
>   return hc;
> }
>
> @Override
> public boolean equals(final Object o) {
>   if (o == this) {
>     return true;
>   } else if (o instanceof Element) {
>     final Element other = (Element) o;
>     return x == other.x && y == other.y && z == other.z;
>   }
>   return false;
> }
>
> @Override
> public String toString() {
>   return "<" + x + ", " + y + ", " + z + ">";
> }
> }
>
> When I run this, I immediately observe breakages:
>
> Hashcode should be 16554621 or 16621628
> After 227690 tries, got bad hashcode: 16620930
> After 379544 tries, got bad hashcode: 16620930
> After 232377 tries, got bad hashcode: 16620930
> After 206754 tries, got bad hashcode: 16620930
> After 98116 tries, got bad hashcode: 16620930
> After 90573 tries, got bad hashcode: 16620930
> After 90503 tries, got bad hashcode: 16620930
> After 505897 tries, got bad hashcode: 16620930
> After 529645 tries, got bad hashcode: 16621612
> After 497268 tries, got bad hashcode: 16620930
> After 1155576 tries, got bad hashcode: 16620930
> After 949490 tries, got bad hashcode: 16620930
> After 314761 tries, got bad hashcode: 16620930
> After 800675 tries, got bad hashcode: 16620930
> After 281174 tries, got bad hashcode: 16620930
> After 358146 tries, got bad hashcode: 16620930
> After 346746 tries, got bad hashcode: 16621612
> After 465604 tries, got bad hashcode: 16620930
> (and so on)
>
> Obviously, the equal() and toString() methods of the list could be forced
> to observe an intermediate state of an Element object too.
>
> So, why the silence on this issue?  Seems like this is something even
> experienced programmers are bound to mess up, never mind programmers new to
> concurrency.
>
>
> On a related note, but not specifically a concurrency observation, it
> seems to be pretty much a very very bad idea to override hashCode() on a
> mutable object (even though the collection classes do it).  But I've never
> seen this mentioned anywhere either.  Certainly I've never seen any one say
> don't modify an object after you stick in a collection.  If you put an
> object in a set or map and then change its state in such a way that affects
> its hash code, you have broken the set or map that you put it in because
> the object is still indexed by its original hash code.  You can see this
> with this example where I use an ArrayList has an element of other
> collections.
>
> public class Test {
> public static void main(String[] s) {
>   final List<String> element = new ArrayList<String>();
>   final Set<List<? extends Object>> hashSet = new HashSet<List<? extends
> Object>>();
>   final List<List<? extends Object>> arrayList = new ArrayList<List<?
> extends Object>>();
>   final List<List<? extends Object>> linkedList = new LinkedList<List<?
> extends Object>>();
>
>   element.add("a");
>   element.add("b");
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   hashSet.add(element);
>   System.out.println("Hash set is " + hashSet);
>   System.out.println("Hash set has hashcode " + hashSet.hashCode());
>   System.out.println("Hash set contains element? " +
> hashSet.contains(element));
>
>   arrayList.add(element);
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " +
> arrayList.contains(element));
>
>   linkedList.add(element);
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " +
> linkedList.contains(element));
>
>
>   System.out.println();
>   System.out.println("=== Adding c and d to element ===");
>   element.add("c");
>   element.add("d");
>
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   System.out.println("Set is " + hashSet);
>   System.out.println("Set has hashcode " + hashSet.hashCode());
>   System.out.println("Set contains element? " + hashSet.contains(element));
>
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " +
> arrayList.contains(element));
>
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " +
> linkedList.contains(element));
> }
> }
>
> I get the output
>
> Element is [a, b]
> Element has hashcode 4066
> Hash set is [[a, b]]
> Hash set has hashcode 4066
> Hash set contains element? true
> Array list is [[a, b]]
> Array list has hashcode 4097
> Array list contains element? true
> Linked list is [[a, b]]
> Linked list has hashcode 4097
> Linked list contains element? true
>
> === Adding c and d to element ===
> Element is [a, b, c, d]
> Element has hashcode 3910595
> Set is [[a, b, c, d]]
> Set has hashcode 3910595
> Set contains element? false
> Array list is [[a, b, c, d]]
> Array list has hashcode 3910626
> Array list contains element? true
> Linked list is [[a, b, c, d]]
> Linked list has hashcode 3910626
> Linked list contains element? true
>
> Of note is that after adding "c" and "d" to the element list,
> set.contains() returns the wrong value.
>
> --Aaron Greenhouse
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/753e1702/attachment-0001.html>

From zhong.j.yu at gmail.com  Tue Sep  4 20:38:51 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 4 Sep 2012 19:38:51 -0500
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
References: <50464B9A.3020900@oracle.com>
	<NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>

On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> The JLS doesn't say anything about what applications should do. All the
> application knows when the IE is thrown is that the thread was interrupted
> and the interrupt state is now clear. It is up to the application to respond
> to the interruption in an appropriate manner.

I'm also unsure about the use of interruption in real world.

In simple cases, the interrupt-er and the interrupt-ee can assign any
special meaning to interruptions. But they can also instead use an
explicit variable to transmit the meaning; interruption doesn't offer
a lot of value here.

In more complex applications, it's hard for interrupt-er to know which
piece of code the interrupt-ee is running at the moment; it's unlikely
that interruption can be used to deliver special meanings.
Interruption can only have 1 meaning universally accepted by all,
which is probably "stop everything and quit the thread"

To achieve that, interruptions need to propagate up, therefore pretty
much all method signatures will be polluted by InterruptedException.
We don't see that in practice.

Or an application will simply restrain from using interruption at all,
since it doesn't know how to handle it. Then all InterruptedExceptions
can be ignored anywhere in the application code.


Zhong Yu


>
> David
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
> otenko
> Sent: Wednesday, 5 September 2012 4:43 AM
> To: Vitaly Davidovich
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
> If these two events arrive concurrently, there is no ordering between them.
> So preferring interruption over notification doesn't change the correctness.
>
> Does JLS specify what the application _should_ do upon receiving
> InterruptedException?
>
> Alex
>
>
> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>
> Dave,
>
> I can see why one may want to leave interrupt pending (thread may complete
> without checking interrupt status) but I can also see an argument in favor
> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
> sooner, assuming thread will notice the interrupt soon thereafter).
>
> So just curious - what's the rationale for choosing notification over
> interrupt here?
>
> Thanks
>
> Sent from my phone
>
> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>
>> As an aside, in the current implementation in hotspot if we have a both a
>> pending notification and interrupt, we return from wait() leaving the
>> interrupt pending.
>>
>> Dave
>> https://blogs.oracle.com/dave/
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From davidcholmes at aapt.net.au  Tue Sep  4 20:46:45 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 10:46:45 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEJMJGAA.davidcholmes@aapt.net.au>

See

- Chapter 3, Section 3.1.2, "Cancellation" in Concurrent Programming in
Java, 2nd Ed.
- Chapter 7, "Cancellation and Shutdown", in Java Concurrency in Practice.

David
-----

> -----Original Message-----
> From: Zhong Yu [mailto:zhong.j.yu at gmail.com]
> Sent: Wednesday, 5 September 2012 10:39 AM
> To: dholmes at ieee.org
> Cc: oleksandr otenko; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
>
> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > The JLS doesn't say anything about what applications should do. All the
> > application knows when the IE is thrown is that the thread was
> interrupted
> > and the interrupt state is now clear. It is up to the
> application to respond
> > to the interruption in an appropriate manner.
>
> I'm also unsure about the use of interruption in real world.
>
> In simple cases, the interrupt-er and the interrupt-ee can assign any
> special meaning to interruptions. But they can also instead use an
> explicit variable to transmit the meaning; interruption doesn't offer
> a lot of value here.
>
> In more complex applications, it's hard for interrupt-er to know which
> piece of code the interrupt-ee is running at the moment; it's unlikely
> that interruption can be used to deliver special meanings.
> Interruption can only have 1 meaning universally accepted by all,
> which is probably "stop everything and quit the thread"
>
> To achieve that, interruptions need to propagate up, therefore pretty
> much all method signatures will be polluted by InterruptedException.
> We don't see that in practice.
>
> Or an application will simply restrain from using interruption at all,
> since it doesn't know how to handle it. Then all InterruptedExceptions
> can be ignored anywhere in the application code.
>
>
> Zhong Yu
>
>
> >
> > David
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> oleksandr
> > otenko
> > Sent: Wednesday, 5 September 2012 4:43 AM
> > To: Vitaly Davidovich
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Subject: Re: Interruption
> > afternotification
> >
> > If these two events arrive concurrently, there is no ordering
> between them.
> > So preferring interruption over notification doesn't change the
> correctness.
> >
> > Does JLS specify what the application _should_ do upon receiving
> > InterruptedException?
> >
> > Alex
> >
> >
> > On 04/09/2012 18:35, Vitaly Davidovich wrote:
> >
> > Dave,
> >
> > I can see why one may want to leave interrupt pending (thread
> may complete
> > without checking interrupt status) but I can also see an
> argument in favor
> > of delivering the interrupt in such a case (I.e. deliver the
> "inevitable"
> > sooner, assuming thread will notice the interrupt soon thereafter).
> >
> > So just curious - what's the rationale for choosing notification over
> > interrupt here?
> >
> > Thanks
> >
> > Sent from my phone
> >
> > On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
> >>
> >> As an aside, in the current implementation in hotspot if we
> have a both a
> >> pending notification and interrupt, we return from wait() leaving the
> >> interrupt pending.
> >>
> >> Dave
> >> https://blogs.oracle.com/dave/
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>


From vitalyd at gmail.com  Tue Sep  4 20:48:51 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 20:48:51 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
References: <50464B9A.3020900@oracle.com>
	<NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
	<CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
Message-ID: <CAHjP37GU=VFT0QowMc5p6K6kZoeA6TudFC6PCjir18+M=99T9g@mail.gmail.com>

You need interruption to get out of blocking/sleeping calls (promptly or at
all).  You can used timed waits where available or some other "workaround"
but interrupting has its uses.

Sent from my phone
On Sep 4, 2012 8:42 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> > The JLS doesn't say anything about what applications should do. All the
> > application knows when the IE is thrown is that the thread was
> interrupted
> > and the interrupt state is now clear. It is up to the application to
> respond
> > to the interruption in an appropriate manner.
>
> I'm also unsure about the use of interruption in real world.
>
> In simple cases, the interrupt-er and the interrupt-ee can assign any
> special meaning to interruptions. But they can also instead use an
> explicit variable to transmit the meaning; interruption doesn't offer
> a lot of value here.
>
> In more complex applications, it's hard for interrupt-er to know which
> piece of code the interrupt-ee is running at the moment; it's unlikely
> that interruption can be used to deliver special meanings.
> Interruption can only have 1 meaning universally accepted by all,
> which is probably "stop everything and quit the thread"
>
> To achieve that, interruptions need to propagate up, therefore pretty
> much all method signatures will be polluted by InterruptedException.
> We don't see that in practice.
>
> Or an application will simply restrain from using interruption at all,
> since it doesn't know how to handle it. Then all InterruptedExceptions
> can be ignored anywhere in the application code.
>
>
> Zhong Yu
>
>
> >
> > David
> >
> > -----Original Message-----
> > From: concurrency-interest-bounces at cs.oswego.edu
> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> oleksandr
> > otenko
> > Sent: Wednesday, 5 September 2012 4:43 AM
> > To: Vitaly Davidovich
> > Cc: concurrency-interest at cs.oswego.edu
> > Subject: Re: [concurrency-interest] Subject: Re: Interruption
> > afternotification
> >
> > If these two events arrive concurrently, there is no ordering between
> them.
> > So preferring interruption over notification doesn't change the
> correctness.
> >
> > Does JLS specify what the application _should_ do upon receiving
> > InterruptedException?
> >
> > Alex
> >
> >
> > On 04/09/2012 18:35, Vitaly Davidovich wrote:
> >
> > Dave,
> >
> > I can see why one may want to leave interrupt pending (thread may
> complete
> > without checking interrupt status) but I can also see an argument in
> favor
> > of delivering the interrupt in such a case (I.e. deliver the "inevitable"
> > sooner, assuming thread will notice the interrupt soon thereafter).
> >
> > So just curious - what's the rationale for choosing notification over
> > interrupt here?
> >
> > Thanks
> >
> > Sent from my phone
> >
> > On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
> >>
> >> As an aside, in the current implementation in hotspot if we have a both
> a
> >> pending notification and interrupt, we return from wait() leaving the
> >> interrupt pending.
> >>
> >> Dave
> >> https://blogs.oracle.com/dave/
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/41370ce8/attachment.html>

From zhong.j.yu at gmail.com  Tue Sep  4 21:15:11 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 4 Sep 2012 20:15:11 -0500
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37GU=VFT0QowMc5p6K6kZoeA6TudFC6PCjir18+M=99T9g@mail.gmail.com>
References: <50464B9A.3020900@oracle.com>
	<NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
	<CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
	<CAHjP37GU=VFT0QowMc5p6K6kZoeA6TudFC6PCjir18+M=99T9g@mail.gmail.com>
Message-ID: <CACuKZqFU19Gs5_283yJhFoFF0HiLGPra5e_4KiLU=vj7R7eRTg@mail.gmail.com>

In simple cases, the interrupter knows where the interruptee might be
blocked, either wait(), or an IO operation. The interrupter can then
precisely break it by notify() or close(). Though interrupt() might be
a little more convenient, it's not a necessity here.

In more complex cases, the interrupter can only blindly interrupt the
interruptee, for it doesn't know enough details about the interruptee
code. Then all code in interruptee must react to interruptions
identically; that means interruption cannot carry special meaning in
this application.

Zhong Yu


On Tue, Sep 4, 2012 at 7:48 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> You need interruption to get out of blocking/sleeping calls (promptly or at
> all).  You can used timed waits where available or some other "workaround"
> but interrupting has its uses.
>
> Sent from my phone
>
> On Sep 4, 2012 8:42 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>> > The JLS doesn't say anything about what applications should do. All the
>> > application knows when the IE is thrown is that the thread was
>> > interrupted
>> > and the interrupt state is now clear. It is up to the application to
>> > respond
>> > to the interruption in an appropriate manner.
>>
>> I'm also unsure about the use of interruption in real world.
>>
>> In simple cases, the interrupt-er and the interrupt-ee can assign any
>> special meaning to interruptions. But they can also instead use an
>> explicit variable to transmit the meaning; interruption doesn't offer
>> a lot of value here.
>>
>> In more complex applications, it's hard for interrupt-er to know which
>> piece of code the interrupt-ee is running at the moment; it's unlikely
>> that interruption can be used to deliver special meanings.
>> Interruption can only have 1 meaning universally accepted by all,
>> which is probably "stop everything and quit the thread"
>>
>> To achieve that, interruptions need to propagate up, therefore pretty
>> much all method signatures will be polluted by InterruptedException.
>> We don't see that in practice.
>>
>> Or an application will simply restrain from using interruption at all,
>> since it doesn't know how to handle it. Then all InterruptedExceptions
>> can be ignored anywhere in the application code.
>>
>>
>> Zhong Yu
>>
>>
>> >
>> > David
>> >
>> > -----Original Message-----
>> > From: concurrency-interest-bounces at cs.oswego.edu
>> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> > oleksandr
>> > otenko
>> > Sent: Wednesday, 5 September 2012 4:43 AM
>> > To: Vitaly Davidovich
>> > Cc: concurrency-interest at cs.oswego.edu
>> > Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> > afternotification
>> >
>> > If these two events arrive concurrently, there is no ordering between
>> > them.
>> > So preferring interruption over notification doesn't change the
>> > correctness.
>> >
>> > Does JLS specify what the application _should_ do upon receiving
>> > InterruptedException?
>> >
>> > Alex
>> >
>> >
>> > On 04/09/2012 18:35, Vitaly Davidovich wrote:
>> >
>> > Dave,
>> >
>> > I can see why one may want to leave interrupt pending (thread may
>> > complete
>> > without checking interrupt status) but I can also see an argument in
>> > favor
>> > of delivering the interrupt in such a case (I.e. deliver the
>> > "inevitable"
>> > sooner, assuming thread will notice the interrupt soon thereafter).
>> >
>> > So just curious - what's the rationale for choosing notification over
>> > interrupt here?
>> >
>> > Thanks
>> >
>> > Sent from my phone
>> >
>> > On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>> >>
>> >> As an aside, in the current implementation in hotspot if we have a both
>> >> a
>> >> pending notification and interrupt, we return from wait() leaving the
>> >> interrupt pending.
>> >>
>> >> Dave
>> >> https://blogs.oracle.com/dave/
>> >>
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From davidcholmes at aapt.net.au  Tue Sep  4 21:26:21 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 11:26:21 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CACuKZqFU19Gs5_283yJhFoFF0HiLGPra5e_4KiLU=vj7R7eRTg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEJNJGAA.davidcholmes@aapt.net.au>

Zhong Yu writes: [mailto:zhong.j.yu at gmail.com]
>
> In simple cases, the interrupter knows where the interruptee might be
> blocked, either wait(), or an IO operation. The interrupter can then
> precisely break it by notify() or close(). Though interrupt() might be
> a little more convenient, it's not a necessity here.

I think it would be extremely rare for the thread issuing the interrupt to
know and be able to access the objects on which a wait() or I/O operation is
being performed. These things are normally deeply encapsulated within the
functionality of a type not exposed via simple variables you manipulate.
Further, as distinct from an interrupt this would potentially affect all
threads using the same object - and in the case of notify() may not even
target the correct object. So this "simple" case would rarely be applicable
and interrupt is more than just "a little more convenient", it is essential
in general.

> In more complex cases, the interrupter can only blindly interrupt the
> interruptee, for it doesn't know enough details about the interruptee
> code. Then all code in interruptee must react to interruptions
> identically; that means interruption cannot carry special meaning in
> this application.

I don't dispute this. It is very difficult to give interruption a special
meaning - you have to know exactly what the target set of threads might do
in all cases. Generally interruption must be considered as a simple
cancellation request.

David

> Zhong Yu
>
>
> On Tue, Sep 4, 2012 at 7:48 PM, Vitaly Davidovich
> <vitalyd at gmail.com> wrote:
> > You need interruption to get out of blocking/sleeping calls
> (promptly or at
> > all).  You can used timed waits where available or some other
> "workaround"
> > but interrupting has its uses.
> >
> > Sent from my phone
> >
> > On Sep 4, 2012 8:42 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
> >>
> >> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
> >> wrote:
> >> > The JLS doesn't say anything about what applications should
> do. All the
> >> > application knows when the IE is thrown is that the thread was
> >> > interrupted
> >> > and the interrupt state is now clear. It is up to the application to
> >> > respond
> >> > to the interruption in an appropriate manner.
> >>
> >> I'm also unsure about the use of interruption in real world.
> >>
> >> In simple cases, the interrupt-er and the interrupt-ee can assign any
> >> special meaning to interruptions. But they can also instead use an
> >> explicit variable to transmit the meaning; interruption doesn't offer
> >> a lot of value here.
> >>
> >> In more complex applications, it's hard for interrupt-er to know which
> >> piece of code the interrupt-ee is running at the moment; it's unlikely
> >> that interruption can be used to deliver special meanings.
> >> Interruption can only have 1 meaning universally accepted by all,
> >> which is probably "stop everything and quit the thread"
> >>
> >> To achieve that, interruptions need to propagate up, therefore pretty
> >> much all method signatures will be polluted by InterruptedException.
> >> We don't see that in practice.
> >>
> >> Or an application will simply restrain from using interruption at all,
> >> since it doesn't know how to handle it. Then all InterruptedExceptions
> >> can be ignored anywhere in the application code.
> >>
> >>
> >> Zhong Yu
> >>
> >>
> >> >
> >> > David
> >> >
> >> > -----Original Message-----
> >> > From: concurrency-interest-bounces at cs.oswego.edu
> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> >> > oleksandr
> >> > otenko
> >> > Sent: Wednesday, 5 September 2012 4:43 AM
> >> > To: Vitaly Davidovich
> >> > Cc: concurrency-interest at cs.oswego.edu
> >> > Subject: Re: [concurrency-interest] Subject: Re: Interruption
> >> > afternotification
> >> >
> >> > If these two events arrive concurrently, there is no ordering between
> >> > them.
> >> > So preferring interruption over notification doesn't change the
> >> > correctness.
> >> >
> >> > Does JLS specify what the application _should_ do upon receiving
> >> > InterruptedException?
> >> >
> >> > Alex
> >> >
> >> >
> >> > On 04/09/2012 18:35, Vitaly Davidovich wrote:
> >> >
> >> > Dave,
> >> >
> >> > I can see why one may want to leave interrupt pending (thread may
> >> > complete
> >> > without checking interrupt status) but I can also see an argument in
> >> > favor
> >> > of delivering the interrupt in such a case (I.e. deliver the
> >> > "inevitable"
> >> > sooner, assuming thread will notice the interrupt soon thereafter).
> >> >
> >> > So just curious - what's the rationale for choosing notification over
> >> > interrupt here?
> >> >
> >> > Thanks
> >> >
> >> > Sent from my phone
> >> >
> >> > On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
> >> >>
> >> >> As an aside, in the current implementation in hotspot if we
> have a both
> >> >> a
> >> >> pending notification and interrupt, we return from wait()
> leaving the
> >> >> interrupt pending.
> >> >>
> >> >> Dave
> >> >> https://blogs.oracle.com/dave/
> >> >>
> >> >>
> >> >>
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>
> >> >
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From zhong.j.yu at gmail.com  Tue Sep  4 21:44:05 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 4 Sep 2012 20:44:05 -0500
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
References: <50464B9A.3020900@oracle.com>
	<NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
	<CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
Message-ID: <CACuKZqG=G_OHsXP6Rap2JRQrii1+E3VKKptAUK45hBfqCEBQ7A@mail.gmail.com>

On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
>> The JLS doesn't say anything about what applications should do. All the
>> application knows when the IE is thrown is that the thread was interrupted
>> and the interrupt state is now clear. It is up to the application to respond
>> to the interruption in an appropriate manner.
>
> I'm also unsure about the use of interruption in real world.
>
> In simple cases, the interrupt-er and the interrupt-ee can assign any
> special meaning to interruptions. But they can also instead use an
> explicit variable to transmit the meaning; interruption doesn't offer
> a lot of value here.
>
> In more complex applications, it's hard for interrupt-er to know which
> piece of code the interrupt-ee is running at the moment; it's unlikely
> that interruption can be used to deliver special meanings.
> Interruption can only have 1 meaning universally accepted by all,
> which is probably "stop everything and quit the thread"
>
> To achieve that, interruptions need to propagate up, therefore pretty
> much all method signatures will be polluted by InterruptedException.

This is incorrect. A method doesn't have to propagate
InterruptedException in this case; it can re-interrupt the current
thread, then return normally, leaving the caller to discover and
handle the interruption.

> We don't see that in practice.
>
> Or an application will simply restrain from using interruption at all,
> since it doesn't know how to handle it. Then all InterruptedExceptions
> can be ignored anywhere in the application code.
>
>
> Zhong Yu
>
>
>>
>> David
>>
>> -----Original Message-----
>> From: concurrency-interest-bounces at cs.oswego.edu
>> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
>> otenko
>> Sent: Wednesday, 5 September 2012 4:43 AM
>> To: Vitaly Davidovich
>> Cc: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> afternotification
>>
>> If these two events arrive concurrently, there is no ordering between them.
>> So preferring interruption over notification doesn't change the correctness.
>>
>> Does JLS specify what the application _should_ do upon receiving
>> InterruptedException?
>>
>> Alex
>>
>>
>> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>
>> Dave,
>>
>> I can see why one may want to leave interrupt pending (thread may complete
>> without checking interrupt status) but I can also see an argument in favor
>> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
>> sooner, assuming thread will notice the interrupt soon thereafter).
>>
>> So just curious - what's the rationale for choosing notification over
>> interrupt here?
>>
>> Thanks
>>
>> Sent from my phone
>>
>> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>
>>> As an aside, in the current implementation in hotspot if we have a both a
>>> pending notification and interrupt, we return from wait() leaving the
>>> interrupt pending.
>>>
>>> Dave
>>> https://blogs.oracle.com/dave/
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

From zhong.j.yu at gmail.com  Tue Sep  4 21:49:47 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 4 Sep 2012 20:49:47 -0500
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJNJGAA.davidcholmes@aapt.net.au>
References: <CACuKZqFU19Gs5_283yJhFoFF0HiLGPra5e_4KiLU=vj7R7eRTg@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCCEJNJGAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqGWHVsU+XvxAq3D=pSOYfPC7XsFvLRSSNatmUmt+iwWZg@mail.gmail.com>

On Tue, Sep 4, 2012 at 8:26 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> Zhong Yu writes: [mailto:zhong.j.yu at gmail.com]
>>
>> In simple cases, the interrupter knows where the interruptee might be
>> blocked, either wait(), or an IO operation. The interrupter can then
>> precisely break it by notify() or close(). Though interrupt() might be
>> a little more convenient, it's not a necessity here.
>
> I think it would be extremely rare for the thread issuing the interrupt to
> know and be able to access the objects on which a wait() or I/O operation is
> being performed. These things are normally deeply encapsulated within the
> functionality of a type not exposed via simple variables you manipulate.
> Further, as distinct from an interrupt this would potentially affect all
> threads using the same object - and in the case of notify() may not even
> target the correct object. So this "simple" case would rarely be applicable
> and interrupt is more than just "a little more convenient", it is essential
> in general.
>
>> In more complex cases, the interrupter can only blindly interrupt the
>> interruptee, for it doesn't know enough details about the interruptee
>> code. Then all code in interruptee must react to interruptions
>> identically; that means interruption cannot carry special meaning in
>> this application.
>
> I don't dispute this. It is very difficult to give interruption a special
> meaning - you have to know exactly what the target set of threads might do
> in all cases. Generally interruption must be considered as a simple
> cancellation request.

That seems to be an answer to the original question: "what the
application _should_ do upon receiving InterruptedException?"

>
> David
>
>> Zhong Yu
>>
>>
>> On Tue, Sep 4, 2012 at 7:48 PM, Vitaly Davidovich
>> <vitalyd at gmail.com> wrote:
>> > You need interruption to get out of blocking/sleeping calls
>> (promptly or at
>> > all).  You can used timed waits where available or some other
>> "workaround"
>> > but interrupting has its uses.
>> >
>> > Sent from my phone
>> >
>> > On Sep 4, 2012 8:42 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>> >>
>> >> On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>> >> wrote:
>> >> > The JLS doesn't say anything about what applications should
>> do. All the
>> >> > application knows when the IE is thrown is that the thread was
>> >> > interrupted
>> >> > and the interrupt state is now clear. It is up to the application to
>> >> > respond
>> >> > to the interruption in an appropriate manner.
>> >>
>> >> I'm also unsure about the use of interruption in real world.
>> >>
>> >> In simple cases, the interrupt-er and the interrupt-ee can assign any
>> >> special meaning to interruptions. But they can also instead use an
>> >> explicit variable to transmit the meaning; interruption doesn't offer
>> >> a lot of value here.
>> >>
>> >> In more complex applications, it's hard for interrupt-er to know which
>> >> piece of code the interrupt-ee is running at the moment; it's unlikely
>> >> that interruption can be used to deliver special meanings.
>> >> Interruption can only have 1 meaning universally accepted by all,
>> >> which is probably "stop everything and quit the thread"
>> >>
>> >> To achieve that, interruptions need to propagate up, therefore pretty
>> >> much all method signatures will be polluted by InterruptedException.
>> >> We don't see that in practice.
>> >>
>> >> Or an application will simply restrain from using interruption at all,
>> >> since it doesn't know how to handle it. Then all InterruptedExceptions
>> >> can be ignored anywhere in the application code.
>> >>
>> >>
>> >> Zhong Yu
>> >>
>> >>
>> >> >
>> >> > David
>> >> >
>> >> > -----Original Message-----
>> >> > From: concurrency-interest-bounces at cs.oswego.edu
>> >> > [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> >> > oleksandr
>> >> > otenko
>> >> > Sent: Wednesday, 5 September 2012 4:43 AM
>> >> > To: Vitaly Davidovich
>> >> > Cc: concurrency-interest at cs.oswego.edu
>> >> > Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> >> > afternotification
>> >> >
>> >> > If these two events arrive concurrently, there is no ordering between
>> >> > them.
>> >> > So preferring interruption over notification doesn't change the
>> >> > correctness.
>> >> >
>> >> > Does JLS specify what the application _should_ do upon receiving
>> >> > InterruptedException?
>> >> >
>> >> > Alex
>> >> >
>> >> >
>> >> > On 04/09/2012 18:35, Vitaly Davidovich wrote:
>> >> >
>> >> > Dave,
>> >> >
>> >> > I can see why one may want to leave interrupt pending (thread may
>> >> > complete
>> >> > without checking interrupt status) but I can also see an argument in
>> >> > favor
>> >> > of delivering the interrupt in such a case (I.e. deliver the
>> >> > "inevitable"
>> >> > sooner, assuming thread will notice the interrupt soon thereafter).
>> >> >
>> >> > So just curious - what's the rationale for choosing notification over
>> >> > interrupt here?
>> >> >
>> >> > Thanks
>> >> >
>> >> > Sent from my phone
>> >> >
>> >> > On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>> >> >>
>> >> >> As an aside, in the current implementation in hotspot if we
>> have a both
>> >> >> a
>> >> >> pending notification and interrupt, we return from wait()
>> leaving the
>> >> >> interrupt pending.
>> >> >>
>> >> >> Dave
>> >> >> https://blogs.oracle.com/dave/
>> >> >>
>> >> >>
>> >> >>
>> >> >> _______________________________________________
>> >> >> Concurrency-interest mailing list
>> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

From vitalyd at gmail.com  Tue Sep  4 22:28:36 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 22:28:36 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CACuKZqG=G_OHsXP6Rap2JRQrii1+E3VKKptAUK45hBfqCEBQ7A@mail.gmail.com>
References: <50464B9A.3020900@oracle.com>
	<NFBBKALFDCPFIDBNKAPCKEJKJGAA.davidcholmes@aapt.net.au>
	<CACuKZqEKsvOrAK4j+w2wS9vxOZT+TeYy8-1N9okT9gsCUVJQ9g@mail.gmail.com>
	<CACuKZqG=G_OHsXP6Rap2JRQrii1+E3VKKptAUK45hBfqCEBQ7A@mail.gmail.com>
Message-ID: <CAHjP37H5z9WV0QFt7Ts76mDPFzsWftjescn0V_do_GPobz18yw@mail.gmail.com>

I think typically you catch IE, do whatever cleanup and rethrow it rather
than reinterrupting the thread (unless you're at a point where handling it
makes sense).  If you simply reinterrupt, you effectively delay (or lose)
the interrupt delivery to the caller.

Sent from my phone
On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
> >> The JLS doesn't say anything about what applications should do. All the
> >> application knows when the IE is thrown is that the thread was
> interrupted
> >> and the interrupt state is now clear. It is up to the application to
> respond
> >> to the interruption in an appropriate manner.
> >
> > I'm also unsure about the use of interruption in real world.
> >
> > In simple cases, the interrupt-er and the interrupt-ee can assign any
> > special meaning to interruptions. But they can also instead use an
> > explicit variable to transmit the meaning; interruption doesn't offer
> > a lot of value here.
> >
> > In more complex applications, it's hard for interrupt-er to know which
> > piece of code the interrupt-ee is running at the moment; it's unlikely
> > that interruption can be used to deliver special meanings.
> > Interruption can only have 1 meaning universally accepted by all,
> > which is probably "stop everything and quit the thread"
> >
> > To achieve that, interruptions need to propagate up, therefore pretty
> > much all method signatures will be polluted by InterruptedException.
>
> This is incorrect. A method doesn't have to propagate
> InterruptedException in this case; it can re-interrupt the current
> thread, then return normally, leaving the caller to discover and
> handle the interruption.
>
> > We don't see that in practice.
> >
> > Or an application will simply restrain from using interruption at all,
> > since it doesn't know how to handle it. Then all InterruptedExceptions
> > can be ignored anywhere in the application code.
> >
> >
> > Zhong Yu
> >
> >
> >>
> >> David
> >>
> >> -----Original Message-----
> >> From: concurrency-interest-bounces at cs.oswego.edu
> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
> oleksandr
> >> otenko
> >> Sent: Wednesday, 5 September 2012 4:43 AM
> >> To: Vitaly Davidovich
> >> Cc: concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
> >> afternotification
> >>
> >> If these two events arrive concurrently, there is no ordering between
> them.
> >> So preferring interruption over notification doesn't change the
> correctness.
> >>
> >> Does JLS specify what the application _should_ do upon receiving
> >> InterruptedException?
> >>
> >> Alex
> >>
> >>
> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
> >>
> >> Dave,
> >>
> >> I can see why one may want to leave interrupt pending (thread may
> complete
> >> without checking interrupt status) but I can also see an argument in
> favor
> >> of delivering the interrupt in such a case (I.e. deliver the
> "inevitable"
> >> sooner, assuming thread will notice the interrupt soon thereafter).
> >>
> >> So just curious - what's the rationale for choosing notification over
> >> interrupt here?
> >>
> >> Thanks
> >>
> >> Sent from my phone
> >>
> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
> >>>
> >>> As an aside, in the current implementation in hotspot if we have a
> both a
> >>> pending notification and interrupt, we return from wait() leaving the
> >>> interrupt pending.
> >>>
> >>> Dave
> >>> https://blogs.oracle.com/dave/
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/1f1a815e/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Sep  4 22:35:39 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 12:35:39 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37H5z9WV0QFt7Ts76mDPFzsWftjescn0V_do_GPobz18yw@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEJOJGAA.davidcholmes@aapt.net.au>

Typically you either define an API that inherently reflects the potential
blocking nature of the operation and supports cancellation, or the blocking
operation is just an implementation detail. In the former case you will
declare that you throw IE and throw it; in the latter you won't declare IE
and so can't throw it but must re-interrupt the thread. (Golden rule is to
never swallow an interrupt.)

Again cancellation techniques and options are well covered in CPJ and JCiP.

David
  -----Original Message-----
  From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
  Sent: Wednesday, 5 September 2012 12:29 PM
  To: Zhong Yu
  Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


  I think typically you catch IE, do whatever cleanup and rethrow it rather
than reinterrupting the thread (unless you're at a point where handling it
makes sense).  If you simply reinterrupt, you effectively delay (or lose)
the interrupt delivery to the caller.

  Sent from my phone

  On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

    On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
    > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:
    >> The JLS doesn't say anything about what applications should do. All
the
    >> application knows when the IE is thrown is that the thread was
interrupted
    >> and the interrupt state is now clear. It is up to the application to
respond
    >> to the interruption in an appropriate manner.
    >
    > I'm also unsure about the use of interruption in real world.
    >
    > In simple cases, the interrupt-er and the interrupt-ee can assign any
    > special meaning to interruptions. But they can also instead use an
    > explicit variable to transmit the meaning; interruption doesn't offer
    > a lot of value here.
    >
    > In more complex applications, it's hard for interrupt-er to know which
    > piece of code the interrupt-ee is running at the moment; it's unlikely
    > that interruption can be used to deliver special meanings.
    > Interruption can only have 1 meaning universally accepted by all,
    > which is probably "stop everything and quit the thread"
    >
    > To achieve that, interruptions need to propagate up, therefore pretty
    > much all method signatures will be polluted by InterruptedException.

    This is incorrect. A method doesn't have to propagate
    InterruptedException in this case; it can re-interrupt the current
    thread, then return normally, leaving the caller to discover and
    handle the interruption.

    > We don't see that in practice.
    >
    > Or an application will simply restrain from using interruption at all,
    > since it doesn't know how to handle it. Then all InterruptedExceptions
    > can be ignored anywhere in the application code.
    >
    >
    > Zhong Yu
    >
    >
    >>
    >> David
    >>
    >> -----Original Message-----
    >> From: concurrency-interest-bounces at cs.oswego.edu
    >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
oleksandr
    >> otenko
    >> Sent: Wednesday, 5 September 2012 4:43 AM
    >> To: Vitaly Davidovich
    >> Cc: concurrency-interest at cs.oswego.edu
    >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
    >> afternotification
    >>
    >> If these two events arrive concurrently, there is no ordering between
them.
    >> So preferring interruption over notification doesn't change the
correctness.
    >>
    >> Does JLS specify what the application _should_ do upon receiving
    >> InterruptedException?
    >>
    >> Alex
    >>
    >>
    >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
    >>
    >> Dave,
    >>
    >> I can see why one may want to leave interrupt pending (thread may
complete
    >> without checking interrupt status) but I can also see an argument in
favor
    >> of delivering the interrupt in such a case (I.e. deliver the
"inevitable"
    >> sooner, assuming thread will notice the interrupt soon thereafter).
    >>
    >> So just curious - what's the rationale for choosing notification over
    >> interrupt here?
    >>
    >> Thanks
    >>
    >> Sent from my phone
    >>
    >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
    >>>
    >>> As an aside, in the current implementation in hotspot if we have a
both a
    >>> pending notification and interrupt, we return from wait() leaving
the
    >>> interrupt pending.
    >>>
    >>> Dave
    >>> https://blogs.oracle.com/dave/
    >>>
    >>>
    >>>
    >>> _______________________________________________
    >>> Concurrency-interest mailing list
    >>> Concurrency-interest at cs.oswego.edu
    >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    >>>
    >>
    >>
    >> _______________________________________________
    >> Concurrency-interest mailing list
    >> Concurrency-interest at cs.oswego.edu
    >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    >>
    >>
    >> _______________________________________________
    >> Concurrency-interest mailing list
    >> Concurrency-interest at cs.oswego.edu
    >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
    >>
    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/5f013d33/attachment.html>

From vitalyd at gmail.com  Tue Sep  4 22:59:34 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 4 Sep 2012 22:59:34 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJOJGAA.davidcholmes@aapt.net.au>
References: <CAHjP37H5z9WV0QFt7Ts76mDPFzsWftjescn0V_do_GPobz18yw@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCAEJOJGAA.davidcholmes@aapt.net.au>
Message-ID: <CAHjP37HtAEDGLziGdiU-PWxpTQEi7AaPgCuE5Cw5ZYNRr=Faaw@mail.gmail.com>

That's true, but I seem to rarely come across the latter (blocking op as
impl detail that re-interrupts) and hence mentioned the far more common
former case.  Maybe that's just me though ...

Cheers

Sent from my phone
On Sep 4, 2012 10:35 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> **
> Typically you either define an API that inherently reflects the potential
> blocking nature of the operation and supports cancellation, or the blocking
> operation is just an implementation detail. In the former case you will
> declare that you throw IE and throw it; in the latter you won't declare IE
> and so can't throw it but must re-interrupt the thread. (Golden rule is to
> never swallow an interrupt.)
>
> Again cancellation techniques and options are well covered in CPJ and JCiP.
>
> David
>
> -----Original Message-----
> *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com]
> *Sent:* Wednesday, 5 September 2012 12:29 PM
> *To:* Zhong Yu
> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
> I think typically you catch IE, do whatever cleanup and rethrow it rather
> than reinterrupting the thread (unless you're at a point where handling it
> makes sense).  If you simply reinterrupt, you effectively delay (or lose)
> the interrupt delivery to the caller.
>
> Sent from my phone
> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>
>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>> >> The JLS doesn't say anything about what applications should do. All the
>> >> application knows when the IE is thrown is that the thread was
>> interrupted
>> >> and the interrupt state is now clear. It is up to the application to
>> respond
>> >> to the interruption in an appropriate manner.
>> >
>> > I'm also unsure about the use of interruption in real world.
>> >
>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>> > special meaning to interruptions. But they can also instead use an
>> > explicit variable to transmit the meaning; interruption doesn't offer
>> > a lot of value here.
>> >
>> > In more complex applications, it's hard for interrupt-er to know which
>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>> > that interruption can be used to deliver special meanings.
>> > Interruption can only have 1 meaning universally accepted by all,
>> > which is probably "stop everything and quit the thread"
>> >
>> > To achieve that, interruptions need to propagate up, therefore pretty
>> > much all method signatures will be polluted by InterruptedException.
>>
>> This is incorrect. A method doesn't have to propagate
>> InterruptedException in this case; it can re-interrupt the current
>> thread, then return normally, leaving the caller to discover and
>> handle the interruption.
>>
>> > We don't see that in practice.
>> >
>> > Or an application will simply restrain from using interruption at all,
>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>> > can be ignored anywhere in the application code.
>> >
>> >
>> > Zhong Yu
>> >
>> >
>> >>
>> >> David
>> >>
>> >> -----Original Message-----
>> >> From: concurrency-interest-bounces at cs.oswego.edu
>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> oleksandr
>> >> otenko
>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>> >> To: Vitaly Davidovich
>> >> Cc: concurrency-interest at cs.oswego.edu
>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> >> afternotification
>> >>
>> >> If these two events arrive concurrently, there is no ordering between
>> them.
>> >> So preferring interruption over notification doesn't change the
>> correctness.
>> >>
>> >> Does JLS specify what the application _should_ do upon receiving
>> >> InterruptedException?
>> >>
>> >> Alex
>> >>
>> >>
>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>> >>
>> >> Dave,
>> >>
>> >> I can see why one may want to leave interrupt pending (thread may
>> complete
>> >> without checking interrupt status) but I can also see an argument in
>> favor
>> >> of delivering the interrupt in such a case (I.e. deliver the
>> "inevitable"
>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>> >>
>> >> So just curious - what's the rationale for choosing notification over
>> >> interrupt here?
>> >>
>> >> Thanks
>> >>
>> >> Sent from my phone
>> >>
>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>> >>>
>> >>> As an aside, in the current implementation in hotspot if we have a
>> both a
>> >>> pending notification and interrupt, we return from wait() leaving the
>> >>> interrupt pending.
>> >>>
>> >>> Dave
>> >>> https://blogs.oracle.com/dave/
>> >>>
>> >>>
>> >>>
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>>
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120904/12844b07/attachment-0001.html>

From kirk at kodewerk.com  Tue Sep  4 23:28:17 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 5 Sep 2012 05:28:17 +0200
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEJNJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEJNJGAA.davidcholmes@aapt.net.au>
Message-ID: <FE61BFF8-20C6-4578-B9BA-28F41A46A05A@kodewerk.com>

> 
> 
>> In more complex cases, the interrupter can only blindly interrupt the
>> interruptee, for it doesn't know enough details about the interruptee
>> code. Then all code in interruptee must react to interruptions
>> identically; that means interruption cannot carry special meaning in
>> this application.
> 
> I don't dispute this. It is very difficult to give interruption a special
> meaning - you have to know exactly what the target set of threads might do
> in all cases. Generally interruption must be considered as a simple
> cancellation request.

What makes IE so confusing is that it comes at you orthogonally and without context. How is one suppose to react? Is it really a simple cancellation request? Or can one simply ignore it. I don't believe there is an all purpose answer to the question. Consider Thread.sleep(). What happens if that call is interrupted? Should I eat the exception? shutdown the thread? Can't really say as I need more context, the context of application semantics, to help me decide.

It's not a very satisfying answer but then not all answers can be satisfying.

-- Kirk



From kirk at kodewerk.com  Tue Sep  4 23:37:35 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 5 Sep 2012 05:37:35 +0200
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEJOJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEJOJGAA.davidcholmes@aapt.net.au>
Message-ID: <5D2C78FF-6684-43A8-8E83-8A1D4F503071@kodewerk.com>


On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:

> Typically you either define an API that inherently reflects the potential blocking nature of the operation and supports cancellation, or the blocking operation is just an implementation detail. In the former case you will declare that you throw IE and throw it; in the latter you won't declare IE and so can't throw it but must re-interrupt the thread. (Golden rule is to never swallow an interrupt.)

Sorry but the golden rule is, he who has the gold makes the rules. ;-) The IE is the *only* exception that I eat on a fairly regular basis. Why? Because there is nothing to be done and no point to propagate (which is different than I don't know how to react so I should re-throw). Cancelation scenarios are about the only times I'll not eat an IE.

Kirk

>  
> Again cancellation techniques and options are well covered in CPJ and JCiP.
>  
> David
> -----Original Message-----
> From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
> Sent: Wednesday, 5 September 2012 12:29 PM
> To: Zhong Yu
> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
> 
> I think typically you catch IE, do whatever cleanup and rethrow it rather than reinterrupting the thread (unless you're at a point where handling it makes sense).  If you simply reinterrupt, you effectively delay (or lose) the interrupt delivery to the caller.
> 
> Sent from my phone
> 
> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
> >> The JLS doesn't say anything about what applications should do. All the
> >> application knows when the IE is thrown is that the thread was interrupted
> >> and the interrupt state is now clear. It is up to the application to respond
> >> to the interruption in an appropriate manner.
> >
> > I'm also unsure about the use of interruption in real world.
> >
> > In simple cases, the interrupt-er and the interrupt-ee can assign any
> > special meaning to interruptions. But they can also instead use an
> > explicit variable to transmit the meaning; interruption doesn't offer
> > a lot of value here.
> >
> > In more complex applications, it's hard for interrupt-er to know which
> > piece of code the interrupt-ee is running at the moment; it's unlikely
> > that interruption can be used to deliver special meanings.
> > Interruption can only have 1 meaning universally accepted by all,
> > which is probably "stop everything and quit the thread"
> >
> > To achieve that, interruptions need to propagate up, therefore pretty
> > much all method signatures will be polluted by InterruptedException.
> 
> This is incorrect. A method doesn't have to propagate
> InterruptedException in this case; it can re-interrupt the current
> thread, then return normally, leaving the caller to discover and
> handle the interruption.
> 
> > We don't see that in practice.
> >
> > Or an application will simply restrain from using interruption at all,
> > since it doesn't know how to handle it. Then all InterruptedExceptions
> > can be ignored anywhere in the application code.
> >
> >
> > Zhong Yu
> >
> >
> >>
> >> David
> >>
> >> -----Original Message-----
> >> From: concurrency-interest-bounces at cs.oswego.edu
> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
> >> otenko
> >> Sent: Wednesday, 5 September 2012 4:43 AM
> >> To: Vitaly Davidovich
> >> Cc: concurrency-interest at cs.oswego.edu
> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
> >> afternotification
> >>
> >> If these two events arrive concurrently, there is no ordering between them.
> >> So preferring interruption over notification doesn't change the correctness.
> >>
> >> Does JLS specify what the application _should_ do upon receiving
> >> InterruptedException?
> >>
> >> Alex
> >>
> >>
> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
> >>
> >> Dave,
> >>
> >> I can see why one may want to leave interrupt pending (thread may complete
> >> without checking interrupt status) but I can also see an argument in favor
> >> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
> >> sooner, assuming thread will notice the interrupt soon thereafter).
> >>
> >> So just curious - what's the rationale for choosing notification over
> >> interrupt here?
> >>
> >> Thanks
> >>
> >> Sent from my phone
> >>
> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
> >>>
> >>> As an aside, in the current implementation in hotspot if we have a both a
> >>> pending notification and interrupt, we return from wait() leaving the
> >>> interrupt pending.
> >>>
> >>> Dave
> >>> https://blogs.oracle.com/dave/
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/8a8ffff1/attachment.html>

From davidcholmes at aapt.net.au  Tue Sep  4 23:38:00 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 13:38:00 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <FE61BFF8-20C6-4578-B9BA-28F41A46A05A@kodewerk.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEJPJGAA.davidcholmes@aapt.net.au>

Kirk Pepperdine:
> >
> >> In more complex cases, the interrupter can only blindly interrupt the
> >> interruptee, for it doesn't know enough details about the interruptee
> >> code. Then all code in interruptee must react to interruptions
> >> identically; that means interruption cannot carry special meaning in
> >> this application.
> >
> > I don't dispute this. It is very difficult to give interruption
> > a special meaning - you have to know exactly what the target set of
> > threads might do in all cases. Generally interruption must be
> > considered as a simple cancellation request.
>
> What makes IE so confusing is that it comes at you orthogonally
> and without context. How is one suppose to react? Is it really a
> simple cancellation request? Or can one simply ignore it. I don't
> believe there is an all purpose answer to the question. Consider
> Thread.sleep(). What happens if that call is interrupted? Should
> I eat the exception? shutdown the thread? Can't really say as I
> need more context, the context of application semantics, to help
> me decide.

It is your code that is calling Thread.sleep and so your code has to
determine whether it is responsive to cancellation requests. The context
comes from you - the author of the code.

As I said before the code you are writing for a specific type defines
certain semantics. If those semantics expose the blocking nature of an
operation then you can expose cancellation support directly by declaring and
throwing the IE. Otherwise you simply re-interrupt the current thread after
deciding whether to ignore the interrupt or return early because of it -
that is up to you. The main thing is to either propagate IE or re-interrupt
because even if your code doesn't care about cancellation, some code higher
up the call stack might.

David
-----

> It's not a very satisfying answer but then not all answers can be
> satisfying.
>
> -- Kirk
>
>


From davidcholmes at aapt.net.au  Tue Sep  4 23:43:40 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 13:43:40 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <5D2C78FF-6684-43A8-8E83-8A1D4F503071@kodewerk.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEJPJGAA.davidcholmes@aapt.net.au>

In your applications you can do what you like. If you are a library writer
(which in simplest terms means you write a class for others to use) then you
need to follow the rule else you will break any application that uses your
library and which does care about cancellation.

David
  -----Original Message-----
  From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
  Sent: Wednesday, 5 September 2012 1:38 PM
  To: dholmes at ieee.org
  Cc: Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification




  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:


    Typically you either define an API that inherently reflects the
potential blocking nature of the operation and supports cancellation, or the
blocking operation is just an implementation detail. In the former case you
will declare that you throw IE and throw it; in the latter you won't declare
IE and so can't throw it but must re-interrupt the thread. (Golden rule is
to never swallow an interrupt.)


  Sorry but the golden rule is, he who has the gold makes the rules. ;-) The
IE is the *only* exception that I eat on a fairly regular basis. Why?
Because there is nothing to be done and no point to propagate (which is
different than I don't know how to react so I should re-throw). Cancelation
scenarios are about the only times I'll not eat an IE.


  Kirk



    Again cancellation techniques and options are well covered in CPJ and
JCiP.

    David
      -----Original Message-----
      From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
      Sent: Wednesday, 5 September 2012 12:29 PM
      To: Zhong Yu
      Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


      I think typically you catch IE, do whatever cleanup and rethrow it
rather than reinterrupting the thread (unless you're at a point where
handling it makes sense).  If you simply reinterrupt, you effectively delay
(or lose) the interrupt delivery to the caller.

      Sent from my phone

      On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

        On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com>
wrote:
        > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:
        >> The JLS doesn't say anything about what applications should do.
All the
        >> application knows when the IE is thrown is that the thread was
interrupted
        >> and the interrupt state is now clear. It is up to the application
to respond
        >> to the interruption in an appropriate manner.
        >
        > I'm also unsure about the use of interruption in real world.
        >
        > In simple cases, the interrupt-er and the interrupt-ee can assign
any
        > special meaning to interruptions. But they can also instead use an
        > explicit variable to transmit the meaning; interruption doesn't
offer
        > a lot of value here.
        >
        > In more complex applications, it's hard for interrupt-er to know
which
        > piece of code the interrupt-ee is running at the moment; it's
unlikely
        > that interruption can be used to deliver special meanings.
        > Interruption can only have 1 meaning universally accepted by all,
        > which is probably "stop everything and quit the thread"
        >
        > To achieve that, interruptions need to propagate up, therefore
pretty
        > much all method signatures will be polluted by
InterruptedException.

        This is incorrect. A method doesn't have to propagate
        InterruptedException in this case; it can re-interrupt the current
        thread, then return normally, leaving the caller to discover and
        handle the interruption.

        > We don't see that in practice.
        >
        > Or an application will simply restrain from using interruption at
all,
        > since it doesn't know how to handle it. Then all
InterruptedExceptions
        > can be ignored anywhere in the application code.
        >
        >
        > Zhong Yu
        >
        >
        >>
        >> David
        >>
        >> -----Original Message-----
        >> From: concurrency-interest-bounces at cs.oswego.edu
        >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
oleksandr
        >> otenko
        >> Sent: Wednesday, 5 September 2012 4:43 AM
        >> To: Vitaly Davidovich
        >> Cc: concurrency-interest at cs.oswego.edu
        >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
        >> afternotification
        >>
        >> If these two events arrive concurrently, there is no ordering
between them.
        >> So preferring interruption over notification doesn't change the
correctness.
        >>
        >> Does JLS specify what the application _should_ do upon receiving
        >> InterruptedException?
        >>
        >> Alex
        >>
        >>
        >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
        >>
        >> Dave,
        >>
        >> I can see why one may want to leave interrupt pending (thread may
complete
        >> without checking interrupt status) but I can also see an argument
in favor
        >> of delivering the interrupt in such a case (I.e. deliver the
"inevitable"
        >> sooner, assuming thread will notice the interrupt soon
thereafter).
        >>
        >> So just curious - what's the rationale for choosing notification
over
        >> interrupt here?
        >>
        >> Thanks
        >>
        >> Sent from my phone
        >>
        >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com>
wrote:
        >>>
        >>> As an aside, in the current implementation in hotspot if we have
a both a
        >>> pending notification and interrupt, we return from wait()
leaving the
        >>> interrupt pending.
        >>>
        >>> Dave
        >>> https://blogs.oracle.com/dave/
        >>>
        >>>
        >>>
        >>> _______________________________________________
        >>> Concurrency-interest mailing list
        >>> Concurrency-interest at cs.oswego.edu
        >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
        >>>
        >>
        >>
        >> _______________________________________________
        >> Concurrency-interest mailing list
        >> Concurrency-interest at cs.oswego.edu
        >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
        >>
        >>
        >> _______________________________________________
        >> Concurrency-interest mailing list
        >> Concurrency-interest at cs.oswego.edu
        >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
        >>
        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest at cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest

    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/0ef95625/attachment-0001.html>

From kirk at kodewerk.com  Tue Sep  4 23:47:16 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 5 Sep 2012 05:47:16 +0200
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEJPJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEJPJGAA.davidcholmes@aapt.net.au>
Message-ID: <F42D3B6D-82A9-405E-AC14-DFE1457195D5@kodewerk.com>

>>> 
>> 
>> What makes IE so confusing is that it comes at you orthogonally
>> and without context. How is one suppose to react? Is it really a
>> simple cancellation request? Or can one simply ignore it. I don't
>> believe there is an all purpose answer to the question. Consider
>> Thread.sleep(). What happens if that call is interrupted? Should
>> I eat the exception? shutdown the thread? Can't really say as I
>> need more context, the context of application semantics, to help
>> me decide.
> 
> It is your code that is calling Thread.sleep and so your code has to
> determine whether it is responsive to cancellation requests. The context
> comes from you - the author of the code.

yes indeed, that was my point. And my POV is that of a consumer of libraries, not a producer of them meaning that libraries should propagate. As a consumer of a library I would hate to have a cancelation IE that I created eaten by a library that I'm using.


> 
> As I said before the code you are writing for a specific type defines
> certain semantics. If those semantics expose the blocking nature of an
> operation then you can expose cancellation support directly by declaring and
> throwing the IE. Otherwise you simply re-interrupt the current thread after
> deciding whether to ignore the interrupt or return early because of it -
> that is up to you. The main thing is to either propagate IE or re-interrupt
> because even if your code doesn't care about cancellation, some code higher
> up the call stack might.
> 
> David
> -----
> 
>> It's not a very satisfying answer but then not all answers can be
>> satisfying.
>> 
>> -- Kirk
>> 
>> 
> 



From oleksandr.otenko at oracle.com  Wed Sep  5 06:03:18 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 11:03:18 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEJPJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMEJPJGAA.davidcholmes@aapt.net.au>
Message-ID: <50472366.5060109@oracle.com>

But how can one tell who was meant to be cancelled?

Since there is no requirement on the semantics of what a cancel 
operation might be, I can define my cancel operation as "stop waiting, 
think again, then maybe enter the same wait". So the effect is I 
consumed the IE and didn't even re-trigger it.

I guess we can't define strictly what a good way of dealing with IE is, 
since it is like a "last resort" to unblock a wait, which can offer "the 
best effort" semantics.

Alex

On 05/09/2012 04:43, David Holmes wrote:
> In your applications you can do what you like. If you are a library 
> writer (which in simplest terms means you write a class for others to 
> use) then you need to follow the rule else you will break any 
> application that uses your library and which does care about cancellation.
> David
>
>     -----Original Message-----
>     *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com]
>     *Sent:* Wednesday, 5 September 2012 1:38 PM
>     *To:* dholmes at ieee.org
>     *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>     afternotification
>
>
>     On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au
>     <mailto:davidcholmes at aapt.net.au>> wrote:
>
>>     Typically you either define an API that inherently reflects the
>>     potential blocking nature of the operation and supports
>>     cancellation, or the blocking operation is just an implementation
>>     detail. In the former case you will declare that you throw IE and
>>     throw it; in the latter you won't declare IE and so can't throw
>>     it but must re-interrupt the thread. (Golden rule is to never
>>     swallow an interrupt.)
>
>     Sorry but the golden rule is, he who has the gold makes the rules.
>     ;-) The IE is the *only* exception that I eat on a fairly regular
>     basis. Why? Because there is nothing to be done and no point to
>     propagate (which is different than I don't know how to react so I
>     should re-throw). Cancelation scenarios are about the only times
>     I'll not eat an IE.
>
>     Kirk
>
>>     Again cancellation techniques and options are well covered in CPJ
>>     and JCiP.
>>     David
>>
>>         -----Original Message-----
>>         *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com
>>         <http://gmail.com>]
>>         *Sent:* Wednesday, 5 September 2012 12:29 PM
>>         *To:* Zhong Yu
>>         *Cc:* dholmes at ieee.org <mailto:dholmes at ieee.org>;
>>         concurrency-interest at cs.oswego.edu
>>         <mailto:concurrency-interest at cs.oswego.edu>
>>         *Subject:* Re: [concurrency-interest] Subject: Re:
>>         Interruption afternotification
>>
>>         I think typically you catch IE, do whatever cleanup and
>>         rethrow it rather than reinterrupting the thread (unless
>>         you're at a point where handling it makes sense).  If you
>>         simply reinterrupt, you effectively delay (or lose) the
>>         interrupt delivery to the caller.
>>
>>         Sent from my phone
>>
>>         On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com
>>         <mailto:zhong.j.yu at gmail.com>> wrote:
>>
>>             On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
>>             <zhong.j.yu at gmail.com <mailto:zhong.j.yu at gmail.com>> wrote:
>>             > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
>>             <davidcholmes at aapt.net.au
>>             <mailto:davidcholmes at aapt.net.au>> wrote:
>>             >> The JLS doesn't say anything about what applications
>>             should do. All the
>>             >> application knows when the IE is thrown is that the
>>             thread was interrupted
>>             >> and the interrupt state is now clear. It is up to the
>>             application to respond
>>             >> to the interruption in an appropriate manner.
>>             >
>>             > I'm also unsure about the use of interruption in real
>>             world.
>>             >
>>             > In simple cases, the interrupt-er and the interrupt-ee
>>             can assign any
>>             > special meaning to interruptions. But they can also
>>             instead use an
>>             > explicit variable to transmit the meaning; interruption
>>             doesn't offer
>>             > a lot of value here.
>>             >
>>             > In more complex applications, it's hard for
>>             interrupt-er to know which
>>             > piece of code the interrupt-ee is running at the
>>             moment; it's unlikely
>>             > that interruption can be used to deliver special meanings.
>>             > Interruption can only have 1 meaning universally
>>             accepted by all,
>>             > which is probably "stop everything and quit the thread"
>>             >
>>             > To achieve that, interruptions need to propagate up,
>>             therefore pretty
>>             > much all method signatures will be polluted by
>>             InterruptedException.
>>
>>             This is incorrect. A method doesn't have to propagate
>>             InterruptedException in this case; it can re-interrupt
>>             the current
>>             thread, then return normally, leaving the caller to
>>             discover and
>>             handle the interruption.
>>
>>             > We don't see that in practice.
>>             >
>>             > Or an application will simply restrain from using
>>             interruption at all,
>>             > since it doesn't know how to handle it. Then all
>>             InterruptedExceptions
>>             > can be ignored anywhere in the application code.
>>             >
>>             >
>>             > Zhong Yu
>>             >
>>             >
>>             >>
>>             >> David
>>             >>
>>             >> -----Original Message-----
>>             >> From: concurrency-interest-bounces at cs.oswego.edu
>>             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>             >> [mailto:concurrency-interest-bounces at cs.oswego.edu
>>             <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>             Behalf Of oleksandr
>>             >> otenko
>>             >> Sent: Wednesday, 5 September 2012 4:43 AM
>>             >> To: Vitaly Davidovich
>>             >> Cc: concurrency-interest at cs.oswego.edu
>>             <mailto:concurrency-interest at cs.oswego.edu>
>>             >> Subject: Re: [concurrency-interest] Subject: Re:
>>             Interruption
>>             >> afternotification
>>             >>
>>             >> If these two events arrive concurrently, there is no
>>             ordering between them.
>>             >> So preferring interruption over notification doesn't
>>             change the correctness.
>>             >>
>>             >> Does JLS specify what the application _should_ do upon
>>             receiving
>>             >> InterruptedException?
>>             >>
>>             >> Alex
>>             >>
>>             >>
>>             >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>             >>
>>             >> Dave,
>>             >>
>>             >> I can see why one may want to leave interrupt pending
>>             (thread may complete
>>             >> without checking interrupt status) but I can also see
>>             an argument in favor
>>             >> of delivering the interrupt in such a case (I.e.
>>             deliver the "inevitable"
>>             >> sooner, assuming thread will notice the interrupt soon
>>             thereafter).
>>             >>
>>             >> So just curious - what's the rationale for choosing
>>             notification over
>>             >> interrupt here?
>>             >>
>>             >> Thanks
>>             >>
>>             >> Sent from my phone
>>             >>
>>             >> On Sep 4, 2012 1:10 PM, "David Dice"
>>             <david.dice at gmail.com <mailto:david.dice at gmail.com>> wrote:
>>             >>>
>>             >>> As an aside, in the current implementation in hotspot
>>             if we have a both a
>>             >>> pending notification and interrupt, we return from
>>             wait() leaving the
>>             >>> interrupt pending.
>>             >>>
>>             >>> Dave
>>             >>> https://blogs.oracle.com/dave/
>>             >>>
>>             >>>
>>             >>>
>>             >>> _______________________________________________
>>             >>> Concurrency-interest mailing list
>>             >>> Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             >>>
>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>             >>>
>>             >>
>>             >>
>>             >> _______________________________________________
>>             >> Concurrency-interest mailing list
>>             >> Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>             >>
>>             >>
>>             >> _______________________________________________
>>             >> Concurrency-interest mailing list
>>             >> Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>             >>
>>             _______________________________________________
>>             Concurrency-interest mailing list
>>             Concurrency-interest at cs.oswego.edu
>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/cad07716/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Sep  5 06:12:18 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 5 Sep 2012 20:12:18 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50472366.5060109@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>

That is why interrupt generally can't be given a special meaning. You have
to interpret it as a general cancellation request unless you have full
knowledge of the execution stack. If your "cancellation" response is to
ignore the request then you've made your code incompatible with all other
code in the execution stack that wants to be actually cancelled. Hence the
basic responses to IE are to either propagate it, or consume it and
re-assert the interrupt state. It is a cooperative cancellation protocol.

David

 -----Original Message-----
From: oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
Sent: Wednesday, 5 September 2012 8:03 PM
To: dholmes at ieee.org
Cc: David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


  But how can one tell who was meant to be cancelled?

  Since there is no requirement on the semantics of what a cancel operation
might be, I can define my cancel operation as "stop waiting, think again,
then maybe enter the same wait". So the effect is I consumed the IE and
didn't even re-trigger it.

  I guess we can't define strictly what a good way of dealing with IE is,
since it is like a "last resort" to unblock a wait, which can offer "the
best effort" semantics.

  Alex

  On 05/09/2012 04:43, David Holmes wrote:
    In your applications you can do what you like. If you are a library
writer (which in simplest terms means you write a class for others to use)
then you need to follow the rule else you will break any application that
uses your library and which does care about cancellation.

    David
      -----Original Message-----
      From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
      Sent: Wednesday, 5 September 2012 1:38 PM
      To: dholmes at ieee.org
      Cc: Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification




      On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:


        Typically you either define an API that inherently reflects the
potential blocking nature of the operation and supports cancellation, or the
blocking operation is just an implementation detail. In the former case you
will declare that you throw IE and throw it; in the latter you won't declare
IE and so can't throw it but must re-interrupt the thread. (Golden rule is
to never swallow an interrupt.)


      Sorry but the golden rule is, he who has the gold makes the rules. ;-)
The IE is the *only* exception that I eat on a fairly regular basis. Why?
Because there is nothing to be done and no point to propagate (which is
different than I don't know how to react so I should re-throw). Cancelation
scenarios are about the only times I'll not eat an IE.


      Kirk



        Again cancellation techniques and options are well covered in CPJ
and JCiP.

        David
          -----Original Message-----
          From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
          Sent: Wednesday, 5 September 2012 12:29 PM
          To: Zhong Yu
          Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
          Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


          I think typically you catch IE, do whatever cleanup and rethrow it
rather than reinterrupting the thread (unless you're at a point where
handling it makes sense).  If you simply reinterrupt, you effectively delay
(or lose) the interrupt delivery to the caller.

          Sent from my phone

          On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:

            On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com>
wrote:
            > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
<davidcholmes at aapt.net.au> wrote:
            >> The JLS doesn't say anything about what applications should
do. All the
            >> application knows when the IE is thrown is that the thread
was interrupted
            >> and the interrupt state is now clear. It is up to the
application to respond
            >> to the interruption in an appropriate manner.
            >
            > I'm also unsure about the use of interruption in real world.
            >
            > In simple cases, the interrupt-er and the interrupt-ee can
assign any
            > special meaning to interruptions. But they can also instead
use an
            > explicit variable to transmit the meaning; interruption
doesn't offer
            > a lot of value here.
            >
            > In more complex applications, it's hard for interrupt-er to
know which
            > piece of code the interrupt-ee is running at the moment; it's
unlikely
            > that interruption can be used to deliver special meanings.
            > Interruption can only have 1 meaning universally accepted by
all,
            > which is probably "stop everything and quit the thread"
            >
            > To achieve that, interruptions need to propagate up, therefore
pretty
            > much all method signatures will be polluted by
InterruptedException.

            This is incorrect. A method doesn't have to propagate
            InterruptedException in this case; it can re-interrupt the
current
            thread, then return normally, leaving the caller to discover and
            handle the interruption.

            > We don't see that in practice.
            >
            > Or an application will simply restrain from using interruption
at all,
            > since it doesn't know how to handle it. Then all
InterruptedExceptions
            > can be ignored anywhere in the application code.
            >
            >
            > Zhong Yu
            >
            >
            >>
            >> David
            >>
            >> -----Original Message-----
            >> From: concurrency-interest-bounces at cs.oswego.edu
            >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf
Of oleksandr
            >> otenko
            >> Sent: Wednesday, 5 September 2012 4:43 AM
            >> To: Vitaly Davidovich
            >> Cc: concurrency-interest at cs.oswego.edu
            >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
            >> afternotification
            >>
            >> If these two events arrive concurrently, there is no ordering
between them.
            >> So preferring interruption over notification doesn't change
the correctness.
            >>
            >> Does JLS specify what the application _should_ do upon
receiving
            >> InterruptedException?
            >>
            >> Alex
            >>
            >>
            >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
            >>
            >> Dave,
            >>
            >> I can see why one may want to leave interrupt pending (thread
may complete
            >> without checking interrupt status) but I can also see an
argument in favor
            >> of delivering the interrupt in such a case (I.e. deliver the
"inevitable"
            >> sooner, assuming thread will notice the interrupt soon
thereafter).
            >>
            >> So just curious - what's the rationale for choosing
notification over
            >> interrupt here?
            >>
            >> Thanks
            >>
            >> Sent from my phone
            >>
            >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com>
wrote:
            >>>
            >>> As an aside, in the current implementation in hotspot if we
have a both a
            >>> pending notification and interrupt, we return from wait()
leaving the
            >>> interrupt pending.
            >>>
            >>> Dave
            >>> https://blogs.oracle.com/dave/
            >>>
            >>>
            >>>
            >>> _______________________________________________
            >>> Concurrency-interest mailing list
            >>> Concurrency-interest at cs.oswego.edu
            >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
            >>>
            >>
            >>
            >> _______________________________________________
            >> Concurrency-interest mailing list
            >> Concurrency-interest at cs.oswego.edu
            >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
            >>
            >>
            >> _______________________________________________
            >> Concurrency-interest mailing list
            >> Concurrency-interest at cs.oswego.edu
            >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
            >>
            _______________________________________________
            Concurrency-interest mailing list
            Concurrency-interest at cs.oswego.edu
            http://cs.oswego.edu/mailman/listinfo/concurrency-interest

        _______________________________________________
        Concurrency-interest mailing list
        Concurrency-interest at cs.oswego.edu
        http://cs.oswego.edu/mailman/listinfo/concurrency-interest






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/32f01da4/attachment.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 06:25:22 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 11:25:22 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
Message-ID: <50472892.7060608@oracle.com>

I guess the problem is similar to rolling back in presence of nested 
transactions. Suppose, A does B, then C. If you interrupt during B, do 
you mean to "rollback" just B, or A in its entirety? What you are saying 
looks more like "A in its entirety".

Alex


On 05/09/2012 11:12, David Holmes wrote:
> That is why interrupt generally can't be given a special meaning. You 
> have to interpret it as a general cancellation request unless you have 
> full knowledge of the execution stack. If your "cancellation" response 
> is to ignore the request then you've made your code incompatible with 
> all other code in the execution stack that wants to be actually 
> cancelled. Hence the basic responses to IE are to either propagate it, 
> or consume it and re-assert the interrupt state. It is a cooperative 
> cancellation protocol.
> David
> -----Original Message-----
> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
> *Sent:* Wednesday, 5 September 2012 8:03 PM
> *To:* dholmes at ieee.org
> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption 
> afternotification
>
>     But how can one tell who was meant to be cancelled?
>
>     Since there is no requirement on the semantics of what a cancel
>     operation might be, I can define my cancel operation as "stop
>     waiting, think again, then maybe enter the same wait". So the
>     effect is I consumed the IE and didn't even re-trigger it.
>
>     I guess we can't define strictly what a good way of dealing with
>     IE is, since it is like a "last resort" to unblock a wait, which
>     can offer "the best effort" semantics.
>
>     Alex
>
>     On 05/09/2012 04:43, David Holmes wrote:
>>     In your applications you can do what you like. If you are a
>>     library writer (which in simplest terms means you write a class
>>     for others to use) then you need to follow the rule else you will
>>     break any application that uses your library and which does care
>>     about cancellation.
>>     David
>>
>>         -----Original Message-----
>>         *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>         *Sent:* Wednesday, 5 September 2012 1:38 PM
>>         *To:* dholmes at ieee.org
>>         *Cc:* Vitaly Davidovich; Zhong Yu;
>>         concurrency-interest at cs.oswego.edu
>>         *Subject:* Re: [concurrency-interest] Subject: Re:
>>         Interruption afternotification
>>
>>
>>         On 2012-09-05, at 4:35 AM, David Holmes
>>         <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>>         wrote:
>>
>>>         Typically you either define an API that inherently reflects
>>>         the potential blocking nature of the operation and supports
>>>         cancellation, or the blocking operation is just an
>>>         implementation detail. In the former case you will declare
>>>         that you throw IE and throw it; in the latter you won't
>>>         declare IE and so can't throw it but must re-interrupt the
>>>         thread. (Golden rule is to never swallow an interrupt.)
>>
>>         Sorry but the golden rule is, he who has the gold makes the
>>         rules. ;-) The IE is the *only* exception that I eat on a
>>         fairly regular basis. Why? Because there is nothing to be
>>         done and no point to propagate (which is different than I
>>         don't know how to react so I should re-throw). Cancelation
>>         scenarios are about the only times I'll not eat an IE.
>>
>>         Kirk
>>
>>>         Again cancellation techniques and options are well covered
>>>         in CPJ and JCiP.
>>>         David
>>>
>>>             -----Original Message-----
>>>             *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com
>>>             <http://gmail.com>]
>>>             *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>             *To:* Zhong Yu
>>>             *Cc:* dholmes at ieee.org <mailto:dholmes at ieee.org>;
>>>             concurrency-interest at cs.oswego.edu
>>>             <mailto:concurrency-interest at cs.oswego.edu>
>>>             *Subject:* Re: [concurrency-interest] Subject: Re:
>>>             Interruption afternotification
>>>
>>>             I think typically you catch IE, do whatever cleanup and
>>>             rethrow it rather than reinterrupting the thread (unless
>>>             you're at a point where handling it makes sense).  If
>>>             you simply reinterrupt, you effectively delay (or lose)
>>>             the interrupt delivery to the caller.
>>>
>>>             Sent from my phone
>>>
>>>             On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>             <zhong.j.yu at gmail.com <mailto:zhong.j.yu at gmail.com>> wrote:
>>>
>>>                 On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
>>>                 <zhong.j.yu at gmail.com <mailto:zhong.j.yu at gmail.com>>
>>>                 wrote:
>>>                 > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
>>>                 <davidcholmes at aapt.net.au
>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>                 >> The JLS doesn't say anything about what
>>>                 applications should do. All the
>>>                 >> application knows when the IE is thrown is that
>>>                 the thread was interrupted
>>>                 >> and the interrupt state is now clear. It is up to
>>>                 the application to respond
>>>                 >> to the interruption in an appropriate manner.
>>>                 >
>>>                 > I'm also unsure about the use of interruption in
>>>                 real world.
>>>                 >
>>>                 > In simple cases, the interrupt-er and the
>>>                 interrupt-ee can assign any
>>>                 > special meaning to interruptions. But they can
>>>                 also instead use an
>>>                 > explicit variable to transmit the meaning;
>>>                 interruption doesn't offer
>>>                 > a lot of value here.
>>>                 >
>>>                 > In more complex applications, it's hard for
>>>                 interrupt-er to know which
>>>                 > piece of code the interrupt-ee is running at the
>>>                 moment; it's unlikely
>>>                 > that interruption can be used to deliver special
>>>                 meanings.
>>>                 > Interruption can only have 1 meaning universally
>>>                 accepted by all,
>>>                 > which is probably "stop everything and quit the
>>>                 thread"
>>>                 >
>>>                 > To achieve that, interruptions need to propagate
>>>                 up, therefore pretty
>>>                 > much all method signatures will be polluted by
>>>                 InterruptedException.
>>>
>>>                 This is incorrect. A method doesn't have to propagate
>>>                 InterruptedException in this case; it can
>>>                 re-interrupt the current
>>>                 thread, then return normally, leaving the caller to
>>>                 discover and
>>>                 handle the interruption.
>>>
>>>                 > We don't see that in practice.
>>>                 >
>>>                 > Or an application will simply restrain from using
>>>                 interruption at all,
>>>                 > since it doesn't know how to handle it. Then all
>>>                 InterruptedExceptions
>>>                 > can be ignored anywhere in the application code.
>>>                 >
>>>                 >
>>>                 > Zhong Yu
>>>                 >
>>>                 >
>>>                 >>
>>>                 >> David
>>>                 >>
>>>                 >> -----Original Message-----
>>>                 >> From: concurrency-interest-bounces at cs.oswego.edu
>>>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>                 >>
>>>                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>                 Behalf Of oleksandr
>>>                 >> otenko
>>>                 >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>                 >> To: Vitaly Davidovich
>>>                 >> Cc: concurrency-interest at cs.oswego.edu
>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>                 >> Subject: Re: [concurrency-interest] Subject: Re:
>>>                 Interruption
>>>                 >> afternotification
>>>                 >>
>>>                 >> If these two events arrive concurrently, there is
>>>                 no ordering between them.
>>>                 >> So preferring interruption over notification
>>>                 doesn't change the correctness.
>>>                 >>
>>>                 >> Does JLS specify what the application _should_ do
>>>                 upon receiving
>>>                 >> InterruptedException?
>>>                 >>
>>>                 >> Alex
>>>                 >>
>>>                 >>
>>>                 >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>                 >>
>>>                 >> Dave,
>>>                 >>
>>>                 >> I can see why one may want to leave interrupt
>>>                 pending (thread may complete
>>>                 >> without checking interrupt status) but I can also
>>>                 see an argument in favor
>>>                 >> of delivering the interrupt in such a case (I.e.
>>>                 deliver the "inevitable"
>>>                 >> sooner, assuming thread will notice the interrupt
>>>                 soon thereafter).
>>>                 >>
>>>                 >> So just curious - what's the rationale for
>>>                 choosing notification over
>>>                 >> interrupt here?
>>>                 >>
>>>                 >> Thanks
>>>                 >>
>>>                 >> Sent from my phone
>>>                 >>
>>>                 >> On Sep 4, 2012 1:10 PM, "David Dice"
>>>                 <david.dice at gmail.com <mailto:david.dice at gmail.com>>
>>>                 wrote:
>>>                 >>>
>>>                 >>> As an aside, in the current implementation in
>>>                 hotspot if we have a both a
>>>                 >>> pending notification and interrupt, we return
>>>                 from wait() leaving the
>>>                 >>> interrupt pending.
>>>                 >>>
>>>                 >>> Dave
>>>                 >>> https://blogs.oracle.com/dave/
>>>                 >>>
>>>                 >>>
>>>                 >>>
>>>                 >>> _______________________________________________
>>>                 >>> Concurrency-interest mailing list
>>>                 >>> Concurrency-interest at cs.oswego.edu
>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>                 >>>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>                 >>>
>>>                 >>
>>>                 >>
>>>                 >> _______________________________________________
>>>                 >> Concurrency-interest mailing list
>>>                 >> Concurrency-interest at cs.oswego.edu
>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>                 >>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>                 >>
>>>                 >>
>>>                 >> _______________________________________________
>>>                 >> Concurrency-interest mailing list
>>>                 >> Concurrency-interest at cs.oswego.edu
>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>                 >>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>                 >>
>>>                 _______________________________________________
>>>                 Concurrency-interest mailing list
>>>                 Concurrency-interest at cs.oswego.edu
>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/32663fca/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 06:56:08 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 11:56:08 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50472892.7060608@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com>
Message-ID: <50472FC8.7050604@oracle.com>

Even more interesting:

A does B, then C, then D. Interrupt during C. Now if we cancel A in its 
entirety, how do we cancel B after it finished? (eg return an element to 
FIFO queue in the same position?..) Since C is agnostic of the context, 
how can it ignore interruption (if we can't cancel B, and can't complete 
D without C, then C shouldn't cancel upon interruption)

Alex

On 05/09/2012 11:25, oleksandr otenko wrote:
> I guess the problem is similar to rolling back in presence of nested 
> transactions. Suppose, A does B, then C. If you interrupt during B, do 
> you mean to "rollback" just B, or A in its entirety? What you are 
> saying looks more like "A in its entirety".
>
> Alex
>
>
> On 05/09/2012 11:12, David Holmes wrote:
>> That is why interrupt generally can't be given a special meaning. You 
>> have to interpret it as a general cancellation request unless you 
>> have full knowledge of the execution stack. If your "cancellation" 
>> response is to ignore the request then you've made your code 
>> incompatible with all other code in the execution stack that wants to 
>> be actually cancelled. Hence the basic responses to IE are to either 
>> propagate it, or consume it and re-assert the interrupt state. It is 
>> a cooperative cancellation protocol.
>> David
>> -----Original Message-----
>> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>> *Sent:* Wednesday, 5 September 2012 8:03 PM
>> *To:* dholmes at ieee.org
>> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption 
>> afternotification
>>
>>     But how can one tell who was meant to be cancelled?
>>
>>     Since there is no requirement on the semantics of what a cancel
>>     operation might be, I can define my cancel operation as "stop
>>     waiting, think again, then maybe enter the same wait". So the
>>     effect is I consumed the IE and didn't even re-trigger it.
>>
>>     I guess we can't define strictly what a good way of dealing with
>>     IE is, since it is like a "last resort" to unblock a wait, which
>>     can offer "the best effort" semantics.
>>
>>     Alex
>>
>>     On 05/09/2012 04:43, David Holmes wrote:
>>>     In your applications you can do what you like. If you are a
>>>     library writer (which in simplest terms means you write a class
>>>     for others to use) then you need to follow the rule else you
>>>     will break any application that uses your library and which does
>>>     care about cancellation.
>>>     David
>>>
>>>         -----Original Message-----
>>>         *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>>         *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>         *To:* dholmes at ieee.org
>>>         *Cc:* Vitaly Davidovich; Zhong Yu;
>>>         concurrency-interest at cs.oswego.edu
>>>         *Subject:* Re: [concurrency-interest] Subject: Re:
>>>         Interruption afternotification
>>>
>>>
>>>         On 2012-09-05, at 4:35 AM, David Holmes
>>>         <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>>
>>>         wrote:
>>>
>>>>         Typically you either define an API that inherently reflects
>>>>         the potential blocking nature of the operation and supports
>>>>         cancellation, or the blocking operation is just an
>>>>         implementation detail. In the former case you will declare
>>>>         that you throw IE and throw it; in the latter you won't
>>>>         declare IE and so can't throw it but must re-interrupt the
>>>>         thread. (Golden rule is to never swallow an interrupt.)
>>>
>>>         Sorry but the golden rule is, he who has the gold makes the
>>>         rules. ;-) The IE is the *only* exception that I eat on a
>>>         fairly regular basis. Why? Because there is nothing to be
>>>         done and no point to propagate (which is different than I
>>>         don't know how to react so I should re-throw). Cancelation
>>>         scenarios are about the only times I'll not eat an IE.
>>>
>>>         Kirk
>>>
>>>>         Again cancellation techniques and options are well covered
>>>>         in CPJ and JCiP.
>>>>         David
>>>>
>>>>             -----Original Message-----
>>>>             *From:* Vitaly Davidovich [mailto:vitalyd at gmail.com
>>>>             <http://gmail.com>]
>>>>             *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>>             *To:* Zhong Yu
>>>>             *Cc:* dholmes at ieee.org <mailto:dholmes at ieee.org>;
>>>>             concurrency-interest at cs.oswego.edu
>>>>             <mailto:concurrency-interest at cs.oswego.edu>
>>>>             *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>             Interruption afternotification
>>>>
>>>>             I think typically you catch IE, do whatever cleanup and
>>>>             rethrow it rather than reinterrupting the thread
>>>>             (unless you're at a point where handling it makes
>>>>             sense).  If you simply reinterrupt, you effectively
>>>>             delay (or lose) the interrupt delivery to the caller.
>>>>
>>>>             Sent from my phone
>>>>
>>>>             On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>>             <zhong.j.yu at gmail.com <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>
>>>>                 On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
>>>>                 <zhong.j.yu at gmail.com
>>>>                 <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>                 > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
>>>>                 <davidcholmes at aapt.net.au
>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>                 >> The JLS doesn't say anything about what
>>>>                 applications should do. All the
>>>>                 >> application knows when the IE is thrown is that
>>>>                 the thread was interrupted
>>>>                 >> and the interrupt state is now clear. It is up
>>>>                 to the application to respond
>>>>                 >> to the interruption in an appropriate manner.
>>>>                 >
>>>>                 > I'm also unsure about the use of interruption in
>>>>                 real world.
>>>>                 >
>>>>                 > In simple cases, the interrupt-er and the
>>>>                 interrupt-ee can assign any
>>>>                 > special meaning to interruptions. But they can
>>>>                 also instead use an
>>>>                 > explicit variable to transmit the meaning;
>>>>                 interruption doesn't offer
>>>>                 > a lot of value here.
>>>>                 >
>>>>                 > In more complex applications, it's hard for
>>>>                 interrupt-er to know which
>>>>                 > piece of code the interrupt-ee is running at the
>>>>                 moment; it's unlikely
>>>>                 > that interruption can be used to deliver special
>>>>                 meanings.
>>>>                 > Interruption can only have 1 meaning universally
>>>>                 accepted by all,
>>>>                 > which is probably "stop everything and quit the
>>>>                 thread"
>>>>                 >
>>>>                 > To achieve that, interruptions need to propagate
>>>>                 up, therefore pretty
>>>>                 > much all method signatures will be polluted by
>>>>                 InterruptedException.
>>>>
>>>>                 This is incorrect. A method doesn't have to propagate
>>>>                 InterruptedException in this case; it can
>>>>                 re-interrupt the current
>>>>                 thread, then return normally, leaving the caller to
>>>>                 discover and
>>>>                 handle the interruption.
>>>>
>>>>                 > We don't see that in practice.
>>>>                 >
>>>>                 > Or an application will simply restrain from using
>>>>                 interruption at all,
>>>>                 > since it doesn't know how to handle it. Then all
>>>>                 InterruptedExceptions
>>>>                 > can be ignored anywhere in the application code.
>>>>                 >
>>>>                 >
>>>>                 > Zhong Yu
>>>>                 >
>>>>                 >
>>>>                 >>
>>>>                 >> David
>>>>                 >>
>>>>                 >> -----Original Message-----
>>>>                 >> From: concurrency-interest-bounces at cs.oswego.edu
>>>>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>                 >>
>>>>                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>                 Behalf Of oleksandr
>>>>                 >> otenko
>>>>                 >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>                 >> To: Vitaly Davidovich
>>>>                 >> Cc: concurrency-interest at cs.oswego.edu
>>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>                 >> Subject: Re: [concurrency-interest] Subject: Re:
>>>>                 Interruption
>>>>                 >> afternotification
>>>>                 >>
>>>>                 >> If these two events arrive concurrently, there
>>>>                 is no ordering between them.
>>>>                 >> So preferring interruption over notification
>>>>                 doesn't change the correctness.
>>>>                 >>
>>>>                 >> Does JLS specify what the application _should_
>>>>                 do upon receiving
>>>>                 >> InterruptedException?
>>>>                 >>
>>>>                 >> Alex
>>>>                 >>
>>>>                 >>
>>>>                 >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>>                 >>
>>>>                 >> Dave,
>>>>                 >>
>>>>                 >> I can see why one may want to leave interrupt
>>>>                 pending (thread may complete
>>>>                 >> without checking interrupt status) but I can
>>>>                 also see an argument in favor
>>>>                 >> of delivering the interrupt in such a case (I.e.
>>>>                 deliver the "inevitable"
>>>>                 >> sooner, assuming thread will notice the
>>>>                 interrupt soon thereafter).
>>>>                 >>
>>>>                 >> So just curious - what's the rationale for
>>>>                 choosing notification over
>>>>                 >> interrupt here?
>>>>                 >>
>>>>                 >> Thanks
>>>>                 >>
>>>>                 >> Sent from my phone
>>>>                 >>
>>>>                 >> On Sep 4, 2012 1:10 PM, "David Dice"
>>>>                 <david.dice at gmail.com
>>>>                 <mailto:david.dice at gmail.com>> wrote:
>>>>                 >>>
>>>>                 >>> As an aside, in the current implementation in
>>>>                 hotspot if we have a both a
>>>>                 >>> pending notification and interrupt, we return
>>>>                 from wait() leaving the
>>>>                 >>> interrupt pending.
>>>>                 >>>
>>>>                 >>> Dave
>>>>                 >>> https://blogs.oracle.com/dave/
>>>>                 >>>
>>>>                 >>>
>>>>                 >>>
>>>>                 >>> _______________________________________________
>>>>                 >>> Concurrency-interest mailing list
>>>>                 >>> Concurrency-interest at cs.oswego.edu
>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>                 >>>
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>                 >>>
>>>>                 >>
>>>>                 >>
>>>>                 >> _______________________________________________
>>>>                 >> Concurrency-interest mailing list
>>>>                 >> Concurrency-interest at cs.oswego.edu
>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>                 >>
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>                 >>
>>>>                 >>
>>>>                 >> _______________________________________________
>>>>                 >> Concurrency-interest mailing list
>>>>                 >> Concurrency-interest at cs.oswego.edu
>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>                 >>
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>                 >>
>>>>                 _______________________________________________
>>>>                 Concurrency-interest mailing list
>>>>                 Concurrency-interest at cs.oswego.edu
>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu
>>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>     _______________________________________________
>>>     Concurrency-interest mailing list
>>>     Concurrency-interest at cs.oswego.edu
>>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/133126f8/attachment-0001.html>

From dl at cs.oswego.edu  Wed Sep  5 06:57:35 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 05 Sep 2012 06:57:35 -0400
Subject: [concurrency-interest] Thread safety of elements in ThreadSafe
 collections
In-Reply-To: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
References: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
Message-ID: <5047301F.8030201@cs.oswego.edu>

On 09/04/12 10:46, Aaron Greenhouse wrote:
> I have a question about something that I'm surprised I haven't seen discussed
> anywhere before.  If I have a thread safe collection, such as a
> CopyOnWriteArrayList, what are the thread safety requirements of the elements
> I put in the collection?

As implied already in other responses, it seems that the main reason
you don't see much discussion of this is that, for j.u.c collections
anyway, the issues are nearly identical to non-concurrent cases.
All concurrent collections guarantee a happens-before
between any writes before an element is placed in a collection
and any accesses. If you modify the state of an element
while it is inside the collection, and those modifications
somehow impact collection operations (as in affecting, equals(),
hashCode(), compareTo()/comparators, for either the element or the
collection), then all bets are off. The only difference with the
non-concurrent case is some added non-determinism about whether
client operations will even see these disruptive modifications.

>
> On a related note, but not specifically a concurrency observation, it seems
> to be pretty much a very very bad idea to override hashCode() on a mutable
> object (even though the collection classes do it).  But I've never seen this
> mentioned anywhere either.  Certainly I've never seen any one say don't
> modify an object after you stick in a collection.

Or, don't modify any aspect of the object that affects equals(), etc.
Which, for most mutable objects, amounts to: just rely on identity-based
equals() and hashCode(), which is one reason these are the defaults.
The cases that resist simple recipes are those in which an object is
sometimes value-like, and sometimes not.

> If you put an object in a
> set or map and then change its state in such a way that affects its hash
> code, you have broken the set or map that you put it in because the object is
> still indexed by its original hash code.

Yes. There's not enough user guidance about this out there,
and choices about it, even inside JDK, are not completely consistent.
The decision to define a compositional version of hashCode for
Collections (rather than identity-based) was a marginal call.
It is useful/usable only when one Collection remains unmodified
while it is an element of another Collection. This is not a
common use case (and these usages cannot easily be statically
checked for correctness), but Josh Bloch (mainly) thought that supplying
a hashCode method that *is* applicable in this case was worthwhile.
In other cases, for example, AtomicInteger, I've made the opposite
decision (i.e., hashCode is just identityHashCode, because using the
value of AtomicInteger as a hash table key is too terrible an idea to
support.

-Doug

From vitalyd at gmail.com  Wed Sep  5 07:09:59 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 5 Sep 2012 07:09:59 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50472FC8.7050604@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
Message-ID: <CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>

This will depend on your use case/API really as to what interruption
actually entails - hard to generalize.  All your code knows is that if it's
interrupted, some other code has decided to cancel the operation across the
stack of calls - what each call frame does in this case depends on
specifics.

Sent from my phone
On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
wrote:

>  Even more interesting:
>
> A does B, then C, then D. Interrupt during C. Now if we cancel A in its
> entirety, how do we cancel B after it finished? (eg return an element to
> FIFO queue in the same position?..) Since C is agnostic of the context, how
> can it ignore interruption (if we can't cancel B, and can't complete D
> without C, then C shouldn't cancel upon interruption)
>
> Alex
>
> On 05/09/2012 11:25, oleksandr otenko wrote:
>
> I guess the problem is similar to rolling back in presence of nested
> transactions. Suppose, A does B, then C. If you interrupt during B, do you
> mean to "rollback" just B, or A in its entirety? What you are saying looks
> more like "A in its entirety".
>
> Alex
>
>
> On 05/09/2012 11:12, David Holmes wrote:
>
> That is why interrupt generally can't be given a special meaning. You have
> to interpret it as a general cancellation request unless you have full
> knowledge of the execution stack. If your "cancellation" response is to
> ignore the request then you've made your code incompatible with all other
> code in the execution stack that wants to be actually cancelled. Hence the
> basic responses to IE are to either propagate it, or consume it and
> re-assert the interrupt state. It is a cooperative cancellation protocol.
>
> David
>
>  -----Original Message-----
> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com<oleksandr.otenko at oracle.com>
> ]
> *Sent:* Wednesday, 5 September 2012 8:03 PM
> *To:* dholmes at ieee.org
> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
>  But how can one tell who was meant to be cancelled?
>
> Since there is no requirement on the semantics of what a cancel operation
> might be, I can define my cancel operation as "stop waiting, think again,
> then maybe enter the same wait". So the effect is I consumed the IE and
> didn't even re-trigger it.
>
> I guess we can't define strictly what a good way of dealing with IE is,
> since it is like a "last resort" to unblock a wait, which can offer "the
> best effort" semantics.
>
> Alex
>
> On 05/09/2012 04:43, David Holmes wrote:
>
> In your applications you can do what you like. If you are a library writer
> (which in simplest terms means you write a class for others to use) then
> you need to follow the rule else you will break any application that uses
> your library and which does care about cancellation.
>
> David
>
> -----Original Message-----
> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
> *Sent:* Wednesday, 5 September 2012 1:38 PM
> *To:* dholmes at ieee.org
> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
>
>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>
>  Typically you either define an API that inherently reflects the
> potential blocking nature of the operation and supports cancellation, or
> the blocking operation is just an implementation detail. In the former case
> you will declare that you throw IE and throw it; in the latter you won't
> declare IE and so can't throw it but must re-interrupt the thread. (Golden
> rule is to never swallow an interrupt.)
>
>
>  Sorry but the golden rule is, he who has the gold makes the rules. ;-)
> The IE is the *only* exception that I eat on a fairly regular basis. Why?
> Because there is nothing to be done and no point to propagate (which is
> different than I don't know how to react so I should re-throw). Cancelation
> scenarios are about the only times I'll not eat an IE.
>
>  Kirk
>
>
> Again cancellation techniques and options are well covered in CPJ and JCiP.
>
> David
>
> -----Original Message-----
> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
> *Sent:* Wednesday, 5 September 2012 12:29 PM
> *To:* Zhong Yu
> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
>  I think typically you catch IE, do whatever cleanup and rethrow it
> rather than reinterrupting the thread (unless you're at a point where
> handling it makes sense).  If you simply reinterrupt, you effectively delay
> (or lose) the interrupt delivery to the caller.
>
> Sent from my phone
> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>
>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>> >> The JLS doesn't say anything about what applications should do. All the
>> >> application knows when the IE is thrown is that the thread was
>> interrupted
>> >> and the interrupt state is now clear. It is up to the application to
>> respond
>> >> to the interruption in an appropriate manner.
>> >
>> > I'm also unsure about the use of interruption in real world.
>> >
>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>> > special meaning to interruptions. But they can also instead use an
>> > explicit variable to transmit the meaning; interruption doesn't offer
>> > a lot of value here.
>> >
>> > In more complex applications, it's hard for interrupt-er to know which
>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>> > that interruption can be used to deliver special meanings.
>> > Interruption can only have 1 meaning universally accepted by all,
>> > which is probably "stop everything and quit the thread"
>> >
>> > To achieve that, interruptions need to propagate up, therefore pretty
>> > much all method signatures will be polluted by InterruptedException.
>>
>> This is incorrect. A method doesn't have to propagate
>> InterruptedException in this case; it can re-interrupt the current
>> thread, then return normally, leaving the caller to discover and
>> handle the interruption.
>>
>> > We don't see that in practice.
>> >
>> > Or an application will simply restrain from using interruption at all,
>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>> > can be ignored anywhere in the application code.
>> >
>> >
>> > Zhong Yu
>> >
>> >
>> >>
>> >> David
>> >>
>> >> -----Original Message-----
>> >> From: concurrency-interest-bounces at cs.oswego.edu
>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> oleksandr
>> >> otenko
>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>> >> To: Vitaly Davidovich
>> >> Cc: concurrency-interest at cs.oswego.edu
>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> >> afternotification
>> >>
>> >> If these two events arrive concurrently, there is no ordering between
>> them.
>> >> So preferring interruption over notification doesn't change the
>> correctness.
>> >>
>> >> Does JLS specify what the application _should_ do upon receiving
>> >> InterruptedException?
>> >>
>> >> Alex
>> >>
>> >>
>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>> >>
>> >> Dave,
>> >>
>> >> I can see why one may want to leave interrupt pending (thread may
>> complete
>> >> without checking interrupt status) but I can also see an argument in
>> favor
>> >> of delivering the interrupt in such a case (I.e. deliver the
>> "inevitable"
>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>> >>
>> >> So just curious - what's the rationale for choosing notification over
>> >> interrupt here?
>> >>
>> >> Thanks
>> >>
>> >> Sent from my phone
>> >>
>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>> >>>
>> >>> As an aside, in the current implementation in hotspot if we have a
>> both a
>> >>> pending notification and interrupt, we return from wait() leaving the
>> >>> interrupt pending.
>> >>>
>> >>> Dave
>> >>> https://blogs.oracle.com/dave/
>> >>>
>> >>>
>> >>>
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>>
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>   _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/c4999a5c/attachment-0001.html>

From kirk at kodewerk.com  Wed Sep  5 09:07:02 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 5 Sep 2012 15:07:02 +0200
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
Message-ID: <8A9DFBDE-F1E9-4FF5-B856-D08BD49807CB@kodewerk.com>

Hi David,

I'm sorry but I have to disagree with the cancelation assumption. I feel it's no better an assumption than to ignore it. If a library is throwing IE it should state intent so that the user of the library can know how to react to this exception. If the proper thing to do is cancel... then.... But the problem is the historical response is cancelation and I think that is an over-reaching assumption.

Regards,
Kirk

On 2012-09-05, at 12:12 PM, "David Holmes" <davidcholmes at aapt.net.au> wrote:

> That is why interrupt generally can't be given a special meaning. You have to interpret it as a general cancellation request unless you have full knowledge of the execution stack. If your "cancellation" response is to ignore the request then you've made your code incompatible with all other code in the execution stack that wants to be actually cancelled. Hence the basic responses to IE are to either propagate it, or consume it and re-assert the interrupt state. It is a cooperative cancellation protocol.
>  
> David
>  
>  -----Original Message-----
> From: oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
> Sent: Wednesday, 5 September 2012 8:03 PM
> To: dholmes at ieee.org
> Cc: David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
> 
> But how can one tell who was meant to be cancelled?
> 
> Since there is no requirement on the semantics of what a cancel operation might be, I can define my cancel operation as "stop waiting, think again, then maybe enter the same wait". So the effect is I consumed the IE and didn't even re-trigger it.
> 
> I guess we can't define strictly what a good way of dealing with IE is, since it is like a "last resort" to unblock a wait, which can offer "the best effort" semantics.
> 
> Alex
> 
> On 05/09/2012 04:43, David Holmes wrote:
>> 
>> In your applications you can do what you like. If you are a library writer (which in simplest terms means you write a class for others to use) then you need to follow the rule else you will break any application that uses your library and which does care about cancellation.
>>  
>> David
>> -----Original Message-----
>> From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
>> Sent: Wednesday, 5 September 2012 1:38 PM
>> To: dholmes at ieee.org
>> Cc: Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
>> 
>> 
>> On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>> 
>>> Typically you either define an API that inherently reflects the potential blocking nature of the operation and supports cancellation, or the blocking operation is just an implementation detail. In the former case you will declare that you throw IE and throw it; in the latter you won't declare IE and so can't throw it but must re-interrupt the thread. (Golden rule is to never swallow an interrupt.)
>> 
>> Sorry but the golden rule is, he who has the gold makes the rules. ;-) The IE is the *only* exception that I eat on a fairly regular basis. Why? Because there is nothing to be done and no point to propagate (which is different than I don't know how to react so I should re-throw). Cancelation scenarios are about the only times I'll not eat an IE.
>> 
>> Kirk
>> 
>>>  
>>> Again cancellation techniques and options are well covered in CPJ and JCiP.
>>>  
>>> David
>>> -----Original Message-----
>>> From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
>>> Sent: Wednesday, 5 September 2012 12:29 PM
>>> To: Zhong Yu
>>> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
>>> 
>>> I think typically you catch IE, do whatever cleanup and rethrow it rather than reinterrupting the thread (unless you're at a point where handling it makes sense).  If you simply reinterrupt, you effectively delay (or lose) the interrupt delivery to the caller.
>>> 
>>> Sent from my phone
>>> 
>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>> >> The JLS doesn't say anything about what applications should do. All the
>>> >> application knows when the IE is thrown is that the thread was interrupted
>>> >> and the interrupt state is now clear. It is up to the application to respond
>>> >> to the interruption in an appropriate manner.
>>> >
>>> > I'm also unsure about the use of interruption in real world.
>>> >
>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>> > special meaning to interruptions. But they can also instead use an
>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>> > a lot of value here.
>>> >
>>> > In more complex applications, it's hard for interrupt-er to know which
>>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>>> > that interruption can be used to deliver special meanings.
>>> > Interruption can only have 1 meaning universally accepted by all,
>>> > which is probably "stop everything and quit the thread"
>>> >
>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>> > much all method signatures will be polluted by InterruptedException.
>>> 
>>> This is incorrect. A method doesn't have to propagate
>>> InterruptedException in this case; it can re-interrupt the current
>>> thread, then return normally, leaving the caller to discover and
>>> handle the interruption.
>>> 
>>> > We don't see that in practice.
>>> >
>>> > Or an application will simply restrain from using interruption at all,
>>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>>> > can be ignored anywhere in the application code.
>>> >
>>> >
>>> > Zhong Yu
>>> >
>>> >
>>> >>
>>> >> David
>>> >>
>>> >> -----Original Message-----
>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
>>> >> otenko
>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>> >> To: Vitaly Davidovich
>>> >> Cc: concurrency-interest at cs.oswego.edu
>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>> >> afternotification
>>> >>
>>> >> If these two events arrive concurrently, there is no ordering between them.
>>> >> So preferring interruption over notification doesn't change the correctness.
>>> >>
>>> >> Does JLS specify what the application _should_ do upon receiving
>>> >> InterruptedException?
>>> >>
>>> >> Alex
>>> >>
>>> >>
>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>> >>
>>> >> Dave,
>>> >>
>>> >> I can see why one may want to leave interrupt pending (thread may complete
>>> >> without checking interrupt status) but I can also see an argument in favor
>>> >> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>> >>
>>> >> So just curious - what's the rationale for choosing notification over
>>> >> interrupt here?
>>> >>
>>> >> Thanks
>>> >>
>>> >> Sent from my phone
>>> >>
>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>> >>>
>>> >>> As an aside, in the current implementation in hotspot if we have a both a
>>> >>> pending notification and interrupt, we return from wait() leaving the
>>> >>> interrupt pending.
>>> >>>
>>> >>> Dave
>>> >>> https://blogs.oracle.com/dave/
>>> >>>
>>> >>>
>>> >>>
>>> >>> _______________________________________________
>>> >>> Concurrency-interest mailing list
>>> >>> Concurrency-interest at cs.oswego.edu
>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>>
>>> >>
>>> >>
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> >>
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/e15b2b3d/attachment.html>

From vitalyd at gmail.com  Wed Sep  5 10:35:11 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 5 Sep 2012 10:35:11 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <8A9DFBDE-F1E9-4FF5-B856-D08BD49807CB@kodewerk.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<8A9DFBDE-F1E9-4FF5-B856-D08BD49807CB@kodewerk.com>
Message-ID: <CAHjP37HOOpZFFHERwy02EyMJ-=sYyfYnNgfHNqm+L-=jC9XShQ@mail.gmail.com>

Library typically will tell you (javadoc and/or checked exception)  if it
throws IE and under what condition.  For a lib, that condition is almost
always user code cancelling the operation.  Can you describe a realistic
scenario where IE was ambiguous or caused some other problem/uncertainty as
to what to do with it?

Sent from my phone
On Sep 5, 2012 9:11 AM, "Kirk Pepperdine" <kirk at kodewerk.com> wrote:

> Hi David,
>
> I'm sorry but I have to disagree with the cancelation assumption. I feel
> it's no better an assumption than to ignore it. If a library is throwing IE
> it should state intent so that the user of the library can know how to
> react to this exception. If the proper thing to do is cancel... then....
> But the problem is the historical response is cancelation and I think that
> is an over-reaching assumption.
>
> Regards,
> Kirk
>
> On 2012-09-05, at 12:12 PM, "David Holmes" <davidcholmes at aapt.net.au>
> wrote:
>
>  That is why interrupt generally can't be given a special meaning. You
> have to interpret it as a general cancellation request unless you have full
> knowledge of the execution stack. If your "cancellation" response is to
> ignore the request then you've made your code incompatible with all other
> code in the execution stack that wants to be actually cancelled. Hence the
> basic responses to IE are to either propagate it, or consume it and
> re-assert the interrupt state. It is a cooperative cancellation protocol.
>
> David
>
>  -----Original Message-----
> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
> *Sent:* Wednesday, 5 September 2012 8:03 PM
> *To:* dholmes at ieee.org
> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
> But how can one tell who was meant to be cancelled?
>
> Since there is no requirement on the semantics of what a cancel operation
> might be, I can define my cancel operation as "stop waiting, think again,
> then maybe enter the same wait". So the effect is I consumed the IE and
> didn't even re-trigger it.
>
> I guess we can't define strictly what a good way of dealing with IE is,
> since it is like a "last resort" to unblock a wait, which can offer "the
> best effort" semantics.
>
> Alex
>
> On 05/09/2012 04:43, David Holmes wrote:
>
> In your applications you can do what you like. If you are a library writer
> (which in simplest terms means you write a class for others to use) then
> you need to follow the rule else you will break any application that uses
> your library and which does care about cancellation.
>
> David
>
> -----Original Message-----
> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
> *Sent:* Wednesday, 5 September 2012 1:38 PM
> *To:* dholmes at ieee.org
> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
>
>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>
>  Typically you either define an API that inherently reflects the
> potential blocking nature of the operation and supports cancellation, or
> the blocking operation is just an implementation detail. In the former case
> you will declare that you throw IE and throw it; in the latter you won't
> declare IE and so can't throw it but must re-interrupt the thread. (Golden
> rule is to never swallow an interrupt.)
>
>
> Sorry but the golden rule is, he who has the gold makes the rules. ;-) The
> IE is the *only* exception that I eat on a fairly regular basis. Why?
> Because there is nothing to be done and no point to propagate (which is
> different than I don't know how to react so I should re-throw). Cancelation
> scenarios are about the only times I'll not eat an IE.
>
> Kirk
>
>
> Again cancellation techniques and options are well covered in CPJ and JCiP.
>
> David
>
> -----Original Message-----
> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
> *Sent:* Wednesday, 5 September 2012 12:29 PM
> *To:* Zhong Yu
> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
> afternotification
>
> I think typically you catch IE, do whatever cleanup and rethrow it rather
> than reinterrupting the thread (unless you're at a point where handling it
> makes sense).  If you simply reinterrupt, you effectively delay (or lose)
> the interrupt delivery to the caller.
>
> Sent from my phone
> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>
>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>> >> The JLS doesn't say anything about what applications should do. All the
>> >> application knows when the IE is thrown is that the thread was
>> interrupted
>> >> and the interrupt state is now clear. It is up to the application to
>> respond
>> >> to the interruption in an appropriate manner.
>> >
>> > I'm also unsure about the use of interruption in real world.
>> >
>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>> > special meaning to interruptions. But they can also instead use an
>> > explicit variable to transmit the meaning; interruption doesn't offer
>> > a lot of value here.
>> >
>> > In more complex applications, it's hard for interrupt-er to know which
>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>> > that interruption can be used to deliver special meanings.
>> > Interruption can only have 1 meaning universally accepted by all,
>> > which is probably "stop everything and quit the thread"
>> >
>> > To achieve that, interruptions need to propagate up, therefore pretty
>> > much all method signatures will be polluted by InterruptedException.
>>
>> This is incorrect. A method doesn't have to propagate
>> InterruptedException in this case; it can re-interrupt the current
>> thread, then return normally, leaving the caller to discover and
>> handle the interruption.
>>
>> > We don't see that in practice.
>> >
>> > Or an application will simply restrain from using interruption at all,
>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>> > can be ignored anywhere in the application code.
>> >
>> >
>> > Zhong Yu
>> >
>> >
>> >>
>> >> David
>> >>
>> >> -----Original Message-----
>> >> From: concurrency-interest-bounces at cs.oswego.edu
>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>> oleksandr
>> >> otenko
>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>> >> To: Vitaly Davidovich
>> >> Cc: concurrency-interest at cs.oswego.edu
>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>> >> afternotification
>> >>
>> >> If these two events arrive concurrently, there is no ordering between
>> them.
>> >> So preferring interruption over notification doesn't change the
>> correctness.
>> >>
>> >> Does JLS specify what the application _should_ do upon receiving
>> >> InterruptedException?
>> >>
>> >> Alex
>> >>
>> >>
>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>> >>
>> >> Dave,
>> >>
>> >> I can see why one may want to leave interrupt pending (thread may
>> complete
>> >> without checking interrupt status) but I can also see an argument in
>> favor
>> >> of delivering the interrupt in such a case (I.e. deliver the
>> "inevitable"
>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>> >>
>> >> So just curious - what's the rationale for choosing notification over
>> >> interrupt here?
>> >>
>> >> Thanks
>> >>
>> >> Sent from my phone
>> >>
>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>> >>>
>> >>> As an aside, in the current implementation in hotspot if we have a
>> both a
>> >>> pending notification and interrupt, we return from wait() leaving the
>> >>> interrupt pending.
>> >>>
>> >>> Dave
>> >>> https://blogs.oracle.com/dave/
>> >>>
>> >>>
>> >>>
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>>
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/6c921b16/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 10:36:56 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 15:36:56 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
Message-ID: <50476388.4000705@oracle.com>

It doesn't just depend on API. If A can't tell C to ignore the 
interrupts, then it will always cancel, and A needs to... redo? Then C 
needs to support a redo. (But how do you redo, for example, a closed 
connection)

I am poking to see if there are valid cases when cancelling lower layer 
without upper layer's permission is a destructive state transition. Then 
the lower layer - the library - should somehow take these things into 
account. Is there further guidance on this?

Alex

On 05/09/2012 12:09, Vitaly Davidovich wrote:
>
> This will depend on your use case/API really as to what interruption 
> actually entails - hard to generalize.  All your code knows is that if 
> it's interrupted, some other code has decided to cancel the operation 
> across the stack of calls - what each call frame does in this case 
> depends on specifics.
>
> Sent from my phone
>
> On Sep 5, 2012 7:05 AM, "oleksandr otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Even more interesting:
>
>     A does B, then C, then D. Interrupt during C. Now if we cancel A
>     in its entirety, how do we cancel B after it finished? (eg return
>     an element to FIFO queue in the same position?..) Since C is
>     agnostic of the context, how can it ignore interruption (if we
>     can't cancel B, and can't complete D without C, then C shouldn't
>     cancel upon interruption)
>
>     Alex
>
>     On 05/09/2012 11:25, oleksandr otenko wrote:
>>     I guess the problem is similar to rolling back in presence of
>>     nested transactions. Suppose, A does B, then C. If you interrupt
>>     during B, do you mean to "rollback" just B, or A in its entirety?
>>     What you are saying looks more like "A in its entirety".
>>
>>     Alex
>>
>>
>>     On 05/09/2012 11:12, David Holmes wrote:
>>>     That is why interrupt generally can't be given a special
>>>     meaning. You have to interpret it as a general cancellation
>>>     request unless you have full knowledge of the execution stack.
>>>     If your "cancellation" response is to ignore the request then
>>>     you've made your code incompatible with all other code in the
>>>     execution stack that wants to be actually cancelled. Hence the
>>>     basic responses to IE are to either propagate it, or consume it
>>>     and re-assert the interrupt state. It is a cooperative
>>>     cancellation protocol.
>>>     David
>>>     -----Original Message-----
>>>     *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>>>     *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>     *Cc:* David Holmes; Kirk Pepperdine;
>>>     concurrency-interest at cs.oswego.edu
>>>     <mailto:concurrency-interest at cs.oswego.edu>
>>>     *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>     afternotification
>>>
>>>         But how can one tell who was meant to be cancelled?
>>>
>>>         Since there is no requirement on the semantics of what a
>>>         cancel operation might be, I can define my cancel operation
>>>         as "stop waiting, think again, then maybe enter the same
>>>         wait". So the effect is I consumed the IE and didn't even
>>>         re-trigger it.
>>>
>>>         I guess we can't define strictly what a good way of dealing
>>>         with IE is, since it is like a "last resort" to unblock a
>>>         wait, which can offer "the best effort" semantics.
>>>
>>>         Alex
>>>
>>>         On 05/09/2012 04:43, David Holmes wrote:
>>>>         In your applications you can do what you like. If you are a
>>>>         library writer (which in simplest terms means you write a
>>>>         class for others to use) then you need to follow the rule
>>>>         else you will break any application that uses your library
>>>>         and which does care about cancellation.
>>>>         David
>>>>
>>>>             -----Original Message-----
>>>>             *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>>>             *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>>             *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>             *Cc:* Vitaly Davidovich; Zhong Yu;
>>>>             concurrency-interest at cs.oswego.edu
>>>>             <mailto:concurrency-interest at cs.oswego.edu>
>>>>             *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>             Interruption afternotification
>>>>
>>>>
>>>>             On 2012-09-05, at 4:35 AM, David Holmes
>>>>             <davidcholmes at aapt.net.au
>>>>             <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>
>>>>>             Typically you either define an API that inherently
>>>>>             reflects the potential blocking nature of the
>>>>>             operation and supports cancellation, or the blocking
>>>>>             operation is just an implementation detail. In the
>>>>>             former case you will declare that you throw IE and
>>>>>             throw it; in the latter you won't declare IE and so
>>>>>             can't throw it but must re-interrupt the thread.
>>>>>             (Golden rule is to never swallow an interrupt.)
>>>>
>>>>             Sorry but the golden rule is, he who has the gold makes
>>>>             the rules. ;-) The IE is the *only* exception that I
>>>>             eat on a fairly regular basis. Why? Because there is
>>>>             nothing to be done and no point to propagate (which is
>>>>             different than I don't know how to react so I should
>>>>             re-throw). Cancelation scenarios are about the only
>>>>             times I'll not eat an IE.
>>>>
>>>>             Kirk
>>>>
>>>>>             Again cancellation techniques and options are well
>>>>>             covered in CPJ and JCiP.
>>>>>             David
>>>>>
>>>>>                 -----Original Message-----
>>>>>                 *From:* Vitaly Davidovich
>>>>>                 [mailto:vitalyd at gmail.com <http://gmail.com>]
>>>>>                 *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>>>                 *To:* Zhong Yu
>>>>>                 *Cc:* dholmes at ieee.org <mailto:dholmes at ieee.org>;
>>>>>                 concurrency-interest at cs.oswego.edu
>>>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                 *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>>                 Interruption afternotification
>>>>>
>>>>>                 I think typically you catch IE, do whatever
>>>>>                 cleanup and rethrow it rather than reinterrupting
>>>>>                 the thread (unless you're at a point where
>>>>>                 handling it makes sense).  If you simply
>>>>>                 reinterrupt, you effectively delay (or lose) the
>>>>>                 interrupt delivery to the caller.
>>>>>
>>>>>                 Sent from my phone
>>>>>
>>>>>                 On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>>>                 <zhong.j.yu at gmail.com
>>>>>                 <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>
>>>>>                     On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
>>>>>                     <zhong.j.yu at gmail.com
>>>>>                     <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>                     > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
>>>>>                     <davidcholmes at aapt.net.au
>>>>>                     <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>                     >> The JLS doesn't say anything about what
>>>>>                     applications should do. All the
>>>>>                     >> application knows when the IE is thrown is
>>>>>                     that the thread was interrupted
>>>>>                     >> and the interrupt state is now clear. It is
>>>>>                     up to the application to respond
>>>>>                     >> to the interruption in an appropriate manner.
>>>>>                     >
>>>>>                     > I'm also unsure about the use of
>>>>>                     interruption in real world.
>>>>>                     >
>>>>>                     > In simple cases, the interrupt-er and the
>>>>>                     interrupt-ee can assign any
>>>>>                     > special meaning to interruptions. But they
>>>>>                     can also instead use an
>>>>>                     > explicit variable to transmit the meaning;
>>>>>                     interruption doesn't offer
>>>>>                     > a lot of value here.
>>>>>                     >
>>>>>                     > In more complex applications, it's hard for
>>>>>                     interrupt-er to know which
>>>>>                     > piece of code the interrupt-ee is running at
>>>>>                     the moment; it's unlikely
>>>>>                     > that interruption can be used to deliver
>>>>>                     special meanings.
>>>>>                     > Interruption can only have 1 meaning
>>>>>                     universally accepted by all,
>>>>>                     > which is probably "stop everything and quit
>>>>>                     the thread"
>>>>>                     >
>>>>>                     > To achieve that, interruptions need to
>>>>>                     propagate up, therefore pretty
>>>>>                     > much all method signatures will be polluted
>>>>>                     by InterruptedException.
>>>>>
>>>>>                     This is incorrect. A method doesn't have to
>>>>>                     propagate
>>>>>                     InterruptedException in this case; it can
>>>>>                     re-interrupt the current
>>>>>                     thread, then return normally, leaving the
>>>>>                     caller to discover and
>>>>>                     handle the interruption.
>>>>>
>>>>>                     > We don't see that in practice.
>>>>>                     >
>>>>>                     > Or an application will simply restrain from
>>>>>                     using interruption at all,
>>>>>                     > since it doesn't know how to handle it. Then
>>>>>                     all InterruptedExceptions
>>>>>                     > can be ignored anywhere in the application code.
>>>>>                     >
>>>>>                     >
>>>>>                     > Zhong Yu
>>>>>                     >
>>>>>                     >
>>>>>                     >>
>>>>>                     >> David
>>>>>                     >>
>>>>>                     >> -----Original Message-----
>>>>>                     >> From:
>>>>>                     concurrency-interest-bounces at cs.oswego.edu
>>>>>                     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>                     >>
>>>>>                     [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>                     <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>                     Behalf Of oleksandr
>>>>>                     >> otenko
>>>>>                     >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>>                     >> To: Vitaly Davidovich
>>>>>                     >> Cc: concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                     >> Subject: Re: [concurrency-interest]
>>>>>                     Subject: Re: Interruption
>>>>>                     >> afternotification
>>>>>                     >>
>>>>>                     >> If these two events arrive concurrently,
>>>>>                     there is no ordering between them.
>>>>>                     >> So preferring interruption over
>>>>>                     notification doesn't change the correctness.
>>>>>                     >>
>>>>>                     >> Does JLS specify what the application
>>>>>                     _should_ do upon receiving
>>>>>                     >> InterruptedException?
>>>>>                     >>
>>>>>                     >> Alex
>>>>>                     >>
>>>>>                     >>
>>>>>                     >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>>>                     >>
>>>>>                     >> Dave,
>>>>>                     >>
>>>>>                     >> I can see why one may want to leave
>>>>>                     interrupt pending (thread may complete
>>>>>                     >> without checking interrupt status) but I
>>>>>                     can also see an argument in favor
>>>>>                     >> of delivering the interrupt in such a case
>>>>>                     (I.e. deliver the "inevitable"
>>>>>                     >> sooner, assuming thread will notice the
>>>>>                     interrupt soon thereafter).
>>>>>                     >>
>>>>>                     >> So just curious - what's the rationale for
>>>>>                     choosing notification over
>>>>>                     >> interrupt here?
>>>>>                     >>
>>>>>                     >> Thanks
>>>>>                     >>
>>>>>                     >> Sent from my phone
>>>>>                     >>
>>>>>                     >> On Sep 4, 2012 1:10 PM, "David Dice"
>>>>>                     <david.dice at gmail.com
>>>>>                     <mailto:david.dice at gmail.com>> wrote:
>>>>>                     >>>
>>>>>                     >>> As an aside, in the current implementation
>>>>>                     in hotspot if we have a both a
>>>>>                     >>> pending notification and interrupt, we
>>>>>                     return from wait() leaving the
>>>>>                     >>> interrupt pending.
>>>>>                     >>>
>>>>>                     >>> Dave
>>>>>                     >>> https://blogs.oracle.com/dave/
>>>>>                     >>>
>>>>>                     >>>
>>>>>                     >>>
>>>>>                     >>>
>>>>>                     _______________________________________________
>>>>>                     >>> Concurrency-interest mailing list
>>>>>                     >>> Concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                     >>>
>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>                     >>>
>>>>>                     >>
>>>>>                     >>
>>>>>                     >> _______________________________________________
>>>>>                     >> Concurrency-interest mailing list
>>>>>                     >> Concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                     >>
>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>                     >>
>>>>>                     >>
>>>>>                     >> _______________________________________________
>>>>>                     >> Concurrency-interest mailing list
>>>>>                     >> Concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                     >>
>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>                     >>
>>>>>                     _______________________________________________
>>>>>                     Concurrency-interest mailing list
>>>>>                     Concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>             _______________________________________________
>>>>>             Concurrency-interest mailing list
>>>>>             Concurrency-interest at cs.oswego.edu
>>>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>         _______________________________________________
>>>>         Concurrency-interest mailing list
>>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/9f4025d2/attachment-0001.html>

From vitalyd at gmail.com  Wed Sep  5 10:42:14 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 5 Sep 2012 10:42:14 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50476388.4000705@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
Message-ID: <CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>

If C can be interrupted or is interrupt aware, then it encapsulates what
happens when it detects/receives cancellation.  If there are
user-configurable options then C's API should allow for that and then A
configures C appropriately.

I think it would be more useful if we can take some concrete/real example
and dissect it.

Sent from my phone
On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
wrote:

>  It doesn't just depend on API. If A can't tell C to ignore the
> interrupts, then it will always cancel, and A needs to... redo? Then C
> needs to support a redo. (But how do you redo, for example, a closed
> connection)
>
> I am poking to see if there are valid cases when cancelling lower layer
> without upper layer's permission is a destructive state transition. Then
> the lower layer - the library - should somehow take these things into
> account. Is there further guidance on this?
>
> Alex
>
> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>
> This will depend on your use case/API really as to what interruption
> actually entails - hard to generalize.  All your code knows is that if it's
> interrupted, some other code has decided to cancel the operation across the
> stack of calls - what each call frame does in this case depends on
> specifics.
>
> Sent from my phone
> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
> wrote:
>
>>  Even more interesting:
>>
>> A does B, then C, then D. Interrupt during C. Now if we cancel A in its
>> entirety, how do we cancel B after it finished? (eg return an element to
>> FIFO queue in the same position?..) Since C is agnostic of the context, how
>> can it ignore interruption (if we can't cancel B, and can't complete D
>> without C, then C shouldn't cancel upon interruption)
>>
>> Alex
>>
>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>
>> I guess the problem is similar to rolling back in presence of nested
>> transactions. Suppose, A does B, then C. If you interrupt during B, do you
>> mean to "rollback" just B, or A in its entirety? What you are saying looks
>> more like "A in its entirety".
>>
>> Alex
>>
>>
>> On 05/09/2012 11:12, David Holmes wrote:
>>
>> That is why interrupt generally can't be given a special meaning. You
>> have to interpret it as a general cancellation request unless you have full
>> knowledge of the execution stack. If your "cancellation" response is to
>> ignore the request then you've made your code incompatible with all other
>> code in the execution stack that wants to be actually cancelled. Hence the
>> basic responses to IE are to either propagate it, or consume it and
>> re-assert the interrupt state. It is a cooperative cancellation protocol.
>>
>> David
>>
>>  -----Original Message-----
>> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com<oleksandr.otenko at oracle.com>
>> ]
>> *Sent:* Wednesday, 5 September 2012 8:03 PM
>> *To:* dholmes at ieee.org
>> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>> afternotification
>>
>>  But how can one tell who was meant to be cancelled?
>>
>> Since there is no requirement on the semantics of what a cancel operation
>> might be, I can define my cancel operation as "stop waiting, think again,
>> then maybe enter the same wait". So the effect is I consumed the IE and
>> didn't even re-trigger it.
>>
>> I guess we can't define strictly what a good way of dealing with IE is,
>> since it is like a "last resort" to unblock a wait, which can offer "the
>> best effort" semantics.
>>
>> Alex
>>
>> On 05/09/2012 04:43, David Holmes wrote:
>>
>> In your applications you can do what you like. If you are a library
>> writer (which in simplest terms means you write a class for others to use)
>> then you need to follow the rule else you will break any application that
>> uses your library and which does care about cancellation.
>>
>> David
>>
>> -----Original Message-----
>> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
>> *Sent:* Wednesday, 5 September 2012 1:38 PM
>> *To:* dholmes at ieee.org
>> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>> afternotification
>>
>>
>>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au>
>> wrote:
>>
>>  Typically you either define an API that inherently reflects the
>> potential blocking nature of the operation and supports cancellation, or
>> the blocking operation is just an implementation detail. In the former case
>> you will declare that you throw IE and throw it; in the latter you won't
>> declare IE and so can't throw it but must re-interrupt the thread. (Golden
>> rule is to never swallow an interrupt.)
>>
>>
>>  Sorry but the golden rule is, he who has the gold makes the rules. ;-)
>> The IE is the *only* exception that I eat on a fairly regular basis. Why?
>> Because there is nothing to be done and no point to propagate (which is
>> different than I don't know how to react so I should re-throw). Cancelation
>> scenarios are about the only times I'll not eat an IE.
>>
>>  Kirk
>>
>>
>> Again cancellation techniques and options are well covered in CPJ and
>> JCiP.
>>
>> David
>>
>> -----Original Message-----
>> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
>> *Sent:* Wednesday, 5 September 2012 12:29 PM
>> *To:* Zhong Yu
>> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>> afternotification
>>
>>  I think typically you catch IE, do whatever cleanup and rethrow it
>> rather than reinterrupting the thread (unless you're at a point where
>> handling it makes sense).  If you simply reinterrupt, you effectively delay
>> (or lose) the interrupt delivery to the caller.
>>
>> Sent from my phone
>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>
>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au>
>>> wrote:
>>> >> The JLS doesn't say anything about what applications should do. All
>>> the
>>> >> application knows when the IE is thrown is that the thread was
>>> interrupted
>>> >> and the interrupt state is now clear. It is up to the application to
>>> respond
>>> >> to the interruption in an appropriate manner.
>>> >
>>> > I'm also unsure about the use of interruption in real world.
>>> >
>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>> > special meaning to interruptions. But they can also instead use an
>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>> > a lot of value here.
>>> >
>>> > In more complex applications, it's hard for interrupt-er to know which
>>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>>> > that interruption can be used to deliver special meanings.
>>> > Interruption can only have 1 meaning universally accepted by all,
>>> > which is probably "stop everything and quit the thread"
>>> >
>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>> > much all method signatures will be polluted by InterruptedException.
>>>
>>> This is incorrect. A method doesn't have to propagate
>>> InterruptedException in this case; it can re-interrupt the current
>>> thread, then return normally, leaving the caller to discover and
>>> handle the interruption.
>>>
>>> > We don't see that in practice.
>>> >
>>> > Or an application will simply restrain from using interruption at all,
>>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>>> > can be ignored anywhere in the application code.
>>> >
>>> >
>>> > Zhong Yu
>>> >
>>> >
>>> >>
>>> >> David
>>> >>
>>> >> -----Original Message-----
>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>> oleksandr
>>> >> otenko
>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>> >> To: Vitaly Davidovich
>>> >> Cc: concurrency-interest at cs.oswego.edu
>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>> >> afternotification
>>> >>
>>> >> If these two events arrive concurrently, there is no ordering between
>>> them.
>>> >> So preferring interruption over notification doesn't change the
>>> correctness.
>>> >>
>>> >> Does JLS specify what the application _should_ do upon receiving
>>> >> InterruptedException?
>>> >>
>>> >> Alex
>>> >>
>>> >>
>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>> >>
>>> >> Dave,
>>> >>
>>> >> I can see why one may want to leave interrupt pending (thread may
>>> complete
>>> >> without checking interrupt status) but I can also see an argument in
>>> favor
>>> >> of delivering the interrupt in such a case (I.e. deliver the
>>> "inevitable"
>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>> >>
>>> >> So just curious - what's the rationale for choosing notification over
>>> >> interrupt here?
>>> >>
>>> >> Thanks
>>> >>
>>> >> Sent from my phone
>>> >>
>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>> >>>
>>> >>> As an aside, in the current implementation in hotspot if we have a
>>> both a
>>> >>> pending notification and interrupt, we return from wait() leaving the
>>> >>> interrupt pending.
>>> >>>
>>> >>> Dave
>>> >>> https://blogs.oracle.com/dave/
>>> >>>
>>> >>>
>>> >>>
>>> >>> _______________________________________________
>>> >>> Concurrency-interest mailing list
>>> >>> Concurrency-interest at cs.oswego.edu
>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>>
>>> >>
>>> >>
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> >>
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>   _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/b38e865d/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 11:57:00 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 16:57:00 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
Message-ID: <5047764C.6020305@oracle.com>

Not sure what a concrete example is. For C to be safely redoable, all 
transitions performed by C, including a cancellation upon IE, must form 
a group - that is, for each state transition there is a way to revert 
it. I don't see how an arbitrary computation C can be turned into a 
group by A - how the reversing of the state can be done by A without 
knowing how C does it.

Suppose, A cannot afford to drop requests, unless the connection is lost 
(in which case all of other concurrent requests will be dropped - there 
is a guarantee the later requests cannot be observed complete). B 
computed a part of response, and that is passed to C. C decides to set 
response flag to error and rethrow IE. We cannot safely redo from A, 
unless there is a way to revert the state of the response object.

Yes, C should have thought of a possible vetoing / cancellation of the 
cancellation by the caller. Or the interruption API should have thought 
of a way to disable interruptions during C by A.

Alex

On 05/09/2012 15:42, Vitaly Davidovich wrote:
>
> If C can be interrupted or is interrupt aware, then it encapsulates 
> what happens when it detects/receives cancellation.  If there are 
> user-configurable options then C's API should allow for that and then 
> A configures C appropriately.
>
> I think it would be more useful if we can take some concrete/real 
> example and dissect it.
>
> Sent from my phone
>
> On Sep 5, 2012 10:37 AM, "oleksandr otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     It doesn't just depend on API. If A can't tell C to ignore the
>     interrupts, then it will always cancel, and A needs to... redo?
>     Then C needs to support a redo. (But how do you redo, for example,
>     a closed connection)
>
>     I am poking to see if there are valid cases when cancelling lower
>     layer without upper layer's permission is a destructive state
>     transition. Then the lower layer - the library - should somehow
>     take these things into account. Is there further guidance on this?
>
>     Alex
>
>     On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>
>>     This will depend on your use case/API really as to what
>>     interruption actually entails - hard to generalize.  All your
>>     code knows is that if it's interrupted, some other code has
>>     decided to cancel the operation across the stack of calls - what
>>     each call frame does in this case depends on specifics.
>>
>>     Sent from my phone
>>
>>     On Sep 5, 2012 7:05 AM, "oleksandr otenko"
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         Even more interesting:
>>
>>         A does B, then C, then D. Interrupt during C. Now if we
>>         cancel A in its entirety, how do we cancel B after it
>>         finished? (eg return an element to FIFO queue in the same
>>         position?..) Since C is agnostic of the context, how can it
>>         ignore interruption (if we can't cancel B, and can't complete
>>         D without C, then C shouldn't cancel upon interruption)
>>
>>         Alex
>>
>>         On 05/09/2012 11:25, oleksandr otenko wrote:
>>>         I guess the problem is similar to rolling back in presence
>>>         of nested transactions. Suppose, A does B, then C. If you
>>>         interrupt during B, do you mean to "rollback" just B, or A
>>>         in its entirety? What you are saying looks more like "A in
>>>         its entirety".
>>>
>>>         Alex
>>>
>>>
>>>         On 05/09/2012 11:12, David Holmes wrote:
>>>>         That is why interrupt generally can't be given a special
>>>>         meaning. You have to interpret it as a general cancellation
>>>>         request unless you have full knowledge of the execution
>>>>         stack. If your "cancellation" response is to ignore the
>>>>         request then you've made your code incompatible with all
>>>>         other code in the execution stack that wants to be actually
>>>>         cancelled. Hence the basic responses to IE are to either
>>>>         propagate it, or consume it and re-assert the interrupt
>>>>         state. It is a cooperative cancellation protocol.
>>>>         David
>>>>         -----Original Message-----
>>>>         *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>>>>         *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>>         *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>         *Cc:* David Holmes; Kirk Pepperdine;
>>>>         concurrency-interest at cs.oswego.edu
>>>>         <mailto:concurrency-interest at cs.oswego.edu>
>>>>         *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>         Interruption afternotification
>>>>
>>>>             But how can one tell who was meant to be cancelled?
>>>>
>>>>             Since there is no requirement on the semantics of what
>>>>             a cancel operation might be, I can define my cancel
>>>>             operation as "stop waiting, think again, then maybe
>>>>             enter the same wait". So the effect is I consumed the
>>>>             IE and didn't even re-trigger it.
>>>>
>>>>             I guess we can't define strictly what a good way of
>>>>             dealing with IE is, since it is like a "last resort" to
>>>>             unblock a wait, which can offer "the best effort"
>>>>             semantics.
>>>>
>>>>             Alex
>>>>
>>>>             On 05/09/2012 04:43, David Holmes wrote:
>>>>>             In your applications you can do what you like. If you
>>>>>             are a library writer (which in simplest terms means
>>>>>             you write a class for others to use) then you need to
>>>>>             follow the rule else you will break any application
>>>>>             that uses your library and which does care about
>>>>>             cancellation.
>>>>>             David
>>>>>
>>>>>                 -----Original Message-----
>>>>>                 *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>>>>                 *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>>>                 *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>                 *Cc:* Vitaly Davidovich; Zhong Yu;
>>>>>                 concurrency-interest at cs.oswego.edu
>>>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>                 *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>>                 Interruption afternotification
>>>>>
>>>>>
>>>>>                 On 2012-09-05, at 4:35 AM, David Holmes
>>>>>                 <davidcholmes at aapt.net.au
>>>>>                 <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>
>>>>>>                 Typically you either define an API that
>>>>>>                 inherently reflects the potential blocking nature
>>>>>>                 of the operation and supports cancellation, or
>>>>>>                 the blocking operation is just an implementation
>>>>>>                 detail. In the former case you will declare that
>>>>>>                 you throw IE and throw it; in the latter you
>>>>>>                 won't declare IE and so can't throw it but must
>>>>>>                 re-interrupt the thread. (Golden rule is to never
>>>>>>                 swallow an interrupt.)
>>>>>
>>>>>                 Sorry but the golden rule is, he who has the gold
>>>>>                 makes the rules. ;-) The IE is the *only*
>>>>>                 exception that I eat on a fairly regular basis.
>>>>>                 Why? Because there is nothing to be done and no
>>>>>                 point to propagate (which is different than I
>>>>>                 don't know how to react so I should re-throw).
>>>>>                 Cancelation scenarios are about the only times
>>>>>                 I'll not eat an IE.
>>>>>
>>>>>                 Kirk
>>>>>
>>>>>>                 Again cancellation techniques and options are
>>>>>>                 well covered in CPJ and JCiP.
>>>>>>                 David
>>>>>>
>>>>>>                     -----Original Message-----
>>>>>>                     *From:* Vitaly Davidovich
>>>>>>                     [mailto:vitalyd at gmail.com <http://gmail.com>]
>>>>>>                     *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>>>>                     *To:* Zhong Yu
>>>>>>                     *Cc:* dholmes at ieee.org
>>>>>>                     <mailto:dholmes at ieee.org>;
>>>>>>                     concurrency-interest at cs.oswego.edu
>>>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                     *Subject:* Re: [concurrency-interest]
>>>>>>                     Subject: Re: Interruption afternotification
>>>>>>
>>>>>>                     I think typically you catch IE, do whatever
>>>>>>                     cleanup and rethrow it rather than
>>>>>>                     reinterrupting the thread (unless you're at a
>>>>>>                     point where handling it makes sense).  If you
>>>>>>                     simply reinterrupt, you effectively delay (or
>>>>>>                     lose) the interrupt delivery to the caller.
>>>>>>
>>>>>>                     Sent from my phone
>>>>>>
>>>>>>                     On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>>>>                     <zhong.j.yu at gmail.com
>>>>>>                     <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>>
>>>>>>                         On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
>>>>>>                         <zhong.j.yu at gmail.com
>>>>>>                         <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>>                         > On Tue, Sep 4, 2012 at 5:37 PM, David
>>>>>>                         Holmes <davidcholmes at aapt.net.au
>>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>                         >> The JLS doesn't say anything about
>>>>>>                         what applications should do. All the
>>>>>>                         >> application knows when the IE is
>>>>>>                         thrown is that the thread was interrupted
>>>>>>                         >> and the interrupt state is now clear.
>>>>>>                         It is up to the application to respond
>>>>>>                         >> to the interruption in an appropriate
>>>>>>                         manner.
>>>>>>                         >
>>>>>>                         > I'm also unsure about the use of
>>>>>>                         interruption in real world.
>>>>>>                         >
>>>>>>                         > In simple cases, the interrupt-er and
>>>>>>                         the interrupt-ee can assign any
>>>>>>                         > special meaning to interruptions. But
>>>>>>                         they can also instead use an
>>>>>>                         > explicit variable to transmit the
>>>>>>                         meaning; interruption doesn't offer
>>>>>>                         > a lot of value here.
>>>>>>                         >
>>>>>>                         > In more complex applications, it's hard
>>>>>>                         for interrupt-er to know which
>>>>>>                         > piece of code the interrupt-ee is
>>>>>>                         running at the moment; it's unlikely
>>>>>>                         > that interruption can be used to
>>>>>>                         deliver special meanings.
>>>>>>                         > Interruption can only have 1 meaning
>>>>>>                         universally accepted by all,
>>>>>>                         > which is probably "stop everything and
>>>>>>                         quit the thread"
>>>>>>                         >
>>>>>>                         > To achieve that, interruptions need to
>>>>>>                         propagate up, therefore pretty
>>>>>>                         > much all method signatures will be
>>>>>>                         polluted by InterruptedException.
>>>>>>
>>>>>>                         This is incorrect. A method doesn't have
>>>>>>                         to propagate
>>>>>>                         InterruptedException in this case; it can
>>>>>>                         re-interrupt the current
>>>>>>                         thread, then return normally, leaving the
>>>>>>                         caller to discover and
>>>>>>                         handle the interruption.
>>>>>>
>>>>>>                         > We don't see that in practice.
>>>>>>                         >
>>>>>>                         > Or an application will simply restrain
>>>>>>                         from using interruption at all,
>>>>>>                         > since it doesn't know how to handle it.
>>>>>>                         Then all InterruptedExceptions
>>>>>>                         > can be ignored anywhere in the
>>>>>>                         application code.
>>>>>>                         >
>>>>>>                         >
>>>>>>                         > Zhong Yu
>>>>>>                         >
>>>>>>                         >
>>>>>>                         >>
>>>>>>                         >> David
>>>>>>                         >>
>>>>>>                         >> -----Original Message-----
>>>>>>                         >> From:
>>>>>>                         concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>                         >>
>>>>>>                         [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>                         <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>>                         Behalf Of oleksandr
>>>>>>                         >> otenko
>>>>>>                         >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>>>                         >> To: Vitaly Davidovich
>>>>>>                         >> Cc: concurrency-interest at cs.oswego.edu
>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                         >> Subject: Re: [concurrency-interest]
>>>>>>                         Subject: Re: Interruption
>>>>>>                         >> afternotification
>>>>>>                         >>
>>>>>>                         >> If these two events arrive
>>>>>>                         concurrently, there is no ordering
>>>>>>                         between them.
>>>>>>                         >> So preferring interruption over
>>>>>>                         notification doesn't change the correctness.
>>>>>>                         >>
>>>>>>                         >> Does JLS specify what the application
>>>>>>                         _should_ do upon receiving
>>>>>>                         >> InterruptedException?
>>>>>>                         >>
>>>>>>                         >> Alex
>>>>>>                         >>
>>>>>>                         >>
>>>>>>                         >> On 04/09/2012 18:35, Vitaly Davidovich
>>>>>>                         wrote:
>>>>>>                         >>
>>>>>>                         >> Dave,
>>>>>>                         >>
>>>>>>                         >> I can see why one may want to leave
>>>>>>                         interrupt pending (thread may complete
>>>>>>                         >> without checking interrupt status) but
>>>>>>                         I can also see an argument in favor
>>>>>>                         >> of delivering the interrupt in such a
>>>>>>                         case (I.e. deliver the "inevitable"
>>>>>>                         >> sooner, assuming thread will notice
>>>>>>                         the interrupt soon thereafter).
>>>>>>                         >>
>>>>>>                         >> So just curious - what's the rationale
>>>>>>                         for choosing notification over
>>>>>>                         >> interrupt here?
>>>>>>                         >>
>>>>>>                         >> Thanks
>>>>>>                         >>
>>>>>>                         >> Sent from my phone
>>>>>>                         >>
>>>>>>                         >> On Sep 4, 2012 1:10 PM, "David Dice"
>>>>>>                         <david.dice at gmail.com
>>>>>>                         <mailto:david.dice at gmail.com>> wrote:
>>>>>>                         >>>
>>>>>>                         >>> As an aside, in the current
>>>>>>                         implementation in hotspot if we have a both a
>>>>>>                         >>> pending notification and interrupt,
>>>>>>                         we return from wait() leaving the
>>>>>>                         >>> interrupt pending.
>>>>>>                         >>>
>>>>>>                         >>> Dave
>>>>>>                         >>> https://blogs.oracle.com/dave/
>>>>>>                         >>>
>>>>>>                         >>>
>>>>>>                         >>>
>>>>>>                         >>>
>>>>>>                         _______________________________________________
>>>>>>                         >>> Concurrency-interest mailing list
>>>>>>                         >>> Concurrency-interest at cs.oswego.edu
>>>>>>                         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                         >>>
>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>                         >>>
>>>>>>                         >>
>>>>>>                         >>
>>>>>>                         >>
>>>>>>                         _______________________________________________
>>>>>>                         >> Concurrency-interest mailing list
>>>>>>                         >> Concurrency-interest at cs.oswego.edu
>>>>>>                         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                         >>
>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>                         >>
>>>>>>                         >>
>>>>>>                         >>
>>>>>>                         _______________________________________________
>>>>>>                         >> Concurrency-interest mailing list
>>>>>>                         >> Concurrency-interest at cs.oswego.edu
>>>>>>                         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                         >>
>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>                         >>
>>>>>>                         _______________________________________________
>>>>>>                         Concurrency-interest mailing list
>>>>>>                         Concurrency-interest at cs.oswego.edu
>>>>>>                         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>                 _______________________________________________
>>>>>>                 Concurrency-interest mailing list
>>>>>>                 Concurrency-interest at cs.oswego.edu
>>>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>>             _______________________________________________
>>>>>             Concurrency-interest mailing list
>>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/69aee78f/attachment-0001.html>

From jacyg at alumni.rice.edu  Wed Sep  5 12:09:24 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Wed, 5 Sep 2012 11:09:24 -0500
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <5047764C.6020305@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
Message-ID: <CAESiqErixwPXcgMNMB-ER1QMSidD9MPZjqa1Da10255PtnEs4g@mail.gmail.com>

I suppose one way to reduce ambiguity would be to be able to pass an
optional value as part of doing the interrupt, handlers could check
for the optional value and determine if the interrupt is intended to
be handled by them or not?  I do think it's a reasonable use case.
Library A has multiple resources it can use, sometimes a resource
blocks, separate monitor thread interrupts to tell it to switch to a
different resource.  Library A is used by B, which wants to get
interrupts in order to do a graceful shutdown of the thread, but may
not if A is handling them and using them for a different purpose.

On Wed, Sep 5, 2012 at 10:57 AM, oleksandr otenko
<oleksandr.otenko at oracle.com> wrote:
> Not sure what a concrete example is. For C to be safely redoable, all
> transitions performed by C, including a cancellation upon IE, must form a
> group - that is, for each state transition there is a way to revert it. I
> don't see how an arbitrary computation C can be turned into a group by A -
> how the reversing of the state can be done by A without knowing how C does
> it.
>
> Suppose, A cannot afford to drop requests, unless the connection is lost (in
> which case all of other concurrent requests will be dropped - there is a
> guarantee the later requests cannot be observed complete). B computed a part
> of response, and that is passed to C. C decides to set response flag to
> error and rethrow IE. We cannot safely redo from A, unless there is a way to
> revert the state of the response object.
>
> Yes, C should have thought of a possible vetoing / cancellation of the
> cancellation by the caller. Or the interruption API should have thought of a
> way to disable interruptions during C by A.
>
> Alex
>
> On 05/09/2012 15:42, Vitaly Davidovich wrote:
>
> If C can be interrupted or is interrupt aware, then it encapsulates what
> happens when it detects/receives cancellation.  If there are
> user-configurable options then C's API should allow for that and then A
> configures C appropriately.
>
> I think it would be more useful if we can take some concrete/real example
> and dissect it.
>
> Sent from my phone
>
> On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
> wrote:
>>
>> It doesn't just depend on API. If A can't tell C to ignore the interrupts,
>> then it will always cancel, and A needs to... redo? Then C needs to support
>> a redo. (But how do you redo, for example, a closed connection)
>>
>> I am poking to see if there are valid cases when cancelling lower layer
>> without upper layer's permission is a destructive state transition. Then the
>> lower layer - the library - should somehow take these things into account.
>> Is there further guidance on this?
>>
>> Alex
>>
>> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>
>> This will depend on your use case/API really as to what interruption
>> actually entails - hard to generalize.  All your code knows is that if it's
>> interrupted, some other code has decided to cancel the operation across the
>> stack of calls - what each call frame does in this case depends on
>> specifics.
>>
>> Sent from my phone
>>
>> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>> wrote:
>>>
>>> Even more interesting:
>>>
>>> A does B, then C, then D. Interrupt during C. Now if we cancel A in its
>>> entirety, how do we cancel B after it finished? (eg return an element to
>>> FIFO queue in the same position?..) Since C is agnostic of the context, how
>>> can it ignore interruption (if we can't cancel B, and can't complete D
>>> without C, then C shouldn't cancel upon interruption)
>>>
>>> Alex
>>>
>>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>>
>>> I guess the problem is similar to rolling back in presence of nested
>>> transactions. Suppose, A does B, then C. If you interrupt during B, do you
>>> mean to "rollback" just B, or A in its entirety? What you are saying looks
>>> more like "A in its entirety".
>>>
>>> Alex
>>>
>>>
>>> On 05/09/2012 11:12, David Holmes wrote:
>>>
>>> That is why interrupt generally can't be given a special meaning. You
>>> have to interpret it as a general cancellation request unless you have full
>>> knowledge of the execution stack. If your "cancellation" response is to
>>> ignore the request then you've made your code incompatible with all other
>>> code in the execution stack that wants to be actually cancelled. Hence the
>>> basic responses to IE are to either propagate it, or consume it and
>>> re-assert the interrupt state. It is a cooperative cancellation protocol.
>>>
>>> David
>>>
>>>  -----Original Message-----
>>> From: oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>>> Sent: Wednesday, 5 September 2012 8:03 PM
>>> To: dholmes at ieee.org
>>> Cc: David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>> But how can one tell who was meant to be cancelled?
>>>
>>> Since there is no requirement on the semantics of what a cancel operation
>>> might be, I can define my cancel operation as "stop waiting, think again,
>>> then maybe enter the same wait". So the effect is I consumed the IE and
>>> didn't even re-trigger it.
>>>
>>> I guess we can't define strictly what a good way of dealing with IE is,
>>> since it is like a "last resort" to unblock a wait, which can offer "the
>>> best effort" semantics.
>>>
>>> Alex
>>>
>>> On 05/09/2012 04:43, David Holmes wrote:
>>>
>>> In your applications you can do what you like. If you are a library
>>> writer (which in simplest terms means you write a class for others to use)
>>> then you need to follow the rule else you will break any application that
>>> uses your library and which does care about cancellation.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>> Sent: Wednesday, 5 September 2012 1:38 PM
>>> To: dholmes at ieee.org
>>> Cc: Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>>
>>> On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>
>>> Typically you either define an API that inherently reflects the potential
>>> blocking nature of the operation and supports cancellation, or the blocking
>>> operation is just an implementation detail. In the former case you will
>>> declare that you throw IE and throw it; in the latter you won't declare IE
>>> and so can't throw it but must re-interrupt the thread. (Golden rule is to
>>> never swallow an interrupt.)
>>>
>>>
>>> Sorry but the golden rule is, he who has the gold makes the rules. ;-)
>>> The IE is the *only* exception that I eat on a fairly regular basis. Why?
>>> Because there is nothing to be done and no point to propagate (which is
>>> different than I don't know how to react so I should re-throw). Cancelation
>>> scenarios are about the only times I'll not eat an IE.
>>>
>>> Kirk
>>>
>>>
>>> Again cancellation techniques and options are well covered in CPJ and
>>> JCiP.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
>>> Sent: Wednesday, 5 September 2012 12:29 PM
>>> To: Zhong Yu
>>> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>> I think typically you catch IE, do whatever cleanup and rethrow it rather
>>> than reinterrupting the thread (unless you're at a point where handling it
>>> makes sense).  If you simply reinterrupt, you effectively delay (or lose)
>>> the interrupt delivery to the caller.
>>>
>>> Sent from my phone
>>>
>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>>
>>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes
>>>> > <davidcholmes at aapt.net.au> wrote:
>>>> >> The JLS doesn't say anything about what applications should do. All
>>>> >> the
>>>> >> application knows when the IE is thrown is that the thread was
>>>> >> interrupted
>>>> >> and the interrupt state is now clear. It is up to the application to
>>>> >> respond
>>>> >> to the interruption in an appropriate manner.
>>>> >
>>>> > I'm also unsure about the use of interruption in real world.
>>>> >
>>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>>> > special meaning to interruptions. But they can also instead use an
>>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>>> > a lot of value here.
>>>> >
>>>> > In more complex applications, it's hard for interrupt-er to know which
>>>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>>>> > that interruption can be used to deliver special meanings.
>>>> > Interruption can only have 1 meaning universally accepted by all,
>>>> > which is probably "stop everything and quit the thread"
>>>> >
>>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>>> > much all method signatures will be polluted by InterruptedException.
>>>>
>>>> This is incorrect. A method doesn't have to propagate
>>>> InterruptedException in this case; it can re-interrupt the current
>>>> thread, then return normally, leaving the caller to discover and
>>>> handle the interruption.
>>>>
>>>> > We don't see that in practice.
>>>> >
>>>> > Or an application will simply restrain from using interruption at all,
>>>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>>>> > can be ignored anywhere in the application code.
>>>> >
>>>> >
>>>> > Zhong Yu
>>>> >
>>>> >
>>>> >>
>>>> >> David
>>>> >>
>>>> >> -----Original Message-----
>>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>>> >> oleksandr
>>>> >> otenko
>>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>> >> To: Vitaly Davidovich
>>>> >> Cc: concurrency-interest at cs.oswego.edu
>>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>>> >> afternotification
>>>> >>
>>>> >> If these two events arrive concurrently, there is no ordering between
>>>> >> them.
>>>> >> So preferring interruption over notification doesn't change the
>>>> >> correctness.
>>>> >>
>>>> >> Does JLS specify what the application _should_ do upon receiving
>>>> >> InterruptedException?
>>>> >>
>>>> >> Alex
>>>> >>
>>>> >>
>>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>> >>
>>>> >> Dave,
>>>> >>
>>>> >> I can see why one may want to leave interrupt pending (thread may
>>>> >> complete
>>>> >> without checking interrupt status) but I can also see an argument in
>>>> >> favor
>>>> >> of delivering the interrupt in such a case (I.e. deliver the
>>>> >> "inevitable"
>>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>>> >>
>>>> >> So just curious - what's the rationale for choosing notification over
>>>> >> interrupt here?
>>>> >>
>>>> >> Thanks
>>>> >>
>>>> >> Sent from my phone
>>>> >>
>>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>> >>>
>>>> >>> As an aside, in the current implementation in hotspot if we have a
>>>> >>> both a
>>>> >>> pending notification and interrupt, we return from wait() leaving
>>>> >>> the
>>>> >>> interrupt pending.
>>>> >>>
>>>> >>> Dave
>>>> >>> https://blogs.oracle.com/dave/
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>> _______________________________________________
>>>> >>> Concurrency-interest mailing list
>>>> >>> Concurrency-interest at cs.oswego.edu
>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>>
>>>> >>
>>>> >>
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> >>
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From vitalyd at gmail.com  Wed Sep  5 12:40:54 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 5 Sep 2012 12:40:54 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <5047764C.6020305@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
Message-ID: <CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>

Suppose you were doing this via some other cooperative cancellation scheme
(e.g. set flag) - how would that work better?

If you need transactional support of sorts then you need to handle state
transitions one way or another, irrespective of how cancellation is
implemented.  I'm failing to see how IE makes this more difficult.

Sent from my phone
On Sep 5, 2012 11:57 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
wrote:

>  Not sure what a concrete example is. For C to be safely redoable, all
> transitions performed by C, including a cancellation upon IE, must form a
> group - that is, for each state transition there is a way to revert it. I
> don't see how an arbitrary computation C can be turned into a group by A -
> how the reversing of the state can be done by A without knowing how C does
> it.
>
> Suppose, A cannot afford to drop requests, unless the connection is lost
> (in which case all of other concurrent requests will be dropped - there is
> a guarantee the later requests cannot be observed complete). B computed a
> part of response, and that is passed to C. C decides to set response flag
> to error and rethrow IE. We cannot safely redo from A, unless there is a
> way to revert the state of the response object.
>
> Yes, C should have thought of a possible vetoing / cancellation of the
> cancellation by the caller. Or the interruption API should have thought of
> a way to disable interruptions during C by A.
>
> Alex
>
> On 05/09/2012 15:42, Vitaly Davidovich wrote:
>
> If C can be interrupted or is interrupt aware, then it encapsulates what
> happens when it detects/receives cancellation.  If there are
> user-configurable options then C's API should allow for that and then A
> configures C appropriately.
>
> I think it would be more useful if we can take some concrete/real example
> and dissect it.
>
>  Sent from my phone
> On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
> wrote:
>
>>  It doesn't just depend on API. If A can't tell C to ignore the
>> interrupts, then it will always cancel, and A needs to... redo? Then C
>> needs to support a redo. (But how do you redo, for example, a closed
>> connection)
>>
>> I am poking to see if there are valid cases when cancelling lower layer
>> without upper layer's permission is a destructive state transition. Then
>> the lower layer - the library - should somehow take these things into
>> account. Is there further guidance on this?
>>
>> Alex
>>
>> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>
>> This will depend on your use case/API really as to what interruption
>> actually entails - hard to generalize.  All your code knows is that if it's
>> interrupted, some other code has decided to cancel the operation across the
>> stack of calls - what each call frame does in this case depends on
>> specifics.
>>
>> Sent from my phone
>> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>> wrote:
>>
>>>  Even more interesting:
>>>
>>> A does B, then C, then D. Interrupt during C. Now if we cancel A in its
>>> entirety, how do we cancel B after it finished? (eg return an element to
>>> FIFO queue in the same position?..) Since C is agnostic of the context, how
>>> can it ignore interruption (if we can't cancel B, and can't complete D
>>> without C, then C shouldn't cancel upon interruption)
>>>
>>> Alex
>>>
>>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>>
>>> I guess the problem is similar to rolling back in presence of nested
>>> transactions. Suppose, A does B, then C. If you interrupt during B, do you
>>> mean to "rollback" just B, or A in its entirety? What you are saying looks
>>> more like "A in its entirety".
>>>
>>> Alex
>>>
>>>
>>> On 05/09/2012 11:12, David Holmes wrote:
>>>
>>> That is why interrupt generally can't be given a special meaning. You
>>> have to interpret it as a general cancellation request unless you have full
>>> knowledge of the execution stack. If your "cancellation" response is to
>>> ignore the request then you've made your code incompatible with all other
>>> code in the execution stack that wants to be actually cancelled. Hence the
>>> basic responses to IE are to either propagate it, or consume it and
>>> re-assert the interrupt state. It is a cooperative cancellation protocol.
>>>
>>> David
>>>
>>>  -----Original Message-----
>>> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com<oleksandr.otenko at oracle.com>
>>> ]
>>> *Sent:* Wednesday, 5 September 2012 8:03 PM
>>> *To:* dholmes at ieee.org
>>> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>>  But how can one tell who was meant to be cancelled?
>>>
>>> Since there is no requirement on the semantics of what a cancel
>>> operation might be, I can define my cancel operation as "stop waiting,
>>> think again, then maybe enter the same wait". So the effect is I consumed
>>> the IE and didn't even re-trigger it.
>>>
>>> I guess we can't define strictly what a good way of dealing with IE is,
>>> since it is like a "last resort" to unblock a wait, which can offer "the
>>> best effort" semantics.
>>>
>>> Alex
>>>
>>> On 05/09/2012 04:43, David Holmes wrote:
>>>
>>> In your applications you can do what you like. If you are a library
>>> writer (which in simplest terms means you write a class for others to use)
>>> then you need to follow the rule else you will break any application that
>>> uses your library and which does care about cancellation.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
>>> *Sent:* Wednesday, 5 September 2012 1:38 PM
>>> *To:* dholmes at ieee.org
>>> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>>
>>>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au>
>>> wrote:
>>>
>>>  Typically you either define an API that inherently reflects the
>>> potential blocking nature of the operation and supports cancellation, or
>>> the blocking operation is just an implementation detail. In the former case
>>> you will declare that you throw IE and throw it; in the latter you won't
>>> declare IE and so can't throw it but must re-interrupt the thread. (Golden
>>> rule is to never swallow an interrupt.)
>>>
>>>
>>>  Sorry but the golden rule is, he who has the gold makes the rules. ;-)
>>> The IE is the *only* exception that I eat on a fairly regular basis. Why?
>>> Because there is nothing to be done and no point to propagate (which is
>>> different than I don't know how to react so I should re-throw). Cancelation
>>> scenarios are about the only times I'll not eat an IE.
>>>
>>>  Kirk
>>>
>>>
>>> Again cancellation techniques and options are well covered in CPJ and
>>> JCiP.
>>>
>>> David
>>>
>>> -----Original Message-----
>>> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
>>> *Sent:* Wednesday, 5 September 2012 12:29 PM
>>> *To:* Zhong Yu
>>> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>> afternotification
>>>
>>>  I think typically you catch IE, do whatever cleanup and rethrow it
>>> rather than reinterrupting the thread (unless you're at a point where
>>> handling it makes sense).  If you simply reinterrupt, you effectively delay
>>> (or lose) the interrupt delivery to the caller.
>>>
>>> Sent from my phone
>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>
>>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <
>>>> davidcholmes at aapt.net.au> wrote:
>>>> >> The JLS doesn't say anything about what applications should do. All
>>>> the
>>>> >> application knows when the IE is thrown is that the thread was
>>>> interrupted
>>>> >> and the interrupt state is now clear. It is up to the application to
>>>> respond
>>>> >> to the interruption in an appropriate manner.
>>>> >
>>>> > I'm also unsure about the use of interruption in real world.
>>>> >
>>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>>> > special meaning to interruptions. But they can also instead use an
>>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>>> > a lot of value here.
>>>> >
>>>> > In more complex applications, it's hard for interrupt-er to know which
>>>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>>>> > that interruption can be used to deliver special meanings.
>>>> > Interruption can only have 1 meaning universally accepted by all,
>>>> > which is probably "stop everything and quit the thread"
>>>> >
>>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>>> > much all method signatures will be polluted by InterruptedException.
>>>>
>>>> This is incorrect. A method doesn't have to propagate
>>>> InterruptedException in this case; it can re-interrupt the current
>>>> thread, then return normally, leaving the caller to discover and
>>>> handle the interruption.
>>>>
>>>> > We don't see that in practice.
>>>> >
>>>> > Or an application will simply restrain from using interruption at all,
>>>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>>>> > can be ignored anywhere in the application code.
>>>> >
>>>> >
>>>> > Zhong Yu
>>>> >
>>>> >
>>>> >>
>>>> >> David
>>>> >>
>>>> >> -----Original Message-----
>>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>>> oleksandr
>>>> >> otenko
>>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>> >> To: Vitaly Davidovich
>>>> >> Cc: concurrency-interest at cs.oswego.edu
>>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>>> >> afternotification
>>>> >>
>>>> >> If these two events arrive concurrently, there is no ordering
>>>> between them.
>>>> >> So preferring interruption over notification doesn't change the
>>>> correctness.
>>>> >>
>>>> >> Does JLS specify what the application _should_ do upon receiving
>>>> >> InterruptedException?
>>>> >>
>>>> >> Alex
>>>> >>
>>>> >>
>>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>> >>
>>>> >> Dave,
>>>> >>
>>>> >> I can see why one may want to leave interrupt pending (thread may
>>>> complete
>>>> >> without checking interrupt status) but I can also see an argument in
>>>> favor
>>>> >> of delivering the interrupt in such a case (I.e. deliver the
>>>> "inevitable"
>>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>>> >>
>>>> >> So just curious - what's the rationale for choosing notification over
>>>> >> interrupt here?
>>>> >>
>>>> >> Thanks
>>>> >>
>>>> >> Sent from my phone
>>>> >>
>>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>> >>>
>>>> >>> As an aside, in the current implementation in hotspot if we have a
>>>> both a
>>>> >>> pending notification and interrupt, we return from wait() leaving
>>>> the
>>>> >>> interrupt pending.
>>>> >>>
>>>> >>> Dave
>>>> >>> https://blogs.oracle.com/dave/
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>> _______________________________________________
>>>> >>> Concurrency-interest mailing list
>>>> >>> Concurrency-interest at cs.oswego.edu
>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>>
>>>> >>
>>>> >>
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> >>
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>   _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/774e60f1/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 13:59:36 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 18:59:36 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
	<CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
Message-ID: <50479308.3020000@oracle.com>

If cancellations are disabled in the callee code, there is no state 
transition to think about.

If cancellations are always a possibility, the callee needs to address 
this possible state transition (a redo as a possible consequence, I 
mean). Maybe this is made explicit in some guide notes, just I am not 
looking in the right place.


Alex


On 05/09/2012 17:40, Vitaly Davidovich wrote:
>
> Suppose you were doing this via some other cooperative cancellation 
> scheme (e.g. set flag) - how would that work better?
>
> If you need transactional support of sorts then you need to handle 
> state transitions one way or another, irrespective of how cancellation 
> is implemented.  I'm failing to see how IE makes this more difficult.
>
> Sent from my phone
>
> On Sep 5, 2012 11:57 AM, "oleksandr otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Not sure what a concrete example is. For C to be safely redoable,
>     all transitions performed by C, including a cancellation upon IE,
>     must form a group - that is, for each state transition there is a
>     way to revert it. I don't see how an arbitrary computation C can
>     be turned into a group by A - how the reversing of the state can
>     be done by A without knowing how C does it.
>
>     Suppose, A cannot afford to drop requests, unless the connection
>     is lost (in which case all of other concurrent requests will be
>     dropped - there is a guarantee the later requests cannot be
>     observed complete). B computed a part of response, and that is
>     passed to C. C decides to set response flag to error and rethrow
>     IE. We cannot safely redo from A, unless there is a way to revert
>     the state of the response object.
>
>     Yes, C should have thought of a possible vetoing / cancellation of
>     the cancellation by the caller. Or the interruption API should
>     have thought of a way to disable interruptions during C by A.
>
>     Alex
>
>     On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>
>>     If C can be interrupted or is interrupt aware, then it
>>     encapsulates what happens when it detects/receives cancellation. 
>>     If there are user-configurable options then C's API should allow
>>     for that and then A configures C appropriately.
>>
>>     I think it would be more useful if we can take some concrete/real
>>     example and dissect it.
>>
>>     Sent from my phone
>>
>>     On Sep 5, 2012 10:37 AM, "oleksandr otenko"
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         It doesn't just depend on API. If A can't tell C to ignore
>>         the interrupts, then it will always cancel, and A needs to...
>>         redo? Then C needs to support a redo. (But how do you redo,
>>         for example, a closed connection)
>>
>>         I am poking to see if there are valid cases when cancelling
>>         lower layer without upper layer's permission is a destructive
>>         state transition. Then the lower layer - the library - should
>>         somehow take these things into account. Is there further
>>         guidance on this?
>>
>>         Alex
>>
>>         On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>
>>>         This will depend on your use case/API really as to what
>>>         interruption actually entails - hard to generalize.  All
>>>         your code knows is that if it's interrupted, some other code
>>>         has decided to cancel the operation across the stack of
>>>         calls - what each call frame does in this case depends on
>>>         specifics.
>>>
>>>         Sent from my phone
>>>
>>>         On Sep 5, 2012 7:05 AM, "oleksandr otenko"
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             Even more interesting:
>>>
>>>             A does B, then C, then D. Interrupt during C. Now if we
>>>             cancel A in its entirety, how do we cancel B after it
>>>             finished? (eg return an element to FIFO queue in the
>>>             same position?..) Since C is agnostic of the context,
>>>             how can it ignore interruption (if we can't cancel B,
>>>             and can't complete D without C, then C shouldn't cancel
>>>             upon interruption)
>>>
>>>             Alex
>>>
>>>             On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>             I guess the problem is similar to rolling back in
>>>>             presence of nested transactions. Suppose, A does B,
>>>>             then C. If you interrupt during B, do you mean to
>>>>             "rollback" just B, or A in its entirety? What you are
>>>>             saying looks more like "A in its entirety".
>>>>
>>>>             Alex
>>>>
>>>>
>>>>             On 05/09/2012 11:12, David Holmes wrote:
>>>>>             That is why interrupt generally can't be given a
>>>>>             special meaning. You have to interpret it as a general
>>>>>             cancellation request unless you have full knowledge of
>>>>>             the execution stack. If your "cancellation" response
>>>>>             is to ignore the request then you've made your code
>>>>>             incompatible with all other code in the execution
>>>>>             stack that wants to be actually cancelled. Hence the
>>>>>             basic responses to IE are to either propagate it, or
>>>>>             consume it and re-assert the interrupt state. It is a
>>>>>             cooperative cancellation protocol.
>>>>>             David
>>>>>             -----Original Message-----
>>>>>             *From:* oleksandr otenko
>>>>>             [mailto:oleksandr.otenko at oracle.com]
>>>>>             *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>>>             *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>             *Cc:* David Holmes; Kirk Pepperdine;
>>>>>             concurrency-interest at cs.oswego.edu
>>>>>             <mailto:concurrency-interest at cs.oswego.edu>
>>>>>             *Subject:* Re: [concurrency-interest] Subject: Re:
>>>>>             Interruption afternotification
>>>>>
>>>>>                 But how can one tell who was meant to be cancelled?
>>>>>
>>>>>                 Since there is no requirement on the semantics of
>>>>>                 what a cancel operation might be, I can define my
>>>>>                 cancel operation as "stop waiting, think again,
>>>>>                 then maybe enter the same wait". So the effect is
>>>>>                 I consumed the IE and didn't even re-trigger it.
>>>>>
>>>>>                 I guess we can't define strictly what a good way
>>>>>                 of dealing with IE is, since it is like a "last
>>>>>                 resort" to unblock a wait, which can offer "the
>>>>>                 best effort" semantics.
>>>>>
>>>>>                 Alex
>>>>>
>>>>>                 On 05/09/2012 04:43, David Holmes wrote:
>>>>>>                 In your applications you can do what you like. If
>>>>>>                 you are a library writer (which in simplest terms
>>>>>>                 means you write a class for others to use) then
>>>>>>                 you need to follow the rule else you will break
>>>>>>                 any application that uses your library and which
>>>>>>                 does care about cancellation.
>>>>>>                 David
>>>>>>
>>>>>>                     -----Original Message-----
>>>>>>                     *From:* Kirk Pepperdine
>>>>>>                     [mailto:kirk at kodewerk.com]
>>>>>>                     *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>>>>                     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>                     *Cc:* Vitaly Davidovich; Zhong Yu;
>>>>>>                     concurrency-interest at cs.oswego.edu
>>>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                     *Subject:* Re: [concurrency-interest]
>>>>>>                     Subject: Re: Interruption afternotification
>>>>>>
>>>>>>
>>>>>>                     On 2012-09-05, at 4:35 AM, David Holmes
>>>>>>                     <davidcholmes at aapt.net.au
>>>>>>                     <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>
>>>>>>>                     Typically you either define an API that
>>>>>>>                     inherently reflects the potential blocking
>>>>>>>                     nature of the operation and supports
>>>>>>>                     cancellation, or the blocking operation is
>>>>>>>                     just an implementation detail. In the former
>>>>>>>                     case you will declare that you throw IE and
>>>>>>>                     throw it; in the latter you won't declare IE
>>>>>>>                     and so can't throw it but must re-interrupt
>>>>>>>                     the thread. (Golden rule is to never swallow
>>>>>>>                     an interrupt.)
>>>>>>
>>>>>>                     Sorry but the golden rule is, he who has the
>>>>>>                     gold makes the rules. ;-) The IE is the
>>>>>>                     *only* exception that I eat on a fairly
>>>>>>                     regular basis. Why? Because there is nothing
>>>>>>                     to be done and no point to propagate (which
>>>>>>                     is different than I don't know how to react
>>>>>>                     so I should re-throw). Cancelation scenarios
>>>>>>                     are about the only times I'll not eat an IE.
>>>>>>
>>>>>>                     Kirk
>>>>>>
>>>>>>>                     Again cancellation techniques and options
>>>>>>>                     are well covered in CPJ and JCiP.
>>>>>>>                     David
>>>>>>>
>>>>>>>                         -----Original Message-----
>>>>>>>                         *From:* Vitaly Davidovich
>>>>>>>                         [mailto:vitalyd at gmail.com
>>>>>>>                         <http://gmail.com>]
>>>>>>>                         *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>>>>>                         *To:* Zhong Yu
>>>>>>>                         *Cc:* dholmes at ieee.org
>>>>>>>                         <mailto:dholmes at ieee.org>;
>>>>>>>                         concurrency-interest at cs.oswego.edu
>>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>>>                         Subject: Re: Interruption afternotification
>>>>>>>
>>>>>>>                         I think typically you catch IE, do
>>>>>>>                         whatever cleanup and rethrow it rather
>>>>>>>                         than reinterrupting the thread (unless
>>>>>>>                         you're at a point where handling it
>>>>>>>                         makes sense).  If you simply
>>>>>>>                         reinterrupt, you effectively delay (or
>>>>>>>                         lose) the interrupt delivery to the caller.
>>>>>>>
>>>>>>>                         Sent from my phone
>>>>>>>
>>>>>>>                         On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>>>>>                         <zhong.j.yu at gmail.com
>>>>>>>                         <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>>>
>>>>>>>                             On Tue, Sep 4, 2012 at 7:38 PM,
>>>>>>>                             Zhong Yu <zhong.j.yu at gmail.com
>>>>>>>                             <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>>>                             > On Tue, Sep 4, 2012 at 5:37 PM,
>>>>>>>                             David Holmes
>>>>>>>                             <davidcholmes at aapt.net.au
>>>>>>>                             <mailto:davidcholmes at aapt.net.au>>
>>>>>>>                             wrote:
>>>>>>>                             >> The JLS doesn't say anything
>>>>>>>                             about what applications should do.
>>>>>>>                             All the
>>>>>>>                             >> application knows when the IE is
>>>>>>>                             thrown is that the thread was
>>>>>>>                             interrupted
>>>>>>>                             >> and the interrupt state is now
>>>>>>>                             clear. It is up to the application
>>>>>>>                             to respond
>>>>>>>                             >> to the interruption in an
>>>>>>>                             appropriate manner.
>>>>>>>                             >
>>>>>>>                             > I'm also unsure about the use of
>>>>>>>                             interruption in real world.
>>>>>>>                             >
>>>>>>>                             > In simple cases, the interrupt-er
>>>>>>>                             and the interrupt-ee can assign any
>>>>>>>                             > special meaning to interruptions.
>>>>>>>                             But they can also instead use an
>>>>>>>                             > explicit variable to transmit the
>>>>>>>                             meaning; interruption doesn't offer
>>>>>>>                             > a lot of value here.
>>>>>>>                             >
>>>>>>>                             > In more complex applications, it's
>>>>>>>                             hard for interrupt-er to know which
>>>>>>>                             > piece of code the interrupt-ee is
>>>>>>>                             running at the moment; it's unlikely
>>>>>>>                             > that interruption can be used to
>>>>>>>                             deliver special meanings.
>>>>>>>                             > Interruption can only have 1
>>>>>>>                             meaning universally accepted by all,
>>>>>>>                             > which is probably "stop everything
>>>>>>>                             and quit the thread"
>>>>>>>                             >
>>>>>>>                             > To achieve that, interruptions
>>>>>>>                             need to propagate up, therefore pretty
>>>>>>>                             > much all method signatures will be
>>>>>>>                             polluted by InterruptedException.
>>>>>>>
>>>>>>>                             This is incorrect. A method doesn't
>>>>>>>                             have to propagate
>>>>>>>                             InterruptedException in this case;
>>>>>>>                             it can re-interrupt the current
>>>>>>>                             thread, then return normally,
>>>>>>>                             leaving the caller to discover and
>>>>>>>                             handle the interruption.
>>>>>>>
>>>>>>>                             > We don't see that in practice.
>>>>>>>                             >
>>>>>>>                             > Or an application will simply
>>>>>>>                             restrain from using interruption at all,
>>>>>>>                             > since it doesn't know how to
>>>>>>>                             handle it. Then all
>>>>>>>                             InterruptedExceptions
>>>>>>>                             > can be ignored anywhere in the
>>>>>>>                             application code.
>>>>>>>                             >
>>>>>>>                             >
>>>>>>>                             > Zhong Yu
>>>>>>>                             >
>>>>>>>                             >
>>>>>>>                             >>
>>>>>>>                             >> David
>>>>>>>                             >>
>>>>>>>                             >> -----Original Message-----
>>>>>>>                             >> From:
>>>>>>>                             concurrency-interest-bounces at cs.oswego.edu
>>>>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>                             >>
>>>>>>>                             [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>                             <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>>>                             Behalf Of oleksandr
>>>>>>>                             >> otenko
>>>>>>>                             >> Sent: Wednesday, 5 September 2012
>>>>>>>                             4:43 AM
>>>>>>>                             >> To: Vitaly Davidovich
>>>>>>>                             >> Cc:
>>>>>>>                             concurrency-interest at cs.oswego.edu
>>>>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                             >> Subject: Re:
>>>>>>>                             [concurrency-interest] Subject: Re:
>>>>>>>                             Interruption
>>>>>>>                             >> afternotification
>>>>>>>                             >>
>>>>>>>                             >> If these two events arrive
>>>>>>>                             concurrently, there is no ordering
>>>>>>>                             between them.
>>>>>>>                             >> So preferring interruption over
>>>>>>>                             notification doesn't change the
>>>>>>>                             correctness.
>>>>>>>                             >>
>>>>>>>                             >> Does JLS specify what the
>>>>>>>                             application _should_ do upon receiving
>>>>>>>                             >> InterruptedException?
>>>>>>>                             >>
>>>>>>>                             >> Alex
>>>>>>>                             >>
>>>>>>>                             >>
>>>>>>>                             >> On 04/09/2012 18:35, Vitaly
>>>>>>>                             Davidovich wrote:
>>>>>>>                             >>
>>>>>>>                             >> Dave,
>>>>>>>                             >>
>>>>>>>                             >> I can see why one may want to
>>>>>>>                             leave interrupt pending (thread may
>>>>>>>                             complete
>>>>>>>                             >> without checking interrupt
>>>>>>>                             status) but I can also see an
>>>>>>>                             argument in favor
>>>>>>>                             >> of delivering the interrupt in
>>>>>>>                             such a case (I.e. deliver the
>>>>>>>                             "inevitable"
>>>>>>>                             >> sooner, assuming thread will
>>>>>>>                             notice the interrupt soon thereafter).
>>>>>>>                             >>
>>>>>>>                             >> So just curious - what's the
>>>>>>>                             rationale for choosing notification over
>>>>>>>                             >> interrupt here?
>>>>>>>                             >>
>>>>>>>                             >> Thanks
>>>>>>>                             >>
>>>>>>>                             >> Sent from my phone
>>>>>>>                             >>
>>>>>>>                             >> On Sep 4, 2012 1:10 PM, "David
>>>>>>>                             Dice" <david.dice at gmail.com
>>>>>>>                             <mailto:david.dice at gmail.com>> wrote:
>>>>>>>                             >>>
>>>>>>>                             >>> As an aside, in the current
>>>>>>>                             implementation in hotspot if we have
>>>>>>>                             a both a
>>>>>>>                             >>> pending notification and
>>>>>>>                             interrupt, we return from wait()
>>>>>>>                             leaving the
>>>>>>>                             >>> interrupt pending.
>>>>>>>                             >>>
>>>>>>>                             >>> Dave
>>>>>>>                             >>> https://blogs.oracle.com/dave/
>>>>>>>                             >>>
>>>>>>>                             >>>
>>>>>>>                             >>>
>>>>>>>                             >>>
>>>>>>>                             _______________________________________________
>>>>>>>                             >>> Concurrency-interest mailing list
>>>>>>>                             >>>
>>>>>>>                             Concurrency-interest at cs.oswego.edu
>>>>>>>                             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                             >>>
>>>>>>>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>                             >>>
>>>>>>>                             >>
>>>>>>>                             >>
>>>>>>>                             >>
>>>>>>>                             _______________________________________________
>>>>>>>                             >> Concurrency-interest mailing list
>>>>>>>                             >>
>>>>>>>                             Concurrency-interest at cs.oswego.edu
>>>>>>>                             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                             >>
>>>>>>>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>                             >>
>>>>>>>                             >>
>>>>>>>                             >>
>>>>>>>                             _______________________________________________
>>>>>>>                             >> Concurrency-interest mailing list
>>>>>>>                             >>
>>>>>>>                             Concurrency-interest at cs.oswego.edu
>>>>>>>                             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                             >>
>>>>>>>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>                             >>
>>>>>>>                             _______________________________________________
>>>>>>>                             Concurrency-interest mailing list
>>>>>>>                             Concurrency-interest at cs.oswego.edu
>>>>>>>                             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>                     _______________________________________________
>>>>>>>                     Concurrency-interest mailing list
>>>>>>>                     Concurrency-interest at cs.oswego.edu
>>>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>
>>>>>>
>>>>>>                 _______________________________________________
>>>>>>                 Concurrency-interest mailing list
>>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>>             _______________________________________________
>>>>             Concurrency-interest mailing list
>>>>             Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>             _______________________________________________
>>>             Concurrency-interest mailing list
>>>             Concurrency-interest at cs.oswego.edu
>>>             <mailto:Concurrency-interest at cs.oswego.edu>
>>>             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/4cba2115/attachment-0001.html>

From kirk at kodewerk.com  Wed Sep  5 14:23:43 2012
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Wed, 5 Sep 2012 20:23:43 +0200
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50479308.3020000@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
	<CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
	<50479308.3020000@oracle.com>
Message-ID: <6128C793-6DA8-4676-BC97-B327E082AA23@kodewerk.com>

I think a call back would be a nice to have.

-- Kirk

On 2012-09-05, at 7:59 PM, oleksandr otenko <oleksandr.otenko at oracle.com> wrote:

> If cancellations are disabled in the callee code, there is no state transition to think about.
> 
> If cancellations are always a possibility, the callee needs to address this possible state transition (a redo as a possible consequence, I mean). Maybe this is made explicit in some guide notes, just I am not looking in the right place.
> 
> 
> Alex
> 
> 
> On 05/09/2012 17:40, Vitaly Davidovich wrote:
>> 
>> Suppose you were doing this via some other cooperative cancellation scheme (e.g. set flag) - how would that work better?
>> 
>> If you need transactional support of sorts then you need to handle state transitions one way or another, irrespective of how cancellation is implemented.  I'm failing to see how IE makes this more difficult.
>> 
>> Sent from my phone
>> 
>> On Sep 5, 2012 11:57 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com> wrote:
>> Not sure what a concrete example is. For C to be safely redoable, all transitions performed by C, including a cancellation upon IE, must form a group - that is, for each state transition there is a way to revert it. I don't see how an arbitrary computation C can be turned into a group by A - how the reversing of the state can be done by A without knowing how C does it.
>> 
>> Suppose, A cannot afford to drop requests, unless the connection is lost (in which case all of other concurrent requests will be dropped - there is a guarantee the later requests cannot be observed complete). B computed a part of response, and that is passed to C. C decides to set response flag to error and rethrow IE. We cannot safely redo from A, unless there is a way to revert the state of the response object.
>> 
>> Yes, C should have thought of a possible vetoing / cancellation of the cancellation by the caller. Or the interruption API should have thought of a way to disable interruptions during C by A.
>> 
>> Alex
>> 
>> On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>> 
>>> If C can be interrupted or is interrupt aware, then it encapsulates what happens when it detects/receives cancellation.  If there are user-configurable options then C's API should allow for that and then A configures C appropriately.
>>> 
>>> I think it would be more useful if we can take some concrete/real example and dissect it.
>>> 
>>> Sent from my phone
>>> 
>>> On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com> wrote:
>>> It doesn't just depend on API. If A can't tell C to ignore the interrupts, then it will always cancel, and A needs to... redo? Then C needs to support a redo. (But how do you redo, for example, a closed connection)
>>> 
>>> I am poking to see if there are valid cases when cancelling lower layer without upper layer's permission is a destructive state transition. Then the lower layer - the library - should somehow take these things into account. Is there further guidance on this?
>>> 
>>> Alex
>>> 
>>> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>> 
>>>> This will depend on your use case/API really as to what interruption actually entails - hard to generalize.  All your code knows is that if it's interrupted, some other code has decided to cancel the operation across the stack of calls - what each call frame does in this case depends on specifics.
>>>> 
>>>> Sent from my phone
>>>> 
>>>> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com> wrote:
>>>> Even more interesting:
>>>> 
>>>> A does B, then C, then D. Interrupt during C. Now if we cancel A in its entirety, how do we cancel B after it finished? (eg return an element to FIFO queue in the same position?..) Since C is agnostic of the context, how can it ignore interruption (if we can't cancel B, and can't complete D without C, then C shouldn't cancel upon interruption)
>>>> 
>>>> Alex
>>>> 
>>>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>> 
>>>>> I guess the problem is similar to rolling back in presence of nested transactions. Suppose, A does B, then C. If you interrupt during B, do you mean to "rollback" just B, or A in its entirety? What you are saying looks more like "A in its entirety".
>>>>> 
>>>>> Alex
>>>>> 
>>>>> 
>>>>> On 05/09/2012 11:12, David Holmes wrote:
>>>>>> 
>>>>>> That is why interrupt generally can't be given a special meaning. You have to interpret it as a general cancellation request unless you have full knowledge of the execution stack. If your "cancellation" response is to ignore the request then you've made your code incompatible with all other code in the execution stack that wants to be actually cancelled. Hence the basic responses to IE are to either propagate it, or consume it and re-assert the interrupt state. It is a cooperative cancellation protocol.
>>>>>>  
>>>>>> David
>>>>>>  
>>>>>>  -----Original Message-----
>>>>>> From: oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>>>>>> Sent: Wednesday, 5 September 2012 8:03 PM
>>>>>> To: dholmes at ieee.org
>>>>>> Cc: David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>>>>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
>>>>>> 
>>>>>> But how can one tell who was meant to be cancelled?
>>>>>> 
>>>>>> Since there is no requirement on the semantics of what a cancel operation might be, I can define my cancel operation as "stop waiting, think again, then maybe enter the same wait". So the effect is I consumed the IE and didn't even re-trigger it.
>>>>>> 
>>>>>> I guess we can't define strictly what a good way of dealing with IE is, since it is like a "last resort" to unblock a wait, which can offer "the best effort" semantics.
>>>>>> 
>>>>>> Alex
>>>>>> 
>>>>>> On 05/09/2012 04:43, David Holmes wrote:
>>>>>>> 
>>>>>>> In your applications you can do what you like. If you are a library writer (which in simplest terms means you write a class for others to use) then you need to follow the rule else you will break any application that uses your library and which does care about cancellation.
>>>>>>>  
>>>>>>> David
>>>>>>> -----Original Message-----
>>>>>>> From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
>>>>>>> Sent: Wednesday, 5 September 2012 1:38 PM
>>>>>>> To: dholmes at ieee.org
>>>>>>> Cc: Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>>>>>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
>>>>>>> 
>>>>>>> 
>>>>>>> On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>>> 
>>>>>>>> Typically you either define an API that inherently reflects the potential blocking nature of the operation and supports cancellation, or the blocking operation is just an implementation detail. In the former case you will declare that you throw IE and throw it; in the latter you won't declare IE and so can't throw it but must re-interrupt the thread. (Golden rule is to never swallow an interrupt.)
>>>>>>> 
>>>>>>> Sorry but the golden rule is, he who has the gold makes the rules. ;-) The IE is the *only* exception that I eat on a fairly regular basis. Why? Because there is nothing to be done and no point to propagate (which is different than I don't know how to react so I should re-throw). Cancelation scenarios are about the only times I'll not eat an IE.
>>>>>>> 
>>>>>>> Kirk
>>>>>>> 
>>>>>>>>  
>>>>>>>> Again cancellation techniques and options are well covered in CPJ and JCiP.
>>>>>>>>  
>>>>>>>> David
>>>>>>>> -----Original Message-----
>>>>>>>> From: Vitaly Davidovich [mailto:vitalyd at gmail.com]
>>>>>>>> Sent: Wednesday, 5 September 2012 12:29 PM
>>>>>>>> To: Zhong Yu
>>>>>>>> Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>>>>>>> Subject: Re: [concurrency-interest] Subject: Re: Interruption afternotification
>>>>>>>> 
>>>>>>>> I think typically you catch IE, do whatever cleanup and rethrow it rather than reinterrupting the thread (unless you're at a point where handling it makes sense).  If you simply reinterrupt, you effectively delay (or lose) the interrupt delivery to the caller.
>>>>>>>> 
>>>>>>>> Sent from my phone
>>>>>>>> 
>>>>>>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>>>>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>>>>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <davidcholmes at aapt.net.au> wrote:
>>>>>>>> >> The JLS doesn't say anything about what applications should do. All the
>>>>>>>> >> application knows when the IE is thrown is that the thread was interrupted
>>>>>>>> >> and the interrupt state is now clear. It is up to the application to respond
>>>>>>>> >> to the interruption in an appropriate manner.
>>>>>>>> >
>>>>>>>> > I'm also unsure about the use of interruption in real world.
>>>>>>>> >
>>>>>>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>>>>>>> > special meaning to interruptions. But they can also instead use an
>>>>>>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>>>>>>> > a lot of value here.
>>>>>>>> >
>>>>>>>> > In more complex applications, it's hard for interrupt-er to know which
>>>>>>>> > piece of code the interrupt-ee is running at the moment; it's unlikely
>>>>>>>> > that interruption can be used to deliver special meanings.
>>>>>>>> > Interruption can only have 1 meaning universally accepted by all,
>>>>>>>> > which is probably "stop everything and quit the thread"
>>>>>>>> >
>>>>>>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>>>>>>> > much all method signatures will be polluted by InterruptedException.
>>>>>>>> 
>>>>>>>> This is incorrect. A method doesn't have to propagate
>>>>>>>> InterruptedException in this case; it can re-interrupt the current
>>>>>>>> thread, then return normally, leaving the caller to discover and
>>>>>>>> handle the interruption.
>>>>>>>> 
>>>>>>>> > We don't see that in practice.
>>>>>>>> >
>>>>>>>> > Or an application will simply restrain from using interruption at all,
>>>>>>>> > since it doesn't know how to handle it. Then all InterruptedExceptions
>>>>>>>> > can be ignored anywhere in the application code.
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > Zhong Yu
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >>
>>>>>>>> >> David
>>>>>>>> >>
>>>>>>>> >> -----Original Message-----
>>>>>>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>>>>>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
>>>>>>>> >> otenko
>>>>>>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>>>>> >> To: Vitaly Davidovich
>>>>>>>> >> Cc: concurrency-interest at cs.oswego.edu
>>>>>>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>>>>>>> >> afternotification
>>>>>>>> >>
>>>>>>>> >> If these two events arrive concurrently, there is no ordering between them.
>>>>>>>> >> So preferring interruption over notification doesn't change the correctness.
>>>>>>>> >>
>>>>>>>> >> Does JLS specify what the application _should_ do upon receiving
>>>>>>>> >> InterruptedException?
>>>>>>>> >>
>>>>>>>> >> Alex
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>>>>>> >>
>>>>>>>> >> Dave,
>>>>>>>> >>
>>>>>>>> >> I can see why one may want to leave interrupt pending (thread may complete
>>>>>>>> >> without checking interrupt status) but I can also see an argument in favor
>>>>>>>> >> of delivering the interrupt in such a case (I.e. deliver the "inevitable"
>>>>>>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>>>>>>> >>
>>>>>>>> >> So just curious - what's the rationale for choosing notification over
>>>>>>>> >> interrupt here?
>>>>>>>> >>
>>>>>>>> >> Thanks
>>>>>>>> >>
>>>>>>>> >> Sent from my phone
>>>>>>>> >>
>>>>>>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>>>>>> >>>
>>>>>>>> >>> As an aside, in the current implementation in hotspot if we have a both a
>>>>>>>> >>> pending notification and interrupt, we return from wait() leaving the
>>>>>>>> >>> interrupt pending.
>>>>>>>> >>>
>>>>>>>> >>> Dave
>>>>>>>> >>> https://blogs.oracle.com/dave/
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>> _______________________________________________
>>>>>>>> >>> Concurrency-interest mailing list
>>>>>>>> >>> Concurrency-interest at cs.oswego.edu
>>>>>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> >>>
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >> _______________________________________________
>>>>>>>> >> Concurrency-interest mailing list
>>>>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >> _______________________________________________
>>>>>>>> >> Concurrency-interest mailing list
>>>>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> >>
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/16100e4d/attachment-0001.html>

From vitalyd at gmail.com  Wed Sep  5 15:38:11 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 5 Sep 2012 15:38:11 -0400
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <50479308.3020000@oracle.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
	<CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
	<50479308.3020000@oracle.com>
Message-ID: <CAHjP37Fv08vmWSWCLXj-mUyp-jnDn=yTwBpoPjdMbD-kmK08Ew@mail.gmail.com>

So IE is not an async exception, like say OOMError, which means (a) it's
not always a possibility (someone has to call interrupt()) and (b) if you
want cancellation then you need to use classes that support that (this goes
back to API) - if callee doesn't know what to do with IE and it mutates or
transitions states, then it's not suitable for use.  The bigger issue,
IMHO, in protecting state/invariants is async exceptions, which can truly
happen almost anywhere.

Keep in mind that interruption can simply serve as a flag as well
(Thread.isInterrupted()) - it just so happens that its most useful aspect
is allowing early return from various blocking calls.  I'm not sure if
isInterrupted() entails some overhead (e.g. checking for safepoint), so it
may be slightly less efficient than rolling your own java flag (David or
someone else may know offhand).

Sent from my phone
On Sep 5, 2012 2:00 PM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
wrote:

>  If cancellations are disabled in the callee code, there is no state
> transition to think about.
>
> If cancellations are always a possibility, the callee needs to address
> this possible state transition (a redo as a possible consequence, I mean).
> Maybe this is made explicit in some guide notes, just I am not looking in
> the right place.
>
>
> Alex
>
>
> On 05/09/2012 17:40, Vitaly Davidovich wrote:
>
> Suppose you were doing this via some other cooperative cancellation scheme
> (e.g. set flag) - how would that work better?
>
> If you need transactional support of sorts then you need to handle state
> transitions one way or another, irrespective of how cancellation is
> implemented.  I'm failing to see how IE makes this more difficult.
>
> Sent from my phone
> On Sep 5, 2012 11:57 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
> wrote:
>
>>  Not sure what a concrete example is. For C to be safely redoable, all
>> transitions performed by C, including a cancellation upon IE, must form a
>> group - that is, for each state transition there is a way to revert it. I
>> don't see how an arbitrary computation C can be turned into a group by A -
>> how the reversing of the state can be done by A without knowing how C does
>> it.
>>
>> Suppose, A cannot afford to drop requests, unless the connection is lost
>> (in which case all of other concurrent requests will be dropped - there is
>> a guarantee the later requests cannot be observed complete). B computed a
>> part of response, and that is passed to C. C decides to set response flag
>> to error and rethrow IE. We cannot safely redo from A, unless there is a
>> way to revert the state of the response object.
>>
>> Yes, C should have thought of a possible vetoing / cancellation of the
>> cancellation by the caller. Or the interruption API should have thought of
>> a way to disable interruptions during C by A.
>>
>> Alex
>>
>> On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>
>> If C can be interrupted or is interrupt aware, then it encapsulates what
>> happens when it detects/receives cancellation.  If there are
>> user-configurable options then C's API should allow for that and then A
>> configures C appropriately.
>>
>> I think it would be more useful if we can take some concrete/real example
>> and dissect it.
>>
>>  Sent from my phone
>> On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>> wrote:
>>
>>>  It doesn't just depend on API. If A can't tell C to ignore the
>>> interrupts, then it will always cancel, and A needs to... redo? Then C
>>> needs to support a redo. (But how do you redo, for example, a closed
>>> connection)
>>>
>>> I am poking to see if there are valid cases when cancelling lower layer
>>> without upper layer's permission is a destructive state transition. Then
>>> the lower layer - the library - should somehow take these things into
>>> account. Is there further guidance on this?
>>>
>>> Alex
>>>
>>> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>
>>> This will depend on your use case/API really as to what interruption
>>> actually entails - hard to generalize.  All your code knows is that if it's
>>> interrupted, some other code has decided to cancel the operation across the
>>> stack of calls - what each call frame does in this case depends on
>>> specifics.
>>>
>>> Sent from my phone
>>> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>>> wrote:
>>>
>>>>  Even more interesting:
>>>>
>>>> A does B, then C, then D. Interrupt during C. Now if we cancel A in its
>>>> entirety, how do we cancel B after it finished? (eg return an element to
>>>> FIFO queue in the same position?..) Since C is agnostic of the context, how
>>>> can it ignore interruption (if we can't cancel B, and can't complete D
>>>> without C, then C shouldn't cancel upon interruption)
>>>>
>>>> Alex
>>>>
>>>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>
>>>> I guess the problem is similar to rolling back in presence of nested
>>>> transactions. Suppose, A does B, then C. If you interrupt during B, do you
>>>> mean to "rollback" just B, or A in its entirety? What you are saying looks
>>>> more like "A in its entirety".
>>>>
>>>> Alex
>>>>
>>>>
>>>> On 05/09/2012 11:12, David Holmes wrote:
>>>>
>>>> That is why interrupt generally can't be given a special meaning. You
>>>> have to interpret it as a general cancellation request unless you have full
>>>> knowledge of the execution stack. If your "cancellation" response is to
>>>> ignore the request then you've made your code incompatible with all other
>>>> code in the execution stack that wants to be actually cancelled. Hence the
>>>> basic responses to IE are to either propagate it, or consume it and
>>>> re-assert the interrupt state. It is a cooperative cancellation protocol.
>>>>
>>>> David
>>>>
>>>>  -----Original Message-----
>>>> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com<oleksandr.otenko at oracle.com>
>>>> ]
>>>> *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>> *To:* dholmes at ieee.org
>>>> *Cc:* David Holmes; Kirk Pepperdine; concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>> afternotification
>>>>
>>>>  But how can one tell who was meant to be cancelled?
>>>>
>>>> Since there is no requirement on the semantics of what a cancel
>>>> operation might be, I can define my cancel operation as "stop waiting,
>>>> think again, then maybe enter the same wait". So the effect is I consumed
>>>> the IE and didn't even re-trigger it.
>>>>
>>>> I guess we can't define strictly what a good way of dealing with IE is,
>>>> since it is like a "last resort" to unblock a wait, which can offer "the
>>>> best effort" semantics.
>>>>
>>>> Alex
>>>>
>>>> On 05/09/2012 04:43, David Holmes wrote:
>>>>
>>>> In your applications you can do what you like. If you are a library
>>>> writer (which in simplest terms means you write a class for others to use)
>>>> then you need to follow the rule else you will break any application that
>>>> uses your library and which does care about cancellation.
>>>>
>>>> David
>>>>
>>>> -----Original Message-----
>>>> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
>>>> *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>> *To:* dholmes at ieee.org
>>>> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>> afternotification
>>>>
>>>>
>>>>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au>
>>>> wrote:
>>>>
>>>>  Typically you either define an API that inherently reflects the
>>>> potential blocking nature of the operation and supports cancellation, or
>>>> the blocking operation is just an implementation detail. In the former case
>>>> you will declare that you throw IE and throw it; in the latter you won't
>>>> declare IE and so can't throw it but must re-interrupt the thread. (Golden
>>>> rule is to never swallow an interrupt.)
>>>>
>>>>
>>>>  Sorry but the golden rule is, he who has the gold makes the rules. ;-)
>>>> The IE is the *only* exception that I eat on a fairly regular basis. Why?
>>>> Because there is nothing to be done and no point to propagate (which is
>>>> different than I don't know how to react so I should re-throw). Cancelation
>>>> scenarios are about the only times I'll not eat an IE.
>>>>
>>>>  Kirk
>>>>
>>>>
>>>> Again cancellation techniques and options are well covered in CPJ and
>>>> JCiP.
>>>>
>>>> David
>>>>
>>>> -----Original Message-----
>>>> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
>>>> *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>> *To:* Zhong Yu
>>>> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>> afternotification
>>>>
>>>>  I think typically you catch IE, do whatever cleanup and rethrow it
>>>> rather than reinterrupting the thread (unless you're at a point where
>>>> handling it makes sense).  If you simply reinterrupt, you effectively delay
>>>> (or lose) the interrupt delivery to the caller.
>>>>
>>>> Sent from my phone
>>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>>
>>>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <
>>>>> davidcholmes at aapt.net.au> wrote:
>>>>> >> The JLS doesn't say anything about what applications should do. All
>>>>> the
>>>>> >> application knows when the IE is thrown is that the thread was
>>>>> interrupted
>>>>> >> and the interrupt state is now clear. It is up to the application
>>>>> to respond
>>>>> >> to the interruption in an appropriate manner.
>>>>> >
>>>>> > I'm also unsure about the use of interruption in real world.
>>>>> >
>>>>> > In simple cases, the interrupt-er and the interrupt-ee can assign any
>>>>> > special meaning to interruptions. But they can also instead use an
>>>>> > explicit variable to transmit the meaning; interruption doesn't offer
>>>>> > a lot of value here.
>>>>> >
>>>>> > In more complex applications, it's hard for interrupt-er to know
>>>>> which
>>>>> > piece of code the interrupt-ee is running at the moment; it's
>>>>> unlikely
>>>>> > that interruption can be used to deliver special meanings.
>>>>> > Interruption can only have 1 meaning universally accepted by all,
>>>>> > which is probably "stop everything and quit the thread"
>>>>> >
>>>>> > To achieve that, interruptions need to propagate up, therefore pretty
>>>>> > much all method signatures will be polluted by InterruptedException.
>>>>>
>>>>> This is incorrect. A method doesn't have to propagate
>>>>> InterruptedException in this case; it can re-interrupt the current
>>>>> thread, then return normally, leaving the caller to discover and
>>>>> handle the interruption.
>>>>>
>>>>> > We don't see that in practice.
>>>>> >
>>>>> > Or an application will simply restrain from using interruption at
>>>>> all,
>>>>> > since it doesn't know how to handle it. Then all
>>>>> InterruptedExceptions
>>>>> > can be ignored anywhere in the application code.
>>>>> >
>>>>> >
>>>>> > Zhong Yu
>>>>> >
>>>>> >
>>>>> >>
>>>>> >> David
>>>>> >>
>>>>> >> -----Original Message-----
>>>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>>>> oleksandr
>>>>> >> otenko
>>>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>> >> To: Vitaly Davidovich
>>>>> >> Cc: concurrency-interest at cs.oswego.edu
>>>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>>>> >> afternotification
>>>>> >>
>>>>> >> If these two events arrive concurrently, there is no ordering
>>>>> between them.
>>>>> >> So preferring interruption over notification doesn't change the
>>>>> correctness.
>>>>> >>
>>>>> >> Does JLS specify what the application _should_ do upon receiving
>>>>> >> InterruptedException?
>>>>> >>
>>>>> >> Alex
>>>>> >>
>>>>> >>
>>>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>>> >>
>>>>> >> Dave,
>>>>> >>
>>>>> >> I can see why one may want to leave interrupt pending (thread may
>>>>> complete
>>>>> >> without checking interrupt status) but I can also see an argument
>>>>> in favor
>>>>> >> of delivering the interrupt in such a case (I.e. deliver the
>>>>> "inevitable"
>>>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>>>> >>
>>>>> >> So just curious - what's the rationale for choosing notification
>>>>> over
>>>>> >> interrupt here?
>>>>> >>
>>>>> >> Thanks
>>>>> >>
>>>>> >> Sent from my phone
>>>>> >>
>>>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>>> >>>
>>>>> >>> As an aside, in the current implementation in hotspot if we have a
>>>>> both a
>>>>> >>> pending notification and interrupt, we return from wait() leaving
>>>>> the
>>>>> >>> interrupt pending.
>>>>> >>>
>>>>> >>> Dave
>>>>> >>> https://blogs.oracle.com/dave/
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>> _______________________________________________
>>>>> >>> Concurrency-interest mailing list
>>>>> >>> Concurrency-interest at cs.oswego.edu
>>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> >>>
>>>>> >>
>>>>> >>
>>>>> >> _______________________________________________
>>>>> >> Concurrency-interest mailing list
>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> >>
>>>>> >>
>>>>> >> _______________________________________________
>>>>> >> Concurrency-interest mailing list
>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> >>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>   _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/689c2d28/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Sep  5 15:59:55 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 05 Sep 2012 20:59:55 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37Fv08vmWSWCLXj-mUyp-jnDn=yTwBpoPjdMbD-kmK08Ew@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
	<CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
	<50479308.3020000@oracle.com>
	<CAHjP37Fv08vmWSWCLXj-mUyp-jnDn=yTwBpoPjdMbD-kmK08Ew@mail.gmail.com>
Message-ID: <5047AF3B.7030500@oracle.com>

On 05/09/2012 20:38, Vitaly Davidovich wrote:
>
> So IE is not an async exception, like say OOMError, which means (a) 
> it's not always a possibility (someone has to call interrupt()) and 
> (b) if you want cancellation then you need to use classes that support 
> that (this goes back to API) - if callee doesn't know what to do with 
> IE and it mutates or transitions states, then it's not suitable for 
> use.  The bigger issue, IMHO, in protecting state/invariants is async 
> exceptions, which can truly happen almost anywhere.
>
This interpretation increases the scope of code to be considered. From 
the library writer's point of view interruption is always a possibility.

> Keep in mind that interruption can simply serve as a flag as well 
> (Thread.isInterrupted()) - it just so happens that its most useful 
> aspect is allowing early return from various blocking calls.  I'm not 
> sure if isInterrupted() entails some overhead (e.g. checking for 
> safepoint), so it may be slightly less efficient than rolling your own 
> java flag (David or someone else may know offhand).
>
Yes, and A doesn't want C to bail out sooner, but to keep trundling 
until A completes, because A cannot bail out sooner anyway. Maybe A will 
let someone outside A to pick up the interruption, but not A.

Oh, well. We can write a duplicate method for everything, just like we 
have acquire and acquireNonInterruptibly, and proportionately add 
functional tests and cross-method consistency tests.

Alex


> Sent from my phone
>
> On Sep 5, 2012 2:00 PM, "oleksandr otenko" 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     If cancellations are disabled in the callee code, there is no
>     state transition to think about.
>
>     If cancellations are always a possibility, the callee needs to
>     address this possible state transition (a redo as a possible
>     consequence, I mean). Maybe this is made explicit in some guide
>     notes, just I am not looking in the right place.
>
>
>     Alex
>
>
>     On 05/09/2012 17:40, Vitaly Davidovich wrote:
>>
>>     Suppose you were doing this via some other cooperative
>>     cancellation scheme (e.g. set flag) - how would that work better?
>>
>>     If you need transactional support of sorts then you need to
>>     handle state transitions one way or another, irrespective of how
>>     cancellation is implemented.  I'm failing to see how IE makes
>>     this more difficult.
>>
>>     Sent from my phone
>>
>>     On Sep 5, 2012 11:57 AM, "oleksandr otenko"
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         Not sure what a concrete example is. For C to be safely
>>         redoable, all transitions performed by C, including a
>>         cancellation upon IE, must form a group - that is, for each
>>         state transition there is a way to revert it. I don't see how
>>         an arbitrary computation C can be turned into a group by A -
>>         how the reversing of the state can be done by A without
>>         knowing how C does it.
>>
>>         Suppose, A cannot afford to drop requests, unless the
>>         connection is lost (in which case all of other concurrent
>>         requests will be dropped - there is a guarantee the later
>>         requests cannot be observed complete). B computed a part of
>>         response, and that is passed to C. C decides to set response
>>         flag to error and rethrow IE. We cannot safely redo from A,
>>         unless there is a way to revert the state of the response object.
>>
>>         Yes, C should have thought of a possible vetoing /
>>         cancellation of the cancellation by the caller. Or the
>>         interruption API should have thought of a way to disable
>>         interruptions during C by A.
>>
>>         Alex
>>
>>         On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>>
>>>         If C can be interrupted or is interrupt aware, then it
>>>         encapsulates what happens when it detects/receives
>>>         cancellation.  If there are user-configurable options then
>>>         C's API should allow for that and then A configures C
>>>         appropriately.
>>>
>>>         I think it would be more useful if we can take some
>>>         concrete/real example and dissect it.
>>>
>>>         Sent from my phone
>>>
>>>         On Sep 5, 2012 10:37 AM, "oleksandr otenko"
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             It doesn't just depend on API. If A can't tell C to
>>>             ignore the interrupts, then it will always cancel, and A
>>>             needs to... redo? Then C needs to support a redo. (But
>>>             how do you redo, for example, a closed connection)
>>>
>>>             I am poking to see if there are valid cases when
>>>             cancelling lower layer without upper layer's permission
>>>             is a destructive state transition. Then the lower layer
>>>             - the library - should somehow take these things into
>>>             account. Is there further guidance on this?
>>>
>>>             Alex
>>>
>>>             On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>>
>>>>             This will depend on your use case/API really as to what
>>>>             interruption actually entails - hard to generalize. 
>>>>             All your code knows is that if it's interrupted, some
>>>>             other code has decided to cancel the operation across
>>>>             the stack of calls - what each call frame does in this
>>>>             case depends on specifics.
>>>>
>>>>             Sent from my phone
>>>>
>>>>             On Sep 5, 2012 7:05 AM, "oleksandr otenko"
>>>>             <oleksandr.otenko at oracle.com
>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>                 Even more interesting:
>>>>
>>>>                 A does B, then C, then D. Interrupt during C. Now
>>>>                 if we cancel A in its entirety, how do we cancel B
>>>>                 after it finished? (eg return an element to FIFO
>>>>                 queue in the same position?..) Since C is agnostic
>>>>                 of the context, how can it ignore interruption (if
>>>>                 we can't cancel B, and can't complete D without C,
>>>>                 then C shouldn't cancel upon interruption)
>>>>
>>>>                 Alex
>>>>
>>>>                 On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>>                 I guess the problem is similar to rolling back in
>>>>>                 presence of nested transactions. Suppose, A does
>>>>>                 B, then C. If you interrupt during B, do you mean
>>>>>                 to "rollback" just B, or A in its entirety? What
>>>>>                 you are saying looks more like "A in its entirety".
>>>>>
>>>>>                 Alex
>>>>>
>>>>>
>>>>>                 On 05/09/2012 11:12, David Holmes wrote:
>>>>>>                 That is why interrupt generally can't be given a
>>>>>>                 special meaning. You have to interpret it as a
>>>>>>                 general cancellation request unless you have full
>>>>>>                 knowledge of the execution stack. If your
>>>>>>                 "cancellation" response is to ignore the request
>>>>>>                 then you've made your code incompatible with all
>>>>>>                 other code in the execution stack that wants to
>>>>>>                 be actually cancelled. Hence the basic responses
>>>>>>                 to IE are to either propagate it, or consume it
>>>>>>                 and re-assert the interrupt state. It is a
>>>>>>                 cooperative cancellation protocol.
>>>>>>                 David
>>>>>>                 -----Original Message-----
>>>>>>                 *From:* oleksandr otenko
>>>>>>                 [mailto:oleksandr.otenko at oracle.com]
>>>>>>                 *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>>>>                 *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>                 *Cc:* David Holmes; Kirk Pepperdine;
>>>>>>                 concurrency-interest at cs.oswego.edu
>>>>>>                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>                 *Subject:* Re: [concurrency-interest] Subject:
>>>>>>                 Re: Interruption afternotification
>>>>>>
>>>>>>                     But how can one tell who was meant to be
>>>>>>                     cancelled?
>>>>>>
>>>>>>                     Since there is no requirement on the
>>>>>>                     semantics of what a cancel operation might
>>>>>>                     be, I can define my cancel operation as "stop
>>>>>>                     waiting, think again, then maybe enter the
>>>>>>                     same wait". So the effect is I consumed the
>>>>>>                     IE and didn't even re-trigger it.
>>>>>>
>>>>>>                     I guess we can't define strictly what a good
>>>>>>                     way of dealing with IE is, since it is like a
>>>>>>                     "last resort" to unblock a wait, which can
>>>>>>                     offer "the best effort" semantics.
>>>>>>
>>>>>>                     Alex
>>>>>>
>>>>>>                     On 05/09/2012 04:43, David Holmes wrote:
>>>>>>>                     In your applications you can do what you
>>>>>>>                     like. If you are a library writer (which in
>>>>>>>                     simplest terms means you write a class for
>>>>>>>                     others to use) then you need to follow the
>>>>>>>                     rule else you will break any application
>>>>>>>                     that uses your library and which does care
>>>>>>>                     about cancellation.
>>>>>>>                     David
>>>>>>>
>>>>>>>                         -----Original Message-----
>>>>>>>                         *From:* Kirk Pepperdine
>>>>>>>                         [mailto:kirk at kodewerk.com]
>>>>>>>                         *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>>>>>                         *To:* dholmes at ieee.org
>>>>>>>                         <mailto:dholmes at ieee.org>
>>>>>>>                         *Cc:* Vitaly Davidovich; Zhong Yu;
>>>>>>>                         concurrency-interest at cs.oswego.edu
>>>>>>>                         <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                         *Subject:* Re: [concurrency-interest]
>>>>>>>                         Subject: Re: Interruption afternotification
>>>>>>>
>>>>>>>
>>>>>>>                         On 2012-09-05, at 4:35 AM, David Holmes
>>>>>>>                         <davidcholmes at aapt.net.au
>>>>>>>                         <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>
>>>>>>>>                         Typically you either define an API that
>>>>>>>>                         inherently reflects the potential
>>>>>>>>                         blocking nature of the operation and
>>>>>>>>                         supports cancellation, or the blocking
>>>>>>>>                         operation is just an implementation
>>>>>>>>                         detail. In the former case you will
>>>>>>>>                         declare that you throw IE and throw it;
>>>>>>>>                         in the latter you won't declare IE and
>>>>>>>>                         so can't throw it but must re-interrupt
>>>>>>>>                         the thread. (Golden rule is to never
>>>>>>>>                         swallow an interrupt.)
>>>>>>>
>>>>>>>                         Sorry but the golden rule is, he who has
>>>>>>>                         the gold makes the rules. ;-) The IE is
>>>>>>>                         the *only* exception that I eat on a
>>>>>>>                         fairly regular basis. Why? Because there
>>>>>>>                         is nothing to be done and no point to
>>>>>>>                         propagate (which is different than I
>>>>>>>                         don't know how to react so I should
>>>>>>>                         re-throw). Cancelation scenarios are
>>>>>>>                         about the only times I'll not eat an IE.
>>>>>>>
>>>>>>>                         Kirk
>>>>>>>
>>>>>>>>                         Again cancellation techniques and
>>>>>>>>                         options are well covered in CPJ and JCiP.
>>>>>>>>                         David
>>>>>>>>
>>>>>>>>                             -----Original Message-----
>>>>>>>>                             *From:* Vitaly Davidovich
>>>>>>>>                             [mailto:vitalyd at gmail.com
>>>>>>>>                             <http://gmail.com>]
>>>>>>>>                             *Sent:* Wednesday, 5 September 2012
>>>>>>>>                             12:29 PM
>>>>>>>>                             *To:* Zhong Yu
>>>>>>>>                             *Cc:* dholmes at ieee.org
>>>>>>>>                             <mailto:dholmes at ieee.org>;
>>>>>>>>                             concurrency-interest at cs.oswego.edu
>>>>>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>                             *Subject:* Re:
>>>>>>>>                             [concurrency-interest] Subject: Re:
>>>>>>>>                             Interruption afternotification
>>>>>>>>
>>>>>>>>                             I think typically you catch IE, do
>>>>>>>>                             whatever cleanup and rethrow it
>>>>>>>>                             rather than reinterrupting the
>>>>>>>>                             thread (unless you're at a point
>>>>>>>>                             where handling it makes sense).  If
>>>>>>>>                             you simply reinterrupt, you
>>>>>>>>                             effectively delay (or lose) the
>>>>>>>>                             interrupt delivery to the caller.
>>>>>>>>
>>>>>>>>                             Sent from my phone
>>>>>>>>
>>>>>>>>                             On Sep 4, 2012 10:00 PM, "Zhong Yu"
>>>>>>>>                             <zhong.j.yu at gmail.com
>>>>>>>>                             <mailto:zhong.j.yu at gmail.com>> wrote:
>>>>>>>>
>>>>>>>>                                 On Tue, Sep 4, 2012 at 7:38 PM,
>>>>>>>>                                 Zhong Yu <zhong.j.yu at gmail.com
>>>>>>>>                                 <mailto:zhong.j.yu at gmail.com>>
>>>>>>>>                                 wrote:
>>>>>>>>                                 > On Tue, Sep 4, 2012 at 5:37
>>>>>>>>                                 PM, David Holmes
>>>>>>>>                                 <davidcholmes at aapt.net.au
>>>>>>>>                                 <mailto:davidcholmes at aapt.net.au>>
>>>>>>>>                                 wrote:
>>>>>>>>                                 >> The JLS doesn't say anything
>>>>>>>>                                 about what applications should
>>>>>>>>                                 do. All the
>>>>>>>>                                 >> application knows when the
>>>>>>>>                                 IE is thrown is that the thread
>>>>>>>>                                 was interrupted
>>>>>>>>                                 >> and the interrupt state is
>>>>>>>>                                 now clear. It is up to the
>>>>>>>>                                 application to respond
>>>>>>>>                                 >> to the interruption in an
>>>>>>>>                                 appropriate manner.
>>>>>>>>                                 >
>>>>>>>>                                 > I'm also unsure about the use
>>>>>>>>                                 of interruption in real world.
>>>>>>>>                                 >
>>>>>>>>                                 > In simple cases, the
>>>>>>>>                                 interrupt-er and the
>>>>>>>>                                 interrupt-ee can assign any
>>>>>>>>                                 > special meaning to
>>>>>>>>                                 interruptions. But they can
>>>>>>>>                                 also instead use an
>>>>>>>>                                 > explicit variable to transmit
>>>>>>>>                                 the meaning; interruption
>>>>>>>>                                 doesn't offer
>>>>>>>>                                 > a lot of value here.
>>>>>>>>                                 >
>>>>>>>>                                 > In more complex applications,
>>>>>>>>                                 it's hard for interrupt-er to
>>>>>>>>                                 know which
>>>>>>>>                                 > piece of code the
>>>>>>>>                                 interrupt-ee is running at the
>>>>>>>>                                 moment; it's unlikely
>>>>>>>>                                 > that interruption can be used
>>>>>>>>                                 to deliver special meanings.
>>>>>>>>                                 > Interruption can only have 1
>>>>>>>>                                 meaning universally accepted by
>>>>>>>>                                 all,
>>>>>>>>                                 > which is probably "stop
>>>>>>>>                                 everything and quit the thread"
>>>>>>>>                                 >
>>>>>>>>                                 > To achieve that,
>>>>>>>>                                 interruptions need to propagate
>>>>>>>>                                 up, therefore pretty
>>>>>>>>                                 > much all method signatures
>>>>>>>>                                 will be polluted by
>>>>>>>>                                 InterruptedException.
>>>>>>>>
>>>>>>>>                                 This is incorrect. A method
>>>>>>>>                                 doesn't have to propagate
>>>>>>>>                                 InterruptedException in this
>>>>>>>>                                 case; it can re-interrupt the
>>>>>>>>                                 current
>>>>>>>>                                 thread, then return normally,
>>>>>>>>                                 leaving the caller to discover and
>>>>>>>>                                 handle the interruption.
>>>>>>>>
>>>>>>>>                                 > We don't see that in practice.
>>>>>>>>                                 >
>>>>>>>>                                 > Or an application will simply
>>>>>>>>                                 restrain from using
>>>>>>>>                                 interruption at all,
>>>>>>>>                                 > since it doesn't know how to
>>>>>>>>                                 handle it. Then all
>>>>>>>>                                 InterruptedExceptions
>>>>>>>>                                 > can be ignored anywhere in
>>>>>>>>                                 the application code.
>>>>>>>>                                 >
>>>>>>>>                                 >
>>>>>>>>                                 > Zhong Yu
>>>>>>>>                                 >
>>>>>>>>                                 >
>>>>>>>>                                 >>
>>>>>>>>                                 >> David
>>>>>>>>                                 >>
>>>>>>>>                                 >> -----Original Message-----
>>>>>>>>                                 >> From:
>>>>>>>>                                 concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>>                                 >>
>>>>>>>>                                 [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>>>>                                 Behalf Of oleksandr
>>>>>>>>                                 >> otenko
>>>>>>>>                                 >> Sent: Wednesday, 5 September
>>>>>>>>                                 2012 4:43 AM
>>>>>>>>                                 >> To: Vitaly Davidovich
>>>>>>>>                                 >> Cc:
>>>>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 >> Subject: Re:
>>>>>>>>                                 [concurrency-interest] Subject:
>>>>>>>>                                 Re: Interruption
>>>>>>>>                                 >> afternotification
>>>>>>>>                                 >>
>>>>>>>>                                 >> If these two events arrive
>>>>>>>>                                 concurrently, there is no
>>>>>>>>                                 ordering between them.
>>>>>>>>                                 >> So preferring interruption
>>>>>>>>                                 over notification doesn't
>>>>>>>>                                 change the correctness.
>>>>>>>>                                 >>
>>>>>>>>                                 >> Does JLS specify what the
>>>>>>>>                                 application _should_ do upon
>>>>>>>>                                 receiving
>>>>>>>>                                 >> InterruptedException?
>>>>>>>>                                 >>
>>>>>>>>                                 >> Alex
>>>>>>>>                                 >>
>>>>>>>>                                 >>
>>>>>>>>                                 >> On 04/09/2012 18:35, Vitaly
>>>>>>>>                                 Davidovich wrote:
>>>>>>>>                                 >>
>>>>>>>>                                 >> Dave,
>>>>>>>>                                 >>
>>>>>>>>                                 >> I can see why one may want
>>>>>>>>                                 to leave interrupt pending
>>>>>>>>                                 (thread may complete
>>>>>>>>                                 >> without checking interrupt
>>>>>>>>                                 status) but I can also see an
>>>>>>>>                                 argument in favor
>>>>>>>>                                 >> of delivering the interrupt
>>>>>>>>                                 in such a case (I.e. deliver
>>>>>>>>                                 the "inevitable"
>>>>>>>>                                 >> sooner, assuming thread will
>>>>>>>>                                 notice the interrupt soon
>>>>>>>>                                 thereafter).
>>>>>>>>                                 >>
>>>>>>>>                                 >> So just curious - what's the
>>>>>>>>                                 rationale for choosing
>>>>>>>>                                 notification over
>>>>>>>>                                 >> interrupt here?
>>>>>>>>                                 >>
>>>>>>>>                                 >> Thanks
>>>>>>>>                                 >>
>>>>>>>>                                 >> Sent from my phone
>>>>>>>>                                 >>
>>>>>>>>                                 >> On Sep 4, 2012 1:10 PM,
>>>>>>>>                                 "David Dice"
>>>>>>>>                                 <david.dice at gmail.com
>>>>>>>>                                 <mailto:david.dice at gmail.com>>
>>>>>>>>                                 wrote:
>>>>>>>>                                 >>>
>>>>>>>>                                 >>> As an aside, in the current
>>>>>>>>                                 implementation in hotspot if we
>>>>>>>>                                 have a both a
>>>>>>>>                                 >>> pending notification and
>>>>>>>>                                 interrupt, we return from
>>>>>>>>                                 wait() leaving the
>>>>>>>>                                 >>> interrupt pending.
>>>>>>>>                                 >>>
>>>>>>>>                                 >>> Dave
>>>>>>>>                                 >>> https://blogs.oracle.com/dave/
>>>>>>>>                                 >>>
>>>>>>>>                                 >>>
>>>>>>>>                                 >>>
>>>>>>>>                                 >>>
>>>>>>>>                                 _______________________________________________
>>>>>>>>                                 >>> Concurrency-interest
>>>>>>>>                                 mailing list
>>>>>>>>                                 >>>
>>>>>>>>                                 Concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 >>>
>>>>>>>>                                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>                                 >>>
>>>>>>>>                                 >>
>>>>>>>>                                 >>
>>>>>>>>                                 >>
>>>>>>>>                                 _______________________________________________
>>>>>>>>                                 >> Concurrency-interest mailing
>>>>>>>>                                 list
>>>>>>>>                                 >>
>>>>>>>>                                 Concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 >>
>>>>>>>>                                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>                                 >>
>>>>>>>>                                 >>
>>>>>>>>                                 >>
>>>>>>>>                                 _______________________________________________
>>>>>>>>                                 >> Concurrency-interest mailing
>>>>>>>>                                 list
>>>>>>>>                                 >>
>>>>>>>>                                 Concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 >>
>>>>>>>>                                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>                                 >>
>>>>>>>>                                 _______________________________________________
>>>>>>>>                                 Concurrency-interest mailing list
>>>>>>>>                                 Concurrency-interest at cs.oswego.edu
>>>>>>>>                                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>
>>>>>>>>                         _______________________________________________
>>>>>>>>                         Concurrency-interest mailing list
>>>>>>>>                         Concurrency-interest at cs.oswego.edu
>>>>>>>>                         <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>                     _______________________________________________
>>>>>>>                     Concurrency-interest mailing list
>>>>>>>                     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>
>>>>>
>>>>>                 _______________________________________________
>>>>>                 Concurrency-interest mailing list
>>>>>                 Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>                 _______________________________________________
>>>>                 Concurrency-interest mailing list
>>>>                 Concurrency-interest at cs.oswego.edu
>>>>                 <mailto:Concurrency-interest at cs.oswego.edu>
>>>>                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120905/cf6041d6/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Sep  5 16:31:12 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 6 Sep 2012 06:31:12 +1000
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <5047AF3B.7030500@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCAEKGJGAA.davidcholmes@aapt.net.au>

Outside a transactional system (and maybe not even  then) some responses to
cancellation requests cannot be reasonably implemented. There is no pretense
here that an arbitrary call stack can choose an arbitrary cancellation
response. In many cases you may have to keep going and either complete or at
least roll-forward to a point where semantically things make sense. Because
throwing IE (generally) clears the interrupt state it allow you to retry the
operation that threw it. Again this is not a carte-blanche ability to redo
absolutely anything - it all depends on what you were doing.

I/O is a huge problem and the A, B, C scenarios here are exactly why
interruptible I/O was never implemented (only on Solaris) and was replaced
in NIO with interruptible channels that close the stream. It was easy to
unblock a thread that was waiting for input but semantically you were left
with a stream in an unknown state (eg you were interrupted after reading the
first few bytes of a HTML GET request - noone can continue reading from the
stream and make sense of it.)

Interruption is a simple cooperative cancellation mechanism. It sets a flag
to say "the user has requested you think about not continuing with what you
are doing". Certain blocking library operations will abort the blocking call
and throw the IE (clearing the interrupt state in the process). If you can
use it then use it, if you can't then don't. But think about other code in
the stack that might want to use it.

And that is my last word on the subject (read the books, it is all there
:) ).

David
  -----Original Message-----
  From: oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
  Sent: Thursday, 6 September 2012 6:00 AM
  To: Vitaly Davidovich
  Cc: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Subject: Re: Interruption
afternotification


  On 05/09/2012 20:38, Vitaly Davidovich wrote:
    So IE is not an async exception, like say OOMError, which means (a) it's
not always a possibility (someone has to call interrupt()) and (b) if you
want cancellation then you need to use classes that support that (this goes
back to API) - if callee doesn't know what to do with IE and it mutates or
transitions states, then it's not suitable for use.  The bigger issue, IMHO,
in protecting state/invariants is async exceptions, which can truly happen
almost anywhere.

  This interpretation increases the scope of code to be considered. From the
library writer's point of view interruption is always a possibility.


    Keep in mind that interruption can simply serve as a flag as well
(Thread.isInterrupted()) - it just so happens that its most useful aspect is
allowing early return from various blocking calls.  I'm not sure if
isInterrupted() entails some overhead (e.g. checking for safepoint), so it
may be slightly less efficient than rolling your own java flag (David or
someone else may know offhand).

  Yes, and A doesn't want C to bail out sooner, but to keep trundling until
A completes, because A cannot bail out sooner anyway. Maybe A will let
someone outside A to pick up the interruption, but not A.

  Oh, well. We can write a duplicate method for everything, just like we
have acquire and acquireNonInterruptibly, and proportionately add functional
tests and cross-method consistency tests.

  Alex



    Sent from my phone

    On Sep 5, 2012 2:00 PM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
wrote:

      If cancellations are disabled in the callee code, there is no state
transition to think about.

      If cancellations are always a possibility, the callee needs to address
this possible state transition (a redo as a possible consequence, I mean).
Maybe this is made explicit in some guide notes, just I am not looking in
the right place.


      Alex


      On 05/09/2012 17:40, Vitaly Davidovich wrote:
        Suppose you were doing this via some other cooperative cancellation
scheme (e.g. set flag) - how would that work better?

        If you need transactional support of sorts then you need to handle
state transitions one way or another, irrespective of how cancellation is
implemented.  I'm failing to see how IE makes this more difficult.

        Sent from my phone

        On Sep 5, 2012 11:57 AM, "oleksandr otenko"
<oleksandr.otenko at oracle.com> wrote:

          Not sure what a concrete example is. For C to be safely redoable,
all transitions performed by C, including a cancellation upon IE, must form
a group - that is, for each state transition there is a way to revert it. I
don't see how an arbitrary computation C can be turned into a group by A -
how the reversing of the state can be done by A without knowing how C does
it.

          Suppose, A cannot afford to drop requests, unless the connection
is lost (in which case all of other concurrent requests will be dropped -
there is a guarantee the later requests cannot be observed complete). B
computed a part of response, and that is passed to C. C decides to set
response flag to error and rethrow IE. We cannot safely redo from A, unless
there is a way to revert the state of the response object.

          Yes, C should have thought of a possible vetoing / cancellation of
the cancellation by the caller. Or the interruption API should have thought
of a way to disable interruptions during C by A.

          Alex

          On 05/09/2012 15:42, Vitaly Davidovich wrote:
            If C can be interrupted or is interrupt aware, then it
encapsulates what happens when it detects/receives cancellation.  If there
are user-configurable options then C's API should allow for that and then A
configures C appropriately.

            I think it would be more useful if we can take some
concrete/real example and dissect it.



            Sent from my phone

            On Sep 5, 2012 10:37 AM, "oleksandr otenko"
<oleksandr.otenko at oracle.com> wrote:

              It doesn't just depend on API. If A can't tell C to ignore the
interrupts, then it will always cancel, and A needs to... redo? Then C needs
to support a redo. (But how do you redo, for example, a closed connection)

              I am poking to see if there are valid cases when cancelling
lower layer without upper layer's permission is a destructive state
transition. Then the lower layer - the library - should somehow take these
things into account. Is there further guidance on this?

              Alex

              On 05/09/2012 12:09, Vitaly Davidovich wrote:
                This will depend on your use case/API really as to what
interruption actually entails - hard to generalize.  All your code knows is
that if it's interrupted, some other code has decided to cancel the
operation across the stack of calls - what each call frame does in this case
depends on specifics.

                Sent from my phone

                On Sep 5, 2012 7:05 AM, "oleksandr otenko"
<oleksandr.otenko at oracle.com> wrote:

                  Even more interesting:

                  A does B, then C, then D. Interrupt during C. Now if we
cancel A in its entirety, how do we cancel B after it finished? (eg return
an element to FIFO queue in the same position?..) Since C is agnostic of the
context, how can it ignore interruption (if we can't cancel B, and can't
complete D without C, then C shouldn't cancel upon interruption)

                  Alex

                  On 05/09/2012 11:25, oleksandr otenko wrote:
                    I guess the problem is similar to rolling back in
presence of nested transactions. Suppose, A does B, then C. If you interrupt
during B, do you mean to "rollback" just B, or A in its entirety? What you
are saying looks more like "A in its entirety".

                    Alex


                    On 05/09/2012 11:12, David Holmes wrote:
                      That is why interrupt generally can't be given a
special meaning. You have to interpret it as a general cancellation request
unless you have full knowledge of the execution stack. If your
"cancellation" response is to ignore the request then you've made your code
incompatible with all other code in the execution stack that wants to be
actually cancelled. Hence the basic responses to IE are to either propagate
it, or consume it and re-assert the interrupt state. It is a cooperative
cancellation protocol.

                      David

                       -----Original Message-----
                      From: oleksandr otenko
[mailto:oleksandr.otenko at oracle.com]
                      Sent: Wednesday, 5 September 2012 8:03 PM
                      To: dholmes at ieee.org
                      Cc: David Holmes; Kirk Pepperdine;
concurrency-interest at cs.oswego.edu
                      Subject: Re: [concurrency-interest] Subject: Re:
Interruption afternotification


                        But how can one tell who was meant to be cancelled?

                        Since there is no requirement on the semantics of
what a cancel operation might be, I can define my cancel operation as "stop
waiting, think again, then maybe enter the same wait". So the effect is I
consumed the IE and didn't even re-trigger it.

                        I guess we can't define strictly what a good way of
dealing with IE is, since it is like a "last resort" to unblock a wait,
which can offer "the best effort" semantics.

                        Alex

                        On 05/09/2012 04:43, David Holmes wrote:
                          In your applications you can do what you like. If
you are a library writer (which in simplest terms means you write a class
for others to use) then you need to follow the rule else you will break any
application that uses your library and which does care about cancellation.

                          David
                            -----Original Message-----
                            From: Kirk Pepperdine [mailto:kirk at kodewerk.com]
                            Sent: Wednesday, 5 September 2012 1:38 PM
                            To: dholmes at ieee.org
                            Cc: Vitaly Davidovich; Zhong Yu;
concurrency-interest at cs.oswego.edu
                            Subject: Re: [concurrency-interest] Subject: Re:
Interruption afternotification




                            On 2012-09-05, at 4:35 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:


                              Typically you either define an API that
inherently reflects the potential blocking nature of the operation and
supports cancellation, or the blocking operation is just an implementation
detail. In the former case you will declare that you throw IE and throw it;
in the latter you won't declare IE and so can't throw it but must
re-interrupt the thread. (Golden rule is to never swallow an interrupt.)


                            Sorry but the golden rule is, he who has the
gold makes the rules. ;-) The IE is the *only* exception that I eat on a
fairly regular basis. Why? Because there is nothing to be done and no point
to propagate (which is different than I don't know how to react so I should
re-throw). Cancelation scenarios are about the only times I'll not eat an
IE.


                            Kirk



                              Again cancellation techniques and options are
well covered in CPJ and JCiP.

                              David
                                -----Original Message-----
                                From: Vitaly Davidovich
[mailto:vitalyd at gmail.com]
                                Sent: Wednesday, 5 September 2012 12:29 PM
                                To: Zhong Yu
                                Cc: dholmes at ieee.org;
concurrency-interest at cs.oswego.edu
                                Subject: Re: [concurrency-interest] Subject:
Re: Interruption afternotification


                                I think typically you catch IE, do whatever
cleanup and rethrow it rather than reinterrupting the thread (unless you're
at a point where handling it makes sense).  If you simply reinterrupt, you
effectively delay (or lose) the interrupt delivery to the caller.

                                Sent from my phone

                                On Sep 4, 2012 10:00 PM, "Zhong Yu"
<zhong.j.yu at gmail.com> wrote:

                                On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu
<zhong.j.yu at gmail.com> wrote:
                                > On Tue, Sep 4, 2012 at 5:37 PM, David
Holmes <davidcholmes at aapt.net.au> wrote:
                                >> The JLS doesn't say anything about what
applications should do. All the
                                >> application knows when the IE is thrown
is that the thread was interrupted
                                >> and the interrupt state is now clear. It
is up to the application to respond
                                >> to the interruption in an appropriate
manner.
                                >
                                > I'm also unsure about the use of
interruption in real world.
                                >
                                > In simple cases, the interrupt-er and the
interrupt-ee can assign any
                                > special meaning to interruptions. But they
can also instead use an
                                > explicit variable to transmit the meaning;
interruption doesn't offer
                                > a lot of value here.
                                >
                                > In more complex applications, it's hard
for interrupt-er to know which
                                > piece of code the interrupt-ee is running
at the moment; it's unlikely
                                > that interruption can be used to deliver
special meanings.
                                > Interruption can only have 1 meaning
universally accepted by all,
                                > which is probably "stop everything and
quit the thread"
                                >
                                > To achieve that, interruptions need to
propagate up, therefore pretty
                                > much all method signatures will be
polluted by InterruptedException.

                                This is incorrect. A method doesn't have to
propagate
                                InterruptedException in this case; it can
re-interrupt the current
                                thread, then return normally, leaving the
caller to discover and
                                handle the interruption.

                                > We don't see that in practice.
                                >
                                > Or an application will simply restrain
from using interruption at all,
                                > since it doesn't know how to handle it.
Then all InterruptedExceptions
                                > can be ignored anywhere in the application
code.
                                >
                                >
                                > Zhong Yu
                                >
                                >
                                >>
                                >> David
                                >>
                                >> -----Original Message-----
                                >> From:
concurrency-interest-bounces at cs.oswego.edu
                                >>
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of oleksandr
                                >> otenko
                                >> Sent: Wednesday, 5 September 2012 4:43 AM
                                >> To: Vitaly Davidovich
                                >> Cc: concurrency-interest at cs.oswego.edu
                                >> Subject: Re: [concurrency-interest]
Subject: Re: Interruption
                                >> afternotification
                                >>
                                >> If these two events arrive concurrently,
there is no ordering between them.
                                >> So preferring interruption over
notification doesn't change the correctness.
                                >>
                                >> Does JLS specify what the application
_should_ do upon receiving
                                >> InterruptedException?
                                >>
                                >> Alex
                                >>
                                >>
                                >> On 04/09/2012 18:35, Vitaly Davidovich
wrote:
                                >>
                                >> Dave,
                                >>
                                >> I can see why one may want to leave
interrupt pending (thread may complete
                                >> without checking interrupt status) but I
can also see an argument in favor
                                >> of delivering the interrupt in such a
case (I.e. deliver the "inevitable"
                                >> sooner, assuming thread will notice the
interrupt soon thereafter).
                                >>
                                >> So just curious - what's the rationale
for choosing notification over
                                >> interrupt here?
                                >>
                                >> Thanks
                                >>
                                >> Sent from my phone
                                >>
                                >> On Sep 4, 2012 1:10 PM, "David Dice"
<david.dice at gmail.com> wrote:
                                >>>
                                >>> As an aside, in the current
implementation in hotspot if we have a both a
                                >>> pending notification and interrupt, we
return from wait() leaving the
                                >>> interrupt pending.
                                >>>
                                >>> Dave
                                >>> https://blogs.oracle.com/dave/
                                >>>
                                >>>
                                >>>
                                >>>
_______________________________________________
                                >>> Concurrency-interest mailing list
                                >>> Concurrency-interest at cs.oswego.edu
                                >>>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
                                >>>
                                >>
                                >>
                                >>
_______________________________________________
                                >> Concurrency-interest mailing list
                                >> Concurrency-interest at cs.oswego.edu
                                >>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
                                >>
                                >>
                                >>
_______________________________________________
                                >> Concurrency-interest mailing list
                                >> Concurrency-interest at cs.oswego.edu
                                >>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
                                >>
                                ____________________________________________
___
                                Concurrency-interest mailing list
                                Concurrency-interest at cs.oswego.edu
                                http://cs.oswego.edu/mailman/listinfo/concur
rency-interest

                              ______________________________________________
_
                              Concurrency-interest mailing list
                              Concurrency-interest at cs.oswego.edu
                              http://cs.oswego.edu/mailman/listinfo/concurre
ncy-interest






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

                  _______________________________________________
                  Concurrency-interest mailing list
                  Concurrency-interest at cs.oswego.edu
                  http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/dc8ed96b/attachment-0001.html>

From jwesleysmith at atlassian.com  Wed Sep  5 19:08:07 2012
From: jwesleysmith at atlassian.com (Jed Wesley-Smith)
Date: Thu, 6 Sep 2012 09:08:07 +1000
Subject: [concurrency-interest] Thread safety of elements in ThreadSafe
	collections
In-Reply-To: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
References: <E4CA89ED-A352-424F-9F5A-A4BFA96112A5@cs.cmu.edu>
Message-ID: <CAKh+yi8KYK6MKOs8s6O77Fn549R_+=nu-a1O0eXX_kgxYAbCFQ@mail.gmail.com>

This is basically the thesis of functional programming ? that mutation
(side-effects) is one of the more significant sources of complexity in
programming and that programming using immutable values is not only
possible but beneficial (necessary even) for a range of reasons.

Your advice regarding hashcode/equality is basic essential advice that
should be drilled into every junior Java programmer ? classes that
implement hashcode/equals using mutable internal state are broken!

More generally, the separation of values (immutable) and identity (a
series of values (states) over time) is a very important concept that
many programs conflate. See for instance Rich Hickey's recent GOTO
conference keynote for a good overview
http://www.infoq.com/presentations/Value-Values

For another more general appeal for functional programming to a mostly
Java-style audience see Philip Wadler's recent QCON talk:
http://www.infoq.com/presentations/Faith-Evolution-Programming-Languages

cheers,
jed.

On 5 September 2012 00:46, Aaron Greenhouse <aarong at cs.cmu.edu> wrote:
> I have a question about something that I'm surprised I haven't seen discussed anywhere before.  If I have a thread safe collection, such as a CopyOnWriteArrayList, what are the thread safety requirements of the elements I put in the collection?  It seems to me that any object put into a thread safe collection must be of a type that is also thread safe due to
>
> (1) the fact that the equals, toString, and hashCode methods are going to be invoked on it
>
> (2) possibly from several threads, possibly from a thread distinct from the one that put the element into the collection (or why else is a thread safe collection being used?)
>
> Alternatively, the class of the object must NOT override hashCode() and equals(), and use reference identity preserving implementations from java.lang.Object.
>
> But I've never seen these requirements implicitly or explicitly discussed any where before.  I cooked up a an example this afternoon where by putting a non-thread safe object into a CopyOnWriteArrayList, I can make the hashCode() method of the list violate its invariants.
>
> public class BreakIt {
> public static void main(String[] args) {
>   // Precalculate the expected hash values
>   final List<Element> list = new ArrayList<Element>();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(30, 15, 1));
>   final int hc1 = list.hashCode();
>
>   list.clear();
>   list.add(new Element(10, 20, 30));
>   list.add(new Element(99, 37, 17));
>   final int hc2 = list.hashCode();
>
>   list.clear();
>
>   System.out.println("Hashcode should be " + hc1 + " or " + hc2);
>
>   final List<Element> safeList = new CopyOnWriteArrayList<Element>();
>   final Element e1 = new Element(10, 20, 30);
>   final Element e2 = new Element(30, 15, 1);
>   safeList.add(e1);
>   safeList.add(e2);
>
>   final Executor exec = Executors.newFixedThreadPool(6);
>   for (int i = 0; i < 5; i++) {
>     exec.execute(new ReaderTask(hc1, hc2, safeList));
>   }
>   exec.execute(new Fiddler(e2));
> }
> }
>
> final class ReaderTask implements Runnable {
> private final int hc1;
> private final int hc2;
> private final List<Element> list;
>
> public ReaderTask(int v1, int v2, List<Element> l) {
>   hc1 = v1;
>   hc2 = v2;
>   list = l;
> }
>
> @Override
> public void run() {
>   int good = 0;
>   while (true) {
>     final int h = list.hashCode();
>     if (h != hc1 && h != hc2) {
>       System.out.println("After " + good + " tries, got bad hashcode: " + h);
>       good = 0;
>     } else {
>       good += 1;
>     }
>   }
> }
> }
>
> final class Fiddler implements Runnable {
> private final Element elt;
>
> public Fiddler(Element e) {
>   elt = e;
> }
>
> @Override
> public void run() {
>   while (true) {
>     elt.set(30, 15, 1);
>     try {
>       Thread.sleep(10);
>     } catch (InterruptedException e) {
>       // TODO Auto-generated catch block
>       e.printStackTrace();
>     }
>     elt.set(99, 37, 17);
>   }
> }
> }
>
>
> final class Element {
> private int x;
> private int y;
> private int z;
>
>
> public Element(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> public void set(int a, int b, int c) {
>   x = a;
>   y = b;
>   z = c;
> }
>
> @Override
> public int hashCode() {
>   int hc = 17;
>   hc = 31 * hc + x;
>   hc = 31 * hc + y;
>   hc = 31 * hc + z;
>   return hc;
> }
>
> @Override
> public boolean equals(final Object o) {
>   if (o == this) {
>     return true;
>   } else if (o instanceof Element) {
>     final Element other = (Element) o;
>     return x == other.x && y == other.y && z == other.z;
>   }
>   return false;
> }
>
> @Override
> public String toString() {
>   return "<" + x + ", " + y + ", " + z + ">";
> }
> }
>
> When I run this, I immediately observe breakages:
>
> Hashcode should be 16554621 or 16621628
> After 227690 tries, got bad hashcode: 16620930
> After 379544 tries, got bad hashcode: 16620930
> After 232377 tries, got bad hashcode: 16620930
> After 206754 tries, got bad hashcode: 16620930
> After 98116 tries, got bad hashcode: 16620930
> After 90573 tries, got bad hashcode: 16620930
> After 90503 tries, got bad hashcode: 16620930
> After 505897 tries, got bad hashcode: 16620930
> After 529645 tries, got bad hashcode: 16621612
> After 497268 tries, got bad hashcode: 16620930
> After 1155576 tries, got bad hashcode: 16620930
> After 949490 tries, got bad hashcode: 16620930
> After 314761 tries, got bad hashcode: 16620930
> After 800675 tries, got bad hashcode: 16620930
> After 281174 tries, got bad hashcode: 16620930
> After 358146 tries, got bad hashcode: 16620930
> After 346746 tries, got bad hashcode: 16621612
> After 465604 tries, got bad hashcode: 16620930
> (and so on)
>
> Obviously, the equal() and toString() methods of the list could be forced to observe an intermediate state of an Element object too.
>
> So, why the silence on this issue?  Seems like this is something even experienced programmers are bound to mess up, never mind programmers new to concurrency.
>
>
> On a related note, but not specifically a concurrency observation, it seems to be pretty much a very very bad idea to override hashCode() on a mutable object (even though the collection classes do it).  But I've never seen this mentioned anywhere either.  Certainly I've never seen any one say don't modify an object after you stick in a collection.  If you put an object in a set or map and then change its state in such a way that affects its hash code, you have broken the set or map that you put it in because the object is still indexed by its original hash code.  You can see this with this example where I use an ArrayList has an element of other collections.
>
> public class Test {
> public static void main(String[] s) {
>   final List<String> element = new ArrayList<String>();
>   final Set<List<? extends Object>> hashSet = new HashSet<List<? extends Object>>();
>   final List<List<? extends Object>> arrayList = new ArrayList<List<? extends Object>>();
>   final List<List<? extends Object>> linkedList = new LinkedList<List<? extends Object>>();
>
>   element.add("a");
>   element.add("b");
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   hashSet.add(element);
>   System.out.println("Hash set is " + hashSet);
>   System.out.println("Hash set has hashcode " + hashSet.hashCode());
>   System.out.println("Hash set contains element? " + hashSet.contains(element));
>
>   arrayList.add(element);
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " + arrayList.contains(element));
>
>   linkedList.add(element);
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " + linkedList.contains(element));
>
>
>   System.out.println();
>   System.out.println("=== Adding c and d to element ===");
>   element.add("c");
>   element.add("d");
>
>   System.out.println("Element is " + element);
>   System.out.println("Element has hashcode " + element.hashCode());
>
>   System.out.println("Set is " + hashSet);
>   System.out.println("Set has hashcode " + hashSet.hashCode());
>   System.out.println("Set contains element? " + hashSet.contains(element));
>
>   System.out.println("Array list is " + arrayList);
>   System.out.println("Array list has hashcode " + arrayList.hashCode());
>   System.out.println("Array list contains element? " + arrayList.contains(element));
>
>   System.out.println("Linked list is " + linkedList);
>   System.out.println("Linked list has hashcode " + linkedList.hashCode());
>   System.out.println("Linked list contains element? " + linkedList.contains(element));
> }
> }
>
> I get the output
>
> Element is [a, b]
> Element has hashcode 4066
> Hash set is [[a, b]]
> Hash set has hashcode 4066
> Hash set contains element? true
> Array list is [[a, b]]
> Array list has hashcode 4097
> Array list contains element? true
> Linked list is [[a, b]]
> Linked list has hashcode 4097
> Linked list contains element? true
>
> === Adding c and d to element ===
> Element is [a, b, c, d]
> Element has hashcode 3910595
> Set is [[a, b, c, d]]
> Set has hashcode 3910595
> Set contains element? false
> Array list is [[a, b, c, d]]
> Array list has hashcode 3910626
> Array list contains element? true
> Linked list is [[a, b, c, d]]
> Linked list has hashcode 3910626
> Linked list contains element? true
>
> Of note is that after adding "c" and "d" to the element list, set.contains() returns the wrong value.
>
> --Aaron Greenhouse
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at oracle.com  Wed Sep  5 19:40:30 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Thu, 06 Sep 2012 00:40:30 +0100
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAEKGJGAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCAEKGJGAA.davidcholmes@aapt.net.au>
Message-ID: <5047E2EE.6070509@oracle.com>

I am not disagreeing with cancellation protocol. I am trying to 
understand whether the callee implementation alone can determine 
cancellability of a particular occurrence of interruption.

Alex

On 05/09/2012 21:31, David Holmes wrote:
> Outside a transactional system (and maybe not even  then) some 
> responses to cancellation requests cannot be reasonably implemented. 
> There is no pretense here that an arbitrary call stack can choose an 
> arbitrary cancellation response. In many cases you may have to keep 
> going and either complete or at least roll-forward to a point where 
> semantically things make sense. Because throwing IE (generally) clears 
> the interrupt state it allow you to retry the operation that threw it. 
> Again this is not a carte-blanche ability to redo absolutely anything 
> - it all depends on what you were doing.
> I/O is a huge problem and the A, B, C scenarios here are exactly why 
> interruptible I/O was never implemented (only on Solaris) and was 
> replaced in NIO with interruptible channels that close the stream. It 
> was easy to unblock a thread that was waiting for input but 
> semantically you were left with a stream in an unknown state (eg you 
> were interrupted after reading the first few bytes of a HTML GET 
> request - noone can continue reading from the stream and make sense of 
> it.)
> Interruption is a simple cooperative cancellation mechanism. It sets a 
> flag to say "the user has requested you think about not continuing 
> with what you are doing". Certain blocking library operations will 
> abort the blocking call and throw the IE (clearing the interrupt state 
> in the process). If you can use it then use it, if you can't then 
> don't. But think about other code in the stack that might want to use it.
> And that is my last word on the subject (read the books, it is all 
> there :) ).
> David
>
>     -----Original Message-----
>     *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com]
>     *Sent:* Thursday, 6 September 2012 6:00 AM
>     *To:* Vitaly Davidovich
>     *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>     afternotification
>
>     On 05/09/2012 20:38, Vitaly Davidovich wrote:
>>
>>     So IE is not an async exception, like say OOMError, which means
>>     (a) it's not always a possibility (someone has to call
>>     interrupt()) and (b) if you want cancellation then you need to
>>     use classes that support that (this goes back to API) - if callee
>>     doesn't know what to do with IE and it mutates or transitions
>>     states, then it's not suitable for use.  The bigger issue, IMHO,
>>     in protecting state/invariants is async exceptions, which can
>>     truly happen almost anywhere.
>>
>     This interpretation increases the scope of code to be considered.
>     From the library writer's point of view interruption is always a
>     possibility.
>
>>     Keep in mind that interruption can simply serve as a flag as well
>>     (Thread.isInterrupted()) - it just so happens that its most
>>     useful aspect is allowing early return from various blocking
>>     calls.  I'm not sure if isInterrupted() entails some overhead
>>     (e.g. checking for safepoint), so it may be slightly less
>>     efficient than rolling your own java flag (David or someone else
>>     may know offhand).
>>
>     Yes, and A doesn't want C to bail out sooner, but to keep
>     trundling until A completes, because A cannot bail out sooner
>     anyway. Maybe A will let someone outside A to pick up the
>     interruption, but not A.
>
>     Oh, well. We can write a duplicate method for everything, just
>     like we have acquire and acquireNonInterruptibly, and
>     proportionately add functional tests and cross-method consistency
>     tests.
>
>     Alex
>
>
>>     Sent from my phone
>>
>>     On Sep 5, 2012 2:00 PM, "oleksandr otenko"
>>     <oleksandr.otenko at oracle.com
>>     <mailto:oleksandr.otenko at oracle.com>> wrote:
>>
>>         If cancellations are disabled in the callee code, there is no
>>         state transition to think about.
>>
>>         If cancellations are always a possibility, the callee needs
>>         to address this possible state transition (a redo as a
>>         possible consequence, I mean). Maybe this is made explicit in
>>         some guide notes, just I am not looking in the right place.
>>
>>
>>         Alex
>>
>>
>>         On 05/09/2012 17:40, Vitaly Davidovich wrote:
>>>
>>>         Suppose you were doing this via some other cooperative
>>>         cancellation scheme (e.g. set flag) - how would that work
>>>         better?
>>>
>>>         If you need transactional support of sorts then you need to
>>>         handle state transitions one way or another, irrespective of
>>>         how cancellation is implemented.  I'm failing to see how IE
>>>         makes this more difficult.
>>>
>>>         Sent from my phone
>>>
>>>         On Sep 5, 2012 11:57 AM, "oleksandr otenko"
>>>         <oleksandr.otenko at oracle.com
>>>         <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>
>>>             Not sure what a concrete example is. For C to be safely
>>>             redoable, all transitions performed by C, including a
>>>             cancellation upon IE, must form a group - that is, for
>>>             each state transition there is a way to revert it. I
>>>             don't see how an arbitrary computation C can be turned
>>>             into a group by A - how the reversing of the state can
>>>             be done by A without knowing how C does it.
>>>
>>>             Suppose, A cannot afford to drop requests, unless the
>>>             connection is lost (in which case all of other
>>>             concurrent requests will be dropped - there is a
>>>             guarantee the later requests cannot be observed
>>>             complete). B computed a part of response, and that is
>>>             passed to C. C decides to set response flag to error and
>>>             rethrow IE. We cannot safely redo from A, unless there
>>>             is a way to revert the state of the response object.
>>>
>>>             Yes, C should have thought of a possible vetoing /
>>>             cancellation of the cancellation by the caller. Or the
>>>             interruption API should have thought of a way to disable
>>>             interruptions during C by A.
>>>
>>>             Alex
>>>
>>>             On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>>>
>>>>             If C can be interrupted or is interrupt aware, then it
>>>>             encapsulates what happens when it detects/receives
>>>>             cancellation.  If there are user-configurable options
>>>>             then C's API should allow for that and then A
>>>>             configures C appropriately.
>>>>
>>>>             I think it would be more useful if we can take some
>>>>             concrete/real example and dissect it.
>>>>
>>>>             Sent from my phone
>>>>
>>>>             On Sep 5, 2012 10:37 AM, "oleksandr otenko"
>>>>             <oleksandr.otenko at oracle.com
>>>>             <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>
>>>>                 It doesn't just depend on API. If A can't tell C to
>>>>                 ignore the interrupts, then it will always cancel,
>>>>                 and A needs to... redo? Then C needs to support a
>>>>                 redo. (But how do you redo, for example, a closed
>>>>                 connection)
>>>>
>>>>                 I am poking to see if there are valid cases when
>>>>                 cancelling lower layer without upper layer's
>>>>                 permission is a destructive state transition. Then
>>>>                 the lower layer - the library - should somehow take
>>>>                 these things into account. Is there further
>>>>                 guidance on this?
>>>>
>>>>                 Alex
>>>>
>>>>                 On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>>>
>>>>>                 This will depend on your use case/API really as to
>>>>>                 what interruption actually entails - hard to
>>>>>                 generalize.  All your code knows is that if it's
>>>>>                 interrupted, some other code has decided to cancel
>>>>>                 the operation across the stack of calls - what
>>>>>                 each call frame does in this case depends on
>>>>>                 specifics.
>>>>>
>>>>>                 Sent from my phone
>>>>>
>>>>>                 On Sep 5, 2012 7:05 AM, "oleksandr otenko"
>>>>>                 <oleksandr.otenko at oracle.com
>>>>>                 <mailto:oleksandr.otenko at oracle.com>> wrote:
>>>>>
>>>>>                     Even more interesting:
>>>>>
>>>>>                     A does B, then C, then D. Interrupt during C.
>>>>>                     Now if we cancel A in its entirety, how do we
>>>>>                     cancel B after it finished? (eg return an
>>>>>                     element to FIFO queue in the same position?..)
>>>>>                     Since C is agnostic of the context, how can it
>>>>>                     ignore interruption (if we can't cancel B, and
>>>>>                     can't complete D without C, then C shouldn't
>>>>>                     cancel upon interruption)
>>>>>
>>>>>                     Alex
>>>>>
>>>>>                     On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>>>                     I guess the problem is similar to rolling
>>>>>>                     back in presence of nested transactions.
>>>>>>                     Suppose, A does B, then C. If you interrupt
>>>>>>                     during B, do you mean to "rollback" just B,
>>>>>>                     or A in its entirety? What you are saying
>>>>>>                     looks more like "A in its entirety".
>>>>>>
>>>>>>                     Alex
>>>>>>
>>>>>>
>>>>>>                     On 05/09/2012 11:12, David Holmes wrote:
>>>>>>>                     That is why interrupt generally can't be
>>>>>>>                     given a special meaning. You have to
>>>>>>>                     interpret it as a general cancellation
>>>>>>>                     request unless you have full knowledge of
>>>>>>>                     the execution stack. If your "cancellation"
>>>>>>>                     response is to ignore the request then
>>>>>>>                     you've made your code incompatible with all
>>>>>>>                     other code in the execution stack that wants
>>>>>>>                     to be actually cancelled. Hence the basic
>>>>>>>                     responses to IE are to either propagate it,
>>>>>>>                     or consume it and re-assert the interrupt
>>>>>>>                     state. It is a cooperative cancellation
>>>>>>>                     protocol.
>>>>>>>                     David
>>>>>>>                     -----Original Message-----
>>>>>>>                     *From:* oleksandr otenko
>>>>>>>                     [mailto:oleksandr.otenko at oracle.com]
>>>>>>>                     *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>>>>>                     *To:* dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>                     *Cc:* David Holmes; Kirk Pepperdine;
>>>>>>>                     concurrency-interest at cs.oswego.edu
>>>>>>>                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>                     *Subject:* Re: [concurrency-interest]
>>>>>>>                     Subject: Re: Interruption afternotification
>>>>>>>
>>>>>>>                         But how can one tell who was meant to be
>>>>>>>                         cancelled?
>>>>>>>
>>>>>>>                         Since there is no requirement on the
>>>>>>>                         semantics of what a cancel operation
>>>>>>>                         might be, I can define my cancel
>>>>>>>                         operation as "stop waiting, think again,
>>>>>>>                         then maybe enter the same wait". So the
>>>>>>>                         effect is I consumed the IE and didn't
>>>>>>>                         even re-trigger it.
>>>>>>>
>>>>>>>                         I guess we can't define strictly what a
>>>>>>>                         good way of dealing with IE is, since it
>>>>>>>                         is like a "last resort" to unblock a
>>>>>>>                         wait, which can offer "the best effort"
>>>>>>>                         semantics.
>>>>>>>
>>>>>>>                         Alex
>>>>>>>
>>>>>>>                         On 05/09/2012 04:43, David Holmes wrote:
>>>>>>>>                         In your applications you can do what
>>>>>>>>                         you like. If you are a library writer
>>>>>>>>                         (which in simplest terms means you
>>>>>>>>                         write a class for others to use) then
>>>>>>>>                         you need to follow the rule else you
>>>>>>>>                         will break any application that uses
>>>>>>>>                         your library and which does care about
>>>>>>>>                         cancellation.
>>>>>>>>                         David
>>>>>>>>
>>>>>>>>                             -----Original Message-----
>>>>>>>>                             *From:* Kirk Pepperdine
>>>>>>>>                             [mailto:kirk at kodewerk.com]
>>>>>>>>                             *Sent:* Wednesday, 5 September 2012
>>>>>>>>                             1:38 PM
>>>>>>>>                             *To:* dholmes at ieee.org
>>>>>>>>                             <mailto:dholmes at ieee.org>
>>>>>>>>                             *Cc:* Vitaly Davidovich; Zhong Yu;
>>>>>>>>                             concurrency-interest at cs.oswego.edu
>>>>>>>>                             <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>                             *Subject:* Re:
>>>>>>>>                             [concurrency-interest] Subject: Re:
>>>>>>>>                             Interruption afternotification
>>>>>>>>
>>>>>>>>
>>>>>>>>                             On 2012-09-05, at 4:35 AM, David
>>>>>>>>                             Holmes <davidcholmes at aapt.net.au
>>>>>>>>                             <mailto:davidcholmes at aapt.net.au>>
>>>>>>>>                             wrote:
>>>>>>>>
>>>>>>>>>                             Typically you either define an API
>>>>>>>>>                             that inherently reflects the
>>>>>>>>>                             potential blocking nature of the
>>>>>>>>>                             operation and supports
>>>>>>>>>                             cancellation, or the blocking
>>>>>>>>>                             operation is just an
>>>>>>>>>                             implementation detail. In the
>>>>>>>>>                             former case you will declare that
>>>>>>>>>                             you throw IE and throw it; in the
>>>>>>>>>                             latter you won't declare IE and so
>>>>>>>>>                             can't throw it but must
>>>>>>>>>                             re-interrupt the thread. (Golden
>>>>>>>>>                             rule is to never swallow an
>>>>>>>>>                             interrupt.)
>>>>>>>>
>>>>>>>>                             Sorry but the golden rule is, he
>>>>>>>>                             who has the gold makes the rules.
>>>>>>>>                             ;-) The IE is the *only* exception
>>>>>>>>                             that I eat on a fairly regular
>>>>>>>>                             basis. Why? Because there is
>>>>>>>>                             nothing to be done and no point to
>>>>>>>>                             propagate (which is different than
>>>>>>>>                             I don't know how to react so I
>>>>>>>>                             should re-throw). Cancelation
>>>>>>>>                             scenarios are about the only times
>>>>>>>>                             I'll not eat an IE.
>>>>>>>>
>>>>>>>>                             Kirk
>>>>>>>>
>>>>>>>>>                             Again cancellation techniques and
>>>>>>>>>                             options are well covered in CPJ
>>>>>>>>>                             and JCiP.
>>>>>>>>>                             David
>>>>>>>>>
>>>>>>>>>                                 -----Original Message-----
>>>>>>>>>                                 *From:* Vitaly Davidovich
>>>>>>>>>                                 [mailto:vitalyd at gmail.com
>>>>>>>>>                                 <http://gmail.com>]
>>>>>>>>>                                 *Sent:* Wednesday, 5 September
>>>>>>>>>                                 2012 12:29 PM
>>>>>>>>>                                 *To:* Zhong Yu
>>>>>>>>>                                 *Cc:* dholmes at ieee.org
>>>>>>>>>                                 <mailto:dholmes at ieee.org>;
>>>>>>>>>                                 concurrency-interest at cs.oswego.edu
>>>>>>>>>                                 <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                 *Subject:* Re:
>>>>>>>>>                                 [concurrency-interest]
>>>>>>>>>                                 Subject: Re: Interruption
>>>>>>>>>                                 afternotification
>>>>>>>>>
>>>>>>>>>                                 I think typically you catch
>>>>>>>>>                                 IE, do whatever cleanup and
>>>>>>>>>                                 rethrow it rather than
>>>>>>>>>                                 reinterrupting the thread
>>>>>>>>>                                 (unless you're at a point
>>>>>>>>>                                 where handling it makes
>>>>>>>>>                                 sense).  If you simply
>>>>>>>>>                                 reinterrupt, you effectively
>>>>>>>>>                                 delay (or lose) the interrupt
>>>>>>>>>                                 delivery to the caller.
>>>>>>>>>
>>>>>>>>>                                 Sent from my phone
>>>>>>>>>
>>>>>>>>>                                 On Sep 4, 2012 10:00 PM,
>>>>>>>>>                                 "Zhong Yu"
>>>>>>>>>                                 <zhong.j.yu at gmail.com
>>>>>>>>>                                 <mailto:zhong.j.yu at gmail.com>>
>>>>>>>>>                                 wrote:
>>>>>>>>>
>>>>>>>>>                                     On Tue, Sep 4, 2012 at
>>>>>>>>>                                     7:38 PM, Zhong Yu
>>>>>>>>>                                     <zhong.j.yu at gmail.com
>>>>>>>>>                                     <mailto:zhong.j.yu at gmail.com>>
>>>>>>>>>                                     wrote:
>>>>>>>>>                                     > On Tue, Sep 4, 2012 at
>>>>>>>>>                                     5:37 PM, David Holmes
>>>>>>>>>                                     <davidcholmes at aapt.net.au
>>>>>>>>>                                     <mailto:davidcholmes at aapt.net.au>>
>>>>>>>>>                                     wrote:
>>>>>>>>>                                     >> The JLS doesn't say
>>>>>>>>>                                     anything about what
>>>>>>>>>                                     applications should do.
>>>>>>>>>                                     All the
>>>>>>>>>                                     >> application knows when
>>>>>>>>>                                     the IE is thrown is that
>>>>>>>>>                                     the thread was interrupted
>>>>>>>>>                                     >> and the interrupt state
>>>>>>>>>                                     is now clear. It is up to
>>>>>>>>>                                     the application to respond
>>>>>>>>>                                     >> to the interruption in
>>>>>>>>>                                     an appropriate manner.
>>>>>>>>>                                     >
>>>>>>>>>                                     > I'm also unsure about
>>>>>>>>>                                     the use of interruption in
>>>>>>>>>                                     real world.
>>>>>>>>>                                     >
>>>>>>>>>                                     > In simple cases, the
>>>>>>>>>                                     interrupt-er and the
>>>>>>>>>                                     interrupt-ee can assign any
>>>>>>>>>                                     > special meaning to
>>>>>>>>>                                     interruptions. But they
>>>>>>>>>                                     can also instead use an
>>>>>>>>>                                     > explicit variable to
>>>>>>>>>                                     transmit the meaning;
>>>>>>>>>                                     interruption doesn't offer
>>>>>>>>>                                     > a lot of value here.
>>>>>>>>>                                     >
>>>>>>>>>                                     > In more complex
>>>>>>>>>                                     applications, it's hard
>>>>>>>>>                                     for interrupt-er to know which
>>>>>>>>>                                     > piece of code the
>>>>>>>>>                                     interrupt-ee is running at
>>>>>>>>>                                     the moment; it's unlikely
>>>>>>>>>                                     > that interruption can be
>>>>>>>>>                                     used to deliver special
>>>>>>>>>                                     meanings.
>>>>>>>>>                                     > Interruption can only
>>>>>>>>>                                     have 1 meaning universally
>>>>>>>>>                                     accepted by all,
>>>>>>>>>                                     > which is probably "stop
>>>>>>>>>                                     everything and quit the
>>>>>>>>>                                     thread"
>>>>>>>>>                                     >
>>>>>>>>>                                     > To achieve that,
>>>>>>>>>                                     interruptions need to
>>>>>>>>>                                     propagate up, therefore pretty
>>>>>>>>>                                     > much all method
>>>>>>>>>                                     signatures will be
>>>>>>>>>                                     polluted by
>>>>>>>>>                                     InterruptedException.
>>>>>>>>>
>>>>>>>>>                                     This is incorrect. A
>>>>>>>>>                                     method doesn't have to
>>>>>>>>>                                     propagate
>>>>>>>>>                                     InterruptedException in
>>>>>>>>>                                     this case; it can
>>>>>>>>>                                     re-interrupt the current
>>>>>>>>>                                     thread, then return
>>>>>>>>>                                     normally, leaving the
>>>>>>>>>                                     caller to discover and
>>>>>>>>>                                     handle the interruption.
>>>>>>>>>
>>>>>>>>>                                     > We don't see that in
>>>>>>>>>                                     practice.
>>>>>>>>>                                     >
>>>>>>>>>                                     > Or an application will
>>>>>>>>>                                     simply restrain from using
>>>>>>>>>                                     interruption at all,
>>>>>>>>>                                     > since it doesn't know
>>>>>>>>>                                     how to handle it. Then all
>>>>>>>>>                                     InterruptedExceptions
>>>>>>>>>                                     > can be ignored anywhere
>>>>>>>>>                                     in the application code.
>>>>>>>>>                                     >
>>>>>>>>>                                     >
>>>>>>>>>                                     > Zhong Yu
>>>>>>>>>                                     >
>>>>>>>>>                                     >
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> David
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> -----Original Message-----
>>>>>>>>>                                     >> From:
>>>>>>>>>                                     concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>>                                     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>>>>>>>>>                                     >>
>>>>>>>>>                                     [mailto:concurrency-interest-bounces at cs.oswego.edu
>>>>>>>>>                                     <mailto:concurrency-interest-bounces at cs.oswego.edu>]On
>>>>>>>>>                                     Behalf Of oleksandr
>>>>>>>>>                                     >> otenko
>>>>>>>>>                                     >> Sent: Wednesday, 5
>>>>>>>>>                                     September 2012 4:43 AM
>>>>>>>>>                                     >> To: Vitaly Davidovich
>>>>>>>>>                                     >> Cc:
>>>>>>>>>                                     concurrency-interest at cs.oswego.edu
>>>>>>>>>                                     <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                     >> Subject: Re:
>>>>>>>>>                                     [concurrency-interest]
>>>>>>>>>                                     Subject: Re: Interruption
>>>>>>>>>                                     >> afternotification
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> If these two events
>>>>>>>>>                                     arrive concurrently, there
>>>>>>>>>                                     is no ordering between them.
>>>>>>>>>                                     >> So preferring
>>>>>>>>>                                     interruption over
>>>>>>>>>                                     notification doesn't
>>>>>>>>>                                     change the correctness.
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> Does JLS specify what
>>>>>>>>>                                     the application _should_
>>>>>>>>>                                     do upon receiving
>>>>>>>>>                                     >> InterruptedException?
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> Alex
>>>>>>>>>                                     >>
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> On 04/09/2012 18:35,
>>>>>>>>>                                     Vitaly Davidovich wrote:
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> Dave,
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> I can see why one may
>>>>>>>>>                                     want to leave interrupt
>>>>>>>>>                                     pending (thread may complete
>>>>>>>>>                                     >> without checking
>>>>>>>>>                                     interrupt status) but I
>>>>>>>>>                                     can also see an argument
>>>>>>>>>                                     in favor
>>>>>>>>>                                     >> of delivering the
>>>>>>>>>                                     interrupt in such a case
>>>>>>>>>                                     (I.e. deliver the "inevitable"
>>>>>>>>>                                     >> sooner, assuming thread
>>>>>>>>>                                     will notice the interrupt
>>>>>>>>>                                     soon thereafter).
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> So just curious -
>>>>>>>>>                                     what's the rationale for
>>>>>>>>>                                     choosing notification over
>>>>>>>>>                                     >> interrupt here?
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> Thanks
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> Sent from my phone
>>>>>>>>>                                     >>
>>>>>>>>>                                     >> On Sep 4, 2012 1:10 PM,
>>>>>>>>>                                     "David Dice"
>>>>>>>>>                                     <david.dice at gmail.com
>>>>>>>>>                                     <mailto:david.dice at gmail.com>>
>>>>>>>>>                                     wrote:
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>> As an aside, in the
>>>>>>>>>                                     current implementation in
>>>>>>>>>                                     hotspot if we have a both a
>>>>>>>>>                                     >>> pending notification
>>>>>>>>>                                     and interrupt, we return
>>>>>>>>>                                     from wait() leaving the
>>>>>>>>>                                     >>> interrupt pending.
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>> Dave
>>>>>>>>>                                     >>>
>>>>>>>>>                                     https://blogs.oracle.com/dave/
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>>
>>>>>>>>>                                     _______________________________________________
>>>>>>>>>                                     >>> Concurrency-interest
>>>>>>>>>                                     mailing list
>>>>>>>>>                                     >>>
>>>>>>>>>                                     Concurrency-interest at cs.oswego.edu
>>>>>>>>>                                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                     >>>
>>>>>>>>>                                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>>                                     >>>
>>>>>>>>>                                     >>
>>>>>>>>>                                     >>
>>>>>>>>>                                     >>
>>>>>>>>>                                     _______________________________________________
>>>>>>>>>                                     >> Concurrency-interest
>>>>>>>>>                                     mailing list
>>>>>>>>>                                     >>
>>>>>>>>>                                     Concurrency-interest at cs.oswego.edu
>>>>>>>>>                                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                     >>
>>>>>>>>>                                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>>                                     >>
>>>>>>>>>                                     >>
>>>>>>>>>                                     >>
>>>>>>>>>                                     _______________________________________________
>>>>>>>>>                                     >> Concurrency-interest
>>>>>>>>>                                     mailing list
>>>>>>>>>                                     >>
>>>>>>>>>                                     Concurrency-interest at cs.oswego.edu
>>>>>>>>>                                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                     >>
>>>>>>>>>                                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>>                                     >>
>>>>>>>>>                                     _______________________________________________
>>>>>>>>>                                     Concurrency-interest
>>>>>>>>>                                     mailing list
>>>>>>>>>                                     Concurrency-interest at cs.oswego.edu
>>>>>>>>>                                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>                                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>>
>>>>>>>>>                             _______________________________________________
>>>>>>>>>                             Concurrency-interest mailing list
>>>>>>>>>                             Concurrency-interest at cs.oswego.edu
>>>>>>>>>                             <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>                         _______________________________________________
>>>>>>>>                         Concurrency-interest mailing list
>>>>>>>>                         Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>                         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>
>>>>>>
>>>>>>                     _______________________________________________
>>>>>>                     Concurrency-interest mailing list
>>>>>>                     Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>                     _______________________________________________
>>>>>                     Concurrency-interest mailing list
>>>>>                     Concurrency-interest at cs.oswego.edu
>>>>>                     <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>                     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/0942e223/attachment-0001.html>

From stanimir at riflexo.com  Thu Sep  6 02:52:20 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 6 Sep 2012 09:52:20 +0300
Subject: [concurrency-interest] Subject: Re: Interruption
	afternotification
In-Reply-To: <CAHjP37Fv08vmWSWCLXj-mUyp-jnDn=yTwBpoPjdMbD-kmK08Ew@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCEKCJGAA.davidcholmes@aapt.net.au>
	<50472892.7060608@oracle.com> <50472FC8.7050604@oracle.com>
	<CAHjP37GmjCTORUpL3mdmaC7SNg0tBrv+4UxJCASTB3Z7PC7puA@mail.gmail.com>
	<50476388.4000705@oracle.com>
	<CAHjP37FKV9q7oS=Na3jWLhC+7ABdCdzQSu+G-sgvDHr+ggXhow@mail.gmail.com>
	<5047764C.6020305@oracle.com>
	<CAHjP37G-m0T=yHQcw7rM11hRcPZ8Y-NQ5P5ZXSYewUmDkuWEDQ@mail.gmail.com>
	<50479308.3020000@oracle.com>
	<CAHjP37Fv08vmWSWCLXj-mUyp-jnDn=yTwBpoPjdMbD-kmK08Ew@mail.gmail.com>
Message-ID: <CAEJX8opC4hvxqQtwNwmEogZ2wPjx+-f=MYOs1-5Fe6Je99KPoA@mail.gmail.com>

> Keep in mind that interruption can simply serve as a flag as well
> (Thread.isInterrupted()) - it just so happens that its most useful aspect
> is allowing early return from various blocking calls.  I'm not sure if
> isInterrupted() entails some overhead (e.g. checking for safepoint), so it
> may be slightly less efficient than rolling your own java flag (David or
> someone else may know offhand).
>

Thread.isInterrupted is inlined/intrinsic by the JIT (at least hotspot).
There is an indirection plus getting Thread.currentThread() [which is
another indirection]. The flag is stored into OSThread*, which is read like
this:

bool os::is_interrupted(Thread* thread, bool clear_interrupted) {
  assert(Thread::current() == thread || Threads_lock->owned_by_self(),
    "possibility of dangling Thread pointer");

  OSThread* osthread = thread->osthread();

  bool interrupted = osthread->interrupted();

  if (interrupted && clear_interrupted) {
    osthread->set_interrupted(false);
    // consider thread->_SleepEvent->reset() ... optional optimization
  }

  return interrupted;
}
........
jint _interrupted;              // Thread.isInterrupted state

  // Note:  _interrupted must be jint, so that Java intrinsics can access
it.
  // The value stored there must be either 0 or 1.  It must be possible
  // for Java to emulate Thread.currentThread().isInterrupted() by
performing
  // the double indirection Thread::current()->_osthread->_interrupted.
....
      bool interrupted() const                          { return
_interrupted != 0; }

And that's all. Although I have seen C1 failing to optimize static boolean
Thread.interruped().

Calling Thread.interrupt invokes any interruption handler and that's how
the NIO works. The interruption handler is available via public(!) API -
java.nio.channels.spi.AbstractInterruptibleChannel, the code has to wrapped
in begin/end and protected abstract void implCloseChannel() throws
IOException - implemented as interruption/signal handler.

For 12+ years lib.  and application writing I tend to consider interrupt()
as a cancelation attempt and it never has to be eaten. Propagate it and in
the worst case throw a runtime exception.

Stanimir

Suppose you were doing this via some other cooperative cancellation scheme
> (e.g. set flag) - how would that work better?
>
>> If you need transactional support of sorts then you need to handle state
>> transitions one way or another, irrespective of how cancellation is
>> implemented.  I'm failing to see how IE makes this more difficult.
>>
>> Sent from my phone
>> On Sep 5, 2012 11:57 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>> wrote:
>>
>>>  Not sure what a concrete example is. For C to be safely redoable, all
>>> transitions performed by C, including a cancellation upon IE, must form a
>>> group - that is, for each state transition there is a way to revert it. I
>>> don't see how an arbitrary computation C can be turned into a group by A -
>>> how the reversing of the state can be done by A without knowing how C does
>>> it.
>>>
>>> Suppose, A cannot afford to drop requests, unless the connection is lost
>>> (in which case all of other concurrent requests will be dropped - there is
>>> a guarantee the later requests cannot be observed complete). B computed a
>>> part of response, and that is passed to C. C decides to set response flag
>>> to error and rethrow IE. We cannot safely redo from A, unless there is a
>>> way to revert the state of the response object.
>>>
>>> Yes, C should have thought of a possible vetoing / cancellation of the
>>> cancellation by the caller. Or the interruption API should have thought of
>>> a way to disable interruptions during C by A.
>>>
>>> Alex
>>>
>>> On 05/09/2012 15:42, Vitaly Davidovich wrote:
>>>
>>> If C can be interrupted or is interrupt aware, then it encapsulates what
>>> happens when it detects/receives cancellation.  If there are
>>> user-configurable options then C's API should allow for that and then A
>>> configures C appropriately.
>>>
>>> I think it would be more useful if we can take some concrete/real
>>> example and dissect it.
>>>
>>>  Sent from my phone
>>> On Sep 5, 2012 10:37 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>>> wrote:
>>>
>>>>  It doesn't just depend on API. If A can't tell C to ignore the
>>>> interrupts, then it will always cancel, and A needs to... redo? Then C
>>>> needs to support a redo. (But how do you redo, for example, a closed
>>>> connection)
>>>>
>>>> I am poking to see if there are valid cases when cancelling lower layer
>>>> without upper layer's permission is a destructive state transition. Then
>>>> the lower layer - the library - should somehow take these things into
>>>> account. Is there further guidance on this?
>>>>
>>>> Alex
>>>>
>>>> On 05/09/2012 12:09, Vitaly Davidovich wrote:
>>>>
>>>> This will depend on your use case/API really as to what interruption
>>>> actually entails - hard to generalize.  All your code knows is that if it's
>>>> interrupted, some other code has decided to cancel the operation across the
>>>> stack of calls - what each call frame does in this case depends on
>>>> specifics.
>>>>
>>>> Sent from my phone
>>>> On Sep 5, 2012 7:05 AM, "oleksandr otenko" <oleksandr.otenko at oracle.com>
>>>> wrote:
>>>>
>>>>>  Even more interesting:
>>>>>
>>>>> A does B, then C, then D. Interrupt during C. Now if we cancel A in
>>>>> its entirety, how do we cancel B after it finished? (eg return an element
>>>>> to FIFO queue in the same position?..) Since C is agnostic of the context,
>>>>> how can it ignore interruption (if we can't cancel B, and can't complete D
>>>>> without C, then C shouldn't cancel upon interruption)
>>>>>
>>>>> Alex
>>>>>
>>>>> On 05/09/2012 11:25, oleksandr otenko wrote:
>>>>>
>>>>> I guess the problem is similar to rolling back in presence of nested
>>>>> transactions. Suppose, A does B, then C. If you interrupt during B, do you
>>>>> mean to "rollback" just B, or A in its entirety? What you are saying looks
>>>>> more like "A in its entirety".
>>>>>
>>>>> Alex
>>>>>
>>>>>
>>>>> On 05/09/2012 11:12, David Holmes wrote:
>>>>>
>>>>> That is why interrupt generally can't be given a special meaning. You
>>>>> have to interpret it as a general cancellation request unless you have full
>>>>> knowledge of the execution stack. If your "cancellation" response is to
>>>>> ignore the request then you've made your code incompatible with all other
>>>>> code in the execution stack that wants to be actually cancelled. Hence the
>>>>> basic responses to IE are to either propagate it, or consume it and
>>>>> re-assert the interrupt state. It is a cooperative cancellation protocol.
>>>>>
>>>>> David
>>>>>
>>>>>  -----Original Message-----
>>>>> *From:* oleksandr otenko [mailto:oleksandr.otenko at oracle.com<oleksandr.otenko at oracle.com>
>>>>> ]
>>>>> *Sent:* Wednesday, 5 September 2012 8:03 PM
>>>>> *To:* dholmes at ieee.org
>>>>> *Cc:* David Holmes; Kirk Pepperdine;
>>>>> concurrency-interest at cs.oswego.edu
>>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>>> afternotification
>>>>>
>>>>>  But how can one tell who was meant to be cancelled?
>>>>>
>>>>> Since there is no requirement on the semantics of what a cancel
>>>>> operation might be, I can define my cancel operation as "stop waiting,
>>>>> think again, then maybe enter the same wait". So the effect is I consumed
>>>>> the IE and didn't even re-trigger it.
>>>>>
>>>>> I guess we can't define strictly what a good way of dealing with IE
>>>>> is, since it is like a "last resort" to unblock a wait, which can offer
>>>>> "the best effort" semantics.
>>>>>
>>>>> Alex
>>>>>
>>>>> On 05/09/2012 04:43, David Holmes wrote:
>>>>>
>>>>> In your applications you can do what you like. If you are a library
>>>>> writer (which in simplest terms means you write a class for others to use)
>>>>> then you need to follow the rule else you will break any application that
>>>>> uses your library and which does care about cancellation.
>>>>>
>>>>> David
>>>>>
>>>>> -----Original Message-----
>>>>> *From:* Kirk Pepperdine [mailto:kirk at kodewerk.com <kirk at kodewerk.com>]
>>>>> *Sent:* Wednesday, 5 September 2012 1:38 PM
>>>>> *To:* dholmes at ieee.org
>>>>> *Cc:* Vitaly Davidovich; Zhong Yu; concurrency-interest at cs.oswego.edu
>>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>>> afternotification
>>>>>
>>>>>
>>>>>  On 2012-09-05, at 4:35 AM, David Holmes <davidcholmes at aapt.net.au>
>>>>> wrote:
>>>>>
>>>>>  Typically you either define an API that inherently reflects the
>>>>> potential blocking nature of the operation and supports cancellation, or
>>>>> the blocking operation is just an implementation detail. In the former case
>>>>> you will declare that you throw IE and throw it; in the latter you won't
>>>>> declare IE and so can't throw it but must re-interrupt the thread. (Golden
>>>>> rule is to never swallow an interrupt.)
>>>>>
>>>>>
>>>>>  Sorry but the golden rule is, he who has the gold makes the rules.
>>>>> ;-) The IE is the *only* exception that I eat on a fairly regular basis.
>>>>> Why? Because there is nothing to be done and no point to propagate (which
>>>>> is different than I don't know how to react so I should re-throw).
>>>>> Cancelation scenarios are about the only times I'll not eat an IE.
>>>>>
>>>>>  Kirk
>>>>>
>>>>>
>>>>> Again cancellation techniques and options are well covered in CPJ and
>>>>> JCiP.
>>>>>
>>>>> David
>>>>>
>>>>> -----Original Message-----
>>>>> *From:* Vitaly Davidovich [mailto:vitalyd@ <vitalyd@>gmail.com]
>>>>> *Sent:* Wednesday, 5 September 2012 12:29 PM
>>>>> *To:* Zhong Yu
>>>>> *Cc:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>>>>> *Subject:* Re: [concurrency-interest] Subject: Re: Interruption
>>>>> afternotification
>>>>>
>>>>>  I think typically you catch IE, do whatever cleanup and rethrow it
>>>>> rather than reinterrupting the thread (unless you're at a point where
>>>>> handling it makes sense).  If you simply reinterrupt, you effectively delay
>>>>> (or lose) the interrupt delivery to the caller.
>>>>>
>>>>> Sent from my phone
>>>>> On Sep 4, 2012 10:00 PM, "Zhong Yu" <zhong.j.yu at gmail.com> wrote:
>>>>>
>>>>>> On Tue, Sep 4, 2012 at 7:38 PM, Zhong Yu <zhong.j.yu at gmail.com>
>>>>>> wrote:
>>>>>> > On Tue, Sep 4, 2012 at 5:37 PM, David Holmes <
>>>>>> davidcholmes at aapt.net.au> wrote:
>>>>>> >> The JLS doesn't say anything about what applications should do.
>>>>>> All the
>>>>>> >> application knows when the IE is thrown is that the thread was
>>>>>> interrupted
>>>>>> >> and the interrupt state is now clear. It is up to the application
>>>>>> to respond
>>>>>> >> to the interruption in an appropriate manner.
>>>>>> >
>>>>>> > I'm also unsure about the use of interruption in real world.
>>>>>> >
>>>>>> > In simple cases, the interrupt-er and the interrupt-ee can assign
>>>>>> any
>>>>>> > special meaning to interruptions. But they can also instead use an
>>>>>> > explicit variable to transmit the meaning; interruption doesn't
>>>>>> offer
>>>>>> > a lot of value here.
>>>>>> >
>>>>>> > In more complex applications, it's hard for interrupt-er to know
>>>>>> which
>>>>>> > piece of code the interrupt-ee is running at the moment; it's
>>>>>> unlikely
>>>>>> > that interruption can be used to deliver special meanings.
>>>>>> > Interruption can only have 1 meaning universally accepted by all,
>>>>>> > which is probably "stop everything and quit the thread"
>>>>>> >
>>>>>> > To achieve that, interruptions need to propagate up, therefore
>>>>>> pretty
>>>>>> > much all method signatures will be polluted by InterruptedException.
>>>>>>
>>>>>> This is incorrect. A method doesn't have to propagate
>>>>>> InterruptedException in this case; it can re-interrupt the current
>>>>>> thread, then return normally, leaving the caller to discover and
>>>>>> handle the interruption.
>>>>>>
>>>>>> > We don't see that in practice.
>>>>>> >
>>>>>> > Or an application will simply restrain from using interruption at
>>>>>> all,
>>>>>> > since it doesn't know how to handle it. Then all
>>>>>> InterruptedExceptions
>>>>>> > can be ignored anywhere in the application code.
>>>>>> >
>>>>>> >
>>>>>> > Zhong Yu
>>>>>> >
>>>>>> >
>>>>>> >>
>>>>>> >> David
>>>>>> >>
>>>>>> >> -----Original Message-----
>>>>>> >> From: concurrency-interest-bounces at cs.oswego.edu
>>>>>> >> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of
>>>>>> oleksandr
>>>>>> >> otenko
>>>>>> >> Sent: Wednesday, 5 September 2012 4:43 AM
>>>>>> >> To: Vitaly Davidovich
>>>>>> >> Cc: concurrency-interest at cs.oswego.edu
>>>>>> >> Subject: Re: [concurrency-interest] Subject: Re: Interruption
>>>>>> >> afternotification
>>>>>> >>
>>>>>> >> If these two events arrive concurrently, there is no ordering
>>>>>> between them.
>>>>>> >> So preferring interruption over notification doesn't change the
>>>>>> correctness.
>>>>>> >>
>>>>>> >> Does JLS specify what the application _should_ do upon receiving
>>>>>> >> InterruptedException?
>>>>>> >>
>>>>>> >> Alex
>>>>>> >>
>>>>>> >>
>>>>>> >> On 04/09/2012 18:35, Vitaly Davidovich wrote:
>>>>>> >>
>>>>>> >> Dave,
>>>>>> >>
>>>>>> >> I can see why one may want to leave interrupt pending (thread may
>>>>>> complete
>>>>>> >> without checking interrupt status) but I can also see an argument
>>>>>> in favor
>>>>>> >> of delivering the interrupt in such a case (I.e. deliver the
>>>>>> "inevitable"
>>>>>> >> sooner, assuming thread will notice the interrupt soon thereafter).
>>>>>> >>
>>>>>> >> So just curious - what's the rationale for choosing notification
>>>>>> over
>>>>>> >> interrupt here?
>>>>>> >>
>>>>>> >> Thanks
>>>>>> >>
>>>>>> >> Sent from my phone
>>>>>> >>
>>>>>> >> On Sep 4, 2012 1:10 PM, "David Dice" <david.dice at gmail.com> wrote:
>>>>>> >>>
>>>>>> >>> As an aside, in the current implementation in hotspot if we have
>>>>>> a both a
>>>>>> >>> pending notification and interrupt, we return from wait() leaving
>>>>>> the
>>>>>> >>> interrupt pending.
>>>>>> >>>
>>>>>> >>> Dave
>>>>>> >>> https://blogs.oracle.com/dave/
>>>>>> >>>
>>>>>> >>>
>>>>>> >>>
>>>>>> >>> _______________________________________________
>>>>>> >>> Concurrency-interest mailing list
>>>>>> >>> Concurrency-interest at cs.oswego.edu
>>>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>> >>>
>>>>>> >>
>>>>>> >>
>>>>>> >> _______________________________________________
>>>>>> >> Concurrency-interest mailing list
>>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>> >>
>>>>>> >>
>>>>>> >> _______________________________________________
>>>>>> >> Concurrency-interest mailing list
>>>>>> >> Concurrency-interest at cs.oswego.edu
>>>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>> >>
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>   _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/909364ad/attachment-0001.html>

From uclio.work at googlemail.com  Thu Sep  6 04:53:42 2012
From: uclio.work at googlemail.com (Uclio Work)
Date: Thu, 06 Sep 2012 10:53:42 +0200
Subject: [concurrency-interest] CountedCompleter test
Message-ID: <50486496.2070103@googlemail.com>

I'm playing with CountedCompleter, so to optionally have a 
continuation-like mechanism in the toy PL I'm working on. Unfortunately 
it seems I just don't grasp its semantics the right way.
Here an (in)famous Fibonacci test, with CountedCompleter acting like a 
plain ForkJoinTask. This works as expected :

package jsr166y;
public class Fibo extends CountedCompleter<Integer> {
     Integer n;
     public Fibo(Integer n) { this.n = n; }

     @Override
     public void compute() {
         if ( n > 1 ) {
             Fibo f1 = new Fibo(n - 1); f1.fork();
             Fibo f2 = new Fibo(n - 2); f2.compute();
             n = f2.n + f1.join();
         }
         tryComplete();
     }

     @Override
     public Integer getRawResult() { return n; }

     public static void main(String[] args) {
         ForkJoinTask<Integer> aFuture = new ForkJoinPool().submit(new 
Fibo(20));
         System.out.println(aFuture.join());
     }

}


After that I just don't get why the the same version only modified in 
the constructor doesn't work anymore.
Do not the children call the default onCompletion when they are finished ?

package jsr166y;
public class Fibo extends CountedCompleter<Integer> {
     Integer n;
     public Fibo(Integer n, CountedCompleter<Integer> cc) { super(cc); 
this.n = n; }

     @Override
     public void compute() {
         if ( n > 1 ) {
             Fibo f1 = new Fibo(n - 1, this); f1.fork();
             Fibo f2 = new Fibo(n - 2, this); f2.compute();
             n = f2.n + f1.join();
         }
         tryComplete();
     }

     @Override
     public Integer getRawResult() { return n; }

     public static void main(String[] args) {
         ForkJoinTask<Integer> aFuture = new ForkJoinPool().submit(new 
Fibo(20, null));
         System.out.println(aFuture.join());
     }
}

I also tried adding setPendingCount(1) (and then addToPendingCount(1)) 
before the fork, but that not only doesn't work too, but even exhausted 
all threads (Unable to create new native thread).

Probably it's explained somewhere in the Javadoc, but I just don't see 
what is missing. Some other method to override, maybe ? I have to also 
admit, after the first working test, to not fully understand the 
relation between the  pending completions and the tryComplete method.

Thanks.
Uclio

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/1b429b8c/attachment.html>

From ach at quartetfs.com  Thu Sep  6 12:38:07 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Thu, 6 Sep 2012 18:38:07 +0200
Subject: [concurrency-interest] [Volatile Store,
	Normal Store] ordering for multi-version data stuctures
Message-ID: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>

While designing a multiversion data structure I wrote a simple thread
synchronization based on "volatile".

The shared data is made of a base list, and a volatile "replacement" list.
   List base = ...;
   volatile List replacement = null;

There is only one writer thread. The writer thread will change some
elements in the list. It creates a copy of the original list, puts it as
the replacement (volatile write). It is thought that the replacement list
can "hide" the base and that the modifications can be safely written into
the base list.
   List replacement = new SubList();
   transfer(shared.base, replacement)
   shared.replacement = replacement;
   ...
   modify(shared.base);

There are multiple readers, concurrently with the writer. If a reader sees
a replacement list, it will read values from it. Else it reads data from
the base list and before returning it checks that the replacement was not
set in the meantime.

   List replacement;
   for(;;) {
      replacement = shared.replacement;
  if(replacement != null) return replacement.get(index);
  else {
         Object value = shared.base.get(index);
 List tmp = replacement;
 replacement = shared.replacement;
 if(replacement = tmp) return value;
  }
   }


The design passes a modest set of unit tests on an x86 multi-core processor
but a colleague spotted a big flaw. This expects too much from the java
memory model. The modifications to the base list that were thought to be
invisible to readers could be reordered before the volatile write of the
replacement. So a writer could read garbage from the base, think the
replacement was not set and return the garbage.


Do you see other means (volatile, CAS, UNSAFE,...) that would fix the above
design without resorting to synchronized blocks or locks ?


Thanks a lot,
-Antoine CHAMBILLE
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/4e8c34bb/attachment.html>

From zhong.j.yu at gmail.com  Thu Sep  6 13:04:18 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 6 Sep 2012 12:04:18 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
Message-ID: <CACuKZqFsWHvXTHcfv6efFP6Gs9=mS6fAyWMpCqrfV0iqQVZViQ@mail.gmail.com>

maybe you can simply use a CopyOnWriteArrayList?

On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com> wrote:
> While designing a multiversion data structure I wrote a simple thread
> synchronization based on "volatile".
>
> The shared data is made of a base list, and a volatile "replacement" list.
>    List base = ...;
>    volatile List replacement = null;
>
> There is only one writer thread. The writer thread will change some elements
> in the list. It creates a copy of the original list, puts it as the
> replacement (volatile write). It is thought that the replacement list can
> "hide" the base and that the modifications can be safely written into the
> base list.
>    List replacement = new SubList();
>    transfer(shared.base, replacement)
>    shared.replacement = replacement;
>    ...
>    modify(shared.base);
>
> There are multiple readers, concurrently with the writer. If a reader sees a
> replacement list, it will read values from it. Else it reads data from the
> base list and before returning it checks that the replacement was not set in
> the meantime.
>
>    List replacement;
>    for(;;) {
>       replacement = shared.replacement;
>  if(replacement != null) return replacement.get(index);
>  else {
>          Object value = shared.base.get(index);
> List tmp = replacement;
> replacement = shared.replacement;
> if(replacement = tmp) return value;
>  }
>    }
>
>
> The design passes a modest set of unit tests on an x86 multi-core processor
> but a colleague spotted a big flaw. This expects too much from the java
> memory model. The modifications to the base list that were thought to be
> invisible to readers could be reordered before the volatile write of the
> replacement. So a writer could read garbage from the base, think the
> replacement was not set and return the garbage.
>
>
> Do you see other means (volatile, CAS, UNSAFE,...) that would fix the above
> design without resorting to synchronized blocks or locks ?
>
>
> Thanks a lot,
> -Antoine CHAMBILLE
> Quartet FS
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jacyg at alumni.rice.edu  Thu Sep  6 13:06:43 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Thu, 6 Sep 2012 12:06:43 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
Message-ID: <CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>

Well, without knowing a lot about the details....  Could do something like:


   private volatile List base = new ArrayList();

   private void write()
   {
      List copy = new ArrayList(base);
      //do writes to copy
      base = copy;
   }

   private void read()
   {
      List local = base;
      // do reading using the local variable, NOT the volatile shared
variable.  this is essential,
      // must only read the replacement variable 1x for any set of
reads you expect to be consistent.
      // of course, if you only have a single read, you could dispense
with the local variable, but just
      // bear in mind that the contents of base could be different
each time you reference it.
   }

Of course, it would also be worth seeing if CopyOnWriteArrayList can
satisfy your requirement.

jacy

On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com> wrote:
> While designing a multiversion data structure I wrote a simple thread
> synchronization based on "volatile".
>
> The shared data is made of a base list, and a volatile "replacement" list.
>    List base = ...;
>    volatile List replacement = null;
>
> There is only one writer thread. The writer thread will change some elements
> in the list. It creates a copy of the original list, puts it as the
> replacement (volatile write). It is thought that the replacement list can
> "hide" the base and that the modifications can be safely written into the
> base list.
>    List replacement = new SubList();
>    transfer(shared.base, replacement)
>    shared.replacement = replacement;
>    ...
>    modify(shared.base);
>
> There are multiple readers, concurrently with the writer. If a reader sees a
> replacement list, it will read values from it. Else it reads data from the
> base list and before returning it checks that the replacement was not set in
> the meantime.
>
>    List replacement;
>    for(;;) {
>       replacement = shared.replacement;
>  if(replacement != null) return replacement.get(index);
>  else {
>          Object value = shared.base.get(index);
> List tmp = replacement;
> replacement = shared.replacement;
> if(replacement = tmp) return value;
>  }

   private volatile List base = new ArrayList();

   private void write()
   {
      List copy = new ArrayList(base);
      //do writes to copy
      base = copy;
   }

   private void read()
   {
      List local = base;
      // do reading using the local variable, NOT the volatile shared
variable.  this is essential,
      // must only read the replacement variable 1x for any set of
reads you expect to be consistent.
      // of course, if you only have a single read, you could dispense
with the local variable, but just
      // bear in mind that the contents of base could be different
each time you reference it.
   }
>    }
>
>
> The design passes a modest set of unit tests on an x86 multi-core processor
> but a colleague spotted a big flaw. This expects too much from the java
> memory model. The modifications to the base list that were thought to be
> invisible to readers could be reordered before the volatile write of the
> replacement. So a writer could read garbage from the base, think the
> replacement was not set and return the garbage.
>
>
> Do you see other means (volatile, CAS, UNSAFE,...) that would fix the above
> design without resorting to synchronized blocks or locks ?
>
>
> Thanks a lot,
> -Antoine CHAMBILLE
> Quartet FS
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From oleksandr.otenko at oracle.com  Thu Sep  6 13:50:34 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Thu, 06 Sep 2012 18:50:34 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
Message-ID: <5048E26A.3060007@oracle.com>

Why not

*volatile**List base = ...;
List replacement = ...;
*
List replacement = new SubList();
transfer(shared.base, replacement);
shared.replacement = replacement;
...
modify(shared.replacement);
*shared.base = replacement; // now all modifications become visible 
atomically.
*
then reader needn't worry about replacement, just always look at base. 
In absence of synchronization with the writer it makes no sense to check 
whether shared.base has changed since looking at it at the beginning of 
reader loop.


Alex


On 06/09/2012 17:38, Antoine Chambille wrote:
> While designing a multiversion data structure I wrote a simple thread 
> synchronization based on "volatile".
>
> The shared data is made of a base list, and a volatile "replacement" list.
>    List base = ...;
>    volatile List replacement = null;
>
> There is only one writer thread. The writer thread will change some 
> elements in the list. It creates a copy of the original list, puts it 
> as the replacement (volatile write). It is thought that the 
> replacement list can "hide" the base and that the modifications can be 
> safely written into the base list.
>    List replacement = new SubList();
>    transfer(shared.base, replacement)
>    shared.replacement = replacement;
>    ...
>    modify(shared.base);
>
> There are multiple readers, concurrently with the writer. If a reader 
> sees a replacement list, it will read values from it. Else it reads 
> data from the base list and before returning it checks that the 
> replacement was not set in the meantime.
>
>    List replacement;
>    for(;;) {
>       replacement = shared.replacement;
>  if(replacement != null) return replacement.get(index);
>  else {
>          Object value = shared.base.get(index);
> List tmp = replacement;
> replacement = shared.replacement;
> if(replacement = tmp) return value;
>  }
>    }
>
>
> The design passes a modest set of unit tests on an x86 multi-core 
> processor but a colleague spotted a big flaw. This expects too much 
> from the java memory model. The modifications to the base list that 
> were thought to be invisible to readers could be reordered before the 
> volatile write of the replacement. So a writer could read garbage from 
> the base, think the replacement was not set and return the garbage.
>
>
> Do you see other means (volatile, CAS, UNSAFE,...) that would fix the 
> above design without resorting to synchronized blocks or locks ?
>
>
> Thanks a lot,
> -Antoine CHAMBILLE
> Quartet FS
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/c285178f/attachment.html>

From rco at quartetfs.com  Thu Sep  6 14:19:41 2012
From: rco at quartetfs.com (Romain Colle)
Date: Thu, 6 Sep 2012 20:19:41 +0200
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
Message-ID: <CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>

Hi all,

Antoine's description was a simplified version of our issue, so let me try
to describe the actual problem.

The key thing is that the list that is being "multi-versioned" is very
large while each modification only affects a few elements.
The idea is therefore not to create a full copy for each version (like
CopyOnWriteArrayList or some very good suggestions on this list), but to
simply store a "delta" with the previous version.

Here is a simple example.
Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
large structure for the sake of the example).
The first version of this list would look like this:
L1 = { base = L; delta = null; }

Any reader thread that wants to access the list at this point gets L1, and
all the read requests are forwarded to the base.

Now a writer comes in and wants to change the first element to 5. We will,
in the writer thread
  1) create a delta structure with this new mapping: D1 = {element 0: 1->5 }
  2) create a new version L2 = { base = L; delta = null; }
  3) update L1's base and delta. L1 = { base = L2; delta = D1; }
  4) update L to (5, 2, 3, 4)

Any reader thread that had a reference to L1 will do the following to read
a value:
 1) Look for it in the delta. If we find it in there, return the "previous"
value
 2) The value is not in the delta. Forward the read request to L2 (that
will itself forward it to L), then make sure the delta has not been updated
if it was null before, and return. Otherwise, go back to 1).

This looks like it would work nicely: we are updating L1's base and delta
through volatile writes, hence "masking" the first element in the list.

However, we spotted the issue mentioned before: because the writes to L in
step 4 are not volatile (and we'd like to avoid the cost), they can be
reordered before step 3 where we set L1's base and delta through volatile
writes (roach motel semantics).
Therefore, a reader of L1 could read the delta field that is still null and
get the value from L which is now set to 5, which is incorrect.

As Antoine mentioned, we never observed that in our tests (seeing a null
version of L1.delta while seeing the updates to L), but it seems that this
could happen under the JMM.
Is this correct? Do you see any ways around it?

Thanks!


-- 
Romain Colle
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com

On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu>wrote:

> Well, without knowing a lot about the details....  Could do something like:
>
>
>    private volatile List base = new ArrayList();
>
>    private void write()
>    {
>       List copy = new ArrayList(base);
>       //do writes to copy
>       base = copy;
>    }
>
>    private void read()
>    {
>       List local = base;
>       // do reading using the local variable, NOT the volatile shared
> variable.  this is essential,
>       // must only read the replacement variable 1x for any set of
> reads you expect to be consistent.
>       // of course, if you only have a single read, you could dispense
> with the local variable, but just
>       // bear in mind that the contents of base could be different
> each time you reference it.
>    }
>
> Of course, it would also be worth seeing if CopyOnWriteArrayList can
> satisfy your requirement.
>
> jacy
>
> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
> wrote:
> > While designing a multiversion data structure I wrote a simple thread
> > synchronization based on "volatile".
> >
> > The shared data is made of a base list, and a volatile "replacement"
> list.
> >    List base = ...;
> >    volatile List replacement = null;
> >
> > There is only one writer thread. The writer thread will change some
> elements
> > in the list. It creates a copy of the original list, puts it as the
> > replacement (volatile write). It is thought that the replacement list can
> > "hide" the base and that the modifications can be safely written into the
> > base list.
> >    List replacement = new SubList();
> >    transfer(shared.base, replacement)
> >    shared.replacement = replacement;
> >    ...
> >    modify(shared.base);
> >
> > There are multiple readers, concurrently with the writer. If a reader
> sees a
> > replacement list, it will read values from it. Else it reads data from
> the
> > base list and before returning it checks that the replacement was not
> set in
> > the meantime.
> >
> >    List replacement;
> >    for(;;) {
> >       replacement = shared.replacement;
> >  if(replacement != null) return replacement.get(index);
> >  else {
> >          Object value = shared.base.get(index);
> > List tmp = replacement;
> > replacement = shared.replacement;
> > if(replacement = tmp) return value;
> >  }
>
>    private volatile List base = new ArrayList();
>
>    private void write()
>    {
>       List copy = new ArrayList(base);
>       //do writes to copy
>       base = copy;
>    }
>
>    private void read()
>    {
>       List local = base;
>       // do reading using the local variable, NOT the volatile shared
> variable.  this is essential,
>       // must only read the replacement variable 1x for any set of
> reads you expect to be consistent.
>       // of course, if you only have a single read, you could dispense
> with the local variable, but just
>       // bear in mind that the contents of base could be different
> each time you reference it.
>    }
> >    }
> >
> >
> > The design passes a modest set of unit tests on an x86 multi-core
> processor
> > but a colleague spotted a big flaw. This expects too much from the java
> > memory model. The modifications to the base list that were thought to be
> > invisible to readers could be reordered before the volatile write of the
> > replacement. So a writer could read garbage from the base, think the
> > replacement was not set and return the garbage.
> >
> >
> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
> above
> > design without resorting to synchronized blocks or locks ?
> >
> >
> > Thanks a lot,
> > -Antoine CHAMBILLE
> > Quartet FS
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/d86d56a3/attachment-0001.html>

From jacyg at alumni.rice.edu  Thu Sep  6 14:52:24 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Thu, 6 Sep 2012 13:52:24 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
Message-ID: <CAESiqEorcBgadxawtdberD-8SuaQuNNG2b6MA_NEcp52++p1QA@mail.gmail.com>

If you want L to be written to, and you could potentially have lots of
readers trying to read from it (because they're reading values which
might not be in the current delta and are therefore falling through to
the base list), you will have to have some sort of thread safety on L.
 That's really the fundamental item I see.  That said...it's difficult
to say what will be most efficient without more knowledge of the
actual usage pattern (does the list grow?  are you just swapping
element N for a new value?  do you ever remove elements?).  What's
most difficult for me to understand is why you need to have the
readers see the delta values before they end up in L?  Think of this
as a transaction, where the delta is the transaction payload.  Why
have people peek at the transaction payload before it's committed?
Also, the versioning scheme...it doesn't seem like one, frankly. If
you are going to commit the deltas to L at some point, then you're not
maintaining a version history, just a set of views on transactions in
flight.

Based on what you are saying, well, several solutions come to mind
depending on what you are actually trying to do.  For one, you could
look at AtomicReferenceArray.  That would let you swap out values
atomically without locking the whole array.  But of course if your
list changes size, that wouldn't work so well.   And then there's
ReadWriteLock.  You could use ReadWriteLock to guard L, still gives
you parallel reads...except when you're making updates.  If you wanted
to minimize the impact of that, you could create a structure which
splits the underlying list into multiple sections, have a RWLock on
each section (a strategy similar to what ConcurrentHashMap does). Or
you could have a List<AtomicReference>, where every value in L is
wrapped with an AtomicReference.  Given that you say your data
structure is very large, that probably isn't a very memory efficient
strategy, though.  But it could allow you some more flexibility on
locking...L would still need to be guarded with a RWLock, but you'd
only do a Write lock when you are making structural mods, you could do
a read lock if all you're doing is updating a value held by one of the
AtomicReferences.

Other than that...I'd have to think about it longer.  But I'd really
think about this version scheme, it seems to be introducing a fair bit
of complexity and overhead (you're almost always forwarding reads at
least 1 level down, for example) for...well, hopefully a really good
reason.

jacy

On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
> Hi all,
>
> Antoine's description was a simplified version of our issue, so let me try
> to describe the actual problem.
>
> The key thing is that the list that is being "multi-versioned" is very large
> while each modification only affects a few elements.
> The idea is therefore not to create a full copy for each version (like
> CopyOnWriteArrayList or some very good suggestions on this list), but to
> simply store a "delta" with the previous version.
>
> Here is a simple example.
> Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very large
> structure for the sake of the example).
> The first version of this list would look like this:
> L1 = { base = L; delta = null; }
>
> Any reader thread that wants to access the list at this point gets L1, and
> all the read requests are forwarded to the base.
>
> Now a writer comes in and wants to change the first element to 5. We will,
> in the writer thread
>   1) create a delta structure with this new mapping: D1 = {element 0: 1->5 }
>   2) create a new version L2 = { base = L; delta = null; }
>   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>   4) update L to (5, 2, 3, 4)
>
> Any reader thread that had a reference to L1 will do the following to read a
> value:
>  1) Look for it in the delta. If we find it in there, return the "previous"
> value
>  2) The value is not in the delta. Forward the read request to L2 (that will
> itself forward it to L), then make sure the delta has not been updated if it
> was null before, and return. Otherwise, go back to 1).
>
> This looks like it would work nicely: we are updating L1's base and delta
> through volatile writes, hence "masking" the first element in the list.
>
> However, we spotted the issue mentioned before: because the writes to L in
> step 4 are not volatile (and we'd like to avoid the cost), they can be
> reordered before step 3 where we set L1's base and delta through volatile
> writes (roach motel semantics).
> Therefore, a reader of L1 could read the delta field that is still null and
> get the value from L which is now set to 5, which is incorrect.
>
> As Antoine mentioned, we never observed that in our tests (seeing a null
> version of L1.delta while seeing the updates to L), but it seems that this
> could happen under the JMM.
> Is this correct? Do you see any ways around it?
>
> Thanks!
>
>
> --
> Romain Colle
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu>
> wrote:
>>
>> Well, without knowing a lot about the details....  Could do something
>> like:
>>
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>>
>> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>> satisfy your requirement.
>>
>> jacy
>>
>> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>> wrote:
>> > While designing a multiversion data structure I wrote a simple thread
>> > synchronization based on "volatile".
>> >
>> > The shared data is made of a base list, and a volatile "replacement"
>> > list.
>> >    List base = ...;
>> >    volatile List replacement = null;
>> >
>> > There is only one writer thread. The writer thread will change some
>> > elements
>> > in the list. It creates a copy of the original list, puts it as the
>> > replacement (volatile write). It is thought that the replacement list
>> > can
>> > "hide" the base and that the modifications can be safely written into
>> > the
>> > base list.
>> >    List replacement = new SubList();
>> >    transfer(shared.base, replacement)
>> >    shared.replacement = replacement;
>> >    ...
>> >    modify(shared.base);
>> >
>> > There are multiple readers, concurrently with the writer. If a reader
>> > sees a
>> > replacement list, it will read values from it. Else it reads data from
>> > the
>> > base list and before returning it checks that the replacement was not
>> > set in
>> > the meantime.
>> >
>> >    List replacement;
>> >    for(;;) {
>> >       replacement = shared.replacement;
>> >  if(replacement != null) return replacement.get(index);
>> >  else {
>> >          Object value = shared.base.get(index);
>> > List tmp = replacement;
>> > replacement = shared.replacement;
>> > if(replacement = tmp) return value;
>> >  }
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>> >    }
>> >
>> >
>> > The design passes a modest set of unit tests on an x86 multi-core
>> > processor
>> > but a colleague spotted a big flaw. This expects too much from the java
>> > memory model. The modifications to the base list that were thought to be
>> > invisible to readers could be reordered before the volatile write of the
>> > replacement. So a writer could read garbage from the base, think the
>> > replacement was not set and return the garbage.
>> >
>> >
>> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>> > above
>> > design without resorting to synchronized blocks or locks ?
>> >
>> >
>> > Thanks a lot,
>> > -Antoine CHAMBILLE
>> > Quartet FS
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>

From vitalyd at gmail.com  Thu Sep  6 16:09:17 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 6 Sep 2012 16:09:17 -0400
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
Message-ID: <CAHjP37Gpi_gSweCM-q6r5uhuvx8sJy3N64pFiEeyKKTHA4ETRw@mail.gmail.com>

>
> However, we spotted the issue mentioned before: because the writes to L in
> step 4 are not volatile (and we'd like to avoid the cost), they can be
> reordered before step 3 where we set L1's base and delta through volatile
> writes (roach motel semantics).
> Therefore, a reader of L1 could read the delta field that is still null
> and get the value from L which is now set to 5, which is incorrect.


How about using Unsafe.putOrderedXXX() to store base and/or delta before
storing into L? I don't know if you need timeliness features of the
volatile write, but if you don't, you may be able to get away with just
ordered writes.  Just a thought ...

Also, you're already doing two volatile writes right before storing into L
-- why are you trying to avoid one more? The store buffer is going to be
nearly empty at the point where L is written, so I'm not sure that volatile
write will add any measurable difference to performance.

Vitaly


On Thu, Sep 6, 2012 at 2:19 PM, Romain Colle <rco at quartetfs.com> wrote:

> Hi all,
>
> Antoine's description was a simplified version of our issue, so let me try
> to describe the actual problem.
>
> The key thing is that the list that is being "multi-versioned" is very
> large while each modification only affects a few elements.
> The idea is therefore not to create a full copy for each version (like
> CopyOnWriteArrayList or some very good suggestions on this list), but to
> simply store a "delta" with the previous version.
>
> Here is a simple example.
> Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
> large structure for the sake of the example).
> The first version of this list would look like this:
> L1 = { base = L; delta = null; }
>
> Any reader thread that wants to access the list at this point gets L1, and
> all the read requests are forwarded to the base.
>
> Now a writer comes in and wants to change the first element to 5. We will,
> in the writer thread
>   1) create a delta structure with this new mapping: D1 = {element 0: 1->5
> }
>   2) create a new version L2 = { base = L; delta = null; }
>   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>   4) update L to (5, 2, 3, 4)
>
> Any reader thread that had a reference to L1 will do the following to read
> a value:
>  1) Look for it in the delta. If we find it in there, return the
> "previous" value
>  2) The value is not in the delta. Forward the read request to L2 (that
> will itself forward it to L), then make sure the delta has not been updated
> if it was null before, and return. Otherwise, go back to 1).
>
> This looks like it would work nicely: we are updating L1's base and delta
> through volatile writes, hence "masking" the first element in the list.
>
> However, we spotted the issue mentioned before: because the writes to L in
> step 4 are not volatile (and we'd like to avoid the cost), they can be
> reordered before step 3 where we set L1's base and delta through volatile
> writes (roach motel semantics).
> Therefore, a reader of L1 could read the delta field that is still null
> and get the value from L which is now set to 5, which is incorrect.
>
> As Antoine mentioned, we never observed that in our tests (seeing a null
> version of L1.delta while seeing the updates to L), but it seems that this
> could happen under the JMM.
> Is this correct? Do you see any ways around it?
>
> Thanks!
>
>
> --
> Romain Colle
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu>wrote:
>
>> Well, without knowing a lot about the details....  Could do something
>> like:
>>
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>>
>> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>> satisfy your requirement.
>>
>> jacy
>>
>> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>> wrote:
>> > While designing a multiversion data structure I wrote a simple thread
>> > synchronization based on "volatile".
>> >
>> > The shared data is made of a base list, and a volatile "replacement"
>> list.
>> >    List base = ...;
>> >    volatile List replacement = null;
>> >
>> > There is only one writer thread. The writer thread will change some
>> elements
>> > in the list. It creates a copy of the original list, puts it as the
>> > replacement (volatile write). It is thought that the replacement list
>> can
>> > "hide" the base and that the modifications can be safely written into
>> the
>> > base list.
>> >    List replacement = new SubList();
>> >    transfer(shared.base, replacement)
>> >    shared.replacement = replacement;
>> >    ...
>> >    modify(shared.base);
>> >
>> > There are multiple readers, concurrently with the writer. If a reader
>> sees a
>> > replacement list, it will read values from it. Else it reads data from
>> the
>> > base list and before returning it checks that the replacement was not
>> set in
>> > the meantime.
>> >
>> >    List replacement;
>> >    for(;;) {
>> >       replacement = shared.replacement;
>> >  if(replacement != null) return replacement.get(index);
>> >  else {
>> >          Object value = shared.base.get(index);
>> > List tmp = replacement;
>> > replacement = shared.replacement;
>> > if(replacement = tmp) return value;
>> >  }
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>> >    }
>> >
>> >
>> > The design passes a modest set of unit tests on an x86 multi-core
>> processor
>> > but a colleague spotted a big flaw. This expects too much from the java
>> > memory model. The modifications to the base list that were thought to be
>> > invisible to readers could be reordered before the volatile write of the
>> > replacement. So a writer could read garbage from the base, think the
>> > replacement was not set and return the garbage.
>> >
>> >
>> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>> above
>> > design without resorting to synchronized blocks or locks ?
>> >
>> >
>> > Thanks a lot,
>> > -Antoine CHAMBILLE
>> > Quartet FS
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/1795cbf0/attachment-0001.html>

From zhong.j.yu at gmail.com  Thu Sep  6 16:19:52 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 6 Sep 2012 15:19:52 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
Message-ID: <CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>

In your simplified example, the only write is to replace an element at
an existing index. That's an easy problem to solve, e.g.

    volatile List list = new ArrayList();

    // writer
    list.set(i, newItem);
    list=list;  // to perform a volatile write

    // reader
    return list.get(i);

Your real problem probably involves more complex writes, where
multiple variables are updated non-atomically, confusing (if not
corrupting) concurrent readers. So you want to check whether there's
state change during a read session.

The reminds me of Doug Lea's SequenceLock

http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html

However note that in the example, x and y are volatile. There are
minimum 4 volatile reads in the read-only method, even in this very
simple use case.

Zhong Yu


On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
> Hi all,
>
> Antoine's description was a simplified version of our issue, so let me try
> to describe the actual problem.
>
> The key thing is that the list that is being "multi-versioned" is very large
> while each modification only affects a few elements.
> The idea is therefore not to create a full copy for each version (like
> CopyOnWriteArrayList or some very good suggestions on this list), but to
> simply store a "delta" with the previous version.
>
> Here is a simple example.
> Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very large
> structure for the sake of the example).
> The first version of this list would look like this:
> L1 = { base = L; delta = null; }
>
> Any reader thread that wants to access the list at this point gets L1, and
> all the read requests are forwarded to the base.
>
> Now a writer comes in and wants to change the first element to 5. We will,
> in the writer thread
>   1) create a delta structure with this new mapping: D1 = {element 0: 1->5 }
>   2) create a new version L2 = { base = L; delta = null; }
>   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>   4) update L to (5, 2, 3, 4)
>
> Any reader thread that had a reference to L1 will do the following to read a
> value:
>  1) Look for it in the delta. If we find it in there, return the "previous"
> value
>  2) The value is not in the delta. Forward the read request to L2 (that will
> itself forward it to L), then make sure the delta has not been updated if it
> was null before, and return. Otherwise, go back to 1).
>
> This looks like it would work nicely: we are updating L1's base and delta
> through volatile writes, hence "masking" the first element in the list.
>
> However, we spotted the issue mentioned before: because the writes to L in
> step 4 are not volatile (and we'd like to avoid the cost), they can be
> reordered before step 3 where we set L1's base and delta through volatile
> writes (roach motel semantics).
> Therefore, a reader of L1 could read the delta field that is still null and
> get the value from L which is now set to 5, which is incorrect.
>
> As Antoine mentioned, we never observed that in our tests (seeing a null
> version of L1.delta while seeing the updates to L), but it seems that this
> could happen under the JMM.
> Is this correct? Do you see any ways around it?
>
> Thanks!
>
>
> --
> Romain Colle
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu>
> wrote:
>>
>> Well, without knowing a lot about the details....  Could do something
>> like:
>>
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>>
>> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>> satisfy your requirement.
>>
>> jacy
>>
>> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>> wrote:
>> > While designing a multiversion data structure I wrote a simple thread
>> > synchronization based on "volatile".
>> >
>> > The shared data is made of a base list, and a volatile "replacement"
>> > list.
>> >    List base = ...;
>> >    volatile List replacement = null;
>> >
>> > There is only one writer thread. The writer thread will change some
>> > elements
>> > in the list. It creates a copy of the original list, puts it as the
>> > replacement (volatile write). It is thought that the replacement list
>> > can
>> > "hide" the base and that the modifications can be safely written into
>> > the
>> > base list.
>> >    List replacement = new SubList();
>> >    transfer(shared.base, replacement)
>> >    shared.replacement = replacement;
>> >    ...
>> >    modify(shared.base);
>> >
>> > There are multiple readers, concurrently with the writer. If a reader
>> > sees a
>> > replacement list, it will read values from it. Else it reads data from
>> > the
>> > base list and before returning it checks that the replacement was not
>> > set in
>> > the meantime.
>> >
>> >    List replacement;
>> >    for(;;) {
>> >       replacement = shared.replacement;
>> >  if(replacement != null) return replacement.get(index);
>> >  else {
>> >          Object value = shared.base.get(index);
>> > List tmp = replacement;
>> > replacement = shared.replacement;
>> > if(replacement = tmp) return value;
>> >  }
>>
>>    private volatile List base = new ArrayList();
>>
>>    private void write()
>>    {
>>       List copy = new ArrayList(base);
>>       //do writes to copy
>>       base = copy;
>>    }
>>
>>    private void read()
>>    {
>>       List local = base;
>>       // do reading using the local variable, NOT the volatile shared
>> variable.  this is essential,
>>       // must only read the replacement variable 1x for any set of
>> reads you expect to be consistent.
>>       // of course, if you only have a single read, you could dispense
>> with the local variable, but just
>>       // bear in mind that the contents of base could be different
>> each time you reference it.
>>    }
>> >    }
>> >
>> >
>> > The design passes a modest set of unit tests on an x86 multi-core
>> > processor
>> > but a colleague spotted a big flaw. This expects too much from the java
>> > memory model. The modifications to the base list that were thought to be
>> > invisible to readers could be reordered before the volatile write of the
>> > replacement. So a writer could read garbage from the base, think the
>> > replacement was not set and return the garbage.
>> >
>> >
>> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>> > above
>> > design without resorting to synchronized blocks or locks ?
>> >
>> >
>> > Thanks a lot,
>> > -Antoine CHAMBILLE
>> > Quartet FS
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From csgzlong at iastate.edu  Thu Sep  6 23:37:20 2012
From: csgzlong at iastate.edu (Yuheng Long)
Date: Thu, 6 Sep 2012 22:37:20 -0500
Subject: [concurrency-interest] help show speed-up on a recursive divided
	and conquer example
Message-ID: <CAHYWNzA-qy3ej-6gpbrtMexrKov6t2BJh02nE-dBFbyHn9Ootw@mail.gmail.com>

Hi all,
    Would you please help on why the attached program (also
inlined below) runs the sequential version faster than the
parallel version? I apologize if I have missed something.
    Note that the example is taken from the fj framework.
I used the original fj framework to parallelize it.
I also used jsr to parallelize it.
All experiments are average in 10 runs.
The sequential version finishes in 10    seconds.
The fj              version finishes in 18    seconds.
The jsr            version finishes in 10.5 seconds.

I used the input as the paper
     http://gee.cs.oswego.edu/dl/papers/fj.pdf
Integrate: Recursive Gaussian quadrature of
          (2*i-1)*x^{(2*i-1)}
summing over odd values of i from 1 to 5 and integrating
from -47 to 48.
But I did not see any speedup as shown in the paper.
I did the experiments in a system with a total of 4 cores
running Fedora GNU/Linux.

Thank you very much,
Sincerely,
Yuheng

//////// sequential
//////////////////////////////////////////////////////////////////////////////////////
/**
 * Sample program using Guassian Quadrature for numerical integration.
 * Inspired by a
 * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
 * demo program. */
public class IntegrateSequential {
    public static void main(String[] args) {
        double start = -47;
        double end = 48;

        Function f = new SampleFunction(6);
        Integrator integrator = new Integrator(f, 0.001);

        double result = integrator.integral(start, end);

        System.out.println("Answer = " + result);
    }

    static interface Function {
        double compute(double x);
    }

    static class SampleFunction implements Function {
        final int n;
        SampleFunction(int n) { this.n = n; }

        public double compute(double x)  {
            double power = x;
            double xsq = x * x;
            double val = power;
            double di = 1.0;
            for (int i = n - 1; i > 0; --i) {
                di += 2.0;
                power *= xsq;
                val += di * power;
            }
            return val;
        }
    }

    static class Integrator {
        final Function f;      // The function to integrate
        final double errorTolerance;

        Integrator(Function f, double errorTolerance) {
            this.f = f;
            this.errorTolerance = errorTolerance;
        }

        double integral(double lowerBound, double upperBound) {
            double f_lower = f.compute(lowerBound);
            double f_upper = f.compute(upperBound);
            double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
f_lower);
            Quad q = new Quad(f, errorTolerance);
            return q.run(lowerBound, upperBound, f_lower, f_upper,
initialArea);
        }

        static class Quad {
            final Function f;
            final double errorTolerance;

            Quad(Function f, double errorTolerance) {
                this.f = f;
                this.errorTolerance = errorTolerance;
            }

            public double run(double left, double right, double f_left,
double f_right, double area) {
                double center = 0.5 * (left + right);
                double f_center = f.compute(center);

                double leftArea  = 0.5 * (center - left)  * (f_left +
f_center);
                double rightArea = 0.5 * (right - center) * (f_center +
f_right);
                double sum = leftArea + rightArea;

                double diff = sum - area;
                if (diff < 0) diff = -diff;

                if (diff >= errorTolerance) {
                    double q1 = run(left, center, f_left, f_center,
leftArea);
                    double q2 = run(center, right,  f_center, f_right,
rightArea);
                    sum = q1 + q2;
                }

                return sum;
            }
        }
    }
}

//////// forkjoin
//////////////////////////////////////////////////////////////////////////////////////
import EDU.oswego.cs.dl.util.concurrent.*;


/**
 * Sample program using Guassian Quadrature for numerical integration.
 * Inspired by a
 * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
 * demo program.
 *
 */

public class IntegrateForkJoin {
    public static void main(String[] args) {
        int procs = 4;
        double start = -47;
        double end = 48;

        Function f = new SampleFunction(6);
        FJTaskRunnerGroup group = new FJTaskRunnerGroup(procs);
        Integrator integrator = new Integrator(f, 0.001, group);

        double result = integrator.integral(start, end);
        System.out.println("Answer = " + result);
    }

    /*
    This is all set up as if it were part of a more serious
    framework, but is for now just a demo, with all
    classes declared as static within Integrate
     */

    /** A function to be integrated **/
    static interface Function {
        double compute(double x);
    }

    /**
     * Sample from filaments demo.
     * Computes (2*n-1)*(x^(2*n-1)) for all odd values
     **/
    static class SampleFunction implements Function {
        final int n;
        SampleFunction(int n) { this.n = n; }

        public double compute(double x)  {
            double power = x;
            double xsq = x * x;
            double val = power;
            double di = 1.0;
            for (int i = n - 1; i > 0; --i) {
                di += 2.0;
                power *= xsq;
                val += di * power;
            }
            return val;
        }
    }


    static class Integrator {
        final Function f;      // The function to integrate
        final double errorTolerance;
        final FJTaskRunnerGroup group;

        Integrator(Function f, double errorTolerance, FJTaskRunnerGroup
group) {
            this.f = f;
            this.errorTolerance = errorTolerance;
            this.group = group;
        }

        double integral(double lowerBound, double upperBound) {
            double f_lower = f.compute(lowerBound);
            double f_upper = f.compute(upperBound);
            double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
f_lower);
            Quad q = new Quad(lowerBound, upperBound,
                    f_lower, f_upper,
                    initialArea);
            try {
                group.invoke(q);
                return q.area;
            }
            catch(InterruptedException ex) {
                Thread.currentThread().interrupt();
                throw new Error("Interrupted during computation");
            }
        }


        /**
         * FJTask to recursively perform the quadrature.
         * Algorithm:
         *  Compute the area from lower bound to the center point of
interval,
         *  and from the center point to the upper bound. If this
         *  differs from the value from lower to upper by more than
         *  the error tolerance, recurse on each half.
         **/
        class Quad extends FJTask {
            final double left;       // lower bound
            final double right;      // upper bound
            final double f_left;     // value of the function evaluated at
left
            final double f_right;    // value of the function evaluated at
right

            // Area initialized with original estimate from left to right.
            // It is replaced with refined value.
            volatile double area;

            Quad(double left, double right,
                    double f_left, double f_right,
                    double area) {
                this.left = left;
                this.right = right;
                this.f_left = f_left;
                this.f_right = f_right;
                this.area = area;
            }

            public void run() {
                double center = 0.5 * (left + right);
                double f_center = f.compute(center);

                double leftArea  = 0.5 * (center - left)  * (f_left +
f_center);
                double rightArea = 0.5 * (right - center) * (f_center +
f_right);
                double sum = leftArea + rightArea;

                double diff = sum - area;
                if (diff < 0) diff = -diff;

                if (diff >= errorTolerance) {
                    Quad q1 = new Quad(left,   center, f_left,   f_center,
leftArea);
                    Quad q2 = new Quad(center, right,  f_center, f_right,
rightArea);
                    coInvoke(q1, q2);
                    sum = q1.area + q2.area;
                }

                area = sum;
            }
        }
    }
}

//////// jsr
//////////////////////////////////////////////////////////////////////////////////////
import java.util.concurrent.*;

/**
 * Sample program using Guassian Quadrature for numerical integration.
 * Inspired by a
 * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
 * demo program.
 *
 */

public class IntegrateJSR {
    public static void main(String[] args) {
        double start = -47;
        double end = 48;

        Function f = new SampleFunction(6);
        ForkJoinPool fjp = new ForkJoinPool();
        Integrator integrator = new Integrator(f, 0.001, fjp);

        double result = integrator.integral(start, end);

        System.out.println("Answer = " + result);
    }

    /*
    This is all set up as if it were part of a more serious
    framework, but is for now just a demo, with all
    classes declared as static within Integrate
     */

    /** A function to be integrated **/
    static interface Function {
        double compute(double x);
    }

    /**
     * Sample from filaments demo.
     * Computes (2*n-1)*(x^(2*n-1)) for all odd values
     **/
    static class SampleFunction implements Function {
        final int n;
        SampleFunction(int n) { this.n = n; }

        public double compute(double x)  {
            double power = x;
            double xsq = x * x;
            double val = power;
            double di = 1.0;
            for (int i = n - 1; i > 0; --i) {
                di += 2.0;
                power *= xsq;
                val += di * power;
            }
            return val;
        }
    }


    static class Integrator {
        final Function f;      // The function to integrate
        final double errorTolerance;
        final ForkJoinPool group;

        Integrator(Function f, double errorTolerance, ForkJoinPool group) {
            this.f = f;
            this.errorTolerance = errorTolerance;
            this.group = group;
        }

        double integral(double lowerBound, double upperBound) {
            double f_lower = f.compute(lowerBound);
            double f_upper = f.compute(upperBound);
            double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
f_lower);
            Quad q = new Quad(f, errorTolerance, lowerBound, upperBound,
                              f_lower, f_upper, initialArea);

            group.invoke(q);
            return q.getRawResult();
        }


        /**
         * FJTask to recursively perform the quadrature.
         * Algorithm:
         *  Compute the area from lower bound to the center point of
interval,
         *  and from the center point to the upper bound. If this
         *  differs from the value from lower to upper by more than
         *  the error tolerance, recurse on each half.
         **/
        static class Quad extends ForkJoinTask<Double> {
            private static final long serialVersionUID =
5232453952276485270L;

            private Double result;

            public final Double getRawResult() {
                return result;
            }

            protected final void setRawResult(Double value) {
                result = value;
            }

            protected final boolean exec() {
                result = compute();
                return true;
            }

            final Function f;      // The function to integrate
            final double errorTolerance;

            final double left;
            final double right;
            final double f_left;
            final double f_right;
            final double area;

            Quad(Function f, double errorTolerance, double left, double
right,
                 double f_left, double f_right, double area) {
                this.f = f;
                this.errorTolerance = errorTolerance;
                this.left = left;
                this.right = right;
                this.f_left = f_left;
                this.f_right = f_right;
                this.area = area;
            }

            protected Double compute () {
                double center = 0.5 * (left + right);
                double f_center = f.compute(center);

                double leftArea  = 0.5 * (center - left)  * (f_left +
f_center);
                double rightArea = 0.5 * (right - center) * (f_center +
f_right);
                double sum = leftArea + rightArea;

                double diff = sum - area;
                if (diff < 0) diff = -diff;

                if (diff >= errorTolerance) {
                    Quad q1 = new Quad(f, errorTolerance, left, center,
f_left,
                                       f_center, leftArea);
                    q1.fork();
                    Quad q2 = new Quad(f, errorTolerance, center, right,
                                       f_center, f_right,  rightArea);

                    sum = q2.compute() + q1.join();
                }

                return sum;
            }
        }
    }
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/ce12f664/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: IntegrateForkJoin.java
Type: application/octet-stream
Size: 3734 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/ce12f664/attachment-0003.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: IntegrateJSR.java
Type: application/octet-stream
Size: 3927 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/ce12f664/attachment-0004.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: IntegrateSequential.java
Type: application/octet-stream
Size: 2330 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120906/ce12f664/attachment-0005.obj>

From kasperni at gmail.com  Fri Sep  7 04:26:45 2012
From: kasperni at gmail.com (Kasper Nielsen)
Date: Fri, 7 Sep 2012 10:26:45 +0200
Subject: [concurrency-interest] help show speed-up on a recursive
 divided and conquer example
In-Reply-To: <CAHYWNzA-qy3ej-6gpbrtMexrKov6t2BJh02nE-dBFbyHn9Ootw@mail.gmail.com>
References: <CAHYWNzA-qy3ej-6gpbrtMexrKov6t2BJh02nE-dBFbyHn9Ootw@mail.gmail.com>
Message-ID: <CAPs61533dakgK9eEVwU-yY4iSZXQ180_FEWUYbSG4Y=jiDkVsA@mail.gmail.com>

Hi Yuheng

The FJ paper was written more than 10 years running on computers with
a lot less MIPS and a less advanced JIT.
On modern day hardware you just need to do more work per chunk. To
avoid your runtime being dominated by the overhead of the FJ
framework.

So I am pretty sure it is the SampleFunction that is doing to little work.
Try changing exp = 5 to exp = 50 (or even more).

cheers
  Kasper

On Fri, Sep 7, 2012 at 5:37 AM, Yuheng Long <csgzlong at iastate.edu> wrote:
> Hi all,
>     Would you please help on why the attached program (also
> inlined below) runs the sequential version faster than the
> parallel version? I apologize if I have missed something.
>     Note that the example is taken from the fj framework.
> I used the original fj framework to parallelize it.
> I also used jsr to parallelize it.
> All experiments are average in 10 runs.
> The sequential version finishes in 10    seconds.
> The fj              version finishes in 18    seconds.
> The jsr            version finishes in 10.5 seconds.
>
> I used the input as the paper
>      http://gee.cs.oswego.edu/dl/papers/fj.pdf
> Integrate: Recursive Gaussian quadrature of
>           (2*i-1)*x^{(2*i-1)}
> summing over odd values of i from 1 to 5 and integrating
> from -47 to 48.
> But I did not see any speedup as shown in the paper.
> I did the experiments in a system with a total of 4 cores
> running Fedora GNU/Linux.
>
> Thank you very much,
> Sincerely,
> Yuheng
>
> //////// sequential
> //////////////////////////////////////////////////////////////////////////////////////
> /**
>  * Sample program using Guassian Quadrature for numerical integration.
>  * Inspired by a
>  * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
>  * demo program. */
> public class IntegrateSequential {
>     public static void main(String[] args) {
>         double start = -47;
>         double end = 48;
>
>         Function f = new SampleFunction(6);
>         Integrator integrator = new Integrator(f, 0.001);
>
>         double result = integrator.integral(start, end);
>
>         System.out.println("Answer = " + result);
>     }
>
>     static interface Function {
>         double compute(double x);
>     }
>
>     static class SampleFunction implements Function {
>         final int n;
>         SampleFunction(int n) { this.n = n; }
>
>         public double compute(double x)  {
>             double power = x;
>             double xsq = x * x;
>             double val = power;
>             double di = 1.0;
>             for (int i = n - 1; i > 0; --i) {
>                 di += 2.0;
>                 power *= xsq;
>                 val += di * power;
>             }
>             return val;
>         }
>     }
>
>     static class Integrator {
>         final Function f;      // The function to integrate
>         final double errorTolerance;
>
>         Integrator(Function f, double errorTolerance) {
>             this.f = f;
>             this.errorTolerance = errorTolerance;
>         }
>
>         double integral(double lowerBound, double upperBound) {
>             double f_lower = f.compute(lowerBound);
>             double f_upper = f.compute(upperBound);
>             double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
> f_lower);
>             Quad q = new Quad(f, errorTolerance);
>             return q.run(lowerBound, upperBound, f_lower, f_upper,
> initialArea);
>         }
>
>         static class Quad {
>             final Function f;
>             final double errorTolerance;
>
>             Quad(Function f, double errorTolerance) {
>                 this.f = f;
>                 this.errorTolerance = errorTolerance;
>             }
>
>             public double run(double left, double right, double f_left,
> double f_right, double area) {
>                 double center = 0.5 * (left + right);
>                 double f_center = f.compute(center);
>
>                 double leftArea  = 0.5 * (center - left)  * (f_left +
> f_center);
>                 double rightArea = 0.5 * (right - center) * (f_center +
> f_right);
>                 double sum = leftArea + rightArea;
>
>                 double diff = sum - area;
>                 if (diff < 0) diff = -diff;
>
>                 if (diff >= errorTolerance) {
>                     double q1 = run(left, center, f_left, f_center,
> leftArea);
>                     double q2 = run(center, right,  f_center, f_right,
> rightArea);
>                     sum = q1 + q2;
>                 }
>
>                 return sum;
>             }
>         }
>     }
> }
>
> //////// forkjoin
> //////////////////////////////////////////////////////////////////////////////////////
> import EDU.oswego.cs.dl.util.concurrent.*;
>
>
> /**
>  * Sample program using Guassian Quadrature for numerical integration.
>  * Inspired by a
>  * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
>  * demo program.
>  *
>  */
>
> public class IntegrateForkJoin {
>     public static void main(String[] args) {
>         int procs = 4;
>         double start = -47;
>         double end = 48;
>
>         Function f = new SampleFunction(6);
>         FJTaskRunnerGroup group = new FJTaskRunnerGroup(procs);
>         Integrator integrator = new Integrator(f, 0.001, group);
>
>         double result = integrator.integral(start, end);
>         System.out.println("Answer = " + result);
>     }
>
>     /*
>     This is all set up as if it were part of a more serious
>     framework, but is for now just a demo, with all
>     classes declared as static within Integrate
>      */
>
>     /** A function to be integrated **/
>     static interface Function {
>         double compute(double x);
>     }
>
>     /**
>      * Sample from filaments demo.
>      * Computes (2*n-1)*(x^(2*n-1)) for all odd values
>      **/
>     static class SampleFunction implements Function {
>         final int n;
>         SampleFunction(int n) { this.n = n; }
>
>         public double compute(double x)  {
>             double power = x;
>             double xsq = x * x;
>             double val = power;
>             double di = 1.0;
>             for (int i = n - 1; i > 0; --i) {
>                 di += 2.0;
>                 power *= xsq;
>                 val += di * power;
>             }
>             return val;
>         }
>     }
>
>
>     static class Integrator {
>         final Function f;      // The function to integrate
>         final double errorTolerance;
>         final FJTaskRunnerGroup group;
>
>         Integrator(Function f, double errorTolerance, FJTaskRunnerGroup
> group) {
>             this.f = f;
>             this.errorTolerance = errorTolerance;
>             this.group = group;
>         }
>
>         double integral(double lowerBound, double upperBound) {
>             double f_lower = f.compute(lowerBound);
>             double f_upper = f.compute(upperBound);
>             double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
> f_lower);
>             Quad q = new Quad(lowerBound, upperBound,
>                     f_lower, f_upper,
>                     initialArea);
>             try {
>                 group.invoke(q);
>                 return q.area;
>             }
>             catch(InterruptedException ex) {
>                 Thread.currentThread().interrupt();
>                 throw new Error("Interrupted during computation");
>             }
>         }
>
>
>         /**
>          * FJTask to recursively perform the quadrature.
>          * Algorithm:
>          *  Compute the area from lower bound to the center point of
> interval,
>          *  and from the center point to the upper bound. If this
>          *  differs from the value from lower to upper by more than
>          *  the error tolerance, recurse on each half.
>          **/
>         class Quad extends FJTask {
>             final double left;       // lower bound
>             final double right;      // upper bound
>             final double f_left;     // value of the function evaluated at
> left
>             final double f_right;    // value of the function evaluated at
> right
>
>             // Area initialized with original estimate from left to right.
>             // It is replaced with refined value.
>             volatile double area;
>
>             Quad(double left, double right,
>                     double f_left, double f_right,
>                     double area) {
>                 this.left = left;
>                 this.right = right;
>                 this.f_left = f_left;
>                 this.f_right = f_right;
>                 this.area = area;
>             }
>
>             public void run() {
>                 double center = 0.5 * (left + right);
>                 double f_center = f.compute(center);
>
>                 double leftArea  = 0.5 * (center - left)  * (f_left +
> f_center);
>                 double rightArea = 0.5 * (right - center) * (f_center +
> f_right);
>                 double sum = leftArea + rightArea;
>
>                 double diff = sum - area;
>                 if (diff < 0) diff = -diff;
>
>                 if (diff >= errorTolerance) {
>                     Quad q1 = new Quad(left,   center, f_left,   f_center,
> leftArea);
>                     Quad q2 = new Quad(center, right,  f_center, f_right,
> rightArea);
>                     coInvoke(q1, q2);
>                     sum = q1.area + q2.area;
>                 }
>
>                 area = sum;
>             }
>         }
>     }
> }
>
> //////// jsr
> //////////////////////////////////////////////////////////////////////////////////////
> import java.util.concurrent.*;
>
> /**
>  * Sample program using Guassian Quadrature for numerical integration.
>  * Inspired by a
>  * <A href="http://www.cs.uga.edu/~dkl/filaments/dist.html"> Filaments</A>
>  * demo program.
>  *
>  */
>
> public class IntegrateJSR {
>     public static void main(String[] args) {
>         double start = -47;
>         double end = 48;
>
>         Function f = new SampleFunction(6);
>         ForkJoinPool fjp = new ForkJoinPool();
>         Integrator integrator = new Integrator(f, 0.001, fjp);
>
>         double result = integrator.integral(start, end);
>
>         System.out.println("Answer = " + result);
>     }
>
>     /*
>     This is all set up as if it were part of a more serious
>     framework, but is for now just a demo, with all
>     classes declared as static within Integrate
>      */
>
>     /** A function to be integrated **/
>     static interface Function {
>         double compute(double x);
>     }
>
>     /**
>      * Sample from filaments demo.
>      * Computes (2*n-1)*(x^(2*n-1)) for all odd values
>      **/
>     static class SampleFunction implements Function {
>         final int n;
>         SampleFunction(int n) { this.n = n; }
>
>         public double compute(double x)  {
>             double power = x;
>             double xsq = x * x;
>             double val = power;
>             double di = 1.0;
>             for (int i = n - 1; i > 0; --i) {
>                 di += 2.0;
>                 power *= xsq;
>                 val += di * power;
>             }
>             return val;
>         }
>     }
>
>
>     static class Integrator {
>         final Function f;      // The function to integrate
>         final double errorTolerance;
>         final ForkJoinPool group;
>
>         Integrator(Function f, double errorTolerance, ForkJoinPool group) {
>             this.f = f;
>             this.errorTolerance = errorTolerance;
>             this.group = group;
>         }
>
>         double integral(double lowerBound, double upperBound) {
>             double f_lower = f.compute(lowerBound);
>             double f_upper = f.compute(upperBound);
>             double initialArea = 0.5 * (upperBound-lowerBound) * (f_upper +
> f_lower);
>             Quad q = new Quad(f, errorTolerance, lowerBound, upperBound,
>                               f_lower, f_upper, initialArea);
>
>             group.invoke(q);
>             return q.getRawResult();
>         }
>
>
>         /**
>          * FJTask to recursively perform the quadrature.
>          * Algorithm:
>          *  Compute the area from lower bound to the center point of
> interval,
>          *  and from the center point to the upper bound. If this
>          *  differs from the value from lower to upper by more than
>          *  the error tolerance, recurse on each half.
>          **/
>         static class Quad extends ForkJoinTask<Double> {
>             private static final long serialVersionUID =
> 5232453952276485270L;
>
>             private Double result;
>
>             public final Double getRawResult() {
>                 return result;
>             }
>
>             protected final void setRawResult(Double value) {
>                 result = value;
>             }
>
>             protected final boolean exec() {
>                 result = compute();
>                 return true;
>             }
>
>             final Function f;      // The function to integrate
>             final double errorTolerance;
>
>             final double left;
>             final double right;
>             final double f_left;
>             final double f_right;
>             final double area;
>
>             Quad(Function f, double errorTolerance, double left, double
> right,
>                  double f_left, double f_right, double area) {
>                 this.f = f;
>                 this.errorTolerance = errorTolerance;
>                 this.left = left;
>                 this.right = right;
>                 this.f_left = f_left;
>                 this.f_right = f_right;
>                 this.area = area;
>             }
>
>             protected Double compute () {
>                 double center = 0.5 * (left + right);
>                 double f_center = f.compute(center);
>
>                 double leftArea  = 0.5 * (center - left)  * (f_left +
> f_center);
>                 double rightArea = 0.5 * (right - center) * (f_center +
> f_right);
>                 double sum = leftArea + rightArea;
>
>                 double diff = sum - area;
>                 if (diff < 0) diff = -diff;
>
>                 if (diff >= errorTolerance) {
>                     Quad q1 = new Quad(f, errorTolerance, left, center,
> f_left,
>                                        f_center, leftArea);
>                     q1.fork();
>                     Quad q2 = new Quad(f, errorTolerance, center, right,
>                                        f_center, f_right,  rightArea);
>
>                     sum = q2.compute() + q1.join();
>                 }
>
>                 return sum;
>             }
>         }
>     }
> }
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From ach at quartetfs.com  Fri Sep  7 06:09:48 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Fri, 7 Sep 2012 12:09:48 +0200
Subject: [concurrency-interest] [Volatile Store,
	Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
Message-ID: <CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>

Dear All,

Thanks a lot for your interest and the help so far.

I apologize for oversimplifying the design. When I read the top of this
thread I realize that CopyOnWriteArrayList or equivalent proposed by Zhong,
Oleksander and Jacy would work well.

Thanks to Romain the right amount of detail was added. But after reading
the subsequent respsonses I understand that more context is needed.



The goal is to achieve efficient lock-free multi-versioning for large data
sets.
Imagine a large table in a database, with one billion values. There are
frequent updates to the table, written in small batches, by a single writer
thread. A batch may modify thousands of values but that remains a tiny bit
of the whole table. Each update batch introduces one new "version" of the
table.

There are tens of concurrent readers, that query the table. For the
duration of a query, a reader must of course see the same version of the
table. We want to avoid the simple approach: a read-write lock between
readers and the writer. We don't want a long running query to postpone the
next update. We don't want queries to be rejected or postponed while the
writer awaits or owns the write lock. A multi-version concurrency control
design is thus required.


The table being huge we discarded the pure copy on write approach. We use
"delta" structures that look like tiny transaction logs:

[version #0] (initial state), a table with 4 cells: [0, 1, 2, 3]

[delta #1] we change the content of cells 0 and 3:
   0: 0 -> 4
   3: 3 -> 5

[version #1]: [4, 1, 2, 5]


A fairly simple approach would be to leave the (large) base data immutable
and recursively chain delta stuctures on top of it. Obtaining a version
simply means locating the right delta in the linked list. Versions are
stable by construction as the base is immutable and new versions are pushed
earlier in the chain.


But by far the most common read pattern is to execute a small query on the
latest version of the data. And the above solution makes this most common
use case very inefficient: After a significant number of updates, each read
must go through a cascade of lookups in delta stuctures down to the base.
The most recent version is the furthest from the base data.


That's why I thought about reversing the design: The (large) base data
always contains the latest state, delta structures record the "before
update" values of modified cells, and the latest version is the closest to
the base data.

Let's see how it works with our previous update example:
   * Inject [delta #1] into [version #0]. When a reader of [version #0]
sees a delta was injected and reads a cell that is mapped in the delta, it
reads the previous value of that cells without looking at the base.
   * When we are sure that readers of [version #0] see the delta, then the
cells of the base data are hidden from readers and we can safely reuse them.
   * Modify the cells in the base data.
   * Create [version #1] that points directrly to the base (and does not
yet have any delta)
   * Upcoming readers will see [version #1]


For this to work we need to be sure that readers will realize a delta was
injected in their version, before we write (reuse) the cells of the base
data. I initially hoped that a volatile write of the delta into the version
would work. It seems to be the case on x86. But the Java Memory Model
promises nothing. When cells are updated in the base data that's a "normal
store" and it could theoretically be reordered with the delta injection
"volatile store". And as an update batch potentially contains thousands of
writes, making all those writes volatile is not a good option.


I am a bit distraught I have to abandon a design that looked neat ;) Do you
think we can still make it work?


-Antoine CHAMBILLE
Quartet FS




On 6 September 2012 22:19, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> In your simplified example, the only write is to replace an element at
> an existing index. That's an easy problem to solve, e.g.
>
>     volatile List list = new ArrayList();
>
>     // writer
>     list.set(i, newItem);
>     list=list;  // to perform a volatile write
>
>     // reader
>     return list.get(i);
>
> Your real problem probably involves more complex writes, where
> multiple variables are updated non-atomically, confusing (if not
> corrupting) concurrent readers. So you want to check whether there's
> state change during a read session.
>
> The reminds me of Doug Lea's SequenceLock
>
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>
> However note that in the example, x and y are volatile. There are
> minimum 4 volatile reads in the read-only method, even in this very
> simple use case.
>
> Zhong Yu
>
>
> On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
> > Hi all,
> >
> > Antoine's description was a simplified version of our issue, so let me
> try
> > to describe the actual problem.
> >
> > The key thing is that the list that is being "multi-versioned" is very
> large
> > while each modification only affects a few elements.
> > The idea is therefore not to create a full copy for each version (like
> > CopyOnWriteArrayList or some very good suggestions on this list), but to
> > simply store a "delta" with the previous version.
> >
> > Here is a simple example.
> > Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
> large
> > structure for the sake of the example).
> > The first version of this list would look like this:
> > L1 = { base = L; delta = null; }
> >
> > Any reader thread that wants to access the list at this point gets L1,
> and
> > all the read requests are forwarded to the base.
> >
> > Now a writer comes in and wants to change the first element to 5. We
> will,
> > in the writer thread
> >   1) create a delta structure with this new mapping: D1 = {element 0:
> 1->5 }
> >   2) create a new version L2 = { base = L; delta = null; }
> >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
> >   4) update L to (5, 2, 3, 4)
> >
> > Any reader thread that had a reference to L1 will do the following to
> read a
> > value:
> >  1) Look for it in the delta. If we find it in there, return the
> "previous"
> > value
> >  2) The value is not in the delta. Forward the read request to L2 (that
> will
> > itself forward it to L), then make sure the delta has not been updated
> if it
> > was null before, and return. Otherwise, go back to 1).
> >
> > This looks like it would work nicely: we are updating L1's base and delta
> > through volatile writes, hence "masking" the first element in the list.
> >
> > However, we spotted the issue mentioned before: because the writes to L
> in
> > step 4 are not volatile (and we'd like to avoid the cost), they can be
> > reordered before step 3 where we set L1's base and delta through volatile
> > writes (roach motel semantics).
> > Therefore, a reader of L1 could read the delta field that is still null
> and
> > get the value from L which is now set to 5, which is incorrect.
> >
> > As Antoine mentioned, we never observed that in our tests (seeing a null
> > version of L1.delta while seeing the updates to L), but it seems that
> this
> > could happen under the JMM.
> > Is this correct? Do you see any ways around it?
> >
> > Thanks!
> >
> >
> > --
> > Romain Colle
> > QuartetFS
> > 2 rue Jean Lantier, 75001 Paris, France
> > http://www.quartetfs.com
> >
> > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu
> >
> > wrote:
> >>
> >> Well, without knowing a lot about the details....  Could do something
> >> like:
> >>
> >>
> >>    private volatile List base = new ArrayList();
> >>
> >>    private void write()
> >>    {
> >>       List copy = new ArrayList(base);
> >>       //do writes to copy
> >>       base = copy;
> >>    }
> >>
> >>    private void read()
> >>    {
> >>       List local = base;
> >>       // do reading using the local variable, NOT the volatile shared
> >> variable.  this is essential,
> >>       // must only read the replacement variable 1x for any set of
> >> reads you expect to be consistent.
> >>       // of course, if you only have a single read, you could dispense
> >> with the local variable, but just
> >>       // bear in mind that the contents of base could be different
> >> each time you reference it.
> >>    }
> >>
> >> Of course, it would also be worth seeing if CopyOnWriteArrayList can
> >> satisfy your requirement.
> >>
> >> jacy
> >>
> >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
> >> wrote:
> >> > While designing a multiversion data structure I wrote a simple thread
> >> > synchronization based on "volatile".
> >> >
> >> > The shared data is made of a base list, and a volatile "replacement"
> >> > list.
> >> >    List base = ...;
> >> >    volatile List replacement = null;
> >> >
> >> > There is only one writer thread. The writer thread will change some
> >> > elements
> >> > in the list. It creates a copy of the original list, puts it as the
> >> > replacement (volatile write). It is thought that the replacement list
> >> > can
> >> > "hide" the base and that the modifications can be safely written into
> >> > the
> >> > base list.
> >> >    List replacement = new SubList();
> >> >    transfer(shared.base, replacement)
> >> >    shared.replacement = replacement;
> >> >    ...
> >> >    modify(shared.base);
> >> >
> >> > There are multiple readers, concurrently with the writer. If a reader
> >> > sees a
> >> > replacement list, it will read values from it. Else it reads data from
> >> > the
> >> > base list and before returning it checks that the replacement was not
> >> > set in
> >> > the meantime.
> >> >
> >> >    List replacement;
> >> >    for(;;) {
> >> >       replacement = shared.replacement;
> >> >  if(replacement != null) return replacement.get(index);
> >> >  else {
> >> >          Object value = shared.base.get(index);
> >> > List tmp = replacement;
> >> > replacement = shared.replacement;
> >> > if(replacement = tmp) return value;
> >> >  }
> >>
> >>    private volatile List base = new ArrayList();
> >>
> >>    private void write()
> >>    {
> >>       List copy = new ArrayList(base);
> >>       //do writes to copy
> >>       base = copy;
> >>    }
> >>
> >>    private void read()
> >>    {
> >>       List local = base;
> >>       // do reading using the local variable, NOT the volatile shared
> >> variable.  this is essential,
> >>       // must only read the replacement variable 1x for any set of
> >> reads you expect to be consistent.
> >>       // of course, if you only have a single read, you could dispense
> >> with the local variable, but just
> >>       // bear in mind that the contents of base could be different
> >> each time you reference it.
> >>    }
> >> >    }
> >> >
> >> >
> >> > The design passes a modest set of unit tests on an x86 multi-core
> >> > processor
> >> > but a colleague spotted a big flaw. This expects too much from the
> java
> >> > memory model. The modifications to the base list that were thought to
> be
> >> > invisible to readers could be reordered before the volatile write of
> the
> >> > replacement. So a writer could read garbage from the base, think the
> >> > replacement was not set and return the garbage.
> >> >
> >> >
> >> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
> >> > above
> >> > design without resorting to synchronized blocks or locks ?
> >> >
> >> >
> >> > Thanks a lot,
> >> > -Antoine CHAMBILLE
> >> > Quartet FS
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/61196a11/attachment-0001.html>

From oleksandr.otenko at oracle.com  Fri Sep  7 07:12:04 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Fri, 07 Sep 2012 12:12:04 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
Message-ID: <5049D684.1020000@oracle.com>

I think you are missing an important point in this description:

what is considered a consistent state the readers and writers can 
observe? (What is considered a consistent set of data a reader can use?)

For example, if all modifications a writer does are meant to be atomic, 
then you need to tie all values to a "epoch" in the data set evolution. 
Then if a reader sees a value with the version greater than the latets 
delta it observed, it means the reader needs to redo the reading.

eg

final List<Pair<Integer, V>> base = ...
volatile Pair<Integer, List<Modification<V>>> delta = new 
Pair(Integer.valueOf(0), EmptyList); // never null

reader:

List d = delta;

for(...) { // peek the values
   if (snd(d).contains(i)) {
    add_to_read_list(snd(d).get(i));
    continue;
   }
Pair<Integer, V> p = base.get(i);
   if (fst(p) > fst(d)) { // a concurrent write overlaps
    d = delta;
    reset_read_list_and_start_again;
    continue;
   }

   add_to_read_list(snd(p));
}

then writer can create and set the delta, and only then copy over to the 
base using normal writes.


Alex


On 07/09/2012 11:09, Antoine Chambille wrote:
> Dear All,
>
> Thanks a lot for your interest and the help so far.
>
> I apologize for oversimplifying the design. When I read the top of 
> this thread I realize that CopyOnWriteArrayList or equivalent proposed 
> by Zhong, Oleksander and Jacy would work well.
>
> Thanks to Romain the right amount of detail was added. But after 
> reading the subsequent respsonses I understand that more context is 
> needed.
>
>
>
> The goal is to achieve efficient lock-free multi-versioning for large 
> data sets.
> Imagine a large table in a database, with one billion values. There 
> are frequent updates to the table, written in small batches, by a 
> single writer thread. A batch may modify thousands of values but that 
> remains a tiny bit of the whole table. Each update batch introduces 
> one new "version" of the table.
>
> There are tens of concurrent readers, that query the table. For the 
> duration of a query, a reader must of course see the same version of 
> the table. We want to avoid the simple approach: a read-write lock 
> between readers and the writer. We don't want a long running query to 
> postpone the next update. We don't want queries to be rejected or 
> postponed while the writer awaits or owns the write lock. A 
> multi-version concurrency control design is thus required.
>
>
> The table being huge we discarded the pure copy on write approach. We 
> use "delta" structures that look like tiny transaction logs:
>
> [version #0] (initial state), a table with 4 cells: [0, 1, 2, 3]
>
> [delta #1] we change the content of cells 0 and 3:
>    0: 0 -> 4
>    3: 3 -> 5
> [version #1]: [4, 1, 2, 5]
>
>
> A fairly simple approach would be to leave the (large) base data 
> immutable and recursively chain delta stuctures on top of it. 
> Obtaining a version simply means locating the right delta in the 
> linked list. Versions are stable by construction as the base is 
> immutable and new versions are pushed earlier in the chain.
>
>
> But by far the most common read pattern is to execute a small query on 
> the latest version of the data. And the above solution makes this most 
> common use case very inefficient: After a significant number of 
> updates, each read must go through a cascade of lookups in delta 
> stuctures down to the base. The most recent version is the furthest 
> from the base data.
>
>
> That's why I thought about reversing the design: The (large) base data 
> always contains the latest state, delta structures record the "before 
> update" values of modified cells, and the latest version is the 
> closest to the base data.
>
> Let's see how it works with our previous update example:
>    * Inject [delta #1] into [version #0]. When a reader of [version 
> #0] sees a delta was injected and reads a cell that is mapped in the 
> delta, it reads the previous value of that cells without looking at 
> the base.
>    * When we are sure that readers of [version #0] see the delta, then 
> the cells of the base data are hidden from readers and we can safely 
> reuse them.
>    * Modify the cells in the base data.
>    * Create [version #1] that points directrly to the base (and does 
> not yet have any delta)
>    * Upcoming readers will see [version #1]
>
> For this to work we need to be sure that readers will realize a delta 
> was injected in their version, before we write (reuse) the cells of 
> the base data. I initially hoped that a volatile write of the delta 
> into the version would work. It seems to be the case on x86. But the 
> Java Memory Model promises nothing. When cells are updated in the base 
> data that's a "normal store" and it could theoretically be reordered 
> with the delta injection "volatile store". And as an update batch 
> potentially contains thousands of writes, making all those writes 
> volatile is not a good option.
>
>
> I am a bit distraught I have to abandon a design that looked neat ;) 
> Do you think we can still make it work?
>
>
> -Antoine CHAMBILLE
> Quartet FS
>
>
>
>
> On 6 September 2012 22:19, Zhong Yu <zhong.j.yu at gmail.com 
> <mailto:zhong.j.yu at gmail.com>> wrote:
>
>     In your simplified example, the only write is to replace an element at
>     an existing index. That's an easy problem to solve, e.g.
>
>         volatile List list = new ArrayList();
>
>         // writer
>         list.set(i, newItem);
>         list=list;  // to perform a volatile write
>
>         // reader
>         return list.get(i);
>
>     Your real problem probably involves more complex writes, where
>     multiple variables are updated non-atomically, confusing (if not
>     corrupting) concurrent readers. So you want to check whether there's
>     state change during a read session.
>
>     The reminds me of Doug Lea's SequenceLock
>
>     http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>
>     However note that in the example, x and y are volatile. There are
>     minimum 4 volatile reads in the read-only method, even in this very
>     simple use case.
>
>     Zhong Yu
>
>
>     On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com
>     <mailto:rco at quartetfs.com>> wrote:
>     > Hi all,
>     >
>     > Antoine's description was a simplified version of our issue, so
>     let me try
>     > to describe the actual problem.
>     >
>     > The key thing is that the list that is being "multi-versioned"
>     is very large
>     > while each modification only affects a few elements.
>     > The idea is therefore not to create a full copy for each version
>     (like
>     > CopyOnWriteArrayList or some very good suggestions on this
>     list), but to
>     > simply store a "delta" with the previous version.
>     >
>     > Here is a simple example.
>     > Let's assume our list is L=(1, 2, 3, 4). (it's not the
>     advertised very large
>     > structure for the sake of the example).
>     > The first version of this list would look like this:
>     > L1 = { base = L; delta = null; }
>     >
>     > Any reader thread that wants to access the list at this point
>     gets L1, and
>     > all the read requests are forwarded to the base.
>     >
>     > Now a writer comes in and wants to change the first element to
>     5. We will,
>     > in the writer thread
>     >   1) create a delta structure with this new mapping: D1 =
>     {element 0: 1->5 }
>     >   2) create a new version L2 = { base = L; delta = null; }
>     >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>     >   4) update L to (5, 2, 3, 4)
>     >
>     > Any reader thread that had a reference to L1 will do the
>     following to read a
>     > value:
>     >  1) Look for it in the delta. If we find it in there, return the
>     "previous"
>     > value
>     >  2) The value is not in the delta. Forward the read request to
>     L2 (that will
>     > itself forward it to L), then make sure the delta has not been
>     updated if it
>     > was null before, and return. Otherwise, go back to 1).
>     >
>     > This looks like it would work nicely: we are updating L1's base
>     and delta
>     > through volatile writes, hence "masking" the first element in
>     the list.
>     >
>     > However, we spotted the issue mentioned before: because the
>     writes to L in
>     > step 4 are not volatile (and we'd like to avoid the cost), they
>     can be
>     > reordered before step 3 where we set L1's base and delta through
>     volatile
>     > writes (roach motel semantics).
>     > Therefore, a reader of L1 could read the delta field that is
>     still null and
>     > get the value from L which is now set to 5, which is incorrect.
>     >
>     > As Antoine mentioned, we never observed that in our tests
>     (seeing a null
>     > version of L1.delta while seeing the updates to L), but it seems
>     that this
>     > could happen under the JMM.
>     > Is this correct? Do you see any ways around it?
>     >
>     > Thanks!
>     >
>     >
>     > --
>     > Romain Colle
>     > QuartetFS
>     > 2 rue Jean Lantier, 75001 Paris, France
>     > http://www.quartetfs.com
>     >
>     > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis
>     <jacyg at alumni.rice.edu <mailto:jacyg at alumni.rice.edu>>
>     > wrote:
>     >>
>     >> Well, without knowing a lot about the details....  Could do
>     something
>     >> like:
>     >>
>     >>
>     >>    private volatile List base = new ArrayList();
>     >>
>     >>    private void write()
>     >>    {
>     >>       List copy = new ArrayList(base);
>     >>       //do writes to copy
>     >>       base = copy;
>     >>    }
>     >>
>     >>    private void read()
>     >>    {
>     >>       List local = base;
>     >>       // do reading using the local variable, NOT the volatile
>     shared
>     >> variable.  this is essential,
>     >>       // must only read the replacement variable 1x for any set of
>     >> reads you expect to be consistent.
>     >>       // of course, if you only have a single read, you could
>     dispense
>     >> with the local variable, but just
>     >>       // bear in mind that the contents of base could be different
>     >> each time you reference it.
>     >>    }
>     >>
>     >> Of course, it would also be worth seeing if
>     CopyOnWriteArrayList can
>     >> satisfy your requirement.
>     >>
>     >> jacy
>     >>
>     >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille
>     <ach at quartetfs.com <mailto:ach at quartetfs.com>>
>     >> wrote:
>     >> > While designing a multiversion data structure I wrote a
>     simple thread
>     >> > synchronization based on "volatile".
>     >> >
>     >> > The shared data is made of a base list, and a volatile
>     "replacement"
>     >> > list.
>     >> >    List base = ...;
>     >> >    volatile List replacement = null;
>     >> >
>     >> > There is only one writer thread. The writer thread will
>     change some
>     >> > elements
>     >> > in the list. It creates a copy of the original list, puts it
>     as the
>     >> > replacement (volatile write). It is thought that the
>     replacement list
>     >> > can
>     >> > "hide" the base and that the modifications can be safely
>     written into
>     >> > the
>     >> > base list.
>     >> >    List replacement = new SubList();
>     >> >    transfer(shared.base, replacement)
>     >> >    shared.replacement = replacement;
>     >> >    ...
>     >> >    modify(shared.base);
>     >> >
>     >> > There are multiple readers, concurrently with the writer. If
>     a reader
>     >> > sees a
>     >> > replacement list, it will read values from it. Else it reads
>     data from
>     >> > the
>     >> > base list and before returning it checks that the replacement
>     was not
>     >> > set in
>     >> > the meantime.
>     >> >
>     >> >    List replacement;
>     >> >    for(;;) {
>     >> >       replacement = shared.replacement;
>     >> >  if(replacement != null) return replacement.get(index);
>     >> >  else {
>     >> >          Object value = shared.base.get(index);
>     >> > List tmp = replacement;
>     >> > replacement = shared.replacement;
>     >> > if(replacement = tmp) return value;
>     >> >  }
>     >>
>     >>    private volatile List base = new ArrayList();
>     >>
>     >>    private void write()
>     >>    {
>     >>       List copy = new ArrayList(base);
>     >>       //do writes to copy
>     >>       base = copy;
>     >>    }
>     >>
>     >>    private void read()
>     >>    {
>     >>       List local = base;
>     >>       // do reading using the local variable, NOT the volatile
>     shared
>     >> variable.  this is essential,
>     >>       // must only read the replacement variable 1x for any set of
>     >> reads you expect to be consistent.
>     >>       // of course, if you only have a single read, you could
>     dispense
>     >> with the local variable, but just
>     >>       // bear in mind that the contents of base could be different
>     >> each time you reference it.
>     >>    }
>     >> >    }
>     >> >
>     >> >
>     >> > The design passes a modest set of unit tests on an x86 multi-core
>     >> > processor
>     >> > but a colleague spotted a big flaw. This expects too much
>     from the java
>     >> > memory model. The modifications to the base list that were
>     thought to be
>     >> > invisible to readers could be reordered before the volatile
>     write of the
>     >> > replacement. So a writer could read garbage from the base,
>     think the
>     >> > replacement was not set and return the garbage.
>     >> >
>     >> >
>     >> > Do you see other means (volatile, CAS, UNSAFE,...) that would
>     fix the
>     >> > above
>     >> > design without resorting to synchronized blocks or locks ?
>     >> >
>     >> >
>     >> > Thanks a lot,
>     >> > -Antoine CHAMBILLE
>     >> > Quartet FS
>     >> >
>     >> > _______________________________________________
>     >> > Concurrency-interest mailing list
>     >> > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >> >
>     >> _______________________________________________
>     >> Concurrency-interest mailing list
>     >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     >
>     >
>     >
>     >
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/09b9132f/attachment-0001.html>

From dl at cs.oswego.edu  Fri Sep  7 07:41:20 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 07 Sep 2012 07:41:20 -0400
Subject: [concurrency-interest] CountedCompleter test
In-Reply-To: <50486496.2070103@googlemail.com>
References: <50486496.2070103@googlemail.com>
Message-ID: <5049DD60.1070801@cs.oswego.edu>

On 09/06/12 04:53, Uclio Work wrote:
> I'm playing with CountedCompleter, so to optionally have a continuation-like
> mechanism in the toy PL I'm working on. Unfortunately it seems I just don't
> grasp its semantics the right way.

I'm sure you are not alone. Components based on inversion-of-control
(callbacks, completions, etc) are usually not very intuitive.
Working through the examples (as well as others like CCBoxedLongSort
and CCJacobi in our test/loops CVS) might help. Suggestions for
further examples or guidance would be welcome.

> Here an (in)famous Fibonacci test, with CountedCompleter acting like a plain
> ForkJoinTask.
 > ....

Your version mixed completions with joins.
First rule of thumb: Never do this. Choose one or the other style;
with the usual exception of an external submitter
using join/invoke on the root task.

Below is a version (using the "sib" recording illustrated in
one of the javadoc examples) that helps show one of the
ways to do this with CountedCompleters.

>
> I have to also admit, after the
> first working test, to not fully understand the relation between the  pending
> completions and the tryComplete method.
>

The javadoc for tryComplete tersely says everything you need to know :-)
And you definitely need to know it to use them. The counting/triggering rules
are similar to, but not quite the same as, other count-based components
such as semaphores, phasers, and latches.

public final void tryComplete()

     If the pending count is nonzero, decrements the count; otherwise invokes 
onCompletion(java.util.concurrent.CountedCompleter) and then similarly tries to 
complete this task's completer, if one exists, else marks this task as complete.

...

class CCFib extends CountedCompleter<Integer> {
     final int n;
     int result;
     CCFib sib;
     public CCFib(CountedCompleter<?> p, int n) { super(p); this.n = n; }
     public void compute() {
         if (n > 1) {
             setPendingCount(1);
             CCFib left = new CCFib(this, n - 1);
             CCFib right = new CCFib(this, n - 2);
             left.sib = right;
             right.sib = left;
             right.fork();
             left.compute();
         }
         else
             result = n;
             tryComplete();
         }
     }

     protected void onCompletion(CountedCompleter<?> caller) {
         if (caller != this) {
             CCFib f = (CCFib)caller;
             result = f.result + f.sib.result;
         }
     }

     public Integer getRawResult() { return result; }

}

From dl at cs.oswego.edu  Fri Sep  7 08:19:56 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 07 Sep 2012 08:19:56 -0400
Subject: [concurrency-interest] help show speed-up on a recursive
 divided and conquer example
In-Reply-To: <CAHYWNzA-qy3ej-6gpbrtMexrKov6t2BJh02nE-dBFbyHn9Ootw@mail.gmail.com>
References: <CAHYWNzA-qy3ej-6gpbrtMexrKov6t2BJh02nE-dBFbyHn9Ootw@mail.gmail.com>
Message-ID: <5049E66C.80706@cs.oswego.edu>

On 09/06/12 23:37, Yuheng Long wrote:
> Hi all,
>      Would you please help on why the attached program (also
> inlined below) runs the sequential version faster than the
> parallel version? I apologize if I have missed something.

I think you are mainly seeing JVM+FJ start-up effects, that on some
platforms/programs are really terrible. Try placing your
main tests in loops, as in:

         for (int i = 0; i < 10; ++i) {
             long startTime = System.nanoTime();
             double result = integrator.integral(start, end);
             long time = System.nanoTime() - startTime;
             double secs = ((double)time) / 1000000000.0;
             System.out.printf("Time: %7.3f result = %f\n", secs, result);
         }

BTW, an update of the Integrate.java test, that is in part designed
to monitor these kinds of issues, is in our CVS. See
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/loops/

-Doug


From uclio.work at googlemail.com  Fri Sep  7 11:13:10 2012
From: uclio.work at googlemail.com (Uclio Work)
Date: Fri, 07 Sep 2012 17:13:10 +0200
Subject: [concurrency-interest] CountedCompleter test
In-Reply-To: <5049DD60.1070801@cs.oswego.edu>
References: <50486496.2070103@googlemail.com> <5049DD60.1070801@cs.oswego.edu>
Message-ID: <504A0F06.1060906@googlemail.com>

Yes, now I see it.
>>
>> I have to also admit, after the
>> first working test, to not fully understand the relation between the  
>> pending
>> completions and the tryComplete method.
>>
>
> The javadoc for tryComplete tersely says everything you need to know :-)
> And you definitely need to know it to use them. The 
> counting/triggering rules
> are similar to, but not quite the same as, other count-based components
> such as semaphores, phasers, and latches.
>
:-[ Sorry. I wrote that under frustration.  The javadoc clearly 
expresses the concept.

Thank you so much for this valuable help, Doug.

Uclio

From zhong.j.yu at gmail.com  Fri Sep  7 11:43:31 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 7 Sep 2012 10:43:31 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
Message-ID: <CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>

Antoine, if I understand you correctly, your strategy is similar to
this simplified one:

------------------------------------
class Version
    volatile boolean mutating;

Mutable mutable = ...;
volatile Version version = new Version();

// writer

    version.mutating = true;
    write(mutable);
    version = new Version();

// reader

    for(;;)
        Version v = version;
        result = read(mutable);
        if(!v.mutating)
            return result;
------------------------------------

If a reader returns, its last read session is nicely sandwiched
between two write sessions.

1    version.mutating = true;
     write#1(mutable);
2    version = new Version();

3        Version v = version;
         result = read(mutable);
4        v.mutating==false

5    version.mutating = true;
     write#2(mutable);
6    version = new Version();

We have synchronization order 1<2<3<4<5<6.

writer#1() happens-before read(), no problem there.

This strategy is essentially the same as SequenceLock.

However, read() and write#2() are in a data race, and roach motel
model allows them to overlap (not sure if that can really happen on
real VMs). We can see that in the javadoc example of SequenceLock, the
entire read() consists of all volatile reads, to avoid this problem.

I think we can also solve the problem by introducing another volatile
variable; the reader writes to it, and the writer reads from it; this
will establish hb(read, write#2). This way every read costs at least a
volatile write.

Zhong Yu

From oleksandr.otenko at oracle.com  Fri Sep  7 11:52:36 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Fri, 07 Sep 2012 16:52:36 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
Message-ID: <504A1844.6030902@oracle.com>

This is no different to write-locking the entire mega-structure

Alex


On 07/09/2012 16:43, Zhong Yu wrote:
> Antoine, if I understand you correctly, your strategy is similar to
> this simplified one:
>
> ------------------------------------
> class Version
>      volatile boolean mutating;
>
> Mutable mutable = ...;
> volatile Version version = new Version();
>
> // writer
>
>      version.mutating = true;
>      write(mutable);
>      version = new Version();
>
> // reader
>
>      for(;;)
>          Version v = version;
>          result = read(mutable);
>          if(!v.mutating)
>              return result;
> ------------------------------------
>
> If a reader returns, its last read session is nicely sandwiched
> between two write sessions.
>
> 1    version.mutating = true;
>       write#1(mutable);
> 2    version = new Version();
>
> 3        Version v = version;
>           result = read(mutable);
> 4        v.mutating==false
>
> 5    version.mutating = true;
>       write#2(mutable);
> 6    version = new Version();
>
> We have synchronization order 1<2<3<4<5<6.
>
> writer#1() happens-before read(), no problem there.
>
> This strategy is essentially the same as SequenceLock.
>
> However, read() and write#2() are in a data race, and roach motel
> model allows them to overlap (not sure if that can really happen on
> real VMs). We can see that in the javadoc example of SequenceLock, the
> entire read() consists of all volatile reads, to avoid this problem.
>
> I think we can also solve the problem by introducing another volatile
> variable; the reader writes to it, and the writer reads from it; this
> will establish hb(read, write#2). This way every read costs at least a
> volatile write.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/e000b879/attachment.html>

From zhong.j.yu at gmail.com  Fri Sep  7 12:01:15 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 7 Sep 2012 11:01:15 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <504A1844.6030902@oracle.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
Message-ID: <CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>

Yes, but I think it reflects the same concurrency flaw in the original design.

On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
<oleksandr.otenko at oracle.com> wrote:
> This is no different to write-locking the entire mega-structure
>
> Alex
>
>
> On 07/09/2012 16:43, Zhong Yu wrote:
>
> Antoine, if I understand you correctly, your strategy is similar to
> this simplified one:
>
> ------------------------------------
> class Version
>     volatile boolean mutating;
>
> Mutable mutable = ...;
> volatile Version version = new Version();
>
> // writer
>
>     version.mutating = true;
>     write(mutable);
>     version = new Version();
>
> // reader
>
>     for(;;)
>         Version v = version;
>         result = read(mutable);
>         if(!v.mutating)
>             return result;
> ------------------------------
> ------
>
> If a reader returns, its last read session is nicely sandwiched
> between two write sessions.
>
> 1    version.mutating = true;
>      write#1(mutable);
> 2    version = new Version();
>
> 3        Version v = version;
>          result = read(mutable);
> 4        v.mutating==false
>
> 5    version.mutating = true;
>      write#2(mutable);
> 6    version = new Version();
>
> We have synchronization order 1<2<3<4<5<6.
>
> writer#1() happens-before read(), no problem there.
>
> This strategy is essentially the same as SequenceLock.
>
> However, read() and write#2() are in a data race, and roach motel
> model allows them to overlap (not sure if that can really happen on
> real VMs). We can see that in the javadoc example of SequenceLock, the
> entire read() consists of all volatile reads, to avoid this problem.
>
> I think we can also solve the problem by introducing another volatile
> variable; the reader writes to it, and the writer reads from it; this
> will establish hb(read, write#2). This way every read costs at least a
> volatile write.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From oleksandr.otenko at oracle.com  Fri Sep  7 12:08:22 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Fri, 07 Sep 2012 17:08:22 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
	<CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
Message-ID: <504A1BF6.5030508@oracle.com>

Mmmm.... There was a delta (declaring element-wise mutation) somewhere 
in their design. This is very important, because a delta is immutable 
and observing a delta is meaningful w.r.t. considering the base in a 
consistent state.

Alex

On 07/09/2012 17:01, Zhong Yu wrote:
> Yes, but I think it reflects the same concurrency flaw in the original design.
>
> On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com>  wrote:
>> This is no different to write-locking the entire mega-structure
>>
>> Alex
>>
>>
>> On 07/09/2012 16:43, Zhong Yu wrote:
>>
>> Antoine, if I understand you correctly, your strategy is similar to
>> this simplified one:
>>
>> ------------------------------------
>> class Version
>>      volatile boolean mutating;
>>
>> Mutable mutable = ...;
>> volatile Version version = new Version();
>>
>> // writer
>>
>>      version.mutating = true;
>>      write(mutable);
>>      version = new Version();
>>
>> // reader
>>
>>      for(;;)
>>          Version v = version;
>>          result = read(mutable);
>>          if(!v.mutating)
>>              return result;
>> ------------------------------
>> ------
>>
>> If a reader returns, its last read session is nicely sandwiched
>> between two write sessions.
>>
>> 1    version.mutating = true;
>>       write#1(mutable);
>> 2    version = new Version();
>>
>> 3        Version v = version;
>>           result = read(mutable);
>> 4        v.mutating==false
>>
>> 5    version.mutating = true;
>>       write#2(mutable);
>> 6    version = new Version();
>>
>> We have synchronization order 1<2<3<4<5<6.
>>
>> writer#1() happens-before read(), no problem there.
>>
>> This strategy is essentially the same as SequenceLock.
>>
>> However, read() and write#2() are in a data race, and roach motel
>> model allows them to overlap (not sure if that can really happen on
>> real VMs). We can see that in the javadoc example of SequenceLock, the
>> entire read() consists of all volatile reads, to avoid this problem.
>>
>> I think we can also solve the problem by introducing another volatile
>> variable; the reader writes to it, and the writer reads from it; this
>> will establish hb(read, write#2). This way every read costs at least a
>> volatile write.
>>
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/1d5b18f7/attachment.html>

From zhong.j.yu at gmail.com  Fri Sep  7 12:17:51 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 7 Sep 2012 11:17:51 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <504A1BF6.5030508@oracle.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
	<CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
	<504A1BF6.5030508@oracle.com>
Message-ID: <CACuKZqGi20NotyWk=pubm7GDR+1H=9ekJwGXA9b33QnERxHOZg@mail.gmail.com>

The problem is when the reader doesn't observe a delta (or in my
example, the reader sees mutating==false). the reader thinks it was
reading a stable data structure, while in fact it could have been
overlapping with write#2().

As long as the read method consists of only normal reads and volatile
reads, the normal reads must be in data race with future writes.

Zhong Yu

On Fri, Sep 7, 2012 at 11:08 AM, oleksandr otenko
<oleksandr.otenko at oracle.com> wrote:
> Mmmm.... There was a delta (declaring element-wise mutation) somewhere in
> their design. This is very important, because a delta is immutable and
> observing a delta is meaningful w.r.t. considering the base in a consistent
> state.
>
> Alex
>
> On 07/09/2012 17:01, Zhong Yu wrote:
>
> Yes, but I think it reflects the same concurrency flaw in the original
> design.
>
> On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com> wrote:
>
> This is no different to write-locking the entire mega-structure
>
> Alex
>
>
> On 07/09/2012 16:43, Zhong Yu wrote:
>
> Antoine, if I understand you correctly, your strategy is similar to
> this simplified one:
>
> ------------------------------------
> class Version
>     volatile boolean mutating;
>
> Mutable mutable = ...;
> volatile Version version = new Version();
>
> // writer
>
>     version.mutating = true;
>     write(mutable);
>     version = new Version();
>
> // reader
>
>     for(;;)
>         Version v = version;
>         result = read(mutable);
>         if(!v.mutating)
>             return result;
> ------------------------------
> ------
>
> If a reader returns, its last read session is nicely sandwiched
> between two write sessions.
>
> 1    version.mutating = true;
>      write#1(mutable);
> 2    version = new Version();
>
> 3        Version v = version;
>          result = read(mutable);
> 4        v.mutating==false
>
> 5    version.mutating = true;
>      write#2(mutable);
> 6    version = new Version();
>
> We have synchronization order 1<2<3<4<5<6.
>
> writer#1() happens-before read(), no problem there.
>
> This strategy is essentially the same as SequenceLock.
>
> However, read() and write#2() are in a data race, and roach motel
> model allows them to overlap (not sure if that can really happen on
> real VMs). We can see that in the javadoc example of SequenceLock, the
> entire read() consists of all volatile reads, to avoid this problem.
>
> I think we can also solve the problem by introducing another volatile
> variable; the reader writes to it, and the writer reads from it; this
> will establish hb(read, write#2). This way every read costs at least a
> volatile write.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From oleksandr.otenko at oracle.com  Fri Sep  7 12:32:09 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Fri, 07 Sep 2012 17:32:09 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqGi20NotyWk=pubm7GDR+1H=9ekJwGXA9b33QnERxHOZg@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
	<CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
	<504A1BF6.5030508@oracle.com>
	<CACuKZqGi20NotyWk=pubm7GDR+1H=9ekJwGXA9b33QnERxHOZg@mail.gmail.com>
Message-ID: <504A2189.3060100@oracle.com>

Yes, and the solution is to ensure the delta is never null.So that you 
always know where you are in time.

What harm in having it non-null? What benefit in having it null?

Alex


On 07/09/2012 17:17, Zhong Yu wrote:
> The problem is when the reader doesn't observe a delta (or in my
> example, the reader sees mutating==false). the reader thinks it was
> reading a stable data structure, while in fact it could have been
> overlapping with write#2().
>
> As long as the read method consists of only normal reads and volatile
> reads, the normal reads must be in data race with future writes.
>
> Zhong Yu
>
> On Fri, Sep 7, 2012 at 11:08 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com>  wrote:
>> Mmmm.... There was a delta (declaring element-wise mutation) somewhere in
>> their design. This is very important, because a delta is immutable and
>> observing a delta is meaningful w.r.t. considering the base in a consistent
>> state.
>>
>> Alex
>>
>> On 07/09/2012 17:01, Zhong Yu wrote:
>>
>> Yes, but I think it reflects the same concurrency flaw in the original
>> design.
>>
>> On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
>> <oleksandr.otenko at oracle.com>  wrote:
>>
>> This is no different to write-locking the entire mega-structure
>>
>> Alex
>>
>>
>> On 07/09/2012 16:43, Zhong Yu wrote:
>>
>> Antoine, if I understand you correctly, your strategy is similar to
>> this simplified one:
>>
>> ------------------------------------
>> class Version
>>      volatile boolean mutating;
>>
>> Mutable mutable = ...;
>> volatile Version version = new Version();
>>
>> // writer
>>
>>      version.mutating = true;
>>      write(mutable);
>>      version = new Version();
>>
>> // reader
>>
>>      for(;;)
>>          Version v = version;
>>          result = read(mutable);
>>          if(!v.mutating)
>>              return result;
>> ------------------------------
>> ------
>>
>> If a reader returns, its last read session is nicely sandwiched
>> between two write sessions.
>>
>> 1    version.mutating = true;
>>       write#1(mutable);
>> 2    version = new Version();
>>
>> 3        Version v = version;
>>           result = read(mutable);
>> 4        v.mutating==false
>>
>> 5    version.mutating = true;
>>       write#2(mutable);
>> 6    version = new Version();
>>
>> We have synchronization order 1<2<3<4<5<6.
>>
>> writer#1() happens-before read(), no problem there.
>>
>> This strategy is essentially the same as SequenceLock.
>>
>> However, read() and write#2() are in a data race, and roach motel
>> model allows them to overlap (not sure if that can really happen on
>> real VMs). We can see that in the javadoc example of SequenceLock, the
>> entire read() consists of all volatile reads, to avoid this problem.
>>
>> I think we can also solve the problem by introducing another volatile
>> variable; the reader writes to it, and the writer reads from it; this
>> will establish hb(read, write#2). This way every read costs at least a
>> volatile write.
>>
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/a40d7f42/attachment.html>

From zhong.j.yu at gmail.com  Fri Sep  7 12:34:34 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 7 Sep 2012 11:34:34 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
Message-ID: <CACuKZqHAvaSW2zgKdndLHX2GL9R53K_ipTN+7oHHCnx7oZ=GXQ@mail.gmail.com>

On Thu, Sep 6, 2012 at 3:19 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> In your simplified example, the only write is to replace an element at
> an existing index.

>That's an easy problem to solve, e.g.

Well that's embarrassing, my "easy" solution is wrong. It only works
if items are immutable, otherwise a reader can see a partial item
(from a "future" write)

>
>     volatile List list = new ArrayList();
>
>     // writer
>     list.set(i, newItem);
>     list=list;  // to perform a volatile write
>
>     // reader
>     return list.get(i);
>
> Your real problem probably involves more complex writes, where
> multiple variables are updated non-atomically, confusing (if not
> corrupting) concurrent readers. So you want to check whether there's
> state change during a read session.
>
> The reminds me of Doug Lea's SequenceLock
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>
> However note that in the example, x and y are volatile. There are
> minimum 4 volatile reads in the read-only method, even in this very
> simple use case.
>
> Zhong Yu
>
>
> On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
>> Hi all,
>>
>> Antoine's description was a simplified version of our issue, so let me try
>> to describe the actual problem.
>>
>> The key thing is that the list that is being "multi-versioned" is very large
>> while each modification only affects a few elements.
>> The idea is therefore not to create a full copy for each version (like
>> CopyOnWriteArrayList or some very good suggestions on this list), but to
>> simply store a "delta" with the previous version.
>>
>> Here is a simple example.
>> Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very large
>> structure for the sake of the example).
>> The first version of this list would look like this:
>> L1 = { base = L; delta = null; }
>>
>> Any reader thread that wants to access the list at this point gets L1, and
>> all the read requests are forwarded to the base.
>>
>> Now a writer comes in and wants to change the first element to 5. We will,
>> in the writer thread
>>   1) create a delta structure with this new mapping: D1 = {element 0: 1->5 }
>>   2) create a new version L2 = { base = L; delta = null; }
>>   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>>   4) update L to (5, 2, 3, 4)
>>
>> Any reader thread that had a reference to L1 will do the following to read a
>> value:
>>  1) Look for it in the delta. If we find it in there, return the "previous"
>> value
>>  2) The value is not in the delta. Forward the read request to L2 (that will
>> itself forward it to L), then make sure the delta has not been updated if it
>> was null before, and return. Otherwise, go back to 1).
>>
>> This looks like it would work nicely: we are updating L1's base and delta
>> through volatile writes, hence "masking" the first element in the list.
>>
>> However, we spotted the issue mentioned before: because the writes to L in
>> step 4 are not volatile (and we'd like to avoid the cost), they can be
>> reordered before step 3 where we set L1's base and delta through volatile
>> writes (roach motel semantics).
>> Therefore, a reader of L1 could read the delta field that is still null and
>> get the value from L which is now set to 5, which is incorrect.
>>
>> As Antoine mentioned, we never observed that in our tests (seeing a null
>> version of L1.delta while seeing the updates to L), but it seems that this
>> could happen under the JMM.
>> Is this correct? Do you see any ways around it?
>>
>> Thanks!
>>
>>
>> --
>> Romain Colle
>> QuartetFS
>> 2 rue Jean Lantier, 75001 Paris, France
>> http://www.quartetfs.com
>>
>> On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu>
>> wrote:
>>>
>>> Well, without knowing a lot about the details....  Could do something
>>> like:
>>>
>>>
>>>    private volatile List base = new ArrayList();
>>>
>>>    private void write()
>>>    {
>>>       List copy = new ArrayList(base);
>>>       //do writes to copy
>>>       base = copy;
>>>    }
>>>
>>>    private void read()
>>>    {
>>>       List local = base;
>>>       // do reading using the local variable, NOT the volatile shared
>>> variable.  this is essential,
>>>       // must only read the replacement variable 1x for any set of
>>> reads you expect to be consistent.
>>>       // of course, if you only have a single read, you could dispense
>>> with the local variable, but just
>>>       // bear in mind that the contents of base could be different
>>> each time you reference it.
>>>    }
>>>
>>> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>>> satisfy your requirement.
>>>
>>> jacy
>>>
>>> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>>> wrote:
>>> > While designing a multiversion data structure I wrote a simple thread
>>> > synchronization based on "volatile".
>>> >
>>> > The shared data is made of a base list, and a volatile "replacement"
>>> > list.
>>> >    List base = ...;
>>> >    volatile List replacement = null;
>>> >
>>> > There is only one writer thread. The writer thread will change some
>>> > elements
>>> > in the list. It creates a copy of the original list, puts it as the
>>> > replacement (volatile write). It is thought that the replacement list
>>> > can
>>> > "hide" the base and that the modifications can be safely written into
>>> > the
>>> > base list.
>>> >    List replacement = new SubList();
>>> >    transfer(shared.base, replacement)
>>> >    shared.replacement = replacement;
>>> >    ...
>>> >    modify(shared.base);
>>> >
>>> > There are multiple readers, concurrently with the writer. If a reader
>>> > sees a
>>> > replacement list, it will read values from it. Else it reads data from
>>> > the
>>> > base list and before returning it checks that the replacement was not
>>> > set in
>>> > the meantime.
>>> >
>>> >    List replacement;
>>> >    for(;;) {
>>> >       replacement = shared.replacement;
>>> >  if(replacement != null) return replacement.get(index);
>>> >  else {
>>> >          Object value = shared.base.get(index);
>>> > List tmp = replacement;
>>> > replacement = shared.replacement;
>>> > if(replacement = tmp) return value;
>>> >  }
>>>
>>>    private volatile List base = new ArrayList();
>>>
>>>    private void write()
>>>    {
>>>       List copy = new ArrayList(base);
>>>       //do writes to copy
>>>       base = copy;
>>>    }
>>>
>>>    private void read()
>>>    {
>>>       List local = base;
>>>       // do reading using the local variable, NOT the volatile shared
>>> variable.  this is essential,
>>>       // must only read the replacement variable 1x for any set of
>>> reads you expect to be consistent.
>>>       // of course, if you only have a single read, you could dispense
>>> with the local variable, but just
>>>       // bear in mind that the contents of base could be different
>>> each time you reference it.
>>>    }
>>> >    }
>>> >
>>> >
>>> > The design passes a modest set of unit tests on an x86 multi-core
>>> > processor
>>> > but a colleague spotted a big flaw. This expects too much from the java
>>> > memory model. The modifications to the base list that were thought to be
>>> > invisible to readers could be reordered before the volatile write of the
>>> > replacement. So a writer could read garbage from the base, think the
>>> > replacement was not set and return the garbage.
>>> >
>>> >
>>> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>>> > above
>>> > design without resorting to synchronized blocks or locks ?
>>> >
>>> >
>>> > Thanks a lot,
>>> > -Antoine CHAMBILLE
>>> > Quartet FS
>>> >
>>> > _______________________________________________
>>> > Concurrency-interest mailing list
>>> > Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

From zhong.j.yu at gmail.com  Fri Sep  7 12:48:33 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Fri, 7 Sep 2012 11:48:33 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <504A2189.3060100@oracle.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
	<CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
	<504A1BF6.5030508@oracle.com>
	<CACuKZqGi20NotyWk=pubm7GDR+1H=9ekJwGXA9b33QnERxHOZg@mail.gmail.com>
	<504A2189.3060100@oracle.com>
Message-ID: <CACuKZqH8Wcou2ddqpyNBDcUP8scfibRGN+jPT1oSG2UCPw10bQ@mail.gmail.com>

I don't fully understand your solution given earlier, but does it not
suffer from the same flaw if V is mutable?

On the other hand, OP seems to suggest that V can be easily cloned; if
that's true why not make it immutable, and forget about in-place
editing of V.

On Fri, Sep 7, 2012 at 11:32 AM, oleksandr otenko
<oleksandr.otenko at oracle.com> wrote:
> Yes, and the solution is to ensure the delta is never null. So that you
> always know where you are in time.
>
> What harm in having it non-null? What benefit in having it null?
>
> Alex
>
>
> On 07/09/2012 17:17, Zhong Yu wrote:
>
> The problem is when the reader doesn't observe a delta (or in my
> example, the reader sees mutating==false). the reader thinks it was
> reading a stable data structure, while in fact it could have been
> overlapping with write#2().
>
> As long as the read method consists of only normal reads and volatile
> reads, the normal reads must be in data race with future writes.
>
> Zhong Yu
>
> On Fri, Sep 7, 2012 at 11:08 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com> wrote:
>
> Mmmm.... There was a delta (declaring element-wise mutation) somewhere in
> their design. This is very important, because a delta is immutable and
> observing a delta is meaningful w.r.t. considering the base in a consistent
> state.
>
> Alex
>
> On 07/09/2012 17:01, Zhong Yu wrote:
>
> Yes, but I think it reflects the same concurrency flaw in the original
> design.
>
> On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com> wrote:
>
> This is no different to write-locking the entire mega-structure
>
> Alex
>
>
> On 07/09/2012 16:43, Zhong Yu wrote:
>
> Antoine, if I understand you correctly, your strategy is similar to
> this simplified one:
>
> ------------------------------------
> class Version
>     volatile boolean mutating;
>
> Mutable mutable = ...;
> volatile Version version = new Version();
>
> // writer
>
>     version.mutating = true;
>     write(mutable);
>     version = new Version();
>
> // reader
>
>     for(;;)
>         Version v = version;
>         result = read(mutable);
>         if(!v.mutating)
>             return result;
> ------------------------------
> ------
>
> If a reader returns, its last read session is nicely sandwiched
> between two write sessions.
>
> 1    version.mutating = true;
>      write#1(mutable);
> 2    version = new Version();
>
> 3        Version v = version;
>          result = read(mutable);
> 4        v.mutating==false
>
> 5    version.mutating = true;
>      write#2(mutable);
> 6    version = new Version();
>
> We have synchronization order 1<2<3<4<5<6.
>
> writer#1() happens-before read(), no problem there.
>
> This strategy is essentially the same as SequenceLock.
>
> However, read() and write#2() are in a data race, and roach motel
> model allows them to overlap (not sure if that can really happen on
> real VMs). We can see that in the javadoc example of SequenceLock, the
> entire read() consists of all volatile reads, to avoid this problem.
>
> I think we can also solve the problem by introducing another volatile
> variable; the reader writes to it, and the writer reads from it; this
> will establish hb(read, write#2). This way every read costs at least a
> volatile write.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From jacyg at alumni.rice.edu  Fri Sep  7 13:42:32 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Fri, 7 Sep 2012 12:42:32 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
Message-ID: <CAESiqEroXYB6AjnL3rwY19-ekXjwu=7odvtEytYhrcfZ_mKHvA@mail.gmail.com>

Hi,

So, you probably want to look at how DB do this.  Suffice it to say, I
don't think there's a simple solution where you just use a single
concurrency/synchronization feature to accomplish your underlying
task.

Sketch of what I'd probably look to do:
1. need to know start and end of query.
2. when query starts, empty delta object is created.
3. write needs to gather ALL changes to be made before writing any of
them to base data.
   a. Gather previous changes as well--this needs to include not just
direct changes, but if its a list, this would need to include, say,
index changes due to an insertion/deletion.
4. each delta object contains list of delta sets (since one query
could conceivably take place across multiple write operations)
5. To actually do write, write thread adds its delta set to each
outstanding delta object (needs some sort of locking to ensure you
don't race condition doing this and new query coming in).  Then it
locks underlying structure (which could involve a collection of locks
if you fragment the structure with each fragment getting its own
lock).
6. Reads always read from oldest delta set through to newest, then
down to underlying structure.
7. When query completes, its delta object is discarded.

Some pseudo code:

BigData bigData;
List<QueryObject> queries;

QueryObject {
List<Delta> deltas;
public Object retrieve(Object param)
{
  readLock(deltas);

  for (Delta d in deltas)
  {
    if (d contains param)Query
      return d.get(param);
  }
  return bigData.get(param);

  finally readUnlock(deltas);
}
public void addDelta(Delta d)
{
   writeLock(deltas);
   deltas.add(d);
   writeUnlock(deltas);
}
}

runQuery(Object queryCriteria)
{
  QueryObject qo = new QueryObject();
   writeLock(queries)
   queries.add(qo);
   writeUnlock(queries);
//   run Query against qo;
   writeLock(queries)
   queries.remove(qo);
   writeUnlock(queries);

}

write(Set<Change> changes)
{
  Delta d = new Delta();
  for (Change c in changes)
  {
    d.computeChanges(c);
  }
  readLock(queries);
  for (QueryObject qo in queries)
  {
    qo.addDelta(d);
  }
  readUnlock(queries);

  bigData.writeChanges(changes);
}

BigData
{
  public Object get(Object param)
  {
    readLock(sectionOfDataFor(param));
    return internalGet(param);
    readUnlock(sectionOfDataFor(param));
  }


}



On Fri, Sep 7, 2012 at 5:09 AM, Antoine Chambille <ach at quartetfs.com> wrote:
> Dear All,
>
> Thanks a lot for your interest and the help so far.
>
> I apologize for oversimplifying the design. When I read the top of this
> thread I realize that CopyOnWriteArrayList or equivalent proposed by Zhong,
> Oleksander and Jacy would work well.
>
> Thanks to Romain the right amount of detail was added. But after reading the
> subsequent respsonses I understand that more context is needed.
>
>
>
> The goal is to achieve efficient lock-free multi-versioning for large data
> sets.
> Imagine a large table in a database, with one billion values. There are
> frequent updates to the table, written in small batches, by a single writer
> thread. A batch may modify thousands of values but that remains a tiny bit
> of the whole table. Each update batch introduces one new "version" of the
> table.
>
> There are tens of concurrent readers, that query the table. For the duration
> of a query, a reader must of course see the same version of the table. We
> want to avoid the simple approach: a read-write lock between readers and the
> writer. We don't want a long running query to postpone the next update. We
> don't want queries to be rejected or postponed while the writer awaits or
> owns the write lock. A multi-version concurrency control design is thus
> required.
>
>
> The table being huge we discarded the pure copy on write approach. We use
> "delta" structures that look like tiny transaction logs:
>
> [version #0] (initial state), a table with 4 cells: [0, 1, 2, 3]
>
> [delta #1] we change the content of cells 0 and 3:
>    0: 0 -> 4
>    3: 3 -> 5
>
> [version #1]: [4, 1, 2, 5]
>
>
> A fairly simple approach would be to leave the (large) base data immutable
> and recursively chain delta stuctures on top of it. Obtaining a version
> simply means locating the right delta in the linked list. Versions are
> stable by construction as the base is immutable and new versions are pushed
> earlier in the chain.
>
>
> But by far the most common read pattern is to execute a small query on the
> latest version of the data. And the above solution makes this most common
> use case very inefficient: After a significant number of updates, each read
> must go through a cascade of lookups in delta stuctures down to the base.
> The most recent version is the furthest from the base data.
>
>
> That's why I thought about reversing the design: The (large) base data
> always contains the latest state, delta structures record the "before
> update" values of modified cells, and the latest version is the closest to
> the base data.
>
> Let's see how it works with our previous update example:
>    * Inject [delta #1] into [version #0]. When a reader of [version #0] sees
> a delta was injected and reads a cell that is mapped in the delta, it reads
> the previous value of that cells without looking at the base.
>    * When we are sure that readers of [version #0] see the delta, then the
> cells of the base data are hidden from readers and we can safely reuse them.
>    * Modify the cells in the base data.
>    * Create [version #1] that points directrly to the base (and does not yet
> have any delta)
>    * Upcoming readers will see [version #1]
>
>
> For this to work we need to be sure that readers will realize a delta was
> injected in their version, before we write (reuse) the cells of the base
> data. I initially hoped that a volatile write of the delta into the version
> would work. It seems to be the case on x86. But the Java Memory Model
> promises nothing. When cells are updated in the base data that's a "normal
> store" and it could theoretically be reordered with the delta injection
> "volatile store". And as an update batch potentially contains thousands of
> writes, making all those writes volatile is not a good option.
>
>
> I am a bit distraught I have to abandon a design that looked neat ;) Do you
> think we can still make it work?
>
>
> -Antoine CHAMBILLE
> Quartet FS
>
>
>
>
> On 6 September 2012 22:19, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>
>> In your simplified example, the only write is to replace an element at
>> an existing index. That's an easy problem to solve, e.g.
>>
>>     volatile List list = new ArrayList();
>>
>>     // writer
>>     list.set(i, newItem);
>>     list=list;  // to perform a volatile write
>>
>>     // reader
>>     return list.get(i);
>>
>> Your real problem probably involves more complex writes, where
>> multiple variables are updated non-atomically, confusing (if not
>> corrupting) concurrent readers. So you want to check whether there's
>> state change during a read session.
>>
>> The reminds me of Doug Lea's SequenceLock
>>
>>
>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>>
>> However note that in the example, x and y are volatile. There are
>> minimum 4 volatile reads in the read-only method, even in this very
>> simple use case.
>>
>> Zhong Yu
>>
>>
>> On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
>> > Hi all,
>> >
>> > Antoine's description was a simplified version of our issue, so let me
>> > try
>> > to describe the actual problem.
>> >
>> > The key thing is that the list that is being "multi-versioned" is very
>> > large
>> > while each modification only affects a few elements.
>> > The idea is therefore not to create a full copy for each version (like
>> > CopyOnWriteArrayList or some very good suggestions on this list), but to
>> > simply store a "delta" with the previous version.
>> >
>> > Here is a simple example.
>> > Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
>> > large
>> > structure for the sake of the example).
>> > The first version of this list would look like this:
>> > L1 = { base = L; delta = null; }
>> >
>> > Any reader thread that wants to access the list at this point gets L1,
>> > and
>> > all the read requests are forwarded to the base.
>> >
>> > Now a writer comes in and wants to change the first element to 5. We
>> > will,
>> > in the writer thread
>> >   1) create a delta structure with this new mapping: D1 = {element 0:
>> > 1->5 }
>> >   2) create a new version L2 = { base = L; delta = null; }
>> >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>> >   4) update L to (5, 2, 3, 4)
>> >
>> > Any reader thread that had a reference to L1 will do the following to
>> > read a
>> > value:
>> >  1) Look for it in the delta. If we find it in there, return the
>> > "previous"
>> > value
>> >  2) The value is not in the delta. Forward the read request to L2 (that
>> > will
>> > itself forward it to L), then make sure the delta has not been updated
>> > if it
>> > was null before, and return. Otherwise, go back to 1).
>> >
>> > This looks like it would work nicely: we are updating L1's base and
>> > delta
>> > through volatile writes, hence "masking" the first element in the list.
>> >
>> > However, we spotted the issue mentioned before: because the writes to L
>> > in
>> > step 4 are not volatile (and we'd like to avoid the cost), they can be
>> > reordered before step 3 where we set L1's base and delta through
>> > volatile
>> > writes (roach motel semantics).
>> > Therefore, a reader of L1 could read the delta field that is still null
>> > and
>> > get the value from L which is now set to 5, which is incorrect.
>> >
>> > As Antoine mentioned, we never observed that in our tests (seeing a null
>> > version of L1.delta while seeing the updates to L), but it seems that
>> > this
>> > could happen under the JMM.
>> > Is this correct? Do you see any ways around it?
>> >
>> > Thanks!
>> >
>> >
>> > --
>> > Romain Colle
>> > QuartetFS
>> > 2 rue Jean Lantier, 75001 Paris, France
>> > http://www.quartetfs.com
>> >
>> > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis
>> > <jacyg at alumni.rice.edu>
>> > wrote:
>> >>
>> >> Well, without knowing a lot about the details....  Could do something
>> >> like:
>> >>
>> >>
>> >>    private volatile List base = new ArrayList();
>> >>
>> >>    private void write()
>> >>    {
>> >>       List copy = new ArrayList(base);
>> >>       //do writes to copy
>> >>       base = copy;
>> >>    }
>> >>
>> >>    private void read()
>> >>    {
>> >>       List local = base;
>> >>       // do reading using the local variable, NOT the volatile shared
>> >> variable.  this is essential,
>> >>       // must only read the replacement variable 1x for any set of
>> >> reads you expect to be consistent.
>> >>       // of course, if you only have a single read, you could dispense
>> >> with the local variable, but just
>> >>       // bear in mind that the contents of base could be different
>> >> each time you reference it.
>> >>    }
>> >>
>> >> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>> >> satisfy your requirement.
>> >>
>> >> jacy
>> >>
>> >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>> >> wrote:
>> >> > While designing a multiversion data structure I wrote a simple thread
>> >> > synchronization based on "volatile".
>> >> >
>> >> > The shared data is made of a base list, and a volatile "replacement"
>> >> > list.
>> >> >    List base = ...;
>> >> >    volatile List replacement = null;
>> >> >
>> >> > There is only one writer thread. The writer thread will change some
>> >> > elements
>> >> > in the list. It creates a copy of the original list, puts it as the
>> >> > replacement (volatile write). It is thought that the replacement list
>> >> > can
>> >> > "hide" the base and that the modifications can be safely written into
>> >> > the
>> >> > base list.
>> >> >    List replacement = new SubList();
>> >> >    transfer(shared.base, replacement)
>> >> >    shared.replacement = replacement;
>> >> >    ...
>> >> >    modify(shared.base);
>> >> >
>> >> > There are multiple readers, concurrently with the writer. If a reader
>> >> > sees a
>> >> > replacement list, it will read values from it. Else it reads data
>> >> > from
>> >> > the
>> >> > base list and before returning it checks that the replacement was not
>> >> > set in
>> >> > the meantime.
>> >> >
>> >> >    List replacement;
>> >> >    for(;;) {
>> >> >       replacement = shared.replacement;
>> >> >  if(replacement != null) return replacement.get(index);
>> >> >  else {
>> >> >          Object value = shared.base.get(index);
>> >> > List tmp = replacement;
>> >> > replacement = shared.replacement;
>> >> > if(replacement = tmp) return value;
>> >> >  }
>> >>
>> >>    private volatile List base = new ArrayList();
>> >>
>> >>    private void write()
>> >>    {
>> >>       List copy = new ArrayList(base);
>> >>       //do writes to copy
>> >>       base = copy;
>> >>    }
>> >>
>> >>    private void read()
>> >>    {
>> >>       List local = base;
>> >>       // do reading using the local variable, NOT the volatile shared
>> >> variable.  this is essential,
>> >>       // must only read the replacement variable 1x for any set of
>> >> reads you expect to be consistent.
>> >>       // of course, if you only have a single read, you could dispense
>> >> with the local variable, but just
>> >>       // bear in mind that the contents of base could be different
>> >> each time you reference it.
>> >>    }
>> >> >    }
>> >> >
>> >> >
>> >> > The design passes a modest set of unit tests on an x86 multi-core
>> >> > processor
>> >> > but a colleague spotted a big flaw. This expects too much from the
>> >> > java
>> >> > memory model. The modifications to the base list that were thought to
>> >> > be
>> >> > invisible to readers could be reordered before the volatile write of
>> >> > the
>> >> > replacement. So a writer could read garbage from the base, think the
>> >> > replacement was not set and return the garbage.
>> >> >
>> >> >
>> >> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>> >> > above
>> >> > design without resorting to synchronized blocks or locks ?
>> >> >
>> >> >
>> >> > Thanks a lot,
>> >> > -Antoine CHAMBILLE
>> >> > Quartet FS
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> >
>> >
>> >
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From jacyg at alumni.rice.edu  Fri Sep  7 13:46:36 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Fri, 7 Sep 2012 12:46:36 -0500
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAESiqEroXYB6AjnL3rwY19-ekXjwu=7odvtEytYhrcfZ_mKHvA@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CAESiqEroXYB6AjnL3rwY19-ekXjwu=7odvtEytYhrcfZ_mKHvA@mail.gmail.com>
Message-ID: <CAESiqErshG9XKUUJN6cMFMQa2GTw_Z5jLZNiuWB988apH3t2_Q@mail.gmail.com>

Drat, wasn't done typing.  problem with using web interface...keep
hitting tab and getting out of the edit window, ended up sending
before i was done editing.

last method in BigData would be

public void writeChanges(List<Change> changes)
{
   for (Change c in changes)
    writeLock(sectionOfDataFor(c));
   for (Change c in changes)
     apply(c);
   for (Change c in changes)
    writeUnlock(sectionOfDataFor(c));
}


Anyhow, it is simplified b/c you don't have multiple writers...if you
did, you'd have to handle lock back out where two writers wanted to
write to same section of data structure.  Long story short, I think
something along these lines is what you'll have to look to if you want
to try to preserve as much concurrency as possible between your reads
and writes while keeping things read-consistent.

j

On Fri, Sep 7, 2012 at 12:42 PM, Jacy Odin Grannis
<jacyg at alumni.rice.edu> wrote:
> Hi,
>
> So, you probably want to look at how DB do this.  Suffice it to say, I
> don't think there's a simple solution where you just use a single
> concurrency/synchronization feature to accomplish your underlying
> task.
>
> Sketch of what I'd probably look to do:
> 1. need to know start and end of query.
> 2. when query starts, empty delta object is created.
> 3. write needs to gather ALL changes to be made before writing any of
> them to base data.
>    a. Gather previous changes as well--this needs to include not just
> direct changes, but if its a list, this would need to include, say,
> index changes due to an insertion/deletion.
> 4. each delta object contains list of delta sets (since one query
> could conceivably take place across multiple write operations)
> 5. To actually do write, write thread adds its delta set to each
> outstanding delta object (needs some sort of locking to ensure you
> don't race condition doing this and new query coming in).  Then it
> locks underlying structure (which could involve a collection of locks
> if you fragment the structure with each fragment getting its own
> lock).
> 6. Reads always read from oldest delta set through to newest, then
> down to underlying structure.
> 7. When query completes, its delta object is discarded.
>
> Some pseudo code:
>
> BigData bigData;
> List<QueryObject> queries;
>
> QueryObject {
> List<Delta> deltas;
> public Object retrieve(Object param)
> {
>   readLock(deltas);
>
>   for (Delta d in deltas)
>   {
>     if (d contains param)Query
>       return d.get(param);
>   }
>   return bigData.get(param);
>
>   finally readUnlock(deltas);
> }
> public void addDelta(Delta d)
> {
>    writeLock(deltas);
>    deltas.add(d);
>    writeUnlock(deltas);
> }
> }
>
> runQuery(Object queryCriteria)
> {
>   QueryObject qo = new QueryObject();
>    writeLock(queries)
>    queries.add(qo);
>    writeUnlock(queries);
> //   run Query against qo;
>    writeLock(queries)
>    queries.remove(qo);
>    writeUnlock(queries);
>
> }a simple solution t
>
> write(Set<Change> changes)
> {
>   Delta d = new Delta();
>   for (Change c in changes)
>   {
>     d.computeChanges(c);
>   }
>   readLock(queries);
>   for (QueryObject qo in queries)
>   {
>     qo.addDelta(d);
>   }
>   readUnlock(queries);
>
>   bigData.writeChanges(changes);
> }
>
> BigData
> {
>   public Object get(Object param)
>   {
>     readLock(sectionOfDataFor(param));
>     return internalGet(param);
>     readUnlock(sectionOfDataFor(param));
>   }
>
>
> }
>
>
>
> On Fri, Sep 7, 2012 at 5:09 AM, Antoine Chambille <ach at quartetfs.com> wrote:
>> Dear All,
>>
>> Thanks a lot for your interest and the help so far.
>>
>> I apologize for oversimplifying the design. When I read the top of this
>> thread I realize that CopyOnWriteArrayList or equivalent proposed by Zhong,
>> Oleksander and Jacy would work well.
>>
>> Thanks to Romain the right amount of detail was added. But after reading the
>> subsequent respsonses I understand that more context is needed.
>>
>>
>>
>> The goal is to achieve efficient lock-free multi-versioning for large data
>> sets.
>> Imagine a large table in a database, with one billion values. There are
>> frequent updates to the table, written in small batches, by a single writer
>> thread. A batch may modify thousands of values but that remains a tiny bit
>> of the whole table. Each update batch introduces one new "version" of the
>> table.
>>
>> There are tens of concurrent readers, that query the table. For the duration
>> of a query, a reader must of course see the same version of the table. We
>> want to avoid the simple approach: a read-write lock between readers and the
>> writer. We don't want a long running query to postpone the next update. We
>> don't want queries to be rejected or postponed while the writer awaits or
>> owns the write lock. A multi-version concurrency control design is thus
>> required.
>>
>>
>> The table being huge we discarded the pure copy on write approach. We use
>> "delta" structures that look like tiny transaction logs:
>>
>> [version #0] (initial state), a table with 4 cells: [0, 1, 2, 3]
>>
>> [delta #1] we change the content of cells 0 and 3:
>>    0: 0 -> 4
>>    3: 3 -> 5
>>
>> [version #1]: [4, 1, 2, 5]
>>
>>
>> A fairly simple approach would be to leave the (large) base data immutable
>> and recursively chain delta stuctures on top of it. Obtaining a version
>> simply means locating the right delta in the linked list. Versions are
>> stable by construction as the base is immutable and new versions are pushed
>> earlier in the chain.
>>
>>
>> But by far the most common read pattern is to execute a small query on the
>> latest version of the data. And the above solution makes this most common
>> use case very inefficient: After a significant number of updates, each read
>> must go through a cascade of lookups in delta stuctures down to the base.
>> The most recent version is the furthest from the base data.
>>
>>
>> That's why I thought about reversing the design: The (large) base data
>> always contains the latest state, delta structures record the "before
>> update" values of modified cells, and the latest version is the closest to
>> the base data.
>>
>> Let's see how it works with our previous update example:
>>    * Inject [delta #1] into [version #0]. When a reader of [version #0] sees
>> a delta was injected and reads a cell that is mapped in the delta, it reads
>> the previous value of that cells without looking at the base.
>>    * When we are sure that readers of [version #0] see the delta, then the
>> cells of the base data are hidden from readers and we can safely reuse them.
>>    * Modify the cells in the base data.
>>    * Create [version #1] that points directrly to the base (and does not yet
>> have any delta)
>>    * Upcoming readers will see [version #1]
>>
>>
>> For this to work we need to be sure that readers will realize a delta was
>> injected in their version, before we write (reuse) the cells of the base
>> data. I initially hoped that a volatile write of the delta into the version
>> would work. It seems to be the case on x86. But the Java Memory Model
>> promises nothing. When cells are updated in the base data that's a "normal
>> store" and it could theoretically be reordered with the delta injection
>> "volatile store". And as an update batch potentially contains thousands of
>> writes, making all those writes volatile is not a good option.
>>
>>
>> I am a bit distraught I have to abandon a design that looked neat ;) Do you
>> think we can still make it work?
>>
>>
>> -Antoine CHAMBILLE
>> Quartet FS
>>
>>
>>
>>
>> On 6 September 2012 22:19, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>
>>> In your simplified example, the only write is to replace an element at
>>> an existing index. That's an easy problem to solve, e.g.
>>>
>>>     volatile List list = new ArrayList();
>>>
>>>     // writer
>>>     list.set(i, newItem);
>>>     list=list;  // to perform a volatile write
>>>
>>>     // reader
>>>     return list.get(i);
>>>
>>> Your real problem probably involves more complex writes, where
>>> multiple variables are updated non-atomically, confusing (if not
>>> corrupting) concurrent readers. So you want to check whether there's
>>> state change during a read session.
>>>
>>> The reminds me of Doug Lea's SequenceLock
>>>
>>>
>>> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>>>
>>> However note that in the example, x and y are volatile. There are
>>> minimum 4 volatile reads in the read-only method, even in this very
>>> simple use case.
>>>
>>> Zhong Yu
>>>
>>>
>>> On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
>>> > Hi all,
>>> >
>>> > Antoine's description was a simplified version of our issue, so let me
>>> > try
>>> > to describe the actual problem.
>>> >
>>> > The key thing is that the list that is being "multi-versioned" is very
>>> > large
>>> > while each modification only affects a few elements.
>>> > The idea is therefore not to create a full copy for each version (like
>>> > CopyOnWriteArrayList or some very good suggestions on this list), but to
>>> > simply store a "delta" with the previous version.
>>> >
>>> > Here is a simple example.
>>> > Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
>>> > large
>>> > structure for the sake of the example).
>>> > The first version of this list would look like this:
>>> > L1 = { base = L; delta = null; }
>>> >
>>> > Any reader thread that wants to access the list at this point gets L1,
>>> > and
>>> > all the read requests are forwarded to the base.
>>> >
>>> > Now a writer comes in and wants to change the first element to 5. We
>>> > will,
>>> > in the writer thread
>>> >   1) create a delta structure with this new mapping: D1 = {element 0:
>>> > 1->5 }
>>> >   2) create a new version L2 = { base = L; delta = null; }
>>> >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>>> >   4) update L to (5, 2, 3, 4)
>>> >
>>> > Any reader thread that had a reference to L1 will do the following to
>>> > read a
>>> > value:
>>> >  1) Look for it in the delta. If we find it in there, return the
>>> > "previous"
>>> > value
>>> >  2) The value is not in the delta. Forward the read request to L2 (that
>>> > will
>>> > itself forward it to L), then make sure the delta has not been updated
>>> > if it
>>> > was null before, and return. Otherwise, go back to 1).
>>> >
>>> > This looks like it would work nicely: we are updating L1's base and
>>> > delta
>>> > through volatile writes, hence "masking" the first element in the list.
>>> >
>>> > However, we spotted the issue mentioned before: because the writes to L
>>> > in
>>> > step 4 are not volatile (and we'd like to avoid the cost), they can be
>>> > reordered before step 3 where we set L1's base and delta through
>>> > volatile
>>> > writes (roach motel semantics).
>>> > Therefore, a reader of L1 could read the delta field that is still null
>>> > and
>>> > get the value from L which is now set to 5, which is incorrect.
>>> >
>>> > As Antoine mentioned, we never observed that in our tests (seeing a null
>>> > version of L1.delta while seeing the updates to L), but it seems that
>>> > this
>>> > could happen under the JMM.
>>> > Is this correct? Do you see any ways around it?
>>> >
>>> > Thanks!
>>> >
>>> >
>>> > --
>>> > Romain Colle
>>> > QuartetFS
>>> > 2 rue Jean Lantier, 75001 Paris, France
>>> > http://www.quartetfs.com
>>> >
>>> > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis
>>> > <jacyg at alumni.rice.edu>
>>> > wrote:
>>> >>
>>> >> Well, without knowing a lot about the details....  Could do something
>>> >> like:
>>> >>
>>> >>
>>> >>    private volatile List base = new ArrayList();
>>> >>
>>> >>    private void write()
>>> >>    {
>>> >>       List copy = new ArrayList(base);
>>> >>       //do writes to copy
>>> >>       base = copy;
>>> >>    }
>>> >>
>>> >>    private void read()
>>> >>    {
>>> >>       List local = base;
>>> >>       // do reading using the local variable, NOT the volatile shared
>>> >> variable.  this is essential,
>>> >>       // must only read the replacement variable 1x for any set of
>>> >> reads you expect to be consistent.
>>> >>       // of course, if you only have a single read, you could dispense
>>> >> with the local variable, but just
>>> >>       // bear in mind that the contents of base could be different
>>> >> each time you reference it.
>>> >>    }
>>> >>
>>> >> Of course, it would also be worth seeing if CopyOnWriteArrayList can
>>> >> satisfy your requirement.
>>> >>
>>> >> jacy
>>> >>
>>> >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
>>> >> wrote:
>>> >> > While designing a multiversion data structure I wrote a simple thread
>>> >> > synchronization based on "volatile".
>>> >> >
>>> >> > The shared data is made of a base list, and a volatile "replacement"
>>> >> > list.
>>> >> >    List base = ...;
>>> >> >    volatile List replacement = null;
>>> >> >
>>> >> > There is only one writer thread. The writer thread will change some
>>> >> > elements
>>> >> > in the list. It creates a copy of the original list, puts it as the
>>> >> > replacement (volatile write). It is thought that the replacement list
>>> >> > can
>>> >> > "hide" the base and that the modifications can be safely written into
>>> >> > the
>>> >> > base list.
>>> >> >    List replacement = new SubList();
>>> >> >    transfer(shared.base, replacement)
>>> >> >    shared.replacement = replacement;
>>> >> >    ...
>>> >> >    modify(shared.base);
>>> >> >
>>> >> > There are multiple readers, concurrently with the writer. If a reader
>>> >> > sees a
>>> >> > replacement list, it will read values from it. Else it reads data
>>> >> > from
>>> >> > the
>>> >> > base list and before returning it checks that the replacement was not
>>> >> > set in
>>> >> > the meantime.
>>> >> >
>>> >> >    List replacement;
>>> >> >    for(;;) {
>>> >> >       replacement = shared.replacement;
>>> >> >  if(replacement != null) return replacement.get(index);
>>> >> >  else {
>>> >> >          Object value = shared.base.get(index);
>>> >> > List tmp = replacement;
>>> >> > replacement = shared.replacement;
>>> >> > if(replacement = tmp) return value;
>>> >> >  }
>>> >>
>>> >>    private volatile List base = new ArrayList();
>>> >>
>>> >>    private void write()
>>> >>    {
>>> >>       List copy = new ArrayList(base);
>>> >>       //do writes to copy
>>> >>       base = copy;
>>> >>    }
>>> >>
>>> >>    private void read()
>>> >>    {
>>> >>       List local = base;
>>> >>       // do reading using the local variable, NOT the volatile shared
>>> >> variable.  this is essential,
>>> >>       // must only read the replacement variable 1x for any set of
>>> >> reads you expect to be consistent.
>>> >>       // of course, if you only have a single read, you could dispense
>>> >> with the local variable, but just
>>> >>       // bear in mind that the contents of base could be different
>>> >> each time you reference it.
>>> >>    }
>>> >> >    }
>>> >> >
>>> >> >
>>> >> > The design passes a modest set of unit tests on an x86 multi-core
>>> >> > processor
>>> >> > but a colleague spotted a big flaw. This expects too much from the
>>> >> > java
>>> >> > memory model. The modifications to the base list that were thought to
>>> >> > be
>>> >> > invisible to readers could be reordered before the volatile write of
>>> >> > the
>>> >> > replacement. So a writer could read garbage from the base, think the
>>> >> > replacement was not set and return the garbage.
>>> >> >
>>> >> >
>>> >> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
>>> >> > above
>>> >> > design without resorting to synchronized blocks or locks ?
>>> >> >
>>> >> >
>>> >> > Thanks a lot,
>>> >> > -Antoine CHAMBILLE
>>> >> > Quartet FS
>>> >> >
>>> >> > _______________________________________________
>>> >> > Concurrency-interest mailing list
>>> >> > Concurrency-interest at cs.oswego.edu
>>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >> >
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > _______________________________________________
>>> > Concurrency-interest mailing list
>>> > Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> --
>> Antoine CHAMBILLE
>> R&D Director
>> Quartet FS
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>

From oleksandr.otenko at oracle.com  Fri Sep  7 14:14:45 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Fri, 07 Sep 2012 19:14:45 +0100
Subject: [concurrency-interest] [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CACuKZqH8Wcou2ddqpyNBDcUP8scfibRGN+jPT1oSG2UCPw10bQ@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<CAJGQDwm9CpFe+Fo_q33B_pybSNL+bLDMqmF3aQKvWwJkD9fi+Q@mail.gmail.com>
	<CACuKZqFpFEp0u+xf=9zAVaZSVx40X7L1XJO-baS6DxcT--cWpQ@mail.gmail.com>
	<504A1844.6030902@oracle.com>
	<CACuKZqHnDZt6C_A1Gu3ydutx4fEBGuEDzq3cw8-kYr7=7GnSog@mail.gmail.com>
	<504A1BF6.5030508@oracle.com>
	<CACuKZqGi20NotyWk=pubm7GDR+1H=9ekJwGXA9b33QnERxHOZg@mail.gmail.com>
	<504A2189.3060100@oracle.com>
	<CACuKZqH8Wcou2ddqpyNBDcUP8scfibRGN+jPT1oSG2UCPw10bQ@mail.gmail.com>
Message-ID: <504A3995.4070809@oracle.com>

The mutators of V must synchronize among themselves. I only provide some 
form of consistency of the structure - ie that structure.get(i) and 
structure.get(j) have some application-specific consistency observed at 
all times (because writer modifying both i and j will make them visible 
to readers atomically, and the reader follows a form of invalidation 
protocol before returning values i and j to the caller).


All permitted writes form a partial order.

The proof of correctness is trivial, if you consider that the integer 
associated with the delta corresponds to the total order of all writes, 
and the integer "version" stored with individual elements in the list 
tell which write modified them last. Therefore, one is allowed to 
observe values with different version, only if there were stores 
modifying one of them but not the other, but only smaller versions are 
allowed (remember the partial order). So if I disallow the next write to 
occur before the values are copied into the base, the reader looking at 
the base and delta can tell whether the values are consistent: if delta 
doesn't contain the value for i, then it must have been written to base 
by a previous write, and for any j it is in a consistent state. Also, if 
for some i we observe a value in base with version greater than the 
total order of the delta, then more writes occurred, and they managed to 
set some of the values in the base, possibly the values we already 
looked at - so, forget what the reader looked at, and restart the read.

assert: if you have a delta with total order N, then all values read 
from base have versions M_i <= N, and all such values are consistent.

assert: if we always look at delta first, then we don't need to worry 
about the timing, atomicity and order of copying the updates from delta 
to base.

assert: if you observe a value in base with M_j > N, then more copying 
after more writes occurred, which managed to copy a value to the base, 
and such values may be inconsistent with the ones we already looked at.

Alex

On 07/09/2012 17:48, Zhong Yu wrote:
> I don't fully understand your solution given earlier, but does it not
> suffer from the same flaw if V is mutable?
>
> On the other hand, OP seems to suggest that V can be easily cloned; if
> that's true why not make it immutable, and forget about in-place
> editing of V.
>
> On Fri, Sep 7, 2012 at 11:32 AM, oleksandr otenko
> <oleksandr.otenko at oracle.com>  wrote:
>> Yes, and the solution is to ensure the delta is never null. So that you
>> always know where you are in time.
>>
>> What harm in having it non-null? What benefit in having it null?
>>
>> Alex
>>
>>
>> On 07/09/2012 17:17, Zhong Yu wrote:
>>
>> The problem is when the reader doesn't observe a delta (or in my
>> example, the reader sees mutating==false). the reader thinks it was
>> reading a stable data structure, while in fact it could have been
>> overlapping with write#2().
>>
>> As long as the read method consists of only normal reads and volatile
>> reads, the normal reads must be in data race with future writes.
>>
>> Zhong Yu
>>
>> On Fri, Sep 7, 2012 at 11:08 AM, oleksandr otenko
>> <oleksandr.otenko at oracle.com>  wrote:
>>
>> Mmmm.... There was a delta (declaring element-wise mutation) somewhere in
>> their design. This is very important, because a delta is immutable and
>> observing a delta is meaningful w.r.t. considering the base in a consistent
>> state.
>>
>> Alex
>>
>> On 07/09/2012 17:01, Zhong Yu wrote:
>>
>> Yes, but I think it reflects the same concurrency flaw in the original
>> design.
>>
>> On Fri, Sep 7, 2012 at 10:52 AM, oleksandr otenko
>> <oleksandr.otenko at oracle.com>  wrote:
>>
>> This is no different to write-locking the entire mega-structure
>>
>> Alex
>>
>>
>> On 07/09/2012 16:43, Zhong Yu wrote:
>>
>> Antoine, if I understand you correctly, your strategy is similar to
>> this simplified one:
>>
>> ------------------------------------
>> class Version
>>      volatile boolean mutating;
>>
>> Mutable mutable = ...;
>> volatile Version version = new Version();
>>
>> // writer
>>
>>      version.mutating = true;
>>      write(mutable);
>>      version = new Version();
>>
>> // reader
>>
>>      for(;;)
>>          Version v = version;
>>          result = read(mutable);
>>          if(!v.mutating)
>>              return result;
>> ------------------------------
>> ------
>>
>> If a reader returns, its last read session is nicely sandwiched
>> between two write sessions.
>>
>> 1    version.mutating = true;
>>       write#1(mutable);
>> 2    version = new Version();
>>
>> 3        Version v = version;
>>           result = read(mutable);
>> 4        v.mutating==false
>>
>> 5    version.mutating = true;
>>       write#2(mutable);
>> 6    version = new Version();
>>
>> We have synchronization order 1<2<3<4<5<6.
>>
>> writer#1() happens-before read(), no problem there.
>>
>> This strategy is essentially the same as SequenceLock.
>>
>> However, read() and write#2() are in a data race, and roach motel
>> model allows them to overlap (not sure if that can really happen on
>> real VMs). We can see that in the javadoc example of SequenceLock, the
>> entire read() consists of all volatile reads, to avoid this problem.
>>
>> I think we can also solve the problem by introducing another volatile
>> variable; the reader writes to it, and the writer reads from it; this
>> will establish hb(read, write#2). This way every read costs at least a
>> volatile write.
>>
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120907/fb921c92/attachment.html>

From ach at quartetfs.com  Mon Sep 10 08:00:35 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Mon, 10 Sep 2012 14:00:35 +0200
Subject: [concurrency-interest] FW:  [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <55750586F6FCD84DA95BC188F9628C8045CDFD77@mailnycmb4a.winmail.deshaw.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<55750586F6FCD84DA95BC188F9628C8045CDFD77@mailnycmb4a.winmail.deshaw.com>
Message-ID: <CAJGQDwmUBs9Et2Wxj_b1dY+ntGtk2cKsDHJehK=EH+jAhqrp2g@mail.gmail.com>

@Alex

Thanks for sharing your design, the one wrapping data elements in
Pair<Integer, V>. I think it works and the best is that it is lock-free. I
will probably implement something like that for some of our smaller data
structures.

But not the big ones, as you see it consuming a lot of memory, and
scattering data in tons of tiny objects that will hinder GC performance.

Example: one typical data structure is an array of integers. One billion of
those. Using a plain int[] will use about 4GB of memory. If instead I were
allocating an array of one billion Pair<int, int> the memory usage would be
at least 32GB.



@Stacy

Thanks a lot for posting a solution. Your design allows to use compact data
representations, but it is not lock free. A query in a read section holds
the readLock and may delay write transactions. So one must find the right
compromise between short read sections (ok to read a few values,
inefficient for a large scan) or longer more efficient read sections that
introduce "jitter" in writes.

I will definitely git it a try.



@Stephen

I was excited reading your entry because we ourselves tried playing with a
few more volatiles in the design. But it does not work. I think it is
theoretically impossible to get the synchronization we need with only
volatile reads on the reader side. Either plain locking is required, or at
least having the reader writing to a volatile (which can become more
expensive than a read lock).

In the following section of your design:

            else {
                // This assumes that doSomethingWith() can handle the
                // list mutating under its feet in possibly very bad
                // (IndexOutOfBoundsException-sort-of-bad) ways
                doSomethingWith(l);
                if (version == v) {
                    // The version number is the same so, since the
                    // list was visible in the first place, this means
                    // we did not trip over it being changed
                    return;
                }
            }

The compiler will actually write the following instructions:
...
doSomethingWith(l);
int v2 = this.version;
if(v2 == v) { ... }
And that could be reordered into:
...
int v2 = this.version;
doSomethingWith(l);
if(v2 == v) { ... }
 Because "doSomething(l)" involves only "normal load" of memory, it could
be reordered with the subsequent "this.version" volatile load. (I get that
from the table at the top of Doug Lea's cookbook for compiler writers).


-Antoine CHAMBILLE
QuartetFS




On 7 September 2012 23:44, Payne, Stephen <Stephen-Payne at deshaw.com> wrote:

> I tried to send this to the list yesterday but it got black-holed for some
> reason, so I'm sending it directly to you guys instead. Note that it comes
> with big "untested" warning lights on it; it could be utter nonsense.
>
> srp
>
> -----Original Message-----
> From: Payne, Stephen
> Sent: Thursday, September 06, 2012 5:11 PM
> To: Concurrency-interest at cs.oswego.edu
> Subject: RE: [concurrency-interest] [Volatile Store, Normal Store]
> ordering for multi-version data stuctures
>
> I'm going to stick my neck out here (first post and all that) but I
> believe that the following will work:
>
>     // Use two volatiles: the list will be invisible while it is being
>     // mutated; the version will change during this mutation so that,
>     // when the list is once again visible, it will be different from
>     // the value it had when the list was previously visible.
>     //
>     // Assumes only a single writer, but any number of readers.
>     volatile List list    = new ArrayList();
>     volatile int  version = 0;
>
>     // Writes never block
>     write()
>     {
>         List l = list;
>         list = null; // hide list from reader
>         version++;   // bump the mutation count _after_ nulling the list
>         mutate(l);
>         list = l;    // make the list visible again, along with changes
>     }
>
>     // Reads will block (busy-wait) if the writer is active but that's
>     // probably okay since they will have to re-read the changed list
>     // anyway
>     read()
>     {
>         do {
>             // Important -- read the version before the list
>             int  v = version;
>             List l = list;
>             if (l == null) {
>                 // list being mutated; don't starve the writer
>                 Thread.yield();
>             }
>             else {
>                 // This assumes that doSomethingWith() can handle the
>                 // list mutating under its feet in possibly very bad
>                 // (IndexOutOfBoundsException-sort-of-bad) ways
>                 doSomethingWith(l);
>                 if (version == v) {
>                     // The version number is the same so, since the
>                     // list was visible in the first place, this means
>                     // we did not trip over it being changed
>                     return;
>                 }
>             }
>         } while(true);
>     }
>
> It employs the trick of having two atomic operations in the write (the
> initial writes to 'list' and 'version') which are then read in the opposite
> order.
>
> This pseudo-code isn't tested and probably contains an obvious concurrency
> bug which I have not seen...
>
> srp
>
> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Zhong Yu
> Sent: Thursday, September 06, 2012 1:20 PM
> To: Romain Colle
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] [Volatile Store, Normal Store]
> ordering for multi-version data stuctures
>
> In your simplified example, the only write is to replace an element at
> an existing index. That's an easy problem to solve, e.g.
>
>     volatile List list = new ArrayList();
>
>     // writer
>     list.set(i, newItem);
>     list=list;  // to perform a volatile write
>
>     // reader
>     return list.get(i);
>
> Your real problem probably involves more complex writes, where
> multiple variables are updated non-atomically, confusing (if not
> corrupting) concurrent readers. So you want to check whether there's
> state change during a read session.
>
> The reminds me of Doug Lea's SequenceLock
>
>
> http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>
> However note that in the example, x and y are volatile. There are
> minimum 4 volatile reads in the read-only method, even in this very
> simple use case.
>
> Zhong Yu
>
>
> On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com> wrote:
> > Hi all,
> >
> > Antoine's description was a simplified version of our issue, so let me
> try
> > to describe the actual problem.
> >
> > The key thing is that the list that is being "multi-versioned" is very
> large
> > while each modification only affects a few elements.
> > The idea is therefore not to create a full copy for each version (like
> > CopyOnWriteArrayList or some very good suggestions on this list), but to
> > simply store a "delta" with the previous version.
> >
> > Here is a simple example.
> > Let's assume our list is L=(1, 2, 3, 4). (it's not the advertised very
> large
> > structure for the sake of the example).
> > The first version of this list would look like this:
> > L1 = { base = L; delta = null; }
> >
> > Any reader thread that wants to access the list at this point gets L1,
> and
> > all the read requests are forwarded to the base.
> >
> > Now a writer comes in and wants to change the first element to 5. We
> will,
> > in the writer thread
> >   1) create a delta structure with this new mapping: D1 = {element 0:
> 1->5 }
> >   2) create a new version L2 = { base = L; delta = null; }
> >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
> >   4) update L to (5, 2, 3, 4)
> >
> > Any reader thread that had a reference to L1 will do the following to
> read a
> > value:
> >  1) Look for it in the delta. If we find it in there, return the
> "previous"
> > value
> >  2) The value is not in the delta. Forward the read request to L2 (that
> will
> > itself forward it to L), then make sure the delta has not been updated
> if it
> > was null before, and return. Otherwise, go back to 1).
> >
> > This looks like it would work nicely: we are updating L1's base and delta
> > through volatile writes, hence "masking" the first element in the list.
> >
> > However, we spotted the issue mentioned before: because the writes to L
> in
> > step 4 are not volatile (and we'd like to avoid the cost), they can be
> > reordered before step 3 where we set L1's base and delta through volatile
> > writes (roach motel semantics).
> > Therefore, a reader of L1 could read the delta field that is still null
> and
> > get the value from L which is now set to 5, which is incorrect.
> >
> > As Antoine mentioned, we never observed that in our tests (seeing a null
> > version of L1.delta while seeing the updates to L), but it seems that
> this
> > could happen under the JMM.
> > Is this correct? Do you see any ways around it?
> >
> > Thanks!
> >
> >
> > --
> > Romain Colle
> > QuartetFS
> > 2 rue Jean Lantier, 75001 Paris, France
> > http://www.quartetfs.com
> >
> > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis <jacyg at alumni.rice.edu
> >
> > wrote:
> >>
> >> Well, without knowing a lot about the details....  Could do something
> >> like:
> >>
> >>
> >>    private volatile List base = new ArrayList();
> >>
> >>    private void write()
> >>    {
> >>       List copy = new ArrayList(base);
> >>       //do writes to copy
> >>       base = copy;
> >>    }
> >>
> >>    private void read()
> >>    {
> >>       List local = base;
> >>       // do reading using the local variable, NOT the volatile shared
> >> variable.  this is essential,
> >>       // must only read the replacement variable 1x for any set of
> >> reads you expect to be consistent.
> >>       // of course, if you only have a single read, you could dispense
> >> with the local variable, but just
> >>       // bear in mind that the contents of base could be different
> >> each time you reference it.
> >>    }
> >>
> >> Of course, it would also be worth seeing if CopyOnWriteArrayList can
> >> satisfy your requirement.
> >>
> >> jacy
> >>
> >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille <ach at quartetfs.com>
> >> wrote:
> >> > While designing a multiversion data structure I wrote a simple thread
> >> > synchronization based on "volatile".
> >> >
> >> > The shared data is made of a base list, and a volatile "replacement"
> >> > list.
> >> >    List base = ...;
> >> >    volatile List replacement = null;
> >> >
> >> > There is only one writer thread. The writer thread will change some
> >> > elements
> >> > in the list. It creates a copy of the original list, puts it as the
> >> > replacement (volatile write). It is thought that the replacement list
> >> > can
> >> > "hide" the base and that the modifications can be safely written into
> >> > the
> >> > base list.
> >> >    List replacement = new SubList();
> >> >    transfer(shared.base, replacement)
> >> >    shared.replacement = replacement;
> >> >    ...
> >> >    modify(shared.base);
> >> >
> >> > There are multiple readers, concurrently with the writer. If a reader
> >> > sees a
> >> > replacement list, it will read values from it. Else it reads data from
> >> > the
> >> > base list and before returning it checks that the replacement was not
> >> > set in
> >> > the meantime.
> >> >
> >> >    List replacement;
> >> >    for(;;) {
> >> >       replacement = shared.replacement;
> >> >  if(replacement != null) return replacement.get(index);
> >> >  else {
> >> >          Object value = shared.base.get(index);
> >> > List tmp = replacement;
> >> > replacement = shared.replacement;
> >> > if(replacement = tmp) return value;
> >> >  }
> >>
> >>    private volatile List base = new ArrayList();
> >>
> >>    private void write()
> >>    {
> >>       List copy = new ArrayList(base);
> >>       //do writes to copy
> >>       base = copy;
> >>    }
> >>
> >>    private void read()
> >>    {
> >>       List local = base;
> >>       // do reading using the local variable, NOT the volatile shared
> >> variable.  this is essential,
> >>       // must only read the replacement variable 1x for any set of
> >> reads you expect to be consistent.
> >>       // of course, if you only have a single read, you could dispense
> >> with the local variable, but just
> >>       // bear in mind that the contents of base could be different
> >> each time you reference it.
> >>    }
> >> >    }
> >> >
> >> >
> >> > The design passes a modest set of unit tests on an x86 multi-core
> >> > processor
> >> > but a colleague spotted a big flaw. This expects too much from the
> java
> >> > memory model. The modifications to the base list that were thought to
> be
> >> > invisible to readers could be reordered before the volatile write of
> the
> >> > replacement. So a writer could read garbage from the base, think the
> >> > replacement was not set and return the garbage.
> >> >
> >> >
> >> > Do you see other means (volatile, CAS, UNSAFE,...) that would fix the
> >> > above
> >> > design without resorting to synchronized blocks or locks ?
> >> >
> >> >
> >> > Thanks a lot,
> >> > -Antoine CHAMBILLE
> >> > Quartet FS
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120910/a15ae62c/attachment-0001.html>

From oleksandr.otenko at oracle.com  Mon Sep 10 12:35:26 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Mon, 10 Sep 2012 17:35:26 +0100
Subject: [concurrency-interest] FW:  [Volatile Store,
 Normal Store] ordering for multi-version data stuctures
In-Reply-To: <CAJGQDwmUBs9Et2Wxj_b1dY+ntGtk2cKsDHJehK=EH+jAhqrp2g@mail.gmail.com>
References: <CAJGQDwmZVmvsX9shxAfnS83eR6-CUZXMS89dczqRwZVJaU7C3w@mail.gmail.com>
	<CAESiqErELwF5qHJ1+bKQR2ffM2CXb0hvXtYdPJ4KRg21n0BY-Q@mail.gmail.com>
	<CAJp3eRAnk7xX7TKKDLrBO7B5o9_8ijdvO6Jc5hO3SYc45vyqVA@mail.gmail.com>
	<CACuKZqFxjQt=-Xsv45r79Bn9dSgY_pETGdXfHehxuY7W_z9hYA@mail.gmail.com>
	<55750586F6FCD84DA95BC188F9628C8045CDFD77@mailnycmb4a.winmail.deshaw.com>
	<CAJGQDwmUBs9Et2Wxj_b1dY+ntGtk2cKsDHJehK=EH+jAhqrp2g@mail.gmail.com>
Message-ID: <504E16CE.1020109@oracle.com>

I don't think that is the flaw of the design. There are standard 
practices how the footprint can be reduced, especially if you own the 
design of the data structure holding the billions of references.


Alex


On 10/09/2012 13:00, Antoine Chambille wrote:
> @Alex
>
> Thanks for sharing your design, the one wrapping data elements in 
> Pair<Integer, V>. I think it works and the best is that it is 
> lock-free. I will probably implement something like that for some of 
> our smaller data structures.
>
> But not the big ones, as you see it consuming a lot of memory, and 
> scattering data in tons of tiny objects that will hinder GC performance.
>
> Example: one typical data structure is an array of integers. One 
> billion of those. Using a plain int[] will use about 4GB of memory. If 
> instead I were allocating an array of one billion Pair<int, int> the 
> memory usage would be at least 32GB.
>
>
>
> @Stacy
>
> Thanks a lot for posting a solution. Your design allows to use compact 
> data representations, but it is not lock free. A query in a read 
> section holds the readLock and may delay write transactions. So one 
> must find the right compromise between short read sections (ok to read 
> a few values, inefficient for a large scan) or longer more efficient 
> read sections that introduce "jitter" in writes.
>
> I will definitely git it a try.
>
>
>
> @Stephen
>
> I was excited reading your entry because we ourselves tried playing 
> with a few more volatiles in the design. But it does not work. I think 
> it is theoretically impossible to get the synchronization we need with 
> only volatile reads on the reader side. Either plain locking is 
> required, or at least having the reader writing to a volatile (which 
> can become more expensive than a read lock).
>
> In the following section of your design:
>
>             else {
>                 // This assumes that doSomethingWith() can handle the
>                 // list mutating under its feet in possibly very bad
>                 // (IndexOutOfBoundsException-sort-of-bad) ways
>                 doSomethingWith(l);
>                 if (version == v) {
>                     // The version number is the same so, since the
>                     // list was visible in the first place, this means
>                     // we did not trip over it being changed
>                     return;
>                 }
>             }
>
> The compiler will actually write the following instructions:
> ...
> doSomethingWith(l);
> int v2 = this.version;
> if(v2 == v) { ... }
> And that could be reordered into:
> ...
> int v2 = this.version;
> doSomethingWith(l);
> if(v2 == v) { ... }
> Because "doSomething(l)" involves only "normal load" of memory, it 
> could be reordered with the subsequent "this.version" volatile load. 
> (I get that from the table at the top of Doug Lea's cookbook for 
> compiler writers).
>
>
> -Antoine CHAMBILLE
> QuartetFS
>
>
>
>
> On 7 September 2012 23:44, Payne, Stephen <Stephen-Payne at deshaw.com 
> <mailto:Stephen-Payne at deshaw.com>> wrote:
>
>     I tried to send this to the list yesterday but it got black-holed
>     for some reason, so I'm sending it directly to you guys instead.
>     Note that it comes with big "untested" warning lights on it; it
>     could be utter nonsense.
>
>     srp
>
>     -----Original Message-----
>     From: Payne, Stephen
>     Sent: Thursday, September 06, 2012 5:11 PM
>     To: Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     Subject: RE: [concurrency-interest] [Volatile Store, Normal Store]
>     ordering for multi-version data stuctures
>
>     I'm going to stick my neck out here (first post and all that) but
>     I believe that the following will work:
>
>         // Use two volatiles: the list will be invisible while it is being
>         // mutated; the version will change during this mutation so that,
>         // when the list is once again visible, it will be different from
>         // the value it had when the list was previously visible.
>         //
>         // Assumes only a single writer, but any number of readers.
>         volatile List list    = new ArrayList();
>         volatile int  version = 0;
>
>         // Writes never block
>         write()
>         {
>             List l = list;
>             list = null; // hide list from reader
>             version++;   // bump the mutation count _after_ nulling
>     the list
>             mutate(l);
>             list = l;    // make the list visible again, along with
>     changes
>         }
>
>         // Reads will block (busy-wait) if the writer is active but that's
>         // probably okay since they will have to re-read the changed list
>         // anyway
>         read()
>         {
>             do {
>                 // Important -- read the version before the list
>                 int  v = version;
>                 List l = list;
>                 if (l == null) {
>                     // list being mutated; don't starve the writer
>                     Thread.yield();
>                 }
>                 else {
>                     // This assumes that doSomethingWith() can handle the
>                     // list mutating under its feet in possibly very bad
>                     // (IndexOutOfBoundsException-sort-of-bad) ways
>                     doSomethingWith(l);
>                     if (version == v) {
>                         // The version number is the same so, since the
>                         // list was visible in the first place, this means
>                         // we did not trip over it being changed
>                         return;
>                     }
>                 }
>             } while(true);
>         }
>
>     It employs the trick of having two atomic operations in the write
>     (the initial writes to 'list' and 'version') which are then read
>     in the opposite order.
>
>     This pseudo-code isn't tested and probably contains an obvious
>     concurrency bug which I have not seen...
>
>     srp
>
>     -----Original Message-----
>     From: concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>
>     [mailto:concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of
>     Zhong Yu
>     Sent: Thursday, September 06, 2012 1:20 PM
>     To: Romain Colle
>     Cc: Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     Subject: Re: [concurrency-interest] [Volatile Store, Normal Store]
>     ordering for multi-version data stuctures
>
>     In your simplified example, the only write is to replace an element at
>     an existing index. That's an easy problem to solve, e.g.
>
>         volatile List list = new ArrayList();
>
>         // writer
>         list.set(i, newItem);
>         list=list;  // to perform a volatile write
>
>         // reader
>         return list.get(i);
>
>     Your real problem probably involves more complex writes, where
>     multiple variables are updated non-atomically, confusing (if not
>     corrupting) concurrent readers. So you want to check whether there's
>     state change during a read session.
>
>     The reminds me of Doug Lea's SequenceLock
>
>     http://gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/jsr166e/SequenceLock.html
>
>     However note that in the example, x and y are volatile. There are
>     minimum 4 volatile reads in the read-only method, even in this very
>     simple use case.
>
>     Zhong Yu
>
>
>     On Thu, Sep 6, 2012 at 1:19 PM, Romain Colle <rco at quartetfs.com
>     <mailto:rco at quartetfs.com>> wrote:
>     > Hi all,
>     >
>     > Antoine's description was a simplified version of our issue, so
>     let me try
>     > to describe the actual problem.
>     >
>     > The key thing is that the list that is being "multi-versioned"
>     is very large
>     > while each modification only affects a few elements.
>     > The idea is therefore not to create a full copy for each version
>     (like
>     > CopyOnWriteArrayList or some very good suggestions on this
>     list), but to
>     > simply store a "delta" with the previous version.
>     >
>     > Here is a simple example.
>     > Let's assume our list is L=(1, 2, 3, 4). (it's not the
>     advertised very large
>     > structure for the sake of the example).
>     > The first version of this list would look like this:
>     > L1 = { base = L; delta = null; }
>     >
>     > Any reader thread that wants to access the list at this point
>     gets L1, and
>     > all the read requests are forwarded to the base.
>     >
>     > Now a writer comes in and wants to change the first element to
>     5. We will,
>     > in the writer thread
>     >   1) create a delta structure with this new mapping: D1 =
>     {element 0: 1->5 }
>     >   2) create a new version L2 = { base = L; delta = null; }
>     >   3) update L1's base and delta. L1 = { base = L2; delta = D1; }
>     >   4) update L to (5, 2, 3, 4)
>     >
>     > Any reader thread that had a reference to L1 will do the
>     following to read a
>     > value:
>     >  1) Look for it in the delta. If we find it in there, return the
>     "previous"
>     > value
>     >  2) The value is not in the delta. Forward the read request to
>     L2 (that will
>     > itself forward it to L), then make sure the delta has not been
>     updated if it
>     > was null before, and return. Otherwise, go back to 1).
>     >
>     > This looks like it would work nicely: we are updating L1's base
>     and delta
>     > through volatile writes, hence "masking" the first element in
>     the list.
>     >
>     > However, we spotted the issue mentioned before: because the
>     writes to L in
>     > step 4 are not volatile (and we'd like to avoid the cost), they
>     can be
>     > reordered before step 3 where we set L1's base and delta through
>     volatile
>     > writes (roach motel semantics).
>     > Therefore, a reader of L1 could read the delta field that is
>     still null and
>     > get the value from L which is now set to 5, which is incorrect.
>     >
>     > As Antoine mentioned, we never observed that in our tests
>     (seeing a null
>     > version of L1.delta while seeing the updates to L), but it seems
>     that this
>     > could happen under the JMM.
>     > Is this correct? Do you see any ways around it?
>     >
>     > Thanks!
>     >
>     >
>     > --
>     > Romain Colle
>     > QuartetFS
>     > 2 rue Jean Lantier, 75001 Paris, France
>     > http://www.quartetfs.com
>     >
>     > On Thu, Sep 6, 2012 at 7:06 PM, Jacy Odin Grannis
>     <jacyg at alumni.rice.edu <mailto:jacyg at alumni.rice.edu>>
>     > wrote:
>     >>
>     >> Well, without knowing a lot about the details....  Could do
>     something
>     >> like:
>     >>
>     >>
>     >>    private volatile List base = new ArrayList();
>     >>
>     >>    private void write()
>     >>    {
>     >>       List copy = new ArrayList(base);
>     >>       //do writes to copy
>     >>       base = copy;
>     >>    }
>     >>
>     >>    private void read()
>     >>    {
>     >>       List local = base;
>     >>       // do reading using the local variable, NOT the volatile
>     shared
>     >> variable.  this is essential,
>     >>       // must only read the replacement variable 1x for any set of
>     >> reads you expect to be consistent.
>     >>       // of course, if you only have a single read, you could
>     dispense
>     >> with the local variable, but just
>     >>       // bear in mind that the contents of base could be different
>     >> each time you reference it.
>     >>    }
>     >>
>     >> Of course, it would also be worth seeing if
>     CopyOnWriteArrayList can
>     >> satisfy your requirement.
>     >>
>     >> jacy
>     >>
>     >> On Thu, Sep 6, 2012 at 11:38 AM, Antoine Chambille
>     <ach at quartetfs.com <mailto:ach at quartetfs.com>>
>     >> wrote:
>     >> > While designing a multiversion data structure I wrote a
>     simple thread
>     >> > synchronization based on "volatile".
>     >> >
>     >> > The shared data is made of a base list, and a volatile
>     "replacement"
>     >> > list.
>     >> >    List base = ...;
>     >> >    volatile List replacement = null;
>     >> >
>     >> > There is only one writer thread. The writer thread will
>     change some
>     >> > elements
>     >> > in the list. It creates a copy of the original list, puts it
>     as the
>     >> > replacement (volatile write). It is thought that the
>     replacement list
>     >> > can
>     >> > "hide" the base and that the modifications can be safely
>     written into
>     >> > the
>     >> > base list.
>     >> >    List replacement = new SubList();
>     >> >    transfer(shared.base, replacement)
>     >> >    shared.replacement = replacement;
>     >> >    ...
>     >> >    modify(shared.base);
>     >> >
>     >> > There are multiple readers, concurrently with the writer. If
>     a reader
>     >> > sees a
>     >> > replacement list, it will read values from it. Else it reads
>     data from
>     >> > the
>     >> > base list and before returning it checks that the replacement
>     was not
>     >> > set in
>     >> > the meantime.
>     >> >
>     >> >    List replacement;
>     >> >    for(;;) {
>     >> >       replacement = shared.replacement;
>     >> >  if(replacement != null) return replacement.get(index);
>     >> >  else {
>     >> >          Object value = shared.base.get(index);
>     >> > List tmp = replacement;
>     >> > replacement = shared.replacement;
>     >> > if(replacement = tmp) return value;
>     >> >  }
>     >>
>     >>    private volatile List base = new ArrayList();
>     >>
>     >>    private void write()
>     >>    {
>     >>       List copy = new ArrayList(base);
>     >>       //do writes to copy
>     >>       base = copy;
>     >>    }
>     >>
>     >>    private void read()
>     >>    {
>     >>       List local = base;
>     >>       // do reading using the local variable, NOT the volatile
>     shared
>     >> variable.  this is essential,
>     >>       // must only read the replacement variable 1x for any set of
>     >> reads you expect to be consistent.
>     >>       // of course, if you only have a single read, you could
>     dispense
>     >> with the local variable, but just
>     >>       // bear in mind that the contents of base could be different
>     >> each time you reference it.
>     >>    }
>     >> >    }
>     >> >
>     >> >
>     >> > The design passes a modest set of unit tests on an x86 multi-core
>     >> > processor
>     >> > but a colleague spotted a big flaw. This expects too much
>     from the java
>     >> > memory model. The modifications to the base list that were
>     thought to be
>     >> > invisible to readers could be reordered before the volatile
>     write of the
>     >> > replacement. So a writer could read garbage from the base,
>     think the
>     >> > replacement was not set and return the garbage.
>     >> >
>     >> >
>     >> > Do you see other means (volatile, CAS, UNSAFE,...) that would
>     fix the
>     >> > above
>     >> > design without resorting to synchronized blocks or locks ?
>     >> >
>     >> >
>     >> > Thanks a lot,
>     >> > -Antoine CHAMBILLE
>     >> > Quartet FS
>     >> >
>     >> > _______________________________________________
>     >> > Concurrency-interest mailing list
>     >> > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >> >
>     >> _______________________________________________
>     >> Concurrency-interest mailing list
>     >> Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     >
>     >
>     >
>     >
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     >
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> -- 
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120910/e5491435/attachment-0001.html>

From ach at quartetfs.com  Tue Sep 11 11:28:19 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Tue, 11 Sep 2012 17:28:19 +0200
Subject: [concurrency-interest] Establishing memory fences with volatile
Message-ID: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>

Hello.

To implement lock-free multiversion data structures we try to establish
memory fences with the help of volatiles. Maybe you read about those
experiments in a previous thread titled "[Volatile Store, Normal Store]
ordering for multi-version data stuctures".

There is a piece of shared data that several readers access, and it is not
atomic. A writer decides to close access to this shared data, and once the
access is closed it writes modifications to the shared data, that none of
the readers should "see". The danger is a reader reads modified data
 without realizing the access was closed.


We propose the following design:

[SOLUTION 1]

[SHARED]
data;
volatile v1 = false;
volatile v2;

[WRITER]
#W1   v1 = true; // volatile store of v1
#W2   v2; // volatile load of v2
#W3   modify(data);

[READER]
#R1   d = read(data);
#R2   v2 = something; // volatile store of v2
#R3   if(v1) {return null;} else {return d;} // volatile load of v1

We hope we do not miss a flaw, and believe the strong "happens before"
semantics of the Java Memory Model make it work.



Now we wonder if we can have the same for less. Using ordered puts instead
of volatile writes for instance. Are we right to think it provides the same
ordering guarantee?

[SOLUTION 2]

[SHARED]
data;
volatile v1 = false;
volatile v2;

[WRITER]
#W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
#W2   v2; // volatile load of v2
#W3   modify(data);

[READER]
#R1   d = read(data);
#R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
#R3   if(v1) {return null;} else {return d;} // volatile load of v1




Finally are we allowed to reason purely about the non-reordering
constraints of the JMM ("roach motels") and rely on the following solution
that does not involve any volatile write by the readers?

[SOLUTION 3]

[SHARED]
data;
volatile v1 = false;

[WRITER]
#W1   v1 = true; // volatile store of v1
#W2   v1; // volatile load
#W3   modify(data)

[READER]
#R1   d = readVolatile(data); // volatile loads
#R2   if(v1) {return null;} else {return d;} // volatile load of v1

On the writer side, the modification of the data cannot be reordered with
the above volatile load, that itself cannot be reordered with the previous
volatile store. On the reader side the volatile reads in the data cannot be
reordered with the volatile load of v1. So it is not possible for the
reader to read modified data without knowing about it.



Thanks for reading,

Antoine CHAMBILLE
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120911/c0f4df42/attachment.html>

From zhong.j.yu at gmail.com  Tue Sep 11 12:32:28 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 11 Sep 2012 11:32:28 -0500
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
Message-ID: <CACuKZqG1+Rcy-J1=2+_HNy=rCAVpg+day4SkJR+6o8C46SxBPA@mail.gmail.com>

On Tue, Sep 11, 2012 at 10:28 AM, Antoine Chambille <ach at quartetfs.com> wrote:
> Hello.
>
> To implement lock-free multiversion data structures we try to establish
> memory fences with the help of volatiles. Maybe you read about those
> experiments in a previous thread titled "[Volatile Store, Normal Store]
> ordering for multi-version data stuctures".
>
> There is a piece of shared data that several readers access, and it is not
> atomic. A writer decides to close access to this shared data, and once the
> access is closed it writes modifications to the shared data, that none of
> the readers should "see". The danger is a reader reads modified data
> without realizing the access was closed.
>
>
> We propose the following design:
>
> [SOLUTION 1]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   v2 = something; // volatile store of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
> We hope we do not miss a flaw, and believe the strong "happens before"
> semantics of the Java Memory Model make it work.
>
>
>
> Now we wonder if we can have the same for less. Using ordered puts instead
> of volatile writes for instance. Are we right to think it provides the same
> ordering guarantee?
>
> [SOLUTION 2]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
>
>
>
> Finally are we allowed to reason purely about the non-reordering constraints
> of the JMM ("roach motels") and rely on the following solution that does not
> involve any volatile write by the readers?
>
> [SOLUTION 3]
>
> [SHARED]
> data;
> volatile v1 = false;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v1; // volatile load
> #W3   modify(data)
>
> [READER]
> #R1   d = readVolatile(data); // volatile loads
> #R2   if(v1) {return null;} else {return d;} // volatile load of v1
>
> On the writer side, the modification of the data cannot be reordered with
> the above volatile load, that itself cannot be reordered with the previous
> volatile store. On the reader side the volatile reads in the data cannot be
> reordered with the volatile load of v1. So it is not possible for the reader
> to read modified data without knowing about it.

I'm not sure about solution#3. Suppose in #R2, v1 reads false, so it
must be the case that #R2 is before #W1 in synchronization order.
However that does not establish any constraint that prevents #R1 from
seeing #W3, as far as JMM is concerned. If #W3 are all volatile
writes, then it'll work due to synchronization-order consistency
requirement. Making #W3 volatile is probably inexpensive in your app.


>
> Thanks for reading,
>
> Antoine CHAMBILLE
> Quartet FS
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From oleksandr.otenko at oracle.com  Tue Sep 11 12:45:19 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Tue, 11 Sep 2012 17:45:19 +0100
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
Message-ID: <504F6A9F.3020608@oracle.com>

But you haven't explained how you reset the "write lock" flag back.


Surely it is just a delta that covers the whole range of the 
datastructure, so not very difficult to add a condition check on the 
path of delta.contains(i).


Alex


On 11/09/2012 16:28, Antoine Chambille wrote:
> Hello.
>
> To implement lock-free multiversion data structures we try to 
> establish memory fences with the help of volatiles. Maybe you read 
> about those experiments in a previous thread titled "[Volatile Store, 
> Normal Store] ordering for multi-version data stuctures".
>
> There is a piece of shared data that several readers access, and it is 
> not atomic. A writer decides to close access to this shared data, and 
> once the access is closed it writes modifications to the shared data, 
> that none of the readers should "see". The danger is a reader reads 
> modified data  without realizing the access was closed.
>
>
> We propose the following design:
>
> [SOLUTION 1]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   v2 = something; // volatile store of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
> We hope we do not miss a flaw, and believe the strong "happens before" 
> semantics of the Java Memory Model make it work.
>
>
>
> Now we wonder if we can have the same for less. Using ordered puts 
> instead of volatile writes for instance. Are we right to think it 
> provides the same ordering guarantee?
>
> [SOLUTION 2]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
>
>
>
> Finally are we allowed to reason purely about the non-reordering 
> constraints of the JMM ("roach motels") and rely on the following 
> solution that does not involve any volatile write by the readers?
>
> [SOLUTION 3]
>
> [SHARED]
> data;
> volatile v1 = false;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v1; // volatile load
> #W3   modify(data)
>
> [READER]
> #R1   d = readVolatile(data); // volatile loads
> #R2   if(v1) {return null;} else {return d;} // volatile load of v1
>
> On the writer side, the modification of the data cannot be reordered 
> with the above volatile load, that itself cannot be reordered with the 
> previous volatile store. On the reader side the volatile reads in the 
> data cannot be reordered with the volatile load of v1. So it is not 
> possible for the reader to read modified data without knowing about it.
>
>
>
> Thanks for reading,
>
> Antoine CHAMBILLE
> Quartet FS
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120911/43119019/attachment.html>

From hans.boehm at hp.com  Tue Sep 11 20:57:29 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Wed, 12 Sep 2012 00:57:29 +0000
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <504F6A9F.3020608@oracle.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>

In the non-null return case, R3 precedes W1 in sync order.  Sync order is consistent with program order, so R2 precedes R3 precedes W1 precedes W2 in sync order.  Which means R2 synchronizes with W2, so R1 happens before W3.  So I think your basic conclusion is correct.

The code for read() still needs to be incredible defensive, since it may see wildly inconsistent state.  For example, it may see a counter decrease that's only incremented by modify().

And all of this is on somewhat thin ice, since it depends on the known-buggy Java semantics of data races.  It's an interesting example, in that it shows that discarded volatile loads can't be eliminated.

Solution 2 doesn't have well-defined semantics, so who knows?

Solution 3 doesn't have a corresponding happens-before relationship, so I don't believe it's correct, though it may work on most implementations.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of oleksandr otenko
Sent: Tuesday, September 11, 2012 9:45 AM
To: Antoine Chambille
Cc: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Establishing memory fences with volatile

But you haven't explained how you reset the "write lock" flag back.


Surely it is just a delta that covers the whole range of the datastructure, so not very difficult to add a condition check on the path of delta.contains(i).


Alex


On 11/09/2012 16:28, Antoine Chambille wrote:
Hello.

To implement lock-free multiversion data structures we try to establish memory fences with the help of volatiles. Maybe you read about those experiments in a previous thread titled "[Volatile Store, Normal Store] ordering for multi-version data stuctures".

There is a piece of shared data that several readers access, and it is not atomic. A writer decides to close access to this shared data, and once the access is closed it writes modifications to the shared data, that none of the readers should "see". The danger is a reader reads modified data  without realizing the access was closed.


We propose the following design:

[SOLUTION 1]

[SHARED]
data;
volatile v1 = false;
volatile v2;

[WRITER]
#W1   v1 = true; // volatile store of v1
#W2   v2; // volatile load of v2
#W3   modify(data);

[READER]
#R1   d = read(data);
#R2   v2 = something; // volatile store of v2
#R3   if(v1) {return null;} else {return d;} // volatile load of v1

We hope we do not miss a flaw, and believe the strong "happens before" semantics of the Java Memory Model make it work.



Now we wonder if we can have the same for less. Using ordered puts instead of volatile writes for instance. Are we right to think it provides the same ordering guarantee?

[SOLUTION 2]

[SHARED]
data;
volatile v1 = false;
volatile v2;

[WRITER]
#W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
#W2   v2; // volatile load of v2
#W3   modify(data);

[READER]
#R1   d = read(data);
#R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
#R3   if(v1) {return null;} else {return d;} // volatile load of v1




Finally are we allowed to reason purely about the non-reordering constraints of the JMM ("roach motels") and rely on the following solution that does not involve any volatile write by the readers?

[SOLUTION 3]

[SHARED]
data;
volatile v1 = false;

[WRITER]
#W1   v1 = true; // volatile store of v1
#W2   v1; // volatile load
#W3   modify(data)

[READER]
#R1   d = readVolatile(data); // volatile loads
#R2   if(v1) {return null;} else {return d;} // volatile load of v1

On the writer side, the modification of the data cannot be reordered with the above volatile load, that itself cannot be reordered with the previous volatile store. On the reader side the volatile reads in the data cannot be reordered with the volatile load of v1. So it is not possible for the reader to read modified data without knowing about it.



Thanks for reading,

Antoine CHAMBILLE
Quartet FS




_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>

http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/d8ab0880/attachment-0001.html>

From ach at quartetfs.com  Wed Sep 12 04:28:00 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Wed, 12 Sep 2012 10:28:00 +0200
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
Message-ID: <CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>

Thank you, I really appreciate the feedback.

In particular thank you Hans for analysing each of the 3 solutions.


So the solution 1 appears to be valid, because the reasoning relies on
"to-the-letter" happens-before relationships. Of course the readers must be
very careful when they look at the data and watch for null references,
array bounds,... It is certainly not strong enough for a user API but we
consider implementing that for private, core internal multiversion
structures in our main memory database.

Solution 2 cannot be used because putOrdered(...) does not have well
defined semantics (That's sad because putOrdered seem a lot cheaper on x86
than full volatile writes). I apologize for being candid but then is there
and what is the definition of putOrdered? And can we use it for anything at
all if not in this case?

Solution 3 is discarded because it does not have a corresponding
happens-before relationship. This is precisely what keeps confusing me with
java concurrency. I have seen several times the following JVM rules stated:
 - Two volatile writes cannot be reordered
 - A volatile write cannot be reordered with a volatile write
 - A normal store cannot be reordered with a previous volatile load
 - A normal load cannot be reordered with a subsequent volatile store
Are we not allowed to reason with those rules, that offer finer fencing
control that plain "happens-before" relationships? Are we aware of one
single hardware platform or JVM implementation that would possibly not
respect the above rules?


-Antoine CHAMBILLE
QuartetFS





On 12 September 2012 02:57, Boehm, Hans <hans.boehm at hp.com> wrote:

>  In the non-null return case, R3 precedes W1 in sync order.  Sync order
> is consistent with program order, so R2 precedes R3 precedes W1 precedes W2
> in sync order.  Which means R2 synchronizes with W2, so R1 happens before
> W3.  So I think your basic conclusion is correct.****
>
> ** **
>
> The code for read() still needs to be incredible defensive, since it may
> see wildly inconsistent state.  For example, it may see a counter decrease
> that?s only incremented by modify().****
>
> ** **
>
> And all of this is on somewhat thin ice, since it depends on the
> known-buggy Java semantics of data races.  It?s an interesting example, in
> that it shows that discarded volatile loads can?t be eliminated.****
>
> ** **
>
> Solution 2 doesn?t have well-defined semantics, so who knows?****
>
> ** **
>
> Solution 3 doesn?t have a corresponding happens-before relationship, so I
> don?t believe it?s correct, though it may work on most implementations.***
> *
>
> ** **
>
> Hans****
>
> ** **
>
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *oleksandr
> otenko
> *Sent:* Tuesday, September 11, 2012 9:45 AM
> *To:* Antoine Chambille
> *Cc:* Concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Establishing memory fences with
> volatile****
>
> ** **
>
> But you haven't explained how you reset the "write lock" flag back.
>
>
> Surely it is just a delta that covers the whole range of the
> datastructure, so not very difficult to add a condition check on the path
> of delta.contains(i).
>
>
> Alex
>
>
> On 11/09/2012 16:28, Antoine Chambille wrote: ****
>
> Hello.****
>
> ** **
>
> To implement lock-free multiversion data structures we try to establish
> memory fences with the help of volatiles. Maybe you read about those
> experiments in a previous thread titled "[Volatile Store, Normal Store]
> ordering for multi-version data stuctures".****
>
> ** **
>
> There is a piece of shared data that several readers access, and it is not
> atomic. A writer decides to close access to this shared data, and once the
> access is closed it writes modifications to the shared data, that none of
> the readers should "see". The danger is a reader reads modified data
>  without realizing the access was closed.****
>
> ** **
>
> ** **
>
> We propose the following design:****
>
> ** **
>
> [SOLUTION 1]****
>
> ** **
>
> [SHARED]****
>
> data;****
>
> volatile v1 = false;****
>
> volatile v2;****
>
> ** **
>
> [WRITER]****
>
> #W1   v1 = true; // volatile store of v1****
>
> #W2   v2; // volatile load of v2****
>
> #W3   modify(data);****
>
> ** **
>
> [READER]****
>
> #R1   d = read(data);****
>
> #R2   v2 = something; // volatile store of v2****
>
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1****
>
> ** **
>
> We hope we do not miss a flaw, and believe the strong "happens before"
> semantics of the Java Memory Model make it work.****
>
> ** **
>
> ** **
>
> ** **
>
> Now we wonder if we can have the same for less. Using ordered puts instead
> of volatile writes for instance. Are we right to think it provides the same
> ordering guarantee?****
>
> ** **
>
> [SOLUTION 2]****
>
> ** **
>
> [SHARED]****
>
> data;****
>
> volatile v1 = false;****
>
> volatile v2;****
>
> ** **
>
> [WRITER]****
>
> #W1   UNSAFE.putOrdered(v1, true); // ordered put of v1****
>
> #W2   v2; // volatile load of v2****
>
> #W3   modify(data);****
>
> ** **
>
> [READER]****
>
> #R1   d = read(data);****
>
> #R2   UNSAFE.putOrdered(v2, something); // ordered put of v2****
>
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1****
>
> ** **
>
> ** **
>
> ** **
>
> ** **
>
> Finally are we allowed to reason purely about the non-reordering
> constraints of the JMM ("roach motels") and rely on the following solution
> that does not involve any volatile write by the readers?****
>
> ** **
>
> [SOLUTION 3]****
>
> ** **
>
> [SHARED]****
>
> data;****
>
> volatile v1 = false;****
>
> ** **
>
> [WRITER]****
>
> #W1   v1 = true; // volatile store of v1****
>
> #W2   v1; // volatile load****
>
> #W3   modify(data)****
>
> ** **
>
> [READER]****
>
> #R1   d = readVolatile(data); // volatile loads****
>
> #R2   if(v1) {return null;} else {return d;} // volatile load of v1****
>
> ** **
>
> On the writer side, the modification of the data cannot be reordered with
> the above volatile load, that itself cannot be reordered with the previous
> volatile store. On the reader side the volatile reads in the data cannot be
> reordered with the volatile load of v1. So it is not possible for the
> reader to read modified data without knowing about it.****
>
> ** **
>
> ** **
>
> ** **
>
> Thanks for reading,****
>
> ** **
>
> Antoine CHAMBILLE****
>
> Quartet FS****
>
>
>
>
> ****
>
> _______________________________________________****
>
> Concurrency-interest mailing list****
>
> Concurrency-interest at cs.oswego.edu****
>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest****
>
>


-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/25e7c936/attachment.html>

From oleksandr.otenko at oracle.com  Wed Sep 12 05:25:07 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Wed, 12 Sep 2012 10:25:07 +0100
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
Message-ID: <505054F3.7060305@oracle.com>

Not clear why you consider solution 1 and 3 as different.

In solution 1 R2 orders R3 with respect to R1. In solution 3 R2 is 
naturally ordered with respect to R1.


Alex

On 12/09/2012 01:57, Boehm, Hans wrote:
>
> In the non-null return case, R3 precedes W1 in sync order.  Sync order 
> is consistent with program order, so R2 precedes R3 precedes W1 
> precedes W2 in sync order.  Which means R2 synchronizes with W2, so R1 
> happens before W3.  So I think your basic conclusion is correct.
>
> The code for read() still needs to be incredible defensive, since it 
> may see wildly inconsistent state.  For example, it may see a counter 
> decrease that's only incremented by modify().
>
> And all of this is on somewhat thin ice, since it depends on the 
> known-buggy Java semantics of data races.  It's an interesting 
> example, in that it shows that discarded volatile loads can't be 
> eliminated.
>
> Solution 2 doesn't have well-defined semantics, so who knows?
>
> Solution 3 doesn't have a corresponding happens-before relationship, 
> so I don't believe it's correct, though it may work on most 
> implementations.
>
> Hans
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *oleksandr otenko
> *Sent:* Tuesday, September 11, 2012 9:45 AM
> *To:* Antoine Chambille
> *Cc:* Concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Establishing memory fences with 
> volatile
>
> But you haven't explained how you reset the "write lock" flag back.
>
>
> Surely it is just a delta that covers the whole range of the 
> datastructure, so not very difficult to add a condition check on the 
> path of delta.contains(i).
>
>
> Alex
>
>
> On 11/09/2012 16:28, Antoine Chambille wrote:
>
> Hello.
>
> To implement lock-free multiversion data structures we try to 
> establish memory fences with the help of volatiles. Maybe you read 
> about those experiments in a previous thread titled "[Volatile Store, 
> Normal Store] ordering for multi-version data stuctures".
>
> There is a piece of shared data that several readers access, and it is 
> not atomic. A writer decides to close access to this shared data, and 
> once the access is closed it writes modifications to the shared data, 
> that none of the readers should "see". The danger is a reader reads 
> modified data  without realizing the access was closed.
>
> We propose the following design:
>
> [SOLUTION 1]
>
> [SHARED]
>
> data;
>
> volatile v1 = false;
>
> volatile v2;
>
> [WRITER]
>
> #W1   v1 = true; // volatile store of v1
>
> #W2   v2; // volatile load of v2
>
> #W3   modify(data);
>
> [READER]
>
> #R1   d = read(data);
>
> #R2   v2 = something; // volatile store of v2
>
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
> We hope we do not miss a flaw, and believe the strong "happens before" 
> semantics of the Java Memory Model make it work.
>
> Now we wonder if we can have the same for less. Using ordered puts 
> instead of volatile writes for instance. Are we right to think it 
> provides the same ordering guarantee?
>
> [SOLUTION 2]
>
> [SHARED]
>
> data;
>
> volatile v1 = false;
>
> volatile v2;
>
> [WRITER]
>
> #W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
>
> #W2   v2; // volatile load of v2
>
> #W3   modify(data);
>
> [READER]
>
> #R1   d = read(data);
>
> #R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
>
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
> Finally are we allowed to reason purely about the non-reordering 
> constraints of the JMM ("roach motels") and rely on the following 
> solution that does not involve any volatile write by the readers?
>
> [SOLUTION 3]
>
> [SHARED]
>
> data;
>
> volatile v1 = false;
>
> [WRITER]
>
> #W1   v1 = true; // volatile store of v1
>
> #W2   v1; // volatile load
>
> #W3   modify(data)
>
> [READER]
>
> #R1   d = readVolatile(data); // volatile loads
>
> #R2   if(v1) {return null;} else {return d;} // volatile load of v1
>
> On the writer side, the modification of the data cannot be reordered 
> with the above volatile load, that itself cannot be reordered with the 
> previous volatile store. On the reader side the volatile reads in the 
> data cannot be reordered with the volatile load of v1. So it is not 
> possible for the reader to read modified data without knowing about it.
>
> Thanks for reading,
>
> Antoine CHAMBILLE
>
> Quartet FS
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu  <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/1fc6f4f7/attachment-0001.html>

From andrew_nuss at yahoo.com  Wed Sep 12 09:00:44 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Wed, 12 Sep 2012 06:00:44 -0700 (PDT)
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
Message-ID: <1347454844.50491.YahooMailNeo@web120301.mail.ne1.yahoo.com>

Hans,

I am using volatiles alot in my own lockfree algorithms.? Mostly as references to arrays.? The updater does this to the volatile array member:

ar = ar;

And the reader just gets a local reference to the volatile member and uses it.

What do you mean by "known buggy behavior for data races"?? What do I have to watchout for?

Thanks,
Andy



________________________________
 From: "Boehm, Hans" <hans.boehm at hp.com>
To: oleksandr otenko <oleksandr.otenko at oracle.com>; Antoine Chambille <ach at quartetfs.com> 
Cc: "Concurrency-interest at cs.oswego.edu" <Concurrency-interest at cs.oswego.edu> 
Sent: Tuesday, September 11, 2012 5:57 PM
Subject: Re: [concurrency-interest] Establishing memory fences with volatile
 

 
In the non-null return case, R3 precedes W1 in sync order.? Sync order is consistent with program order, so R2 precedes R3 precedes W1 precedes W2 in sync order.? Which means R2 synchronizes with W2, so R1 happens before W3.? So I think your basic conclusion is correct.
?
The code for read() still needs to be incredible defensive, since it may see wildly inconsistent state.? For example, it may see a counter decrease that?s only incremented by modify().
?
And all of this is on somewhat thin ice, since it depends on the known-buggy Java semantics of data races.? It?s an interesting example, in that it shows that discarded volatile loads can?t be eliminated.
?
Solution 2 doesn?t have well-defined semantics, so who knows?
?
Solution 3 doesn?t have a corresponding happens-before relationship, so I don?t believe it?s correct, though it may work on most implementations.
?
Hans
?
From:concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of oleksandr otenko
Sent: Tuesday, September 11, 2012 9:45 AM
To: Antoine Chambille
Cc: Concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Establishing memory fences with volatile
?
But you haven't explained how you reset the "write lock" flag back.


Surely it is just a delta that covers the whole range of the datastructure, so not very difficult to add a condition check on the path of delta.contains(i).


Alex


On 11/09/2012 16:28, Antoine Chambille wrote: 
Hello.
?
To implement lock-free multiversion data structures we try to establish memory fences with the help of volatiles. Maybe you read about those experiments in a previous thread titled "[Volatile Store, Normal Store] ordering for multi-version data stuctures".
?
There is a piece of shared data that several readers access, and it is not atomic. A writer decides to close access to this shared data, and once the access is closed it writes modifications to the shared data, that none of the readers should "see". The danger is a reader reads modified data ?without realizing the access was closed.
?
?
We propose the following design:
?
[SOLUTION 1]
?
[SHARED]
data;
volatile v1 = false;
volatile v2;
?
[WRITER]
#W1 ? v1 = true; // volatile store of v1
#W2 ? v2; // volatile load of v2
#W3 ? modify(data);
?
[READER]
#R1 ? d = read(data);
#R2 ? v2 = something; // volatile store of v2
#R3 ? if(v1) {return null;} else {return d;} // volatile load of v1
?
We hope we do not miss a flaw, and believe the strong "happens before" semantics of the Java Memory Model make it work.
?
?
?
Now we wonder if we can have the same for less. Using ordered puts instead of volatile writes for instance. Are we right to think it provides the same ordering guarantee?
?
[SOLUTION 2]
?
[SHARED]
data;
volatile v1 = false;
volatile v2;
?
[WRITER]
#W1 ? UNSAFE.putOrdered(v1, true); // ordered put of v1
#W2 ? v2; // volatile load of v2
#W3 ? modify(data);
?
[READER]
#R1 ? d = read(data);
#R2 ? UNSAFE.putOrdered(v2, something); // ordered put of v2
#R3 ? if(v1) {return null;} else {return d;} // volatile load of v1
?
?
?
?
Finally are we allowed to reason purely about the non-reordering constraints of the JMM ("roach motels") and rely on the following solution that does not involve any volatile write by the readers?
?
[SOLUTION 3]
?
[SHARED]
data;
volatile v1 = false;
?
[WRITER]
#W1 ? v1 = true; // volatile store of v1
#W2 ? v1; // volatile load
#W3 ? modify(data)
?
[READER]
#R1 ? d = readVolatile(data); // volatile loads
#R2 ? if(v1) {return null;} else {return d;} // volatile load of v1
?
On the writer side, the modification of the data cannot be reordered with the above volatile load, that itself cannot be reordered with the previous volatile store. On the reader side the volatile reads in the data cannot be reordered with the volatile load of v1. So it is not possible for the reader to read modified data without knowing about it.
?
?
?
Thanks for reading,
?
Antoine CHAMBILLE
Quartet FS



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/76df1a40/attachment.html>

From dl at cs.oswego.edu  Wed Sep 12 09:42:27 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 12 Sep 2012 09:42:27 -0400
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
Message-ID: <50509143.7040403@cs.oswego.edu>

On 09/11/12 11:28, Antoine Chambille wrote:
> Hello.
>
> To implement lock-free multiversion data structures we try to establish memory
> fences with the help of volatiles. Maybe you read about those experiments in a
> previous thread titled "[Volatile Store, Normal Store] ordering for
> multi-version data stuctures".

The need for a non-roach-motel-reorderable volatile read or fence
is coming up with increasing frequency. (Among other things, this
issue is also holding up the proposed StampedLock API, which, if
it existed, you might be able to use here.) I'm renewing efforts
find some way to support it in upcoming JDK/j.u.c.
Even though Java had a 10+ year head start in defining memory
models and control vs C/C++, the recent C11/C++11 specs include
better ordering control support for people developing new
concurrent/parallel algorithms. Reviving the Fences API or something
like it may help.

In the mean time, as Hans Boehm noted, the only tactics actually
spec'ed to prohibit reorderings with non-volatile reads
involve a volatile write/CAS by readers -- your Solution 1 and variants.
Hans's MSPC paper last June
(http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html)
measured the performance effects of a RW lock based on this
approach and they are not very good.

The slightly weakened version in your Solution 2 is not
guaranteed/recommended since ordered/lazy writes can
themselves be reordered downward. The idea of performing all
"plain" non-volatile data reads using forced-volatile
Unsafe.getXVolatile does seem OK even though there's no
public spec on this.

There are some other tricks that happen to have the right effect
on some VMs/platforms, but none are actually spec'ed to work.
So for the moment, you are probably stuck with something like
your solution 1.

-Doug

From dl at cs.oswego.edu  Wed Sep 12 09:53:10 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 12 Sep 2012 09:53:10 -0400
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
Message-ID: <505093C6.6080309@cs.oswego.edu>

On 09/12/12 04:28, Antoine Chambille wrote:

>  This is precisely what keeps confusing me with java concurrency. I
> have seen several times the following JVM rules stated:
>  ...
>   - A volatile write cannot be reordered with a volatile write
>  ...

These rules form a conservative approximation of the JMM. My JSR133
cookbook for compiler writers discusses such rules, because
they provides a relatively simple way to ensure conformance without
compiler developers needing to figure out the consequences of the
full model in every situation. But programmers cannot rely on
compiler writers only using this recommended scheme. Which
sadly makes it much harder to prove the validity of some constructions.

-Doug




From ach at quartetfs.com  Wed Sep 12 10:40:24 2012
From: ach at quartetfs.com (Antoine Chambille)
Date: Wed, 12 Sep 2012 16:40:24 +0200
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <505093C6.6080309@cs.oswego.edu>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
Message-ID: <CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>

Doug, thank you for taking the time to explain. I think I got it.

Now I understand that the ordering rules you propose in the jsr133 cookbook
are sufficient to implement a JVM but not necessary. One cannot in theory
rely on them.

Solution 1 officially works. But is costly.
Solution 2 is totally broken. putOrdered() does not provide the
putVolatile() ordering guarantees. (is there an official specification of
putOrdered/lazySet somewhere?)
Solution 3 expects too much from the JMM and will only work on 100% of the
JVMs. ;)

I think we'll go with solution 1 and increase the quantity of data read in
a read transaction, to amortize the volatile stores.

You referenced the seqlock article by Hans and that was a great read, too
bad it ends up with "you can't do it well in java". I really hope you'll
manage enriching memory ordering control for the upcoming JDK. Can we help
by voting or registering interest somewhere? Oh and when you mention the
upcoming JDK are we still talking about JDK8?


Thanks again,

-Antoine




On 12 September 2012 15:53, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/12/12 04:28, Antoine Chambille wrote:
>
>   This is precisely what keeps confusing me with java concurrency. I
>> have seen several times the following JVM rules stated:
>>  ...
>>
>>   - A volatile write cannot be reordered with a volatile write
>>  ...
>>
>
> These rules form a conservative approximation of the JMM. My JSR133
> cookbook for compiler writers discusses such rules, because
> they provides a relatively simple way to ensure conformance without
> compiler developers needing to figure out the consequences of the
> full model in every situation. But programmers cannot rely on
> compiler writers only using this recommended scheme. Which
> sadly makes it much harder to prove the validity of some constructions.
>
> -Doug
>
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>



-- 
Antoine CHAMBILLE
R&D Director
Quartet FS
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/92b02a61/attachment.html>

From vitalyd at gmail.com  Wed Sep 12 10:49:50 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Wed, 12 Sep 2012 10:49:50 -0400
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
Message-ID: <CAHjP37FUaDqXPdssVViVgDSedhC0X98LXo72FA9G_8cjAXX3bQ@mail.gmail.com>

lazySet/putOrdered is basically a StoreStore barrier; it only orders the
lazy/ordered write with prior writes, but says/does nothing about
subsequent writes or any loads.  There's, unfortunately, not enough fine
grained control for the times you need it, at the moment.

Sent from my phone
On Sep 12, 2012 10:44 AM, "Antoine Chambille" <ach at quartetfs.com> wrote:

> Doug, thank you for taking the time to explain. I think I got it.
>
> Now I understand that the ordering rules you propose in the jsr133
> cookbook are sufficient to implement a JVM but not necessary. One cannot in
> theory rely on them.
>
> Solution 1 officially works. But is costly.
> Solution 2 is totally broken. putOrdered() does not provide the
> putVolatile() ordering guarantees. (is there an official specification of
> putOrdered/lazySet somewhere?)
> Solution 3 expects too much from the JMM and will only work on 100% of the
> JVMs. ;)
>
> I think we'll go with solution 1 and increase the quantity of data read in
> a read transaction, to amortize the volatile stores.
>
> You referenced the seqlock article by Hans and that was a great read, too
> bad it ends up with "you can't do it well in java". I really hope you'll
> manage enriching memory ordering control for the upcoming JDK. Can we help
> by voting or registering interest somewhere? Oh and when you mention the
> upcoming JDK are we still talking about JDK8?
>
>
> Thanks again,
>
> -Antoine
>
>
>
>
> On 12 September 2012 15:53, Doug Lea <dl at cs.oswego.edu> wrote:
>
>> On 09/12/12 04:28, Antoine Chambille wrote:
>>
>>   This is precisely what keeps confusing me with java concurrency. I
>>> have seen several times the following JVM rules stated:
>>>  ...
>>>
>>>   - A volatile write cannot be reordered with a volatile write
>>>  ...
>>>
>>
>> These rules form a conservative approximation of the JMM. My JSR133
>> cookbook for compiler writers discusses such rules, because
>> they provides a relatively simple way to ensure conformance without
>> compiler developers needing to figure out the consequences of the
>> full model in every situation. But programmers cannot rely on
>> compiler writers only using this recommended scheme. Which
>> sadly makes it much harder to prove the validity of some constructions.
>>
>> -Doug
>>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>
>
>
> --
> Antoine CHAMBILLE
> R&D Director
> Quartet FS
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120912/d5df27f9/attachment.html>

From zhong.j.yu at gmail.com  Wed Sep 12 11:06:06 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 12 Sep 2012 10:06:06 -0500
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <1347454844.50491.YahooMailNeo@web120301.mail.ne1.yahoo.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<1347454844.50491.YahooMailNeo@web120301.mail.ne1.yahoo.com>
Message-ID: <CACuKZqE5o39REejoCUvwu-Hi5GbOjW-iFa_OP8msyG_qtJbQOQ@mail.gmail.com>

If you have something like this

    volatile X[] ar = ...;

    write(i, x)
        local = ar;
        local[i] = x;  // w
        ar = local;

    read(i)
        local = ar;
        return local[i];  // r

An execution may not have hb(w, r), then w and r are in data race. The
data race is benign if X is immutable (primitive included).

If X is mutable, the program is incorrect, reader can see a partially
constructed object. AtomicReferenceArray can be used instead to make
array elements volatile.

Zhong Yu

On Wed, Sep 12, 2012 at 8:00 AM, Andy Nuss <andrew_nuss at yahoo.com> wrote:
> Hans,
>
> I am using volatiles alot in my own lockfree algorithms.  Mostly as
> references to arrays.  The updater does this to the volatile array member:
>
> ar = ar;
>
> And the reader just gets a local reference to the volatile member and uses
> it.
>
> What do you mean by "known buggy behavior for data races"?  What do I have
> to watchout for?
>
> Thanks,
> Andy
>
> ________________________________
> From: "Boehm, Hans" <hans.boehm at hp.com>
> To: oleksandr otenko <oleksandr.otenko at oracle.com>; Antoine Chambille
> <ach at quartetfs.com>
> Cc: "Concurrency-interest at cs.oswego.edu"
> <Concurrency-interest at cs.oswego.edu>
> Sent: Tuesday, September 11, 2012 5:57 PM
>
> Subject: Re: [concurrency-interest] Establishing memory fences with volatile
>
> In the non-null return case, R3 precedes W1 in sync order.  Sync order is
> consistent with program order, so R2 precedes R3 precedes W1 precedes W2 in
> sync order.  Which means R2 synchronizes with W2, so R1 happens before W3.
> So I think your basic conclusion is correct.
>
> The code for read() still needs to be incredible defensive, since it may see
> wildly inconsistent state.  For example, it may see a counter decrease
> that?s only incremented by modify().
>
> And all of this is on somewhat thin ice, since it depends on the known-buggy
> Java semantics of data races.  It?s an interesting example, in that it shows
> that discarded volatile loads can?t be eliminated.
>
> Solution 2 doesn?t have well-defined semantics, so who knows?
>
> Solution 3 doesn?t have a corresponding happens-before relationship, so I
> don?t believe it?s correct, though it may work on most implementations.
>
> Hans
>
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of oleksandr
> otenko
> Sent: Tuesday, September 11, 2012 9:45 AM
> To: Antoine Chambille
> Cc: Concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Establishing memory fences with volatile
>
> But you haven't explained how you reset the "write lock" flag back.
>
>
> Surely it is just a delta that covers the whole range of the datastructure,
> so not very difficult to add a condition check on the path of
> delta.contains(i).
>
>
> Alex
>
>
> On 11/09/2012 16:28, Antoine Chambille wrote:
> Hello.
>
> To implement lock-free multiversion data structures we try to establish
> memory fences with the help of volatiles. Maybe you read about those
> experiments in a previous thread titled "[Volatile Store, Normal Store]
> ordering for multi-version data stuctures".
>
> There is a piece of shared data that several readers access, and it is not
> atomic. A writer decides to close access to this shared data, and once the
> access is closed it writes modifications to the shared data, that none of
> the readers should "see". The danger is a reader reads modified data
> without realizing the access was closed.
>
>
> We propose the following design:
>
> [SOLUTION 1]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   v2 = something; // volatile store of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
> We hope we do not miss a flaw, and believe the strong "happens before"
> semantics of the Java Memory Model make it work.
>
>
>
> Now we wonder if we can have the same for less. Using ordered puts instead
> of volatile writes for instance. Are we right to think it provides the same
> ordering guarantee?
>
> [SOLUTION 2]
>
> [SHARED]
> data;
> volatile v1 = false;
> volatile v2;
>
> [WRITER]
> #W1   UNSAFE.putOrdered(v1, true); // ordered put of v1
> #W2   v2; // volatile load of v2
> #W3   modify(data);
>
> [READER]
> #R1   d = read(data);
> #R2   UNSAFE.putOrdered(v2, something); // ordered put of v2
> #R3   if(v1) {return null;} else {return d;} // volatile load of v1
>
>
>
>
> Finally are we allowed to reason purely about the non-reordering constraints
> of the JMM ("roach motels") and rely on the following solution that does not
> involve any volatile write by the readers?
>
> [SOLUTION 3]
>
> [SHARED]
> data;
> volatile v1 = false;
>
> [WRITER]
> #W1   v1 = true; // volatile store of v1
> #W2   v1; // volatile load
> #W3   modify(data)
>
> [READER]
> #R1   d = readVolatile(data); // volatile loads
> #R2   if(v1) {return null;} else {return d;} // volatile load of v1
>
> On the writer side, the modification of the data cannot be reordered with
> the above volatile load, that itself cannot be reordered with the previous
> volatile store. On the reader side the volatile reads in the data cannot be
> reordered with the volatile load of v1. So it is not possible for the reader
> to read modified data without knowing about it.
>
>
>
> Thanks for reading,
>
> Antoine CHAMBILLE
> Quartet FS
>
>
>
> _______________________________________________
>
> Concurrency-interest mailing list
>
> Concurrency-interest at cs.oswego.edu
>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From hans.boehm at hp.com  Thu Sep 13 01:50:03 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Thu, 13 Sep 2012 05:50:03 +0000
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235F713EA@G9W0750.americas.hpqcorp.net>

To make this slightly more concrete still, in solution 3, since there is no write to v1 in any thread other than WRITER, nothing can synchronize with W2, the read of v1.  Hence W2 has no impact on happens-before, and a compiler with whole program knowledge can safely delete W2, breaking the code.  That's probably not really going to happen, but ...

As Doug already pointed out, solution 2 seems much more likely to really get compiled to incorrect code.  Looking at it again, the most likely Itanium translation, for example, seems to result in incorrect code.

Hans


From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Antoine Chambille
Sent: Wednesday, September 12, 2012 7:40 AM
To: Doug Lea
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Establishing memory fences with volatile

Doug, thank you for taking the time to explain. I think I got it.

Now I understand that the ordering rules you propose in the jsr133 cookbook are sufficient to implement a JVM but not necessary. One cannot in theory rely on them.

Solution 1 officially works. But is costly.
Solution 2 is totally broken. putOrdered() does not provide the putVolatile() ordering guarantees. (is there an official specification of putOrdered/lazySet somewhere?)
Solution 3 expects too much from the JMM and will only work on 100% of the JVMs. ;)

I think we'll go with solution 1 and increase the quantity of data read in a read transaction, to amortize the volatile stores.

You referenced the seqlock article by Hans and that was a great read, too bad it ends up with "you can't do it well in java". I really hope you'll manage enriching memory ordering control for the upcoming JDK. Can we help by voting or registering interest somewhere? Oh and when you mention the upcoming JDK are we still talking about JDK8?


Thanks again,

-Antoine



On 12 September 2012 15:53, Doug Lea <dl at cs.oswego.edu<mailto:dl at cs.oswego.edu>> wrote:
On 09/12/12 04:28, Antoine Chambille wrote:
 This is precisely what keeps confusing me with java concurrency. I
have seen several times the following JVM rules stated:
 ...

  - A volatile write cannot be reordered with a volatile write
 ...

These rules form a conservative approximation of the JMM. My JSR133
cookbook for compiler writers discusses such rules, because
they provides a relatively simple way to ensure conformance without
compiler developers needing to figure out the consequences of the
full model in every situation. But programmers cannot rely on
compiler writers only using this recommended scheme. Which
sadly makes it much harder to prove the validity of some constructions.

-Doug




_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



--
Antoine CHAMBILLE
R&D Director
Quartet FS

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/b63774d7/attachment.html>

From oleksandr.otenko at oracle.com  Thu Sep 13 04:36:55 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Thu, 13 Sep 2012 09:36:55 +0100
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F713EA@G9W0750.americas.hpqcorp.net>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F713EA@G9W0750.americas.hpqcorp.net>
Message-ID: <50519B27.1060400@oracle.com>

Can you please explain why the elimination of W2 breaks the code? I 
don't understand whether this is something JMM permits, or whether 
that's what the JVM implementations might do (eg some are known to do?)

I don't see which clause in JMM permits a problem with that elimination 
- I thought the whole idea was that any volatile load or store, if 
eliminated, should still behave like it existed - w.r.t. serialization 
of preceding writes and barriers preventing reordering of the loads and 
writes that follow.

So I thought Solution 3 is sound, because the reader consists of 
volatile loads (can't reorder among themselves), and the writer posts v1 
through a volatile store. Any loads and stores in modify(data) can't 
cross the W2, since the optimizer shouldn't eliminate the barriers, 
hence the modification will always be seen after v1==true can be seen by 
the reader.

Alex


On 13/09/2012 06:50, Boehm, Hans wrote:
>
> To make this slightly more concrete still, in solution 3, since there 
> is no write to v1 in any thread other than WRITER, nothing can 
> synchronize with W2, the read of v1.  Hence W2 has no impact on 
> happens-before, and a compiler with whole program knowledge can safely 
> delete W2, breaking the code.  That's probably not really going to 
> happen, but ...
>
> As Doug already pointed out, solution 2 seems much more likely to 
> really get compiled to incorrect code.  Looking at it again, the most 
> likely Itanium translation, for example, seems to result in incorrect 
> code.
>
> Hans
>
> *From:*concurrency-interest-bounces at cs.oswego.edu 
> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
> *Antoine Chambille
> *Sent:* Wednesday, September 12, 2012 7:40 AM
> *To:* Doug Lea
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Establishing memory fences with 
> volatile
>
> Doug, thank you for taking the time to explain. I think I got it.
>
> Now I understand that the ordering rules you propose in the jsr133 
> cookbook are sufficient to implement a JVM but not necessary. One 
> cannot in theory rely on them.
>
> Solution 1 officially works. But is costly.
>
> Solution 2 is totally broken. putOrdered() does not provide the 
> putVolatile() ordering guarantees. (is there an official specification 
> of putOrdered/lazySet somewhere?)
>
> Solution 3 expects too much from the JMM and will only work on 100% of 
> the JVMs. ;)
>
> I think we'll go with solution 1 and increase the quantity of data 
> read in a read transaction, to amortize the volatile stores.
>
> You referenced the seqlock article by Hans and that was a great read, 
> too bad it ends up with "you can't do it well in java". I really hope 
> you'll manage enriching memory ordering control for the upcoming JDK. 
> Can we help by voting or registering interest somewhere? Oh and when 
> you mention the upcoming JDK are we still talking about JDK8?
>
> Thanks again,
>
> -Antoine
>
> On 12 September 2012 15:53, Doug Lea <dl at cs.oswego.edu 
> <mailto:dl at cs.oswego.edu>> wrote:
>
> On 09/12/12 04:28, Antoine Chambille wrote:
>
>      This is precisely what keeps confusing me with java concurrency. I
>     have seen several times the following JVM rules stated:
>
>      ...
>
>
>       - A volatile write cannot be reordered with a volatile write
>
>      ...
>
>
> These rules form a conservative approximation of the JMM. My JSR133
> cookbook for compiler writers discusses such rules, because
> they provides a relatively simple way to ensure conformance without
> compiler developers needing to figure out the consequences of the
> full model in every situation. But programmers cannot rely on
> compiler writers only using this recommended scheme. Which
> sadly makes it much harder to prove the validity of some constructions.
>
> -Doug
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu 
> <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> -- 
> Antoine CHAMBILLE
>
> R&D Director
>
> Quartet FS
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/d6b4af84/attachment-0001.html>

From mojianhao at gmail.com  Thu Sep 13 06:04:34 2012
From: mojianhao at gmail.com (Jianhao Mo)
Date: Thu, 13 Sep 2012 18:04:34 +0800
Subject: [concurrency-interest] UpgradeableRead lock like
	ReaderWriterLockSlim in C#
Message-ID: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>

Hi all,

I wondering Is there any  UpgradeableRead lock in java similar
to ReaderWriterLockSlim in C#
(
http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
).

For now, I try to use two ReentrantReadWriteLock to simulate the
ReaderWriterLockSlim. Is there any better solution?

like these:
*  void readLock() {*
*    this.rw.readLock().lock();*
*  }*
*
*
*  void readUnlock() {*
*    this.rw.readLock().unlock();*
*  }*
*
*
*  void writeLock() {*
*    this.up.writeLock().lock();*
*    this.rw.writeLock().lock();*
*  }*
*
*
*  void writeUnlock() {*
*    this.rw.writeLock().unlock();*
*    this.up.writeLock().unlock();*
*  }*
*
*
*  boolean hasWriteLock() {*
*    return this.rw.isWriteLockedByCurrentThread();*
*  }*
*
*
*  void  UpgradeableReadLock() {*
*    this.up.writeLock().lock();*
*  }*
*
*
*  void Upgrade() {*
*    this.rw.writeLock().lock();*
*  }*
*
*
*  void * *Upgradeable**Unlock() {*
*    if (hasWriteLock()) {*
*      this.rw.writeLock().unlock();*
*    }*
*    this.up.writeLock().unlock();*
*  }*


Regards,

Hal Mo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/5e8a1391/attachment.html>

From oleksandr.otenko at oracle.com  Thu Sep 13 07:07:46 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Thu, 13 Sep 2012 12:07:46 +0100
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <50519B27.1060400@oracle.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F713EA@G9W0750.americas.hpqcorp.net>
	<50519B27.1060400@oracle.com>
Message-ID: <5051BE82.1090007@oracle.com>

As an interesting consequence I consider the following a valid condition 
wait:

shared:

volatile boolean x;
boolean y;

wait loop:

while( x || y );

Despite y being non-volatile, its load cannot leave the loop and must be 
executed on every iteration (cannot be optimized to be read just once 
before the loop), because the barriers between volatile loads of x 
should remain.

I am reasoning like so:

suppose the optimizer unrolled this loop into an infinite sequence of 
loads, barriers, and condition checks:

load x;
loadload
ifne ...
load y;
ifne ...
load x;
loadload
ifne ...
...

suppose a finite number of load x and loadload got reordered and fused:

load x;
loadload
ifne ...
load y;
ifne ...
ifne ...
load y;
ifne ...
ifne ...
load y;
ifne ...
...

now many load y can be reordered and fused.

However, load y still cannot escape the beginning of the loop because of 
the barrier after the first load x and has to be executed only after we 
observe x is true. Because of program order, if y is observed true, we 
have to behave as if x was loaded again, and when we do so, we also need 
to behave as if the barrier remained. So I conclude all load ys after it 
cannot be reordered with the start of the next iteration. (Hence the 
condition that only a finite number of load x and loadload can be 
reordered) Then the loop must be correct by induction.

Alex


On 13/09/2012 09:36, oleksandr otenko wrote:
> Can you please explain why the elimination of W2 breaks the code? I 
> don't understand whether this is something JMM permits, or whether 
> that's what the JVM implementations might do (eg some are known to do?)
>
> I don't see which clause in JMM permits a problem with that 
> elimination - I thought the whole idea was that any volatile load or 
> store, if eliminated, should still behave like it existed - w.r.t. 
> serialization of preceding writes and barriers preventing reordering 
> of the loads and writes that follow.
>
> So I thought Solution 3 is sound, because the reader consists of 
> volatile loads (can't reorder among themselves), and the writer posts 
> v1 through a volatile store. Any loads and stores in modify(data) 
> can't cross the W2, since the optimizer shouldn't eliminate the 
> barriers, hence the modification will always be seen after v1==true 
> can be seen by the reader.
>
> Alex
>
>
> On 13/09/2012 06:50, Boehm, Hans wrote:
>>
>> To make this slightly more concrete still, in solution 3, since there 
>> is no write to v1 in any thread other than WRITER, nothing can 
>> synchronize with W2, the read of v1.  Hence W2 has no impact on 
>> happens-before, and a compiler with whole program knowledge can 
>> safely delete W2, breaking the code.  That's probably not really 
>> going to happen, but ...
>>
>> As Doug already pointed out, solution 2 seems much more likely to 
>> really get compiled to incorrect code.  Looking at it again, the most 
>> likely Itanium translation, for example, seems to result in incorrect 
>> code.
>>
>> Hans
>>
>> *From:*concurrency-interest-bounces at cs.oswego.edu 
>> [mailto:concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of 
>> *Antoine Chambille
>> *Sent:* Wednesday, September 12, 2012 7:40 AM
>> *To:* Doug Lea
>> *Cc:* concurrency-interest at cs.oswego.edu
>> *Subject:* Re: [concurrency-interest] Establishing memory fences with 
>> volatile
>>
>> Doug, thank you for taking the time to explain. I think I got it.
>>
>> Now I understand that the ordering rules you propose in the jsr133 
>> cookbook are sufficient to implement a JVM but not necessary. One 
>> cannot in theory rely on them.
>>
>> Solution 1 officially works. But is costly.
>>
>> Solution 2 is totally broken. putOrdered() does not provide the 
>> putVolatile() ordering guarantees. (is there an official 
>> specification of putOrdered/lazySet somewhere?)
>>
>> Solution 3 expects too much from the JMM and will only work on 100% 
>> of the JVMs. ;)
>>
>> I think we'll go with solution 1 and increase the quantity of data 
>> read in a read transaction, to amortize the volatile stores.
>>
>> You referenced the seqlock article by Hans and that was a great read, 
>> too bad it ends up with "you can't do it well in java". I really hope 
>> you'll manage enriching memory ordering control for the upcoming JDK. 
>> Can we help by voting or registering interest somewhere? Oh and when 
>> you mention the upcoming JDK are we still talking about JDK8?
>>
>> Thanks again,
>>
>> -Antoine
>>
>> On 12 September 2012 15:53, Doug Lea <dl at cs.oswego.edu 
>> <mailto:dl at cs.oswego.edu>> wrote:
>>
>> On 09/12/12 04:28, Antoine Chambille wrote:
>>
>>      This is precisely what keeps confusing me with java concurrency. I
>>     have seen several times the following JVM rules stated:
>>
>>      ...
>>
>>
>>       - A volatile write cannot be reordered with a volatile write
>>
>>      ...
>>
>>
>> These rules form a conservative approximation of the JMM. My JSR133
>> cookbook for compiler writers discusses such rules, because
>> they provides a relatively simple way to ensure conformance without
>> compiler developers needing to figure out the consequences of the
>> full model in every situation. But programmers cannot rely on
>> compiler writers only using this recommended scheme. Which
>> sadly makes it much harder to prove the validity of some constructions.
>>
>> -Doug
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> -- 
>> Antoine CHAMBILLE
>>
>> R&D Director
>>
>> Quartet FS
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/0e28316f/attachment-0001.html>

From dl at cs.oswego.edu  Thu Sep 13 07:58:26 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 13 Sep 2012 07:58:26 -0400
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
Message-ID: <5051CA62.7000605@cs.oswego.edu>

On 09/12/12 10:40, Antoine Chambille wrote:
>  I really hope you'll manage
> enriching memory ordering control for the upcoming JDK. Can we help by voting or
> registering interest somewhere? Oh and when you mention the upcoming JDK are we
> still talking about JDK8?
>

I'm not sure. This requires some coordination among
different JVM vendors/suppliers to support intrinsics
that are not not part of any Java/JDK spec. This
is mostly a matter of finding relatively easy to
implement internal forms (typically in "Unsafe") that, if
supported in a JVM, would allow these JVMs to use our
base j.u.c implementations that call them,
rather than having to figure out some other way to
implement j.u.c stuff.

We had some tentative plans in place when proposing
the Fences API, but never materialized when this wasn't
incorporated in JDK7. It may be possible to revive these,
either in original or updated form.
Some people hate the Fences API, but it may be
better to live with some objections (and to live with
method specs that are as good as possible given known
issues in JMM formal specs) than to cause people
who really need it to get things wrong, create horrible
workarounds, or just give up on using languages running
on JVMs.

-Doug



From gregg at cytetech.com  Thu Sep 13 09:43:06 2012
From: gregg at cytetech.com (Gregg Wonderly)
Date: Thu, 13 Sep 2012 08:43:06 -0500
Subject: [concurrency-interest] Establishing memory fences with volatile
In-Reply-To: <5051CA62.7000605@cs.oswego.edu>
References: <CAJGQDwkdJaRgQRTkVGdv2vYOrsF8oQFdvgLyx9MjHWXfNZHyUQ@mail.gmail.com>
	<504F6A9F.3020608@oracle.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F70C5A@G9W0750.americas.hpqcorp.net>
	<CAJGQDwkrB8j_Ah2LrsLQkPJLHQEVpUCOzWtRKa7ipeWhmF5K4A@mail.gmail.com>
	<505093C6.6080309@cs.oswego.edu>
	<CAJGQDw=Pu+mXH=xnXMPxtHgrhdxj5vB0CBmMJGdT1mvWu78JzA@mail.gmail.com>
	<5051CA62.7000605@cs.oswego.edu>
Message-ID: <5051E2EA.7080604@cytetech.com>

On 9/13/2012 6:58 AM, Doug Lea wrote:
> Some people hate the Fences API, but it may be
> better to live with some objections (and to live with
> method specs that are as good as possible given known
> issues in JMM formal specs) than to cause people
> who really need it to get things wrong, create horrible
> workarounds, or just give up on using languages running
> on JVMs.

Doug, given that some time has passed since the fences discussion last went 
around, and you presented some "defense" of the issues here on the list, do you 
have any new insight into what would be the ultimate implementation to interface 
the language and multi-threading with multi-core/cache management?  The CPU 
vendors have driven a lot of what has happened...

Gregg Wonderly

From vitalyd at gmail.com  Thu Sep 13 10:08:29 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 13 Sep 2012 10:08:29 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
Message-ID: <CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>

Hi Hal,

I've never really found the upgrade feature all that useful in .Net.  Its
main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL you
simply release the read lock and try to acquire the write lock.  Assuming
you have mostly readers (or else why use RRWL?) I don't think the upgrade
feature buys much.  Downgrading is supported though, which seems more
useful.

Perhaps you can elaborate a bit more on why you'd like the upgrade aspect?

Thanks

Sent from my phone
On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:

> Hi all,
>
> I wondering Is there any  UpgradeableRead lock in java similar
> to ReaderWriterLockSlim in C#
> (
> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
> ).
>
> For now, I try to use two ReentrantReadWriteLock to simulate the
> ReaderWriterLockSlim. Is there any better solution?
>
> like these:
> *  void readLock() {*
> *    this.rw.readLock().lock();*
> *  }*
> *
> *
> *  void readUnlock() {*
> *    this.rw.readLock().unlock();*
> *  }*
> *
> *
> *  void writeLock() {*
> *    this.up.writeLock().lock();*
> *    this.rw.writeLock().lock();*
> *  }*
> *
> *
> *  void writeUnlock() {*
> *    this.rw.writeLock().unlock();*
> *    this.up.writeLock().unlock();*
> *  }*
> *
> *
> *  boolean hasWriteLock() {*
> *    return this.rw.isWriteLockedByCurrentThread();*
> *  }*
> *
> *
> *  void  UpgradeableReadLock() {*
> *    this.up.writeLock().lock();*
> *  }*
> *
> *
> *  void Upgrade() {*
> *    this.rw.writeLock().lock();*
> *  }*
> *
> *
> *  void * *Upgradeable**Unlock() {*
> *    if (hasWriteLock()) {*
> *      this.rw.writeLock().unlock();*
> *    }*
> *    this.up.writeLock().unlock();*
> *  }*
>
>
> Regards,
>
> Hal Mo
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/ecf55927/attachment.html>

From stanimir at riflexo.com  Thu Sep 13 11:18:21 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 13 Sep 2012 18:18:21 +0300
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
Message-ID: <CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>

If you release the read lock and then obtain the write lock, you have to
check again the conditions under the write lock as they might have been
altered meanwhile.
With upgrading there is no need since it's guaranteed no other writes have
been messing the state.

Stanimir

On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Hi Hal,
>
> I've never really found the upgrade feature all that useful in .Net.  Its
> main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL you
> simply release the read lock and try to acquire the write lock.  Assuming
> you have mostly readers (or else why use RRWL?) I don't think the upgrade
> feature buys much.  Downgrading is supported though, which seems more
> useful.
>
> Perhaps you can elaborate a bit more on why you'd like the upgrade aspect?
>
> Thanks
>
> Sent from my phone
> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>
>> Hi all,
>>
>> I wondering Is there any  UpgradeableRead lock in java similar
>> to ReaderWriterLockSlim in C#
>> (
>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>> ).
>>
>> For now, I try to use two ReentrantReadWriteLock to simulate the
>> ReaderWriterLockSlim. Is there any better solution?
>>
>> like these:
>> *  void readLock() {*
>> *    this.rw.readLock().lock();*
>> *  }*
>> *
>> *
>> *  void readUnlock() {*
>> *    this.rw.readLock().unlock();*
>> *  }*
>> *
>> *
>> *  void writeLock() {*
>> *    this.up.writeLock().lock();*
>> *    this.rw.writeLock().lock();*
>> *  }*
>> *
>> *
>> *  void writeUnlock() {*
>> *    this.rw.writeLock().unlock();*
>> *    this.up.writeLock().unlock();*
>> *  }*
>> *
>> *
>> *  boolean hasWriteLock() {*
>> *    return this.rw.isWriteLockedByCurrentThread();*
>> *  }*
>> *
>> *
>> *  void  UpgradeableReadLock() {*
>> *    this.up.writeLock().lock();*
>> *  }*
>> *
>> *
>> *  void Upgrade() {*
>> *    this.rw.writeLock().lock();*
>> *  }*
>> *
>> *
>> *  void * *Upgradeable**Unlock() {*
>> *    if (hasWriteLock()) {*
>> *      this.rw.writeLock().unlock();*
>> *    }*
>> *    this.up.writeLock().unlock();*
>> *  }*
>>
>>
>> Regards,
>>
>> Hal Mo
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/eea7f540/attachment.html>

From vitalyd at gmail.com  Thu Sep 13 11:59:15 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 13 Sep 2012 11:59:15 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
Message-ID: <CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>

Yes that's true, but in my experience the double check hasn't bothered me.
In addition, emulating this via a couple of RW locks just to omit the
second check doesn't seem worth it to me.  However, thanks for pointing
that out.

Sent from my phone
On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com> wrote:

> If you release the read lock and then obtain the write lock, you have to
> check again the conditions under the write lock as they might have been
> altered meanwhile.
> With upgrading there is no need since it's guaranteed no other writes have
> been messing the state.
>
> Stanimir
>
> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Hi Hal,
>>
>> I've never really found the upgrade feature all that useful in .Net.  Its
>> main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL you
>> simply release the read lock and try to acquire the write lock.  Assuming
>> you have mostly readers (or else why use RRWL?) I don't think the upgrade
>> feature buys much.  Downgrading is supported though, which seems more
>> useful.
>>
>> Perhaps you can elaborate a bit more on why you'd like the upgrade aspect?
>>
>> Thanks
>>
>> Sent from my phone
>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>
>>> Hi all,
>>>
>>> I wondering Is there any  UpgradeableRead lock in java similar
>>> to ReaderWriterLockSlim in C#
>>> (
>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>> ).
>>>
>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>> ReaderWriterLockSlim. Is there any better solution?
>>>
>>> like these:
>>> *  void readLock() {*
>>> *    this.rw.readLock().lock();*
>>> *  }*
>>> *
>>> *
>>> *  void readUnlock() {*
>>> *    this.rw.readLock().unlock();*
>>> *  }*
>>> *
>>> *
>>> *  void writeLock() {*
>>> *    this.up.writeLock().lock();*
>>> *    this.rw.writeLock().lock();*
>>> *  }*
>>> *
>>> *
>>> *  void writeUnlock() {*
>>> *    this.rw.writeLock().unlock();*
>>> *    this.up.writeLock().unlock();*
>>> *  }*
>>> *
>>> *
>>> *  boolean hasWriteLock() {*
>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>> *  }*
>>> *
>>> *
>>> *  void  UpgradeableReadLock() {*
>>> *    this.up.writeLock().lock();*
>>> *  }*
>>> *
>>> *
>>> *  void Upgrade() {*
>>> *    this.rw.writeLock().lock();*
>>> *  }*
>>> *
>>> *
>>> *  void * *Upgradeable**Unlock() {*
>>> *    if (hasWriteLock()) {*
>>> *      this.rw.writeLock().unlock();*
>>> *    }*
>>> *    this.up.writeLock().unlock();*
>>> *  }*
>>>
>>>
>>> Regards,
>>>
>>> Hal Mo
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/19139dc5/attachment-0001.html>

From stanimir at riflexo.com  Thu Sep 13 12:10:22 2012
From: stanimir at riflexo.com (Stanimir Simeonoff)
Date: Thu, 13 Sep 2012 19:10:22 +0300
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
Message-ID: <CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>

> Yes that's true, but in my experience the double check hasn't bothered
> me.
>
Me either... but you have to know/remember about it. R/W Lock is quite poor
as even the readers have to alter the shared state. I have not checked the
recent source of it but it was (is?) 'hackable' by storing the
Thread.getId() as identifier... the latter can be overridden.

Stanimir

> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
> wrote:
>
>> If you release the read lock and then obtain the write lock, you have to
>> check again the conditions under the write lock as they might have been
>> altered meanwhile.
>> With upgrading there is no need since it's guaranteed no other writes
>> have been messing the state.
>>
>> Stanimir
>>
>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>
>>> Hi Hal,
>>>
>>> I've never really found the upgrade feature all that useful in .Net.
>>> Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL
>>> you simply release the read lock and try to acquire the write lock.
>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>> more useful.
>>>
>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>> aspect?
>>>
>>> Thanks
>>>
>>> Sent from my phone
>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>
>>>> Hi all,
>>>>
>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>> to ReaderWriterLockSlim in C#
>>>> (
>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>> ).
>>>>
>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>
>>>> like these:
>>>> *  void readLock() {*
>>>> *    this.rw.readLock().lock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void readUnlock() {*
>>>> *    this.rw.readLock().unlock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void writeLock() {*
>>>> *    this.up.writeLock().lock();*
>>>> *    this.rw.writeLock().lock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void writeUnlock() {*
>>>> *    this.rw.writeLock().unlock();*
>>>> *    this.up.writeLock().unlock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  boolean hasWriteLock() {*
>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void  UpgradeableReadLock() {*
>>>> *    this.up.writeLock().lock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void Upgrade() {*
>>>> *    this.rw.writeLock().lock();*
>>>> *  }*
>>>> *
>>>> *
>>>> *  void * *Upgradeable**Unlock() {*
>>>> *    if (hasWriteLock()) {*
>>>> *      this.rw.writeLock().unlock();*
>>>> *    }*
>>>> *    this.up.writeLock().unlock();*
>>>> *  }*
>>>>
>>>>
>>>> Regards,
>>>>
>>>> Hal Mo
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/0c2a087c/attachment.html>

From mojianhao at gmail.com  Thu Sep 13 12:25:20 2012
From: mojianhao at gmail.com (Jianhao Mo)
Date: Fri, 14 Sep 2012 00:25:20 +0800
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
	<CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
Message-ID: <CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>

if the read operation is time consuming, would upgrade be worth ?
I am trying to optimize a hadoop namenode which manage 2000+ datanodes.

2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>

>
> Yes that's true, but in my experience the double check hasn't bothered
>> me.
>>
> Me either... but you have to know/remember about it. R/W Lock is quite
> poor as even the readers have to alter the shared state. I have not checked
> the recent source of it but it was (is?) 'hackable' by storing the
> Thread.getId() as identifier... the latter can be overridden.
>
> Stanimir
>
>> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>> wrote:
>>
>>> If you release the read lock and then obtain the write lock, you have to
>>> check again the conditions under the write lock as they might have been
>>> altered meanwhile.
>>> With upgrading there is no need since it's guaranteed no other writes
>>> have been messing the state.
>>>
>>> Stanimir
>>>
>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>>
>>>> Hi Hal,
>>>>
>>>> I've never really found the upgrade feature all that useful in .Net.
>>>> Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL
>>>> you simply release the read lock and try to acquire the write lock.
>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>> more useful.
>>>>
>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>> aspect?
>>>>
>>>> Thanks
>>>>
>>>> Sent from my phone
>>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>>> to ReaderWriterLockSlim in C#
>>>>> (
>>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>>> ).
>>>>>
>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>
>>>>> like these:
>>>>> *  void readLock() {*
>>>>> *    this.rw.readLock().lock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void readUnlock() {*
>>>>> *    this.rw.readLock().unlock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void writeLock() {*
>>>>> *    this.up.writeLock().lock();*
>>>>> *    this.rw.writeLock().lock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void writeUnlock() {*
>>>>> *    this.rw.writeLock().unlock();*
>>>>> *    this.up.writeLock().unlock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  boolean hasWriteLock() {*
>>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void  UpgradeableReadLock() {*
>>>>> *    this.up.writeLock().lock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void Upgrade() {*
>>>>> *    this.rw.writeLock().lock();*
>>>>> *  }*
>>>>> *
>>>>> *
>>>>> *  void * *Upgradeable**Unlock() {*
>>>>> *    if (hasWriteLock()) {*
>>>>> *      this.rw.writeLock().unlock();*
>>>>> *    }*
>>>>> *    this.up.writeLock().unlock();*
>>>>> *  }*
>>>>>
>>>>>
>>>>> Regards,
>>>>>
>>>>> Hal Mo
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120914/09ff5f95/attachment.html>

From andrew_nuss at yahoo.com  Thu Sep 13 14:17:43 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Thu, 13 Sep 2012 11:17:43 -0700 (PDT)
Subject: [concurrency-interest] tryinng to understand gotchas with volatile
	as memory fences, and lock-free algorithms
Message-ID: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>

Hi,

I have to write a bunch of specialized lock-free algorithms, many of which leverage those in the java concurrent package.

I have 2 general approaches in mind that can best be described by a simple hypothetical map, based on an array as follows:

class Map {
??? private volatile Object[]?? ar;

??? Object get (Object key)
??? {
???????? Object[] ar = this.ar;
???????? .... do some index calculating and return ar[index]

??? }

??? put (Object key, Object val);

}

The put function would use a lock-free critical section relative to simultaneous putters to ensure that there is no obvious bug.? The important point is that I am trying to publish the change to the array for the get() function, in such a way that the get() uses only the volatile memory fence, and freely gets its value from some index.? In the critical section, the put() stuffs an element into the array at some index.


At the end the "put" critical section, I do an:

this.ar = this.ar;??? // publishing fence for getters as well as other putters so that they see the element stuffed just prior to this assignment


Wondering under what condition hotspot would ignore the above attempt to "publish" a new immutable object into the array?? The statement sure looks like a nop!


Wondering if it is necessary that hotspot be able to infer even a remote possibility that the "ar" member could ever change from its constructed state?


Finally, wondering about Object elems in the array not having out-of-thin air safety. I.e. despite the publishing fence to see the reference stuffed by the latest writer, a subsequent writer could be changing the Object at the index calculated by a getter(), and the getter() sees main memory in an inconsistent state given for 64-bit object references relative to that index because it pulls the element just before the subsequent writer does the statement this.ar = this.ar.


In some of my cases, the array is just an array of int, so in those cases, there are no out-of-thin-air values on the array seen by the getter, so I assume that the above approach might really work for volatile int[] ar.

I know that I could have my array be an array of AtomicReference, but I was hoping that could be avoided!

Therefore, assuming that the above works for volatile int[] ar, another approach might be a non-volatile array of int indices, and a non-volatile array of Objects, both held in a volatile member reference to a POD object where its 2 (array) fields are final.? The change: putter never overwrites an existing element in the Object[] ar, but just appends one, when a put is really a replace.? The putter then stuffs the index into the int array (out of thin air safety for getters).? The putter publishes his elem changes with this.pod = this.pod, and getters, without needing to do anything but get the volatile pod, are assured of not getting corrupt objects.? Why, because they know that any index they pull from the index array is guaranteed to get them an object that has been set and never reset, and the values in the index array and the object array were published together by this.pod = this.pod.

I sure would like some feedback on the above!

Thanks,
Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/4e72d446/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Sep 13 17:29:11 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 14 Sep 2012 07:29:11 +1000
Subject: [concurrency-interest] tryinng to understand gotchas with
	volatileas memory fences, and lock-free algorithms
In-Reply-To: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>

Andy,

You can never get out-of-thin-air Object references - reference stores are
atomic (64-bit or not).

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andy Nuss
  Sent: Friday, 14 September 2012 4:18 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] tryinng to understand gotchas with
volatileas memory fences, and lock-free algorithms


  Hi,


  I have to write a bunch of specialized lock-free algorithms, many of which
leverage those in the java concurrent package.


  I have 2 general approaches in mind that can best be described by a simple
hypothetical map, based on an array as follows:


  class Map {
      private volatile Object[]   ar;


      Object get (Object key)
      {
           Object[] ar = this.ar;
           .... do some index calculating and return ar[index]

      }


      put (Object key, Object val);

  }


  The put function would use a lock-free critical section relative to
simultaneous putters to ensure that there is no obvious bug.  The important
point is that I am trying to publish the change to the array for the get()
function, in such a way that the get() uses only the volatile memory fence,
and freely gets its value from some index.  In the critical section, the
put() stuffs an element into the array at some index.



  At the end the "put" critical section, I do an:


  this.ar = this.ar;    // publishing fence for getters as well as other
putters so that they see the element stuffed just prior to this assignment



  Wondering under what condition hotspot would ignore the above attempt to
"publish" a new immutable object into the array?  The statement sure looks
like a nop!



  Wondering if it is necessary that hotspot be able to infer even a remote
possibility that the "ar" member could ever change from its constructed
state?



  Finally, wondering about Object elems in the array not having out-of-thin
air safety. I.e. despite the publishing fence to see the reference stuffed
by the latest writer, a subsequent writer could be changing the Object at
the index calculated by a getter(), and the getter() sees main memory in an
inconsistent state given for 64-bit object references relative to that index
because it pulls the element just before the subsequent writer does the
statement this.ar = this.ar.



  In some of my cases, the array is just an array of int, so in those cases,
there are no out-of-thin-air values on the array seen by the getter, so I
assume that the above approach might really work for volatile int[] ar.


  I know that I could have my array be an array of AtomicReference, but I
was hoping that could be avoided!


  Therefore, assuming that the above works for volatile int[] ar, another
approach might be a non-volatile array of int indices, and a non-volatile
array of Objects, both held in a volatile member reference to a POD object
where its 2 (array) fields are final.  The change: putter never overwrites
an existing element in the Object[] ar, but just appends one, when a put is
really a replace.  The putter then stuffs the index into the int array (out
of thin air safety for getters).  The putter publishes his elem changes with
this.pod = this.pod, and getters, without needing to do anything but get the
volatile pod, are assured of not getting corrupt objects.  Why, because they
know that any index they pull from the index array is guaranteed to get them
an object that has been set and never reset, and the values in the index
array and the object array were published together by this.pod = this.pod.


  I sure would like some feedback on the above!


  Thanks,
  Andy








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120914/2a04b6fb/attachment.html>

From andrew_nuss at yahoo.com  Thu Sep 13 18:37:10 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Thu, 13 Sep 2012 15:37:10 -0700 (PDT)
Subject: [concurrency-interest] tryinng to understand gotchas with
	volatileas memory fences, and lock-free algorithms
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
Message-ID: <1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>

David,

Thanks for that clarification, still in the dark somewhat.


First, please note that everything I put into my map is idempotent, meaning that if I have a non-null reference mapped to a certain key, it will behave the same way on all inputs as a more recently put version of that object.? And all the objects are themselves either immutable or in some other way threadsafe in their behaviors.

In that case can I really conclude that the wierd statement, "this.ar = this.ar", at the end of the critical section of any putter will publish the element store to getters, and that the getter merely needs to fetch the volatile array reference and return the element, knowing that if it is non-null it is good enough, regardless of putters changing the element just after the getter fetches the array reference?? I.e. is there any risk that hotspot will nop that wierd statement?


My worries started when I was trying to follow the fencing gotchas being thrown around in some recent threads on this mailing list, and wondered if my approach had a flaw relative to the hotspot compiler.? As well, someone told me that I had to use an array of AtomicReferences.? I conclude that this is recommended not because of out-of-thin air corruption, but because that person didn't know that my objects were all "idempotent" in their behavior for a given key.

By the way, for interest sake, how in the world does hotspot, with the possibility of a 16-gig heap and without paying a fencing cost for each non-volatile reference change, offer the guarantee that even unprotected access of a member variable reference changed and loaded by multiple threads, will never return a corrupt reference?? Was this always the case?? I seem to recall reading an article from Brian Goetz in this IBM forum days that all things that need 64-bits in representation that are shared between threads without appropriate protection semantics are out-of-thin air unsafe.? I know he used "long" as an example.


Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/c954e9bd/attachment.html>

From vitalyd at gmail.com  Thu Sep 13 18:54:43 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 13 Sep 2012 18:54:43 -0400
Subject: [concurrency-interest] tryinng to understand gotchas with
 volatileas memory fences, and lock-free algorithms
In-Reply-To: <1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <CAHjP37FbJoDrEdUBEXaJOw0nk2AMQyHa_5X2ZxAxs7aJgbVg1w@mail.gmail.com>

Hi Andy,

You would only have 64 bit object refs on a 64 bit jvm running on a 64 bit
arch; 64 bit is native word size there so no issue on that end.  The other
possibility is if you were writing a 64 bit value that spanned across cache
line or memory page but since hotspot aligns objects to an 8 byte boundary,
a 64 bit value won't span.

Brian must've been talking about reading larger-than-native values - e.g. a
long on a 32 bit platform.

As for the array store to itself, it's probably safe to assume hotspot will
at least emit a volatile store barrier even if it elides the store itself.

Sent from my phone
On Sep 13, 2012 6:39 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> David,
>
> Thanks for that clarification, still in the dark somewhat.
>
> First, please note that everything I put into my map is idempotent,
> meaning that if I have a non-null reference mapped to a certain key, it
> will behave the same way on all inputs as a more recently put version of
> that object.  And all the objects are themselves either immutable or in
> some other way threadsafe in their behaviors.
>
> In that case can I really conclude that the wierd statement, "this.ar =
> this.ar", at the end of the critical section of any putter will publish
> the element store to getters, and that the getter merely needs to fetch the
> volatile array reference and return the element, knowing that if it is
> non-null it is good enough, regardless of putters changing the element just
> after the getter fetches the array reference?  I.e. is there any risk that
> hotspot will nop that wierd statement?
>
> My worries started when I was trying to follow the fencing gotchas being
> thrown around in some recent threads on this mailing list, and wondered if
> my approach had a flaw relative to the hotspot compiler.  As well, someone
> told me that I had to use an array of AtomicReferences.  I conclude that
> this is recommended not because of out-of-thin air corruption, but because
> that person didn't know that my objects were all "idempotent" in their
> behavior for a given key.
>
> By the way, for interest sake, how in the world does hotspot, with the
> possibility of a 16-gig heap and without paying a fencing cost for each
> non-volatile reference change, offer the guarantee that even unprotected
> access of a member variable reference changed and loaded by multiple
> threads, will never return a corrupt reference?  Was this always the case?
> I seem to recall reading an article from Brian Goetz in this IBM forum days
> that all things that need 64-bits in representation that are shared between
> threads without appropriate protection semantics are out-of-thin air
> unsafe.  I know he used "long" as an example.
>
> Andy
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/ff21464b/attachment-0001.html>

From jacyg at alumni.rice.edu  Thu Sep 13 19:05:55 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Thu, 13 Sep 2012 18:05:55 -0500
Subject: [concurrency-interest] tryinng to understand gotchas with
 volatileas memory fences, and lock-free algorithms
In-Reply-To: <CAHjP37FbJoDrEdUBEXaJOw0nk2AMQyHa_5X2ZxAxs7aJgbVg1w@mail.gmail.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<CAHjP37FbJoDrEdUBEXaJOw0nk2AMQyHa_5X2ZxAxs7aJgbVg1w@mail.gmail.com>
Message-ID: <CAESiqEobdsYF+WTeXrd2gK4e4B39FdHFDo62c4hGjRgW4GhKwQ@mail.gmail.com>

http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.7
Read-writes for Object ref are always atomic, as are volatile
long/double.  Non-volatile long/double can be 32bit writes.

j

On Thu, Sep 13, 2012 at 5:54 PM, Vitaly Davidovich <vitalyd at gmail.com> wrote:
> Hi Andy,
>
> You would only have 64 bit object refs on a 64 bit jvm running on a 64 bit
> arch; 64 bit is native word size there so no issue on that end.  The other
> possibility is if you were writing a 64 bit value that spanned across cache
> line or memory page but since hotspot aligns objects to an 8 byte boundary,
> a 64 bit value won't span.
>
> Brian must've been talking about reading larger-than-native values - e.g. a
> long on a 32 bit platform.
>
> As for the array store to itself, it's probably safe to assume hotspot will
> at least emit a volatile store barrier even if it elides the store itself.
>
> Sent from my phone
>
> On Sep 13, 2012 6:39 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:
>>
>> David,
>>
>> Thanks for that clarification, still in the dark somewhat.
>>
>> First, please note that everything I put into my map is idempotent,
>> meaning that if I have a non-null reference mapped to a certain key, it will
>> behave the same way on all inputs as a more recently put version of that
>> object.  And all the objects are themselves either immutable or in some
>> other way threadsafe in their behaviors.
>>
>> In that case can I really conclude that the wierd statement, "this.ar =
>> this.ar", at the end of the critical section of any putter will publish the
>> element store to getters, and that the getter merely needs to fetch the
>> volatile array reference and return the element, knowing that if it is
>> non-null it is good enough, regardless of putters changing the element just
>> after the getter fetches the array reference?  I.e. is there any risk that
>> hotspot will nop that wierd statement?
>>
>> My worries started when I was trying to follow the fencing gotchas being
>> thrown around in some recent threads on this mailing list, and wondered if
>> my approach had a flaw relative to the hotspot compiler.  As well, someone
>> told me that I had to use an array of AtomicReferences.  I conclude that
>> this is recommended not because of out-of-thin air corruption, but because
>> that person didn't know that my objects were all "idempotent" in their
>> behavior for a given key.
>>
>> By the way, for interest sake, how in the world does hotspot, with the
>> possibility of a 16-gig heap and without paying a fencing cost for each
>> non-volatile reference change, offer the guarantee that even unprotected
>> access of a member variable reference changed and loaded by multiple
>> threads, will never return a corrupt reference?  Was this always the case?
>> I seem to recall reading an article from Brian Goetz in this IBM forum days
>> that all things that need 64-bits in representation that are shared between
>> threads without appropriate protection semantics are out-of-thin air unsafe.
>> I know he used "long" as an example.
>>
>> Andy
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From nathan.reynolds at oracle.com  Thu Sep 13 19:08:17 2012
From: nathan.reynolds at oracle.com (Nathan Reynolds)
Date: Thu, 13 Sep 2012 16:08:17 -0700
Subject: [concurrency-interest] tryinng to understand gotchas with
 volatileas memory fences, and lock-free algorithms
In-Reply-To: <1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <50526761.3050909@oracle.com>

 > How in the world does hotspot, with the possibility of a 16-gig heap 
and without paying a fencing cost for each non-volatile reference 
change, offer the guarantee that even unprotected access of a member 
variable reference changed and loaded by multiple threads, will never 
return a corrupt reference?  Was this always the case?

I think you are asking if word tearing can happen.  This is where a 
reader can see part of the word of the old value and part of the word 
from the new value.  This will never happen for any primitive data type 
or reference.  All of the processors ensure this (this wasn't the case 
many many years ago).  So, either readers will see the old value or the 
new value.  They can not see a mix of the two.

When GC is moving objects around, it has to ensure that either the 
threads will read/write to the old location or read/write to the new 
location.  There can't be a mixture of reads/writes to both locations 
concurrently.  I believe this is guaranteed by pausing all of the Java 
threads so that the changes are done "atomically" as far as the Java 
threads can witness.

On the other hand, longs and 64-bit references were a problem up until a 
while ago.  A reader could see the upper 32-bits from the old value and 
the lower 32-bits from the new value.  You could force the JVM to ensure 
this couldn't happen by declaring the long or reference as a volatile.  
Then it would be forced to use an atomic instruction to do the update.  
Now a days, the JVM uses non-atomic 64-bit instructions to ensure word 
tearing can't happen.

What you have to be worried about is updates to 2 different fields or 
elements in the array.  The reader could see the old value for one 
location and the new value for the other location.

I don't know if HotSpot will turn "this.ar = this.ar" into a nop. The 
best way to find out is write a toy test.  Run the test with the -server 
option and with assembly printing (Google for instructions).  Have a 
thread execute a loop with this in it 10,000+ times.  Then, have the 
thread sleep 10 ms and repeat.  The sleep gives JIT a chance to optimize 
the code.  When JIT optimizes the loop, it will print the assembly.  You 
can then see if this line was turned into a nop.  My guess is that it 
won't.  I have put a volatile read in a loop and HotSpot didn't turn it 
into a nop.  So, I wouldn't see why it would turn this weird statement 
into a nop.

The publishing will happen eventually regardless of the weird statement 
(fence statement).  However, if the readers don't access this.ar, then 
they aren't guaranteed to see the updates.  They might see the updates, 
though.

Nathan Reynolds 
<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds> | 
Consulting Member of Technical Staff | 602.333.9091
Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
On 9/13/2012 3:37 PM, Andy Nuss wrote:
> David,
>
> Thanks for that clarification, still in the dark somewhat.
>
> First, please note that everything I put into my map is idempotent, 
> meaning that if I have a non-null reference mapped to a certain key, 
> it will behave the same way on all inputs as a more recently put 
> version of that object.  And all the objects are themselves either 
> immutable or in some other way threadsafe in their behaviors.
>
> In that case can I really conclude that the wierd statement, "this.ar 
> = this.ar", at the end of the critical section of any putter will 
> publish the element store to getters, and that the getter merely needs 
> to fetch the volatile array reference and return the element, knowing 
> that if it is non-null it is good enough, regardless of putters 
> changing the element just after the getter fetches the array 
> reference?  I.e. is there any risk that hotspot will nop that wierd 
> statement?
>
> My worries started when I was trying to follow the fencing gotchas 
> being thrown around in some recent threads on this mailing list, and 
> wondered if my approach had a flaw relative to the hotspot compiler.  
> As well, someone told me that I had to use an array of 
> AtomicReferences.  I conclude that this is recommended not because of 
> out-of-thin air corruption, but because that person didn't know that 
> my objects were all "idempotent" in their behavior for a given key.
>
> By the way, for interest sake, how in the world does hotspot, with the 
> possibility of a 16-gig heap and without paying a fencing cost for 
> each non-volatile reference change, offer the guarantee that even 
> unprotected access of a member variable reference changed and loaded 
> by multiple threads, will never return a corrupt reference?  Was this 
> always the case?  I seem to recall reading an article from Brian Goetz 
> in this IBM forum days that all things that need 64-bits in 
> representation that are shared between threads without appropriate 
> protection semantics are out-of-thin air unsafe.  I know he used 
> "long" as an example.
>
> Andy
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/6f2f5900/attachment.html>

From andrew_nuss at yahoo.com  Thu Sep 13 20:52:32 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Thu, 13 Sep 2012 17:52:32 -0700 (PDT)
Subject: [concurrency-interest] tryinng to understand gotchas with
	volatileas memory fences, and lock-free algorithms
In-Reply-To: <50526761.3050909@oracle.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<50526761.3050909@oracle.com>
Message-ID: <1347583952.85906.YahooMailNeo@web120301.mail.ne1.yahoo.com>

Thanks Nathan and all you guys.? I guess I've been both told that this.ar = this.ar will emit a fence, but that due diligence requires that I make sure with seeing the assembly code generated by hotspot.? Thanks for pointing out that getters that get the volatile array reference can see old values and new values in the array.? I have accounted for that in this case, but have to be super careful going forwards.

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/acde5563/attachment.html>

From davidcholmes at aapt.net.au  Thu Sep 13 22:02:19 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 14 Sep 2012 12:02:19 +1000
Subject: [concurrency-interest] tryinng to understand gotchas with
	volatileas memory fences, and lock-free algorithms
In-Reply-To: <50526761.3050909@oracle.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMENIJGAA.davidcholmes@aapt.net.au>

Just to clarify something:

> On the other hand, longs and 64-bit references were a problem up until a
while ago.
> A reader could see the upper 32-bits from the old value and the lower
32-bits from
> the new value.  You could force the JVM to ensure this couldn't happen by
declaring
> the long or reference as a volatile.  Then it would be forced to use an
atomic
> instruction to do the update.  Now a days, the JVM uses non-atomic 64-bit
instructions
> to ensure word tearing can't happen.

Word-tearing for long and double on a 32-bit system is allowed and can
happen unless they are declared volatile. Even a 64-bit system isn't
required to provide atomic access to non-volatile long and double.

Word-tearing of references has never been an issue - as Vitaly stated
references are always the size of the natural machine word and are aligned
correctly for atomic accesses

All of this is modulo the occasional bug of course.

David

  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Nathan
Reynolds
  Sent: Friday, 14 September 2012 9:08 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] tryinng to understand gotchas with
volatileas memory fences, and lock-free algorithms


  > How in the world does hotspot, with the possibility of a 16-gig heap and
without paying a fencing cost for each non-volatile reference change, offer
the guarantee that even unprotected access of a member variable reference
changed and loaded by multiple threads, will never return a corrupt
reference?  Was this always the case?

  I think you are asking if word tearing can happen.  This is where a reader
can see part of the word of the old value and part of the word from the new
value.  This will never happen for any primitive data type or reference.
All of the processors ensure this (this wasn't the case many many years
ago).  So, either readers will see the old value or the new value.  They can
not see a mix of the two.

  When GC is moving objects around, it has to ensure that either the threads
will read/write to the old location or read/write to the new location.
There can't be a mixture of reads/writes to both locations concurrently.  I
believe this is guaranteed by pausing all of the Java threads so that the
changes are done "atomically" as far as the Java threads can witness.

  On the other hand, longs and 64-bit references were a problem up until a
while ago.  A reader could see the upper 32-bits from the old value and the
lower 32-bits from the new value.  You could force the JVM to ensure this
couldn't happen by declaring the long or reference as a volatile.  Then it
would be forced to use an atomic instruction to do the update.  Now a days,
the JVM uses non-atomic 64-bit instructions to ensure word tearing can't
happen.

  What you have to be worried about is updates to 2 different fields or
elements in the array.  The reader could see the old value for one location
and the new value for the other location.

  I don't know if HotSpot will turn "this.ar = this.ar" into a nop.  The
best way to find out is write a toy test.  Run the test with the -server
option and with assembly printing (Google for instructions).  Have a thread
execute a loop with this in it 10,000+ times.  Then, have the thread sleep
10 ms and repeat.  The sleep gives JIT a chance to optimize the code.  When
JIT optimizes the loop, it will print the assembly.  You can then see if
this line was turned into a nop.  My guess is that it won't.  I have put a
volatile read in a loop and HotSpot didn't turn it into a nop.  So, I
wouldn't see why it would turn this weird statement into a nop.

  The publishing will happen eventually regardless of the weird statement
(fence statement).  However, if the readers don't access this.ar, then they
aren't guaranteed to see the updates.  They might see the updates, though.


  Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
  Oracle PSR Engineering | Server Technology

  On 9/13/2012 3:37 PM, Andy Nuss wrote:

    David,


    Thanks for that clarification, still in the dark somewhat.



    First, please note that everything I put into my map is idempotent,
meaning that if I have a non-null reference mapped to a certain key, it will
behave the same way on all inputs as a more recently put version of that
object.  And all the objects are themselves either immutable or in some
other way threadsafe in their behaviors.


    In that case can I really conclude that the wierd statement, "this.ar =
this.ar", at the end of the critical section of any putter will publish the
element store to getters, and that the getter merely needs to fetch the
volatile array reference and return the element, knowing that if it is
non-null it is good enough, regardless of putters changing the element just
after the getter fetches the array reference?  I.e. is there any risk that
hotspot will nop that wierd statement?



    My worries started when I was trying to follow the fencing gotchas being
thrown around in some recent threads on this mailing list, and wondered if
my approach had a flaw relative to the hotspot compiler.  As well, someone
told me that I had to use an array of AtomicReferences.  I conclude that
this is recommended not because of out-of-thin air corruption, but because
that person didn't know that my objects were all "idempotent" in their
behavior for a given key.


    By the way, for interest sake, how in the world does hotspot, with the
possibility of a 16-gig heap and without paying a fencing cost for each
non-volatile reference change, offer the guarantee that even unprotected
access of a member variable reference changed and loaded by multiple
threads, will never return a corrupt reference?  Was this always the case?
I seem to recall reading an article from Brian Goetz in this IBM forum days
that all things that need 64-bits in representation that are shared between
threads without appropriate protection semantics are out-of-thin air unsafe.
I know he used "long" as an example.


    Andy






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120914/ecace879/attachment-0001.html>

From vitalyd at gmail.com  Thu Sep 13 22:04:52 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 13 Sep 2012 22:04:52 -0400
Subject: [concurrency-interest] tryinng to understand gotchas with
 volatileas memory fences, and lock-free algorithms
In-Reply-To: <50526761.3050909@oracle.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<50526761.3050909@oracle.com>
Message-ID: <CAHjP37EkDhsbageEJN7GAJ0d6Xuuwi=HRYQPpS9KPQkacXqYXQ@mail.gmail.com>

Processors (that allow unaligned reads) only ensure this if the location
meets certain alignment requirements, doesn't exceed bus width, doesn't
cross cache line boundary, and doesn't cross page boundary.  If those
criteria aren't met, a write may not be atomic (if it's otherwise
unsychronized) and tear.  Compilers typically ensure that data is aligned
appropriate to the target architecture (+ unaligned stores/loads are
usually much slower than aligned ones, although some recent processor
models reduce the penalty) so mostly not an issue.

Sent from my phone
On Sep 13, 2012 8:41 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

>  > How in the world does hotspot, with the possibility of a 16-gig heap
> and without paying a fencing cost for each non-volatile reference change,
> offer the guarantee that even unprotected access of a member variable
> reference changed and loaded by multiple threads, will never return a
> corrupt reference?  Was this always the case?
>
> I think you are asking if word tearing can happen.  This is where a reader
> can see part of the word of the old value and part of the word from the new
> value.  This will never happen for any primitive data type or reference.
> All of the processors ensure this (this wasn't the case many many years
> ago).  So, either readers will see the old value or the new value.  They
> can not see a mix of the two.
>
> When GC is moving objects around, it has to ensure that either the threads
> will read/write to the old location or read/write to the new location.
> There can't be a mixture of reads/writes to both locations concurrently.  I
> believe this is guaranteed by pausing all of the Java threads so that the
> changes are done "atomically" as far as the Java threads can witness.
>
> On the other hand, longs and 64-bit references were a problem up until a
> while ago.  A reader could see the upper 32-bits from the old value and the
> lower 32-bits from the new value.  You could force the JVM to ensure this
> couldn't happen by declaring the long or reference as a volatile.  Then it
> would be forced to use an atomic instruction to do the update.  Now a days,
> the JVM uses non-atomic 64-bit instructions to ensure word tearing can't
> happen.
>
> What you have to be worried about is updates to 2 different fields or
> elements in the array.  The reader could see the old value for one location
> and the new value for the other location.
>
> I don't know if HotSpot will turn "this.ar = this.ar" into a nop.  The
> best way to find out is write a toy test.  Run the test with the -server
> option and with assembly printing (Google for instructions).  Have a thread
> execute a loop with this in it 10,000+ times.  Then, have the thread sleep
> 10 ms and repeat.  The sleep gives JIT a chance to optimize the code.  When
> JIT optimizes the loop, it will print the assembly.  You can then see if
> this line was turned into a nop.  My guess is that it won't.  I have put a
> volatile read in a loop and HotSpot didn't turn it into a nop.  So, I
> wouldn't see why it would turn this weird statement into a nop.
>
> The publishing will happen eventually regardless of the weird statement
> (fence statement).  However, if the readers don't access this.ar, then
> they aren't guaranteed to see the updates.  They might see the updates,
> though.
>
>  Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>  On 9/13/2012 3:37 PM, Andy Nuss wrote:
>
>  David,
>
>  Thanks for that clarification, still in the dark somewhat.
>
>  First, please note that everything I put into my map is idempotent,
> meaning that if I have a non-null reference mapped to a certain key, it
> will behave the same way on all inputs as a more recently put version of
> that object.  And all the objects are themselves either immutable or in
> some other way threadsafe in their behaviors.
>
>  In that case can I really conclude that the wierd statement, "this.ar =
> this.ar", at the end of the critical section of any putter will publish
> the element store to getters, and that the getter merely needs to fetch the
> volatile array reference and return the element, knowing that if it is
> non-null it is good enough, regardless of putters changing the element just
> after the getter fetches the array reference?  I.e. is there any risk that
> hotspot will nop that wierd statement?
>
>  My worries started when I was trying to follow the fencing gotchas being
> thrown around in some recent threads on this mailing list, and wondered if
> my approach had a flaw relative to the hotspot compiler.  As well, someone
> told me that I had to use an array of AtomicReferences.  I conclude that
> this is recommended not because of out-of-thin air corruption, but because
> that person didn't know that my objects were all "idempotent" in their
> behavior for a given key.
>
>  By the way, for interest sake, how in the world does hotspot, with the
> possibility of a 16-gig heap and without paying a fencing cost for each
> non-volatile reference change, offer the guarantee that even unprotected
> access of a member variable reference changed and loaded by multiple
> threads, will never return a corrupt reference?  Was this always the case?
> I seem to recall reading an article from Brian Goetz in this IBM forum days
> that all things that need 64-bits in representation that are shared between
> threads without appropriate protection semantics are out-of-thin air
> unsafe.  I know he used "long" as an example.
>
> Andy
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/1cb5d538/attachment.html>

From andrew_nuss at yahoo.com  Thu Sep 13 22:28:59 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Thu, 13 Sep 2012 19:28:59 -0700 (PDT)
Subject: [concurrency-interest] tryinng to understand gotchas with
	volatileas memory fences, and lock-free algorithms
In-Reply-To: <CAHjP37EkDhsbageEJN7GAJ0d6Xuuwi=HRYQPpS9KPQkacXqYXQ@mail.gmail.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<50526761.3050909@oracle.com>
	<CAHjP37EkDhsbageEJN7GAJ0d6Xuuwi=HRYQPpS9KPQkacXqYXQ@mail.gmail.com>
Message-ID: <1347589739.56891.YahooMailNeo@web120302.mail.ne1.yahoo.com>

Vitaly,

I assume that in the context of what David Holmes said, the hotspot compiler is guaranteed at least in intent never to tear 64-bit references.? You were speaking of other compilers, not the certified hotspot compilers?? Maybe the writers of the java concurrent package could say whether they have relied on the memory model for impossibility of reference tearing?? Then I would feel really comfortable.

Andy



________________________________
 From: Vitaly Davidovich <vitalyd at gmail.com>
To: Nathan Reynolds <nathan.reynolds at oracle.com> 
Cc: concurrency-interest at cs.oswego.edu 
Sent: Thursday, September 13, 2012 7:04 PM
Subject: Re: [concurrency-interest] tryinng to understand gotchas with volatileas memory fences, and lock-free algorithms
 

Processors (that allow unaligned reads) only ensure this if the location meets certain alignment requirements, doesn't exceed bus width, doesn't cross cache line boundary, and doesn't cross page boundary.? If those criteria aren't met, a write may not be atomic (if it's otherwise unsychronized) and tear.? Compilers typically ensure that data is aligned appropriate to the target architecture (+ unaligned stores/loads are usually much slower than aligned ones, although some recent processor models reduce the penalty) so mostly not an issue.
Sent from my phone
On Sep 13, 2012 8:41 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com> wrote:

> How in the world does hotspot, with the possibility of a 16-gig heap and without paying a fencing cost for each non-volatile reference change, offer the guarantee that even unprotected access of a member variable reference changed and loaded by multiple threads, will never return a corrupt reference?? Was this always the case?
>
>I think you are asking if word tearing can happen.? This is where
      a reader can see part of the word of the old value and part of the
      word from the new value.? This will never happen for any primitive
      data type or reference.? All of the processors ensure this (this
      wasn't the case many many years ago).? So, either readers will see
      the old value or the new value.? They can not see a mix of the
      two.
>
>When GC is moving objects around, it has to ensure that either the
      threads will read/write to the old location or read/write to the
      new location.? There can't be a mixture of reads/writes to both
      locations concurrently.? I believe this is guaranteed by pausing
      all of the Java threads so that the changes are done "atomically"
      as far as the Java threads can witness.
>
>On the other hand, longs and 64-bit references were a problem up
      until a while ago.? A reader could see the upper 32-bits from the
      old value and the lower 32-bits from the new value.? You could
      force the JVM to ensure this couldn't happen by declaring the long
      or reference as a volatile.? Then it would be forced to use an
      atomic instruction to do the update.? Now a days, the JVM uses
      non-atomic 64-bit instructions to ensure word tearing can't
      happen.
>
>What you have to be worried about is updates to 2 different fields
      or elements in the array.? The reader could see the old value for
      one location and the new value for the other location.
>
>I don't know if HotSpot will turn "this.ar = this.ar" into a nop.? The best way to find out is write a toy test.? Run the test with the -server option and with assembly printing (Google for instructions).? Have a thread execute a loop with this in it 10,000+ times.? Then, have the thread sleep 10 ms and repeat.? The sleep gives JIT a chance to optimize the code.? When JIT optimizes the loop, it will print the assembly.? You can then see if this line was turned into a nop.? My guess is that it won't.? I have put a volatile read in a loop and HotSpot didn't turn it into a nop.? So, I wouldn't see why it would turn this weird statement into a nop.
>
>The publishing will happen eventually regardless of the weird
      statement (fence statement).? However, if the readers don't access this.ar, then they aren't guaranteed to see the updates.? They might see the updates, though.
>
>
>Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
>Oracle PSR Engineering | Server Technology
>
On 9/13/2012 3:37 PM, Andy Nuss wrote:
>
>David,
>>
>>
>>Thanks for that clarification, still in the dark somewhat.
>>
>>
>>
>>First, please note that everything I put into my map is idempotent, meaning that if I have a non-null reference mapped to a certain key, it will behave the same way on all inputs as a more recently put version of that object.? And all the objects are themselves either immutable or in some other way threadsafe in their behaviors.
>>
>>
>>In that case can I really conclude that the wierd statement, "this.ar = this.ar", at the end of the critical section of any putter will publish the element store to getters, and that the getter merely needs to fetch the volatile array reference and return the element, knowing that if it is non-null it is good enough, regardless of putters changing the element just after the getter fetches the array reference?? I.e. is there any risk that hotspot will nop that wierd statement?
>>
>>
>>
>>My worries started when I was trying to follow the fencing gotchas being thrown around in some recent threads on this mailing list, and wondered if my approach had a flaw relative to the hotspot compiler.? As well, someone told me that I had to use an array of AtomicReferences.? I conclude that this is recommended not because of out-of-thin air corruption, but because that person didn't know that my objects were all "idempotent" in their behavior for a given key.
>>
>>
>>By the way, for interest sake, how in the world does hotspot, with the possibility of a 16-gig heap and without paying a fencing cost for each non-volatile reference change, offer the guarantee that even unprotected access of a member variable reference changed and loaded by multiple threads, will never return a corrupt reference?? Was this always the case?? I seem to recall reading an article from Brian Goetz in this IBM forum days that all things that need 64-bits in representation that are shared between threads without appropriate protection semantics are out-of-thin air unsafe.? I know he used "long" as an example.
>>
>>
>>Andy
>>
>>
>>
>>
>>_______________________________________________
Concurrency-interest mailing list Concurrency-interest at cs.oswego.edu http://cs.oswego.edu/mailman/listinfo/concurrency-interest 
>
>_______________________________________________
>Concurrency-interest mailing list
>Concurrency-interest at cs.oswego.edu
>http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/d611e2d1/attachment-0001.html>

From davidcholmes at aapt.net.au  Thu Sep 13 22:39:54 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 14 Sep 2012 12:39:54 +1000
Subject: [concurrency-interest] tryinng to understand gotchas
	withvolatileas memory fences, and lock-free algorithms
In-Reply-To: <1347589739.56891.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKENJJGAA.davidcholmes@aapt.net.au>

Yes we rely on the correct implementation of Java language semantics (atomic
accesses and no word-tearing for references and 32-bit primitives, and
volatile long & double) and the Java Memory Model.

Comfortable now? :)

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andy Nuss
  Sent: Friday, 14 September 2012 12:29 PM
  To: Vitaly Davidovich
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] tryinng to understand gotchas
withvolatileas memory fences, and lock-free algorithms


  Vitaly,


  I assume that in the context of what David Holmes said, the hotspot
compiler is guaranteed at least in intent never to tear 64-bit references.
You were speaking of other compilers, not the certified hotspot compilers?
Maybe the writers of the java concurrent package could say whether they have
relied on the memory model for impossibility of reference tearing?  Then I
would feel really comfortable.


  Andy





----------------------------------------------------------------------------
--
  From: Vitaly Davidovich <vitalyd at gmail.com>
  To: Nathan Reynolds <nathan.reynolds at oracle.com>
  Cc: concurrency-interest at cs.oswego.edu
  Sent: Thursday, September 13, 2012 7:04 PM
  Subject: Re: [concurrency-interest] tryinng to understand gotchas with
volatileas memory fences, and lock-free algorithms



  Processors (that allow unaligned reads) only ensure this if the location
meets certain alignment requirements, doesn't exceed bus width, doesn't
cross cache line boundary, and doesn't cross page boundary.  If those
criteria aren't met, a write may not be atomic (if it's otherwise
unsychronized) and tear.  Compilers typically ensure that data is aligned
appropriate to the target architecture (+ unaligned stores/loads are usually
much slower than aligned ones, although some recent processor models reduce
the penalty) so mostly not an issue.
  Sent from my phone
  On Sep 13, 2012 8:41 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
wrote:

    > How in the world does hotspot, with the possibility of a 16-gig heap
and without paying a fencing cost for each non-volatile reference change,
offer the guarantee that even unprotected access of a member variable
reference changed and loaded by multiple threads, will never return a
corrupt reference?  Was this always the case?

    I think you are asking if word tearing can happen.  This is where a
reader can see part of the word of the old value and part of the word from
the new value.  This will never happen for any primitive data type or
reference.  All of the processors ensure this (this wasn't the case many
many years ago).  So, either readers will see the old value or the new
value.  They can not see a mix of the two.

    When GC is moving objects around, it has to ensure that either the
threads will read/write to the old location or read/write to the new
location.  There can't be a mixture of reads/writes to both locations
concurrently.  I believe this is guaranteed by pausing all of the Java
threads so that the changes are done "atomically" as far as the Java threads
can witness.

    On the other hand, longs and 64-bit references were a problem up until a
while ago.  A reader could see the upper 32-bits from the old value and the
lower 32-bits from the new value.  You could force the JVM to ensure this
couldn't happen by declaring the long or reference as a volatile.  Then it
would be forced to use an atomic instruction to do the update.  Now a days,
the JVM uses non-atomic 64-bit instructions to ensure word tearing can't
happen.

    What you have to be worried about is updates to 2 different fields or
elements in the array.  The reader could see the old value for one location
and the new value for the other location.

    I don't know if HotSpot will turn "this.ar = this.ar" into a nop.  The
best way to find out is write a toy test.  Run the test with the -server
option and with assembly printing (Google for instructions).  Have a thread
execute a loop with this in it 10,000+ times.  Then, have the thread sleep
10 ms and repeat.  The sleep gives JIT a chance to optimize the code.  When
JIT optimizes the loop, it will print the assembly.  You can then see if
this line was turned into a nop.  My guess is that it won't.  I have put a
volatile read in a loop and HotSpot didn't turn it into a nop.  So, I
wouldn't see why it would turn this weird statement into a nop.

    The publishing will happen eventually regardless of the weird statement
(fence statement).  However, if the readers don't access this.ar, then they
aren't guaranteed to see the updates.  They might see the updates, though.


    Nathan Reynolds | Consulting Member of Technical Staff | 602.333.9091
    Oracle PSR Engineering | Server Technology

    On 9/13/2012 3:37 PM, Andy Nuss wrote:

      David,


      Thanks for that clarification, still in the dark somewhat.



      First, please note that everything I put into my map is idempotent,
meaning that if I have a non-null reference mapped to a certain key, it will
behave the same way on all inputs as a more recently put version of that
object.  And all the objects are themselves either immutable or in some
other way threadsafe in their behaviors.


      In that case can I really conclude that the wierd statement, "this.ar
= this.ar", at the end of the critical section of any putter will publish
the element store to getters, and that the getter merely needs to fetch the
volatile array reference and return the element, knowing that if it is
non-null it is good enough, regardless of putters changing the element just
after the getter fetches the array reference?  I.e. is there any risk that
hotspot will nop that wierd statement?



      My worries started when I was trying to follow the fencing gotchas
being thrown around in some recent threads on this mailing list, and
wondered if my approach had a flaw relative to the hotspot compiler.  As
well, someone told me that I had to use an array of AtomicReferences.  I
conclude that this is recommended not because of out-of-thin air corruption,
but because that person didn't know that my objects were all "idempotent" in
their behavior for a given key.


      By the way, for interest sake, how in the world does hotspot, with the
possibility of a 16-gig heap and without paying a fencing cost for each
non-volatile reference change, offer the guarantee that even unprotected
access of a member variable reference changed and loaded by multiple
threads, will never return a corrupt reference?  Was this always the case?
I seem to recall reading an article from Brian Goetz in this IBM forum days
that all things that need 64-bits in representation that are shared between
threads without appropriate protection semantics are out-of-thin air unsafe.
I know he used "long" as an example.


      Andy






_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



    _______________________________________________
    Concurrency-interest mailing list
    Concurrency-interest at cs.oswego.edu
    http://cs.oswego.edu/mailman/listinfo/concurrency-interest



  _______________________________________________
  Concurrency-interest mailing list
  Concurrency-interest at cs.oswego.edu
  http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120914/53f4688b/attachment.html>

From vitalyd at gmail.com  Thu Sep 13 22:55:59 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Thu, 13 Sep 2012 22:55:59 -0400
Subject: [concurrency-interest] tryinng to understand gotchas with
 volatileas memory fences, and lock-free algorithms
In-Reply-To: <1347589739.56891.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1347560263.85870.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<NFBBKALFDCPFIDBNKAPCOENGJGAA.davidcholmes@aapt.net.au>
	<1347575830.6663.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<50526761.3050909@oracle.com>
	<CAHjP37EkDhsbageEJN7GAJ0d6Xuuwi=HRYQPpS9KPQkacXqYXQ@mail.gmail.com>
	<1347589739.56891.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <CAHjP37HnaMrc7OB262uAF=oTx5mFjZRo78Nf5bN7=RRqgKibOA@mail.gmail.com>

Yup, I was talking in general - I see David has tried to put you at ease
with respect to hotspot. :)

Cheers

Sent from my phone
On Sep 13, 2012 10:29 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> Vitaly,
>
> I assume that in the context of what David Holmes said, the hotspot
> compiler is guaranteed at least in intent never to tear 64-bit references.
> You were speaking of other compilers, not the certified hotspot compilers?
> Maybe the writers of the java concurrent package could say whether they
> have relied on the memory model for impossibility of reference tearing?
> Then I would feel really comfortable.
>
> Andy
>
>
>   ------------------------------
> *From:* Vitaly Davidovich <vitalyd at gmail.com>
> *To:* Nathan Reynolds <nathan.reynolds at oracle.com>
> *Cc:* concurrency-interest at cs.oswego.edu
> *Sent:* Thursday, September 13, 2012 7:04 PM
> *Subject:* Re: [concurrency-interest] tryinng to understand gotchas with
> volatileas memory fences, and lock-free algorithms
>
> Processors (that allow unaligned reads) only ensure this if the location
> meets certain alignment requirements, doesn't exceed bus width, doesn't
> cross cache line boundary, and doesn't cross page boundary.  If those
> criteria aren't met, a write may not be atomic (if it's otherwise
> unsychronized) and tear.  Compilers typically ensure that data is aligned
> appropriate to the target architecture (+ unaligned stores/loads are
> usually much slower than aligned ones, although some recent processor
> models reduce the penalty) so mostly not an issue.
> Sent from my phone
> On Sep 13, 2012 8:41 PM, "Nathan Reynolds" <nathan.reynolds at oracle.com>
> wrote:
>
>  > How in the world does hotspot, with the possibility of a 16-gig heap
> and without paying a fencing cost for each non-volatile reference change,
> offer the guarantee that even unprotected access of a member variable
> reference changed and loaded by multiple threads, will never return a
> corrupt reference?  Was this always the case?
>
> I think you are asking if word tearing can happen.  This is where a reader
> can see part of the word of the old value and part of the word from the new
> value.  This will never happen for any primitive data type or reference.
> All of the processors ensure this (this wasn't the case many many years
> ago).  So, either readers will see the old value or the new value.  They
> can not see a mix of the two.
>
> When GC is moving objects around, it has to ensure that either the threads
> will read/write to the old location or read/write to the new location.
> There can't be a mixture of reads/writes to both locations concurrently.  I
> believe this is guaranteed by pausing all of the Java threads so that the
> changes are done "atomically" as far as the Java threads can witness.
>
> On the other hand, longs and 64-bit references were a problem up until a
> while ago.  A reader could see the upper 32-bits from the old value and the
> lower 32-bits from the new value.  You could force the JVM to ensure this
> couldn't happen by declaring the long or reference as a volatile.  Then it
> would be forced to use an atomic instruction to do the update.  Now a days,
> the JVM uses non-atomic 64-bit instructions to ensure word tearing can't
> happen.
>
> What you have to be worried about is updates to 2 different fields or
> elements in the array.  The reader could see the old value for one location
> and the new value for the other location.
>
> I don't know if HotSpot will turn "this.ar = this.ar" into a nop.  The
> best way to find out is write a toy test.  Run the test with the -server
> option and with assembly printing (Google for instructions).  Have a thread
> execute a loop with this in it 10,000+ times.  Then, have the thread sleep
> 10 ms and repeat.  The sleep gives JIT a chance to optimize the code.  When
> JIT optimizes the loop, it will print the assembly.  You can then see if
> this line was turned into a nop.  My guess is that it won't.  I have put a
> volatile read in a loop and HotSpot didn't turn it into a nop.  So, I
> wouldn't see why it would turn this weird statement into a nop.
>
> The publishing will happen eventually regardless of the weird statement
> (fence statement).  However, if the readers don't access this.ar, then
> they aren't guaranteed to see the updates.  They might see the updates,
> though.
>
>  Nathan Reynolds<http://psr.us.oracle.com/wiki/index.php/User:Nathan_Reynolds>| Consulting Member of Technical Staff |
> 602.333.9091
> Oracle PSR Engineering <http://psr.us.oracle.com/> | Server Technology
>  On 9/13/2012 3:37 PM, Andy Nuss wrote:
>
>  David,
>
>  Thanks for that clarification, still in the dark somewhat.
>
>  First, please note that everything I put into my map is idempotent,
> meaning that if I have a non-null reference mapped to a certain key, it
> will behave the same way on all inputs as a more recently put version of
> that object.  And all the objects are themselves either immutable or in
> some other way threadsafe in their behaviors.
>
>  In that case can I really conclude that the wierd statement, "this.ar =
> this.ar", at the end of the critical section of any putter will publish
> the element store to getters, and that the getter merely needs to fetch the
> volatile array reference and return the element, knowing that if it is
> non-null it is good enough, regardless of putters changing the element just
> after the getter fetches the array reference?  I.e. is there any risk that
> hotspot will nop that wierd statement?
>
>  My worries started when I was trying to follow the fencing gotchas being
> thrown around in some recent threads on this mailing list, and wondered if
> my approach had a flaw relative to the hotspot compiler.  As well, someone
> told me that I had to use an array of AtomicReferences.  I conclude that
> this is recommended not because of out-of-thin air corruption, but because
> that person didn't know that my objects were all "idempotent" in their
> behavior for a given key.
>
>  By the way, for interest sake, how in the world does hotspot, with the
> possibility of a 16-gig heap and without paying a fencing cost for each
> non-volatile reference change, offer the guarantee that even unprotected
> access of a member variable reference changed and loaded by multiple
> threads, will never return a corrupt reference?  Was this always the case?
> I seem to recall reading an article from Brian Goetz in this IBM forum days
> that all things that need 64-bits in representation that are shared between
> threads without appropriate protection semantics are out-of-thin air
> unsafe.  I know he used "long" as an example.
>
> Andy
>
>
>
> _______________________________________________
> Concurrency-interest mailing listConcurrency-interest at cs.oswego.eduhttp://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120913/43961f11/attachment-0001.html>

From vitalyd at gmail.com  Fri Sep 14 08:36:09 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Fri, 14 Sep 2012 08:36:09 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
	<CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
	<CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>
Message-ID: <CAHjP37HiAATaNzWZwsrXZ9JocBVSH71RbO4UFm+H1=oCrG45wg@mail.gmail.com>

Do you mean if the double check after acquiring the write lock is expensive?

If you had .NET's rw lock, it would only allow one thread to be in
upgradeable mode - are all of your threads possible writers? If so,
wouldn't you get lock contention?

Maybe you can provide a bit more detail on what you're trying to do and
perhaps a better approach will emerge.

Vitaly

Sent from my phone
On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:

> if the read operation is time consuming, would upgrade be worth ?
> I am trying to optimize a hadoop namenode which manage 2000+ datanodes.
>
> 2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>
>
>>
>> Yes that's true, but in my experience the double check hasn't bothered
>>> me.
>>>
>> Me either... but you have to know/remember about it. R/W Lock is quite
>> poor as even the readers have to alter the shared state. I have not checked
>> the recent source of it but it was (is?) 'hackable' by storing the
>> Thread.getId() as identifier... the latter can be overridden.
>>
>> Stanimir
>>
>>> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>>> wrote:
>>>
>>>> If you release the read lock and then obtain the write lock, you have
>>>> to check again the conditions under the write lock as they might have been
>>>> altered meanwhile.
>>>> With upgrading there is no need since it's guaranteed no other writes
>>>> have been messing the state.
>>>>
>>>> Stanimir
>>>>
>>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>>>
>>>>> Hi Hal,
>>>>>
>>>>> I've never really found the upgrade feature all that useful in .Net.
>>>>> Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL
>>>>> you simply release the read lock and try to acquire the write lock.
>>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>>> more useful.
>>>>>
>>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>>> aspect?
>>>>>
>>>>> Thanks
>>>>>
>>>>> Sent from my phone
>>>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>>>> to ReaderWriterLockSlim in C#
>>>>>> (
>>>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>>>> ).
>>>>>>
>>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>>
>>>>>> like these:
>>>>>> *  void readLock() {*
>>>>>> *    this.rw.readLock().lock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void readUnlock() {*
>>>>>> *    this.rw.readLock().unlock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void writeLock() {*
>>>>>> *    this.up.writeLock().lock();*
>>>>>> *    this.rw.writeLock().lock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void writeUnlock() {*
>>>>>> *    this.rw.writeLock().unlock();*
>>>>>> *    this.up.writeLock().unlock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  boolean hasWriteLock() {*
>>>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void  UpgradeableReadLock() {*
>>>>>> *    this.up.writeLock().lock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void Upgrade() {*
>>>>>> *    this.rw.writeLock().lock();*
>>>>>> *  }*
>>>>>> *
>>>>>> *
>>>>>> *  void * *Upgradeable**Unlock() {*
>>>>>> *    if (hasWriteLock()) {*
>>>>>> *      this.rw.writeLock().unlock();*
>>>>>> *    }*
>>>>>> *    this.up.writeLock().unlock();*
>>>>>> *  }*
>>>>>>
>>>>>>
>>>>>> Regards,
>>>>>>
>>>>>> Hal Mo
>>>>>>
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>>
>>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120914/3c0d6530/attachment.html>

From mojianhao at gmail.com  Sun Sep 16 21:51:52 2012
From: mojianhao at gmail.com (Jianhao Mo)
Date: Mon, 17 Sep 2012 09:51:52 +0800
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAHjP37HiAATaNzWZwsrXZ9JocBVSH71RbO4UFm+H1=oCrG45wg@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
	<CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
	<CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>
	<CAHjP37HiAATaNzWZwsrXZ9JocBVSH71RbO4UFm+H1=oCrG45wg@mail.gmail.com>
Message-ID: <CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>

Yes, there is lock contention.
Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490

On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:

> Do you mean if the double check after acquiring the write lock is
> expensive?
>
> If you had .NET's rw lock, it would only allow one thread to be in
> upgradeable mode - are all of your threads possible writers? If so,
> wouldn't you get lock contention?
>
> Maybe you can provide a bit more detail on what you're trying to do and
> perhaps a better approach will emerge.
>
> Vitaly
>
> Sent from my phone
> On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>
>> if the read operation is time consuming, would upgrade be worth ?
>> I am trying to optimize a hadoop namenode which manage 2000+ datanodes.
>>
>> 2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>
>>
>>>
>>> Yes that's true, but in my experience the double check hasn't bothered
>>>> me.
>>>>
>>> Me either... but you have to know/remember about it. R/W Lock is quite
>>> poor as even the readers have to alter the shared state. I have not checked
>>> the recent source of it but it was (is?) 'hackable' by storing the
>>> Thread.getId() as identifier... the latter can be overridden.
>>>
>>> Stanimir
>>>
>>>> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>>>> wrote:
>>>>
>>>>> If you release the read lock and then obtain the write lock, you have
>>>>> to check again the conditions under the write lock as they might have been
>>>>> altered meanwhile.
>>>>> With upgrading there is no need since it's guaranteed no other writes
>>>>> have been messing the state.
>>>>>
>>>>> Stanimir
>>>>>
>>>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>>>>>
>>>>>> Hi Hal,
>>>>>>
>>>>>> I've never really found the upgrade feature all that useful in .Net.
>>>>>> Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL
>>>>>> you simply release the read lock and try to acquire the write lock.
>>>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>>>> more useful.
>>>>>>
>>>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>>>> aspect?
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> Sent from my phone
>>>>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>>>
>>>>>>> Hi all,
>>>>>>>
>>>>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>>>>> to ReaderWriterLockSlim in C#
>>>>>>> (
>>>>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>>>>> ).
>>>>>>>
>>>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>>>
>>>>>>> like these:
>>>>>>> *  void readLock() {*
>>>>>>> *    this.rw.readLock().lock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void readUnlock() {*
>>>>>>> *    this.rw.readLock().unlock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void writeLock() {*
>>>>>>> *    this.up.writeLock().lock();*
>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void writeUnlock() {*
>>>>>>> *    this.rw.writeLock().unlock();*
>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  boolean hasWriteLock() {*
>>>>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void  UpgradeableReadLock() {*
>>>>>>> *    this.up.writeLock().lock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void Upgrade() {*
>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>> *  }*
>>>>>>> *
>>>>>>> *
>>>>>>> *  void * *Upgradeable**Unlock() {*
>>>>>>> *    if (hasWriteLock()) {*
>>>>>>> *      this.rw.writeLock().unlock();*
>>>>>>> *    }*
>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>> *  }*
>>>>>>>
>>>>>>>
>>>>>>> Regards,
>>>>>>>
>>>>>>> Hal Mo
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>
>>>>>>
>>>>>
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/b60b2caf/attachment.html>

From jacyg at alumni.rice.edu  Sun Sep 16 23:05:55 2012
From: jacyg at alumni.rice.edu (Jacy Odin Grannis)
Date: Sun, 16 Sep 2012 22:05:55 -0500
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
	<CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
	<CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>
	<CAHjP37HiAATaNzWZwsrXZ9JocBVSH71RbO4UFm+H1=oCrG45wg@mail.gmail.com>
	<CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
Message-ID: <CAESiqEqKKP0EQTx5Pt7tyLMyBGHN7yrd_F4Y589WUhUcBd93VA@mail.gmail.com>

If I had to guess at why writes now take longer, it would be because
you've made it considerably more difficult to acquire the write lock
than it used to be.  Assuming that upgradeable events happen with some
regularity, you first run into contention between upgradeable reads
and writes...but then once a write has managed to get lock1, it now
has to start waiting on lock2 and contend with any readers currently
active.  Contrast that with before, where it would basically go
through a single round of contention to get in and do the write.

So...I see a couple possible options.

1.  Change writeLock to do a readLock on lock1 (still a write lock on
lock2 of course).  This could bias against upgradeableReads, where the
throughput on those operations would drop; but it should boost
writeLock performance.  You can counter that bias by making lock1
fair, and preserve some throughput by keeping lock2 unfair.  This
makes sense if most writes are of the writeLock variety rather than
the upgradeable variety.  The main issue I could see is that it means
you can not do an upgradeable read while under write lock, but I'm not
sure if that would be an issue for your usage or not.  Given that
you're encapsulating all this anyway, you could probably do some
bookkeeping inside the FSNamesystemLock class to do the right thing
and preserve flexibility, depends on need/perf hit for doing said
bookkeeping.

2.  Use a single RWLock, but on what you consider to be "upgradeable"
writes, do read part first under read lock, than redo full read/write
under write lock if you determine a write is needed.  Makes the most
sense if the case for wanting upgrade feature is because most of them
result in zero updates (your description doesn't really get to the
ratio of "no updates" vs "few updates", just notes that both exist).

I think option 1 is probably the one that will make you happiest; but
option 2 is worth keeping in mind...if the majority of upgradeable
reads never end up upgrading, it could very easily be worth taking the
time to redo the read a second time for the few you do have to
"upgrade".

Hope that helps,

jacy

On Sun, Sep 16, 2012 at 8:51 PM, Jianhao Mo <mojianhao at gmail.com> wrote:
> Yes, there is lock contention.
> Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>
>
> On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>
> wrote:
>>
>> Do you mean if the double check after acquiring the write lock is
>> expensive?
>>
>> If you had .NET's rw lock, it would only allow one thread to be in
>> upgradeable mode - are all of your threads possible writers? If so, wouldn't
>> you get lock contention?
>>
>> Maybe you can provide a bit more detail on what you're trying to do and
>> perhaps a better approach will emerge.
>>
>> Vitaly
>>
>> Sent from my phone
>>
>> On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>
>>> if the read operation is time consuming, would upgrade be worth ?
>>> I am trying to optimize a hadoop namenode which manage 2000+ datanodes.
>>>
>>> 2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>
>>>>
>>>>
>>>>> Yes that's true, but in my experience the double check hasn't bothered
>>>>> me.
>>>>
>>>> Me either... but you have to know/remember about it. R/W Lock is quite
>>>> poor as even the readers have to alter the shared state. I have not checked
>>>> the recent source of it but it was (is?) 'hackable' by storing the
>>>> Thread.getId() as identifier... the latter can be overridden.
>>>>
>>>> Stanimir
>>>>>
>>>>> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>>>>> wrote:
>>>>>>
>>>>>> If you release the read lock and then obtain the write lock, you have
>>>>>> to check again the conditions under the write lock as they might have been
>>>>>> altered meanwhile.
>>>>>> With upgrading there is no need since it's guaranteed no other writes
>>>>>> have been messing the state.
>>>>>>
>>>>>> Stanimir
>>>>>>
>>>>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com>
>>>>>> wrote:
>>>>>>>
>>>>>>> Hi Hal,
>>>>>>>
>>>>>>> I've never really found the upgrade feature all that useful in .Net.
>>>>>>> Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's RRWL
>>>>>>> you simply release the read lock and try to acquire the write lock.
>>>>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>>>>> more useful.
>>>>>>>
>>>>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>>>>> aspect?
>>>>>>>
>>>>>>> Thanks
>>>>>>>
>>>>>>> Sent from my phone
>>>>>>>
>>>>>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>>>>>
>>>>>>>> Hi all,
>>>>>>>>
>>>>>>>> I wondering Is there any  UpgradeableRead lock in java similar to
>>>>>>>> ReaderWriterLockSlim in C#
>>>>>>>>
>>>>>>>> (http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx).
>>>>>>>>
>>>>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>>>>
>>>>>>>> like these:
>>>>>>>>   void readLock() {
>>>>>>>>     this.rw.readLock().lock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void readUnlock() {
>>>>>>>>     this.rw.readLock().unlock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void writeLock() {
>>>>>>>>     this.up.writeLock().lock();
>>>>>>>>     this.rw.writeLock().lock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void writeUnlock() {
>>>>>>>>     this.rw.writeLock().unlock();
>>>>>>>>     this.up.writeLock().unlock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   boolean hasWriteLock() {
>>>>>>>>     return this.rw.isWriteLockedByCurrentThread();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void  UpgradeableReadLock() {
>>>>>>>>     this.up.writeLock().lock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void Upgrade() {
>>>>>>>>     this.rw.writeLock().lock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>   void  UpgradeableUnlock() {
>>>>>>>>     if (hasWriteLock()) {
>>>>>>>>       this.rw.writeLock().unlock();
>>>>>>>>     }
>>>>>>>>     this.up.writeLock().unlock();
>>>>>>>>   }
>>>>>>>>
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>>
>>>>>>>> Hal Mo
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>
>>>>
>>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From davidcholmes at aapt.net.au  Sun Sep 16 23:25:58 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 17 Sep 2012 13:25:58 +1000
Subject: [concurrency-interest] UpgradeableRead lock like
	ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
Message-ID: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>

I'm going back to the question of what upgrading is supposed to get you? The
problem with upgradeable read locks is establishing semantics that are
generally useful. The simple case is that you want the write to be atomic
with respect to the state seen by the reader - seems reasonable but has a
couple of consequences:
- first you now have to be able to obtain the write lock with a priority
above that of other waiting writers;
- second it only works if you have one upgrader, otherwise the atomicity is
gone.

If upgrading doesn't give you atomicity then it buys you very little over
releasing the read lock and acquiring the write lock.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jianhao Mo
  Sent: Monday, 17 September 2012 11:52 AM
  To: Vitaly Davidovich
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] UpgradeableRead lock like
ReaderWriterLockSlim in C#


  Yes, there is lock contention.
  Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490


  On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

    Do you mean if the double check after acquiring the write lock is
expensive?

    If you had .NET's rw lock, it would only allow one thread to be in
upgradeable mode - are all of your threads possible writers? If so, wouldn't
you get lock contention?

    Maybe you can provide a bit more detail on what you're trying to do and
perhaps a better approach will emerge.

    Vitaly

    Sent from my phone

    On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:

      if the read operation is time consuming, would upgrade be worth ?
      I am trying to optimize a hadoop namenode which manage 2000+
datanodes.


      2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>



          Yes that's true, but in my experience the double check hasn't
bothered me.


        Me either... but you have to know/remember about it. R/W Lock is
quite poor as even the readers have to alter the shared state. I have not
checked the recent source of it but it was (is?) 'hackable' by storing the
Thread.getId() as identifier... the latter can be overridden.

        Stanimir


          On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
<stanimir at riflexo.com> wrote:

            If you release the read lock and then obtain the write lock, you
have to check again the conditions under the write lock as they might have
been altered meanwhile.
            With upgrading there is no need since it's guaranteed no other
writes have been messing the state.

            Stanimir


            On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich
<vitalyd at gmail.com> wrote:

              Hi Hal,

              I've never really found the upgrade feature all that useful in
.Net.  Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's
RRWL you simply release the read lock and try to acquire the write lock.
Assuming you have mostly readers (or else why use RRWL?) I don't think the
upgrade feature buys much.  Downgrading is supported though, which seems
more useful.

              Perhaps you can elaborate a bit more on why you'd like the
upgrade aspect?

              Thanks

              Sent from my phone

              On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com>
wrote:

                Hi all,


                I wondering Is there any  UpgradeableRead lock in java
similar to ReaderWriterLockSlim in C#
                (http://msdn.microsoft.com/en-us/library/system.threading.re
aderwriterlockslim.aspx).


                For now, I try to use two ReentrantReadWriteLock to simulate
the  ReaderWriterLockSlim. Is there any better solution?


                like these:
                  void readLock() {
                    this.rw.readLock().lock();
                  }


                  void readUnlock() {
                    this.rw.readLock().unlock();
                  }


                  void writeLock() {
                    this.up.writeLock().lock();
                    this.rw.writeLock().lock();
                  }


                  void writeUnlock() {
                    this.rw.writeLock().unlock();
                    this.up.writeLock().unlock();
                  }


                  boolean hasWriteLock() {
                    return this.rw.isWriteLockedByCurrentThread();
                  }


                  void  UpgradeableReadLock() {
                    this.up.writeLock().lock();
                  }


                  void Upgrade() {
                    this.rw.writeLock().lock();
                  }


                  void  UpgradeableUnlock() {
                    if (hasWriteLock()) {
                      this.rw.writeLock().unlock();
                    }
                    this.up.writeLock().unlock();
                  }




                Regards,


                Hal Mo


                _______________________________________________
                Concurrency-interest mailing list
                Concurrency-interest at cs.oswego.edu
                http://cs.oswego.edu/mailman/listinfo/concurrency-interest



              _______________________________________________
              Concurrency-interest mailing list
              Concurrency-interest at cs.oswego.edu
              http://cs.oswego.edu/mailman/listinfo/concurrency-interest









-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/25e9c046/attachment-0001.html>

From vitalyd at gmail.com  Mon Sep 17 07:50:56 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 17 Sep 2012 07:50:56 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
References: <CAKz_je5Rnt9Cs8=VQO-tY2rdCvJZ1wkp5N0q78W22yq23JcGgw@mail.gmail.com>
	<CAHjP37GTpzWrztS3YpHGyx=6p0s9PDs-SBmHCZe0tsBxjWXy1w@mail.gmail.com>
	<CAEJX8oqiy4YmSxCq7w_c=7zAV_7Q9S65Yg3tWNJm-n46zD0ebw@mail.gmail.com>
	<CAHjP37G8t3Utyu8_GqHBVL3-POPR2mGmHM67atirsu9Spkr=3A@mail.gmail.com>
	<CAEJX8orHLHno0gD18Dkwt09LHufE43n=zpEAPBBr6vnewW-DyQ@mail.gmail.com>
	<CAKz_je4wS1qwNVUo1KfTDMdmXYFdGdXsiFHgNpGexDYEZ4333A@mail.gmail.com>
	<CAHjP37HiAATaNzWZwsrXZ9JocBVSH71RbO4UFm+H1=oCrG45wg@mail.gmail.com>
	<CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
Message-ID: <CAHjP37GPtrVJ4rtCy3==NM6xvPnp0Y6Ya1Ug+kkVMbGB52tBbg@mail.gmail.com>

Can an optimistic concurrency approach work? That is, a reader determines
that something needs to be updated; it then does a CAS on the object to
flip its state to "updating".  If the CAS succeeds, then this thread won
the right to do the update; if it lost, some other thread is going to do
it.  In the meantime, other threads continue to read the old value.  Once
the updating thread is done, it takes out the write lock and installs the
new entry (or updated one) and flips its state to "ready" (or whatever you
want to call it).

The above allows the write lock to be held for just a brief period of time.

I'm not sure if it's workable in the semantics of the problem, but
something like that may help; i.e. allow one thread to do the update
out-of-band and install the final result via write lock rather than holding
the write lock for the entire duration of the update.

Sent from my phone
On Sep 16, 2012 9:51 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:

> Yes, there is lock contention.
> Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>
> On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Do you mean if the double check after acquiring the write lock is
>> expensive?
>>
>> If you had .NET's rw lock, it would only allow one thread to be in
>> upgradeable mode - are all of your threads possible writers? If so,
>> wouldn't you get lock contention?
>>
>> Maybe you can provide a bit more detail on what you're trying to do and
>> perhaps a better approach will emerge.
>>
>> Vitaly
>>
>> Sent from my phone
>> On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>
>>> if the read operation is time consuming, would upgrade be worth ?
>>> I am trying to optimize a hadoop namenode which manage 2000+ datanodes.
>>>
>>> 2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>
>>>
>>>>
>>>> Yes that's true, but in my experience the double check hasn't bothered
>>>>> me.
>>>>>
>>>> Me either... but you have to know/remember about it. R/W Lock is quite
>>>> poor as even the readers have to alter the shared state. I have not checked
>>>> the recent source of it but it was (is?) 'hackable' by storing the
>>>> Thread.getId() as identifier... the latter can be overridden.
>>>>
>>>> Stanimir
>>>>
>>>>> On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>>>>> wrote:
>>>>>
>>>>>> If you release the read lock and then obtain the write lock, you have
>>>>>> to check again the conditions under the write lock as they might have been
>>>>>> altered meanwhile.
>>>>>> With upgrading there is no need since it's guaranteed no other writes
>>>>>> have been messing the state.
>>>>>>
>>>>>> Stanimir
>>>>>>
>>>>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com
>>>>>> > wrote:
>>>>>>
>>>>>>> Hi Hal,
>>>>>>>
>>>>>>> I've never really found the upgrade feature all that useful in
>>>>>>> .Net.  Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's
>>>>>>> RRWL you simply release the read lock and try to acquire the write lock.
>>>>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>>>>> more useful.
>>>>>>>
>>>>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>>>>> aspect?
>>>>>>>
>>>>>>> Thanks
>>>>>>>
>>>>>>> Sent from my phone
>>>>>>> On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>>>>
>>>>>>>> Hi all,
>>>>>>>>
>>>>>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>>>>>> to ReaderWriterLockSlim in C#
>>>>>>>> (
>>>>>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>>>>>> ).
>>>>>>>>
>>>>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>>>>
>>>>>>>> like these:
>>>>>>>> *  void readLock() {*
>>>>>>>> *    this.rw.readLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void readUnlock() {*
>>>>>>>> *    this.rw.readLock().unlock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void writeLock() {*
>>>>>>>> *    this.up.writeLock().lock();*
>>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void writeUnlock() {*
>>>>>>>> *    this.rw.writeLock().unlock();*
>>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  boolean hasWriteLock() {*
>>>>>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void  UpgradeableReadLock() {*
>>>>>>>> *    this.up.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void Upgrade() {*
>>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void * *Upgradeable**Unlock() {*
>>>>>>>> *    if (hasWriteLock()) {*
>>>>>>>> *      this.rw.writeLock().unlock();*
>>>>>>>> *    }*
>>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>>> *  }*
>>>>>>>>
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>>
>>>>>>>> Hal Mo
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>
>>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>
>>>>>>
>>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/16683e8e/attachment.html>

From david.lloyd at redhat.com  Mon Sep 17 09:11:25 2012
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 17 Sep 2012 08:11:25 -0500
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
Message-ID: <5057217D.9010801@redhat.com>

To be fair I think the use case is more for cases where the necessity to 
write is relatively unlikely, but if you do need to write (based on 
detected state), there would be a savings to not have to re-verify 
whatever state was detected under the read lock.  Thus upgrading would 
be an optimal path because if the upgrade fails, then the caller will 
have to release, reacquire, and redo all the previous work - possibly to 
discover that the conditions are no longer right for the aforementioned 
write work anyway (in which case a downgrade may be in order).

On 09/16/2012 10:25 PM, David Holmes wrote:
> I'm going back to the question of what upgrading is supposed to get you?
> The problem with upgradeable read locks is establishing semantics that
> are generally useful. The simple case is that you want the write to be
> atomic with respect to the state seen by the reader - seems reasonable
> but has a couple of consequences:
> - first you now have to be able to obtain the write lock with a priority
> above that of other waiting writers;
> - second it only works if you have one upgrader, otherwise the atomicity
> is gone.
> If upgrading doesn't give you atomicity then it buys you very little
> over releasing the read lock and acquiring the write lock.
> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Jianhao Mo
>     *Sent:* Monday, 17 September 2012 11:52 AM
>     *To:* Vitaly Davidovich
>     *Cc:* concurrency-interest at cs.oswego.edu
>     *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
>     ReaderWriterLockSlim in C#
>
>     Yes, there is lock contention.
>     Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>
>     On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>
>         Do you mean if the double check after acquiring the write lock
>         is expensive?
>
>         If you had .NET's rw lock, it would only allow one thread to be
>         in upgradeable mode - are all of your threads possible writers?
>         If so, wouldn't you get lock contention?
>
>         Maybe you can provide a bit more detail on what you're trying to
>         do and perhaps a better approach will emerge.
>
>         Vitaly
>
>         Sent from my phone
>
>         On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com
>         <mailto:mojianhao at gmail.com>> wrote:
>
>             if the read operation is time consuming, would upgrade be
>             worth ?
>             I am trying to optimize a hadoop namenode which manage 2000+
>             datanodes.
>
>             2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com
>             <mailto:stanimir at riflexo.com>>
>
>
>                     Yes that's true, but in my experience the double
>                     check hasn't bothered me.
>
>                 Me either... but you have to know/remember about it. R/W
>                 Lock is quite poor as even the readers have to alter the
>                 shared state. I have not checked the recent source of it
>                 but it was (is?) 'hackable' by storing the
>                 Thread.getId() as identifier... the latter can be
>                 overridden.
>
>                 Stanimir
>
>                     On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
>                     <stanimir at riflexo.com <mailto:stanimir at riflexo.com>>
>                     wrote:
>
>                         If you release the read lock and then obtain the
>                         write lock, you have to check again the
>                         conditions under the write lock as they might
>                         have been altered meanwhile.
>                         With upgrading there is no need since it's
>                         guaranteed no other writes have been messing the
>                         state.
>
>                         Stanimir
>
>                         On Thu, Sep 13, 2012 at 5:08 PM, Vitaly
>                         Davidovich <vitalyd at gmail.com
>                         <mailto:vitalyd at gmail.com>> wrote:
>
>                             Hi Hal,
>
>                             I've never really found the upgrade feature
>                             all that useful in .Net.  Its main purpose,
>                             AFAIK, is to avoid deadlock. However, with
>                             Java's RRWL you simply release the read lock
>                             and try to acquire the write lock.  Assuming
>                             you have mostly readers (or else why use
>                             RRWL?) I don't think the upgrade feature
>                             buys much.  Downgrading is supported though,
>                             which seems more useful.
>
>                             Perhaps you can elaborate a bit more on why
>                             you'd like the upgrade aspect?
>
>                             Thanks
>
>                             Sent from my phone
>
>                             On Sep 13, 2012 6:15 AM, "Jianhao Mo"
>                             <mojianhao at gmail.com
>                             <mailto:mojianhao at gmail.com>> wrote:
>
>                                 Hi all,
>
>                                 I wondering Is there any
>                                 UpgradeableRead lock in java similar
>                                 to ReaderWriterLockSlim in C#
>                                 (http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx).
>
>                                 For now, I try to use
>                                 two ReentrantReadWriteLock to simulate
>                                 the ReaderWriterLockSlim. Is there any
>                                 better solution?
>
>                                 like these:
>                                 /  void readLock() {/
>                                 /this.rw.readLock().lock();/
>                                 /}/
>                                 /
>                                 /
>                                 /  void readUnlock() {/
>                                 /this.rw.readLock().unlock();/
>                                 /}/
>                                 /
>                                 /
>                                 /  void writeLock() {/
>                                 /this.up.writeLock().lock();/
>                                 /this.rw.writeLock().lock();/
>                                 /}/
>                                 /
>                                 /
>                                 /  void writeUnlock() {/
>                                 /this.rw.writeLock().unlock();/
>                                 /this.up.writeLock().unlock();/
>                                 /}/
>                                 /
>                                 /
>                                 /  boolean hasWriteLock() {/
>                                 /return
>                                 this.rw.isWriteLockedByCurrentThread();/
>                                 /}/
>                                 /
>                                 /
>                                 /void UpgradeableReadLock() {/
>                                 /this.up.writeLock().lock();/
>                                 /}/
>                                 /
>                                 /
>                                 /  void Upgrade() {/
>                                 /this.rw.writeLock().lock();/
>                                 /}/
>                                 /
>                                 /
>                                 /void / /Upgradeable//Unlock() {/
>                                 /if (hasWriteLock()) {/
>                                 /  this.rw.writeLock().unlock();/
>                                 /}/
>                                 /this.up.writeLock().unlock();/
>                                 /}/
>
>
>                                 Regards,
>
>                                 Hal Mo
>
>                                 _______________________________________________
>                                 Concurrency-interest mailing list
>                                 Concurrency-interest at cs.oswego.edu
>                                 <mailto:Concurrency-interest at cs.oswego.edu>
>                                 http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>                             _______________________________________________
>                             Concurrency-interest mailing list
>                             Concurrency-interest at cs.oswego.edu
>                             <mailto:Concurrency-interest at cs.oswego.edu>
>                             http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
- DML



From vitalyd at gmail.com  Mon Sep 17 09:33:57 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 17 Sep 2012 09:33:57 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <5057217D.9010801@redhat.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com>
Message-ID: <CAHjP37GMEJHjCFgqn2=ik2oEVdN_4xBcusA0JCiW2OzeiNZrkQ@mail.gmail.com>

In the .net implementation of this, only one thread can have the lock in
upgradeable mode at a given time.  If all readers are also possible
writers, then they would all contend for acquiring the lock in that mode.
I think it's really meant for cases where most threads are pure readers,
and very few come in with the possibility of writing.

Sent from my phone
On Sep 17, 2012 9:21 AM, "David M. Lloyd" <david.lloyd at redhat.com> wrote:

> To be fair I think the use case is more for cases where the necessity to
> write is relatively unlikely, but if you do need to write (based on
> detected state), there would be a savings to not have to re-verify whatever
> state was detected under the read lock.  Thus upgrading would be an optimal
> path because if the upgrade fails, then the caller will have to release,
> reacquire, and redo all the previous work - possibly to discover that the
> conditions are no longer right for the aforementioned write work anyway (in
> which case a downgrade may be in order).
>
> On 09/16/2012 10:25 PM, David Holmes wrote:
>
>> I'm going back to the question of what upgrading is supposed to get you?
>> The problem with upgradeable read locks is establishing semantics that
>> are generally useful. The simple case is that you want the write to be
>> atomic with respect to the state seen by the reader - seems reasonable
>> but has a couple of consequences:
>> - first you now have to be able to obtain the write lock with a priority
>> above that of other waiting writers;
>> - second it only works if you have one upgrader, otherwise the atomicity
>> is gone.
>> If upgrading doesn't give you atomicity then it buys you very little
>> over releasing the read lock and acquiring the write lock.
>> David
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces@**cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>
>>     [mailto:concurrency-interest-**bounces at cs.oswego.edu<concurrency-interest-bounces at cs.oswego.edu>]*On
>> Behalf Of
>>     *Jianhao Mo
>>     *Sent:* Monday, 17 September 2012 11:52 AM
>>     *To:* Vitaly Davidovich
>>     *Cc:* concurrency-interest at cs.**oswego.edu<concurrency-interest at cs.oswego.edu>
>>     *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
>>     ReaderWriterLockSlim in C#
>>
>>     Yes, there is lock contention.
>>     Here is the detail: https://issues.apache.org/**jira/browse/HDFS-2490<https://issues.apache.org/jira/browse/HDFS-2490>
>>
>>     On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
>>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>>
>>         Do you mean if the double check after acquiring the write lock
>>         is expensive?
>>
>>         If you had .NET's rw lock, it would only allow one thread to be
>>         in upgradeable mode - are all of your threads possible writers?
>>         If so, wouldn't you get lock contention?
>>
>>         Maybe you can provide a bit more detail on what you're trying to
>>         do and perhaps a better approach will emerge.
>>
>>         Vitaly
>>
>>         Sent from my phone
>>
>>         On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com
>>         <mailto:mojianhao at gmail.com>> wrote:
>>
>>             if the read operation is time consuming, would upgrade be
>>             worth ?
>>             I am trying to optimize a hadoop namenode which manage 2000+
>>             datanodes.
>>
>>             2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com
>>             <mailto:stanimir at riflexo.com>>
>>
>>
>>                     Yes that's true, but in my experience the double
>>                     check hasn't bothered me.
>>
>>                 Me either... but you have to know/remember about it. R/W
>>                 Lock is quite poor as even the readers have to alter the
>>                 shared state. I have not checked the recent source of it
>>                 but it was (is?) 'hackable' by storing the
>>                 Thread.getId() as identifier... the latter can be
>>                 overridden.
>>
>>                 Stanimir
>>
>>                     On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
>>                     <stanimir at riflexo.com <mailto:stanimir at riflexo.com>>
>>                     wrote:
>>
>>                         If you release the read lock and then obtain the
>>                         write lock, you have to check again the
>>                         conditions under the write lock as they might
>>                         have been altered meanwhile.
>>                         With upgrading there is no need since it's
>>                         guaranteed no other writes have been messing the
>>                         state.
>>
>>                         Stanimir
>>
>>                         On Thu, Sep 13, 2012 at 5:08 PM, Vitaly
>>                         Davidovich <vitalyd at gmail.com
>>                         <mailto:vitalyd at gmail.com>> wrote:
>>
>>                             Hi Hal,
>>
>>                             I've never really found the upgrade feature
>>                             all that useful in .Net.  Its main purpose,
>>                             AFAIK, is to avoid deadlock. However, with
>>                             Java's RRWL you simply release the read lock
>>                             and try to acquire the write lock.  Assuming
>>                             you have mostly readers (or else why use
>>                             RRWL?) I don't think the upgrade feature
>>                             buys much.  Downgrading is supported though,
>>                             which seems more useful.
>>
>>                             Perhaps you can elaborate a bit more on why
>>                             you'd like the upgrade aspect?
>>
>>                             Thanks
>>
>>                             Sent from my phone
>>
>>                             On Sep 13, 2012 6:15 AM, "Jianhao Mo"
>>                             <mojianhao at gmail.com
>>                             <mailto:mojianhao at gmail.com>> wrote:
>>
>>                                 Hi all,
>>
>>                                 I wondering Is there any
>>                                 UpgradeableRead lock in java similar
>>                                 to ReaderWriterLockSlim in C#
>>                                 (http://msdn.microsoft.com/en-**
>> us/library/system.threading.**readerwriterlockslim.aspx<http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx>
>> ).
>>
>>                                 For now, I try to use
>>                                 two ReentrantReadWriteLock to simulate
>>                                 the ReaderWriterLockSlim. Is there any
>>                                 better solution?
>>
>>                                 like these:
>>                                 /  void readLock() {/
>>                                 /this.rw.readLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void readUnlock() {/
>>                                 /this.rw.readLock().unlock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void writeLock() {/
>>                                 /this.up.writeLock().lock();/
>>                                 /this.rw.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void writeUnlock() {/
>>                                 /this.rw.writeLock().unlock();**/
>>                                 /this.up.writeLock().unlock();**/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  boolean hasWriteLock() {/
>>                                 /return
>>                                 this.rw.**isWriteLockedByCurrentThread()*
>> *;/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /void UpgradeableReadLock() {/
>>                                 /this.up.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void Upgrade() {/
>>                                 /this.rw.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /void / /Upgradeable//Unlock() {/
>>                                 /if (hasWriteLock()) {/
>>                                 /  this.rw.writeLock().unlock();/
>>                                 /}/
>>                                 /this.up.writeLock().unlock();**/
>>                                 /}/
>>
>>
>>                                 Regards,
>>
>>                                 Hal Mo
>>
>>                                 ______________________________**
>> _________________
>>                                 Concurrency-interest mailing list
>>                                 Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>                                 <mailto:Concurrency-interest@**
>> cs.oswego.edu <Concurrency-interest at cs.oswego.edu>>
>>                                 http://cs.oswego.edu/mailman/**
>> listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>                             ______________________________**
>> _________________
>>                             Concurrency-interest mailing list
>>                             Concurrency-interest at cs.**oswego.edu<Concurrency-interest at cs.oswego.edu>
>>                             <mailto:Concurrency-interest@**cs.oswego.edu<Concurrency-interest at cs.oswego.edu>
>> >
>>                             http://cs.oswego.edu/mailman/**
>> listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>>
>>
>>
>> ______________________________**_________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>
> --
> - DML
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/76b871c0/attachment.html>

From dl at cs.oswego.edu  Mon Sep 17 09:48:49 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 17 Sep 2012 09:48:49 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <5057217D.9010801@redhat.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com>
Message-ID: <50572A41.80609@cs.oswego.edu>


A few notes about this:

If we find a way to support/release it, people will be able
to use StampedLock in situations requiring upgrade-if-only-reader,
as well as a conditional optimistic-reader-to-writer form.
See initial discussions at:
  http://cs.oswego.edu/pipermail/concurrency-interest/2012-June/009530.html
Plus a few followups here and there.

Stamped/ticket locks can intrinsically support such
methods and policies, at the expense of no reentrancy,
and different tradeoffs in which kinds of errors they
can trap. The ReadWriteLock API and ReentrantReadWriteLock
class are nice as plug-in replacements for synchronized
blocks and ReentrantLocks, but limit the kinds of methods
and policies we can support (plus are too slow!)

-Doug




From oleksandr.otenko at oracle.com  Mon Sep 17 09:47:19 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Mon, 17 Sep 2012 14:47:19 +0100
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <5057217D.9010801@redhat.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com>
Message-ID: <505729E7.8090208@oracle.com>

If multiple readers want to write, they'll contend. But that's not all. 
How do you behave after contention? Well, if it is "tryUpgrade" kind of 
call, upgrade can fail without blocking, and someone needs to think how 
to wait for upgrade condition to change. Or if it is a blocking upgrade, 
which always succeeds, ...there may be any number of intervening writers 
or upgrades between the start and end of upgrade call, which will modify 
the state and you'd need to re-validate the condition for update after 
upgrade.

Alex

On 17/09/2012 14:11, David M. Lloyd wrote:
> To be fair I think the use case is more for cases where the necessity 
> to write is relatively unlikely, but if you do need to write (based on 
> detected state), there would be a savings to not have to re-verify 
> whatever state was detected under the read lock.  Thus upgrading would 
> be an optimal path because if the upgrade fails, then the caller will 
> have to release, reacquire, and redo all the previous work - possibly 
> to discover that the conditions are no longer right for the 
> aforementioned write work anyway (in which case a downgrade may be in 
> order).
>
> On 09/16/2012 10:25 PM, David Holmes wrote:
>> I'm going back to the question of what upgrading is supposed to get you?
>> The problem with upgradeable read locks is establishing semantics that
>> are generally useful. The simple case is that you want the write to be
>> atomic with respect to the state seen by the reader - seems reasonable
>> but has a couple of consequences:
>> - first you now have to be able to obtain the write lock with a priority
>> above that of other waiting writers;
>> - second it only works if you have one upgrader, otherwise the atomicity
>> is gone.
>> If upgrading doesn't give you atomicity then it buys you very little
>> over releasing the read lock and acquiring the write lock.
>> David
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>     *Jianhao Mo
>>     *Sent:* Monday, 17 September 2012 11:52 AM
>>     *To:* Vitaly Davidovich
>>     *Cc:* concurrency-interest at cs.oswego.edu
>>     *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
>>     ReaderWriterLockSlim in C#
>>
>>     Yes, there is lock contention.
>>     Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>>
>>     On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
>> <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>>
>>         Do you mean if the double check after acquiring the write lock
>>         is expensive?
>>
>>         If you had .NET's rw lock, it would only allow one thread to be
>>         in upgradeable mode - are all of your threads possible writers?
>>         If so, wouldn't you get lock contention?
>>
>>         Maybe you can provide a bit more detail on what you're trying to
>>         do and perhaps a better approach will emerge.
>>
>>         Vitaly
>>
>>         Sent from my phone
>>
>>         On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com
>> <mailto:mojianhao at gmail.com>> wrote:
>>
>>             if the read operation is time consuming, would upgrade be
>>             worth ?
>>             I am trying to optimize a hadoop namenode which manage 2000+
>>             datanodes.
>>
>>             2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com
>> <mailto:stanimir at riflexo.com>>
>>
>>
>>                     Yes that's true, but in my experience the double
>>                     check hasn't bothered me.
>>
>>                 Me either... but you have to know/remember about it. R/W
>>                 Lock is quite poor as even the readers have to alter the
>>                 shared state. I have not checked the recent source of it
>>                 but it was (is?) 'hackable' by storing the
>>                 Thread.getId() as identifier... the latter can be
>>                 overridden.
>>
>>                 Stanimir
>>
>>                     On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
>> <stanimir at riflexo.com <mailto:stanimir at riflexo.com>>
>>                     wrote:
>>
>>                         If you release the read lock and then obtain the
>>                         write lock, you have to check again the
>>                         conditions under the write lock as they might
>>                         have been altered meanwhile.
>>                         With upgrading there is no need since it's
>>                         guaranteed no other writes have been messing the
>>                         state.
>>
>>                         Stanimir
>>
>>                         On Thu, Sep 13, 2012 at 5:08 PM, Vitaly
>>                         Davidovich <vitalyd at gmail.com
>> <mailto:vitalyd at gmail.com>> wrote:
>>
>>                             Hi Hal,
>>
>>                             I've never really found the upgrade feature
>>                             all that useful in .Net.  Its main purpose,
>>                             AFAIK, is to avoid deadlock. However, with
>>                             Java's RRWL you simply release the read lock
>>                             and try to acquire the write lock.  Assuming
>>                             you have mostly readers (or else why use
>>                             RRWL?) I don't think the upgrade feature
>>                             buys much.  Downgrading is supported though,
>>                             which seems more useful.
>>
>>                             Perhaps you can elaborate a bit more on why
>>                             you'd like the upgrade aspect?
>>
>>                             Thanks
>>
>>                             Sent from my phone
>>
>>                             On Sep 13, 2012 6:15 AM, "Jianhao Mo"
>> <mojianhao at gmail.com
>> <mailto:mojianhao at gmail.com>> wrote:
>>
>>                                 Hi all,
>>
>>                                 I wondering Is there any
>>                                 UpgradeableRead lock in java similar
>>                                 to ReaderWriterLockSlim in C#
>>                                 
>> (http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx).
>>
>>                                 For now, I try to use
>>                                 two ReentrantReadWriteLock to simulate
>>                                 the ReaderWriterLockSlim. Is there any
>>                                 better solution?
>>
>>                                 like these:
>>                                 /  void readLock() {/
>>                                 /this.rw.readLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void readUnlock() {/
>>                                 /this.rw.readLock().unlock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void writeLock() {/
>>                                 /this.up.writeLock().lock();/
>>                                 /this.rw.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void writeUnlock() {/
>>                                 /this.rw.writeLock().unlock();/
>>                                 /this.up.writeLock().unlock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  boolean hasWriteLock() {/
>>                                 /return
>>                                 this.rw.isWriteLockedByCurrentThread();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /void UpgradeableReadLock() {/
>>                                 /this.up.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /  void Upgrade() {/
>>                                 /this.rw.writeLock().lock();/
>>                                 /}/
>>                                 /
>>                                 /
>>                                 /void / /Upgradeable//Unlock() {/
>>                                 /if (hasWriteLock()) {/
>>                                 /  this.rw.writeLock().unlock();/
>>                                 /}/
>>                                 /this.up.writeLock().unlock();/
>>                                 /}/
>>
>>
>>                                 Regards,
>>
>>                                 Hal Mo
>>
>>                                 
>> _______________________________________________
>>                                 Concurrency-interest mailing list
>>                                 Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>>                                 
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>                             
>> _______________________________________________
>>                             Concurrency-interest mailing list
>>                             Concurrency-interest at cs.oswego.edu
>> <mailto:Concurrency-interest at cs.oswego.edu>
>>                             
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/a78f288d/attachment-0001.html>

From david.lloyd at redhat.com  Mon Sep 17 10:04:21 2012
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 17 Sep 2012 09:04:21 -0500
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <505729E7.8090208@oracle.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com> <505729E7.8090208@oracle.com>
Message-ID: <50572DE5.6090805@redhat.com>

Yes indeed, it would have to be a "try" kind of semantic so that 
"failing" readers know they can "never" upgrade.  But not non-blocking. 
  A failure would not need to block, but a success would have to block 
until other readers are released before returning a positive result. 
Furthermore it could be argued that interruption should stop an upgrade 
attempt, meaning that a potential upgrader might be reverted to their 
read lock allowing other threads to upgrade successfully (this is why I 
put "never" in quotes up above - though this eventuality would be 
difficult to plan for, which is why I say that if upgrade fails there's 
no point in trying again).

On 09/17/2012 08:47 AM, oleksandr otenko wrote:
> If multiple readers want to write, they'll contend. But that's not all.
> How do you behave after contention? Well, if it is "tryUpgrade" kind of
> call, upgrade can fail without blocking, and someone needs to think how
> to wait for upgrade condition to change. Or if it is a blocking upgrade,
> which always succeeds, ...there may be any number of intervening writers
> or upgrades between the start and end of upgrade call, which will modify
> the state and you'd need to re-validate the condition for update after
> upgrade.
>
> Alex
>
> On 17/09/2012 14:11, David M. Lloyd wrote:
>> To be fair I think the use case is more for cases where the necessity
>> to write is relatively unlikely, but if you do need to write (based on
>> detected state), there would be a savings to not have to re-verify
>> whatever state was detected under the read lock.  Thus upgrading would
>> be an optimal path because if the upgrade fails, then the caller will
>> have to release, reacquire, and redo all the previous work - possibly
>> to discover that the conditions are no longer right for the
>> aforementioned write work anyway (in which case a downgrade may be in
>> order).
>>
>> On 09/16/2012 10:25 PM, David Holmes wrote:
>>> I'm going back to the question of what upgrading is supposed to get you?
>>> The problem with upgradeable read locks is establishing semantics that
>>> are generally useful. The simple case is that you want the write to be
>>> atomic with respect to the state seen by the reader - seems reasonable
>>> but has a couple of consequences:
>>> - first you now have to be able to obtain the write lock with a priority
>>> above that of other waiting writers;
>>> - second it only works if you have one upgrader, otherwise the atomicity
>>> is gone.
>>> If upgrading doesn't give you atomicity then it buys you very little
>>> over releasing the read lock and acquiring the write lock.
>>> David
>>>
>>>     -----Original Message-----
>>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>>     *Jianhao Mo
>>>     *Sent:* Monday, 17 September 2012 11:52 AM
>>>     *To:* Vitaly Davidovich
>>>     *Cc:* concurrency-interest at cs.oswego.edu
>>>     *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
>>>     ReaderWriterLockSlim in C#
>>>
>>>     Yes, there is lock contention.
>>>     Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>>>
>>>     On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
>>>     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
>>>
>>>         Do you mean if the double check after acquiring the write lock
>>>         is expensive?
>>>
>>>         If you had .NET's rw lock, it would only allow one thread to be
>>>         in upgradeable mode - are all of your threads possible writers?
>>>         If so, wouldn't you get lock contention?
>>>
>>>         Maybe you can provide a bit more detail on what you're trying to
>>>         do and perhaps a better approach will emerge.
>>>
>>>         Vitaly
>>>
>>>         Sent from my phone
>>>
>>>         On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com
>>> <mailto:mojianhao at gmail.com>> wrote:
>>>
>>>             if the read operation is time consuming, would upgrade be
>>>             worth ?
>>>             I am trying to optimize a hadoop namenode which manage 2000+
>>>             datanodes.
>>>
>>>             2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com
>>> <mailto:stanimir at riflexo.com>>
>>>
>>>
>>>                     Yes that's true, but in my experience the double
>>>                     check hasn't bothered me.
>>>
>>>                 Me either... but you have to know/remember about it. R/W
>>>                 Lock is quite poor as even the readers have to alter the
>>>                 shared state. I have not checked the recent source of it
>>>                 but it was (is?) 'hackable' by storing the
>>>                 Thread.getId() as identifier... the latter can be
>>>                 overridden.
>>>
>>>                 Stanimir
>>>
>>>                     On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
>>>                     <stanimir at riflexo.com <mailto:stanimir at riflexo.com>>
>>>                     wrote:
>>>
>>>                         If you release the read lock and then obtain the
>>>                         write lock, you have to check again the
>>>                         conditions under the write lock as they might
>>>                         have been altered meanwhile.
>>>                         With upgrading there is no need since it's
>>>                         guaranteed no other writes have been messing the
>>>                         state.
>>>
>>>                         Stanimir
>>>
>>>                         On Thu, Sep 13, 2012 at 5:08 PM, Vitaly
>>>                         Davidovich <vitalyd at gmail.com
>>> <mailto:vitalyd at gmail.com>> wrote:
>>>
>>>                             Hi Hal,
>>>
>>>                             I've never really found the upgrade feature
>>>                             all that useful in .Net.  Its main purpose,
>>>                             AFAIK, is to avoid deadlock. However, with
>>>                             Java's RRWL you simply release the read lock
>>>                             and try to acquire the write lock. Assuming
>>>                             you have mostly readers (or else why use
>>>                             RRWL?) I don't think the upgrade feature
>>>                             buys much.  Downgrading is supported though,
>>>                             which seems more useful.
>>>
>>>                             Perhaps you can elaborate a bit more on why
>>>                             you'd like the upgrade aspect?
>>>
>>>                             Thanks
>>>
>>>                             Sent from my phone
>>>
>>>                             On Sep 13, 2012 6:15 AM, "Jianhao Mo"
>>>                             <mojianhao at gmail.com
>>> <mailto:mojianhao at gmail.com>> wrote:
>>>
>>>                                 Hi all,
>>>
>>>                                 I wondering Is there any
>>>                                 UpgradeableRead lock in java similar
>>>                                 to ReaderWriterLockSlim in C#
>>> (http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx).
>>>
>>>                                 For now, I try to use
>>>                                 two ReentrantReadWriteLock to simulate
>>>                                 the ReaderWriterLockSlim. Is there any
>>>                                 better solution?
>>>
>>>                                 like these:
>>>                                 /  void readLock() {/
>>>                                 /this.rw.readLock().lock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /  void readUnlock() {/
>>>                                 /this.rw.readLock().unlock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /  void writeLock() {/
>>>                                 /this.up.writeLock().lock();/
>>>                                 /this.rw.writeLock().lock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /  void writeUnlock() {/
>>>                                 /this.rw.writeLock().unlock();/
>>>                                 /this.up.writeLock().unlock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /  boolean hasWriteLock() {/
>>>                                 /return
>>> this.rw.isWriteLockedByCurrentThread();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /void UpgradeableReadLock() {/
>>>                                 /this.up.writeLock().lock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /  void Upgrade() {/
>>>                                 /this.rw.writeLock().lock();/
>>>                                 /}/
>>>                                 /
>>>                                 /
>>>                                 /void / /Upgradeable//Unlock() {/
>>>                                 /if (hasWriteLock()) {/
>>>                                 / this.rw.writeLock().unlock();/
>>>                                 /}/
>>>                                 /this.up.writeLock().unlock();/
>>>                                 /}/
>>>
>>>
>>>                                 Regards,
>>>
>>>                                 Hal Mo
>>>
>>> _______________________________________________
>>>                                 Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>> _______________________________________________
>>>                             Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>


-- 
- DML



From martinrb at google.com  Mon Sep 17 14:46:26 2012
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 17 Sep 2012 11:46:26 -0700
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <505729E7.8090208@oracle.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com> <505729E7.8090208@oracle.com>
Message-ID: <CA+kOe081e+pSyTRAZ5B0Cr+hoZ5U+nsX1Jo5aEFzqsKmjdZfPg@mail.gmail.com>

On Mon, Sep 17, 2012 at 6:47 AM, oleksandr otenko <
oleksandr.otenko at oracle.com> wrote:

>  If multiple readers want to write, they'll contend. But that's not all.
> How do you behave after contention? Well, if it is "tryUpgrade" kind of
> call, upgrade can fail without blocking, and someone needs to think how to
> wait for upgrade condition to change. Or if it is a blocking upgrade, which
> always succeeds, ...there may be any number of intervening writers or
> upgrades between the start and end of upgrade call, which will modify the
> state and you'd need to re-validate the condition for update after upgrade.
>

I imagine

boolean tryUpgrade()  @return true if only reader

boolean upgrade() @return true if acquired write lock without some other
intervening writer having acquired it

In the uncontended case, we can save a volatile write by upgrading in a
single CAS.

I don't see any reason this couldn't be added to RRWL (except for the
engineering effort!)

There is potential for misuse where callers of upgrade() assume atomicity,
so it might be safer to provide only tryUpgrade, and on failure, user has
to unlock and reacquire.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120917/bb2d2284/attachment.html>

From davidcholmes at aapt.net.au  Mon Sep 17 18:01:53 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Sep 2012 08:01:53 +1000
Subject: [concurrency-interest] UpgradeableRead lock like
	ReaderWriterLockSlim in C#
In-Reply-To: <5057217D.9010801@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEPBJGAA.davidcholmes@aapt.net.au>

David M. Lloyd writes:
>
> To be fair I think the use case is more for cases where the necessity to
> write is relatively unlikely, but if you do need to write (based on
> detected state), there would be a savings to not have to re-verify
> whatever state was detected under the read lock.

But this can only work if the additional conditions I described hold,
otherwise even after the upgrade you have no idea what the present state is.
So upgrading just becomes an optimization - but if the conditions for the
write are "relatively unlikely" then the optimization is not going to be of
much value.

Cheers,
David
-----

>  Thus upgrading would
> be an optimal path because if the upgrade fails, then the caller will
> have to release, reacquire, and redo all the previous work - possibly to
> discover that the conditions are no longer right for the aforementioned
> write work anyway (in which case a downgrade may be in order).
>
> On 09/16/2012 10:25 PM, David Holmes wrote:
> > I'm going back to the question of what upgrading is supposed to get you?
> > The problem with upgradeable read locks is establishing semantics that
> > are generally useful. The simple case is that you want the write to be
> > atomic with respect to the state seen by the reader - seems reasonable
> > but has a couple of consequences:
> > - first you now have to be able to obtain the write lock with a priority
> > above that of other waiting writers;
> > - second it only works if you have one upgrader, otherwise the atomicity
> > is gone.
> > If upgrading doesn't give you atomicity then it buys you very little
> > over releasing the read lock and acquiring the write lock.
> > David
> >
> >     -----Original Message-----
> >     *From:* concurrency-interest-bounces at cs.oswego.edu
> >     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
> >     *Jianhao Mo
> >     *Sent:* Monday, 17 September 2012 11:52 AM
> >     *To:* Vitaly Davidovich
> >     *Cc:* concurrency-interest at cs.oswego.edu
> >     *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
> >     ReaderWriterLockSlim in C#
> >
> >     Yes, there is lock contention.
> >     Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
> >
> >     On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
> >     <vitalyd at gmail.com <mailto:vitalyd at gmail.com>> wrote:
> >
> >         Do you mean if the double check after acquiring the write lock
> >         is expensive?
> >
> >         If you had .NET's rw lock, it would only allow one thread to be
> >         in upgradeable mode - are all of your threads possible writers?
> >         If so, wouldn't you get lock contention?
> >
> >         Maybe you can provide a bit more detail on what you're trying to
> >         do and perhaps a better approach will emerge.
> >
> >         Vitaly
> >
> >         Sent from my phone
> >
> >         On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com
> >         <mailto:mojianhao at gmail.com>> wrote:
> >
> >             if the read operation is time consuming, would upgrade be
> >             worth ?
> >             I am trying to optimize a hadoop namenode which manage 2000+
> >             datanodes.
> >
> >             2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com
> >             <mailto:stanimir at riflexo.com>>
> >
> >
> >                     Yes that's true, but in my experience the double
> >                     check hasn't bothered me.
> >
> >                 Me either... but you have to know/remember about it. R/W
> >                 Lock is quite poor as even the readers have to alter the
> >                 shared state. I have not checked the recent source of it
> >                 but it was (is?) 'hackable' by storing the
> >                 Thread.getId() as identifier... the latter can be
> >                 overridden.
> >
> >                 Stanimir
> >
> >                     On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
> >                     <stanimir at riflexo.com <mailto:stanimir at riflexo.com>>
> >                     wrote:
> >
> >                         If you release the read lock and then obtain the
> >                         write lock, you have to check again the
> >                         conditions under the write lock as they might
> >                         have been altered meanwhile.
> >                         With upgrading there is no need since it's
> >                         guaranteed no other writes have been messing the
> >                         state.
> >
> >                         Stanimir
> >
> >                         On Thu, Sep 13, 2012 at 5:08 PM, Vitaly
> >                         Davidovich <vitalyd at gmail.com
> >                         <mailto:vitalyd at gmail.com>> wrote:
> >
> >                             Hi Hal,
> >
> >                             I've never really found the upgrade feature
> >                             all that useful in .Net.  Its main purpose,
> >                             AFAIK, is to avoid deadlock. However, with
> >                             Java's RRWL you simply release the read lock
> >                             and try to acquire the write lock.  Assuming
> >                             you have mostly readers (or else why use
> >                             RRWL?) I don't think the upgrade feature
> >                             buys much.  Downgrading is supported though,
> >                             which seems more useful.
> >
> >                             Perhaps you can elaborate a bit more on why
> >                             you'd like the upgrade aspect?
> >
> >                             Thanks
> >
> >                             Sent from my phone
> >
> >                             On Sep 13, 2012 6:15 AM, "Jianhao Mo"
> >                             <mojianhao at gmail.com
> >                             <mailto:mojianhao at gmail.com>> wrote:
> >
> >                                 Hi all,
> >
> >                                 I wondering Is there any
> >                                 UpgradeableRead lock in java similar
> >                                 to ReaderWriterLockSlim in C#
> >
> (http://msdn.microsoft.com/en-us/library/system.threading.readerwr
> iterlockslim.aspx).
> >
> >                                 For now, I try to use
> >                                 two ReentrantReadWriteLock to simulate
> >                                 the ReaderWriterLockSlim. Is there any
> >                                 better solution?
> >
> >                                 like these:
> >                                 /  void readLock() {/
> >                                 /this.rw.readLock().lock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /  void readUnlock() {/
> >                                 /this.rw.readLock().unlock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /  void writeLock() {/
> >                                 /this.up.writeLock().lock();/
> >                                 /this.rw.writeLock().lock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /  void writeUnlock() {/
> >                                 /this.rw.writeLock().unlock();/
> >                                 /this.up.writeLock().unlock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /  boolean hasWriteLock() {/
> >                                 /return
> >                                 this.rw.isWriteLockedByCurrentThread();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /void UpgradeableReadLock() {/
> >                                 /this.up.writeLock().lock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /  void Upgrade() {/
> >                                 /this.rw.writeLock().lock();/
> >                                 /}/
> >                                 /
> >                                 /
> >                                 /void / /Upgradeable//Unlock() {/
> >                                 /if (hasWriteLock()) {/
> >                                 /  this.rw.writeLock().unlock();/
> >                                 /}/
> >                                 /this.up.writeLock().unlock();/
> >                                 /}/
> >
> >
> >                                 Regards,
> >
> >                                 Hal Mo
> >
> >
> _______________________________________________
> >                                 Concurrency-interest mailing list
> >                                 Concurrency-interest at cs.oswego.edu
> >
> <mailto:Concurrency-interest at cs.oswego.edu>
> >
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> _______________________________________________
> >                             Concurrency-interest mailing list
> >                             Concurrency-interest at cs.oswego.edu
> >                             <mailto:Concurrency-interest at cs.oswego.edu>
> >
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
>
> --
> - DML
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From mojianhao at gmail.com  Mon Sep 17 21:23:50 2012
From: mojianhao at gmail.com (Jianhao Mo)
Date: Tue, 18 Sep 2012 09:23:50 +0800
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
References: <CAKz_je5ddNuJ1bf5fsHyF5CMtTJKfdNOgxNS2KeuD+ekp7tUCA@mail.gmail.com>
	<ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
Message-ID: <CAKz_je5L-y3oyXY+38xJu7a5QvEP6s1z2uziRNRUakQketrumg@mail.gmail.com>

>>upgrading doesn't give you atomicity
I believe atomic is insure by lock1, upgrading thread already has lock
lock1.writelock. other waiting writers must wait until the upgrading
finished and unlocked.

On Mon, Sep 17, 2012 at 11:25 AM, David Holmes <davidcholmes at aapt.net.au>wrote:

> **
> I'm going back to the question of what upgrading is supposed to get you?
> The problem with upgradeable read locks is establishing semantics that are
> generally useful. The simple case is that you want the write to be atomic
> with respect to the state seen by the reader - seems reasonable but has a
> couple of consequences:
> - first you now have to be able to obtain the write lock with a priority
> above that of other waiting writers;
> - second it only works if you have one upgrader, otherwise the atomicity
> is gone.
>
> If upgrading doesn't give you atomicity then it buys you very little over
> releasing the read lock and acquiring the write lock.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Jianhao Mo
> *Sent:* Monday, 17 September 2012 11:52 AM
> *To:* Vitaly Davidovich
> *Cc:* concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] UpgradeableRead lock like
> ReaderWriterLockSlim in C#
>
> Yes, there is lock contention.
> Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490
>
> On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>wrote:
>
>> Do you mean if the double check after acquiring the write lock is
>> expensive?
>>
>> If you had .NET's rw lock, it would only allow one thread to be in
>> upgradeable mode - are all of your threads possible writers? If so,
>> wouldn't you get lock contention?
>>
>> Maybe you can provide a bit more detail on what you're trying to do and
>> perhaps a better approach will emerge.
>>
>> Vitaly
>>
>> Sent from my phone
>>  On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>
>>> if the read operation is time consuming, would upgrade be worth ?
>>> I am trying to optimize a hadoop namenode which manage 2000+ datanodes.
>>>
>>> 2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>
>>>
>>>>
>>>>   Yes that's true, but in my experience the double check hasn't
>>>>> bothered me.
>>>>>
>>>> Me either... but you have to know/remember about it. R/W Lock is quite
>>>> poor as even the readers have to alter the shared state. I have not checked
>>>> the recent source of it but it was (is?) 'hackable' by storing the
>>>> Thread.getId() as identifier... the latter can be overridden.
>>>>
>>>> Stanimir
>>>>
>>>>>   On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff" <stanimir at riflexo.com>
>>>>> wrote:
>>>>>
>>>>>> If you release the read lock and then obtain the write lock, you have
>>>>>> to check again the conditions under the write lock as they might have been
>>>>>> altered meanwhile.
>>>>>> With upgrading there is no need since it's guaranteed no other writes
>>>>>> have been messing the state.
>>>>>>
>>>>>> Stanimir
>>>>>>
>>>>>> On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich <vitalyd at gmail.com
>>>>>> > wrote:
>>>>>>
>>>>>>> Hi Hal,
>>>>>>>
>>>>>>> I've never really found the upgrade feature all that useful in
>>>>>>> .Net.  Its main purpose, AFAIK, is to avoid deadlock.  However, with Java's
>>>>>>> RRWL you simply release the read lock and try to acquire the write lock.
>>>>>>> Assuming you have mostly readers (or else why use RRWL?) I don't think the
>>>>>>> upgrade feature buys much.  Downgrading is supported though, which seems
>>>>>>> more useful.
>>>>>>>
>>>>>>> Perhaps you can elaborate a bit more on why you'd like the upgrade
>>>>>>> aspect?
>>>>>>>
>>>>>>> Thanks
>>>>>>>
>>>>>>> Sent from my phone
>>>>>>>  On Sep 13, 2012 6:15 AM, "Jianhao Mo" <mojianhao at gmail.com> wrote:
>>>>>>>
>>>>>>>>  Hi all,
>>>>>>>>
>>>>>>>> I wondering Is there any  UpgradeableRead lock in java similar
>>>>>>>> to ReaderWriterLockSlim in C#
>>>>>>>> (
>>>>>>>> http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx
>>>>>>>> ).
>>>>>>>>
>>>>>>>> For now, I try to use two ReentrantReadWriteLock to simulate the
>>>>>>>> ReaderWriterLockSlim. Is there any better solution?
>>>>>>>>
>>>>>>>> like these:
>>>>>>>>  *  void readLock() {*
>>>>>>>> *    this.rw.readLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void readUnlock() {*
>>>>>>>> *    this.rw.readLock().unlock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void writeLock() {*
>>>>>>>> *    this.up.writeLock().lock();*
>>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void writeUnlock() {*
>>>>>>>> *    this.rw.writeLock().unlock();*
>>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  boolean hasWriteLock() {*
>>>>>>>> *    return this.rw.isWriteLockedByCurrentThread();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void  UpgradeableReadLock() {*
>>>>>>>> *    this.up.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void Upgrade() {*
>>>>>>>> *    this.rw.writeLock().lock();*
>>>>>>>> *  }*
>>>>>>>> *
>>>>>>>> *
>>>>>>>> *  void * *Upgradeable**Unlock() {*
>>>>>>>> *    if (hasWriteLock()) {*
>>>>>>>> *      this.rw.writeLock().unlock();*
>>>>>>>> *    }*
>>>>>>>> *    this.up.writeLock().unlock();*
>>>>>>>> *  }*
>>>>>>>>
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>>
>>>>>>>> Hal Mo
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>>
>>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> Concurrency-interest mailing list
>>>>>>> Concurrency-interest at cs.oswego.edu
>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>>>
>>>>>>>
>>>>>>
>>>>
>>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/d6b29bbf/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon Sep 17 21:41:26 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Sep 2012 11:41:26 +1000
Subject: [concurrency-interest] UpgradeableRead lock like
	ReaderWriterLockSlim in C#
In-Reply-To: <CAKz_je5L-y3oyXY+38xJu7a5QvEP6s1z2uziRNRUakQketrumg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEPDJGAA.davidcholmes@aapt.net.au>

The atomicity is with respect to the read. The upgrader only has atomicity
after upgrading, by which time other writers or upgraders may have changed
the state from that which the upgrader had last seen.

David
  -----Original Message-----
  From: Jianhao Mo [mailto:mojianhao at gmail.com]
  Sent: Tuesday, 18 September 2012 11:24 AM
  To: dholmes at ieee.org
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] UpgradeableRead lock like
ReaderWriterLockSlim in C#


  >>upgrading doesn't give you atomicity
  I believe atomic is insure by lock1, upgrading thread already has lock
lock1.writelock. other waiting writers must wait until the upgrading
finished and unlocked.


  On Mon, Sep 17, 2012 at 11:25 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

    I'm going back to the question of what upgrading is supposed to get you?
The problem with upgradeable read locks is establishing semantics that are
generally useful. The simple case is that you want the write to be atomic
with respect to the state seen by the reader - seems reasonable but has a
couple of consequences:
    - first you now have to be able to obtain the write lock with a priority
above that of other waiting writers;
    - second it only works if you have one upgrader, otherwise the atomicity
is gone.

    If upgrading doesn't give you atomicity then it buys you very little
over releasing the read lock and acquiring the write lock.

    David
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jianhao Mo
      Sent: Monday, 17 September 2012 11:52 AM
      To: Vitaly Davidovich
      Cc: concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] UpgradeableRead lock like
ReaderWriterLockSlim in C#


      Yes, there is lock contention.
      Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490


      On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich <vitalyd at gmail.com>
wrote:

        Do you mean if the double check after acquiring the write lock is
expensive?

        If you had .NET's rw lock, it would only allow one thread to be in
upgradeable mode - are all of your threads possible writers? If so, wouldn't
you get lock contention?

        Maybe you can provide a bit more detail on what you're trying to do
and perhaps a better approach will emerge.

        Vitaly

        Sent from my phone

        On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com> wrote:

          if the read operation is time consuming, would upgrade be worth ?
          I am trying to optimize a hadoop namenode which manage 2000+
datanodes.


          2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>



              Yes that's true, but in my experience the double check hasn't
bothered me.


            Me either... but you have to know/remember about it. R/W Lock is
quite poor as even the readers have to alter the shared state. I have not
checked the recent source of it but it was (is?) 'hackable' by storing the
Thread.getId() as identifier... the latter can be overridden.

            Stanimir


              On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
<stanimir at riflexo.com> wrote:

                If you release the read lock and then obtain the write lock,
you have to check again the conditions under the write lock as they might
have been altered meanwhile.
                With upgrading there is no need since it's guaranteed no
other writes have been messing the state.

                Stanimir


                On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich
<vitalyd at gmail.com> wrote:

                  Hi Hal,

                  I've never really found the upgrade feature all that
useful in .Net.  Its main purpose, AFAIK, is to avoid deadlock.  However,
with Java's RRWL you simply release the read lock and try to acquire the
write lock.  Assuming you have mostly readers (or else why use RRWL?) I
don't think the upgrade feature buys much.  Downgrading is supported though,
which seems more useful.

                  Perhaps you can elaborate a bit more on why you'd like the
upgrade aspect?

                  Thanks

                  Sent from my phone

                  On Sep 13, 2012 6:15 AM, "Jianhao Mo"
<mojianhao at gmail.com> wrote:

                    Hi all,


                    I wondering Is there any  UpgradeableRead lock in java
similar to ReaderWriterLockSlim in C#
                    (http://msdn.microsoft.com/en-us/library/system.threadin
g.readerwriterlockslim.aspx).


                    For now, I try to use two ReentrantReadWriteLock to
simulate the  ReaderWriterLockSlim. Is there any better solution?


                    like these:
                      void readLock() {
                        this.rw.readLock().lock();
                      }


                      void readUnlock() {
                        this.rw.readLock().unlock();
                      }


                      void writeLock() {
                        this.up.writeLock().lock();
                        this.rw.writeLock().lock();
                      }


                      void writeUnlock() {
                        this.rw.writeLock().unlock();
                        this.up.writeLock().unlock();
                      }


                      boolean hasWriteLock() {
                        return this.rw.isWriteLockedByCurrentThread();
                      }


                      void  UpgradeableReadLock() {
                        this.up.writeLock().lock();
                      }


                      void Upgrade() {
                        this.rw.writeLock().lock();
                      }


                      void  UpgradeableUnlock() {
                        if (hasWriteLock()) {
                          this.rw.writeLock().unlock();
                        }
                        this.up.writeLock().unlock();
                      }




                    Regards,


                    Hal Mo


                    _______________________________________________
                    Concurrency-interest mailing list
                    Concurrency-interest at cs.oswego.edu
                    http://cs.oswego.edu/mailman/listinfo/concurrency-intere
st



                  _______________________________________________
                  Concurrency-interest mailing list
                  Concurrency-interest at cs.oswego.edu
                  http://cs.oswego.edu/mailman/listinfo/concurrency-interest











-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/1174d76a/attachment.html>

From davidcholmes at aapt.net.au  Mon Sep 17 22:02:27 2012
From: davidcholmes at aapt.net.au (David Holmes)
Date: Tue, 18 Sep 2012 12:02:27 +1000
Subject: [concurrency-interest] UpgradeableRead lock
	likeReaderWriterLockSlim in C#
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIEPDJGAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCIEPEJGAA.davidcholmes@aapt.net.au>

Sorry I misunderstood how the API was to be used. I was working from the
assumption that a potential upgrader starts as a reader and then attempts to
upgrade - which would not cause the update to be atomic with respect to the
read unless extra constraints were imposed. But in this API the upgrader
starts with an upgradeable read lock (in this case lock1.writelock) which
precludes all other writers and upgraders from "barging" past.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of David Holmes
  Sent: Tuesday, 18 September 2012 11:41 AM
  To: Jianhao Mo
  Cc: concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] UpgradeableRead lock
likeReaderWriterLockSlim in C#


  The atomicity is with respect to the read. The upgrader only has atomicity
after upgrading, by which time other writers or upgraders may have changed
the state from that which the upgrader had last seen.

  David
    -----Original Message-----
    From: Jianhao Mo [mailto:mojianhao at gmail.com]
    Sent: Tuesday, 18 September 2012 11:24 AM
    To: dholmes at ieee.org
    Cc: concurrency-interest at cs.oswego.edu
    Subject: Re: [concurrency-interest] UpgradeableRead lock like
ReaderWriterLockSlim in C#


    >>upgrading doesn't give you atomicity
    I believe atomic is insure by lock1, upgrading thread already has lock
lock1.writelock. other waiting writers must wait until the upgrading
finished and unlocked.


    On Mon, Sep 17, 2012 at 11:25 AM, David Holmes
<davidcholmes at aapt.net.au> wrote:

      I'm going back to the question of what upgrading is supposed to get
you? The problem with upgradeable read locks is establishing semantics that
are generally useful. The simple case is that you want the write to be
atomic with respect to the state seen by the reader - seems reasonable but
has a couple of consequences:
      - first you now have to be able to obtain the write lock with a
priority above that of other waiting writers;
      - second it only works if you have one upgrader, otherwise the
atomicity is gone.

      If upgrading doesn't give you atomicity then it buys you very little
over releasing the read lock and acquiring the write lock.

      David
        -----Original Message-----
        From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Jianhao Mo
        Sent: Monday, 17 September 2012 11:52 AM
        To: Vitaly Davidovich
        Cc: concurrency-interest at cs.oswego.edu
        Subject: Re: [concurrency-interest] UpgradeableRead lock like
ReaderWriterLockSlim in C#


        Yes, there is lock contention.
        Here is the detail: https://issues.apache.org/jira/browse/HDFS-2490


        On Fri, Sep 14, 2012 at 8:36 PM, Vitaly Davidovich
<vitalyd at gmail.com> wrote:

          Do you mean if the double check after acquiring the write lock is
expensive?

          If you had .NET's rw lock, it would only allow one thread to be in
upgradeable mode - are all of your threads possible writers? If so, wouldn't
you get lock contention?

          Maybe you can provide a bit more detail on what you're trying to
do and perhaps a better approach will emerge.

          Vitaly

          Sent from my phone

          On Sep 13, 2012 12:25 PM, "Jianhao Mo" <mojianhao at gmail.com>
wrote:

            if the read operation is time consuming, would upgrade be worth
?
            I am trying to optimize a hadoop namenode which manage 2000+
datanodes.


            2012/9/14 Stanimir Simeonoff <stanimir at riflexo.com>



                Yes that's true, but in my experience the double check
hasn't bothered me.


              Me either... but you have to know/remember about it. R/W Lock
is quite poor as even the readers have to alter the shared state. I have not
checked the recent source of it but it was (is?) 'hackable' by storing the
Thread.getId() as identifier... the latter can be overridden.

              Stanimir


                On Sep 13, 2012 11:18 AM, "Stanimir Simeonoff"
<stanimir at riflexo.com> wrote:

                  If you release the read lock and then obtain the write
lock, you have to check again the conditions under the write lock as they
might have been altered meanwhile.
                  With upgrading there is no need since it's guaranteed no
other writes have been messing the state.

                  Stanimir


                  On Thu, Sep 13, 2012 at 5:08 PM, Vitaly Davidovich
<vitalyd at gmail.com> wrote:

                    Hi Hal,

                    I've never really found the upgrade feature all that
useful in .Net.  Its main purpose, AFAIK, is to avoid deadlock.  However,
with Java's RRWL you simply release the read lock and try to acquire the
write lock.  Assuming you have mostly readers (or else why use RRWL?) I
don't think the upgrade feature buys much.  Downgrading is supported though,
which seems more useful.

                    Perhaps you can elaborate a bit more on why you'd like
the upgrade aspect?

                    Thanks

                    Sent from my phone

                    On Sep 13, 2012 6:15 AM, "Jianhao Mo"
<mojianhao at gmail.com> wrote:

                      Hi all,


                      I wondering Is there any  UpgradeableRead lock in java
similar to ReaderWriterLockSlim in C#
                      (http://msdn.microsoft.com/en-us/library/system.thread
ing.readerwriterlockslim.aspx).


                      For now, I try to use two ReentrantReadWriteLock to
simulate the  ReaderWriterLockSlim. Is there any better solution?


                      like these:
                        void readLock() {
                          this.rw.readLock().lock();
                        }


                        void readUnlock() {
                          this.rw.readLock().unlock();
                        }


                        void writeLock() {
                          this.up.writeLock().lock();
                          this.rw.writeLock().lock();
                        }


                        void writeUnlock() {
                          this.rw.writeLock().unlock();
                          this.up.writeLock().unlock();
                        }


                        boolean hasWriteLock() {
                          return this.rw.isWriteLockedByCurrentThread();
                        }


                        void  UpgradeableReadLock() {
                          this.up.writeLock().lock();
                        }


                        void Upgrade() {
                          this.rw.writeLock().lock();
                        }


                        void  UpgradeableUnlock() {
                          if (hasWriteLock()) {
                            this.rw.writeLock().unlock();
                          }
                          this.up.writeLock().unlock();
                        }




                      Regards,


                      Hal Mo


                      _______________________________________________
                      Concurrency-interest mailing list
                      Concurrency-interest at cs.oswego.edu
                      http://cs.oswego.edu/mailman/listinfo/concurrency-inte
rest



                    _______________________________________________
                    Concurrency-interest mailing list
                    Concurrency-interest at cs.oswego.edu
                    http://cs.oswego.edu/mailman/listinfo/concurrency-intere
st











-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/79c8f2f7/attachment-0001.html>

From simeon.malchev at gmail.com  Mon Sep 17 23:47:27 2012
From: simeon.malchev at gmail.com (Simeon Malchev)
Date: Tue, 18 Sep 2012 13:47:27 +1000
Subject: [concurrency-interest] Is LinkedTransferQueue fair with respect to
	consumers?
Message-ID: <CAF6dGoBAacCMwYfh-tM-j4+TfhXpLie5w3=Ozw=0njjLdEz11A@mail.gmail.com>

Hi Everyone,

I'm trying to understand is LinkedTransferQueue from Java SE 7 fair with
respect to consumers, i.e. with respect to waiting threads, in the same way
in which could be fair the Semaphore, ArrayBlockingQueue and
SynchronousQueue. The javadoc in LTQ says "This queue orders elements FIFO
(first-in-first-out) with respect to any given producer" however it doesn't
explicitly say whether the same applies to consumers. Based on this
post<http://cs.oswego.edu/pipermail/concurrency-interest/2009-February/005890.html>I
was thinking that LTQ is fair to consumers, however based on the
comments
in this test case<http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/jtreg/util/concurrent/BlockingQueue/ProducerConsumerLoops.java?view=co>,
I'm not so sure.

Will appreciate if someone could clarify.

Cheers,
Simeon
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/cfcc2c7c/attachment.html>

From Alexander.Berger at finnova.ch  Tue Sep 18 04:58:59 2012
From: Alexander.Berger at finnova.ch (Alexander.Berger at finnova.ch)
Date: Tue, 18 Sep 2012 10:58:59 +0200
Subject: [concurrency-interest] What are the plans for Fences.java
Message-ID: <8D57A051FA150A4CA0493D185DDAA855495EB56F3C@CHARON.SIDON.OLYMP>

Hi all,

What are the future plans for class j.u.c.a.Fences? Will it be dropped/replaced in favor of other APIs or will it be integrated into JDK8?

Regards,
Alex

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/d9f4495a/attachment.html>

From dl at cs.oswego.edu  Tue Sep 18 06:53:38 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 Sep 2012 06:53:38 -0400
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <CA+kOe081e+pSyTRAZ5B0Cr+hoZ5U+nsX1Jo5aEFzqsKmjdZfPg@mail.gmail.com>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com> <505729E7.8090208@oracle.com>
	<CA+kOe081e+pSyTRAZ5B0Cr+hoZ5U+nsX1Jo5aEFzqsKmjdZfPg@mail.gmail.com>
Message-ID: <505852B2.7080708@cs.oswego.edu>

On 09/17/12 14:46, Martin Buchholz wrote:
> I imagine
>
> boolean tryUpgrade()  @return true if only reader
>
> boolean upgrade() @return true if acquired write lock without some other
> intervening writer having acquired it
>
> I don't see any reason this couldn't be added to RRWL (except for the
> engineering effort!)
>

The main reason this wasn't done originally is that this
doesn't mesh with policies on reentrant holds, fairness
settings, and the separation of ReadLocks and WriteLocks
as separate objects. While some sort of answer might be
available for each of these issues,  the best move is still to
provide this functionality in a different style of RW-like
lock.

-Doug



From dl at cs.oswego.edu  Tue Sep 18 07:23:46 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 Sep 2012 07:23:46 -0400
Subject: [concurrency-interest] Is LinkedTransferQueue fair with respect
 to consumers?
In-Reply-To: <CAF6dGoBAacCMwYfh-tM-j4+TfhXpLie5w3=Ozw=0njjLdEz11A@mail.gmail.com>
References: <CAF6dGoBAacCMwYfh-tM-j4+TfhXpLie5w3=Ozw=0njjLdEz11A@mail.gmail.com>
Message-ID: <505859C2.4010208@cs.oswego.edu>

On 09/17/12 23:47, Simeon Malchev wrote:

> I'm trying to understand is LinkedTransferQueue from Java SE 7 fair with respect
> to consumers, i.e. with respect to waiting threads, in the same way in which
> could be fair the Semaphore, ArrayBlockingQueue and SynchronousQueue. The
> javadoc in LTQ says "This queue orders elements FIFO (first-in-first-out) with
> respect to any given producer" however it doesn't explicitly say whether the
> same applies to consumers.

I'm not sure what you are asking.

The main fairness spec here applies to both the producer
and consumer side. So for LinkedTransferQueue,
no consumer will take the elements from a given producer out
of order.

If you are asking whether the elements from a given producer
are guaranteed to be equally (or otherwise fairly) distributed
across all consumers, the answer is no -- it is possible for
example for a fast consumer to take multiple elements while
slow ones are still in the process of waking up and trying
to take one.

> however based on the comments in
> this test case
> <http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/jtreg/util/concurrent/BlockingQueue/ProducerConsumerLoops.java?view=co>,
> I'm not so sure.
>

That test includes fairness setting only to ensure that it is run
in both fair and unfair modes on those queues with explicit
fairness parameters. It doesn't otherwise test fairness properties.

-Doug





From simeon.malchev at gmail.com  Tue Sep 18 08:13:17 2012
From: simeon.malchev at gmail.com (Simeon Malchev)
Date: Tue, 18 Sep 2012 22:13:17 +1000
Subject: [concurrency-interest] Is LinkedTransferQueue fair with respect
 to consumers?
In-Reply-To: <505859C2.4010208@cs.oswego.edu>
References: <CAF6dGoBAacCMwYfh-tM-j4+TfhXpLie5w3=Ozw=0njjLdEz11A@mail.gmail.com>
	<505859C2.4010208@cs.oswego.edu>
Message-ID: <CAF6dGoAtq9P=eEiYUx9QcB9tB+U6tvkF97WOLHu1VwjGG3BDVA@mail.gmail.com>

Thanks for replying Doug.

I guess the question I was trying to ask was, lets say the LTQ is empty and
there are 5 consumer threads (th1, ..., th5) which are calling take() or
timed poll() in moments of time t1, t2, .., t5 where t1<t2<...<t5. Than at
time t6>t5 a producer thread adds 5 messages (objects) to the queue. The
question was, is it guaranteed that the first object added to the queue
will be consumed (taken) by th1, the second by th2, and so on until the
fifth is taken by th5?

Sorry that I couldn't make it more clear the first time I asked.

Cheers,
Simeon


On Tue, Sep 18, 2012 at 9:23 PM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/17/12 23:47, Simeon Malchev wrote:
>
>  I'm trying to understand is LinkedTransferQueue from Java SE 7 fair with
>> respect
>> to consumers, i.e. with respect to waiting threads, in the same way in
>> which
>> could be fair the Semaphore, ArrayBlockingQueue and SynchronousQueue. The
>> javadoc in LTQ says "This queue orders elements FIFO (first-in-first-out)
>> with
>> respect to any given producer" however it doesn't explicitly say whether
>> the
>> same applies to consumers.
>>
>
> I'm not sure what you are asking.
>
> The main fairness spec here applies to both the producer
> and consumer side. So for LinkedTransferQueue,
> no consumer will take the elements from a given producer out
> of order.
>
> If you are asking whether the elements from a given producer
> are guaranteed to be equally (or otherwise fairly) distributed
> across all consumers, the answer is no -- it is possible for
> example for a fast consumer to take multiple elements while
> slow ones are still in the process of waking up and trying
> to take one.
>
>  however based on the comments in
>> this test case
>> <http://gee.cs.oswego.edu/cgi-**bin/viewcvs.cgi/jsr166/src/**
>> test/jtreg/util/concurrent/**BlockingQueue/**ProducerConsumerLoops.java?*
>> *view=co<http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/jtreg/util/concurrent/BlockingQueue/ProducerConsumerLoops.java?view=co>
>> >,
>>
>> I'm not so sure.
>>
>>
> That test includes fairness setting only to ensure that it is run
> in both fair and unfair modes on those queues with explicit
> fairness parameters. It doesn't otherwise test fairness properties.
>
> -Doug
>
>
>
>
> ______________________________**_________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.**oswego.edu <Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/**listinfo/concurrency-interest<http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120918/0aa76bb7/attachment.html>

From dl at cs.oswego.edu  Tue Sep 18 08:58:49 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 18 Sep 2012 08:58:49 -0400
Subject: [concurrency-interest] Is LinkedTransferQueue fair with respect
 to consumers?
In-Reply-To: <CAF6dGoAtq9P=eEiYUx9QcB9tB+U6tvkF97WOLHu1VwjGG3BDVA@mail.gmail.com>
References: <CAF6dGoBAacCMwYfh-tM-j4+TfhXpLie5w3=Ozw=0njjLdEz11A@mail.gmail.com>
	<505859C2.4010208@cs.oswego.edu>
	<CAF6dGoAtq9P=eEiYUx9QcB9tB+U6tvkF97WOLHu1VwjGG3BDVA@mail.gmail.com>
Message-ID: <50587009.90403@cs.oswego.edu>

On 09/18/12 08:13, Simeon Malchev wrote:
> I guess the question I was trying to ask was, lets say the LTQ is empty and
> there are 5 consumer threads (th1, ..., th5) which are calling take() or timed
> poll() in moments of time t1, t2, .., t5 where t1<t2<...<t5. Than at time t6>t5
> a producer thread adds 5 messages (objects) to the queue. The question was, is
> it guaranteed that the first object added to the queue will be consumed (taken)
> by th1, the second by th2, and so on until the fifth is taken by th5?
>

Not in general. If for example, th1 is performing looping takes,
it may take two elements before thr2 even takes one. If you do
need to ensure this, you might use a Phaser to force each consumer
to process one element and then wait for all the others to finish
processing theirs before continuing to take another.

Note that you'd need to do something like this even in
fully fair queues, because you cannot otherwise control the
rate at which each consumer proceeds to its take() operation
to start waiting for elements.

-Doug



From andrew_nuss at yahoo.com  Mon Sep 24 07:55:05 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 24 Sep 2012 04:55:05 -0700 (PDT)
Subject: [concurrency-interest] use of Thread.yield() in lockfree busywait
Message-ID: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>

Hi,

I was wondering.? Lets say a lockfree style critical section must be entered.? But the busyloop CAS that controls entering the critical section has failed several times in a row.? Should Thread.yield() be called in that case?? If so, what would be a reasonable number of failed attempts before calling Thread.yield()?

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/43c014ff/attachment.html>

From david.lloyd at redhat.com  Mon Sep 24 08:10:14 2012
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Mon, 24 Sep 2012 07:10:14 -0500
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
Message-ID: <50604DA6.3000502@redhat.com>

On 09/24/2012 06:55 AM, Andy Nuss wrote:
> Hi,
>
> I was wondering.  Lets say a lockfree style critical section must be
> entered.  But the busyloop CAS that controls entering the critical
> section has failed several times in a row.  Should Thread.yield() be
> called in that case?  If so, what would be a reasonable number of failed
> attempts before calling Thread.yield()?

I would say "no".  It makes more sense to go right to park/unpark in 
this case because the cost is (I believe?) roughly the same on UNIXy 
platforms (either way you're getting descheduled), but at the same time 
you're never falsely rescheduled.  Cliff Click had a good writeup about 
it: http://is.gd/xLGZSV

-- 
- DML



From rk at rkuhn.info  Mon Sep 24 08:29:14 2012
From: rk at rkuhn.info (Roland Kuhn)
Date: Mon, 24 Sep 2012 14:29:14 +0200
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <50604DA6.3000502@redhat.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com>
Message-ID: <A3096947-E90C-404B-A0A0-10C3F8F97D40@rkuhn.info>


24 sep 2012 kl. 14:10 skrev David M. Lloyd:

> On 09/24/2012 06:55 AM, Andy Nuss wrote:
>> Hi,
>> 
>> I was wondering.  Lets say a lockfree style critical section must be
>> entered.  But the busyloop CAS that controls entering the critical
>> section has failed several times in a row.  Should Thread.yield() be
>> called in that case?  If so, what would be a reasonable number of failed
>> attempts before calling Thread.yield()?
> 
Of course it depends on what exactly the CAS loop is doing, but in most cases a failure means that someone else has made progress, so there should be no large numbers of repeated failures (with the notable exception of waiting for the var to change into a specific state). If all you do is read-calculateUpdate-CAS loops, I think its unlikely to really have the problem you describe.

> I would say "no".  It makes more sense to go right to park/unpark in this case because the cost is (I believe?) roughly the same on UNIXy platforms (either way you're getting descheduled), but at the same time you're never falsely rescheduled.  Cliff Click had a good writeup about it: http://is.gd/xLGZSV
> 
I?d go as far as saying that Thread.yield() should not ever be called, for anything. What are you yielding to? How is the kernel supposed to know what you are waiting for?

Regards,

Roland

--
I'm a physicist: I have a basic working knowledge of the universe and everything it contains!
    - Sheldon Cooper (The Big Bang Theory)



From vitalyd at gmail.com  Mon Sep 24 08:37:31 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 24 Sep 2012 08:37:31 -0400
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
Message-ID: <CAHjP37HffyC2SgJvd7P9pWHrpSoKLjUB9zk2LTQvFG61k2nfqg@mail.gmail.com>

As David mentioned, it's going to be somewhat brittle to use yield.  First,
you'll have to figure out what the JVM does with that call on the OS you're
supporting.

Second, you'll need to pick a spin value that you may have to determine via
experimentation and then it'll be dependent on processor/hw, how much load
is on the machine, etc.  Alternative, is you dynamically adjust spin count,
which has its own set of issues.

Third, you need to understand why CAS is failing repeatedly and moreover,
why yielding would likely put the "required" thread onproc for your
original one to make progress.  This requires knowing about the type of
hardware, OS, and machine load that you're anticipating.

Basically, it's going to be very difficult to make this profitable (with
respect to parking) and reliable.  So, I'd try really hard to stay away
unless you have really good reason to believe that it's worth it.

Sent from my phone
On Sep 24, 2012 7:59 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> Hi,
>
> I was wondering.  Lets say a lockfree style critical section must be
> entered.  But the busyloop CAS that controls entering the critical section
> has failed several times in a row.  Should Thread.yield() be called in that
> case?  If so, what would be a reasonable number of failed attempts before
> calling Thread.yield()?
>
> Andy
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/fdc727aa/attachment.html>

From dl at cs.oswego.edu  Mon Sep 24 09:00:32 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 24 Sep 2012 09:00:32 -0400
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <50604DA6.3000502@redhat.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com>
Message-ID: <50605970.4030501@cs.oswego.edu>

On 09/24/12 08:10, David M. Lloyd wrote:
> On 09/24/2012 06:55 AM, Andy Nuss wrote:
>> Hi,
>>
>> I was wondering.  Lets say a lockfree style critical section must be
>> entered.  But the busyloop CAS that controls entering the critical
>> section has failed several times in a row.  Should Thread.yield() be
>> called in that case?  If so, what would be a reasonable number of failed
>> attempts before calling Thread.yield()?
>
> I would say "no".  It makes more sense to go right to park/unpark in this case
> because the cost is (I believe?) roughly the same on UNIXy platforms (either way
> you're getting descheduled), but at the same time you're never falsely
> rescheduled.  Cliff Click had a good writeup about it: http://is.gd/xLGZSV
>

I like this answer because it assumes that you are using a
spin-then-block design. This is almost always best when you can do it.
Nearly all internals of j.u.c do this. So we don't use yield() very
often, and when we do, it is because of some particular nichy
tradeoff.

However, in situations where you cannot block, and in
which there is potentially a lot of update (CAS) contention,
you do need some backoff-based relief of memory thrashing
and contention. There's a range of techniques for
memory contention reduction, from localizing spin targets,
up through actual sleeps. In some cases, yield() is a
sensible part of a backoff, because it encourages OS
schedulers to waste fewer resources when a system
has many active threads. But even here, it is challenging
to find values and frequencies that work well on enough
different systems to commit to. (So whenever we do so inside
j.u.c, we do as much testing on as many platforms as possible.)

-Doug




From andrew_nuss at yahoo.com  Mon Sep 24 09:40:26 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 24 Sep 2012 06:40:26 -0700 (PDT)
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com> <50605970.4030501@cs.oswego.edu>
	<1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>

I had 2 cases, one as described where the critical section was a single program wide singleton, and involved a little bit of magic with something like a red-black tree.? Thus the critical section could be quite a few nanos, and I worry that its a program wide singleton critical section.? Ok. Thread.yield() is broken.? But isn't park/unpark not available to tomcat loaded libraries?? Also, where do I find a good writeup on how to use park/unpark?


Another similar case is a little different: there are many readers and just a few infrequent writers to a lock free datastructure.? The writers compete to gain first access to atomically do a quite costly operation that involves creating big arrays on the heap, and copying the old arrays to the new arrays.? When the 2nd writer in the race condition sees that another writer is already in progress with this costly operation, he wants to wait until it is likely to be done, but hopefully without a tight spin, hence I thought Thread.yield was appropriate.? What exactly would the util.concurrent classes do in this case?? It is much more important to solve this case properly than the case I originally described.



________________________________
 From: Doug Lea <dl at cs.oswego.edu>
To: concurrency-interest at cs.oswego.edu 
Sent: Monday, September 24, 2012 6:00 AM
Subject: Re: [concurrency-interest] use of Thread.yield() in lockfree busywait
 
On 09/24/12 08:10, David M. Lloyd wrote:
> On 09/24/2012 06:55 AM, Andy Nuss wrote:
>> Hi,
>>
>> I was wondering.? Lets say a lockfree style critical section must be
>> entered.? But the busyloop CAS that controls entering the critical
>> section has failed several times in a row.? Should Thread.yield() be
>> called in that case?? If so, what would be a reasonable number of failed
>> attempts before calling Thread.yield()?
>
> I would say "no".? It makes more sense to go right to park/unpark in this case
> because the cost is (I believe?) roughly the same on UNIXy platforms (either way
> you're getting descheduled), but at the same time you're never falsely
> rescheduled.? Cliff Click had a good writeup about it: http://is.gd/xLGZSV
>

I like this answer because it assumes that you are using a
spin-then-block
 design. This is almost always best when you can do it.
Nearly all internals of j.u.c do this. So we don't use yield() very
often, and when we do, it is because of some particular nichy
tradeoff.

However, in situations where you cannot block, and in
which there is potentially a lot of update (CAS) contention,
you do need some backoff-based relief of memory thrashing
and contention. There's a range of techniques for
memory contention reduction, from localizing spin targets,
up through actual sleeps. In some cases, yield() is a
sensible part of a backoff, because it encourages OS
schedulers to waste fewer resources when a system
has many active threads. But even here, it is challenging
to find values and frequencies that work well on enough
different systems to commit to. (So whenever we do so inside
j.u.c, we do as much testing on as many platforms as
 possible.)

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/2d66f441/attachment-0001.html>

From dl at cs.oswego.edu  Mon Sep 24 09:49:43 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Mon, 24 Sep 2012 09:49:43 -0400
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com> <50605970.4030501@cs.oswego.edu>
	<1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <506064F7.3040900@cs.oswego.edu>

On 09/24/12 09:32, Andy Nuss wrote:
> I had 2 cases, one as described where the critical section was a single
> program wide singleton, and involved a little bit of magic with something
> like a red-black tree.  Thus the critical section could be quite a few nanos,
> and I worry that its a program wide singleton critical section.  Ok.
> Thread.yield() is broken.  But isn't park/unpark not available to tomcat
> loaded libraries?  Also, where do I find a good writeup on how to use
> park/unpark?

I should have mentioned that one-shot initialization
races are usually a fine place for yield(). We do this in j.u.c.
(for example in JDK8 ConcurrentHashMap(V8).)

park/unpark are available in j.u.c.locks.LockSupport. However,
they all only apply to designs where you record waiters so
can signal/unpark them.


>
> Another similar case is a little different: there are many readers and just
> a few infrequent writers to a lock free datastructure.  The writers compete
> to gain first access to atomically do a quite costly operation that involves
> creating big arrays on the heap, and copying the old arrays to the new
> arrays. When the 2nd writer in the race condition sees that another writer is
> already in progress with this costly operation, he wants to wait until it is
> likely to be done, but hopefully without a tight spin, hence I thought
> Thread.yield was appropriate.

You might use an actual lock accessed by writers, but still
keep the data structure accessible to readers with an
optimistic scheme. This is yet another place where the
hopefully-upcoming StampedLock might be handy.

-Doug


From rco at quartetfs.com  Mon Sep 24 10:08:41 2012
From: rco at quartetfs.com (Romain Colle)
Date: Mon, 24 Sep 2012 16:08:41 +0200
Subject: [concurrency-interest] Memory ordering and conditional operators
Message-ID: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>

Hi all,

Following some previous posts, we are still struggling for, somehow,
applying some fences when none are available ...

I was looking at a previous post in this list by Hans Boehm stating that
optimistic versioned reads using seq_locks were currently not possible in
Java.
http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html

The example looked like this:
> initial_version = version;
> read_a_bunch_of_stuff;
> final_version = version;

I'm assuming the main issue is that if the "bunch of stuff" that are being
read are not volatile, it can be re-ordered after the final version read
and break the whole idea of checking the version after read.

I was therfore wondering if conditional operators could be used to provide
the required fencing.
Assuming a sequence lock where an even number means unlocked and an odd
number means locked, could we have the following piece of code working?

int seq;
if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() &&
seqLock.getSequence() == seq)
  // success!

I'm guessing that this probably does not work since it would be plastered
all over the internet otherwise, but could you explain what the issue would
be?
I undertsand we probably do not have the correct happens-before
relationship, but I would have guessed the conditional && operator would
force the reads to happen in the correct order.

Thanks a lot for your feedback,

-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/68fb361d/attachment.html>

From andrew_nuss at yahoo.com  Mon Sep 24 10:12:20 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 24 Sep 2012 07:12:20 -0700 (PDT)
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <506064F7.3040900@cs.oswego.edu>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com> <50605970.4030501@cs.oswego.edu>
	<1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506064F7.3040900@cs.oswego.edu>
Message-ID: <1348495940.68722.YahooMailNeo@web120302.mail.ne1.yahoo.com>

I studied the blog just mentioned about the gotchas of Thread.yield() for busy waiting until something is done, and the better alternative to sleep for a microsecond, with some exponential backoff if the critical section is still not attainable.

The solution I assume is to use Thread.sleep(0, 1000*backoff_exponent).? But then, can you throw away the InterruptedException?? I would hate for my entire library to be contaminated with InterruptedException versus the alternative simple synchronized(mutex) of Thread.yield().


Likewise with LockSupport.? If you have to signal to unpark the parked threads, that sounds both complex and like it contaminates the entire library with InterruptedException even worse than Thread.sleep(0,1000).

And I saw some expert on this mailing list say "never eat InterruptedExceptions".



________________________________
 From: Doug Lea <dl at cs.oswego.edu>
To: concurrency-interest at cs.oswego.edu 
Sent: Monday, September 24, 2012 6:49 AM
Subject: Re: [concurrency-interest] use of Thread.yield() in lockfree busywait
 
On 09/24/12 09:32, Andy Nuss wrote:
> I had 2 cases, one as described where the critical section was a single
> program wide singleton, and involved a little bit of magic with something
> like a red-black tree.? Thus the critical section could be quite a few nanos,
> and I worry that its a program wide singleton critical section.? Ok.
> Thread.yield() is broken.? But isn't park/unpark not available to tomcat
> loaded libraries?? Also, where do I find a good writeup on how to use
> park/unpark?

I should have mentioned that one-shot initialization
races are usually a fine place for yield(). We do this in j.u.c.
(for example in JDK8 ConcurrentHashMap(V8).)

park/unpark are available in j.u.c.locks.LockSupport. However,
they all only apply to designs where you record waiters so
can signal/unpark them.


>
> Another similar case is a little different: there are many readers and just
> a few infrequent writers to a lock free datastructure.? The writers compete
> to gain first access to atomically do a quite costly operation that involves
> creating big arrays on the heap, and copying the old arrays to the new
> arrays. When the 2nd writer in the race condition sees that another writer is
> already in progress with this costly operation, he wants to wait until it is
> likely to be done, but hopefully without a tight spin, hence I thought
> Thread.yield was appropriate.

You might use an actual lock accessed by writers, but still
keep the data structure accessible to readers with an
optimistic scheme. This is yet another place where the
hopefully-upcoming StampedLock might be handy.

-Doug

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/652cf33f/attachment.html>

From vitalyd at gmail.com  Mon Sep 24 10:25:44 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 24 Sep 2012 10:25:44 -0400
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com> <50605970.4030501@cs.oswego.edu>
	<1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <CAHjP37FdRs89556ZGY062pSRfqicb0gpGR+Gx=1pq1=4sBHynA@mail.gmail.com>

What would the "losing" writer do when it sees the new arrays? Can you
abort the write and do it later (without spin waiting)? Does your process
"own" the machine or is it shared? Do you have spare CPU?

Sent from my phone
On Sep 24, 2012 9:49 AM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> I had 2 cases, one as described where the critical section was a single
> program wide singleton, and involved a little bit of magic with something
> like a red-black tree.  Thus the critical section could be quite a few
> nanos, and I worry that its a program wide singleton critical section.  Ok.
> Thread.yield() is broken.  But isn't park/unpark not available to tomcat
> loaded libraries?  Also, where do I find a good writeup on how to use
> park/unpark?
>
> Another similar case is a little different: there are many readers and
> just a few infrequent writers to a lock free datastructure.  The writers
> compete to gain first access to atomically do a quite costly operation that
> involves creating big arrays on the heap, and copying the old arrays to the
> new arrays.  When the 2nd writer in the race condition sees that another
> writer is already in progress with this costly operation, he wants to wait
> until it is likely to be done, but hopefully without a tight spin, hence I
> thought Thread.yield was appropriate.  What exactly would the
> util.concurrent classes do in this case?  It is much more important to
> solve this case properly than the case I originally described.
>
>   ------------------------------
> *From:* Doug Lea <dl at cs.oswego.edu>
> *To:* concurrency-interest at cs.oswego.edu
> *Sent:* Monday, September 24, 2012 6:00 AM
> *Subject:* Re: [concurrency-interest] use of Thread.yield() in lockfree
> busywait
>
> On 09/24/12 08:10, David M. Lloyd wrote:
> > On 09/24/2012 06:55 AM, Andy Nuss wrote:
> >> Hi,
> >>
> >> I was wondering.  Lets say a lockfree style critical section must be
> >> entered.  But the busyloop CAS that controls entering the critical
> >> section has failed several times in a row.  Should Thread.yield() be
> >> called in that case?  If so, what would be a reasonable number of failed
> >> attempts before calling Thread.yield()?
> >
> > I would say "no".  It makes more sense to go right to park/unpark in
> this case
> > because the cost is (I believe?) roughly the same on UNIXy platforms
> (either way
> > you're getting descheduled), but at the same time you're never falsely
> > rescheduled.  Cliff Click had a good writeup about it:
> http://is.gd/xLGZSV
> >
>
> I like this answer because it assumes that you are using a
> spin-then-block design. This is almost always best when you can do it.
> Nearly all internals of j.u.c do this. So we don't use yield() very
> often, and when we do, it is because of some particular nichy
> tradeoff.
>
> However, in situations where you cannot block, and in
> which there is potentially a lot of update (CAS) contention,
> you do need some backoff-based relief of memory thrashing
> and contention. There's a range of techniques for
> memory contention reduction, from localizing spin targets,
> up through actual sleeps. In some cases, yield() is a
> sensible part of a backoff, because it encourages OS
> schedulers to waste fewer resources when a system
> has many active threads. But even here, it is challenging
> to find values and frequencies that work well on enough
> different systems to commit to. (So whenever we do so inside
> j.u.c, we do as much testing on as many platforms as possible.)
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/c387742b/attachment-0001.html>

From mr.chrisvest at gmail.com  Mon Sep 24 10:25:48 2012
From: mr.chrisvest at gmail.com (Chris Vest)
Date: Mon, 24 Sep 2012 16:25:48 +0200
Subject: [concurrency-interest] use of Thread.yield() in lockfree
	busywait
In-Reply-To: <1348495940.68722.YahooMailNeo@web120302.mail.ne1.yahoo.com>
References: <1348487705.51547.YahooMailNeo@web120305.mail.ne1.yahoo.com>
	<50604DA6.3000502@redhat.com> <50605970.4030501@cs.oswego.edu>
	<1348493545.14576.YahooMailNeo@web120302.mail.ne1.yahoo.com>
	<1348494026.51371.YahooMailNeo@web120304.mail.ne1.yahoo.com>
	<506064F7.3040900@cs.oswego.edu>
	<1348495940.68722.YahooMailNeo@web120302.mail.ne1.yahoo.com>
Message-ID: <CAHXi_0egj1CejZy_UpsWj2yoW0qv55F0hxXeKtMOTkfmby7EVg@mail.gmail.com>

On 24 September 2012 16:12, Andy Nuss <andrew_nuss at yahoo.com> wrote:

> I studied the blog just mentioned about the gotchas of Thread.yield() for
> busy waiting until something is done, and the better alternative to sleep
> for a microsecond, with some exponential backoff if the critical section is
> still not attainable.
>
> The solution I assume is to use Thread.sleep(0, 1000*backoff_exponent).
> But then, can you throw away the InterruptedException?  I would hate for my
> entire library to be contaminated with InterruptedException versus the
> alternative simple synchronized(mutex) of Thread.yield().
>

You can catch the InterruptedException and handle it by interrupting
yourself. Just don't try to redo the thing that was interrupted --
interruption means someone wants you to wrap up whatever you were doing,
and return control.


>
> Likewise with LockSupport.  If you have to signal to unpark the parked
> threads, that sounds both complex and like it contaminates the entire
> library with InterruptedException even worse than Thread.sleep(0,1000).
>

You can LockSupport.parkNanos (with a timeout) if all you want is to wait a
little bit. The parked thread will eventually awaken even if nobody unparks
it.


>
> And I saw some expert on this mailing list say "never eat
> InterruptedExceptions".
>
>   ------------------------------
> *From:* Doug Lea <dl at cs.oswego.edu>
> *To:* concurrency-interest at cs.oswego.edu
> *Sent:* Monday, September 24, 2012 6:49 AM
>
> *Subject:* Re: [concurrency-interest] use of Thread.yield() in lockfree
> busywait
>
> On 09/24/12 09:32, Andy Nuss wrote:
> > I had 2 cases, one as described where the critical section was a single
> > program wide singleton, and involved a little bit of magic with something
> > like a red-black tree.  Thus the critical section could be quite a few
> nanos,
> > and I worry that its a program wide singleton critical section.  Ok.
> > Thread.yield() is broken.  But isn't park/unpark not available to tomcat
> > loaded libraries?  Also, where do I find a good writeup on how to use
> > park/unpark?
>
> I should have mentioned that one-shot initialization
> races are usually a fine place for yield(). We do this in j.u.c.
> (for example in JDK8 ConcurrentHashMap(V8).)
>
> park/unpark are available in j.u.c.locks.LockSupport. However,
> they all only apply to designs where you record waiters so
> can signal/unpark them.
>
>
> >
> > Another similar case is a little different: there are many readers and
> just
> > a few infrequent writers to a lock free datastructure.  The writers
> compete
> > to gain first access to atomically do a quite costly operation that
> involves
> > creating big arrays on the heap, and copying the old arrays to the new
> > arrays. When the 2nd writer in the race condition sees that another
> writer is
> > already in progress with this costly operation, he wants to wait until
> it is
> > likely to be done, but hopefully without a tight spin, hence I thought
> > Thread.yield was appropriate.
>
> You might use an actual lock accessed by writers, but still
> keep the data structure accessible to readers with an
> optimistic scheme. This is yet another place where the
> hopefully-upcoming StampedLock might be handy.
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/ec87bbed/attachment.html>

From zhong.j.yu at gmail.com  Mon Sep 24 13:47:47 2012
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Mon, 24 Sep 2012 12:47:47 -0500
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
Message-ID: <CACuKZqHvpsBsaWircgrmykPX2xfTNaLeyOopJNgjTv8VwhWzKA@mail.gmail.com>

On Mon, Sep 24, 2012 at 9:08 AM, Romain Colle <rco at quartetfs.com> wrote:
> Hi all,
>
> Following some previous posts, we are still struggling for, somehow,
> applying some fences when none are available ...
>
> I was looking at a previous post in this list by Hans Boehm stating that
> optimistic versioned reads using seq_locks were currently not possible in
> Java.
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html
>
> The example looked like this:
>> initial_version = version;
>> read_a_bunch_of_stuff;
>> final_version = version;
>
> I'm assuming the main issue is that if the "bunch of stuff" that are being
> read are not volatile, it can be re-ordered after the final version read and
> break the whole idea of checking the version after read.
>
> I was therfore wondering if conditional operators could be used to provide
> the required fencing.
> Assuming a sequence lock where an even number means unlocked and an odd
> number means locked, could we have the following piece of code working?
>
> int seq;
> if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() &&
> seqLock.getSequence() == seq)
>   // success!
>
> I'm guessing that this probably does not work since it would be plastered
> all over the internet otherwise, but could you explain what the issue would
> be?
> I undertsand we probably do not have the correct happens-before
> relationship, but I would have guessed the conditional && operator would
> force the reads to happen in the correct order.

You'll have to bet on VM not being smart enough. However it's quite
possible that VM sees that read_some_stuff() always returns true, so
it'll turn

    if(read_some_stuff())
       seqLock.getSequence() == seq

into

    read_some_stuff()
    seqLock.getSequence() == seq

back to square one.

My question though on Boehm's comment:

>Making all the reads in the middle volatile gives me SC, but this is often impractical, for both *performance* and software engineering reasons.

at least on x86, making the middle reads volatile doesn't incur any
performance penalty, right?


> Thanks a lot for your feedback,
>
> --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From andrew_nuss at yahoo.com  Mon Sep 24 14:17:23 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 24 Sep 2012 11:17:23 -0700 (PDT)
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
Message-ID: <1348510643.35972.YahooMailNeo@web120303.mail.ne1.yahoo.com>

I'm not sure, but it looks like if your variable "version" is volatile, your simple approach works.

I get this from http://www.ibm.com/developerworks/library/j-jtp03304/ article in "using volatile variable as a guard".? Brian Goetz states: "The JSR 133 Expert Group decided that it would be more
sensible for volatile reads and writes not to be reorderable with any
other memory operations -- to support precisely this and other similar
use cases".


________________________________
 From: Romain Colle <rco at quartetfs.com>
To: concurrency-interest at cs.oswego.edu 
Sent: Monday, September 24, 2012 7:08 AM
Subject: [concurrency-interest] Memory ordering and conditional operators
 

Hi all,

Following some previous posts, we are still struggling for, somehow, applying some fences when none are available ...

I was looking at a previous post in this list by Hans Boehm stating that optimistic versioned reads using seq_locks were currently not possible in Java.
http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html

The example looked like this:
> initial_version = version;
> read_a_bunch_of_stuff;
> final_version = version;

I'm assuming the main issue is that if the "bunch of stuff" that are being read are not volatile, it can be re-ordered after the final version read and break the whole idea of checking the version after read.

I was therfore wondering if conditional operators could be used to provide the required fencing.
Assuming a sequence lock where an even number means unlocked and an odd number means locked, could we have the following piece of code working?

int seq;
if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() && seqLock.getSequence() == seq)
? // success!

I'm guessing that this probably does not work since it would be plastered all over the internet otherwise, but could you explain what the issue would be?
I undertsand we probably do not have the correct happens-before relationship, but I would have guessed the conditional && operator would force the reads to happen in the correct order.

Thanks a lot for your feedback,
-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com/ 

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/8c61171e/attachment.html>

From vitalyd at gmail.com  Mon Sep 24 15:36:09 2012
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Mon, 24 Sep 2012 15:36:09 -0400
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <1348510643.35972.YahooMailNeo@web120303.mail.ne1.yahoo.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<1348510643.35972.YahooMailNeo@web120303.mail.ne1.yahoo.com>
Message-ID: <CAHjP37GvZ_HyacdQOdJjjuccag2m0OpjcwLAt1n4q85rmNq9ZQ@mail.gmail.com>

The problem is that a normal load followed by a volatile load is
re-orderable, which makes it possible for the final version read to happen
before the read_a_bunch_of_stuff.  On x86/64 this would only happen if
compiler rearranges stuff, but it's allowed to do so.

Also on x86/64 volatile loads are pretty cheap as it's just a compiler
barrier and if data being read is already in cache (especially L1), not
enregistering a read is probably negligible (the key is that a volatile
load does not, in and of itself, create a bubble in the pipeline, which
would be expensive).

Sent from my phone
On Sep 24, 2012 2:26 PM, "Andy Nuss" <andrew_nuss at yahoo.com> wrote:

> I'm not sure, but it looks like if your variable "version" is volatile,
> your simple approach works.
>
> I get this from http://www.ibm.com/developerworks/library/j-jtp03304/article in "using volatile variable as a guard".  Brian Goetz states: "The
> JSR 133 Expert Group decided that it would be more sensible for volatile
> reads and writes not to be reorderable with any other memory operations --
> to support precisely this and other similar use cases".
>
>   ------------------------------
> *From:* Romain Colle <rco at quartetfs.com>
> *To:* concurrency-interest at cs.oswego.edu
> *Sent:* Monday, September 24, 2012 7:08 AM
> *Subject:* [concurrency-interest] Memory ordering and conditional
> operators
>
> Hi all,
>
> Following some previous posts, we are still struggling for, somehow,
> applying some fences when none are available ...
>
> I was looking at a previous post in this list by Hans Boehm stating that
> optimistic versioned reads using seq_locks were currently not possible in
> Java.
>
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html
>
> The example looked like this:
> > initial_version = version;
> > read_a_bunch_of_stuff;
> > final_version = version;
>
> I'm assuming the main issue is that if the "bunch of stuff" that are being
> read are not volatile, it can be re-ordered after the final version read
> and break the whole idea of checking the version after read.
>
> I was therfore wondering if conditional operators could be used to provide
> the required fencing.
> Assuming a sequence lock where an even number means unlocked and an odd
> number means locked, could we have the following piece of code working?
>
> int seq;
> if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() &&
> seqLock.getSequence() == seq)
>   // success!
>
> I'm guessing that this probably does not work since it would be plastered
> all over the internet otherwise, but could you explain what the issue would
> be?
> I undertsand we probably do not have the correct happens-before
> relationship, but I would have guessed the conditional && operator would
> force the reads to happen in the correct order.
>
> Thanks a lot for your feedback,
>
> --
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com/
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/132d200d/attachment.html>

From hans.boehm at hp.com  Mon Sep 24 16:16:03 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 24 Sep 2012 20:16:03 +0000
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <CAHjP37GvZ_HyacdQOdJjjuccag2m0OpjcwLAt1n4q85rmNq9ZQ@mail.gmail.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<1348510643.35972.YahooMailNeo@web120303.mail.ne1.yahoo.com>
	<CAHjP37GvZ_HyacdQOdJjjuccag2m0OpjcwLAt1n4q85rmNq9ZQ@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235F7A7C7@G4W3296.americas.hpqcorp.net>

The paper on this is at http://dl.acm.org/citation.cfm?doid=2247684.2247688 or http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html .  These have a minor, trivially fixable, known bug in the writer code, but are otherwise more carefully  worked out than the earlier postings.

Conditionals often don't enforce load-load ordering, since machines commonly predict branches, and will reorder loads across correctly predicted branches.  Thus the conditional doesn't help here, even in a purely empirical sense, and ignoring clever compilation.

A normal load followed by a volatile load is reorderable because properly synchronized code can't tell the difference.  Seqlocks aren't "properly synchronized" in this sense.  The code isunfortunately inherently racy.

Hans

From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Vitaly Davidovich
Sent: Monday, September 24, 2012 12:36 PM
To: Andy Nuss
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] Memory ordering and conditional operators


The problem is that a normal load followed by a volatile load is re-orderable, which makes it possible for the final version read to happen before the read_a_bunch_of_stuff.  On x86/64 this would only happen if compiler rearranges stuff, but it's allowed to do so.

Also on x86/64 volatile loads are pretty cheap as it's just a compiler barrier and if data being read is already in cache (especially L1), not enregistering a read is probably negligible (the key is that a volatile load does not, in and of itself, create a bubble in the pipeline, which would be expensive).

Sent from my phone
On Sep 24, 2012 2:26 PM, "Andy Nuss" <andrew_nuss at yahoo.com<mailto:andrew_nuss at yahoo.com>> wrote:
I'm not sure, but it looks like if your variable "version" is volatile, your simple approach works.

I get this from http://www.ibm.com/developerworks/library/j-jtp03304/ article in "using volatile variable as a guard".  Brian Goetz states: "The JSR 133 Expert Group decided that it would be more sensible for volatile reads and writes not to be reorderable with any other memory operations -- to support precisely this and other similar use cases".

________________________________
From: Romain Colle <rco at quartetfs.com<mailto:rco at quartetfs.com>>
To: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Sent: Monday, September 24, 2012 7:08 AM
Subject: [concurrency-interest] Memory ordering and conditional operators

Hi all,

Following some previous posts, we are still struggling for, somehow, applying some fences when none are available ...

I was looking at a previous post in this list by Hans Boehm stating that optimistic versioned reads using seq_locks were currently not possible in Java.
http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html

The example looked like this:
> initial_version = version;
> read_a_bunch_of_stuff;
> final_version = version;

I'm assuming the main issue is that if the "bunch of stuff" that are being read are not volatile, it can be re-ordered after the final version read and break the whole idea of checking the version after read.

I was therfore wondering if conditional operators could be used to provide the required fencing.
Assuming a sequence lock where an even number means unlocked and an odd number means locked, could we have the following piece of code working?

int seq;
if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() && seqLock.getSequence() == seq)
  // success!

I'm guessing that this probably does not work since it would be plastered all over the internet otherwise, but could you explain what the issue would be?
I undertsand we probably do not have the correct happens-before relationship, but I would have guessed the conditional && operator would force the reads to happen in the correct order.

Thanks a lot for your feedback,

--
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com/

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/8d222321/attachment-0001.html>

From hans.boehm at hp.com  Mon Sep 24 16:23:51 2012
From: hans.boehm at hp.com (Boehm, Hans)
Date: Mon, 24 Sep 2012 20:23:51 +0000
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <CACuKZqHvpsBsaWircgrmykPX2xfTNaLeyOopJNgjTv8VwhWzKA@mail.gmail.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<CACuKZqHvpsBsaWircgrmykPX2xfTNaLeyOopJNgjTv8VwhWzKA@mail.gmail.com>
Message-ID: <A3E67C2071F49C4CBC4F17E6D77CDDD235F7A7E1@G4W3296.americas.hpqcorp.net>

> 
> My question though on Boehm's comment:
> 
> >Making all the reads in the middle volatile gives me SC, but this is
> often impractical, for both *performance* and software engineering
> reasons.
> 
> at least on x86, making the middle reads volatile doesn't incur any
> performance penalty, right?
> 
Right.  The performance problem is on POWER and ARM.

I'm actually no longer sure that making the loads volatile is such a bad idea for software engineering reasons. They are actually racy, and the programmer should be aware of that.  Calling an arbitrary getter-like function is inherently unsafe for other reasons, since it might not be able to deal with inconsistent state.

Hans


From martinrb at google.com  Mon Sep 24 21:58:49 2012
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Sep 2012 18:58:49 -0700
Subject: [concurrency-interest] UpgradeableRead lock like
 ReaderWriterLockSlim in C#
In-Reply-To: <505852B2.7080708@cs.oswego.edu>
References: <ABEHILABNFKEAJNKLENCIEKBCJAA.davidcholmes@aapt.net.au>
	<5057217D.9010801@redhat.com> <505729E7.8090208@oracle.com>
	<CA+kOe081e+pSyTRAZ5B0Cr+hoZ5U+nsX1Jo5aEFzqsKmjdZfPg@mail.gmail.com>
	<505852B2.7080708@cs.oswego.edu>
Message-ID: <CA+kOe09UPngNKX8ODgG_7Lx=w-FuibUZr09+VSM2fCsXXu_AJA@mail.gmail.com>

On Tue, Sep 18, 2012 at 3:53 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 09/17/12 14:46, Martin Buchholz wrote:
>
>> I imagine
>>
>> boolean tryUpgrade()  @return true if only reader
>>
>> boolean upgrade() @return true if acquired write lock without some other
>> intervening writer having acquired it
>>
>> I don't see any reason this couldn't be added to RRWL (except for the
>> engineering effort!)
>>
>>
> The main reason this wasn't done originally is that this
> doesn't mesh with policies on reentrant holds, fairness
> settings, and the separation of ReadLocks and WriteLocks
> as separate objects. While some sort of answer might be
> available for each of these issues,  the best move is still to
> provide this functionality in a different style of RW-like
> lock.


I agree with experimenting with any RRWL variants in a separate class, and
not touching RRWL itself.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/e282f903/attachment.html>

From andrew_nuss at yahoo.com  Tue Sep 25 01:42:54 2012
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Mon, 24 Sep 2012 22:42:54 -0700 (PDT)
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <1348551735.38898.YahooMailNeo@web120303.mail.ne1.yahoo.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<1348551735.38898.YahooMailNeo@web120303.mail.ne1.yahoo.com>
Message-ID: <1348551774.10715.YahooMailNeo@web120304.mail.ne1.yahoo.com>



This problem has me wondering.

What if the guard is an atomicinteger?? Updaters increment.? And to see if work was done without any update we force the function that does the reading to return the value of the atomicinteger at the end of the reading?

So its just:

if (guard.get() == reader.workget(guard)) {
... success

}



________________________________
 From: Romain Colle <rco at quartetfs.com>
To: concurrency-interest at cs.oswego.edu 
Sent: Monday, September 24, 2012 7:08 AM
Subject: [concurrency-interest] Memory ordering and conditional operators
 

Hi all,

Following some previous posts, we are still struggling for, somehow, applying some fences when none are available ...

I was looking at a previous post in this list by Hans Boehm stating that optimistic versioned reads using seq_locks were currently not possible in Java.
http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html

The example looked like this:
> initial_version = version;
> read_a_bunch_of_stuff;
> final_version = version;

I'm assuming the main issue is that if the "bunch of stuff" that are being read are not volatile, it can be re-ordered after the final version read and break the whole idea of checking the version after read.

I was therfore wondering if conditional operators could be used to provide the required fencing.
Assuming a sequence lock where an even number means unlocked and an odd number means locked, could we have the following piece of code working?

int seq;
if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() && seqLock.getSequence() == seq)
? // success!

I'm guessing that this probably does not work since it would be plastered all over the internet otherwise, but could you explain what the issue would be?
I undertsand we probably do not have the correct happens-before relationship, but I would have guessed the conditional && operator would force the reads to happen in the correct order.

Thanks a lot for your feedback,
-- 
Romain Colle
R&D Project Manager
QuartetFS
2 rue Jean Lantier, 75001 Paris, France
http://www.quartetfs.com/ 

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120924/f51b03ae/attachment.html>

From oleksandr.otenko at oracle.com  Tue Sep 25 06:23:22 2012
From: oleksandr.otenko at oracle.com (oleksandr otenko)
Date: Tue, 25 Sep 2012 11:23:22 +0100
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <1348551774.10715.YahooMailNeo@web120304.mail.ne1.yahoo.com>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<1348551735.38898.YahooMailNeo@web120303.mail.ne1.yahoo.com>
	<1348551774.10715.YahooMailNeo@web120304.mail.ne1.yahoo.com>
Message-ID: <5061861A.7000701@oracle.com>

It seems you want the read to occur in program order. That really 
depends on: a. what the (inlined) workget does; b. will the hardware 
decide for the read to go ahead.

Even if the value is used later, the actual memory access may be reordered.

Alex


On 25/09/2012 06:42, Andy Nuss wrote:
>
> This problem has me wondering.
>
> What if the guard is an atomicinteger?  Updaters increment.  And to 
> see if work was done without any update we force the function that 
> does the reading to return the value of the atomicinteger at the end 
> of the reading?
>
> So its just:
>
> if (guard.get() == reader.workget(guard)) {
> ... success
> }
>
> ------------------------------------------------------------------------
> *From:* Romain Colle <rco at quartetfs.com>
> *To:* concurrency-interest at cs.oswego.edu
> *Sent:* Monday, September 24, 2012 7:08 AM
> *Subject:* [concurrency-interest] Memory ordering and conditional 
> operators
>
> Hi all,
>
> Following some previous posts, we are still struggling for, somehow, 
> applying some fences when none are available ...
>
> I was looking at a previous post in this list by Hans Boehm stating 
> that optimistic versioned reads using seq_locks were currently not 
> possible in Java.
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-January/005746.html
>
> The example looked like this:
> > initial_version = version;
> > read_a_bunch_of_stuff;
> > final_version = version;
>
> I'm assuming the main issue is that if the "bunch of stuff" that are 
> being read are not volatile, it can be re-ordered after the final 
> version read and break the whole idea of checking the version after read.
>
> I was therfore wondering if conditional operators could be used to 
> provide the required fencing.
> Assuming a sequence lock where an even number means unlocked and an 
> odd number means locked, could we have the following piece of code 
> working?
>
> int seq;
> if (((seq = seqLock.getSequence()) & 1) == 0 && read_some_stuff() && 
> seqLock.getSequence() == seq)
>   // success!
>
> I'm guessing that this probably does not work since it would be 
> plastered all over the internet otherwise, but could you explain what 
> the issue would be?
> I undertsand we probably do not have the correct happens-before 
> relationship, but I would have guessed the conditional && operator 
> would force the reads to happen in the correct order.
>
> Thanks a lot for your feedback,
>
> -- 
> Romain Colle
> R&D Project Manager
> QuartetFS
> 2 rue Jean Lantier, 75001 Paris, France
> http://www.quartetfs.com/
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu 
> <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20120925/bef8ad3e/attachment-0001.html>

From dl at cs.oswego.edu  Tue Sep 25 06:32:59 2012
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 25 Sep 2012 06:32:59 -0400
Subject: [concurrency-interest] Memory ordering and conditional operators
In-Reply-To: <A3E67C2071F49C4CBC4F17E6D77CDDD235F7A7E1@G4W3296.americas.hpqcorp.net>
References: <CAJp3eRBtuzRZ5wrRyX7MFv6TPMkHfkh5OhQF3aRXomu2kw8N3g@mail.gmail.com>
	<CACuKZqHvpsBsaWircgrmykPX2xfTNaLeyOopJNgjTv8VwhWzKA@mail.gmail.com>
	<A3E67C2071F49C4CBC4F17E6D77CDDD235F7A7E1@G4W3296.americas.hpqcorp.net>
Message-ID: <5061885B.8090104@cs.oswego.edu>

On 09/24/12 16:23, Boehm, Hans wrote:
>
> I'm actually no longer sure that making the loads volatile is such a bad idea
> for software engineering reasons. They are actually racy, and the programmer
> should be aware of that.  Calling an arbitrary getter-like function is
> inherently unsafe for other reasons, since it might not be able to deal with
> inconsistent state.
>

The policy issue here is whether we make it possible for people
who are willing to put in a lot of effort to cope with possible
inconsistencies in these constructions to actually implement
them when applicable. Given the nearly weekly postings we've had on
this list lately, and the history of discussions spanning
several years, I think the only good answer is to somehow do so,
but in a way that no one will ever encounter them by accident.
And to fully document their properties. I'm  still working on this.

-Doug




