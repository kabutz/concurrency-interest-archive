From comp1986 at gmail.com  Thu Jul  7 12:00:28 2016
From: comp1986 at gmail.com (Sergey Zaytsev)
Date: Thu, 7 Jul 2016 19:00:28 +0300
Subject: [concurrency-interest] JMM actions to statements transition
Message-ID: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771@gmail.com>

Hi all. Can somebody , please, bring some light on JMM actions ? How can one use such abstract term like "action" to argue about correctness or possible results, since there is no strict definition is term "action" ? 

I mean is volatile read simply equals to var local = va and volatile write action to va = "some value" ?

Sergey

From martinrb at google.com  Thu Jul  7 16:32:22 2016
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 7 Jul 2016 13:32:22 -0700
Subject: [concurrency-interest] JMM actions to statements transition
In-Reply-To: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771@gmail.com>
References: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771@gmail.com>
Message-ID: <CA+kOe08MPpr=QpqVDePm0_S+kiZ9rOJLukRv8ua=uH-5Yi-ZAw@mail.gmail.com>

There is an attempt to define them in the jls (but it's hard to understand)
https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.2
People don't think about "actions", but do think about "synchronization
actions".

On Thu, Jul 7, 2016 at 9:00 AM, Sergey Zaytsev <comp1986 at gmail.com> wrote:

> Hi all. Can somebody , please, bring some light on JMM actions ? How can
> one use such abstract term like "action" to argue about correctness or
> possible results, since there is no strict definition is term "action" ?
>
> I mean is volatile read simply equals to var local = va and volatile write
> action to va = "some value" ?
>
> Sergey
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160707/68114a1d/attachment.html>

From aleksey.shipilev at oracle.com  Fri Jul  8 06:48:35 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Fri, 8 Jul 2016 13:48:35 +0300
Subject: [concurrency-interest] JMM actions to statements transition
In-Reply-To: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771@gmail.com>
References: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771@gmail.com>
Message-ID: <577F8503.2040104@oracle.com>

On 07/07/2016 07:00 PM, Sergey Zaytsev wrote:
> Hi all. Can somebody , please, bring some light on JMM actions ? How
> can one use such abstract term like "action" to argue about
> correctness or possible results, since there is no strict definition
> is term "action" ?

What do you mean "no strict definition"? There is JLS 17.4.2 "Actions"
that enumerate them.


> I mean is volatile read simply equals to var local = va and volatile
> write action to va = "some value" ?

This is where it gets messy. Actions and program statements are
connected with program order. More precisely, out of the entire "soup of
executions" that you may construct with arbitrary actions, you can only
select those executions where the actions of one particular thread can
be derived from the original program, to reason about that particular
program outcomes.

I thought I explained it here:
  https://shipilev.net/blog/2014/jmm-pragmatics/#_java_memory_model

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160708/09cf1a71/attachment.sig>

From comp1986 at gmail.com  Fri Jul  8 16:32:33 2016
From: comp1986 at gmail.com (Sergey Zaytsev)
Date: Fri, 8 Jul 2016 23:32:33 +0300
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 138,
	Issue 1
In-Reply-To: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
Message-ID: <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>

Well, I think I got the whole point, which might be very obvious to lots of people but might also be useful for those who is still looking for precise expiation. I hope Aleksey and Matrin could verify the following:
the reason we use _actions_ judging about program’s possible result is because we care about real execution. When things are going on. Of course, those executions come from program’ statements and here is the connection point. But statements are static.They do nothing until being executed. And ‘cause results only possible after execution we use term _action_ pointing out only those important for discussion, leaving statement behind.

This might sound very simple, but since JMM likes definitions I thought sharing this particular hindsight might be useful ( Of course considering its correctness )


Sergey


> On 08 Jul 2016, at 19:00, concurrency-interest-request at cs.oswego.edu wrote:
> 
> Send Concurrency-interest mailing list submissions to
> 	concurrency-interest at cs.oswego.edu
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> or, via email, send a message with subject or body 'help' to
> 	concurrency-interest-request at cs.oswego.edu
> 
> You can reach the person managing the list at
> 	concurrency-interest-owner at cs.oswego.edu
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Concurrency-interest digest..."
> 
> 
> Today's Topics:
> 
>   1. JMM actions to statements transition (Sergey Zaytsev)
>   2. Re: JMM actions to statements transition (Martin Buchholz)
>   3. Re: JMM actions to statements transition (Aleksey Shipilev)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 7 Jul 2016 19:00:28 +0300
> From: Sergey Zaytsev <comp1986 at gmail.com>
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] JMM actions to statements transition
> Message-ID: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771 at gmail.com>
> Content-Type: text/plain;	charset=us-ascii
> 
> Hi all. Can somebody , please, bring some light on JMM actions ? How can one use such abstract term like "action" to argue about correctness or possible results, since there is no strict definition is term "action" ? 
> 
> I mean is volatile read simply equals to var local = va and volatile write action to va = "some value" ?
> 
> Sergey
> 
> ------------------------------
> 
> Message: 2
> Date: Thu, 7 Jul 2016 13:32:22 -0700
> From: Martin Buchholz <martinrb at google.com>
> To: Sergey Zaytsev <comp1986 at gmail.com>
> Cc: concurrency-interest <concurrency-interest at cs.oswego.edu>
> Subject: Re: [concurrency-interest] JMM actions to statements
> 	transition
> Message-ID:
> 	<CA+kOe08MPpr=QpqVDePm0_S+kiZ9rOJLukRv8ua=uH-5Yi-ZAw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> There is an attempt to define them in the jls (but it's hard to understand)
> https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.2
> People don't think about "actions", but do think about "synchronization
> actions".
> 
> On Thu, Jul 7, 2016 at 9:00 AM, Sergey Zaytsev <comp1986 at gmail.com> wrote:
> 
>> Hi all. Can somebody , please, bring some light on JMM actions ? How can
>> one use such abstract term like "action" to argue about correctness or
>> possible results, since there is no strict definition is term "action" ?
>> 
>> I mean is volatile read simply equals to var local = va and volatile write
>> action to va = "some value" ?
>> 
>> Sergey
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160707/68114a1d/attachment-0001.html>
> 
> ------------------------------
> 
> Message: 3
> Date: Fri, 8 Jul 2016 13:48:35 +0300
> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
> To: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] JMM actions to statements
> 	transition
> Message-ID: <577F8503.2040104 at oracle.com>
> Content-Type: text/plain; charset="utf-8"
> 
> On 07/07/2016 07:00 PM, Sergey Zaytsev wrote:
>> Hi all. Can somebody , please, bring some light on JMM actions ? How
>> can one use such abstract term like "action" to argue about
>> correctness or possible results, since there is no strict definition
>> is term "action" ?
> 
> What do you mean "no strict definition"? There is JLS 17.4.2 "Actions"
> that enumerate them.
> 
> 
>> I mean is volatile read simply equals to var local = va and volatile
>> write action to va = "some value" ?
> 
> This is where it gets messy. Actions and program statements are
> connected with program order. More precisely, out of the entire "soup of
> executions" that you may construct with arbitrary actions, you can only
> select those executions where the actions of one particular thread can
> be derived from the original program, to reason about that particular
> program outcomes.
> 
> I thought I explained it here:
>  https://shipilev.net/blog/2014/jmm-pragmatics/#_java_memory_model
> 
> Thanks,
> -Aleksey
> 
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: signature.asc
> Type: application/pgp-signature
> Size: 819 bytes
> Desc: OpenPGP digital signature
> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160708/09cf1a71/attachment-0001.sig>
> 
> ------------------------------
> 
> Subject: Digest Footer
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> ------------------------------
> 
> End of Concurrency-interest Digest, Vol 138, Issue 1
> ****************************************************


From aleksey.shipilev at oracle.com  Sun Jul 10 14:05:35 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Sun, 10 Jul 2016 21:05:35 +0300
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 138,
 Issue 1
In-Reply-To: <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
References: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
 <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
Message-ID: <57828E6F.1050301@oracle.com>

On 07/08/2016 11:32 PM, Sergey Zaytsev wrote:
> Well, I think I got the whole point, which might be very obvious to
> lots of people but might also be useful for those who is still
> looking for precise expiation. I hope Aleksey and Matrin could verify
> the following: the reason we use _actions_ judging about program’s
> possible result is because we care about real execution. When things
> are going on. Of course, those executions come from program’
> statements and here is the connection point. But statements are
> static.They do nothing until being executed. And ‘cause results only
> possible after execution we use term _action_ pointing out only those
> important for discussion, leaving statement behind.

Yes, that sounds reasonable.

In memory model, we want to capture the fact that we have indeed written
and read a particular value to/from the particular location. Program (as
the set of statements) itself is a very cumbersome abstraction to
capture that.

We also don't really care about statements that do not affect memory,
this is why it is handy to enumerate the actual actions (reading/writing
variables, locking/unlocking) that interest us, leaving the rest of the
program alone.

-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160710/62651af8/attachment.sig>

From oleksandr.otenko at gmail.com  Mon Jul 11 04:44:59 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 11 Jul 2016 09:44:59 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 138,
	Issue 1
In-Reply-To: <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
References: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
 <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
Message-ID: <B4BE05D1-614B-4B6E-BB43-A87A132C65AE@gmail.com>

An action is an instance of a statement in history.


Without referring to history we cannot speak of temporal relationships.

And there may be multiple instances of the same statement in a history, so there is no 1:1 correspondence between program statements and actions in history - you cannot use program statements as a substitute for actions.

Alex

> On 8 Jul 2016, at 21:32, Sergey Zaytsev <comp1986 at gmail.com> wrote:
> 
> Well, I think I got the whole point, which might be very obvious to lots of people but might also be useful for those who is still looking for precise expiation. I hope Aleksey and Matrin could verify the following:
> the reason we use _actions_ judging about program’s possible result is because we care about real execution. When things are going on. Of course, those executions come from program’ statements and here is the connection point. But statements are static.They do nothing until being executed. And ‘cause results only possible after execution we use term _action_ pointing out only those important for discussion, leaving statement behind.
> 
> This might sound very simple, but since JMM likes definitions I thought sharing this particular hindsight might be useful ( Of course considering its correctness )
> 
> 
> Sergey
> 
> 
>> On 08 Jul 2016, at 19:00, concurrency-interest-request at cs.oswego.edu wrote:
>> 
>> Send Concurrency-interest mailing list submissions to
>> 	concurrency-interest at cs.oswego.edu
>> 
>> To subscribe or unsubscribe via the World Wide Web, visit
>> 	http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> or, via email, send a message with subject or body 'help' to
>> 	concurrency-interest-request at cs.oswego.edu
>> 
>> You can reach the person managing the list at
>> 	concurrency-interest-owner at cs.oswego.edu
>> 
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of Concurrency-interest digest..."
>> 
>> 
>> Today's Topics:
>> 
>>  1. JMM actions to statements transition (Sergey Zaytsev)
>>  2. Re: JMM actions to statements transition (Martin Buchholz)
>>  3. Re: JMM actions to statements transition (Aleksey Shipilev)
>> 
>> 
>> ----------------------------------------------------------------------
>> 
>> Message: 1
>> Date: Thu, 7 Jul 2016 19:00:28 +0300
>> From: Sergey Zaytsev <comp1986 at gmail.com>
>> To: concurrency-interest at cs.oswego.edu
>> Subject: [concurrency-interest] JMM actions to statements transition
>> Message-ID: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771 at gmail.com>
>> Content-Type: text/plain;	charset=us-ascii
>> 
>> Hi all. Can somebody , please, bring some light on JMM actions ? How can one use such abstract term like "action" to argue about correctness or possible results, since there is no strict definition is term "action" ? 
>> 
>> I mean is volatile read simply equals to var local = va and volatile write action to va = "some value" ?
>> 
>> Sergey
>> 
>> ------------------------------
>> 
>> Message: 2
>> Date: Thu, 7 Jul 2016 13:32:22 -0700
>> From: Martin Buchholz <martinrb at google.com>
>> To: Sergey Zaytsev <comp1986 at gmail.com>
>> Cc: concurrency-interest <concurrency-interest at cs.oswego.edu>
>> Subject: Re: [concurrency-interest] JMM actions to statements
>> 	transition
>> Message-ID:
>> 	<CA+kOe08MPpr=QpqVDePm0_S+kiZ9rOJLukRv8ua=uH-5Yi-ZAw at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>> 
>> There is an attempt to define them in the jls (but it's hard to understand)
>> https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.2
>> People don't think about "actions", but do think about "synchronization
>> actions".
>> 
>> On Thu, Jul 7, 2016 at 9:00 AM, Sergey Zaytsev <comp1986 at gmail.com> wrote:
>> 
>>> Hi all. Can somebody , please, bring some light on JMM actions ? How can
>>> one use such abstract term like "action" to argue about correctness or
>>> possible results, since there is no strict definition is term "action" ?
>>> 
>>> I mean is volatile read simply equals to var local = va and volatile write
>>> action to va = "some value" ?
>>> 
>>> Sergey
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>> -------------- next part --------------
>> An HTML attachment was scrubbed...
>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160707/68114a1d/attachment-0001.html>
>> 
>> ------------------------------
>> 
>> Message: 3
>> Date: Fri, 8 Jul 2016 13:48:35 +0300
>> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
>> To: concurrency-interest at cs.oswego.edu
>> Subject: Re: [concurrency-interest] JMM actions to statements
>> 	transition
>> Message-ID: <577F8503.2040104 at oracle.com>
>> Content-Type: text/plain; charset="utf-8"
>> 
>> On 07/07/2016 07:00 PM, Sergey Zaytsev wrote:
>>> Hi all. Can somebody , please, bring some light on JMM actions ? How
>>> can one use such abstract term like "action" to argue about
>>> correctness or possible results, since there is no strict definition
>>> is term "action" ?
>> 
>> What do you mean "no strict definition"? There is JLS 17.4.2 "Actions"
>> that enumerate them.
>> 
>> 
>>> I mean is volatile read simply equals to var local = va and volatile
>>> write action to va = "some value" ?
>> 
>> This is where it gets messy. Actions and program statements are
>> connected with program order. More precisely, out of the entire "soup of
>> executions" that you may construct with arbitrary actions, you can only
>> select those executions where the actions of one particular thread can
>> be derived from the original program, to reason about that particular
>> program outcomes.
>> 
>> I thought I explained it here:
>> https://shipilev.net/blog/2014/jmm-pragmatics/#_java_memory_model
>> 
>> Thanks,
>> -Aleksey
>> 
>> -------------- next part --------------
>> A non-text attachment was scrubbed...
>> Name: signature.asc
>> Type: application/pgp-signature
>> Size: 819 bytes
>> Desc: OpenPGP digital signature
>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160708/09cf1a71/attachment-0001.sig>
>> 
>> ------------------------------
>> 
>> Subject: Digest Footer
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
>> ------------------------------
>> 
>> End of Concurrency-interest Digest, Vol 138, Issue 1
>> ****************************************************
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From comp1986 at gmail.com  Mon Jul 11 05:15:59 2016
From: comp1986 at gmail.com (Sergey Zaytsev)
Date: Mon, 11 Jul 2016 12:15:59 +0300
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 138,
 Issue 1
In-Reply-To: <B4BE05D1-614B-4B6E-BB43-A87A132C65AE@gmail.com>
References: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
 <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
 <B4BE05D1-614B-4B6E-BB43-A87A132C65AE@gmail.com>
Message-ID: <B3A7EC25-6AAE-4072-BC59-B9D33CBC0D46@gmail.com>

Very intersting point, but doesn't look like a handy abstraction since it seems to take quite an affort to build lots of history time lines ( term "histroy" automatically introduces term "time" ) accroding to your quote  

> there may be multiple instances of the same statement in a history


to consider about particular programm output. 

If It is even possible to think about history in terms of SC means we have single timeline. But, JMM avoid notion of time as much as it even possible. So, how is that possible being on top of JMM, which got rid of time, to use the notion of time ? Is it correct ?


Sergey


> On 11 Jul 2016, at 11:44, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> An action is an instance of a statement in history.
> 
> 
> Without referring to history we cannot speak of temporal relationships.
> 
> And there may be multiple instances of the same statement in a history, so there is no 1:1 correspondence between program statements and actions in history - you cannot use program statements as a substitute for actions.
> 
> Alex
> 
>> On 8 Jul 2016, at 21:32, Sergey Zaytsev <comp1986 at gmail.com> wrote:
>> 
>> Well, I think I got the whole point, which might be very obvious to lots of people but might also be useful for those who is still looking for precise expiation. I hope Aleksey and Matrin could verify the following:
>> the reason we use _actions_ judging about program’s possible result is because we care about real execution. When things are going on. Of course, those executions come from program’ statements and here is the connection point. But statements are static.They do nothing until being executed. And ‘cause results only possible after execution we use term _action_ pointing out only those important for discussion, leaving statement behind.
>> 
>> This might sound very simple, but since JMM likes definitions I thought sharing this particular hindsight might be useful ( Of course considering its correctness )
>> 
>> 
>> Sergey
>> 
>> 
>>> On 08 Jul 2016, at 19:00, concurrency-interest-request at cs.oswego.edu wrote:
>>> 
>>> Send Concurrency-interest mailing list submissions to
>>> 	concurrency-interest at cs.oswego.edu
>>> 
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>> 	http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> or, via email, send a message with subject or body 'help' to
>>> 	concurrency-interest-request at cs.oswego.edu
>>> 
>>> You can reach the person managing the list at
>>> 	concurrency-interest-owner at cs.oswego.edu
>>> 
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of Concurrency-interest digest..."
>>> 
>>> 
>>> Today's Topics:
>>> 
>>> 1. JMM actions to statements transition (Sergey Zaytsev)
>>> 2. Re: JMM actions to statements transition (Martin Buchholz)
>>> 3. Re: JMM actions to statements transition (Aleksey Shipilev)
>>> 
>>> 
>>> ----------------------------------------------------------------------
>>> 
>>> Message: 1
>>> Date: Thu, 7 Jul 2016 19:00:28 +0300
>>> From: Sergey Zaytsev <comp1986 at gmail.com>
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: [concurrency-interest] JMM actions to statements transition
>>> Message-ID: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771 at gmail.com>
>>> Content-Type: text/plain;	charset=us-ascii
>>> 
>>> Hi all. Can somebody , please, bring some light on JMM actions ? How can one use such abstract term like "action" to argue about correctness or possible results, since there is no strict definition is term "action" ? 
>>> 
>>> I mean is volatile read simply equals to var local = va and volatile write action to va = "some value" ?
>>> 
>>> Sergey
>>> 
>>> ------------------------------
>>> 
>>> Message: 2
>>> Date: Thu, 7 Jul 2016 13:32:22 -0700
>>> From: Martin Buchholz <martinrb at google.com>
>>> To: Sergey Zaytsev <comp1986 at gmail.com>
>>> Cc: concurrency-interest <concurrency-interest at cs.oswego.edu>
>>> Subject: Re: [concurrency-interest] JMM actions to statements
>>> 	transition
>>> Message-ID:
>>> 	<CA+kOe08MPpr=QpqVDePm0_S+kiZ9rOJLukRv8ua=uH-5Yi-ZAw at mail.gmail.com>
>>> Content-Type: text/plain; charset="utf-8"
>>> 
>>> There is an attempt to define them in the jls (but it's hard to understand)
>>> https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.2
>>> People don't think about "actions", but do think about "synchronization
>>> actions".
>>> 
>>> On Thu, Jul 7, 2016 at 9:00 AM, Sergey Zaytsev <comp1986 at gmail.com> wrote:
>>> 
>>>> Hi all. Can somebody , please, bring some light on JMM actions ? How can
>>>> one use such abstract term like "action" to argue about correctness or
>>>> possible results, since there is no strict definition is term "action" ?
>>>> 
>>>> I mean is volatile read simply equals to var local = va and volatile write
>>>> action to va = "some value" ?
>>>> 
>>>> Sergey
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>> -------------- next part --------------
>>> An HTML attachment was scrubbed...
>>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160707/68114a1d/attachment-0001.html>
>>> 
>>> ------------------------------
>>> 
>>> Message: 3
>>> Date: Fri, 8 Jul 2016 13:48:35 +0300
>>> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
>>> To: concurrency-interest at cs.oswego.edu
>>> Subject: Re: [concurrency-interest] JMM actions to statements
>>> 	transition
>>> Message-ID: <577F8503.2040104 at oracle.com>
>>> Content-Type: text/plain; charset="utf-8"
>>> 
>>> On 07/07/2016 07:00 PM, Sergey Zaytsev wrote:
>>>> Hi all. Can somebody , please, bring some light on JMM actions ? How
>>>> can one use such abstract term like "action" to argue about
>>>> correctness or possible results, since there is no strict definition
>>>> is term "action" ?
>>> 
>>> What do you mean "no strict definition"? There is JLS 17.4.2 "Actions"
>>> that enumerate them.
>>> 
>>> 
>>>> I mean is volatile read simply equals to var local = va and volatile
>>>> write action to va = "some value" ?
>>> 
>>> This is where it gets messy. Actions and program statements are
>>> connected with program order. More precisely, out of the entire "soup of
>>> executions" that you may construct with arbitrary actions, you can only
>>> select those executions where the actions of one particular thread can
>>> be derived from the original program, to reason about that particular
>>> program outcomes.
>>> 
>>> I thought I explained it here:
>>> https://shipilev.net/blog/2014/jmm-pragmatics/#_java_memory_model
>>> 
>>> Thanks,
>>> -Aleksey
>>> 
>>> -------------- next part --------------
>>> A non-text attachment was scrubbed...
>>> Name: signature.asc
>>> Type: application/pgp-signature
>>> Size: 819 bytes
>>> Desc: OpenPGP digital signature
>>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160708/09cf1a71/attachment-0001.sig>
>>> 
>>> ------------------------------
>>> 
>>> Subject: Digest Footer
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> 
>>> 
>>> ------------------------------
>>> 
>>> End of Concurrency-interest Digest, Vol 138, Issue 1
>>> ****************************************************
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From oleksandr.otenko at gmail.com  Mon Jul 11 06:25:10 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 11 Jul 2016 11:25:10 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 138,
	Issue 1
In-Reply-To: <B3A7EC25-6AAE-4072-BC59-B9D33CBC0D46@gmail.com>
References: <mailman.1.1467993601.24831.concurrency-interest@cs.oswego.edu>
 <B0F197EE-AC34-4E6E-85EC-A859D7709E37@gmail.com>
 <B4BE05D1-614B-4B6E-BB43-A87A132C65AE@gmail.com>
 <B3A7EC25-6AAE-4072-BC59-B9D33CBC0D46@gmail.com>
Message-ID: <3284849A-EA0B-486D-871A-E669EFF1D161@gmail.com>

No, I didn’t introduce time. No, I didn’t introduce single global history as a total order of all events in all threads.

Short “definitions” do suffer from misinterpretations, yes. When you clarify it, you get JMM.


Alex


> On 11 Jul 2016, at 10:15, Sergey Zaytsev <comp1986 at gmail.com> wrote:
> 
> Very intersting point, but doesn't look like a handy abstraction since it seems to take quite an affort to build lots of history time lines ( term "histroy" automatically introduces term "time" ) accroding to your quote  
> 
>> there may be multiple instances of the same statement in a history
> 
> 
> to consider about particular programm output. 
> 
> If It is even possible to think about history in terms of SC means we have single timeline. But, JMM avoid notion of time as much as it even possible. So, how is that possible being on top of JMM, which got rid of time, to use the notion of time ? Is it correct ?
> 
> 
> Sergey
> 
> 
>> On 11 Jul 2016, at 11:44, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> 
>> An action is an instance of a statement in history.
>> 
>> 
>> Without referring to history we cannot speak of temporal relationships.
>> 
>> And there may be multiple instances of the same statement in a history, so there is no 1:1 correspondence between program statements and actions in history - you cannot use program statements as a substitute for actions.
>> 
>> Alex
>> 
>>> On 8 Jul 2016, at 21:32, Sergey Zaytsev <comp1986 at gmail.com> wrote:
>>> 
>>> Well, I think I got the whole point, which might be very obvious to lots of people but might also be useful for those who is still looking for precise expiation. I hope Aleksey and Matrin could verify the following:
>>> the reason we use _actions_ judging about program’s possible result is because we care about real execution. When things are going on. Of course, those executions come from program’ statements and here is the connection point. But statements are static.They do nothing until being executed. And ‘cause results only possible after execution we use term _action_ pointing out only those important for discussion, leaving statement behind.
>>> 
>>> This might sound very simple, but since JMM likes definitions I thought sharing this particular hindsight might be useful ( Of course considering its correctness )
>>> 
>>> 
>>> Sergey
>>> 
>>> 
>>>> On 08 Jul 2016, at 19:00, concurrency-interest-request at cs.oswego.edu wrote:
>>>> 
>>>> Send Concurrency-interest mailing list submissions to
>>>> 	concurrency-interest at cs.oswego.edu
>>>> 
>>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>> 	http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> or, via email, send a message with subject or body 'help' to
>>>> 	concurrency-interest-request at cs.oswego.edu
>>>> 
>>>> You can reach the person managing the list at
>>>> 	concurrency-interest-owner at cs.oswego.edu
>>>> 
>>>> When replying, please edit your Subject line so it is more specific
>>>> than "Re: Contents of Concurrency-interest digest..."
>>>> 
>>>> 
>>>> Today's Topics:
>>>> 
>>>> 1. JMM actions to statements transition (Sergey Zaytsev)
>>>> 2. Re: JMM actions to statements transition (Martin Buchholz)
>>>> 3. Re: JMM actions to statements transition (Aleksey Shipilev)
>>>> 
>>>> 
>>>> ----------------------------------------------------------------------
>>>> 
>>>> Message: 1
>>>> Date: Thu, 7 Jul 2016 19:00:28 +0300
>>>> From: Sergey Zaytsev <comp1986 at gmail.com>
>>>> To: concurrency-interest at cs.oswego.edu
>>>> Subject: [concurrency-interest] JMM actions to statements transition
>>>> Message-ID: <D2E0AC2E-9CF6-4CB8-B863-B0A7CF010771 at gmail.com>
>>>> Content-Type: text/plain;	charset=us-ascii
>>>> 
>>>> Hi all. Can somebody , please, bring some light on JMM actions ? How can one use such abstract term like "action" to argue about correctness or possible results, since there is no strict definition is term "action" ? 
>>>> 
>>>> I mean is volatile read simply equals to var local = va and volatile write action to va = "some value" ?
>>>> 
>>>> Sergey
>>>> 
>>>> ------------------------------
>>>> 
>>>> Message: 2
>>>> Date: Thu, 7 Jul 2016 13:32:22 -0700
>>>> From: Martin Buchholz <martinrb at google.com>
>>>> To: Sergey Zaytsev <comp1986 at gmail.com>
>>>> Cc: concurrency-interest <concurrency-interest at cs.oswego.edu>
>>>> Subject: Re: [concurrency-interest] JMM actions to statements
>>>> 	transition
>>>> Message-ID:
>>>> 	<CA+kOe08MPpr=QpqVDePm0_S+kiZ9rOJLukRv8ua=uH-5Yi-ZAw at mail.gmail.com>
>>>> Content-Type: text/plain; charset="utf-8"
>>>> 
>>>> There is an attempt to define them in the jls (but it's hard to understand)
>>>> https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.2
>>>> People don't think about "actions", but do think about "synchronization
>>>> actions".
>>>> 
>>>> On Thu, Jul 7, 2016 at 9:00 AM, Sergey Zaytsev <comp1986 at gmail.com> wrote:
>>>> 
>>>>> Hi all. Can somebody , please, bring some light on JMM actions ? How can
>>>>> one use such abstract term like "action" to argue about correctness or
>>>>> possible results, since there is no strict definition is term "action" ?
>>>>> 
>>>>> I mean is volatile read simply equals to var local = va and volatile write
>>>>> action to va = "some value" ?
>>>>> 
>>>>> Sergey
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> 
>>>> -------------- next part --------------
>>>> An HTML attachment was scrubbed...
>>>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160707/68114a1d/attachment-0001.html>
>>>> 
>>>> ------------------------------
>>>> 
>>>> Message: 3
>>>> Date: Fri, 8 Jul 2016 13:48:35 +0300
>>>> From: Aleksey Shipilev <aleksey.shipilev at oracle.com>
>>>> To: concurrency-interest at cs.oswego.edu
>>>> Subject: Re: [concurrency-interest] JMM actions to statements
>>>> 	transition
>>>> Message-ID: <577F8503.2040104 at oracle.com>
>>>> Content-Type: text/plain; charset="utf-8"
>>>> 
>>>> On 07/07/2016 07:00 PM, Sergey Zaytsev wrote:
>>>>> Hi all. Can somebody , please, bring some light on JMM actions ? How
>>>>> can one use such abstract term like "action" to argue about
>>>>> correctness or possible results, since there is no strict definition
>>>>> is term "action" ?
>>>> 
>>>> What do you mean "no strict definition"? There is JLS 17.4.2 "Actions"
>>>> that enumerate them.
>>>> 
>>>> 
>>>>> I mean is volatile read simply equals to var local = va and volatile
>>>>> write action to va = "some value" ?
>>>> 
>>>> This is where it gets messy. Actions and program statements are
>>>> connected with program order. More precisely, out of the entire "soup of
>>>> executions" that you may construct with arbitrary actions, you can only
>>>> select those executions where the actions of one particular thread can
>>>> be derived from the original program, to reason about that particular
>>>> program outcomes.
>>>> 
>>>> I thought I explained it here:
>>>> https://shipilev.net/blog/2014/jmm-pragmatics/#_java_memory_model
>>>> 
>>>> Thanks,
>>>> -Aleksey
>>>> 
>>>> -------------- next part --------------
>>>> A non-text attachment was scrubbed...
>>>> Name: signature.asc
>>>> Type: application/pgp-signature
>>>> Size: 819 bytes
>>>> Desc: OpenPGP digital signature
>>>> URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160708/09cf1a71/attachment-0001.sig>
>>>> 
>>>> ------------------------------
>>>> 
>>>> Subject: Digest Footer
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> 
>>>> 
>>>> ------------------------------
>>>> 
>>>> End of Concurrency-interest Digest, Vol 138, Issue 1
>>>> ****************************************************
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
> 


From boehm at acm.org  Wed Jul 13 20:53:21 2016
From: boehm at acm.org (Hans Boehm)
Date: Wed, 13 Jul 2016 17:53:21 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
Message-ID: <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>

[Sorry about the delay]

That paper clearly paid too little attention to the writer side of the
seqlock implementation.  It has an outright (boring, unrelated) bug, which
was minimally fixed in the slides at
http://safari.ece.cmu.edu/MSPC2012/slides_posters/boehm-slides.pdf . (This
bug convinced me that the C++ compare_exchange semantics that update the
expected value may not have been the best thing since sliced bread.)

The writer code also assumes that data updates use plain C++ assignments to
atomic variables, which are sequentially consistent. Thus it dodges all
further memory ordering issues in the writer.  At some cost. But the
assumption throughout is that the writer is not performance critical.

If the data updates are allowed to use relaxed operations, then Martin's
concern is entirely valid. I believe it is valid in practice, not just in
theory.  The easiest way to convince yourself is to consider the case in
which compareAndSet is in fact implemented with a lock.  Using "roach motel
semantics", the data stores are allowed to move into the compareAndSet
critical section, and become visible before the compareAndSet update
itself. Oops.

An ARMv8 compareAndSet operation (using only acquire and release
operations, not dmb, as it should be implemented) will behave like the
lock-based one in this respect.  I think the current code above is
incorrect on ARMv8 (barring compensating pessimizations elsewhere).

On Wed, Jun 15, 2016 at 6:53 PM, Martin Buchholz <martinrb at google.com>
wrote:

> Somehow I ended up re-reading Hans' excellent
> Can Seqlocks Get Along With Programming Language Memory Models?
> http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf
> and was wondering about why there wasn't a symmetrical releaseFence to
> pair up with the acquireFence.  The proof in section 5 says
>
> """
> The correctness argument is basically as above, but the
> happens-before chain becomes:
> Initial update of seq by w is sequenced before
> Write to datan by w synchronizes with
> The acquire fence in r (since preceding operation saw
> write, 29.8 p4 in [11]) is sequenced before
> final read of seq by r
> """
>
> But if the write to datan is a relaxed write (as would be written by
> programmers accustomed to using plain writes in a critical section), then I
> don't see the "Write to datan by w synchronizes with ..."  and I wonder
> whether for theoretical correctness one needs something like:
>
> --- src/main/java/util/concurrent/locks/StampedLock.java 9 Jun 2016
> 00:32:02 -0000 1.60
> +++ src/main/java/util/concurrent/locks/StampedLock.java 16 Jun 2016
> 01:30:09 -0000
> @@ -349,9 +347,14 @@
>      public long tryWriteLock() {
>          long s, next;
> -        return ((((s = state) & ABITS) == 0L &&
> -                 STATE.compareAndSet(this, s, next = s + WBIT)) ?
> -                next : 0L);
> +        if (((s = state) & ABITS) == 0L &&
> +            STATE.compareAndSet(this, s, next = s + WBIT)) {
> +            // Necessary in theory, but not in practice?
> +            VarHandle.releaseFence();
> +            return next;
> +        } else {
> +            return 0L;
> +        }
>      }
>
> In practice it's probably not an issue because CASes are implemented using
> full fences, and the JIT cannot reorder the dependent write.
>
> BTW, with jdk9 VarHandles seqlocks can be implemented without Unsafe, so a
> "new release" of the Seqlocks paper might be useful.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160713/bb70f6f5/attachment.html>

From aph at redhat.com  Thu Jul 14 04:23:22 2016
From: aph at redhat.com (Andrew Haley)
Date: Thu, 14 Jul 2016 09:23:22 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
Message-ID: <57874BFA.60302@redhat.com>

On 14/07/16 01:53, Hans Boehm wrote:
> An ARMv8 compareAndSet operation (using only acquire and release
> operations, not dmb, as it should be implemented) will behave like the
> lock-based one in this respect.  I think the current code above is
> incorrect on ARMv8 (barring compensating pessimizations elsewhere).

Umm, what?  The ARMv8 compareAndSet has a sequentially consistent store.
I guess I must be missing something important.

Andrew.


From martinrb at google.com  Thu Jul 14 11:27:00 2016
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 14 Jul 2016 08:27:00 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <57874BFA.60302@redhat.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
Message-ID: <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>

On Thu, Jul 14, 2016 at 1:23 AM, Andrew Haley <aph at redhat.com> wrote:

> On 14/07/16 01:53, Hans Boehm wrote:
> > An ARMv8 compareAndSet operation (using only acquire and release
> > operations, not dmb, as it should be implemented) will behave like the
> > lock-based one in this respect.  I think the current code above is
> > incorrect on ARMv8 (barring compensating pessimizations elsewhere).
>
> Umm, what?  The ARMv8 compareAndSet has a sequentially consistent store.
> I guess I must be missing something important.


(Pretending to be Hans here ...)
The idea is that all ARMv8 "load-acquire/store-release" operations
(including those used for implementing CAS) are sequentially consistent
when considered as a group in the same way that all "synchronization
actions" in Java are, but they can still be reordered with plain
reads/writes, just like Java plain variable access can be reordered with
volatile variable access (unless a happens-before relationship exists).

The section in
https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html
on aarch64 should be useful.

ldar corresponds to Java volatile read
stlr corresponds to Java volatile write
CAS is implemented using a ldaxr followed by stlxr which is efficient, but
allows subsequent writes to move in between the ldaxr and the stlxr.

(Back to being Martin ...)
Reordering a plain store from after to before a stlxr (rather than
non-exclusive stlr) is still rather surprising because it looks like a
speculative store - we don't know yet whether the stlxr will succeed.
Unlike the case where we implement CAS via a lock.  Am I thinking too
atomically?  Perhaps the stlxr instruction implementation exclusively
acquires the cache line, sees that it surely will succeed, but will be slow
because pending memory operations must be completed first.  But no reason
we can't start executing future instructions in the meantime!?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160714/af1ce621/attachment.html>

From carfield at carfield.com.hk  Thu Jul 14 11:56:51 2016
From: carfield at carfield.com.hk (Carfield Yim)
Date: Thu, 14 Jul 2016 23:56:51 +0800
Subject: [concurrency-interest] TransferQueue batch processing
Message-ID: <CACfbOvfZusF8HW9uO-fhm9NTQRZ_Mv7f9+D2O5RWWmvU6H2iPA@mail.gmail.com>

I get code like this as a feed handler:

  private def consume(name: String, callback: (List[Base]) =>
Array[Array[_]], queue: BlockingQueue[Base]) = {
    val listener = new Thread(new Runnable {
      def run() {
        while (true) {
          var list = new ArrayList[Base]();
          try {
            queue.drainTo(list);
            if (list.size() > 0) {
              var converted = callback(list.toList);
              batchInsert(name, converted);
            } else {
              Thread.sleep(100);
            }
          } catch {
            case e: Exception =>
              logger.error(list.toString(), e);
          }
        }
      }
    }, name);
    listener.start();
  }

  def consume(x: Trade) = {
    tradeQueue.put(x)
  }

It work reasonable good but there are still time that too much update from
upstream causing the message blocked and doesn't process fast enough.
Recently I come up with this article (http://php.sabscape.com/blog/?p=557)
saying that transferqueue may help to reduce the blocking time. However,
after I change to use transferqueue and change put() to transfer(), it
actually slower the processing time.

I believe the reason is transferqueue.transfer() will face the handler get
the message asap, thus queue.drainTo(list) will always draining single
element to the list and there won't be batch processing.

Thus, if that mean transfer queue doesn't work for my case? Will it is
similar that disruptor also don't target for this kind of batch processing?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160714/f640de55/attachment.html>

From aph at redhat.com  Thu Jul 14 13:16:44 2016
From: aph at redhat.com (Andrew Haley)
Date: Thu, 14 Jul 2016 18:16:44 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
Message-ID: <5787C8FC.2050407@redhat.com>

On 14/07/16 16:27, Martin Buchholz wrote:
> On Thu, Jul 14, 2016 at 1:23 AM, Andrew Haley <aph at redhat.com> wrote:
> 
>> On 14/07/16 01:53, Hans Boehm wrote:
>>> An ARMv8 compareAndSet operation (using only acquire and release
>>> operations, not dmb, as it should be implemented) will behave like the
>>> lock-based one in this respect.  I think the current code above is
>>> incorrect on ARMv8 (barring compensating pessimizations elsewhere).
>>
>> Umm, what?  The ARMv8 compareAndSet has a sequentially consistent store.
>> I guess I must be missing something important.
> 
> 
> (Pretending to be Hans here ...)
> The idea is that all ARMv8 "load-acquire/store-release" operations
> (including those used for implementing CAS) are sequentially consistent
> when considered as a group in the same way that all "synchronization
> actions" in Java are, but they can still be reordered with plain
> reads/writes, just like Java plain variable access can be reordered with
> volatile variable access (unless a happens-before relationship exists).
> 
> The section in
> https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html
> on aarch64 should be useful.

I get that.  I'm just trying to understand exactly which scenario Hans
is worried about.

void writer(...) {
    unsigned seq0 = seq;
    while (seq0 & 1 ||
           !seq.cmp_exc_wk
           (seq0,seq0+1));
    { seq0 = seq; }
    data1 = ...;
    data2 = ...;
    seq = seq0 + 2;
}

> CAS is implemented using a ldaxr followed by stlxr which is efficient, but
> allows subsequent writes to move in between the ldaxr and the stlxr.

OK, got that.  A write of data1 might move before the seq.cmp_exc_wk
has succeeded in bumping seq0 (the version clock).

Reading the AArch64 specification as carefully as I can, I see

-------------------------------------------------------------------
For a Store-Release, observers in the shareability domain of the
address accessed by the Store-Release observe:

1.  Both of the following, if the shareability of the addresses
accessed requires that the observer observes them:

        Reads and writes caused by loads and stores appearing in
        program order before the Store-Release.

        Writes that have been observed by the PE executing the
        Store-Release before executing the Store-Release.

2.  The write caused by the Store-Release.

There are no additional ordering requirements on loads or stores that
appear in program order after the Store-Release.
-------------------------------------------------------------------

So, yes, it is quite possible for a write of data1 to move before the
write of the clock.  And I can see why that would be bad.  We really
need something like

void writer(...) {
    unsigned seq0 = seq;
    while (seq0 & 1 ||
           !seq.cmp_exc_wk
           (seq0,seq0+1));
    { seq0 = seq; }
    atomic_thread_fence(m_o_store_store);
    data1 = ...;
    data2 = ...;
    seq = seq0 + 2;
}

> (Back to being Martin ...)
> Reordering a plain store from after to before a stlxr (rather than
> non-exclusive stlr) is still rather surprising because it looks like
> a speculative store - we don't know yet whether the stlxr will
> succeed.  Unlike the case where we implement CAS via a lock.

But even CAS via a lock has the roach motel property, so we're used to
the idea of stores and loads moving into a critical section: none of
this should surprise people.

> Am I thinking too atomically?  Perhaps the stlxr instruction
> implementation exclusively acquires the cache line, sees that it
> surely will succeed, but will be slow because pending memory
> operations must be completed first.

I don't think it has to be so complicated.  An out-of-order
implementation can move stores which are after this stlxr to before it
simply because there is no logic preventing it from doing so.  Whether
this is a realistic or useful property of a real machine is a whole
'nother matter.

Andrew.

From boehm at acm.org  Thu Jul 14 15:19:35 2016
From: boehm at acm.org (Hans Boehm)
Date: Thu, 14 Jul 2016 12:19:35 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <5787C8FC.2050407@redhat.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
Message-ID: <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>

On Thu, Jul 14, 2016 at 10:16 AM, Andrew Haley <aph at redhat.com> wrote:

>
> > (Back to being Martin ...)
> > Reordering a plain store from after to before a stlxr (rather than
> > non-exclusive stlr) is still rather surprising because it looks like
> > a speculative store - we don't know yet whether the stlxr will
> > succeed.  Unlike the case where we implement CAS via a lock.
>
> But even CAS via a lock has the roach motel property, so we're used to
> the idea of stores and loads moving into a critical section: none of
> this should surprise people.
>
> > Am I thinking too atomically?  Perhaps the stlxr instruction
> > implementation exclusively acquires the cache line, sees that it
> > surely will succeed, but will be slow because pending memory
> > operations must be completed first.
>
> I don't think it has to be so complicated.  An out-of-order
> implementation can move stores which are after this stlxr to before it
> simply because there is no logic preventing it from doing so.  Whether
> this is a realistic or useful property of a real machine is a whole
> 'nother matter.
>
> Andrew.
>
I think Martin does have a point here that I missed the first time.  The
data stores are "control-dependent" on the store in the CAS
implementation.  ARM and Power effectively preserve ordering between
control-dependent stores, though not a store followed by a load. But we
really only care about stores here.

At least that's probably true; I'm not 100% sure whether stlxr success is
viewed as dependent on the store itself for purposes of determining
ordering. (Will Deacon might be able to answer?)

There is also another subtlety here in the definition of
"control-dependency" in that arguably the control paths have rejoined. My
understanding is that ARM's definition of "control-dependency" is not
affected by such rejoining, but Itanium's is.

A spin-lock-based implementation would indeed still have the issue, since
the lock release there is a plain store.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160714/eb3a904f/attachment.html>

From kimo at webnetic.net  Thu Jul 14 16:00:07 2016
From: kimo at webnetic.net (Kimo Crossman)
Date: Thu, 14 Jul 2016 13:00:07 -0700
Subject: [concurrency-interest] Multicore Locks: The Case Is Not Closed Yet
	- USENIX 2016 ATC
Message-ID: <CALV1V4_zc_i7HT3YrxV7FJqNZ4564n6v-Vg+2+cj6nPb203jAA@mail.gmail.com>

https://www.usenix.org/conference/atc16/technical-sessions/presentation/guiroux

Multicore Locks: The Case Is Not Closed Yet   - USENIX 2016 ATC

Authors:

Hugo Guiroux and Renaud Lachaize, *Université Grenoble Alpes and
Laboratoire d'Informatique de Grenoble;* Vivien Quéma, *Université Grenoble
Alpes, Grenoble Institute of Technology, and Laboratoire d'Informatique de
Grenoble*

Abstract:

NUMA multicore machines are pervasive and many multithreaded applications
are suffering from lock contention. To mitigate this issue, application and
library developers can choose from the plethora of optimized mutex lock
algorithms that have been designed over the past 25 years. Unfortunately,
there is currently no broad study of the behavior of these optimized lock
algorithms on realistic applications. In this paper, we fill this gap. We
perform a performance study of 19 state-of-the-art mutex lock algorithms on
36 realistic applications. Our study shows that regarding locking on
multicore machines, the case is not closed yet. Indeed, our conclusions
include the following findings: (i) no single lock is the best for more
than 50% of the studied workloads; (ii) every lock is harmful for several
applications, even if the application parallelism is properly tuned; (iii)
for several applications, the optimal lock changes when varying the number
of applications or the workload. These findings call for further research
on optimized lock algorithms and dynamic adaptation of contention management


Slides and paper below
https://www.usenix.org/conference/atc16/technical-sessions/presentation/guiroux
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160714/08ebb4d7/attachment.html>

From aph at redhat.com  Fri Jul 15 03:52:00 2016
From: aph at redhat.com (Andrew Haley)
Date: Fri, 15 Jul 2016 08:52:00 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
Message-ID: <57889620.80003@redhat.com>

On 14/07/16 20:19, Hans Boehm wrote:

> I think Martin does have a point here that I missed the first time.
> The data stores are "control-dependent" on the store in the CAS
> implementation.  ARM and Power effectively preserve ordering between
> control-dependent stores, though not a store followed by a load. But
> we really only care about stores here.
> 
> At least that's probably true; I'm not 100% sure whether stlxr
> success is viewed as dependent on the store itself for purposes of
> determining ordering. (Will Deacon might be able to answer?)

I don't think it matters.  The code will always look like

    stlxr status, data, [addr]
    cbnz status, retry
    str r1, [data1]
    str r2, [data2]

The stores are control-dependent on the CBNZ: they cannot be
speculated before the STLXR.

Andrew.


From davidcholmes at aapt.net.au  Fri Jul 15 03:59:24 2016
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 15 Jul 2016 17:59:24 +1000
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
Message-ID: <004d01d1de6e$cdd67d90$698378b0$@aapt.net.au>

Regarding:

 

“CAS is implemented using a ldaxr followed by stlxr which is efficient, but allows subsequent writes to move in between the ldaxr and the stlxr.“

 

“we” don’t think it is the case. Unfortunately the spec does not clearly state this but informally:

-          Any such writes would potentially invalidate the reservation so moving writes into there seems a bad idea unless you expend effort determining it won’t invalidate the reservation

-          Any such writes would be speculative and potentially need undoing. So this also seems like far too much effort for little if any gain

-          If this were truly an issue then the “Barrier Litmus Test” Appendix in the ARMv8 Architecture manual would flag it and show the use of explicit memory barriers

 

It would be good if the ARM folk could clarify this, and if necessary get the “Barrier Litmus test” text updated.

 

Also note that C++11 Cmpxhng-SeqCst  mapping for Aarch64 does not add any additional explicit barriers:

 

https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Martin Buchholz
Sent: Friday, July 15, 2016 1:27 AM
To: Andrew Haley <aph at redhat.com>
Cc: Doug Lea <dl at cs.oswego.edu>; concurrency-interest <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Does StampedLock need a releaseFence in theory?

 

 

 

On Thu, Jul 14, 2016 at 1:23 AM, Andrew Haley <aph at redhat.com <mailto:aph at redhat.com> > wrote:

On 14/07/16 01:53, Hans Boehm wrote:
> An ARMv8 compareAndSet operation (using only acquire and release
> operations, not dmb, as it should be implemented) will behave like the
> lock-based one in this respect.  I think the current code above is
> incorrect on ARMv8 (barring compensating pessimizations elsewhere).

Umm, what?  The ARMv8 compareAndSet has a sequentially consistent store.
I guess I must be missing something important.

 

(Pretending to be Hans here ...)

The idea is that all ARMv8 "load-acquire/store-release" operations (including those used for implementing CAS) are sequentially consistent when considered as a group in the same way that all "synchronization actions" in Java are, but they can still be reordered with plain reads/writes, just like Java plain variable access can be reordered with volatile variable access (unless a happens-before relationship exists).

 

The section in

https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html

on aarch64 should be useful.

 

ldar corresponds to Java volatile read

stlr corresponds to Java volatile write

CAS is implemented using a ldaxr followed by stlxr which is efficient, but allows subsequent writes to move in between the ldaxr and the stlxr.

 

(Back to being Martin ...)

Reordering a plain store from after to before a stlxr (rather than non-exclusive stlr) is still rather surprising because it looks like a speculative store - we don't know yet whether the stlxr will succeed.  Unlike the case where we implement CAS via a lock.  Am I thinking too atomically?  Perhaps the stlxr instruction implementation exclusively acquires the cache line, sees that it surely will succeed, but will be slow because pending memory operations must be completed first.  But no reason we can't start executing future instructions in the meantime!?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160715/a3fd6744/attachment-0001.html>

From aph at redhat.com  Fri Jul 15 07:50:46 2016
From: aph at redhat.com (Andrew Haley)
Date: Fri, 15 Jul 2016 12:50:46 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <20160715084712.GB3897@arm.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
Message-ID: <5788CE16.40302@redhat.com>

On 15/07/16 09:47, Will Deacon wrote:
> On Fri, Jul 15, 2016 at 08:52:00AM +0100, Andrew Haley wrote:
>>
>> I don't think it matters.  The code will always look like
>>
>>     stlxr status, data, [addr]
>>     cbnz status, retry
>>     str r1, [data1]
>>     str r2, [data2]
>>
>> The stores are control-dependent on the CBNZ: they cannot be
>> speculated before the STLXR.
> 
> I'm not so sure about that, unfortunately. You can conceive of a
> microarchitecture that knows stlxr can never fail, in which case the
> control dependency can be folded away. If you want ordering between the
> stlxr and the subsequent stores, you need an explicit barrier.

That's interesting.  I'm surprised that such an optimization can change
the ordering rules, though.

Andrew.


From davidcholmes at aapt.net.au  Fri Jul 15 09:07:53 2016
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 15 Jul 2016 23:07:53 +1000
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <5788CE16.40302@redhat.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com>
Message-ID: <005701d1de99$e63ec150$b2bc43f0$@aapt.net.au>

Andrew Haley writes:
> Sent: Friday, July 15, 2016 9:51 PM
> To: Will Deacon <will.deacon at arm.com>
> Cc: Martin Buchholz <martinrb at google.com>; Doug Lea
> <dl at cs.oswego.edu>; concurrency-interest <concurrency-
> interest at cs.oswego.edu>
> Subject: Re: [concurrency-interest] Does StampedLock need a releaseFence
> in theory?
> 
> On 15/07/16 09:47, Will Deacon wrote:
> > On Fri, Jul 15, 2016 at 08:52:00AM +0100, Andrew Haley wrote:
> >>
> >> I don't think it matters.  The code will always look like
> >>
> >>     stlxr status, data, [addr]
> >>     cbnz status, retry
> >>     str r1, [data1]
> >>     str r2, [data2]
> >>
> >> The stores are control-dependent on the CBNZ: they cannot be
> >> speculated before the STLXR.
> >
> > I'm not so sure about that, unfortunately. You can conceive of a
> > microarchitecture that knows stlxr can never fail, in which case the
> > control dependency can be folded away. If you want ordering between the
> > stlxr and the subsequent stores, you need an explicit barrier.
> 
> That's interesting.  I'm surprised that such an optimization can change
> the ordering rules, though.

Is this "conceive" in a thought-experiment sense or something realistic? Is this just an unintended hole in the abstract architectural model or a deliberate allowance for such "optimizations"?

David 
 
> Andrew.
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Fri Jul 15 09:36:34 2016
From: aph at redhat.com (Andrew Haley)
Date: Fri, 15 Jul 2016 14:36:34 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <5788CE16.40302@redhat.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com>
Message-ID: <5788E6E2.5060103@redhat.com>

On 15/07/16 12:50, Andrew Haley wrote:
> On 15/07/16 09:47, Will Deacon wrote:
>> On Fri, Jul 15, 2016 at 08:52:00AM +0100, Andrew Haley wrote:
>>>
>>> I don't think it matters.  The code will always look like
>>>
>>>     stlxr status, data, [addr]
>>>     cbnz status, retry
>>>     str r1, [data1]
>>>     str r2, [data2]
>>>
>>> The stores are control-dependent on the CBNZ: they cannot be
>>> speculated before the STLXR.
>>
>> I'm not so sure about that, unfortunately. You can conceive of a
>> microarchitecture that knows stlxr can never fail, in which case the
>> control dependency can be folded away. If you want ordering between the
>> stlxr and the subsequent stores, you need an explicit barrier.
> 
> That's interesting.  I'm surprised that such an optimization can change
> the ordering rules, though.

Thinking about it some more, I am very skeptical.  For example, it is a
common trick to enforce ordering by using an address dependency, such as:

    ldr x1, [addr1]
    eor x0, x0, x1
    eor x0, x0, x1
    ldr x2, [x0]

Here, the load of x2 must be after the load of x1 because of the
address dependency.  A "smart" microarchitecture could fold away the
EORs (and maybe even the load of x1).  But I'm sure that would not be
permitted by the specification.

Andrew.



From dl at cs.oswego.edu  Fri Jul 15 13:49:03 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 15 Jul 2016 13:49:03 -0400
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <20160715142719.GA15954@arm.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com> <20160715142719.GA15954@arm.com>
Message-ID: <5789220F.30708@cs.oswego.edu>


On 07/15/2016 10:27 AM, Will Deacon wrote:

> a fence would be required to maintain order with a subsequent store.

Thanks.

I now agree with Martin that we should add VarHandle.storeStoreFence
to write-unlock.

Backing up: We've long known that versioned locks (seqlocks, StampedLock)
should not in general allow "roach-motel" reorderings. We couldn't
introduce StampedLock until we had fence intrinsics for the load-load
case. But no one considered that the implementation of write-unlock
via CAS might permit hardware write reorderings. Thanks to the ARM
folks for finding the tiny bit of wiggle room in CAS specs that
might in theory (if not in practice) require the complementary
fence on unlock. Too bad this will slow down some implementations
for no good reason, but probably not noticeably. I wonder if/how
this impacts other versioned lock implementations in other
languages.

-Doug



From boehm at acm.org  Fri Jul 15 14:06:36 2016
From: boehm at acm.org (Hans Boehm)
Date: Fri, 15 Jul 2016 11:06:36 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <5789220F.30708@cs.oswego.edu>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com> <20160715142719.GA15954@arm.com>
 <5789220F.30708@cs.oswego.edu>
Message-ID: <CAPUmR1Z6rydF57OxPShCZbgnp2G90TkuCN1_E9gNQs2RdunmVQ@mail.gmail.com>

My impression is that Linux kernel seqlock use cases don't care about write
performance.  Presumably you have some StampedLock clients in mind here
that do care, because they don't know the reader-writer mix ahead of time?
If writers are known to be frequent, this doesn't seem like the right tool?


On Fri, Jul 15, 2016 at 10:49 AM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> On 07/15/2016 10:27 AM, Will Deacon wrote:
>
> a fence would be required to maintain order with a subsequent store.
>>
>
> Thanks.
>
> I now agree with Martin that we should add VarHandle.storeStoreFence
> to write-unlock.
>
> Backing up: We've long known that versioned locks (seqlocks, StampedLock)
> should not in general allow "roach-motel" reorderings. We couldn't
> introduce StampedLock until we had fence intrinsics for the load-load
> case. But no one considered that the implementation of write-unlock
> via CAS might permit hardware write reorderings. Thanks to the ARM
> folks for finding the tiny bit of wiggle room in CAS specs that
> might in theory (if not in practice) require the complementary
> fence on unlock. Too bad this will slow down some implementations
> for no good reason, but probably not noticeably. I wonder if/how
> this impacts other versioned lock implementations in other
> languages.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160715/bed359a3/attachment.html>

From dl at cs.oswego.edu  Fri Jul 15 14:52:55 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 15 Jul 2016 14:52:55 -0400
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <CAPUmR1Z6rydF57OxPShCZbgnp2G90TkuCN1_E9gNQs2RdunmVQ@mail.gmail.com>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com> <20160715142719.GA15954@arm.com>
 <5789220F.30708@cs.oswego.edu>
 <CAPUmR1Z6rydF57OxPShCZbgnp2G90TkuCN1_E9gNQs2RdunmVQ@mail.gmail.com>
Message-ID: <57893107.8010605@cs.oswego.edu>

On 07/15/2016 02:06 PM, Hans Boehm wrote:
> My impression is that Linux kernel seqlock use cases don't care about write
> performance.  Presumably you have some StampedLock clients in mind here that do
> care, because they don't know the reader-writer mix ahead of time?  If writers
> are known to be frequent, this doesn't seem like the right tool?
>

StampedLock is multimodal. In the recommended usages (for example
those listed in javadocs), users switch from optimistic to ReadLock on
contention.

In any case, I mainly had in mind possible impact on other
versioned STM-ish locks out there with optimistic modes.

-Doug


>
> On Fri, Jul 15, 2016 at 10:49 AM, Doug Lea <dl at cs.oswego.edu
> <mailto:dl at cs.oswego.edu>> wrote:
>
>
>     On 07/15/2016 10:27 AM, Will Deacon wrote:
>
>         a fence would be required to maintain order with a subsequent store.
>
>
>     Thanks.
>
>     I now agree with Martin that we should add VarHandle.storeStoreFence
>     to write-unlock.
>
>     Backing up: We've long known that versioned locks (seqlocks, StampedLock)
>     should not in general allow "roach-motel" reorderings. We couldn't
>     introduce StampedLock until we had fence intrinsics for the load-load
>     case. But no one considered that the implementation of write-unlock
>     via CAS might permit hardware write reorderings. Thanks to the ARM
>     folks for finding the tiny bit of wiggle room in CAS specs that
>     might in theory (if not in practice) require the complementary
>     fence on unlock. Too bad this will slow down some implementations
>     for no good reason, but probably not noticeably. I wonder if/how
>     this impacts other versioned lock implementations in other
>     languages.
>
>     -Doug
>
>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


From mikeb01 at gmail.com  Tue Jul 19 22:11:15 2016
From: mikeb01 at gmail.com (Michael Barker)
Date: Wed, 20 Jul 2016 14:11:15 +1200
Subject: [concurrency-interest] Ordering Question
Message-ID: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>

Hi,

I have a question around ordering of events.

Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
shared on the heap and visible to T1 and T2.

Initially:

X = 0
Y = 0;

T1:
1) X = 1 (lazySet/putOrdered)
2) B = Y (volatile read)

T2
3) Y = 1 (compare and set)
4) A = X (volatile read)

Is it possible to get a final state of A = 1 and B = 0?

My current suspicion is that it is, due to 1) and 2) being reordered.  If
so, can the final state of A=1, B=0 be prevented by strengthening 1) to be
a volatile store?

Regards,
Michael Barker.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/34a5373f/attachment.html>

From vitalyd at gmail.com  Tue Jul 19 22:30:59 2016
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 19 Jul 2016 22:30:59 -0400
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
Message-ID: <CAHjP37Ed+GdcKm2OyX5Z17cvzUfFsQ+-aRsVSaH8pC9qd3-gyQ@mail.gmail.com>

Yes to both of your questions.  As you suspect, you need a storeLoad
between 1) and 2), and that's what a volatile write would give you.

On Tuesday, July 19, 2016, Michael Barker <mikeb01 at gmail.com> wrote:

> Hi,
>
> I have a question around ordering of events.
>
> Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
> shared on the heap and visible to T1 and T2.
>
> Initially:
>
> X = 0
> Y = 0;
>
> T1:
> 1) X = 1 (lazySet/putOrdered)
> 2) B = Y (volatile read)
>
> T2
> 3) Y = 1 (compare and set)
> 4) A = X (volatile read)
>
> Is it possible to get a final state of A = 1 and B = 0?
>
> My current suspicion is that it is, due to 1) and 2) being reordered.  If
> so, can the final state of A=1, B=0 be prevented by strengthening 1) to be
> a volatile store?
>
> Regards,
> Michael Barker.
>


-- 
Sent from my phone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160719/9a3437ca/attachment.html>

From gil at azul.com  Tue Jul 19 22:40:51 2016
From: gil at azul.com (Gil Tene)
Date: Wed, 20 Jul 2016 02:40:51 +0000
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
Message-ID: <CD67E529-3275-4910-97B5-68E915DD8DAD@azul.com>

Not an authoritative answer Mike, but:

1. Since (to my understanding) the effective StoreStore-fence-like behavior of lazySet/putOrdered occurs *before* the store to X below, and not after it, it has no effect (different from a regular store) on ordering in the sequence.

2. The a volatile read does not prevent previous stores from being reordered past it.

As a result of these two observations, T1 can validly be reordered to:

T1:
1) B = Y (volatile read)
2) X = 1 (lazySet/putOrdered)

Which would then make the result you ask about quite possible:

T1		T2

		Y = 1
B = Y
		A = X
X = 1


[Note that even if the StoreStore-like-fence behavior was after the store (which I believe isn't the case), the reordering above would be valid, since it would still not prevent crossing the volatile read]

— Gil.

> On Jul 19, 2016, at 7:11 PM, Michael Barker <mikeb01 at gmail.com> wrote:
> 
> Hi,
> 
> I have a question around ordering of events.
> 
> Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are shared on the heap and visible to T1 and T2.
> 
> Initially:
> 
> X = 0
> Y = 0;
> 
> T1:
> 1) X = 1 (lazySet/putOrdered)
> 2) B = Y (volatile read)
> 
> T2
> 3) Y = 1 (compare and set)
> 4) A = X (volatile read)
> 
> Is it possible to get a final state of A = 1 and B = 0?
> 
> My current suspicion is that it is, due to 1) and 2) being reordered.  If so, can the final state of A=1, B=0 be prevented by strengthening 1) to be a volatile store?
> 
> Regards,
> Michael Barker.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/856863e1/attachment.sig>

From martinrb at google.com  Tue Jul 19 22:42:12 2016
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 19 Jul 2016 19:42:12 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <004d01d1de6e$cdd67d90$698378b0$@aapt.net.au>
References: <004d01d1de6e$cdd67d90$698378b0$@aapt.net.au>
Message-ID: <CA+kOe0-Z7bHtYFcFXEOY=g8m7=zvDwMq-Pd9JNozoTkiDO48JA@mail.gmail.com>

On Fri, Jul 15, 2016 at 12:59 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:
>
>  Also note that C++11 Cmpxhng-SeqCst  mapping for Aarch64 does not add
> any additional explicit barriers:
>
> https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html
>

I've also been struggling to understand this, having thought of strong CAS
as a single atomic bidirectional fenced operation.

 Cmpxchng SeqCst is implemented using a ldaxr followed by a stlxr

I believe it is legal for relaxed memory ops before the ldaxr to be
reordered with the ldaxr
and likewise
I believe it is legal for relaxed memory ops after the stlxr to be
reordered with the stlxr
and then to be reordered with each other (roach motel style)
without violating sequential consistency of  ldaxr and stlxr and without
interfering with the use of these operations for implementing traditional
locks.  But seqlocks are not traditional locks - they're a little
"backwards".

I even have a mental model that justifies such behavior.  Suppose there is
a slow read in progress and the cpu happens to already have exclusive
access to the cache line containing the cas word.  It knows that the cas
will succeed because it owns the cache line.  But because of release
semantics, the release write cannot complete until the slow read
completes.  Cpus hate stalls, so starts executing subsequent relaxed
stores.  Unlike the stlxr, which has to wait for the slow read, there is
nothing in the spec to prevent the subsequent stores from being written to
memory immediately.  If the fast write and the slow read are to the same
memory location, the read before the cas can see the write after the cas!

"""The Store-Release places no additional ordering constraints on any loads
or stores appearing after the
Store-Release instruction."""
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160719/ef5ec204/attachment.html>

From vitalyd at gmail.com  Tue Jul 19 23:15:18 2016
From: vitalyd at gmail.com (Vitaly Davidovich)
Date: Tue, 19 Jul 2016 23:15:18 -0400
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <CD67E529-3275-4910-97B5-68E915DD8DAD@azul.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <CD67E529-3275-4910-97B5-68E915DD8DAD@azul.com>
Message-ID: <CAHjP37FV=PaYpwUcHL=feZjR_7m2oXZeC0Cd0MaKdMe-0hrTMw@mail.gmail.com>

On Tuesday, July 19, 2016, Gil Tene <gil at azul.com> wrote:

> Not an authoritative answer Mike, but:
>
> 1. Since (to my understanding) the effective StoreStore-fence-like
> behavior of lazySet/putOrdered occurs *before* the store to X below, and
> not after it, it has no effect (different from a regular store) on ordering
> in the sequence.

Yes, the storestore is before the store to X; if it was after, it would
defeat its purpose.  But as you say below, the placement of the storestore
doesn't matter in terms of preventing the volatile load from moving above
it - you need a storeLoad in between 1) and 2).

>
> 2. The a volatile read does not prevent previous stores from being
> reordered past it.
>
> As a result of these two observations, T1 can validly be reordered to:
>
> T1:
> 1) B = Y (volatile read)
> 2) X = 1 (lazySet/putOrdered)
>
> Which would then make the result you ask about quite possible:
>
> T1              T2
>
>                 Y = 1
> B = Y
>                 A = X
> X = 1
>
>
> [Note that even if the StoreStore-like-fence behavior was after the store
> (which I believe isn't the case), the reordering above would be valid,
> since it would still not prevent crossing the volatile read]


> — Gil.
>
> > On Jul 19, 2016, at 7:11 PM, Michael Barker <mikeb01 at gmail.com
> <javascript:;>> wrote:
> >
> > Hi,
> >
> > I have a question around ordering of events.
> >
> > Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
> shared on the heap and visible to T1 and T2.
> >
> > Initially:
> >
> > X = 0
> > Y = 0;
> >
> > T1:
> > 1) X = 1 (lazySet/putOrdered)
> > 2) B = Y (volatile read)
> >
> > T2
> > 3) Y = 1 (compare and set)
> > 4) A = X (volatile read)
> >
> > Is it possible to get a final state of A = 1 and B = 0?
> >
> > My current suspicion is that it is, due to 1) and 2) being reordered.
> If so, can the final state of A=1, B=0 be prevented by strengthening 1) to
> be a volatile store?
> >
> > Regards,
> > Michael Barker.
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <javascript:;>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-- 
Sent from my phone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160719/27b7c194/attachment-0001.html>

From jsampson at guidewire.com  Wed Jul 20 01:19:58 2016
From: jsampson at guidewire.com (Justin Sampson)
Date: Wed, 20 Jul 2016 05:19:58 +0000
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
Message-ID: <BN3PR05MB25162AA59D1E6D30C2068E27D1080@BN3PR05MB2516.namprd05.prod.outlook.com>

Hi Michael,

I'm confused by the question. If T2 runs completely after T1, you get A=1 and B=0 without any reordering whatsoever. The only outcome that is impossible without reordering is A=0 and B=0. Is that the case you're asking about?

Cheers,
Justin


From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Michael Barker
Sent: Tuesday, July 19, 2016 7:11 PM
To: concurrency-interest
Subject: [concurrency-interest] Ordering Question

Hi,

I have a question around ordering of events.

Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are shared on the heap and visible to T1 and T2.

Initially:

X = 0
Y = 0;

T1:
1) X = 1 (lazySet/putOrdered)
2) B = Y (volatile read)

T2
3) Y = 1 (compare and set)
4) A = X (volatile read)

Is it possible to get a final state of A = 1 and B = 0?

My current suspicion is that it is, due to 1) and 2) being reordered.  If so, can the final state of A=1, B=0 be prevented by strengthening 1) to be a volatile store?

Regards,
Michael Barker.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/5777464f/attachment.html>

From mikeb01 at gmail.com  Wed Jul 20 02:42:01 2016
From: mikeb01 at gmail.com (Michael Barker)
Date: Wed, 20 Jul 2016 18:42:01 +1200
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <BN3PR05MB25162AA59D1E6D30C2068E27D1080@BN3PR05MB2516.namprd05.prod.outlook.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <BN3PR05MB25162AA59D1E6D30C2068E27D1080@BN3PR05MB2516.namprd05.prod.outlook.com>
Message-ID: <CALwNKeS9mMfkR5UNwad1nLDn9B_SRiUXZvJH6Yptn2gAg66xYg@mail.gmail.com>

Hi Justin,

Good spot, I did mean A = 0, B= 0.

Mike.

On 20 July 2016 at 17:19, Justin Sampson <jsampson at guidewire.com> wrote:

> Hi Michael,
>
>
>
> I'm confused by the question. If T2 runs completely after T1, you get A=1
> and B=0 without any reordering whatsoever. The only outcome that is
> impossible without reordering is A=0 and B=0. Is that the case you're
> asking about?
>
>
>
> Cheers,
>
> Justin
>
>
>
>
>
> *From:* Concurrency-interest [mailto:
> concurrency-interest-bounces at cs.oswego.edu] *On Behalf Of *Michael Barker
> *Sent:* Tuesday, July 19, 2016 7:11 PM
> *To:* concurrency-interest
> *Subject:* [concurrency-interest] Ordering Question
>
>
>
> Hi,
>
>
>
> I have a question around ordering of events.
>
>
>
> Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
> shared on the heap and visible to T1 and T2.
>
>
>
> Initially:
>
>
>
> X = 0
>
> Y = 0;
>
>
>
> T1:
>
> 1) X = 1 (lazySet/putOrdered)
>
> 2) B = Y (volatile read)
>
>
>
> T2
>
> 3) Y = 1 (compare and set)
>
> 4) A = X (volatile read)
>
>
>
> Is it possible to get a final state of A = 1 and B = 0?
>
>
>
> My current suspicion is that it is, due to 1) and 2) being reordered.  If
> so, can the final state of A=1, B=0 be prevented by strengthening 1) to be
> a volatile store?
>
>
>
> Regards,
>
> Michael Barker.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/30b3c316/attachment.html>

From aleksey.shipilev at oracle.com  Wed Jul 20 05:14:43 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 20 Jul 2016 12:14:43 +0300
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
Message-ID: <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>

On 07/20/2016 05:11 AM, Michael Barker wrote:
> I have a question around ordering of events.
> 
> Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
> shared on the heap and visible to T1 and T2.
> 
> Initially:
> 
> X = 0
> Y = 0;
> 
> T1:
> 1) X = 1 (lazySet/putOrdered)
> 2) B = Y (volatile read)
> 
> T2
> 3) Y = 1 (compare and set)
> 4) A = X (volatile read)
> 
> Is it possible to get a final state of A = 1 and B = 0?

(Later emails say the state in question is A = 0, B = 0)

> My current suspicion is that it is, due to 1) and 2) being reordered. 
> If so, can the final state of A=0, B=0 be prevented by strengthening 1)
> to be a volatile store?

Let's work backwards, and make all ops over X/Y volatile. This gives us
a nice property that all volatile ops are totally ordered by
synchronization order, and therefore either (B = Y) or (A = X) should
come last in the total order. Which automatically precludes (0, 0),
because the last read in the order has to read 1.

If X = 1 is a putOrdered/lazySet/release store, then total
synchronization order is out of the picture. It is actually hard to
reason about the acq/rel outcomes in the realm of plain JMM, but here is
a try. release-acquire brings a happens-before. Let's see if we can
construct a plausible execution that reads (0, 0) and is consistent with
JMM.

We have at least this plausible execution, which is happens-before
consistent:

 (X = 1) --hb--> (B = Y):0  // from program order
 (Y = 1) --hb--> (A = X):0  // from program order
 (X = 1)   ...   (A = X):0  // does not observe the write
 (Y = 1)   ...   (B = Y):0  // does not observe the write

Looking closer at this example, this looks like a Dekker idiom. It is
known to work with sequential consistency (volatiles):
 http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/volatiles/DekkerTest.java

http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerTest.java

And breaks without sequential consistency (acq/rels):

http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerRelaxation1Test.java

http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerRelaxation2Test.java

DekkerRelaxation1Test tests produces interesting result on x86, and
DekkerRelaxation2Test produces interesting result on POWER:

      [OK] o.o.j.t.varhandles.DekkerRelaxation1Test
    (fork: #1, iteration #1, JVM args: [-server])
  Observed state   Occurrences              Expectation
            0, 0       410,875   ACCEPTABLE_INTERESTING
            0, 1    76,450,930               ACCEPTABLE
            1, 0     1,628,809               ACCEPTABLE
            1, 1       116,146               ACCEPTABLE

     [OK] o.o.j.t.varhandles.DekkerRelaxation2Test
    (fork: #1, iteration #1, JVM args: [-server])
  Observed state   Occurrences              Expectation
            0, 0        98,773   ACCEPTABLE_INTERESTING
            0, 1    19,801,809               ACCEPTABLE
            1, 0     2,593,447               ACCEPTABLE
            1, 1        47,501               ACCEPTABLE

Bottom line: (usual rant about using special non-sequentially-consistent
access modes like there is no tomorrow)

Thanks,
-Aleksey


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/c932cc99/attachment-0001.sig>

From oleksandr.otenko at gmail.com  Wed Jul 20 05:48:24 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 20 Jul 2016 10:48:24 +0100
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
Message-ID: <57799422-B6EA-46D2-827E-1AD77EA34E63@gmail.com>

> If X = 1 is a putOrdered/lazySet/release store, then total
> synchronization order is out of the picture. It is actually hard to
> reason about the acq/rel outcomes in the realm of plain JMM, but here is
> a try. release-acquire brings a happens-before. Let's see if we can
> construct a plausible execution that reads (0, 0) and is consistent with
> JMM.



Since hb for putOrdered/laziSet aren’t specified in JMM, can you show which happens-before is brought by release-acquire here? (Or in general which ones are introduced? I have an idea what that might relate to, but need a rubber-stamped statement)


Alex


> On 20 Jul 2016, at 10:14, Aleksey Shipilev <aleksey.shipilev at oracle.com> wrote:
> 
> On 07/20/2016 05:11 AM, Michael Barker wrote:
>> I have a question around ordering of events.
>> 
>> Given, threads (T1, T2), and variables (A, B, X, Y) where X and Y are
>> shared on the heap and visible to T1 and T2.
>> 
>> Initially:
>> 
>> X = 0
>> Y = 0;
>> 
>> T1:
>> 1) X = 1 (lazySet/putOrdered)
>> 2) B = Y (volatile read)
>> 
>> T2
>> 3) Y = 1 (compare and set)
>> 4) A = X (volatile read)
>> 
>> Is it possible to get a final state of A = 1 and B = 0?
> 
> (Later emails say the state in question is A = 0, B = 0)
> 
>> My current suspicion is that it is, due to 1) and 2) being reordered. 
>> If so, can the final state of A=0, B=0 be prevented by strengthening 1)
>> to be a volatile store?
> 
> Let's work backwards, and make all ops over X/Y volatile. This gives us
> a nice property that all volatile ops are totally ordered by
> synchronization order, and therefore either (B = Y) or (A = X) should
> come last in the total order. Which automatically precludes (0, 0),
> because the last read in the order has to read 1.
> 
> If X = 1 is a putOrdered/lazySet/release store, then total
> synchronization order is out of the picture. It is actually hard to
> reason about the acq/rel outcomes in the realm of plain JMM, but here is
> a try. release-acquire brings a happens-before. Let's see if we can
> construct a plausible execution that reads (0, 0) and is consistent with
> JMM.
> 
> We have at least this plausible execution, which is happens-before
> consistent:
> 
> (X = 1) --hb--> (B = Y):0  // from program order
> (Y = 1) --hb--> (A = X):0  // from program order
> (X = 1)   ...   (A = X):0  // does not observe the write
> (Y = 1)   ...   (B = Y):0  // does not observe the write
> 
> Looking closer at this example, this looks like a Dekker idiom. It is
> known to work with sequential consistency (volatiles):
> http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/volatiles/DekkerTest.java
> 
> http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerTest.java
> 
> And breaks without sequential consistency (acq/rels):
> 
> http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerRelaxation1Test.java
> 
> http://hg.openjdk.java.net/code-tools/jcstress/file/6faec60f9c90/tests-custom/src/main/java/org/openjdk/jcstress/tests/varhandles/DekkerRelaxation2Test.java
> 
> DekkerRelaxation1Test tests produces interesting result on x86, and
> DekkerRelaxation2Test produces interesting result on POWER:
> 
>      [OK] o.o.j.t.varhandles.DekkerRelaxation1Test
>    (fork: #1, iteration #1, JVM args: [-server])
>  Observed state   Occurrences              Expectation
>            0, 0       410,875   ACCEPTABLE_INTERESTING
>            0, 1    76,450,930               ACCEPTABLE
>            1, 0     1,628,809               ACCEPTABLE
>            1, 1       116,146               ACCEPTABLE
> 
>     [OK] o.o.j.t.varhandles.DekkerRelaxation2Test
>    (fork: #1, iteration #1, JVM args: [-server])
>  Observed state   Occurrences              Expectation
>            0, 0        98,773   ACCEPTABLE_INTERESTING
>            0, 1    19,801,809               ACCEPTABLE
>            1, 0     2,593,447               ACCEPTABLE
>            1, 1        47,501               ACCEPTABLE
> 
> Bottom line: (usual rant about using special non-sequentially-consistent
> access modes like there is no tomorrow)
> 
> Thanks,
> -Aleksey
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aleksey.shipilev at oracle.com  Wed Jul 20 05:55:35 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 20 Jul 2016 12:55:35 +0300
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <57799422-B6EA-46D2-827E-1AD77EA34E63@gmail.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
 <57799422-B6EA-46D2-827E-1AD77EA34E63@gmail.com>
Message-ID: <de49a256-2640-411a-7120-7bedaf2e27f8@oracle.com>

On 07/20/2016 12:48 PM, Alex Otenko wrote:
>> If X = 1 is a putOrdered/lazySet/release store, then total 
>> synchronization order is out of the picture. It is actually hard
>> to reason about the acq/rel outcomes in the realm of plain JMM, but
>> here is a try. release-acquire brings a happens-before. Let's see
>> if we can construct a plausible execution that reads (0, 0) and is
>> consistent with JMM.
> 
> Since hb for putOrdered/laziSet aren’t specified in JMM, can you show
> which happens-before is brought by release-acquire here? (Or in
> general which ones are introduced? I have an idea what that might
> relate to, but need a rubber-stamped statement)

putOrdered/lazySet/release are not defined in JMM, so there is no
possibility for a rubber-stamped statement. I am using the closest
interpretation that is consistent with it's effect I can come by:
release-acquire brings happens-before, but not synchronization order.

See e.g. here:
  http://cs.oswego.edu/pipermail/concurrency-interest/2016-March/015037.html
  http://cs.oswego.edu/pipermail/concurrency-interest/2016-May/015104.html

Thanks,
-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160720/b2317273/attachment.sig>

From thurston at nomagicsoftware.com  Thu Jul 21 02:32:21 2016
From: thurston at nomagicsoftware.com (thurstonn)
Date: Wed, 20 Jul 2016 23:32:21 -0700 (MST)
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
Message-ID: <1469082741433-13622.post@n7.nabble.com>

Is it necessary that the two int instance variables (a, b) are declared
volatile in those tests that only access them through their respective
VarHandles?

Maybe prevents stack allocation?



--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/Ordering-Question-tp13612p13622.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From aleksey.shipilev at oracle.com  Thu Jul 21 05:21:01 2016
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 21 Jul 2016 12:21:01 +0300
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <1469082741433-13622.post@n7.nabble.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
 <1469082741433-13622.post@n7.nabble.com>
Message-ID: <a6f1aeb5-96eb-e540-5a93-2926e25a3dc9@oracle.com>

On 07/21/2016 09:32 AM, thurstonn wrote:
> Is it necessary that the two int instance variables (a, b) are declared
> volatile in those tests that only access them through their respective
> VarHandles?

No, it's not necessary.

-Aleksey


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160721/c9eb1783/attachment.sig>

From jsampson at guidewire.com  Thu Jul 21 15:02:22 2016
From: jsampson at guidewire.com (Justin Sampson)
Date: Thu, 21 Jul 2016 19:02:22 +0000
Subject: [concurrency-interest] Ordering Question
In-Reply-To: <de49a256-2640-411a-7120-7bedaf2e27f8@oracle.com>
References: <CALwNKeR7+F7ke6iXOerqqvFkwfMyR0mmOTcS42GXd6aH+ijv6A@mail.gmail.com>
 <a946c860-b293-1aac-da41-c3c2edb914b7@oracle.com>
 <57799422-B6EA-46D2-827E-1AD77EA34E63@gmail.com>
 <de49a256-2640-411a-7120-7bedaf2e27f8@oracle.com>
Message-ID: <BN3PR05MB2516504E7392C4B8D4704CBBD1090@BN3PR05MB2516.namprd05.prod.outlook.com>

This is a recurring question -- there was a thread 2 years ago about it:

http://cs.oswego.edu/pipermail/concurrency-interest/2014-September/#12929

This was my contribution:

"My own _guess_ based on the docs is that a full-volatile write ensures a
happens-before relation with _all_ subsequent volatile reads of the same
field, whereas a lazy/ordered write ensures a happens-before relation
with any subsequent volatile read _that sees the value written_ by that
write.  Therefore lazy writes guarantee, for example, safe publication
of objects, without actually forcing everything immediately out to main
memory.  But all bets are off, of course, if the read itself is not a
volatile read."

Cheers,
Justin


-----Original Message-----
From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Aleksey Shipilev
Sent: Wednesday, July 20, 2016 2:56 AM
To: Alex Otenko
Cc: concurrency-interest
Subject: Re: [concurrency-interest] Ordering Question

On 07/20/2016 12:48 PM, Alex Otenko wrote:
>> If X = 1 is a putOrdered/lazySet/release store, then total 
>> synchronization order is out of the picture. It is actually hard
>> to reason about the acq/rel outcomes in the realm of plain JMM, but
>> here is a try. release-acquire brings a happens-before. Let's see
>> if we can construct a plausible execution that reads (0, 0) and is
>> consistent with JMM.
> 
> Since hb for putOrdered/laziSet aren’t specified in JMM, can you show
> which happens-before is brought by release-acquire here? (Or in
> general which ones are introduced? I have an idea what that might
> relate to, but need a rubber-stamped statement)

putOrdered/lazySet/release are not defined in JMM, so there is no
possibility for a rubber-stamped statement. I am using the closest
interpretation that is consistent with it's effect I can come by:
release-acquire brings happens-before, but not synchronization order.

See e.g. here:
  http://cs.oswego.edu/pipermail/concurrency-interest/2016-March/015037.html
  http://cs.oswego.edu/pipermail/concurrency-interest/2016-May/015104.html

Thanks,
-Aleksey


From pavel.rappo at gmail.com  Sun Jul 24 08:57:48 2016
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Sun, 24 Jul 2016 13:57:48 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
Message-ID: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>

Hi,

Is it generally safe to reuse an instance of CompletableFuture? Or am I risking
with memory leaks due to dependants build up?

Say, I have a method that returns a CF. In some cases it may return a CF
straight away indicating that the action has been already done. Should I always
create a new completed CF, or can I reuse a pre-cached one?

There's a comment in the class itself, but I'm not sure I understand it enough
to make a conclusion:

     * ...Without precautions, CompletableFutures would be prone to
     * garbage accumulation as chains of Completions build up, each
     * pointing back to its sources. So we null out fields as soon as
     * possible.  The screening checks needed anyway harmlessly ignore
     * null arguments that may have been obtained during races with
     * threads nulling out fields.  We also try to unlink non-isLive
     * (fired or cancelled) Completions from stacks that might
     * otherwise never be popped: Method cleanStack always unlinks non
     * isLive completions from the head of stack; others may
     * occasionally remain if racing with other cancellations or
     * removals...

Thanks,
-Pavel

From martinrb at google.com  Sun Jul 24 12:19:43 2016
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 24 Jul 2016 09:19:43 -0700
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
Message-ID: <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>

Don't reuse CompletableFutures.
Most obviously because they're mutable.

See also https://bugs.openjdk.java.net/browse/JDK-8161600

On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Hi,
>
> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> risking
> with memory leaks due to dependants build up?
>
> Say, I have a method that returns a CF. In some cases it may return a CF
> straight away indicating that the action has been already done. Should I
> always
> create a new completed CF, or can I reuse a pre-cached one?
>
> There's a comment in the class itself, but I'm not sure I understand it
> enough
> to make a conclusion:
>
>      * ...Without precautions, CompletableFutures would be prone to
>      * garbage accumulation as chains of Completions build up, each
>      * pointing back to its sources. So we null out fields as soon as
>      * possible.  The screening checks needed anyway harmlessly ignore
>      * null arguments that may have been obtained during races with
>      * threads nulling out fields.  We also try to unlink non-isLive
>      * (fired or cancelled) Completions from stacks that might
>      * otherwise never be popped: Method cleanStack always unlinks non
>      * isLive completions from the head of stack; others may
>      * occasionally remain if racing with other cancellations or
>      * removals...
>
> Thanks,
> -Pavel
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160724/4ab32bff/attachment.html>

From boehm at acm.org  Sun Jul 24 12:22:24 2016
From: boehm at acm.org (Hans Boehm)
Date: Sun, 24 Jul 2016 09:22:24 -0700
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
	theory?
In-Reply-To: <CA+kOe0-Z7bHtYFcFXEOY=g8m7=zvDwMq-Pd9JNozoTkiDO48JA@mail.gmail.com>
References: <004d01d1de6e$cdd67d90$698378b0$@aapt.net.au>
 <CA+kOe0-Z7bHtYFcFXEOY=g8m7=zvDwMq-Pd9JNozoTkiDO48JA@mail.gmail.com>
Message-ID: <CAPUmR1Z0sby4DpOU-DYrNkpsMs_Eqg+pawkRfiJcm_hfQ6_c2w@mail.gmail.com>

I think a good analogy is to compare the Aarch64 CAS implementation with
CAS implemented on top of a roach-motel lock associated with the CAS
location. The ordering properties are very simillar for both.

This is a bit unfamiliar because most traditional lock implementations have
included fences, and hence have not allowed full roach-motel reordering at
the hardware level. But Itanium had fence-less lock implementations before
Aarch64 did, with even weaker acquire/release operations.

(On Itanium, I believe

x = a;
unlock l1;
lock l2;
y = a;

does not order the two stores, since release and acquire operations can be
reordered.  On Aarch64, it happens to do so.  None of which is detectable
in data-race-free programs.)

On Tue, Jul 19, 2016 at 7:42 PM, Martin Buchholz <martinrb at google.com>
wrote:

>
>
> On Fri, Jul 15, 2016 at 12:59 AM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>>
>>  Also note that C++11 Cmpxhng-SeqCst  mapping for Aarch64 does not add
>> any additional explicit barriers:
>>
>> https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html
>>
>
> I've also been struggling to understand this, having thought of strong CAS
> as a single atomic bidirectional fenced operation.
>
>  Cmpxchng SeqCst is implemented using a ldaxr followed by a stlxr
>
> I believe it is legal for relaxed memory ops before the ldaxr to be
> reordered with the ldaxr
> and likewise
> I believe it is legal for relaxed memory ops after the stlxr to be
> reordered with the stlxr
> and then to be reordered with each other (roach motel style)
> without violating sequential consistency of  ldaxr and stlxr and without
> interfering with the use of these operations for implementing traditional
> locks.  But seqlocks are not traditional locks - they're a little
> "backwards".
>
> I even have a mental model that justifies such behavior.  Suppose there is
> a slow read in progress and the cpu happens to already have exclusive
> access to the cache line containing the cas word.  It knows that the cas
> will succeed because it owns the cache line.  But because of release
> semantics, the release write cannot complete until the slow read
> completes.  Cpus hate stalls, so starts executing subsequent relaxed
> stores.  Unlike the stlxr, which has to wait for the slow read, there is
> nothing in the spec to prevent the subsequent stores from being written to
> memory immediately.  If the fast write and the slow read are to the same
> memory location, the read before the cas can see the write after the cas!
>
> """The Store-Release places no additional ordering constraints on any
> loads or stores appearing after the
> Store-Release instruction."""
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160724/8dd9c7e9/attachment.html>

From viktor.klang at gmail.com  Sun Jul 24 14:07:22 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Sun, 24 Jul 2016 20:07:22 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
Message-ID: <CANPzfU_D57-F6JgYPqUyGtBmcvVhRUUmkmghoQB5z7N1=ro2hA@mail.gmail.com>

A possible solution is to return CompletionStage rather than
CompletableFuture.

-- 
Cheers,
√

On Jul 24, 2016 18:23, "Martin Buchholz" <martinrb at google.com> wrote:

> Don't reuse CompletableFutures.
> Most obviously because they're mutable.
>
> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>
> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
> wrote:
>
>> Hi,
>>
>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
>> risking
>> with memory leaks due to dependants build up?
>>
>> Say, I have a method that returns a CF. In some cases it may return a CF
>> straight away indicating that the action has been already done. Should I
>> always
>> create a new completed CF, or can I reuse a pre-cached one?
>>
>> There's a comment in the class itself, but I'm not sure I understand it
>> enough
>> to make a conclusion:
>>
>>      * ...Without precautions, CompletableFutures would be prone to
>>      * garbage accumulation as chains of Completions build up, each
>>      * pointing back to its sources. So we null out fields as soon as
>>      * possible.  The screening checks needed anyway harmlessly ignore
>>      * null arguments that may have been obtained during races with
>>      * threads nulling out fields.  We also try to unlink non-isLive
>>      * (fired or cancelled) Completions from stacks that might
>>      * otherwise never be popped: Method cleanStack always unlinks non
>>      * isLive completions from the head of stack; others may
>>      * occasionally remain if racing with other cancellations or
>>      * removals...
>>
>> Thanks,
>> -Pavel
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160724/613062ec/attachment.html>

From pavel.rappo at gmail.com  Sun Jul 24 14:11:39 2016
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Sun, 24 Jul 2016 19:11:39 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
Message-ID: <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>

Hi Martin,

Quite a strong statement. I don't think an isolated fact of mutability
of an entity precludes us from reusing this entity (pool of objects?
reusable buffers?).

You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
value), right? In my example the CF was returned by an API to a user
and this CF was completed prior to be returned.

On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com> wrote:
> Don't reuse CompletableFutures.
> Most obviously because they're mutable.
>
> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>
> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>
>> Hi,
>>
>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
>> risking
>> with memory leaks due to dependants build up?
>>
>> Say, I have a method that returns a CF. In some cases it may return a CF
>> straight away indicating that the action has been already done. Should I
>> always
>> create a new completed CF, or can I reuse a pre-cached one?
>>
>> There's a comment in the class itself, but I'm not sure I understand it
>> enough
>> to make a conclusion:
>>
>>      * ...Without precautions, CompletableFutures would be prone to
>>      * garbage accumulation as chains of Completions build up, each
>>      * pointing back to its sources. So we null out fields as soon as
>>      * possible.  The screening checks needed anyway harmlessly ignore
>>      * null arguments that may have been obtained during races with
>>      * threads nulling out fields.  We also try to unlink non-isLive
>>      * (fired or cancelled) Completions from stacks that might
>>      * otherwise never be popped: Method cleanStack always unlinks non
>>      * isLive completions from the head of stack; others may
>>      * occasionally remain if racing with other cancellations or
>>      * removals...
>>
>> Thanks,
>> -Pavel
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

From pavel.rappo at gmail.com  Sun Jul 24 14:17:55 2016
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Sun, 24 Jul 2016 19:17:55 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CANPzfU_D57-F6JgYPqUyGtBmcvVhRUUmkmghoQB5z7N1=ro2hA@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CANPzfU_D57-F6JgYPqUyGtBmcvVhRUUmkmghoQB5z7N1=ro2hA@mail.gmail.com>
Message-ID: <CAChcVumNC8YpbPsS=js49cBuZ3FjDgcUjJ6hrkycxTiXG-vRiA@mail.gmail.com>

In my experience, get() and join() are too precious to lose them and
CompletionStage.toCompletableFuture is too weakly defined (UOE) to be
relied upon. So either people will do everything in an async fashion
or they will come up with some tricks like:

CompletionStage<?> cs = null;
CompletableFuture<?> cf =
CompletableFuture.completedFuture(null).thenCompose(x -> cs);

On Sun, Jul 24, 2016 at 7:07 PM, Viktor Klang <viktor.klang at gmail.com> wrote:
> A possible solution is to return CompletionStage rather than
> CompletableFuture.
>
> --
> Cheers,
> √
>
>
> On Jul 24, 2016 18:23, "Martin Buchholz" <martinrb at google.com> wrote:
>>
>> Don't reuse CompletableFutures.
>> Most obviously because they're mutable.
>>
>> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>>
>> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
>> wrote:
>>>
>>> Hi,
>>>
>>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
>>> risking
>>> with memory leaks due to dependants build up?
>>>
>>> Say, I have a method that returns a CF. In some cases it may return a CF
>>> straight away indicating that the action has been already done. Should I
>>> always
>>> create a new completed CF, or can I reuse a pre-cached one?
>>>
>>> There's a comment in the class itself, but I'm not sure I understand it
>>> enough
>>> to make a conclusion:
>>>
>>>      * ...Without precautions, CompletableFutures would be prone to
>>>      * garbage accumulation as chains of Completions build up, each
>>>      * pointing back to its sources. So we null out fields as soon as
>>>      * possible.  The screening checks needed anyway harmlessly ignore
>>>      * null arguments that may have been obtained during races with
>>>      * threads nulling out fields.  We also try to unlink non-isLive
>>>      * (fired or cancelled) Completions from stacks that might
>>>      * otherwise never be popped: Method cleanStack always unlinks non
>>>      * isLive completions from the head of stack; others may
>>>      * occasionally remain if racing with other cancellations or
>>>      * removals...
>>>
>>> Thanks,
>>> -Pavel
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

From martinrb at google.com  Sun Jul 24 15:32:25 2016
From: martinrb at google.com (Martin Buchholz)
Date: Sun, 24 Jul 2016 12:32:25 -0700
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
Message-ID: <CA+kOe08U1gm2PfYaCcNd6nH1_M9ScO7qvnkCFRH_86RaBEe3hA@mail.gmail.com>

Arguing for the other side ...

A completed future will never have a chain of dependent completions build
up because they will all be triggered, and if the future was already
completed any continuation will be executed immediately.

It may make sense to reuse CompletableFutures where the mutability has been
removed, e.g. by subclassing.
Are we safe if we override just obtrudeValue and obtrudeException on a
completed future?
Should j.u.c. provide such a thing?
Should j.u.c. provide separate classes for providers and consumers (read
only!) of the future value?

On Sun, Jul 24, 2016 at 11:11 AM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Hi Martin,
>
> Quite a strong statement. I don't think an isolated fact of mutability
> of an entity precludes us from reusing this entity (pool of objects?
> reusable buffers?).
>
> You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
> value), right? In my example the CF was returned by an API to a user
> and this CF was completed prior to be returned.
>
> On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com>
> wrote:
> > Don't reuse CompletableFutures.
> > Most obviously because they're mutable.
> >
> > See also https://bugs.openjdk.java.net/browse/JDK-8161600
> >
> > On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
> wrote:
> >>
> >> Hi,
> >>
> >> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> >> risking
> >> with memory leaks due to dependants build up?
> >>
> >> Say, I have a method that returns a CF. In some cases it may return a CF
> >> straight away indicating that the action has been already done. Should I
> >> always
> >> create a new completed CF, or can I reuse a pre-cached one?
> >>
> >> There's a comment in the class itself, but I'm not sure I understand it
> >> enough
> >> to make a conclusion:
> >>
> >>      * ...Without precautions, CompletableFutures would be prone to
> >>      * garbage accumulation as chains of Completions build up, each
> >>      * pointing back to its sources. So we null out fields as soon as
> >>      * possible.  The screening checks needed anyway harmlessly ignore
> >>      * null arguments that may have been obtained during races with
> >>      * threads nulling out fields.  We also try to unlink non-isLive
> >>      * (fired or cancelled) Completions from stacks that might
> >>      * otherwise never be popped: Method cleanStack always unlinks non
> >>      * isLive completions from the head of stack; others may
> >>      * occasionally remain if racing with other cancellations or
> >>      * removals...
> >>
> >> Thanks,
> >> -Pavel
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160724/c89de705/attachment.html>

From dl at cs.oswego.edu  Sun Jul 24 15:41:43 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 24 Jul 2016 15:41:43 -0400
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CA+kOe08U1gm2PfYaCcNd6nH1_M9ScO7qvnkCFRH_86RaBEe3hA@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <CA+kOe08U1gm2PfYaCcNd6nH1_M9ScO7qvnkCFRH_86RaBEe3hA@mail.gmail.com>
Message-ID: <0d17ace4-5025-22dd-d35c-67fae44e2f47@cs.oswego.edu>

On 07/24/2016 03:32 PM, Martin Buchholz wrote:

> It may make sense to reuse CompletableFutures where the mutability has been
> removed, e.g. by subclassing.
> Are we safe if we override just obtrudeValue and obtrudeException on a completed
> future?
> Should j.u.c. provide such a thing?

It takes a long enough time to put out major releases that it is easy
to forget that this has been in CompletableFuture for almost a year,
but still not routinely available until jdk9:

     /**
      * Returns a new CompletionStage that is already completed with
      * the given value and supports only those methods in
      * interface {@link CompletionStage}.
      *
      * @param value the value
      * @param <U> the type of the value
      * @return the completed CompletionStage
      * @since 9
      */
     public static <U> CompletionStage<U> completedStage(U value) {
         return new MinimalStage<U>((value == null) ? NIL : value);
     }



From viktor.klang at gmail.com  Sun Jul 24 15:45:07 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Sun, 24 Jul 2016 21:45:07 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAChcVumNC8YpbPsS=js49cBuZ3FjDgcUjJ6hrkycxTiXG-vRiA@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CANPzfU_D57-F6JgYPqUyGtBmcvVhRUUmkmghoQB5z7N1=ro2hA@mail.gmail.com>
 <CAChcVumNC8YpbPsS=js49cBuZ3FjDgcUjJ6hrkycxTiXG-vRiA@mail.gmail.com>
Message-ID: <CANPzfU9ASvauLMmavYeeUFLHiG786A9TLhAqQr55E5ZLWXBujw@mail.gmail.com>

Personally, I'd recommend avoiding blocking at "all" cost.

When there's a qualified need to use .get() and .join(): create a new
CompletableFuture which will be completed by the returned CompletionStage
(this is not a trick!).

-- 
Cheers,
√

On Jul 24, 2016 20:18, "Pavel Rappo" <pavel.rappo at gmail.com> wrote:

> In my experience, get() and join() are too precious to lose them and
> CompletionStage.toCompletableFuture is too weakly defined (UOE) to be
> relied upon. So either people will do everything in an async fashion
> or they will come up with some tricks like:
>
> CompletionStage<?> cs = null;
> CompletableFuture<?> cf =
> CompletableFuture.completedFuture(null).thenCompose(x -> cs);
>
> On Sun, Jul 24, 2016 at 7:07 PM, Viktor Klang <viktor.klang at gmail.com>
> wrote:
> > A possible solution is to return CompletionStage rather than
> > CompletableFuture.
> >
> > --
> > Cheers,
> > √
> >
> >
> > On Jul 24, 2016 18:23, "Martin Buchholz" <martinrb at google.com> wrote:
> >>
> >> Don't reuse CompletableFutures.
> >> Most obviously because they're mutable.
> >>
> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
> >>
> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
> >> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> >>> risking
> >>> with memory leaks due to dependants build up?
> >>>
> >>> Say, I have a method that returns a CF. In some cases it may return a
> CF
> >>> straight away indicating that the action has been already done. Should
> I
> >>> always
> >>> create a new completed CF, or can I reuse a pre-cached one?
> >>>
> >>> There's a comment in the class itself, but I'm not sure I understand it
> >>> enough
> >>> to make a conclusion:
> >>>
> >>>      * ...Without precautions, CompletableFutures would be prone to
> >>>      * garbage accumulation as chains of Completions build up, each
> >>>      * pointing back to its sources. So we null out fields as soon as
> >>>      * possible.  The screening checks needed anyway harmlessly ignore
> >>>      * null arguments that may have been obtained during races with
> >>>      * threads nulling out fields.  We also try to unlink non-isLive
> >>>      * (fired or cancelled) Completions from stacks that might
> >>>      * otherwise never be popped: Method cleanStack always unlinks non
> >>>      * isLive completions from the head of stack; others may
> >>>      * occasionally remain if racing with other cancellations or
> >>>      * removals...
> >>>
> >>> Thanks,
> >>> -Pavel
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160724/019d477f/attachment-0001.html>

From pavel.rappo at gmail.com  Sun Jul 24 16:20:02 2016
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Sun, 24 Jul 2016 21:20:02 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <0d17ace4-5025-22dd-d35c-67fae44e2f47@cs.oswego.edu>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <CA+kOe08U1gm2PfYaCcNd6nH1_M9ScO7qvnkCFRH_86RaBEe3hA@mail.gmail.com>
 <0d17ace4-5025-22dd-d35c-67fae44e2f47@cs.oswego.edu>
Message-ID: <CAChcVund0H-4Jtjv4fk3LW0z1kBGwj9S=CV329ST+H_XcCPZHw@mail.gmail.com>

Hi Doug,

Pardon me, are you sure you replied to Martin rather than to Viktor?
Viktor has suggested using CS instead of CF. What Martin has asked is
whether it makes sense to have something which is-a CompletableFuture
but without the "obtrude" logic.

On Sun, Jul 24, 2016 at 8:41 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> On 07/24/2016 03:32 PM, Martin Buchholz wrote:
>
>> It may make sense to reuse CompletableFutures where the mutability has
>> been
>> removed, e.g. by subclassing.
>> Are we safe if we override just obtrudeValue and obtrudeException on a
>> completed
>> future?
>> Should j.u.c. provide such a thing?
>
>
> It takes a long enough time to put out major releases that it is easy
> to forget that this has been in CompletableFuture for almost a year,
> but still not routinely available until jdk9:
>
>     /**
>      * Returns a new CompletionStage that is already completed with
>      * the given value and supports only those methods in
>      * interface {@link CompletionStage}.
>      *
>      * @param value the value
>      * @param <U> the type of the value
>      * @return the completed CompletionStage
>      * @since 9
>      */
>     public static <U> CompletionStage<U> completedStage(U value) {
>         return new MinimalStage<U>((value == null) ? NIL : value);
>
>     }
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Sun Jul 24 17:27:49 2016
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 24 Jul 2016 17:27:49 -0400
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAChcVund0H-4Jtjv4fk3LW0z1kBGwj9S=CV329ST+H_XcCPZHw@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <CA+kOe08U1gm2PfYaCcNd6nH1_M9ScO7qvnkCFRH_86RaBEe3hA@mail.gmail.com>
 <0d17ace4-5025-22dd-d35c-67fae44e2f47@cs.oswego.edu>
 <CAChcVund0H-4Jtjv4fk3LW0z1kBGwj9S=CV329ST+H_XcCPZHw@mail.gmail.com>
Message-ID: <cf56926d-2acd-eb7a-3fdd-8524342c916d@cs.oswego.edu>

On 07/24/2016 04:20 PM, Pavel Rappo wrote:
> Viktor has suggested using CS instead of CF. What Martin has asked is
> whether it makes sense to have something which is-a CompletableFuture
> but without the "obtrude" logic.

And others have had other opinions about exactly which methods
to allow in read-only-ish contexts (googling will find 4 different
discussions on this list). So for jdk9, we predefine the most minimal
one, and make it relatively easy to define others. So I think we
have all the possibilities covered; some more easily by users
than others. See the example in class-level javadocs:

http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/CompletableFuture.html

-Doug


From aph at redhat.com  Mon Jul 25 04:58:09 2016
From: aph at redhat.com (Andrew Haley)
Date: Mon, 25 Jul 2016 09:58:09 +0100
Subject: [concurrency-interest] Does StampedLock need a releaseFence in
 theory?
In-Reply-To: <5789220F.30708@cs.oswego.edu>
References: <CA+kOe0-yucV7zTgb6hWythLg0Qg=L+sLHXDDj2jxvFm=v1gUEQ@mail.gmail.com>
 <CAPUmR1bfDEG68S-Kcs+DtZB-khQ0WKoYnaG5ZRjGP=oXe9jMYg@mail.gmail.com>
 <57874BFA.60302@redhat.com>
 <CA+kOe0_5xnWGRbS-RMMyQM6ZjxBFxWYPt80JDKX+xEv3ggu1Vw@mail.gmail.com>
 <5787C8FC.2050407@redhat.com>
 <CAPUmR1b9mMoxLt61KN6U+4RGA0p8G52FukQ=EVWwSWoheTqs3Q@mail.gmail.com>
 <57889620.80003@redhat.com> <20160715084712.GB3897@arm.com>
 <5788CE16.40302@redhat.com> <20160715142719.GA15954@arm.com>
 <5789220F.30708@cs.oswego.edu>
Message-ID: <5795D4A1.1010207@redhat.com>

On 15/07/16 18:49, Doug Lea wrote:

> Thanks to the ARM folks for finding the tiny bit of wiggle room in
> CAS specs that might in theory (if not in practice) require the
> complementary fence on unlock. Too bad this will slow down some
> implementations for no good reason, but probably not noticeably.

Probably not.  From what I've seen, a StoreStore fence on ARMv8
doesn't cost anything significant when the store buffer is already
empty.  Of course this might change in future designs.

Andrew.

From oleksandr.otenko at gmail.com  Thu Jul 28 05:52:46 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 28 Jul 2016 10:52:46 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
Message-ID: <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>

An isolated fact of reuse is also not very meaningful. You need cross-board support for reuse for the bulk of memory/stateful/stateless objects referenced by CompletableFuture.

Alex

> On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
> 
> Hi Martin,
> 
> Quite a strong statement. I don't think an isolated fact of mutability
> of an entity precludes us from reusing this entity (pool of objects?
> reusable buffers?).
> 
> You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
> value), right? In my example the CF was returned by an API to a user
> and this CF was completed prior to be returned.
> 
> On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com> wrote:
>> Don't reuse CompletableFutures.
>> Most obviously because they're mutable.
>> 
>> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>> 
>> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>> 
>>> Hi,
>>> 
>>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
>>> risking
>>> with memory leaks due to dependants build up?
>>> 
>>> Say, I have a method that returns a CF. In some cases it may return a CF
>>> straight away indicating that the action has been already done. Should I
>>> always
>>> create a new completed CF, or can I reuse a pre-cached one?
>>> 
>>> There's a comment in the class itself, but I'm not sure I understand it
>>> enough
>>> to make a conclusion:
>>> 
>>>     * ...Without precautions, CompletableFutures would be prone to
>>>     * garbage accumulation as chains of Completions build up, each
>>>     * pointing back to its sources. So we null out fields as soon as
>>>     * possible.  The screening checks needed anyway harmlessly ignore
>>>     * null arguments that may have been obtained during races with
>>>     * threads nulling out fields.  We also try to unlink non-isLive
>>>     * (fired or cancelled) Completions from stacks that might
>>>     * otherwise never be popped: Method cleanStack always unlinks non
>>>     * isLive completions from the head of stack; others may
>>>     * occasionally remain if racing with other cancellations or
>>>     * removals...
>>> 
>>> Thanks,
>>> -Pavel
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From pavel.rappo at gmail.com  Thu Jul 28 10:12:39 2016
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Thu, 28 Jul 2016 15:12:39 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
Message-ID: <CAChcVunJR0+5QjEz9Swi2zLb-fmDgy5waWi8XRmdNbCiJfbyyQ@mail.gmail.com>

True. In my particular use case this property is satisfied.

On Thursday 28 July 2016, Alex Otenko <oleksandr.otenko at gmail.com> wrote:

> An isolated fact of reuse is also not very meaningful. You need
> cross-board support for reuse for the bulk of memory/stateful/stateless
> objects referenced by CompletableFuture.
>
> Alex
>
> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com
> <javascript:;>> wrote:
> >
> > Hi Martin,
> >
> > Quite a strong statement. I don't think an isolated fact of mutability
> > of an entity precludes us from reusing this entity (pool of objects?
> > reusable buffers?).
> >
> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
> > value), right? In my example the CF was returned by an API to a user
> > and this CF was completed prior to be returned.
> >
> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com
> <javascript:;>> wrote:
> >> Don't reuse CompletableFutures.
> >> Most obviously because they're mutable.
> >>
> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
> >>
> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com
> <javascript:;>> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> >>> risking
> >>> with memory leaks due to dependants build up?
> >>>
> >>> Say, I have a method that returns a CF. In some cases it may return a
> CF
> >>> straight away indicating that the action has been already done. Should
> I
> >>> always
> >>> create a new completed CF, or can I reuse a pre-cached one?
> >>>
> >>> There's a comment in the class itself, but I'm not sure I understand it
> >>> enough
> >>> to make a conclusion:
> >>>
> >>>     * ...Without precautions, CompletableFutures would be prone to
> >>>     * garbage accumulation as chains of Completions build up, each
> >>>     * pointing back to its sources. So we null out fields as soon as
> >>>     * possible.  The screening checks needed anyway harmlessly ignore
> >>>     * null arguments that may have been obtained during races with
> >>>     * threads nulling out fields.  We also try to unlink non-isLive
> >>>     * (fired or cancelled) Completions from stacks that might
> >>>     * otherwise never be popped: Method cleanStack always unlinks non
> >>>     * isLive completions from the head of stack; others may
> >>>     * occasionally remain if racing with other cancellations or
> >>>     * removals...
> >>>
> >>> Thanks,
> >>> -Pavel
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu <javascript:;>
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <javascript:;>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/5d4e66cd/attachment.html>

From viktor.klang at gmail.com  Thu Jul 28 11:17:33 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 28 Jul 2016 17:17:33 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
Message-ID: <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>

Isn't this a general requirement for concurrency (coordination) structures?

-- 
Cheers,
√

On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:

> An isolated fact of reuse is also not very meaningful. You need
> cross-board support for reuse for the bulk of memory/stateful/stateless
> objects referenced by CompletableFuture.
>
> Alex
>
> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
> >
> > Hi Martin,
> >
> > Quite a strong statement. I don't think an isolated fact of mutability
> > of an entity precludes us from reusing this entity (pool of objects?
> > reusable buffers?).
> >
> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
> > value), right? In my example the CF was returned by an API to a user
> > and this CF was completed prior to be returned.
> >
> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com>
> wrote:
> >> Don't reuse CompletableFutures.
> >> Most obviously because they're mutable.
> >>
> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
> >>
> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> >>> risking
> >>> with memory leaks due to dependants build up?
> >>>
> >>> Say, I have a method that returns a CF. In some cases it may return a
> CF
> >>> straight away indicating that the action has been already done. Should
> I
> >>> always
> >>> create a new completed CF, or can I reuse a pre-cached one?
> >>>
> >>> There's a comment in the class itself, but I'm not sure I understand it
> >>> enough
> >>> to make a conclusion:
> >>>
> >>>     * ...Without precautions, CompletableFutures would be prone to
> >>>     * garbage accumulation as chains of Completions build up, each
> >>>     * pointing back to its sources. So we null out fields as soon as
> >>>     * possible.  The screening checks needed anyway harmlessly ignore
> >>>     * null arguments that may have been obtained during races with
> >>>     * threads nulling out fields.  We also try to unlink non-isLive
> >>>     * (fired or cancelled) Completions from stacks that might
> >>>     * otherwise never be popped: Method cleanStack always unlinks non
> >>>     * isLive completions from the head of stack; others may
> >>>     * occasionally remain if racing with other cancellations or
> >>>     * removals...
> >>>
> >>> Thanks,
> >>> -Pavel
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/41b9f086/attachment.html>

From oleksandr.otenko at gmail.com  Thu Jul 28 14:26:13 2016
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 28 Jul 2016 19:26:13 +0100
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
 <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
Message-ID: <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>

What is? Reusability?

I don’t know about CompletableFuture specifically, but mutability has an immense impact on the implementation, since reuse requires knowing that the mutator repurposing the structure is the last entity looking at it in the old guise. Then there are gotchas that whoever keeps a reference to it, must also have a way of knowing which version of the thing it is looking at - like, suddenly you are not allowed to pass around CompletableFuture uncontrollably, need to devise ways to solve ABA problem - which becomes a problem due to mutability.

Alex

> On 28 Jul 2016, at 16:17, Viktor Klang <viktor.klang at gmail.com> wrote:
> 
> Isn't this a general requirement for concurrency (coordination) structures?
> 
> -- 
> Cheers,
> √
> 
> 
> On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> An isolated fact of reuse is also not very meaningful. You need cross-board support for reuse for the bulk of memory/stateful/stateless objects referenced by CompletableFuture.
> 
> Alex
> 
> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com <mailto:pavel.rappo at gmail.com>> wrote:
> >
> > Hi Martin,
> >
> > Quite a strong statement. I don't think an isolated fact of mutability
> > of an entity precludes us from reusing this entity (pool of objects?
> > reusable buffers?).
> >
> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
> > value), right? In my example the CF was returned by an API to a user
> > and this CF was completed prior to be returned.
> >
> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com <mailto:martinrb at google.com>> wrote:
> >> Don't reuse CompletableFutures.
> >> Most obviously because they're mutable.
> >>
> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600 <https://bugs.openjdk.java.net/browse/JDK-8161600>
> >>
> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com <mailto:pavel.rappo at gmail.com>> wrote:
> >>>
> >>> Hi,
> >>>
> >>> Is it generally safe to reuse an instance of CompletableFuture? Or am I
> >>> risking
> >>> with memory leaks due to dependants build up?
> >>>
> >>> Say, I have a method that returns a CF. In some cases it may return a CF
> >>> straight away indicating that the action has been already done. Should I
> >>> always
> >>> create a new completed CF, or can I reuse a pre-cached one?
> >>>
> >>> There's a comment in the class itself, but I'm not sure I understand it
> >>> enough
> >>> to make a conclusion:
> >>>
> >>>     * ...Without precautions, CompletableFutures would be prone to
> >>>     * garbage accumulation as chains of Completions build up, each
> >>>     * pointing back to its sources. So we null out fields as soon as
> >>>     * possible.  The screening checks needed anyway harmlessly ignore
> >>>     * null arguments that may have been obtained during races with
> >>>     * threads nulling out fields.  We also try to unlink non-isLive
> >>>     * (fired or cancelled) Completions from stacks that might
> >>>     * otherwise never be popped: Method cleanStack always unlinks non
> >>>     * isLive completions from the head of stack; others may
> >>>     * occasionally remain if racing with other cancellations or
> >>>     * removals...
> >>>
> >>> Thanks,
> >>> -Pavel
> >>> _______________________________________________
> >>> Concurrency-interest mailing list
> >>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> >>
> >>
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/c9e0f876/attachment.html>

From viktor.klang at gmail.com  Thu Jul 28 15:04:01 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 28 Jul 2016 21:04:01 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
 <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
 <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>
Message-ID: <CANPzfU9-mEV6+XsjPfSmyrYjRLo5=4RDWGNXvs=Hxo7KuFUYBQ@mail.gmail.com>

For the CompletableFuture itself: I recommended sharing it as a
CompletionStage instead, since that is not mutable.
For the value of the CompletionStage/CompletableFuture, same rules apply to
most concurrent datastructures: instances made available through it needs
to either be immutable, thread-safe or the usage predictably harmless. :)

On Thu, Jul 28, 2016 at 8:26 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> What is? Reusability?
>
> I don’t know about CompletableFuture specifically, but mutability has an
> immense impact on the implementation, since reuse requires knowing that the
> mutator repurposing the structure is the last entity looking at it in the
> old guise. Then there are gotchas that whoever keeps a reference to it,
> must also have a way of knowing which version of the thing it is looking at
> - like, suddenly you are not allowed to pass around CompletableFuture
> uncontrollably, need to devise ways to solve ABA problem - which becomes a
> problem due to mutability.
>
> Alex
>
> On 28 Jul 2016, at 16:17, Viktor Klang <viktor.klang at gmail.com> wrote:
>
> Isn't this a general requirement for concurrency (coordination) structures?
>
> --
> Cheers,
> √
>
> On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:
>
>> An isolated fact of reuse is also not very meaningful. You need
>> cross-board support for reuse for the bulk of memory/stateful/stateless
>> objects referenced by CompletableFuture.
>>
>> Alex
>>
>> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>> >
>> > Hi Martin,
>> >
>> > Quite a strong statement. I don't think an isolated fact of mutability
>> > of an entity precludes us from reusing this entity (pool of objects?
>> > reusable buffers?).
>> >
>> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
>> > value), right? In my example the CF was returned by an API to a user
>> > and this CF was completed prior to be returned.
>> >
>> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com>
>> wrote:
>> >> Don't reuse CompletableFutures.
>> >> Most obviously because they're mutable.
>> >>
>> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>> >>
>> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
>> wrote:
>> >>>
>> >>> Hi,
>> >>>
>> >>> Is it generally safe to reuse an instance of CompletableFuture? Or am
>> I
>> >>> risking
>> >>> with memory leaks due to dependants build up?
>> >>>
>> >>> Say, I have a method that returns a CF. In some cases it may return a
>> CF
>> >>> straight away indicating that the action has been already done.
>> Should I
>> >>> always
>> >>> create a new completed CF, or can I reuse a pre-cached one?
>> >>>
>> >>> There's a comment in the class itself, but I'm not sure I understand
>> it
>> >>> enough
>> >>> to make a conclusion:
>> >>>
>> >>>     * ...Without precautions, CompletableFutures would be prone to
>> >>>     * garbage accumulation as chains of Completions build up, each
>> >>>     * pointing back to its sources. So we null out fields as soon as
>> >>>     * possible.  The screening checks needed anyway harmlessly ignore
>> >>>     * null arguments that may have been obtained during races with
>> >>>     * threads nulling out fields.  We also try to unlink non-isLive
>> >>>     * (fired or cancelled) Completions from stacks that might
>> >>>     * otherwise never be popped: Method cleanStack always unlinks non
>> >>>     * isLive completions from the head of stack; others may
>> >>>     * occasionally remain if racing with other cancellations or
>> >>>     * removals...
>> >>>
>> >>> Thanks,
>> >>> -Pavel
>> >>> _______________________________________________
>> >>> Concurrency-interest mailing list
>> >>> Concurrency-interest at cs.oswego.edu
>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >>
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>


-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/cd9c5284/attachment-0001.html>

From jh at squareup.com  Thu Jul 28 15:35:05 2016
From: jh at squareup.com (Josh Humphries)
Date: Thu, 28 Jul 2016 15:35:05 -0400
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CANPzfU9-mEV6+XsjPfSmyrYjRLo5=4RDWGNXvs=Hxo7KuFUYBQ@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
 <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
 <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>
 <CANPzfU9-mEV6+XsjPfSmyrYjRLo5=4RDWGNXvs=Hxo7KuFUYBQ@mail.gmail.com>
Message-ID: <CAHJZN-tF8MpicUySyEMAdMR-QsGuaVDXwvXXyEBsgvUxojuGLg@mail.gmail.com>

Unfortunately -- unless you create a defensive copy or use a custom
subclass of CompletableFuture -- it is mutable, even as CompletionStage:

stage.toCompletableFuture().obtrudeValue(null);



----
*Josh Humphries*
Payments Engineering
Atlanta, GA  |  678-400-4867
*Square* (www.squareup.com)

On Thu, Jul 28, 2016 at 3:04 PM, Viktor Klang <viktor.klang at gmail.com>
wrote:

> For the CompletableFuture itself: I recommended sharing it as a
> CompletionStage instead, since that is not mutable.
> For the value of the CompletionStage/CompletableFuture, same rules apply
> to most concurrent datastructures: instances made available through it
> needs to either be immutable, thread-safe or the usage predictably
> harmless. :)
>
> On Thu, Jul 28, 2016 at 8:26 PM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> What is? Reusability?
>>
>> I don’t know about CompletableFuture specifically, but mutability has an
>> immense impact on the implementation, since reuse requires knowing that the
>> mutator repurposing the structure is the last entity looking at it in the
>> old guise. Then there are gotchas that whoever keeps a reference to it,
>> must also have a way of knowing which version of the thing it is looking at
>> - like, suddenly you are not allowed to pass around CompletableFuture
>> uncontrollably, need to devise ways to solve ABA problem - which becomes a
>> problem due to mutability.
>>
>> Alex
>>
>> On 28 Jul 2016, at 16:17, Viktor Klang <viktor.klang at gmail.com> wrote:
>>
>> Isn't this a general requirement for concurrency (coordination)
>> structures?
>>
>> --
>> Cheers,
>> √
>>
>> On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:
>>
>>> An isolated fact of reuse is also not very meaningful. You need
>>> cross-board support for reuse for the bulk of memory/stateful/stateless
>>> objects referenced by CompletableFuture.
>>>
>>> Alex
>>>
>>> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>> >
>>> > Hi Martin,
>>> >
>>> > Quite a strong statement. I don't think an isolated fact of mutability
>>> > of an entity precludes us from reusing this entity (pool of objects?
>>> > reusable buffers?).
>>> >
>>> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
>>> > value), right? In my example the CF was returned by an API to a user
>>> > and this CF was completed prior to be returned.
>>> >
>>> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com>
>>> wrote:
>>> >> Don't reuse CompletableFutures.
>>> >> Most obviously because they're mutable.
>>> >>
>>> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>>> >>
>>> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
>>> wrote:
>>> >>>
>>> >>> Hi,
>>> >>>
>>> >>> Is it generally safe to reuse an instance of CompletableFuture? Or
>>> am I
>>> >>> risking
>>> >>> with memory leaks due to dependants build up?
>>> >>>
>>> >>> Say, I have a method that returns a CF. In some cases it may return
>>> a CF
>>> >>> straight away indicating that the action has been already done.
>>> Should I
>>> >>> always
>>> >>> create a new completed CF, or can I reuse a pre-cached one?
>>> >>>
>>> >>> There's a comment in the class itself, but I'm not sure I understand
>>> it
>>> >>> enough
>>> >>> to make a conclusion:
>>> >>>
>>> >>>     * ...Without precautions, CompletableFutures would be prone to
>>> >>>     * garbage accumulation as chains of Completions build up, each
>>> >>>     * pointing back to its sources. So we null out fields as soon as
>>> >>>     * possible.  The screening checks needed anyway harmlessly ignore
>>> >>>     * null arguments that may have been obtained during races with
>>> >>>     * threads nulling out fields.  We also try to unlink non-isLive
>>> >>>     * (fired or cancelled) Completions from stacks that might
>>> >>>     * otherwise never be popped: Method cleanStack always unlinks non
>>> >>>     * isLive completions from the head of stack; others may
>>> >>>     * occasionally remain if racing with other cancellations or
>>> >>>     * removals...
>>> >>>
>>> >>> Thanks,
>>> >>> -Pavel
>>> >>> _______________________________________________
>>> >>> Concurrency-interest mailing list
>>> >>> Concurrency-interest at cs.oswego.edu
>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> >>
>>> > _______________________________________________
>>> > Concurrency-interest mailing list
>>> > Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>
>
> --
> Cheers,
> √
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/af30f5d2/attachment.html>

From viktor.klang at gmail.com  Thu Jul 28 15:39:01 2016
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 28 Jul 2016 21:39:01 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CAHJZN-tF8MpicUySyEMAdMR-QsGuaVDXwvXXyEBsgvUxojuGLg@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
 <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
 <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>
 <CANPzfU9-mEV6+XsjPfSmyrYjRLo5=4RDWGNXvs=Hxo7KuFUYBQ@mail.gmail.com>
 <CAHJZN-tF8MpicUySyEMAdMR-QsGuaVDXwvXXyEBsgvUxojuGLg@mail.gmail.com>
Message-ID: <CANPzfU8szCE0KP5taMKj+=_tGkqbpy8qNV8RbNGxzEQhKHhtqw@mail.gmail.com>

On Thu, Jul 28, 2016 at 9:35 PM, Josh Humphries <jh at squareup.com> wrote:

> Unfortunately -- unless you create a defensive copy or use a custom
> subclass of CompletableFuture -- it is mutable, even as CompletionStage:
>
> stage.toCompletableFuture().obtrudeValue(null);
>

Ouch! Having that method always return a new instance would've been safer,
for sure.
(I always use custom CompletionStages)


>
>
>
> ----
> *Josh Humphries*
> Payments Engineering
> Atlanta, GA  |  678-400-4867
> *Square* (www.squareup.com)
>
> On Thu, Jul 28, 2016 at 3:04 PM, Viktor Klang <viktor.klang at gmail.com>
> wrote:
>
>> For the CompletableFuture itself: I recommended sharing it as a
>> CompletionStage instead, since that is not mutable.
>> For the value of the CompletionStage/CompletableFuture, same rules apply
>> to most concurrent datastructures: instances made available through it
>> needs to either be immutable, thread-safe or the usage predictably
>> harmless. :)
>>
>> On Thu, Jul 28, 2016 at 8:26 PM, Alex Otenko <oleksandr.otenko at gmail.com>
>> wrote:
>>
>>> What is? Reusability?
>>>
>>> I don’t know about CompletableFuture specifically, but mutability has an
>>> immense impact on the implementation, since reuse requires knowing that the
>>> mutator repurposing the structure is the last entity looking at it in the
>>> old guise. Then there are gotchas that whoever keeps a reference to it,
>>> must also have a way of knowing which version of the thing it is looking at
>>> - like, suddenly you are not allowed to pass around CompletableFuture
>>> uncontrollably, need to devise ways to solve ABA problem - which becomes a
>>> problem due to mutability.
>>>
>>> Alex
>>>
>>> On 28 Jul 2016, at 16:17, Viktor Klang <viktor.klang at gmail.com> wrote:
>>>
>>> Isn't this a general requirement for concurrency (coordination)
>>> structures?
>>>
>>> --
>>> Cheers,
>>> √
>>>
>>> On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:
>>>
>>>> An isolated fact of reuse is also not very meaningful. You need
>>>> cross-board support for reuse for the bulk of memory/stateful/stateless
>>>> objects referenced by CompletableFuture.
>>>>
>>>> Alex
>>>>
>>>> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>>> >
>>>> > Hi Martin,
>>>> >
>>>> > Quite a strong statement. I don't think an isolated fact of mutability
>>>> > of an entity precludes us from reusing this entity (pool of objects?
>>>> > reusable buffers?).
>>>> >
>>>> > You're talking about obtrudeException(Throwable ex) and obtrudeValue(T
>>>> > value), right? In my example the CF was returned by an API to a user
>>>> > and this CF was completed prior to be returned.
>>>> >
>>>> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <martinrb at google.com>
>>>> wrote:
>>>> >> Don't reuse CompletableFutures.
>>>> >> Most obviously because they're mutable.
>>>> >>
>>>> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>>>> >>
>>>> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
>>>> wrote:
>>>> >>>
>>>> >>> Hi,
>>>> >>>
>>>> >>> Is it generally safe to reuse an instance of CompletableFuture? Or
>>>> am I
>>>> >>> risking
>>>> >>> with memory leaks due to dependants build up?
>>>> >>>
>>>> >>> Say, I have a method that returns a CF. In some cases it may return
>>>> a CF
>>>> >>> straight away indicating that the action has been already done.
>>>> Should I
>>>> >>> always
>>>> >>> create a new completed CF, or can I reuse a pre-cached one?
>>>> >>>
>>>> >>> There's a comment in the class itself, but I'm not sure I
>>>> understand it
>>>> >>> enough
>>>> >>> to make a conclusion:
>>>> >>>
>>>> >>>     * ...Without precautions, CompletableFutures would be prone to
>>>> >>>     * garbage accumulation as chains of Completions build up, each
>>>> >>>     * pointing back to its sources. So we null out fields as soon as
>>>> >>>     * possible.  The screening checks needed anyway harmlessly
>>>> ignore
>>>> >>>     * null arguments that may have been obtained during races with
>>>> >>>     * threads nulling out fields.  We also try to unlink non-isLive
>>>> >>>     * (fired or cancelled) Completions from stacks that might
>>>> >>>     * otherwise never be popped: Method cleanStack always unlinks
>>>> non
>>>> >>>     * isLive completions from the head of stack; others may
>>>> >>>     * occasionally remain if racing with other cancellations or
>>>> >>>     * removals...
>>>> >>>
>>>> >>> Thanks,
>>>> >>> -Pavel
>>>> >>> _______________________________________________
>>>> >>> Concurrency-interest mailing list
>>>> >>> Concurrency-interest at cs.oswego.edu
>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> >>
>>>> > _______________________________________________
>>>> > Concurrency-interest mailing list
>>>> > Concurrency-interest at cs.oswego.edu
>>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>
>>
>> --
>> Cheers,
>> √
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>


-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/7dbab98d/attachment-0001.html>

From kasperni at gmail.com  Thu Jul 28 16:00:48 2016
From: kasperni at gmail.com (Kasper Nielsen)
Date: Thu, 28 Jul 2016 22:00:48 +0200
Subject: [concurrency-interest] Reusing CompletableFuture
In-Reply-To: <CANPzfU8szCE0KP5taMKj+=_tGkqbpy8qNV8RbNGxzEQhKHhtqw@mail.gmail.com>
References: <CAChcVun3JJJfjdTaNe=iHD+nEhxeoCOsTuD8s4656riL5mH6Xg@mail.gmail.com>
 <CA+kOe0-jM_kReyMJXDezRTXEPXPj1-Ze=+r7RJzTBg1XjBy2kw@mail.gmail.com>
 <CAChcVumuWBT53pXMnZZVoZrw-uCo92QD=J4g5gNgQKnJKaoP=Q@mail.gmail.com>
 <0E074D61-38D1-41C4-BFF5-BE9DF176CE1A@gmail.com>
 <CANPzfU9Jgr=HnsaBgaOXC1cGfqSb_sCZ5wWR_LG3p=+WODgvhQ@mail.gmail.com>
 <77D51EDC-C8D7-45DC-9611-346192A9F117@gmail.com>
 <CANPzfU9-mEV6+XsjPfSmyrYjRLo5=4RDWGNXvs=Hxo7KuFUYBQ@mail.gmail.com>
 <CAHJZN-tF8MpicUySyEMAdMR-QsGuaVDXwvXXyEBsgvUxojuGLg@mail.gmail.com>
 <CANPzfU8szCE0KP5taMKj+=_tGkqbpy8qNV8RbNGxzEQhKHhtqw@mail.gmail.com>
Message-ID: <CAPs61511ka-NyDCFTrNijVhKwFGYsOwMWQj1R222OAiyM4npgA@mail.gmail.com>

copy() and minimalCompletionStage() have been added for JDK 9.

http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/CompletableFuture.html#copy

http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/CompletableFuture.html#minimalCompletionStage

- Kasper


On 28 July 2016 at 21:39, Viktor Klang <viktor.klang at gmail.com> wrote:

>
>
> On Thu, Jul 28, 2016 at 9:35 PM, Josh Humphries <jh at squareup.com> wrote:
>
>> Unfortunately -- unless you create a defensive copy or use a custom
>> subclass of CompletableFuture -- it is mutable, even as CompletionStage:
>>
>> stage.toCompletableFuture().obtrudeValue(null);
>>
>
> Ouch! Having that method always return a new instance would've been safer,
> for sure.
> (I always use custom CompletionStages)
>
>
>>
>>
>>
>> ----
>> *Josh Humphries*
>> Payments Engineering
>> Atlanta, GA  |  678-400-4867
>> *Square* (www.squareup.com)
>>
>> On Thu, Jul 28, 2016 at 3:04 PM, Viktor Klang <viktor.klang at gmail.com>
>> wrote:
>>
>>> For the CompletableFuture itself: I recommended sharing it as a
>>> CompletionStage instead, since that is not mutable.
>>> For the value of the CompletionStage/CompletableFuture, same rules apply
>>> to most concurrent datastructures: instances made available through it
>>> needs to either be immutable, thread-safe or the usage predictably
>>> harmless. :)
>>>
>>> On Thu, Jul 28, 2016 at 8:26 PM, Alex Otenko <oleksandr.otenko at gmail.com
>>> > wrote:
>>>
>>>> What is? Reusability?
>>>>
>>>> I don’t know about CompletableFuture specifically, but mutability has
>>>> an immense impact on the implementation, since reuse requires knowing that
>>>> the mutator repurposing the structure is the last entity looking at it in
>>>> the old guise. Then there are gotchas that whoever keeps a reference to it,
>>>> must also have a way of knowing which version of the thing it is looking at
>>>> - like, suddenly you are not allowed to pass around CompletableFuture
>>>> uncontrollably, need to devise ways to solve ABA problem - which becomes a
>>>> problem due to mutability.
>>>>
>>>> Alex
>>>>
>>>> On 28 Jul 2016, at 16:17, Viktor Klang <viktor.klang at gmail.com> wrote:
>>>>
>>>> Isn't this a general requirement for concurrency (coordination)
>>>> structures?
>>>>
>>>> --
>>>> Cheers,
>>>> √
>>>>
>>>> On Jul 28, 2016 11:57, "Alex Otenko" <oleksandr.otenko at gmail.com>
>>>> wrote:
>>>>
>>>>> An isolated fact of reuse is also not very meaningful. You need
>>>>> cross-board support for reuse for the bulk of memory/stateful/stateless
>>>>> objects referenced by CompletableFuture.
>>>>>
>>>>> Alex
>>>>>
>>>>> > On 24 Jul 2016, at 19:11, Pavel Rappo <pavel.rappo at gmail.com> wrote:
>>>>> >
>>>>> > Hi Martin,
>>>>> >
>>>>> > Quite a strong statement. I don't think an isolated fact of
>>>>> mutability
>>>>> > of an entity precludes us from reusing this entity (pool of objects?
>>>>> > reusable buffers?).
>>>>> >
>>>>> > You're talking about obtrudeException(Throwable ex) and
>>>>> obtrudeValue(T
>>>>> > value), right? In my example the CF was returned by an API to a user
>>>>> > and this CF was completed prior to be returned.
>>>>> >
>>>>> > On Sun, Jul 24, 2016 at 5:19 PM, Martin Buchholz <
>>>>> martinrb at google.com> wrote:
>>>>> >> Don't reuse CompletableFutures.
>>>>> >> Most obviously because they're mutable.
>>>>> >>
>>>>> >> See also https://bugs.openjdk.java.net/browse/JDK-8161600
>>>>> >>
>>>>> >> On Sun, Jul 24, 2016 at 5:57 AM, Pavel Rappo <pavel.rappo at gmail.com>
>>>>> wrote:
>>>>> >>>
>>>>> >>> Hi,
>>>>> >>>
>>>>> >>> Is it generally safe to reuse an instance of CompletableFuture? Or
>>>>> am I
>>>>> >>> risking
>>>>> >>> with memory leaks due to dependants build up?
>>>>> >>>
>>>>> >>> Say, I have a method that returns a CF. In some cases it may
>>>>> return a CF
>>>>> >>> straight away indicating that the action has been already done.
>>>>> Should I
>>>>> >>> always
>>>>> >>> create a new completed CF, or can I reuse a pre-cached one?
>>>>> >>>
>>>>> >>> There's a comment in the class itself, but I'm not sure I
>>>>> understand it
>>>>> >>> enough
>>>>> >>> to make a conclusion:
>>>>> >>>
>>>>> >>>     * ...Without precautions, CompletableFutures would be prone to
>>>>> >>>     * garbage accumulation as chains of Completions build up, each
>>>>> >>>     * pointing back to its sources. So we null out fields as soon
>>>>> as
>>>>> >>>     * possible.  The screening checks needed anyway harmlessly
>>>>> ignore
>>>>> >>>     * null arguments that may have been obtained during races with
>>>>> >>>     * threads nulling out fields.  We also try to unlink non-isLive
>>>>> >>>     * (fired or cancelled) Completions from stacks that might
>>>>> >>>     * otherwise never be popped: Method cleanStack always unlinks
>>>>> non
>>>>> >>>     * isLive completions from the head of stack; others may
>>>>> >>>     * occasionally remain if racing with other cancellations or
>>>>> >>>     * removals...
>>>>> >>>
>>>>> >>> Thanks,
>>>>> >>> -Pavel
>>>>> >>> _______________________________________________
>>>>> >>> Concurrency-interest mailing list
>>>>> >>> Concurrency-interest at cs.oswego.edu
>>>>> >>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>> >>
>>>>> >>
>>>>> > _______________________________________________
>>>>> > Concurrency-interest mailing list
>>>>> > Concurrency-interest at cs.oswego.edu
>>>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> Cheers,
>>> √
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>
>
> --
> Cheers,
> √
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20160728/39fec0aa/attachment.html>

