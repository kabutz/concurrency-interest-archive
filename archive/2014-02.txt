From oleksiy.stashok at oracle.com  Sat Feb  1 00:10:33 2014
From: oleksiy.stashok at oracle.com (Oleksiy Stashok)
Date: Fri, 31 Jan 2014 21:10:33 -0800
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
Message-ID: <52EC81C9.2020809@oracle.com>

May be I'm missing something in your question, but IMO if you don't want 
a core thread to be created - just pass 0 as a constructor parameter.

     public static void main(String[] args)
     {
         ScheduledThreadPoolExecutor exec =
             new ScheduledThreadPoolExecutor(0);
         exec.schedule( ()-> System.out.println("done"),
             1, TimeUnit.SECONDS );
     }


WBR,
Alexey.

On 31.01.14 20:19, Zhong Yu wrote:
> In this simple example, the JVM never exits:
>
>      public static void main(String[] args)
>      {
>          ScheduledThreadPoolExecutor exec =
>              new ScheduledThreadPoolExecutor(1);
>          exec.schedule( ()-> System.out.println("done"),
>              1, TimeUnit.SECONDS );
>      }
>
> because the core thread cannot timeout.
>
> This creates a problem in a hot-reload environment, where each new app
> instance creates a new scheduler thread that never terminates. Is
> there a workaround to the effect that the thread can timeout? Thanks.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Sat Feb  1 02:06:18 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 1 Feb 2014 17:06:18 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMECBKEAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
>
> In this simple example, the JVM never exits:
>
>     public static void main(String[] args)
>     {
>         ScheduledThreadPoolExecutor exec =
>             new ScheduledThreadPoolExecutor(1);
>         exec.schedule( ()-> System.out.println("done"),
>             1, TimeUnit.SECONDS );
>     }
>
> because the core thread cannot timeout.
>
> This creates a problem in a hot-reload environment, where each new app
> instance creates a new scheduler thread that never terminates. Is
> there a workaround to the effect that the thread can timeout? Thanks.

There's no way to have the thread timeout and still have a functioning
executor when there is a task waiting to be scheduled. If you don't care
about it functioning correctly then call allowCoreThreadTimeOut(true) and
set your desired timeout.

David

> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From davidcholmes at aapt.net.au  Sat Feb  1 02:09:37 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 1 Feb 2014 17:09:37 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMECBKEAA.davidcholmes@aapt.net.au>
Message-ID: <NFBBKALFDCPFIDBNKAPCAECCKEAA.davidcholmes@aapt.net.au>

I wrote:
> Zhong Yu writes:
> >
> > In this simple example, the JVM never exits:
> >
> >     public static void main(String[] args)
> >     {
> >         ScheduledThreadPoolExecutor exec =
> >             new ScheduledThreadPoolExecutor(1);
> >         exec.schedule( ()-> System.out.println("done"),
> >             1, TimeUnit.SECONDS );
> >     }
> >
> > because the core thread cannot timeout.
> >
> > This creates a problem in a hot-reload environment, where each new app
> > instance creates a new scheduler thread that never terminates. Is
> > there a workaround to the effect that the thread can timeout? Thanks.
>
> There's no way to have the thread timeout and still have a
> functioning executor when there is a task waiting to be
> scheduled. If you don't care about it functioning correctly then
> call allowCoreThreadTimeOut(true) and set your desired timeout.

Correction the idle timeout won't kick-in if there is a task waiting to be
scheduled. Once there are no tasks then the core thread can timeout.

David

> David
>
> > Zhong Yu
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From zhong.j.yu at gmail.com  Sat Feb  1 02:17:09 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Sat, 1 Feb 2014 01:17:09 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <NFBBKALFDCPFIDBNKAPCAECCKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMECBKEAA.davidcholmes@aapt.net.au>
	<NFBBKALFDCPFIDBNKAPCAECCKEAA.davidcholmes@aapt.net.au>
Message-ID: <CACuKZqHP2_+vhNJzb_7rm8UfOOYtXtq41H9tk3eErNqebEz8BA@mail.gmail.com>

On Sat, Feb 1, 2014 at 1:09 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
> I wrote:
>> Zhong Yu writes:
>> >
>> > In this simple example, the JVM never exits:
>> >
>> >     public static void main(String[] args)
>> >     {
>> >         ScheduledThreadPoolExecutor exec =
>> >             new ScheduledThreadPoolExecutor(1);
>> >         exec.schedule( ()-> System.out.println("done"),
>> >             1, TimeUnit.SECONDS );
>> >     }
>> >
>> > because the core thread cannot timeout.
>> >
>> > This creates a problem in a hot-reload environment, where each new app
>> > instance creates a new scheduler thread that never terminates. Is
>> > there a workaround to the effect that the thread can timeout? Thanks.
>>
>> There's no way to have the thread timeout and still have a
>> functioning executor when there is a task waiting to be
>> scheduled. If you don't care about it functioning correctly then
>> call allowCoreThreadTimeOut(true) and set your desired timeout.
>
> Correction the idle timeout won't kick-in if there is a task waiting to be
> scheduled. Once there are no tasks then the core thread can timeout.

But the javadoc explicitly warns that

> it is almost never a good idea to set corePoolSize to zero or use allowCoreThreadTimeOut because this may leave the pool without threads to handle tasks once they become eligible to run.

is the current implementation more robust than that?

Zhong Yu



>
> David
>
>> David
>>
>> > Zhong Yu
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From davidcholmes at aapt.net.au  Sat Feb  1 02:34:14 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Sat, 1 Feb 2014 17:34:14 +1000
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <CACuKZqHP2_+vhNJzb_7rm8UfOOYtXtq41H9tk3eErNqebEz8BA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>

Zhong Yu writes:
> On Sat, Feb 1, 2014 at 1:09 AM, David Holmes
> <davidcholmes at aapt.net.au> wrote:
> > I wrote:
> >> Zhong Yu writes:
> >> >
> >> > In this simple example, the JVM never exits:
> >> >
> >> >     public static void main(String[] args)
> >> >     {
> >> >         ScheduledThreadPoolExecutor exec =
> >> >             new ScheduledThreadPoolExecutor(1);
> >> >         exec.schedule( ()-> System.out.println("done"),
> >> >             1, TimeUnit.SECONDS );
> >> >     }
> >> >
> >> > because the core thread cannot timeout.
> >> >
> >> > This creates a problem in a hot-reload environment, where
> each new app
> >> > instance creates a new scheduler thread that never terminates. Is
> >> > there a workaround to the effect that the thread can timeout? Thanks.
> >>
> >> There's no way to have the thread timeout and still have a
> >> functioning executor when there is a task waiting to be
> >> scheduled. If you don't care about it functioning correctly then
> >> call allowCoreThreadTimeOut(true) and set your desired timeout.
> >
> > Correction the idle timeout won't kick-in if there is a task
> waiting to be
> > scheduled. Once there are no tasks then the core thread can timeout.
>
> But the javadoc explicitly warns that
>
> > it is almost never a good idea to set corePoolSize to zero or
> use allowCoreThreadTimeOut because this may leave the pool
> without threads to handle tasks once they become eligible to run.
>
> is the current implementation more robust than that?

I think it is in the sense that if there is a task waiting to become
eligible to run then there is a worker thread that is waiting for that time
to arrive. But the details are complex and there may be circumstances where
tasks are not executed as expected.

David

> Zhong Yu
>
>
>
> >
> > David
> >
> >> David
> >>
> >> > Zhong Yu
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Sat Feb  1 15:32:34 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Sat, 01 Feb 2014 15:32:34 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52EBE1F9.9030206@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE1F9.9030206@javaspecialists.eu>
Message-ID: <52ED59E2.7010301@cs.oswego.edu>


To summarize, we have the following suggestions (some off-list)
in response to Heinz's puzzler:

1. Add documentation to TLR warning not to store TLR.current()
in a static, or use as an argument to a method that might do so,
or use as an argument in a method assuming thread-safety.

2. Add similar documentation to java.lang.ThreadLocal, and then
refer and add to it in TLR.

3. Create findBugs rules covering (1) and (2).

4. Invent new type rules for Java enforcing (1) and (2).

5. Add an initialization check on each use of TLR.next() and
throw an exception.

6. Eagerly initialize TLR seeds. (One reason this was not
done originally is that it adds measurable time to Thread
construction even when TLRs are not used in a thread, which
is the most common case.)

7. Tell people to use java.util.SplittableRandom instead.

8. Do nothing.

Considering that this is far from a critical bug, it is
unlikely to become updated in OpenJDK until JDK9, so we
seem to have plenty of time for further suggestions!

-Doug


From oleksandr.otenko at oracle.com  Mon Feb  3 07:36:37 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 03 Feb 2014 12:36:37 +0000
Subject: [concurrency-interest] TLR Puzzle - UI threading
In-Reply-To: <1391207785.7809.YahooMailNeo@web172406.mail.ir2.yahoo.com>
References: <1391207785.7809.YahooMailNeo@web172406.mail.ir2.yahoo.com>
Message-ID: <52EF8D55.2000909@oracle.com>

Deterministically visible?! I wonder what method would you, or any of 
those suggesting it is ok, propose for detecting such a bug in 
application code.


Alex



On 31/01/2014 22:36, Jeff Hain wrote:
>
> Tim Halloran wrote:
> >SWT does this [exception] when event thread calls are detected outside of
> >the SWT thread -- sadly, Swing doesn't.
>
> I'm doing a lightweight GUI framework on top of AWT, but
> something much more simple than AWT and Swing (which were
> slowing me down to a halt, not counting their glitches and hostility
> to huge data models).
> As a side effect of the simplicity, I found it was easy to parallelize
> painting, so I'm glad Graphics2D class lets me paint stuffs from
> different threads (I do check EDT at some places, but through an
> interface, so that it can also work from JUnit thread).
>
>
> As for the TLR puzzle, I agree with those that don't feel the need
> to touch anything except maybe add more warning in the spec.
> I even think that Java 8 behavior is preferable to Java 7 one,
> since it makes the coding error deterministically visible
> instead of hiding it behind some randomness.
>
>
> -Jeff
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/a571d1c2/attachment.html>

From heinz at javaspecialists.eu  Mon Feb  3 09:06:59 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 03 Feb 2014 16:06:59 +0200
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
Message-ID: <52EFA283.7040800@javaspecialists.eu>

How about doing this for a once-off scheduled task?

import java.util.concurrent.*;

public class ForeverYoung {
  public static void main(String[] args) {
    ScheduledThreadPoolExecutor exec =
        new ScheduledThreadPoolExecutor(1);
    exec.schedule(() -> {
      System.out.println("done");
      exec.shutdown();
    },
        1, TimeUnit.SECONDS
    );
  }
}

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Oracle Java Champion 2005-2013
JavaOne Rock Star Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz



Zhong Yu wrote:
> In this simple example, the JVM never exits:
>
>     public static void main(String[] args)
>     {
>         ScheduledThreadPoolExecutor exec =
>             new ScheduledThreadPoolExecutor(1);
>         exec.schedule( ()-> System.out.println("done"),
>             1, TimeUnit.SECONDS );
>     }
>
> because the core thread cannot timeout.
>
> This creates a problem in a hot-reload environment, where each new app
> instance creates a new scheduler thread that never terminates. Is
> there a workaround to the effect that the thread can timeout? Thanks.
>
> Zhong Yu
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> .
>
>   

From zhong.j.yu at gmail.com  Mon Feb  3 13:02:35 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Mon, 3 Feb 2014 12:02:35 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <52EFA283.7040800@javaspecialists.eu>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
Message-ID: <CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>

Assume the task does not know it's the last one...

On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
> How about doing this for a once-off scheduled task?
>
> import java.util.concurrent.*;
>
> public class ForeverYoung {
>
>  public static void main(String[] args) {
>    ScheduledThreadPoolExecutor exec =
>        new ScheduledThreadPoolExecutor(1);
>    exec.schedule(() -> {
>      System.out.println("done");
>      exec.shutdown();
>    },
>        1, TimeUnit.SECONDS
>    );
>  }
> }
>
> Regards
>
> Heinz
> --
> Dr Heinz M. Kabutz (PhD CompSci)
> Author of "The Java(tm) Specialists' Newsletter"
> Oracle Java Champion 2005-2013
> JavaOne Rock Star Speaker 2012
> http://www.javaspecialists.eu
> Tel: +30 69 75 595 262
> Skype: kabutz
>
>
>
> Zhong Yu wrote:
>>
>> In this simple example, the JVM never exits:
>>
>>     public static void main(String[] args)
>>     {
>>         ScheduledThreadPoolExecutor exec =
>>             new ScheduledThreadPoolExecutor(1);
>>         exec.schedule( ()-> System.out.println("done"),
>>             1, TimeUnit.SECONDS );
>>     }
>>
>> because the core thread cannot timeout.
>>
>> This creates a problem in a hot-reload environment, where each new app
>> instance creates a new scheduler thread that never terminates. Is
>> there a workaround to the effect that the thread can timeout? Thanks.
>>
>> Zhong Yu
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> .
>>
>>

From jeffhain at rocketmail.com  Mon Feb  3 13:05:14 2014
From: jeffhain at rocketmail.com (Jeff Hain)
Date: Mon, 3 Feb 2014 18:05:14 +0000 (GMT)
Subject: [concurrency-interest] TLR Puzzle - UI threading
In-Reply-To: <52EF8D55.2000909@oracle.com>
References: <1391207785.7809.YahooMailNeo@web172406.mail.ir2.yahoo.com>
	<52EF8D55.2000909@oracle.com>
Message-ID: <1391450714.32322.YahooMailNeo@web172405.mail.ir2.yahoo.com>



Alex wrote:

>Deterministically visible?! I wonder what method would you, or any of
>those suggesting it is ok, propose for detecting such a bug in
    application code.

Sorry for being vague.
I just meant the possible determinism Vitaly talked about:

>So, in Java 8, you will currently get this output, regardless of which machine you run it on and when:
>
>Thread 1
>0.3999564263366546
>(...)
>
>Thread 2
>0.3999564263366546
>(...)

-Jeff
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/34fa6472/attachment.html>

From heinz at javaspecialists.eu  Mon Feb  3 13:22:50 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 03 Feb 2014 20:22:50 +0200
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>
Message-ID: <52EFDE7A.2020704@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/47fbb939/attachment.html>

From robert.j.saulnier at gmail.com  Mon Feb  3 13:25:14 2014
From: robert.j.saulnier at gmail.com (Robert J. Saulnier)
Date: Mon, 3 Feb 2014 14:25:14 -0400
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
	<CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
Message-ID: <CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>

ScheduledExecutorService executor =
Executors.newSingleThreadScheduledExecutor();

executor.schedule(() -> { System.out.println("hey"); }, 1L,
TimeUnit.SECONDS);

executor.shutdown();



On Mon, Feb 3, 2014 at 2:02 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> Assume the task does not know it's the last one...
>
> On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
> > How about doing this for a once-off scheduled task?
> >
> > import java.util.concurrent.*;
> >
> > public class ForeverYoung {
> >
> >  public static void main(String[] args) {
> >    ScheduledThreadPoolExecutor exec =
> >        new ScheduledThreadPoolExecutor(1);
> >    exec.schedule(() -> {
> >      System.out.println("done");
> >      exec.shutdown();
> >    },
> >        1, TimeUnit.SECONDS
> >    );
> >  }
> > }
> >
> > Regards
> >
> > Heinz
> > --
> > Dr Heinz M. Kabutz (PhD CompSci)
> > Author of "The Java(tm) Specialists' Newsletter"
> > Oracle Java Champion 2005-2013
> > JavaOne Rock Star Speaker 2012
> > http://www.javaspecialists.eu
> > Tel: +30 69 75 595 262
> > Skype: kabutz
> >
> >
> >
> > Zhong Yu wrote:
> >>
> >> In this simple example, the JVM never exits:
> >>
> >>     public static void main(String[] args)
> >>     {
> >>         ScheduledThreadPoolExecutor exec =
> >>             new ScheduledThreadPoolExecutor(1);
> >>         exec.schedule( ()-> System.out.println("done"),
> >>             1, TimeUnit.SECONDS );
> >>     }
> >>
> >> because the core thread cannot timeout.
> >>
> >> This creates a problem in a hot-reload environment, where each new app
> >> instance creates a new scheduler thread that never terminates. Is
> >> there a workaround to the effect that the thread can timeout? Thanks.
> >>
> >> Zhong Yu
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> .
> >>
> >>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/c6848a3c/attachment.html>

From viktor.klang at gmail.com  Mon Feb  3 13:34:50 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 3 Feb 2014 19:34:50 +0100
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
	<CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
	<CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>
Message-ID: <CANPzfU9+QUFN7uLhKETV7ssWHwSoB2=kV+KzpxSC9AEqmMyotA@mail.gmail.com>

On Mon, Feb 3, 2014 at 7:25 PM, Robert J. Saulnier <
robert.j.saulnier at gmail.com> wrote:

> ScheduledExecutorService executor =
> Executors.newSingleThreadScheduledExecutor();
>
> executor.schedule(() -> { System.out.println("hey"); }, 1L,
> TimeUnit.SECONDS);
>
> executor.shutdown();
>

Sadly in JDK8 ScheduledFuture is not a CompletableFuture, otherwise you'd
just attach the shutdown to be executed when the Future completes.


>
>
>
> On Mon, Feb 3, 2014 at 2:02 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>
>> Assume the task does not know it's the last one...
>>
>> On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu> wrote:
>> > How about doing this for a once-off scheduled task?
>> >
>> > import java.util.concurrent.*;
>> >
>> > public class ForeverYoung {
>> >
>> >  public static void main(String[] args) {
>> >    ScheduledThreadPoolExecutor exec =
>> >        new ScheduledThreadPoolExecutor(1);
>> >    exec.schedule(() -> {
>> >      System.out.println("done");
>> >      exec.shutdown();
>> >    },
>> >        1, TimeUnit.SECONDS
>> >    );
>> >  }
>> > }
>> >
>> > Regards
>> >
>> > Heinz
>> > --
>> > Dr Heinz M. Kabutz (PhD CompSci)
>> > Author of "The Java(tm) Specialists' Newsletter"
>> > Oracle Java Champion 2005-2013
>> > JavaOne Rock Star Speaker 2012
>> > http://www.javaspecialists.eu
>> > Tel: +30 69 75 595 262
>> > Skype: kabutz
>> >
>> >
>> >
>> > Zhong Yu wrote:
>> >>
>> >> In this simple example, the JVM never exits:
>> >>
>> >>     public static void main(String[] args)
>> >>     {
>> >>         ScheduledThreadPoolExecutor exec =
>> >>             new ScheduledThreadPoolExecutor(1);
>> >>         exec.schedule( ()-> System.out.println("done"),
>> >>             1, TimeUnit.SECONDS );
>> >>     }
>> >>
>> >> because the core thread cannot timeout.
>> >>
>> >> This creates a problem in a hot-reload environment, where each new app
>> >> instance creates a new scheduler thread that never terminates. Is
>> >> there a workaround to the effect that the thread can timeout? Thanks.
>> >>
>> >> Zhong Yu
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> .
>> >>
>> >>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/73ed68d1/attachment-0001.html>

From robert.j.saulnier at gmail.com  Mon Feb  3 13:49:09 2014
From: robert.j.saulnier at gmail.com (Robert J. Saulnier)
Date: Mon, 3 Feb 2014 14:49:09 -0400
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CANPzfU9+QUFN7uLhKETV7ssWHwSoB2=kV+KzpxSC9AEqmMyotA@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
	<CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
	<CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>
	<CANPzfU9+QUFN7uLhKETV7ssWHwSoB2=kV+KzpxSC9AEqmMyotA@mail.gmail.com>
Message-ID: <CAJ8S3uztJfB9jjNLy0QQ25GzOkesHVYK4aM3SHqsYiUYYxET6w@mail.gmail.com>

You don't need to wait for the Future to complete, you can shutdown the
executor right after scheduling the task(s) and these scheduled tasks will
still be executed.

So I believe my example meets the OP's requirements.


On Mon, Feb 3, 2014 at 2:34 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:

>
>
>
> On Mon, Feb 3, 2014 at 7:25 PM, Robert J. Saulnier <
> robert.j.saulnier at gmail.com> wrote:
>
>> ScheduledExecutorService executor =
>> Executors.newSingleThreadScheduledExecutor();
>>
>> executor.schedule(() -> { System.out.println("hey"); }, 1L,
>> TimeUnit.SECONDS);
>>
>> executor.shutdown();
>>
>
> Sadly in JDK8 ScheduledFuture is not a CompletableFuture, otherwise you'd
> just attach the shutdown to be executed when the Future completes.
>
>
>>
>>
>>
>> On Mon, Feb 3, 2014 at 2:02 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>
>>> Assume the task does not know it's the last one...
>>>
>>> On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
>>> <heinz at javaspecialists.eu> wrote:
>>> > How about doing this for a once-off scheduled task?
>>> >
>>> > import java.util.concurrent.*;
>>> >
>>> > public class ForeverYoung {
>>> >
>>> >  public static void main(String[] args) {
>>> >    ScheduledThreadPoolExecutor exec =
>>> >        new ScheduledThreadPoolExecutor(1);
>>> >    exec.schedule(() -> {
>>> >      System.out.println("done");
>>> >      exec.shutdown();
>>> >    },
>>> >        1, TimeUnit.SECONDS
>>> >    );
>>> >  }
>>> > }
>>> >
>>> > Regards
>>> >
>>> > Heinz
>>> > --
>>> > Dr Heinz M. Kabutz (PhD CompSci)
>>> > Author of "The Java(tm) Specialists' Newsletter"
>>> > Oracle Java Champion 2005-2013
>>> > JavaOne Rock Star Speaker 2012
>>> > http://www.javaspecialists.eu
>>> > Tel: +30 69 75 595 262
>>> > Skype: kabutz
>>> >
>>> >
>>> >
>>> > Zhong Yu wrote:
>>> >>
>>> >> In this simple example, the JVM never exits:
>>> >>
>>> >>     public static void main(String[] args)
>>> >>     {
>>> >>         ScheduledThreadPoolExecutor exec =
>>> >>             new ScheduledThreadPoolExecutor(1);
>>> >>         exec.schedule( ()-> System.out.println("done"),
>>> >>             1, TimeUnit.SECONDS );
>>> >>     }
>>> >>
>>> >> because the core thread cannot timeout.
>>> >>
>>> >> This creates a problem in a hot-reload environment, where each new app
>>> >> instance creates a new scheduler thread that never terminates. Is
>>> >> there a workaround to the effect that the thread can timeout? Thanks.
>>> >>
>>> >> Zhong Yu
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >> .
>>> >>
>>> >>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> --
> Cheers,
> ?
>
> * ??????? **Viktor Klang*
> *Chief Architect - **Typesafe <http://www.typesafe.com/>*
>
>  Twitter: @viktorklang
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/9ee117ac/attachment.html>

From viktor.klang at gmail.com  Mon Feb  3 13:52:27 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Mon, 3 Feb 2014 19:52:27 +0100
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CAJ8S3uztJfB9jjNLy0QQ25GzOkesHVYK4aM3SHqsYiUYYxET6w@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
	<CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
	<CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>
	<CANPzfU9+QUFN7uLhKETV7ssWHwSoB2=kV+KzpxSC9AEqmMyotA@mail.gmail.com>
	<CAJ8S3uztJfB9jjNLy0QQ25GzOkesHVYK4aM3SHqsYiUYYxET6w@mail.gmail.com>
Message-ID: <CANPzfU8gfwmS-bQD2tCJ_BKAd7eA9CVsz9T6Z2HfTwLdpyBLLg@mail.gmail.com>

On Mon, Feb 3, 2014 at 7:49 PM, Robert J. Saulnier <
robert.j.saulnier at gmail.com> wrote:

> You don't need to wait for the Future to complete, you can shutdown the
> executor right after scheduling the task(s) and these scheduled tasks will
> still be executed.
>
> So I believe my example meets the OP's requirements.
>

Absolutely, it's just "uglier" than it could be (relying on implicit
ordering rather than explicit):

submit(...).onComplete(() -> executor.shutdown())

Sadly, as mentioned, ScheduledFuture is not a CompletionStage nor a
CompletableFuture.


>
>
> On Mon, Feb 3, 2014 at 2:34 PM, ?iktor ?lang <viktor.klang at gmail.com>wrote:
>
>>
>>
>>
>> On Mon, Feb 3, 2014 at 7:25 PM, Robert J. Saulnier <
>> robert.j.saulnier at gmail.com> wrote:
>>
>>> ScheduledExecutorService executor =
>>> Executors.newSingleThreadScheduledExecutor();
>>>
>>> executor.schedule(() -> { System.out.println("hey"); }, 1L,
>>> TimeUnit.SECONDS);
>>>
>>> executor.shutdown();
>>>
>>
>> Sadly in JDK8 ScheduledFuture is not a CompletableFuture, otherwise you'd
>> just attach the shutdown to be executed when the Future completes.
>>
>>
>>>
>>>
>>>
>>> On Mon, Feb 3, 2014 at 2:02 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>
>>>> Assume the task does not know it's the last one...
>>>>
>>>> On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
>>>> <heinz at javaspecialists.eu> wrote:
>>>> > How about doing this for a once-off scheduled task?
>>>> >
>>>> > import java.util.concurrent.*;
>>>> >
>>>> > public class ForeverYoung {
>>>> >
>>>> >  public static void main(String[] args) {
>>>> >    ScheduledThreadPoolExecutor exec =
>>>> >        new ScheduledThreadPoolExecutor(1);
>>>> >    exec.schedule(() -> {
>>>> >      System.out.println("done");
>>>> >      exec.shutdown();
>>>> >    },
>>>> >        1, TimeUnit.SECONDS
>>>> >    );
>>>> >  }
>>>> > }
>>>> >
>>>> > Regards
>>>> >
>>>> > Heinz
>>>> > --
>>>> > Dr Heinz M. Kabutz (PhD CompSci)
>>>> > Author of "The Java(tm) Specialists' Newsletter"
>>>> > Oracle Java Champion 2005-2013
>>>> > JavaOne Rock Star Speaker 2012
>>>> > http://www.javaspecialists.eu
>>>> > Tel: +30 69 75 595 262
>>>> > Skype: kabutz
>>>> >
>>>> >
>>>> >
>>>> > Zhong Yu wrote:
>>>> >>
>>>> >> In this simple example, the JVM never exits:
>>>> >>
>>>> >>     public static void main(String[] args)
>>>> >>     {
>>>> >>         ScheduledThreadPoolExecutor exec =
>>>> >>             new ScheduledThreadPoolExecutor(1);
>>>> >>         exec.schedule( ()-> System.out.println("done"),
>>>> >>             1, TimeUnit.SECONDS );
>>>> >>     }
>>>> >>
>>>> >> because the core thread cannot timeout.
>>>> >>
>>>> >> This creates a problem in a hot-reload environment, where each new
>>>> app
>>>> >> instance creates a new scheduler thread that never terminates. Is
>>>> >> there a workaround to the effect that the thread can timeout? Thanks.
>>>> >>
>>>> >> Zhong Yu
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >> .
>>>> >>
>>>> >>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>> * ??????? **Viktor Klang*
>> *Chief Architect - **Typesafe <http://www.typesafe.com/>*
>>
>>  Twitter: @viktorklang
>>
>
>


-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/ca99c604/attachment-0001.html>

From zhong.j.yu at gmail.com  Mon Feb  3 14:37:15 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Mon, 3 Feb 2014 13:37:15 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor thread
	timeout
In-Reply-To: <CAJ8S3uztJfB9jjNLy0QQ25GzOkesHVYK4aM3SHqsYiUYYxET6w@mail.gmail.com>
References: <CACuKZqEsz7WW+-47L9ySreXkRN8Am3Qk9nwzDjaCVw75tsgHhA@mail.gmail.com>
	<52EFA283.7040800@javaspecialists.eu>
	<CACuKZqF27hqtzkBavHYVFS1z_sF1YOJSHjZa--0-5FKFEepsUA@mail.gmail.com>
	<CAJ8S3uxJWXitG6S33434aGcV+ifaT7eJTdLd7LpWYko+kzCE-A@mail.gmail.com>
	<CANPzfU9+QUFN7uLhKETV7ssWHwSoB2=kV+KzpxSC9AEqmMyotA@mail.gmail.com>
	<CAJ8S3uztJfB9jjNLy0QQ25GzOkesHVYK4aM3SHqsYiUYYxET6w@mail.gmail.com>
Message-ID: <CACuKZqFq2aMGHbB+3oimBDqdfJM5xYvgVv4HV2n1xLUeTvXx=w@mail.gmail.com>

On Mon, Feb 3, 2014 at 12:49 PM, Robert J. Saulnier
<robert.j.saulnier at gmail.com> wrote:
> You don't need to wait for the Future to complete, you can shutdown the
> executor right after scheduling the task(s) and these scheduled tasks will
> still be executed.
>
> So I believe my example meets the OP's requirements.

My example was too simplistic. Assume we cannot anticipate the pattern
of task submissions. The question is whether it is safe to timeout the
core thread after a period of idleness. The javadoc says no, and I'd
like to have a workaround.

>
>
> On Mon, Feb 3, 2014 at 2:34 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>>
>>
>>
>>
>> On Mon, Feb 3, 2014 at 7:25 PM, Robert J. Saulnier
>> <robert.j.saulnier at gmail.com> wrote:
>>>
>>> ScheduledExecutorService executor =
>>> Executors.newSingleThreadScheduledExecutor();
>>>
>>> executor.schedule(() -> { System.out.println("hey"); }, 1L,
>>> TimeUnit.SECONDS);
>>>
>>> executor.shutdown();
>>
>>
>> Sadly in JDK8 ScheduledFuture is not a CompletableFuture, otherwise you'd
>> just attach the shutdown to be executed when the Future completes.
>>
>>>
>>>
>>>
>>>
>>> On Mon, Feb 3, 2014 at 2:02 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
>>>>
>>>> Assume the task does not know it's the last one...
>>>>
>>>> On Mon, Feb 3, 2014 at 8:06 AM, Dr Heinz M. Kabutz
>>>> <heinz at javaspecialists.eu> wrote:
>>>> > How about doing this for a once-off scheduled task?
>>>> >
>>>> > import java.util.concurrent.*;
>>>> >
>>>> > public class ForeverYoung {
>>>> >
>>>> >  public static void main(String[] args) {
>>>> >    ScheduledThreadPoolExecutor exec =
>>>> >        new ScheduledThreadPoolExecutor(1);
>>>> >    exec.schedule(() -> {
>>>> >      System.out.println("done");
>>>> >      exec.shutdown();
>>>> >    },
>>>> >        1, TimeUnit.SECONDS
>>>> >    );
>>>> >  }
>>>> > }
>>>> >
>>>> > Regards
>>>> >
>>>> > Heinz
>>>> > --
>>>> > Dr Heinz M. Kabutz (PhD CompSci)
>>>> > Author of "The Java(tm) Specialists' Newsletter"
>>>> > Oracle Java Champion 2005-2013
>>>> > JavaOne Rock Star Speaker 2012
>>>> > http://www.javaspecialists.eu
>>>> > Tel: +30 69 75 595 262
>>>> > Skype: kabutz
>>>> >
>>>> >
>>>> >
>>>> > Zhong Yu wrote:
>>>> >>
>>>> >> In this simple example, the JVM never exits:
>>>> >>
>>>> >>     public static void main(String[] args)
>>>> >>     {
>>>> >>         ScheduledThreadPoolExecutor exec =
>>>> >>             new ScheduledThreadPoolExecutor(1);
>>>> >>         exec.schedule( ()-> System.out.println("done"),
>>>> >>             1, TimeUnit.SECONDS );
>>>> >>     }
>>>> >>
>>>> >> because the core thread cannot timeout.
>>>> >>
>>>> >> This creates a problem in a hot-reload environment, where each new
>>>> >> app
>>>> >> instance creates a new scheduler thread that never terminates. Is
>>>> >> there a workaround to the effect that the thread can timeout? Thanks.
>>>> >>
>>>> >> Zhong Yu
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >> .
>>>> >>
>>>> >>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>> ???????
>> Viktor Klang
>> Chief Architect - Typesafe
>>
>> Twitter: @viktorklang
>
>


From zhong.j.yu at gmail.com  Mon Feb  3 14:44:03 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Mon, 3 Feb 2014 13:44:03 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <52EFDE7A.2020704@javaspecialists.eu>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>
	<52EFDE7A.2020704@javaspecialists.eu>
Message-ID: <CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>

On Mon, Feb 3, 2014 at 12:22 PM, Dr Heinz M. Kabutz
<heinz at javaspecialists.eu> wrote:
>
> it is almost never a good idea to set corePoolSize to zero or
>
>
> use allowCoreThreadTimeOut because this may leave the pool
> without threads to handle tasks once they become eligible to run.
>
> is the current implementation more robust than that?
>
>
> I think it is in the sense that if there is a task waiting to become
> eligible to run then there is a worker thread that is waiting for that time
> to arrive. But the details are complex and there may be circumstances where
> tasks are not executed as expected.
>
>
> It looks like setting the core size to zero might result in additional
> threads being constructed if we finish all the tasks in the queue and wait a
> little bit.  But as far as I could tell, that's the worst case scenario,
> which is better than leaking threads.  Am I missing anything?
>
>
> import java.util.concurrent.*;
>
> public class ForeverYoung {
>   public static void main(String[] args) throws InterruptedException {
>     ThreadPoolExecutor tpe = new ThreadPoolExecutor(
>         0, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS,
>         new LinkedBlockingQueue<>()
>     );
>     tpe.submit(() -> System.out.println("tpe1 by " +
> Thread.currentThread()));
>     tpe.submit(() -> System.out.println("tpe2 by " +
> Thread.currentThread()));
>     tpe.submit(() -> System.out.println("tpe3 by " +
> Thread.currentThread()));
>
>
>     ScheduledThreadPoolExecutor exec =
>         new ScheduledThreadPoolExecutor(0);
>     exec.schedule(() -> {
>       System.out.println("task 1 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     exec.schedule(() -> {
>       System.out.println("task 2 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     exec.schedule(() -> {
>       System.out.println("task 3 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     Thread.sleep(6000);
>     exec.schedule(() -> {
>       System.out.println("task 4 by " + Thread.currentThread());
>     },
>         1,
>         TimeUnit.SECONDS
>     );
>
>   }
> }
>
>
> Output:
>
> java version "1.8.0"
> Java(TM) SE Runtime Environment (build 1.8.0-b126)
> Java HotSpot(TM) 64-Bit Server VM (build 25.0-b67, mixed mode)
>
> tpe1 by Thread[pool-1-thread-1,5,main]
> tpe2 by Thread[pool-1-thread-1,5,main]
> tpe3 by Thread[pool-1-thread-2,5,main]
> task 1 by Thread[pool-2-thread-1,5,main]
> task 3 by Thread[pool-2-thread-1,5,main]
> task 2 by Thread[pool-2-thread-1,5,main]
> task 4 by Thread[pool-2-thread-2,5,main]
>
> As we can see, task 4 is executed by a new thread.  But so what?

I have no problem with that, but I wonder if it is safe to do so,
i.e., all submitted tasks will be executed even if core threads may
time out, against the advice of the javadoc.

>
> Heinz

From heinz at javaspecialists.eu  Mon Feb  3 15:13:53 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Mon, 03 Feb 2014 22:13:53 +0200
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>	<52EFDE7A.2020704@javaspecialists.eu>
	<CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>
Message-ID: <52EFF881.6010900@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140203/ac59c99c/attachment.html>

From belliottsmith at datastax.com  Tue Feb  4 11:48:23 2014
From: belliottsmith at datastax.com (Benedict Elliott Smith)
Date: Tue, 4 Feb 2014 16:48:23 +0000
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like poll/iterator
	remove
Message-ID: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>

Hi,

This may be a bit on the late side for inclusion in JDK8, but I noticed
that ConcurrentLinkedQueue has moved to a non-blocking algorithm, which is
great. It means I may be able to dispose of my own in some places.

However, it would be particularly nice to get a pollIfHead(item) method,
which behaves like a depth-1 limited remove(item), and possibly an
extension of Iterator that supports atomicRemove() (returning
success/failure) or similar.

Both of these operations have been essential in some algorithms I've
implemented recently, although I may be fairly alone in that. However,
they're both very easy to add to the new CLQ implementation.

I'd be happy to submit a patch, although other than deciding the name of
any new interface for atomic interator removal, it's pretty trivial.

Thoughts?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140204/69591bb0/attachment.html>

From martinrb at google.com  Tue Feb  4 12:14:18 2014
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 4 Feb 2014 09:14:18 -0800
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like
 poll/iterator remove
In-Reply-To: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
References: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
Message-ID: <CA+kOe087BGrDdVo_jRMXH3uqyE6xu+TyOZf+6J_D4M7G3AqhSQ@mail.gmail.com>

These suggestions seem reasonable to me, but concurrent collections have
conservative api evolution and are focused on implementing the existing
Collection interfaces.  Which were often designed for a non-concurrent
world.  A concurrent iterator that supported atomic removal seems better
than the traditional void remove() method.  I would name it tryRemove
rather than atomicRemove.  And instead of E pollIfHead(item) I'm thinking E
poll(predicate).  ConcurrentLinkedDeque can get the same treatment.

What does Doug think?


On Tue, Feb 4, 2014 at 8:48 AM, Benedict Elliott Smith <
belliottsmith at datastax.com> wrote:

> Hi,
>
> This may be a bit on the late side for inclusion in JDK8, but I noticed
> that ConcurrentLinkedQueue has moved to a non-blocking algorithm, which is
> great. It means I may be able to dispose of my own in some places.
>
> However, it would be particularly nice to get a pollIfHead(item) method,
> which behaves like a depth-1 limited remove(item), and possibly an
> extension of Iterator that supports atomicRemove() (returning
> success/failure) or similar.
>
> Both of these operations have been essential in some algorithms I've
> implemented recently, although I may be fairly alone in that. However,
> they're both very easy to add to the new CLQ implementation.
>
> I'd be happy to submit a patch, although other than deciding the name of
> any new interface for atomic interator removal, it's pretty trivial.
>
> Thoughts?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140204/a31198ad/attachment.html>

From belliottsmith at datastax.com  Wed Feb  5 04:19:30 2014
From: belliottsmith at datastax.com (Benedict Elliott Smith)
Date: Wed, 5 Feb 2014 09:19:30 +0000
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like
 poll/iterator remove
In-Reply-To: <CA+kOe087BGrDdVo_jRMXH3uqyE6xu+TyOZf+6J_D4M7G3AqhSQ@mail.gmail.com>
References: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
	<CA+kOe087BGrDdVo_jRMXH3uqyE6xu+TyOZf+6J_D4M7G3AqhSQ@mail.gmail.com>
Message-ID: <CAFqWSgewDj-mKAj+V1t+U=_D+MRc=pDM7M+DXX-EGon0A8xmCQ@mail.gmail.com>

I'm certainly not wed to the method names. I have a preference to not
require a predicate for the conditional poll, though, as for the near
future this is likely to mean a heap allocation that could otherwise be
avoided.

Another one to consider is a suitably named conditional append (still for
CLQ), although this is more questionably useful. I think a predicate would
be more necessary here, to make it properly useful in the face of
destructive modification to the head of the queue that catches up with the
tail. e.g. I have had a scenario where I wanted to append a new resource to
a queue on the assumption that no other such resources had been appended
since the queue was just iterated, or that the queue is now empty.




On 4 February 2014 17:14, Martin Buchholz <martinrb at google.com> wrote:

> These suggestions seem reasonable to me, but concurrent collections have
> conservative api evolution and are focused on implementing the existing
> Collection interfaces.  Which were often designed for a non-concurrent
> world.  A concurrent iterator that supported atomic removal seems better
> than the traditional void remove() method.  I would name it tryRemove
> rather than atomicRemove.  And instead of E pollIfHead(item) I'm thinking E
> poll(predicate).  ConcurrentLinkedDeque can get the same treatment.
>
> What does Doug think?
>
>
> On Tue, Feb 4, 2014 at 8:48 AM, Benedict Elliott Smith <
> belliottsmith at datastax.com> wrote:
>
>> Hi,
>>
>> This may be a bit on the late side for inclusion in JDK8, but I noticed
>> that ConcurrentLinkedQueue has moved to a non-blocking algorithm, which is
>> great. It means I may be able to dispose of my own in some places.
>>
>> However, it would be particularly nice to get a pollIfHead(item) method,
>> which behaves like a depth-1 limited remove(item), and possibly an
>> extension of Iterator that supports atomicRemove() (returning
>> success/failure) or similar.
>>
>> Both of these operations have been essential in some algorithms I've
>> implemented recently, although I may be fairly alone in that. However,
>> they're both very easy to add to the new CLQ implementation.
>>
>> I'd be happy to submit a patch, although other than deciding the name of
>> any new interface for atomic interator removal, it's pretty trivial.
>>
>> Thoughts?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/f3c493a8/attachment.html>

From benjamin.john.evans at gmail.com  Wed Feb  5 08:33:59 2014
From: benjamin.john.evans at gmail.com (Ben Evans)
Date: Wed, 5 Feb 2014 13:33:59 +0000
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52ED59E2.7010301@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu> <52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
	<52EBBB46.5080002@javaspecialists.eu>
	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE1F9.9030206@javaspecialists.eu>
	<52ED59E2.7010301@cs.oswego.edu>
Message-ID: <CABKW8RjGi_Hi3siZNcpUeeS3cT1bewzmdgnSGS-n51HWnU=maQ@mail.gmail.com>

Could we do 1 and / or 2 in time for JDK 8, as it just requires a
documentation patch?

Then we can add rules to the static analysis checkers (as they aren't
dependent on the JDK release cycle) and that should catch a decent amount
of people.

Thanks,

Ben


On Sat, Feb 1, 2014 at 8:32 PM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> To summarize, we have the following suggestions (some off-list)
> in response to Heinz's puzzler:
>
> 1. Add documentation to TLR warning not to store TLR.current()
> in a static, or use as an argument to a method that might do so,
> or use as an argument in a method assuming thread-safety.
>
> 2. Add similar documentation to java.lang.ThreadLocal, and then
> refer and add to it in TLR.
>
> 3. Create findBugs rules covering (1) and (2).
>
> 4. Invent new type rules for Java enforcing (1) and (2).
>
> 5. Add an initialization check on each use of TLR.next() and
> throw an exception.
>
> 6. Eagerly initialize TLR seeds. (One reason this was not
> done originally is that it adds measurable time to Thread
> construction even when TLRs are not used in a thread, which
> is the most common case.)
>
> 7. Tell people to use java.util.SplittableRandom instead.
>
> 8. Do nothing.
>
> Considering that this is far from a critical bug, it is
> unlikely to become updated in OpenJDK until JDK9, so we
> seem to have plenty of time for further suggestions!
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/3b2ea2da/attachment.html>

From dl at cs.oswego.edu  Wed Feb  5 08:47:37 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 05 Feb 2014 08:47:37 -0500
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like
 poll/iterator remove
In-Reply-To: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
References: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
Message-ID: <52F240F9.3030505@cs.oswego.edu>

On 02/04/2014 11:48 AM, Benedict Elliott Smith wrote:
> This may be a bit on the late side for inclusion in JDK8,

No chance. JKD8 is completely frozen except for show-stopper bugs.

>  but I noticed that
> ConcurrentLinkedQueue has moved to a non-blocking algorithm,

It has always been non-blocking. Maybe you are thinking of a different Queue?

>
> However, it would be particularly nice to get a pollIfHead(item) method, which

Yes, we initially contemplated a takeIfFirst(Object x) method. Sorry
that I have no recollection of why this never made it into Queue API.
It would be nearly impossible to add it to interface since there is
no reasonable default implementation, but easy to add to CLQ and some
others. I cannot think of a reason not to do this for JDK9.


> possibly an extension of
> Iterator that supports atomicRemove() (returning success/failure) or similar.

I agree that it would have been nice for Iterator.remove to return a
boolean (like Collection remove does). But considering that nearly
all Queue iterators are intrinsically slow anyway (processing
the internal items of a concurrent queue is an unnatural act),
the argument for not just forcing people needing this to use
queue.remove(x) is not all that compelling given that we would
need to define a special Iterator subinterface and class
just to expose this.

-Doug


From belliottsmith at datastax.com  Wed Feb  5 09:13:58 2014
From: belliottsmith at datastax.com (Benedict Elliott Smith)
Date: Wed, 5 Feb 2014 14:13:58 +0000
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like
 poll/iterator remove
In-Reply-To: <52F240F9.3030505@cs.oswego.edu>
References: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
	<52F240F9.3030505@cs.oswego.edu>
Message-ID: <CAFqWSgc6L=up92K5v3oaua7g=buZkh5YE1SNKyf5_6hJvxun3w@mail.gmail.com>

>
> It has always been non-blocking. Maybe you are thinking of a different
> Queue?


My mistake, sorry.


> But considering that nearly all Queue iterators are intrinsically slow
> anyway (processing the internal items of a concurrent queue is an
> unnatural act),


There are two problems with this:

1) it is much slower still, making iterating and removing potentially an
O(n^2) operation, as opposed to O(n), if you need to do it; and
2) it is not accurate: the same item by equality may potentially be
inserted/removed in the intervening time, or occur multiple times in the
same queue, so it would not be semantically equivalent.

I fail to understand your assertions that "Queue iterators are
intrinsically slow" or that "processing the internal items of a concurrent
queue is an unnatural act"; sure, the latter is atypical, but hardly
unnatural, and it is not appreciably slower than iterating any linked data
structure, nor algorithmically slower than iterating any data structure.




On 5 February 2014 13:47, Doug Lea <dl at cs.oswego.edu> wrote:

> On 02/04/2014 11:48 AM, Benedict Elliott Smith wrote:
>
>> This may be a bit on the late side for inclusion in JDK8,
>>
>
> No chance. JKD8 is completely frozen except for show-stopper bugs.
>
>
>   but I noticed that
>> ConcurrentLinkedQueue has moved to a non-blocking algorithm,
>>
>
> It has always been non-blocking. Maybe you are thinking of a different
> Queue?
>
>
>
>> However, it would be particularly nice to get a pollIfHead(item) method,
>> which
>>
>
> Yes, we initially contemplated a takeIfFirst(Object x) method. Sorry
> that I have no recollection of why this never made it into Queue API.
> It would be nearly impossible to add it to interface since there is
> no reasonable default implementation, but easy to add to CLQ and some
> others. I cannot think of a reason not to do this for JDK9.
>
>
>
>  possibly an extension of
>> Iterator that supports atomicRemove() (returning success/failure) or
>> similar.
>>
>
> I agree that it would have been nice for Iterator.remove to return a
> boolean (like Collection remove does). But considering that nearly
> all Queue iterators are intrinsically slow anyway (processing
> the internal items of a concurrent queue is an unnatural act),
> the argument for not just forcing people needing this to use
> queue.remove(x) is not all that compelling given that we would
> need to define a special Iterator subinterface and class
> just to expose this.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/48bbe189/attachment-0001.html>

From paul.sandoz at oracle.com  Wed Feb  5 12:37:32 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Wed, 5 Feb 2014 18:37:32 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CABKW8RjGi_Hi3siZNcpUeeS3cT1bewzmdgnSGS-n51HWnU=maQ@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com> <52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com> <52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
	<52EBBB46.5080002@javaspecialists.eu>
	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE1F9.9030206@javaspecialists.eu>
	<52ED59E2.7010301@cs.oswego.edu>
	<CABKW8RjGi_Hi3siZNcpUeeS3cT1bewzmdgnSGS-n51HWnU=maQ@mail.gmail.com>
Message-ID: <0EB0182C-C5E1-4E6E-9C0C-7CA4E4FAAB2E@oracle.com>

On Feb 5, 2014, at 2:33 PM, Ben Evans <benjamin.john.evans at gmail.com> wrote:
> Could we do 1 and / or 2 in time for JDK 8, as it just requires a documentation patch?
> 

It would be reasonable to think so, but any changes at this point (docs or otherwise) need to be show stoppers :-(

I have not been flowing this thread in great detail, but i believe this stuff is either impl or API notes. So we could add such documentation for the next 8u release.

Paul.

> Then we can add rules to the static analysis checkers (as they aren't dependent on the JDK release cycle) and that should catch a decent amount of people.
> 
> Thanks,
> 
> Be

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/20028a9a/attachment.bin>

From heinz at javaspecialists.eu  Wed Feb  5 13:27:10 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Wed, 05 Feb 2014 20:27:10 +0200
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <0EB0182C-C5E1-4E6E-9C0C-7CA4E4FAAB2E@oracle.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>	<52ED59E2.7010301@cs.oswego.edu>	<CABKW8RjGi_Hi3siZNcpUeeS3cT1bewzmdgnSGS-n51HWnU=maQ@mail.gmail.com>
	<0EB0182C-C5E1-4E6E-9C0C-7CA4E4FAAB2E@oracle.com>
Message-ID: <52F2827E.4000508@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/9b929faf/attachment.html>

From martinrb at google.com  Wed Feb  5 15:28:04 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 5 Feb 2014 12:28:04 -0800
Subject: [concurrency-interest] ConcurrentLinkedQueue CAS-like
 poll/iterator remove
In-Reply-To: <CAFqWSgc6L=up92K5v3oaua7g=buZkh5YE1SNKyf5_6hJvxun3w@mail.gmail.com>
References: <CAFqWSgd3n2pLOMrG_DoCt16ee67QxFZ0uaD=2qj0xYJMcN5stw@mail.gmail.com>
	<52F240F9.3030505@cs.oswego.edu>
	<CAFqWSgc6L=up92K5v3oaua7g=buZkh5YE1SNKyf5_6hJvxun3w@mail.gmail.com>
Message-ID: <CA+kOe0_KnPNSb+DfAT0CQPcYtH+VZdLb+xpWCykNV+XB=dTnng@mail.gmail.com>

I'm leaning towards Benedict's view that iterating over the elements in a
data structure like CLQ is reasonable.  The List API is concurrency-hostile
because access by index doesn't really make sense.  But remove indexes and
use a concurrency-friendly iterator instead and you have something that
should be useful for "concurrent list processing".

If you implement a CLQ.ConcurrentIterator with boolean tryRemove(), then a
hypothetical takeIfFirst can be trivially implemented using the
ConcurrentIterator.

Note that for CLQ and CLD we know how to implement concurrent interior
removal, but not concurrent interior insertion.

Perhaps methods like takeIfFirst didn't make it for the usual reason that
us library folks have the urge to generalize, and that leads us to waiting
for lambdas.  But lambdas are finally here, so it is time to reconsider all
of those old API proposals for future JDKs.


On Wed, Feb 5, 2014 at 6:13 AM, Benedict Elliott Smith <
belliottsmith at datastax.com> wrote:

> It has always been non-blocking. Maybe you are thinking of a different
>> Queue?
>
>
> My mistake, sorry.
>
>
>> But considering that nearly all Queue iterators are intrinsically slow
>> anyway (processing the internal items of a concurrent queue is an
>> unnatural act),
>
>
> There are two problems with this:
>
> 1) it is much slower still, making iterating and removing potentially an
> O(n^2) operation, as opposed to O(n), if you need to do it; and
> 2) it is not accurate: the same item by equality may potentially be
> inserted/removed in the intervening time, or occur multiple times in the
> same queue, so it would not be semantically equivalent.
>
> I fail to understand your assertions that "Queue iterators are
> intrinsically slow" or that "processing the internal items of a concurrent
> queue is an unnatural act"; sure, the latter is atypical, but hardly
> unnatural, and it is not appreciably slower than iterating any linked data
> structure, nor algorithmically slower than iterating any data structure.
>
>
>
>
> On 5 February 2014 13:47, Doug Lea <dl at cs.oswego.edu> wrote:
>
>> On 02/04/2014 11:48 AM, Benedict Elliott Smith wrote:
>>
>>> This may be a bit on the late side for inclusion in JDK8,
>>>
>>
>> No chance. JKD8 is completely frozen except for show-stopper bugs.
>>
>>
>>   but I noticed that
>>> ConcurrentLinkedQueue has moved to a non-blocking algorithm,
>>>
>>
>> It has always been non-blocking. Maybe you are thinking of a different
>> Queue?
>>
>>
>>
>>> However, it would be particularly nice to get a pollIfHead(item) method,
>>> which
>>>
>>
>> Yes, we initially contemplated a takeIfFirst(Object x) method. Sorry
>> that I have no recollection of why this never made it into Queue API.
>> It would be nearly impossible to add it to interface since there is
>> no reasonable default implementation, but easy to add to CLQ and some
>> others. I cannot think of a reason not to do this for JDK9.
>>
>>
>>
>>  possibly an extension of
>>> Iterator that supports atomicRemove() (returning success/failure) or
>>> similar.
>>>
>>
>> I agree that it would have been nice for Iterator.remove to return a
>> boolean (like Collection remove does). But considering that nearly
>> all Queue iterators are intrinsically slow anyway (processing
>> the internal items of a concurrent queue is an unnatural act),
>> the argument for not just forcing people needing this to use
>> queue.remove(x) is not all that compelling given that we would
>> need to define a special Iterator subinterface and class
>> just to expose this.
>>
>> -Doug
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140205/a0356b22/attachment.html>

From ron.pressler at gmail.com  Thu Feb  6 12:08:55 2014
From: ron.pressler at gmail.com (Ron Pressler)
Date: Thu, 6 Feb 2014 19:08:55 +0200
Subject: [concurrency-interest] Implementing,
	Abstracting and Benchmarking Lightweight Threads on the JVM
Message-ID: <CABg6-qj8nNHXM9Kby1oBR-pBiOKuDhsTmuRhoLokO5_eBw5zjg@mail.gmail.com>

Hi.
I've just published a blog post called Implementing, Abstracting and
Benchmarking Lightweight Threads on the
JVM<http://blog.paralleluniverse.co/2014/02/06/fibers-threads-strands/>,
which describes Quasar <https://github.com/puniverse/quasar>'s
implementation of lightweight threads.

In particular, it explains how we've adapted some of java.util.concurrent's
classes to work for both (plain) threads and fibers (Quasar lightweight
threads), by combining both into an abstraction called
strands<http://docs.paralleluniverse.co/quasar/javadoc/co/paralleluniverse/strands/Strand.html>
.

I thought some people here might find it interesting.

Ron
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140206/739b5d80/attachment.html>

From martinrb at google.com  Thu Feb  6 13:55:32 2014
From: martinrb at google.com (Martin Buchholz)
Date: Thu, 6 Feb 2014 10:55:32 -0800
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <52EFF881.6010900@javaspecialists.eu>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>
	<52EFDE7A.2020704@javaspecialists.eu>
	<CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>
	<52EFF881.6010900@javaspecialists.eu>
Message-ID: <CA+kOe08Ts_YURQ+UCuNK_MBSFofeHqpet3DftoUP-TjFi8ikBg@mail.gmail.com>

In fact, the current implementation ensures that we never have the queue
non-empty and no threads to service the task when its time comes.

A higher-quality implementation might ensure that a new thread is created
(up to core size) not only when a task is submitted to the pool, but also
when the scheduled time arrives.  Which might mean not just keeping at
least one thread around, but keeping one idle "manager" thread around that
spawns new threads to service the ones in the queue.

But the ThreadPoolExecutor code is brittle and we're afraid to touch it.


On Mon, Feb 3, 2014 at 12:13 PM, Dr Heinz M. Kabutz <
heinz at javaspecialists.eu> wrote:

>  Zhong Yu wrote:
>
> On Mon, Feb 3, 2014 at 12:22 PM, Dr Heinz M. Kabutz<heinz at javaspecialists.eu> <heinz at javaspecialists.eu> wrote:
>
>
>  it is almost never a good idea to set corePoolSize to zero or
>
>
> use allowCoreThreadTimeOut because this may leave the pool
> without threads to handle tasks once they become eligible to run.
>
> is the current implementation more robust than that?
>
>
> I think it is in the sense that if there is a task waiting to become
> eligible to run then there is a worker thread that is waiting for that time
> to arrive. But the details are complex and there may be circumstances where
> tasks are not executed as expected.
>
>
> It looks like setting the core size to zero might result in additional
> threads being constructed if we finish all the tasks in the queue and wait a
> little bit.  But as far as I could tell, that's the worst case scenario,
> which is better than leaking threads.  Am I missing anything?
>
>
> import java.util.concurrent.*;
>
> public class ForeverYoung {
>   public static void main(String[] args) throws InterruptedException {
>     ThreadPoolExecutor tpe = new ThreadPoolExecutor(
>         0, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS,
>         new LinkedBlockingQueue<>()
>     );
>     tpe.submit(() -> System.out.println("tpe1 by " +
> Thread.currentThread()));
>     tpe.submit(() -> System.out.println("tpe2 by " +
> Thread.currentThread()));
>     tpe.submit(() -> System.out.println("tpe3 by " +
> Thread.currentThread()));
>
>
>     ScheduledThreadPoolExecutor exec =
>         new ScheduledThreadPoolExecutor(0);
>     exec.schedule(() -> {
>       System.out.println("task 1 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     exec.schedule(() -> {
>       System.out.println("task 2 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     exec.schedule(() -> {
>       System.out.println("task 3 by " + Thread.currentThread());
>     },
>         ThreadLocalRandom.current().nextInt(5) + 1,
>         TimeUnit.SECONDS
>     );
>     Thread.sleep(6000);
>     exec.schedule(() -> {
>       System.out.println("task 4 by " + Thread.currentThread());
>     },
>         1,
>         TimeUnit.SECONDS
>     );
>
>   }
> }
>
>
> Output:
>
> java version "1.8.0"
> Java(TM) SE Runtime Environment (build 1.8.0-b126)
> Java HotSpot(TM) 64-Bit Server VM (build 25.0-b67, mixed mode)
>
> tpe1 by Thread[pool-1-thread-1,5,main]
> tpe2 by Thread[pool-1-thread-1,5,main]
> tpe3 by Thread[pool-1-thread-2,5,main]
> task 1 by Thread[pool-2-thread-1,5,main]
> task 3 by Thread[pool-2-thread-1,5,main]
> task 2 by Thread[pool-2-thread-1,5,main]
> task 4 by Thread[pool-2-thread-2,5,main]
>
> As we can see, task 4 is executed by a new thread.  But so what?
>
>
>  I have no problem with that, but I wonder if it is safe to do so,
> i.e., all submitted tasks will be executed even if core threads may
> time out, against the advice of the javadoc.
>
>
>  In my test case, the core thread did time out and the world did not end.
> Another thread was started when a new job was submitted.  But I already got
> into trouble once this week for ignoring a JavaDoc comment, so I won't say
> that this necessarily wil always work ;-)
>
> Heinz
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140206/e835854e/attachment.html>

From heinz at javaspecialists.eu  Thu Feb  6 14:51:42 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Thu, 06 Feb 2014 21:51:42 +0200
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <CA+kOe08Ts_YURQ+UCuNK_MBSFofeHqpet3DftoUP-TjFi8ikBg@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>	<52EFDE7A.2020704@javaspecialists.eu>	<CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>	<52EFF881.6010900@javaspecialists.eu>
	<CA+kOe08Ts_YURQ+UCuNK_MBSFofeHqpet3DftoUP-TjFi8ikBg@mail.gmail.com>
Message-ID: <52F3E7CE.8010001@javaspecialists.eu>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140206/d8f30f00/attachment.html>

From zhong.j.yu at gmail.com  Thu Feb  6 15:02:23 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Thu, 6 Feb 2014 14:02:23 -0600
Subject: [concurrency-interest] ScheduledThreadPoolExecutor threadtimeout
In-Reply-To: <CA+kOe08Ts_YURQ+UCuNK_MBSFofeHqpet3DftoUP-TjFi8ikBg@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCCECDKEAA.davidcholmes@aapt.net.au>
	<52EFDE7A.2020704@javaspecialists.eu>
	<CACuKZqGk-eeA=oSCyb9oveWEB2zHWFQu7rYrLxCUr_pV6tRtjg@mail.gmail.com>
	<52EFF881.6010900@javaspecialists.eu>
	<CA+kOe08Ts_YURQ+UCuNK_MBSFofeHqpet3DftoUP-TjFi8ikBg@mail.gmail.com>
Message-ID: <CACuKZqG6LN+EBSy4eYCid5B=sRRjKZah97B0WQEETizLXhmPtg@mail.gmail.com>

On Thu, Feb 6, 2014 at 12:55 PM, Martin Buchholz <martinrb at google.com> wrote:
> In fact, the current implementation ensures that we never have the queue
> non-empty and no threads to service the task when its time comes.

Thanks, that does seem to be the case. I'll take the risk of ignoring
the javadoc warning.

>
> A higher-quality implementation might ensure that a new thread is created
> (up to core size) not only when a task is submitted to the pool, but also
> when the scheduled time arrives.  Which might mean not just keeping at least
> one thread around, but keeping one idle "manager" thread around that spawns
> new threads to service the ones in the queue.
>
> But the ThreadPoolExecutor code is brittle and we're afraid to touch it.
>
>
> On Mon, Feb 3, 2014 at 12:13 PM, Dr Heinz M. Kabutz
> <heinz at javaspecialists.eu> wrote:
>>
>> Zhong Yu wrote:
>>
>> On Mon, Feb 3, 2014 at 12:22 PM, Dr Heinz M. Kabutz
>> <heinz at javaspecialists.eu> wrote:
>>
>>
>> it is almost never a good idea to set corePoolSize to zero or
>>
>>
>> use allowCoreThreadTimeOut because this may leave the pool
>> without threads to handle tasks once they become eligible to run.
>>
>> is the current implementation more robust than that?
>>
>>
>> I think it is in the sense that if there is a task waiting to become
>> eligible to run then there is a worker thread that is waiting for that
>> time
>> to arrive. But the details are complex and there may be circumstances
>> where
>> tasks are not executed as expected.
>>
>>
>> It looks like setting the core size to zero might result in additional
>> threads being constructed if we finish all the tasks in the queue and wait
>> a
>> little bit.  But as far as I could tell, that's the worst case scenario,
>> which is better than leaking threads.  Am I missing anything?
>>
>>
>> import java.util.concurrent.*;
>>
>> public class ForeverYoung {
>>   public static void main(String[] args) throws InterruptedException {
>>     ThreadPoolExecutor tpe = new ThreadPoolExecutor(
>>         0, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS,
>>         new LinkedBlockingQueue<>()
>>     );
>>     tpe.submit(() -> System.out.println("tpe1 by " +
>> Thread.currentThread()));
>>     tpe.submit(() -> System.out.println("tpe2 by " +
>> Thread.currentThread()));
>>     tpe.submit(() -> System.out.println("tpe3 by " +
>> Thread.currentThread()));
>>
>>
>>     ScheduledThreadPoolExecutor exec =
>>         new ScheduledThreadPoolExecutor(0);
>>     exec.schedule(() -> {
>>       System.out.println("task 1 by " + Thread.currentThread());
>>     },
>>         ThreadLocalRandom.current().nextInt(5) + 1,
>>         TimeUnit.SECONDS
>>     );
>>     exec.schedule(() -> {
>>       System.out.println("task 2 by " + Thread.currentThread());
>>     },
>>         ThreadLocalRandom.current().nextInt(5) + 1,
>>         TimeUnit.SECONDS
>>     );
>>     exec.schedule(() -> {
>>       System.out.println("task 3 by " + Thread.currentThread());
>>     },
>>         ThreadLocalRandom.current().nextInt(5) + 1,
>>         TimeUnit.SECONDS
>>     );
>>     Thread.sleep(6000);
>>     exec.schedule(() -> {
>>       System.out.println("task 4 by " + Thread.currentThread());
>>     },
>>         1,
>>         TimeUnit.SECONDS
>>     );
>>
>>   }
>> }
>>
>>
>> Output:
>>
>> java version "1.8.0"
>> Java(TM) SE Runtime Environment (build 1.8.0-b126)
>> Java HotSpot(TM) 64-Bit Server VM (build 25.0-b67, mixed mode)
>>
>> tpe1 by Thread[pool-1-thread-1,5,main]
>> tpe2 by Thread[pool-1-thread-1,5,main]
>> tpe3 by Thread[pool-1-thread-2,5,main]
>> task 1 by Thread[pool-2-thread-1,5,main]
>> task 3 by Thread[pool-2-thread-1,5,main]
>> task 2 by Thread[pool-2-thread-1,5,main]
>> task 4 by Thread[pool-2-thread-2,5,main]
>>
>> As we can see, task 4 is executed by a new thread.  But so what?
>>
>>
>> I have no problem with that, but I wonder if it is safe to do so,
>> i.e., all submitted tasks will be executed even if core threads may
>> time out, against the advice of the javadoc.
>>
>>
>> In my test case, the core thread did time out and the world did not end.
>> Another thread was started when a new job was submitted.  But I already got
>> into trouble once this week for ignoring a JavaDoc comment, so I won't say
>> that this necessarily wil always work ;-)
>>
>> Heinz
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>

From discus at kotek.net  Mon Feb 10 09:52:32 2014
From: discus at kotek.net (Jan Kotek)
Date: Mon, 10 Feb 2014 16:52:32 +0200
Subject: [concurrency-interest] Implementing,
	Abstracting and Benchmarking Lightweight Threads on the JVM
In-Reply-To: <CABg6-qj8nNHXM9Kby1oBR-pBiOKuDhsTmuRhoLokO5_eBw5zjg@mail.gmail.com>
References: <CABg6-qj8nNHXM9Kby1oBR-pBiOKuDhsTmuRhoLokO5_eBw5zjg@mail.gmail.com>
Message-ID: <19608222.I8hhFaJCUa@artemis>

Hi,

I experimented with Kilim micro-threads a few years ago. 

Is there a plan to provide full stack based on lightweight threads? I mean 
webserver, IO utils and database where all IO operations would use lightweight  
non-blocking operations. 

I think I could modify MapDB for this stack. I already have some non-blocking 
prototype based on AsynchronousFileChannel 

All best,
Jan Kotek

On Thursday, February 06, 2014 19:08:55 Ron Pressler wrote:
> Hi.
> I've just published a blog post called Implementing, Abstracting and
> Benchmarking Lightweight Threads on the
> JVM<http://blog.paralleluniverse.co/2014/02/06/fibers-threads-strands/>,
> which describes Quasar <https://github.com/puniverse/quasar>'s
> implementation of lightweight threads.
> 
> In particular, it explains how we've adapted some of java.util.concurrent's
> classes to work for both (plain) threads and fibers (Quasar lightweight
> threads), by combining both into an abstraction called
> strands<http://docs.paralleluniverse.co/quasar/javadoc/co/paralleluniverse/s
> trands/Strand.html> .
> 
> I thought some people here might find it interesting.
> 
> Ron


From tomas.mikula at gmail.com  Mon Feb 10 19:24:38 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Tue, 11 Feb 2014 01:24:38 +0100
Subject: [concurrency-interest] No *Task counterpart of CompletableFuture?
Message-ID: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>

Hi,

I really like the addition of the CompletionStage interface in 1.8.
However, there is just one implementation of it and that is
CompletableFuture. I am missing a task counterpart of it, i.e.
something that is both a Future and a CompletionStage, but is
completed by a computation (i.e. takes a Callable constructor argument
or has a protected abstract compute() method).

I imagine a hierarchy like this:

interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}

class CompletableFuture<T> implements CompletionFuture<T> {...}

class CompletionFutureTask<T> implements CompletionFuture<T> {
    public CompletionFutureTask(Callable<T> callable) {...}
    // or
    protected abstract T compute();
}


Is there a reason why this is missing? Is there a plan to add this?

Thanks,
Tomas

From dl at cs.oswego.edu  Tue Feb 11 14:46:32 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 11 Feb 2014 14:46:32 -0500
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
Message-ID: <52FA7E18.1020003@cs.oswego.edu>

On 02/10/2014 07:24 PM, Tomas Mikula wrote:
> Hi,
>
> I really like the addition of the CompletionStage interface in 1.8.
> However, there is just one implementation of it and that is
> CompletableFuture. I am missing a task counterpart of it, i.e.
> something that is both a Future and a CompletionStage, but is
> completed by a computation (i.e. takes a Callable constructor argument
> or has a protected abstract compute() method).

There are instead (four) static methods that accept functions and return
a CompletableFuture that is complete after they run. For example
supplyAsync is pasted below. Do you have usages in mind where
you'd need something different?


     /**
      * Returns a new CompletableFuture that is asynchronously completed
      * by a task running in the given executor with the value obtained
      * by calling the given Supplier.
      *
      * @param supplier a function returning the value to be used
      * to complete the returned CompletableFuture
      * @param executor the executor to use for asynchronous execution
      * @param <U> the function's return type
      * @return the new CompletableFuture
      */
     public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,
                                                        Executor executor)


>
> I imagine a hierarchy like this:
>
> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>
> class CompletableFuture<T> implements CompletionFuture<T> {...}
>
> class CompletionFutureTask<T> implements CompletionFuture<T> {
>      public CompletionFutureTask(Callable<T> callable) {...}
>      // or
>      protected abstract T compute();
> }
>
>
> Is there a reason why this is missing? Is there a plan to add this?
>
> Thanks,
> Tomas
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From tomas.mikula at gmail.com  Tue Feb 11 15:53:57 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Tue, 11 Feb 2014 21:53:57 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <52FA7E18.1020003@cs.oswego.edu>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
Message-ID: <CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>

On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>>
>> Hi,
>>
>> I really like the addition of the CompletionStage interface in 1.8.
>> However, there is just one implementation of it and that is
>> CompletableFuture. I am missing a task counterpart of it, i.e.
>> something that is both a Future and a CompletionStage, but is
>> completed by a computation (i.e. takes a Callable constructor argument
>> or has a protected abstract compute() method).
>
>
> There are instead (four) static methods that accept functions and return
> a CompletableFuture that is complete after they run. For example
> supplyAsync is pasted below. Do you have usages in mind where
> you'd need something different?
>
>
>     /**
>      * Returns a new CompletableFuture that is asynchronously completed
>      * by a task running in the given executor with the value obtained
>      * by calling the given Supplier.
>      *
>      * @param supplier a function returning the value to be used
>      * to complete the returned CompletableFuture
>      * @param executor the executor to use for asynchronous execution
>      * @param <U> the function's return type
>      * @return the new CompletableFuture
>      */
>     public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,
>                                                        Executor executor)
>

Thanks, Doug,

turns out my research was too shallow. This is all I need to get the job done.

There's just one minor wrinkle that I can live with. I am designing an
asynchronous interface whose method should return something that is
both a Future and a CompletionStage, but not necessarily a
CompletableFuture, i.e. without the complete* methods. In other words,
the interface should return something that completes on its own and
thus doesn't need the complete* methods. I don't want the client of
the interface to be able to call the complete* methods.

I can accomplish this with

interface Foo<T> {
    <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U> f);
}

which is slightly more verbose than (imaginary)

interface Foo<T> {
    <U> CompletionFuture<U> foo(Function<T, U> f);
}

where CompletionFuture is defined as suggested before:

interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}

Regards,
Tomas

>
>>
>> I imagine a hierarchy like this:
>>
>> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>>
>> class CompletableFuture<T> implements CompletionFuture<T> {...}
>>
>> class CompletionFutureTask<T> implements CompletionFuture<T> {
>>      public CompletionFutureTask(Callable<T> callable) {...}
>>      // or
>>      protected abstract T compute();
>> }
>>
>>
>> Is there a reason why this is missing? Is there a plan to add this?
>>
>> Thanks,
>> Tomas
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From viktor.klang at gmail.com  Tue Feb 11 16:20:19 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 11 Feb 2014 22:20:19 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
Message-ID: <CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>

On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>wrote:

> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
> >>
> >> Hi,
> >>
> >> I really like the addition of the CompletionStage interface in 1.8.
> >> However, there is just one implementation of it and that is
> >> CompletableFuture. I am missing a task counterpart of it, i.e.
> >> something that is both a Future and a CompletionStage, but is
> >> completed by a computation (i.e. takes a Callable constructor argument
> >> or has a protected abstract compute() method).
> >
> >
> > There are instead (four) static methods that accept functions and return
> > a CompletableFuture that is complete after they run. For example
> > supplyAsync is pasted below. Do you have usages in mind where
> > you'd need something different?
> >
> >
> >     /**
> >      * Returns a new CompletableFuture that is asynchronously completed
> >      * by a task running in the given executor with the value obtained
> >      * by calling the given Supplier.
> >      *
> >      * @param supplier a function returning the value to be used
> >      * to complete the returned CompletableFuture
> >      * @param executor the executor to use for asynchronous execution
> >      * @param <U> the function's return type
> >      * @return the new CompletableFuture
> >      */
> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
> supplier,
> >                                                        Executor executor)
> >
>
> Thanks, Doug,
>
> turns out my research was too shallow. This is all I need to get the job
> done.
>
> There's just one minor wrinkle that I can live with. I am designing an
> asynchronous interface whose method should return something that is
> both a Future and a CompletionStage, but not necessarily a
> CompletableFuture, i.e. without the complete* methods. In other words,
> the interface should return something that completes on its own and
> thus doesn't need the complete* methods. I don't want the client of
> the interface to be able to call the complete* methods.
>
> I can accomplish this with
>
> interface Foo<T> {
>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U> f);
> }
>
> which is slightly more verbose than (imaginary)
>
> interface Foo<T> {
>     <U> CompletionFuture<U> foo(Function<T, U> f);
> }
>
> where CompletionFuture is defined as suggested before:
>
> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>

May I ask why it needs to implement Future?


>
> Regards,
> Tomas
>
> >
> >>
> >> I imagine a hierarchy like this:
> >>
> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
> >>
> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
> >>
> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
> >>      public CompletionFutureTask(Callable<T> callable) {...}
> >>      // or
> >>      protected abstract T compute();
> >> }
> >>
> >>
> >> Is there a reason why this is missing? Is there a plan to add this?
> >>
> >> Thanks,
> >> Tomas
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140211/bdd671e3/attachment.html>

From tomas.mikula at gmail.com  Tue Feb 11 16:53:01 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Tue, 11 Feb 2014 22:53:01 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
Message-ID: <CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>

That's a good question and, as a matter of fact, I'm not even calling
any Future methods on the result. I think it's just because of my
current setting where I have other means of synchronization than
Future.get(), namely I'm using Platform.runLater() from JavaFX, like
this:

res.thenAccept(r -> {
    Platform.runLater(() -> handle(r));
});

I thought in other settings you would need to eventually call
Future.get() to synchronize with the main thread of computation.

Are you suggesting that
a) I should probably never need to call Future.get(); or
b) there's always CompletionStage.toCompletableFuture() (which I only
discovered now, so yes, I probably don't need Future)?

Regards,
Tomas

On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>
>
>
> On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
> wrote:
>>
>> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
>> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>> >>
>> >> Hi,
>> >>
>> >> I really like the addition of the CompletionStage interface in 1.8.
>> >> However, there is just one implementation of it and that is
>> >> CompletableFuture. I am missing a task counterpart of it, i.e.
>> >> something that is both a Future and a CompletionStage, but is
>> >> completed by a computation (i.e. takes a Callable constructor argument
>> >> or has a protected abstract compute() method).
>> >
>> >
>> > There are instead (four) static methods that accept functions and return
>> > a CompletableFuture that is complete after they run. For example
>> > supplyAsync is pasted below. Do you have usages in mind where
>> > you'd need something different?
>> >
>> >
>> >     /**
>> >      * Returns a new CompletableFuture that is asynchronously completed
>> >      * by a task running in the given executor with the value obtained
>> >      * by calling the given Supplier.
>> >      *
>> >      * @param supplier a function returning the value to be used
>> >      * to complete the returned CompletableFuture
>> >      * @param executor the executor to use for asynchronous execution
>> >      * @param <U> the function's return type
>> >      * @return the new CompletableFuture
>> >      */
>> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
>> > supplier,
>> >                                                        Executor
>> > executor)
>> >
>>
>> Thanks, Doug,
>>
>> turns out my research was too shallow. This is all I need to get the job
>> done.
>>
>> There's just one minor wrinkle that I can live with. I am designing an
>> asynchronous interface whose method should return something that is
>> both a Future and a CompletionStage, but not necessarily a
>> CompletableFuture, i.e. without the complete* methods. In other words,
>> the interface should return something that completes on its own and
>> thus doesn't need the complete* methods. I don't want the client of
>> the interface to be able to call the complete* methods.
>>
>> I can accomplish this with
>>
>> interface Foo<T> {
>>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U> f);
>> }
>>
>> which is slightly more verbose than (imaginary)
>>
>> interface Foo<T> {
>>     <U> CompletionFuture<U> foo(Function<T, U> f);
>> }
>>
>> where CompletionFuture is defined as suggested before:
>>
>> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>
>
> May I ask why it needs to implement Future?
>
>>
>>
>> Regards,
>> Tomas
>>
>> >
>> >>
>> >> I imagine a hierarchy like this:
>> >>
>> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>> >>
>> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
>> >>
>> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
>> >>      public CompletionFutureTask(Callable<T> callable) {...}
>> >>      // or
>> >>      protected abstract T compute();
>> >> }
>> >>
>> >>
>> >> Is there a reason why this is missing? Is there a plan to add this?
>> >>
>> >> Thanks,
>> >> Tomas
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >>
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> ?
>
> ???????
> Viktor Klang
> Chief Architect - Typesafe
>
> Twitter: @viktorklang


From zhong.j.yu at gmail.com  Tue Feb 11 17:14:51 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Tue, 11 Feb 2014 16:14:51 -0600
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
Message-ID: <CACuKZqGQpNYKgSHBvn0_s_6d71Sq_HZfp9WefVub810NZHRu8w@mail.gmail.com>

On Tue, Feb 11, 2014 at 3:53 PM, Tomas Mikula <tomas.mikula at gmail.com> wrote:
> That's a good question and, as a matter of fact, I'm not even calling
> any Future methods on the result. I think it's just because of my
> current setting where I have other means of synchronization than
> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
> this:
>
> res.thenAccept(r -> {
>     Platform.runLater(() -> handle(r));
> });

A probably better pattern:

    res.thenAcceptAsync( this::handle, fxExecutor );

    static final Executor fxExecutor = Platform::runLater;

>
> I thought in other settings you would need to eventually call
> Future.get() to synchronize with the main thread of computation.
>
> Are you suggesting that
> a) I should probably never need to call Future.get(); or
> b) there's always CompletionStage.toCompletableFuture() (which I only
> discovered now, so yes, I probably don't need Future)?
>
> Regards,
> Tomas
>
> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>>
>>
>>
>> On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
>> wrote:
>>>
>>> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
>>> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>>> >>
>>> >> Hi,
>>> >>
>>> >> I really like the addition of the CompletionStage interface in 1.8.
>>> >> However, there is just one implementation of it and that is
>>> >> CompletableFuture. I am missing a task counterpart of it, i.e.
>>> >> something that is both a Future and a CompletionStage, but is
>>> >> completed by a computation (i.e. takes a Callable constructor argument
>>> >> or has a protected abstract compute() method).
>>> >
>>> >
>>> > There are instead (four) static methods that accept functions and return
>>> > a CompletableFuture that is complete after they run. For example
>>> > supplyAsync is pasted below. Do you have usages in mind where
>>> > you'd need something different?
>>> >
>>> >
>>> >     /**
>>> >      * Returns a new CompletableFuture that is asynchronously completed
>>> >      * by a task running in the given executor with the value obtained
>>> >      * by calling the given Supplier.
>>> >      *
>>> >      * @param supplier a function returning the value to be used
>>> >      * to complete the returned CompletableFuture
>>> >      * @param executor the executor to use for asynchronous execution
>>> >      * @param <U> the function's return type
>>> >      * @return the new CompletableFuture
>>> >      */
>>> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
>>> > supplier,
>>> >                                                        Executor
>>> > executor)
>>> >
>>>
>>> Thanks, Doug,
>>>
>>> turns out my research was too shallow. This is all I need to get the job
>>> done.
>>>
>>> There's just one minor wrinkle that I can live with. I am designing an
>>> asynchronous interface whose method should return something that is
>>> both a Future and a CompletionStage, but not necessarily a
>>> CompletableFuture, i.e. without the complete* methods. In other words,
>>> the interface should return something that completes on its own and
>>> thus doesn't need the complete* methods. I don't want the client of
>>> the interface to be able to call the complete* methods.
>>>
>>> I can accomplish this with
>>>
>>> interface Foo<T> {
>>>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U> f);
>>> }
>>>
>>> which is slightly more verbose than (imaginary)
>>>
>>> interface Foo<T> {
>>>     <U> CompletionFuture<U> foo(Function<T, U> f);
>>> }
>>>
>>> where CompletionFuture is defined as suggested before:
>>>
>>> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>>
>>
>> May I ask why it needs to implement Future?
>>
>>>
>>>
>>> Regards,
>>> Tomas
>>>
>>> >
>>> >>
>>> >> I imagine a hierarchy like this:
>>> >>
>>> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>>> >>
>>> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
>>> >>
>>> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
>>> >>      public CompletionFutureTask(Callable<T> callable) {...}
>>> >>      // or
>>> >>      protected abstract T compute();
>>> >> }
>>> >>
>>> >>
>>> >> Is there a reason why this is missing? Is there a plan to add this?
>>> >>
>>> >> Thanks,
>>> >> Tomas
>>> >> _______________________________________________
>>> >> Concurrency-interest mailing list
>>> >> Concurrency-interest at cs.oswego.edu
>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> >>
>>> >
>>> > _______________________________________________
>>> > Concurrency-interest mailing list
>>> > Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>> --
>> Cheers,
>> ?
>>
>> ???????
>> Viktor Klang
>> Chief Architect - Typesafe
>>
>> Twitter: @viktorklang
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Tue Feb 11 17:22:44 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Tue, 11 Feb 2014 23:22:44 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
Message-ID: <CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>

On Tue, Feb 11, 2014 at 10:53 PM, Tomas Mikula <tomas.mikula at gmail.com>wrote:

> That's a good question and, as a matter of fact, I'm not even calling
> any Future methods on the result. I think it's just because of my
> current setting where I have other means of synchronization than
> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
> this:
>
> res.thenAccept(r -> {
>     Platform.runLater(() -> handle(r));
> });
>
> I thought in other settings you would need to eventually call
> Future.get() to synchronize with the main thread of computation.
>

If you need to "synchronize with main thread" then you can always attach a
CountDownLatch(1) as an on-complete callback and do countDown() there, and
then do a timed wait on the CTD on the main thread.

No need for Future.


>
> Are you suggesting that
> a) I should probably never need to call Future.get(); or
> b) there's always CompletionStage.toCompletableFuture() (which I only
> discovered now, so yes, I probably don't need Future)?
>
> Regards,
> Tomas
>
> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> >
> >
> >
> > On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
> > wrote:
> >>
> >> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> >> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
> >> >>
> >> >> Hi,
> >> >>
> >> >> I really like the addition of the CompletionStage interface in 1.8.
> >> >> However, there is just one implementation of it and that is
> >> >> CompletableFuture. I am missing a task counterpart of it, i.e.
> >> >> something that is both a Future and a CompletionStage, but is
> >> >> completed by a computation (i.e. takes a Callable constructor
> argument
> >> >> or has a protected abstract compute() method).
> >> >
> >> >
> >> > There are instead (four) static methods that accept functions and
> return
> >> > a CompletableFuture that is complete after they run. For example
> >> > supplyAsync is pasted below. Do you have usages in mind where
> >> > you'd need something different?
> >> >
> >> >
> >> >     /**
> >> >      * Returns a new CompletableFuture that is asynchronously
> completed
> >> >      * by a task running in the given executor with the value obtained
> >> >      * by calling the given Supplier.
> >> >      *
> >> >      * @param supplier a function returning the value to be used
> >> >      * to complete the returned CompletableFuture
> >> >      * @param executor the executor to use for asynchronous execution
> >> >      * @param <U> the function's return type
> >> >      * @return the new CompletableFuture
> >> >      */
> >> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
> >> > supplier,
> >> >                                                        Executor
> >> > executor)
> >> >
> >>
> >> Thanks, Doug,
> >>
> >> turns out my research was too shallow. This is all I need to get the job
> >> done.
> >>
> >> There's just one minor wrinkle that I can live with. I am designing an
> >> asynchronous interface whose method should return something that is
> >> both a Future and a CompletionStage, but not necessarily a
> >> CompletableFuture, i.e. without the complete* methods. In other words,
> >> the interface should return something that completes on its own and
> >> thus doesn't need the complete* methods. I don't want the client of
> >> the interface to be able to call the complete* methods.
> >>
> >> I can accomplish this with
> >>
> >> interface Foo<T> {
> >>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U>
> f);
> >> }
> >>
> >> which is slightly more verbose than (imaginary)
> >>
> >> interface Foo<T> {
> >>     <U> CompletionFuture<U> foo(Function<T, U> f);
> >> }
> >>
> >> where CompletionFuture is defined as suggested before:
> >>
> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
> >
> >
> > May I ask why it needs to implement Future?
> >
> >>
> >>
> >> Regards,
> >> Tomas
> >>
> >> >
> >> >>
> >> >> I imagine a hierarchy like this:
> >> >>
> >> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T>
> {}
> >> >>
> >> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
> >> >>
> >> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
> >> >>      public CompletionFutureTask(Callable<T> callable) {...}
> >> >>      // or
> >> >>      protected abstract T compute();
> >> >> }
> >> >>
> >> >>
> >> >> Is there a reason why this is missing? Is there a plan to add this?
> >> >>
> >> >> Thanks,
> >> >> Tomas
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >>
> >> >
> >> > _______________________________________________
> >> > Concurrency-interest mailing list
> >> > Concurrency-interest at cs.oswego.edu
> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> > --
> > Cheers,
> > ?
> >
> > ???????
> > Viktor Klang
> > Chief Architect - Typesafe
> >
> > Twitter: @viktorklang
>



-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140211/e877c616/attachment.html>

From tomas.mikula at gmail.com  Tue Feb 11 17:50:05 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Tue, 11 Feb 2014 23:50:05 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CACuKZqGQpNYKgSHBvn0_s_6d71Sq_HZfp9WefVub810NZHRu8w@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
	<CACuKZqGQpNYKgSHBvn0_s_6d71Sq_HZfp9WefVub810NZHRu8w@mail.gmail.com>
Message-ID: <CA+THrur-K1ruTT=N+PArJD_-UWFrZiqkSO5s+qwjhS_eVFkY4A@mail.gmail.com>

On Tue, Feb 11, 2014 at 11:14 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:
> On Tue, Feb 11, 2014 at 3:53 PM, Tomas Mikula <tomas.mikula at gmail.com> wrote:
>> That's a good question and, as a matter of fact, I'm not even calling
>> any Future methods on the result. I think it's just because of my
>> current setting where I have other means of synchronization than
>> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
>> this:
>>
>> res.thenAccept(r -> {
>>     Platform.runLater(() -> handle(r));
>> });
>
> A probably better pattern:
>
>     res.thenAcceptAsync( this::handle, fxExecutor );
>
>     static final Executor fxExecutor = Platform::runLater;

Thanks!

I was thinking of writing such an fxExecutor and didn't realize that
Executor was a SAM interface, so it's this easy!

Tomas

>
>>
>> I thought in other settings you would need to eventually call
>> Future.get() to synchronize with the main thread of computation.
>>
>> Are you suggesting that
>> a) I should probably never need to call Future.get(); or
>> b) there's always CompletionStage.toCompletableFuture() (which I only
>> discovered now, so yes, I probably don't need Future)?
>>
>> Regards,
>> Tomas
>>
>> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>>>
>>>
>>>
>>> On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
>>> wrote:
>>>>
>>>> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>>>> >>
>>>> >> Hi,
>>>> >>
>>>> >> I really like the addition of the CompletionStage interface in 1.8.
>>>> >> However, there is just one implementation of it and that is
>>>> >> CompletableFuture. I am missing a task counterpart of it, i.e.
>>>> >> something that is both a Future and a CompletionStage, but is
>>>> >> completed by a computation (i.e. takes a Callable constructor argument
>>>> >> or has a protected abstract compute() method).
>>>> >
>>>> >
>>>> > There are instead (four) static methods that accept functions and return
>>>> > a CompletableFuture that is complete after they run. For example
>>>> > supplyAsync is pasted below. Do you have usages in mind where
>>>> > you'd need something different?
>>>> >
>>>> >
>>>> >     /**
>>>> >      * Returns a new CompletableFuture that is asynchronously completed
>>>> >      * by a task running in the given executor with the value obtained
>>>> >      * by calling the given Supplier.
>>>> >      *
>>>> >      * @param supplier a function returning the value to be used
>>>> >      * to complete the returned CompletableFuture
>>>> >      * @param executor the executor to use for asynchronous execution
>>>> >      * @param <U> the function's return type
>>>> >      * @return the new CompletableFuture
>>>> >      */
>>>> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
>>>> > supplier,
>>>> >                                                        Executor
>>>> > executor)
>>>> >
>>>>
>>>> Thanks, Doug,
>>>>
>>>> turns out my research was too shallow. This is all I need to get the job
>>>> done.
>>>>
>>>> There's just one minor wrinkle that I can live with. I am designing an
>>>> asynchronous interface whose method should return something that is
>>>> both a Future and a CompletionStage, but not necessarily a
>>>> CompletableFuture, i.e. without the complete* methods. In other words,
>>>> the interface should return something that completes on its own and
>>>> thus doesn't need the complete* methods. I don't want the client of
>>>> the interface to be able to call the complete* methods.
>>>>
>>>> I can accomplish this with
>>>>
>>>> interface Foo<T> {
>>>>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U> f);
>>>> }
>>>>
>>>> which is slightly more verbose than (imaginary)
>>>>
>>>> interface Foo<T> {
>>>>     <U> CompletionFuture<U> foo(Function<T, U> f);
>>>> }
>>>>
>>>> where CompletionFuture is defined as suggested before:
>>>>
>>>> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>>>
>>>
>>> May I ask why it needs to implement Future?
>>>
>>>>
>>>>
>>>> Regards,
>>>> Tomas
>>>>
>>>> >
>>>> >>
>>>> >> I imagine a hierarchy like this:
>>>> >>
>>>> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>>>> >>
>>>> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
>>>> >>
>>>> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
>>>> >>      public CompletionFutureTask(Callable<T> callable) {...}
>>>> >>      // or
>>>> >>      protected abstract T compute();
>>>> >> }
>>>> >>
>>>> >>
>>>> >> Is there a reason why this is missing? Is there a plan to add this?
>>>> >>
>>>> >> Thanks,
>>>> >> Tomas
>>>> >> _______________________________________________
>>>> >> Concurrency-interest mailing list
>>>> >> Concurrency-interest at cs.oswego.edu
>>>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> >>
>>>> >
>>>> > _______________________________________________
>>>> > Concurrency-interest mailing list
>>>> > Concurrency-interest at cs.oswego.edu
>>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>> --
>>> Cheers,
>>> ?
>>>
>>> ???????
>>> Viktor Klang
>>> Chief Architect - Typesafe
>>>
>>> Twitter: @viktorklang
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From tomas.mikula at gmail.com  Tue Feb 11 17:54:23 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Tue, 11 Feb 2014 23:54:23 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
	<CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>
Message-ID: <CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>

On Tue, Feb 11, 2014 at 11:22 PM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>
>
>
> On Tue, Feb 11, 2014 at 10:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
> wrote:
>>
>> That's a good question and, as a matter of fact, I'm not even calling
>> any Future methods on the result. I think it's just because of my
>> current setting where I have other means of synchronization than
>> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
>> this:
>>
>> res.thenAccept(r -> {
>>     Platform.runLater(() -> handle(r));
>> });
>>
>> I thought in other settings you would need to eventually call
>> Future.get() to synchronize with the main thread of computation.
>
>
> If you need to "synchronize with main thread" then you can always attach a
> CountDownLatch(1) as an on-complete callback and do countDown() there, and
> then do a timed wait on the CTD on the main thread.
>
> No need for Future.

Thanks.

It seems to me that with CountDownLatch there would be an extra work
to get the result of the asynchronous computation back to the main
thread.

Is Future.get() considered a bad practice?

Tomas

>
>>
>>
>> Are you suggesting that
>> a) I should probably never need to call Future.get(); or
>> b) there's always CompletionStage.toCompletableFuture() (which I only
>> discovered now, so yes, I probably don't need Future)?
>>
>> Regards,
>> Tomas
>>
>> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>> >
>> >
>> >
>> > On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
>> > wrote:
>> >>
>> >> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
>> >> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>> >> >>
>> >> >> Hi,
>> >> >>
>> >> >> I really like the addition of the CompletionStage interface in 1.8.
>> >> >> However, there is just one implementation of it and that is
>> >> >> CompletableFuture. I am missing a task counterpart of it, i.e.
>> >> >> something that is both a Future and a CompletionStage, but is
>> >> >> completed by a computation (i.e. takes a Callable constructor
>> >> >> argument
>> >> >> or has a protected abstract compute() method).
>> >> >
>> >> >
>> >> > There are instead (four) static methods that accept functions and
>> >> > return
>> >> > a CompletableFuture that is complete after they run. For example
>> >> > supplyAsync is pasted below. Do you have usages in mind where
>> >> > you'd need something different?
>> >> >
>> >> >
>> >> >     /**
>> >> >      * Returns a new CompletableFuture that is asynchronously
>> >> > completed
>> >> >      * by a task running in the given executor with the value
>> >> > obtained
>> >> >      * by calling the given Supplier.
>> >> >      *
>> >> >      * @param supplier a function returning the value to be used
>> >> >      * to complete the returned CompletableFuture
>> >> >      * @param executor the executor to use for asynchronous execution
>> >> >      * @param <U> the function's return type
>> >> >      * @return the new CompletableFuture
>> >> >      */
>> >> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
>> >> > supplier,
>> >> >                                                        Executor
>> >> > executor)
>> >> >
>> >>
>> >> Thanks, Doug,
>> >>
>> >> turns out my research was too shallow. This is all I need to get the
>> >> job
>> >> done.
>> >>
>> >> There's just one minor wrinkle that I can live with. I am designing an
>> >> asynchronous interface whose method should return something that is
>> >> both a Future and a CompletionStage, but not necessarily a
>> >> CompletableFuture, i.e. without the complete* methods. In other words,
>> >> the interface should return something that completes on its own and
>> >> thus doesn't need the complete* methods. I don't want the client of
>> >> the interface to be able to call the complete* methods.
>> >>
>> >> I can accomplish this with
>> >>
>> >> interface Foo<T> {
>> >>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T, U>
>> >> f);
>> >> }
>> >>
>> >> which is slightly more verbose than (imaginary)
>> >>
>> >> interface Foo<T> {
>> >>     <U> CompletionFuture<U> foo(Function<T, U> f);
>> >> }
>> >>
>> >> where CompletionFuture is defined as suggested before:
>> >>
>> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T> {}
>> >
>> >
>> > May I ask why it needs to implement Future?
>> >
>> >>
>> >>
>> >> Regards,
>> >> Tomas
>> >>
>> >> >
>> >> >>
>> >> >> I imagine a hierarchy like this:
>> >> >>
>> >> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T>
>> >> >> {}
>> >> >>
>> >> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
>> >> >>
>> >> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
>> >> >>      public CompletionFutureTask(Callable<T> callable) {...}
>> >> >>      // or
>> >> >>      protected abstract T compute();
>> >> >> }
>> >> >>
>> >> >>
>> >> >> Is there a reason why this is missing? Is there a plan to add this?
>> >> >>
>> >> >> Thanks,
>> >> >> Tomas
>> >> >> _______________________________________________
>> >> >> Concurrency-interest mailing list
>> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >>
>> >> >
>> >> > _______________________________________________
>> >> > Concurrency-interest mailing list
>> >> > Concurrency-interest at cs.oswego.edu
>> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> _______________________________________________
>> >> Concurrency-interest mailing list
>> >> Concurrency-interest at cs.oswego.edu
>> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >
>> >
>> >
>> >
>> > --
>> > Cheers,
>> > ?
>> >
>> > ???????
>> > Viktor Klang
>> > Chief Architect - Typesafe
>> >
>> > Twitter: @viktorklang
>
>
>
>
> --
> Cheers,
> ?
>
> ???????
> Viktor Klang
> Chief Architect - Typesafe
>
> Twitter: @viktorklang


From viktor.klang at gmail.com  Tue Feb 11 18:11:35 2014
From: viktor.klang at gmail.com (=?UTF-8?B?4oiaaWt0b3Ig0qBsYW5n?=)
Date: Wed, 12 Feb 2014 00:11:35 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
	<CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>
	<CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>
Message-ID: <CANPzfU94zxzFngwsCNthXYazqZUnVA=XJqB+C9xXOVue7=9fGA@mail.gmail.com>

On Tue, Feb 11, 2014 at 11:54 PM, Tomas Mikula <tomas.mikula at gmail.com>wrote:

> On Tue, Feb 11, 2014 at 11:22 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> >
> >
> >
> > On Tue, Feb 11, 2014 at 10:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
> > wrote:
> >>
> >> That's a good question and, as a matter of fact, I'm not even calling
> >> any Future methods on the result. I think it's just because of my
> >> current setting where I have other means of synchronization than
> >> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
> >> this:
> >>
> >> res.thenAccept(r -> {
> >>     Platform.runLater(() -> handle(r));
> >> });
> >>
> >> I thought in other settings you would need to eventually call
> >> Future.get() to synchronize with the main thread of computation.
> >
> >
> > If you need to "synchronize with main thread" then you can always attach
> a
> > CountDownLatch(1) as an on-complete callback and do countDown() there,
> and
> > then do a timed wait on the CTD on the main thread.
> >
> > No need for Future.
>
> Thanks.
>
> It seems to me that with CountDownLatch there would be an extra work
> to get the result of the asynchronous computation back to the main
> thread.
>

You said you wanted to synchronize with the main thread; not that you
needed to return the result of the computation to it?hence my suggestion.
Sorry for the noise.


>
> Is Future.get() considered a bad practice?
>

In my limited experience, blocking is usually the wrong solution to the
problem, however, if you must _block_ the execution of the main thread and
get the result of the Future out there and all you have is a
CompletionStage I'd recommend stage.toCompletableFuture().get()



>
> Tomas
>
> >
> >>
> >>
> >> Are you suggesting that
> >> a) I should probably never need to call Future.get(); or
> >> b) there's always CompletionStage.toCompletableFuture() (which I only
> >> discovered now, so yes, I probably don't need Future)?
> >>
> >> Regards,
> >> Tomas
> >>
> >> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >> >
> >> >
> >> >
> >> > On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> >> >> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
> >> >> >>
> >> >> >> Hi,
> >> >> >>
> >> >> >> I really like the addition of the CompletionStage interface in
> 1.8.
> >> >> >> However, there is just one implementation of it and that is
> >> >> >> CompletableFuture. I am missing a task counterpart of it, i.e.
> >> >> >> something that is both a Future and a CompletionStage, but is
> >> >> >> completed by a computation (i.e. takes a Callable constructor
> >> >> >> argument
> >> >> >> or has a protected abstract compute() method).
> >> >> >
> >> >> >
> >> >> > There are instead (four) static methods that accept functions and
> >> >> > return
> >> >> > a CompletableFuture that is complete after they run. For example
> >> >> > supplyAsync is pasted below. Do you have usages in mind where
> >> >> > you'd need something different?
> >> >> >
> >> >> >
> >> >> >     /**
> >> >> >      * Returns a new CompletableFuture that is asynchronously
> >> >> > completed
> >> >> >      * by a task running in the given executor with the value
> >> >> > obtained
> >> >> >      * by calling the given Supplier.
> >> >> >      *
> >> >> >      * @param supplier a function returning the value to be used
> >> >> >      * to complete the returned CompletableFuture
> >> >> >      * @param executor the executor to use for asynchronous
> execution
> >> >> >      * @param <U> the function's return type
> >> >> >      * @return the new CompletableFuture
> >> >> >      */
> >> >> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
> >> >> > supplier,
> >> >> >                                                        Executor
> >> >> > executor)
> >> >> >
> >> >>
> >> >> Thanks, Doug,
> >> >>
> >> >> turns out my research was too shallow. This is all I need to get the
> >> >> job
> >> >> done.
> >> >>
> >> >> There's just one minor wrinkle that I can live with. I am designing
> an
> >> >> asynchronous interface whose method should return something that is
> >> >> both a Future and a CompletionStage, but not necessarily a
> >> >> CompletableFuture, i.e. without the complete* methods. In other
> words,
> >> >> the interface should return something that completes on its own and
> >> >> thus doesn't need the complete* methods. I don't want the client of
> >> >> the interface to be able to call the complete* methods.
> >> >>
> >> >> I can accomplish this with
> >> >>
> >> >> interface Foo<T> {
> >> >>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T,
> U>
> >> >> f);
> >> >> }
> >> >>
> >> >> which is slightly more verbose than (imaginary)
> >> >>
> >> >> interface Foo<T> {
> >> >>     <U> CompletionFuture<U> foo(Function<T, U> f);
> >> >> }
> >> >>
> >> >> where CompletionFuture is defined as suggested before:
> >> >>
> >> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T>
> {}
> >> >
> >> >
> >> > May I ask why it needs to implement Future?
> >> >
> >> >>
> >> >>
> >> >> Regards,
> >> >> Tomas
> >> >>
> >> >> >
> >> >> >>
> >> >> >> I imagine a hierarchy like this:
> >> >> >>
> >> >> >> interface CompletionFuture<T> extends Future<T>,
> CompletionStage<T>
> >> >> >> {}
> >> >> >>
> >> >> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
> >> >> >>
> >> >> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
> >> >> >>      public CompletionFutureTask(Callable<T> callable) {...}
> >> >> >>      // or
> >> >> >>      protected abstract T compute();
> >> >> >> }
> >> >> >>
> >> >> >>
> >> >> >> Is there a reason why this is missing? Is there a plan to add
> this?
> >> >> >>
> >> >> >> Thanks,
> >> >> >> Tomas
> >> >> >> _______________________________________________
> >> >> >> Concurrency-interest mailing list
> >> >> >> Concurrency-interest at cs.oswego.edu
> >> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> >>
> >> >> >
> >> >> > _______________________________________________
> >> >> > Concurrency-interest mailing list
> >> >> > Concurrency-interest at cs.oswego.edu
> >> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Cheers,
> >> > ?
> >> >
> >> > ???????
> >> > Viktor Klang
> >> > Chief Architect - Typesafe
> >> >
> >> > Twitter: @viktorklang
> >
> >
> >
> >
> > --
> > Cheers,
> > ?
> >
> > ???????
> > Viktor Klang
> > Chief Architect - Typesafe
> >
> > Twitter: @viktorklang
>



-- 
Cheers,
?

*???????**Viktor Klang*
*Chief Architect - **Typesafe <http://www.typesafe.com/>*

Twitter: @viktorklang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140212/a43d9842/attachment-0001.html>

From tomas.mikula at gmail.com  Tue Feb 11 18:32:02 2014
From: tomas.mikula at gmail.com (Tomas Mikula)
Date: Wed, 12 Feb 2014 00:32:02 +0100
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CANPzfU94zxzFngwsCNthXYazqZUnVA=XJqB+C9xXOVue7=9fGA@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
	<CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>
	<CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>
	<CANPzfU94zxzFngwsCNthXYazqZUnVA=XJqB+C9xXOVue7=9fGA@mail.gmail.com>
Message-ID: <CA+THrup1A3K3_mu=N8TkFgF4d--VTjsjM-Zd+X3z8NYouvss_g@mail.gmail.com>

On Wed, Feb 12, 2014 at 12:11 AM, ?iktor ?lang <viktor.klang at gmail.com> wrote:
>
>
>
> On Tue, Feb 11, 2014 at 11:54 PM, Tomas Mikula <tomas.mikula at gmail.com>
> wrote:
>>
>> On Tue, Feb 11, 2014 at 11:22 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> wrote:
>> >
>> >
>> >
>> > On Tue, Feb 11, 2014 at 10:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
>> > wrote:
>> >>
>> >> That's a good question and, as a matter of fact, I'm not even calling
>> >> any Future methods on the result. I think it's just because of my
>> >> current setting where I have other means of synchronization than
>> >> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
>> >> this:
>> >>
>> >> res.thenAccept(r -> {
>> >>     Platform.runLater(() -> handle(r));
>> >> });
>> >>
>> >> I thought in other settings you would need to eventually call
>> >> Future.get() to synchronize with the main thread of computation.
>> >
>> >
>> > If you need to "synchronize with main thread" then you can always attach
>> > a
>> > CountDownLatch(1) as an on-complete callback and do countDown() there,
>> > and
>> > then do a timed wait on the CTD on the main thread.
>> >
>> > No need for Future.
>>
>> Thanks.
>>
>> It seems to me that with CountDownLatch there would be an extra work
>> to get the result of the asynchronous computation back to the main
>> thread.
>
>
> You said you wanted to synchronize with the main thread; not that you needed
> to return the result of the computation to it?hence my suggestion.
> Sorry for the noise.
>
>>
>>
>> Is Future.get() considered a bad practice?
>
>
> In my limited experience, blocking is usually the wrong solution to the
> problem, however, if you must _block_ the execution of the main thread and
> get the result of the Future out there and all you have is a CompletionStage
> I'd recommend stage.toCompletableFuture().get()

Thank you again. Right now I'm delivering the result to the JavaFX
application thread through Platform.runLater(), so there is no
blocking.
If I was writing a command line utility that uses my asynchronous
interface, I can imagine I would write the result to a file from
thenAccept(), so I would be able to avoid blocking, too.

>
>
>>
>>
>> Tomas
>>
>> >
>> >>
>> >>
>> >> Are you suggesting that
>> >> a) I should probably never need to call Future.get(); or
>> >> b) there's always CompletionStage.toCompletableFuture() (which I only
>> >> discovered now, so yes, I probably don't need Future)?
>> >>
>> >> Regards,
>> >> Tomas
>> >>
>> >> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com>
>> >> wrote:
>> >> >
>> >> >
>> >> >
>> >> > On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula
>> >> > <tomas.mikula at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
>> >> >> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
>> >> >> >>
>> >> >> >> Hi,
>> >> >> >>
>> >> >> >> I really like the addition of the CompletionStage interface in
>> >> >> >> 1.8.
>> >> >> >> However, there is just one implementation of it and that is
>> >> >> >> CompletableFuture. I am missing a task counterpart of it, i.e.
>> >> >> >> something that is both a Future and a CompletionStage, but is
>> >> >> >> completed by a computation (i.e. takes a Callable constructor
>> >> >> >> argument
>> >> >> >> or has a protected abstract compute() method).
>> >> >> >
>> >> >> >
>> >> >> > There are instead (four) static methods that accept functions and
>> >> >> > return
>> >> >> > a CompletableFuture that is complete after they run. For example
>> >> >> > supplyAsync is pasted below. Do you have usages in mind where
>> >> >> > you'd need something different?
>> >> >> >
>> >> >> >
>> >> >> >     /**
>> >> >> >      * Returns a new CompletableFuture that is asynchronously
>> >> >> > completed
>> >> >> >      * by a task running in the given executor with the value
>> >> >> > obtained
>> >> >> >      * by calling the given Supplier.
>> >> >> >      *
>> >> >> >      * @param supplier a function returning the value to be used
>> >> >> >      * to complete the returned CompletableFuture
>> >> >> >      * @param executor the executor to use for asynchronous
>> >> >> > execution
>> >> >> >      * @param <U> the function's return type
>> >> >> >      * @return the new CompletableFuture
>> >> >> >      */
>> >> >> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
>> >> >> > supplier,
>> >> >> >                                                        Executor
>> >> >> > executor)
>> >> >> >
>> >> >>
>> >> >> Thanks, Doug,
>> >> >>
>> >> >> turns out my research was too shallow. This is all I need to get the
>> >> >> job
>> >> >> done.
>> >> >>
>> >> >> There's just one minor wrinkle that I can live with. I am designing
>> >> >> an
>> >> >> asynchronous interface whose method should return something that is
>> >> >> both a Future and a CompletionStage, but not necessarily a
>> >> >> CompletableFuture, i.e. without the complete* methods. In other
>> >> >> words,
>> >> >> the interface should return something that completes on its own and
>> >> >> thus doesn't need the complete* methods. I don't want the client of
>> >> >> the interface to be able to call the complete* methods.
>> >> >>
>> >> >> I can accomplish this with
>> >> >>
>> >> >> interface Foo<T> {
>> >> >>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T,
>> >> >> U>
>> >> >> f);
>> >> >> }
>> >> >>
>> >> >> which is slightly more verbose than (imaginary)
>> >> >>
>> >> >> interface Foo<T> {
>> >> >>     <U> CompletionFuture<U> foo(Function<T, U> f);
>> >> >> }
>> >> >>
>> >> >> where CompletionFuture is defined as suggested before:
>> >> >>
>> >> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T>
>> >> >> {}
>> >> >
>> >> >
>> >> > May I ask why it needs to implement Future?
>> >> >
>> >> >>
>> >> >>
>> >> >> Regards,
>> >> >> Tomas
>> >> >>
>> >> >> >
>> >> >> >>
>> >> >> >> I imagine a hierarchy like this:
>> >> >> >>
>> >> >> >> interface CompletionFuture<T> extends Future<T>,
>> >> >> >> CompletionStage<T>
>> >> >> >> {}
>> >> >> >>
>> >> >> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
>> >> >> >>
>> >> >> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
>> >> >> >>      public CompletionFutureTask(Callable<T> callable) {...}
>> >> >> >>      // or
>> >> >> >>      protected abstract T compute();
>> >> >> >> }
>> >> >> >>
>> >> >> >>
>> >> >> >> Is there a reason why this is missing? Is there a plan to add
>> >> >> >> this?
>> >> >> >>
>> >> >> >> Thanks,
>> >> >> >> Tomas
>> >> >> >> _______________________________________________
>> >> >> >> Concurrency-interest mailing list
>> >> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >> >>
>> >> >> >
>> >> >> > _______________________________________________
>> >> >> > Concurrency-interest mailing list
>> >> >> > Concurrency-interest at cs.oswego.edu
>> >> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >> _______________________________________________
>> >> >> Concurrency-interest mailing list
>> >> >> Concurrency-interest at cs.oswego.edu
>> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > Cheers,
>> >> > ?
>> >> >
>> >> > ???????
>> >> > Viktor Klang
>> >> > Chief Architect - Typesafe
>> >> >
>> >> > Twitter: @viktorklang
>> >
>> >
>> >
>> >
>> > --
>> > Cheers,
>> > ?
>> >
>> > ???????
>> > Viktor Klang
>> > Chief Architect - Typesafe
>> >
>> > Twitter: @viktorklang
>
>
>
>
> --
> Cheers,
> ?
>
> ???????
> Viktor Klang
> Chief Architect - Typesafe
>
> Twitter: @viktorklang


From ron.pressler at gmail.com  Tue Feb 11 18:51:42 2014
From: ron.pressler at gmail.com (Ron Pressler)
Date: Wed, 12 Feb 2014 01:51:42 +0200
Subject: [concurrency-interest] Implementing,
 Abstracting and Benchmarking Lightweight Threads on the JVM
In-Reply-To: <19608222.I8hhFaJCUa@artemis>
References: <CABg6-qj8nNHXM9Kby1oBR-pBiOKuDhsTmuRhoLokO5_eBw5zjg@mail.gmail.com>
	<19608222.I8hhFaJCUa@artemis>
Message-ID: <etPan.52fab791.721da317.bd@Rons-MacBook-Pro.local>

Sure. Take a look at?Comsat, which currently provides fiber-aware implementations of servlets, JAX-RS (server and client) and JDBC.
Also, the previously linked blog post explains how to transform any asynchronous operation into a fiber-blocking one.


On February 10, 2014 at 4:57:40 PM, Jan Kotek (discus at kotek.net) wrote:

Hi,  

I experimented with Kilim micro-threads a few years ago.  

Is there a plan to provide full stack based on lightweight threads? I mean  
webserver, IO utils and database where all IO operations would use lightweight  
non-blocking operations.  

I think I could modify MapDB for this stack. I already have some non-blocking  
prototype based on AsynchronousFileChannel  

All best,  
Jan Kotek  

On Thursday, February 06, 2014 19:08:55 Ron Pressler wrote:  
> Hi.  
> I've just published a blog post called Implementing, Abstracting and  
> Benchmarking Lightweight Threads on the  
> JVM<http://blog.paralleluniverse.co/2014/02/06/fibers-threads-strands/>,  
> which describes Quasar <https://github.com/puniverse/quasar>'s  
> implementation of lightweight threads.  
>  
> In particular, it explains how we've adapted some of java.util.concurrent's  
> classes to work for both (plain) threads and fibers (Quasar lightweight  
> threads), by combining both into an abstraction called  
> strands<http://docs.paralleluniverse.co/quasar/javadoc/co/paralleluniverse/s  
> trands/Strand.html> .  
>  
> I thought some people here might find it interesting.  
>  
> Ron  

_______________________________________________  
Concurrency-interest mailing list  
Concurrency-interest at cs.oswego.edu  
http://cs.oswego.edu/mailman/listinfo/concurrency-interest  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140212/70c91d65/attachment.html>

From joe.bowbeer at gmail.com  Tue Feb 11 21:22:56 2014
From: joe.bowbeer at gmail.com (Joe Bowbeer)
Date: Tue, 11 Feb 2014 18:22:56 -0800
Subject: [concurrency-interest] No *Task counterpart of
	CompletableFuture?
In-Reply-To: <CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>
References: <CA+THrup5TP0PDJOGd1woDQEBqUwPLS1gQmY052F8aGLJudMz3A@mail.gmail.com>
	<52FA7E18.1020003@cs.oswego.edu>
	<CA+THruoZr-5fjJoxhxAj6RXiVq=9fqKN6_R2=7t7Q_VQ6S12bA@mail.gmail.com>
	<CANPzfU-QrtRsgVO43LVHPOPR2FQ2wp7jY07yfsMGbWKy4w+=UA@mail.gmail.com>
	<CA+THrupkc7GzE9OeRn7-9_posDCqbdgveBWodONcc8CTi9W61w@mail.gmail.com>
	<CANPzfU9KCD_789MS930BwX526Hu4W8TGHF=aDx0pSntaa8TEMQ@mail.gmail.com>
	<CA+THruosEbftT9xVBGEGMvO=q7vZOKpJ=Hoei3iddV+-gZZS8w@mail.gmail.com>
Message-ID: <CAHzJPEqhtrBDGttAMPZ9Vxat7pYZrbqhvTwE4-VghCFMHFkejA@mail.gmail.com>

Regarding the Future interface, I think it and its implementation are great
building blocks for custom tasks, but if possible I like to expose a
narrower, more app-specific, less exception-laden API at the task level,
hiding the gnarliness of future.
On Feb 11, 2014 2:57 PM, "Tomas Mikula" <tomas.mikula at gmail.com> wrote:

> On Tue, Feb 11, 2014 at 11:22 PM, ?iktor ?lang <viktor.klang at gmail.com>
> wrote:
> >
> >
> >
> > On Tue, Feb 11, 2014 at 10:53 PM, Tomas Mikula <tomas.mikula at gmail.com>
> > wrote:
> >>
> >> That's a good question and, as a matter of fact, I'm not even calling
> >> any Future methods on the result. I think it's just because of my
> >> current setting where I have other means of synchronization than
> >> Future.get(), namely I'm using Platform.runLater() from JavaFX, like
> >> this:
> >>
> >> res.thenAccept(r -> {
> >>     Platform.runLater(() -> handle(r));
> >> });
> >>
> >> I thought in other settings you would need to eventually call
> >> Future.get() to synchronize with the main thread of computation.
> >
> >
> > If you need to "synchronize with main thread" then you can always attach
> a
> > CountDownLatch(1) as an on-complete callback and do countDown() there,
> and
> > then do a timed wait on the CTD on the main thread.
> >
> > No need for Future.
>
> Thanks.
>
> It seems to me that with CountDownLatch there would be an extra work
> to get the result of the asynchronous computation back to the main
> thread.
>
> Is Future.get() considered a bad practice?
>
> Tomas
>
> >
> >>
> >>
> >> Are you suggesting that
> >> a) I should probably never need to call Future.get(); or
> >> b) there's always CompletionStage.toCompletableFuture() (which I only
> >> discovered now, so yes, I probably don't need Future)?
> >>
> >> Regards,
> >> Tomas
> >>
> >> On Tue, Feb 11, 2014 at 10:20 PM, ?iktor ?lang <viktor.klang at gmail.com>
> >> wrote:
> >> >
> >> >
> >> >
> >> > On Tue, Feb 11, 2014 at 9:53 PM, Tomas Mikula <tomas.mikula at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> On Tue, Feb 11, 2014 at 8:46 PM, Doug Lea <dl at cs.oswego.edu> wrote:
> >> >> > On 02/10/2014 07:24 PM, Tomas Mikula wrote:
> >> >> >>
> >> >> >> Hi,
> >> >> >>
> >> >> >> I really like the addition of the CompletionStage interface in
> 1.8.
> >> >> >> However, there is just one implementation of it and that is
> >> >> >> CompletableFuture. I am missing a task counterpart of it, i.e.
> >> >> >> something that is both a Future and a CompletionStage, but is
> >> >> >> completed by a computation (i.e. takes a Callable constructor
> >> >> >> argument
> >> >> >> or has a protected abstract compute() method).
> >> >> >
> >> >> >
> >> >> > There are instead (four) static methods that accept functions and
> >> >> > return
> >> >> > a CompletableFuture that is complete after they run. For example
> >> >> > supplyAsync is pasted below. Do you have usages in mind where
> >> >> > you'd need something different?
> >> >> >
> >> >> >
> >> >> >     /**
> >> >> >      * Returns a new CompletableFuture that is asynchronously
> >> >> > completed
> >> >> >      * by a task running in the given executor with the value
> >> >> > obtained
> >> >> >      * by calling the given Supplier.
> >> >> >      *
> >> >> >      * @param supplier a function returning the value to be used
> >> >> >      * to complete the returned CompletableFuture
> >> >> >      * @param executor the executor to use for asynchronous
> execution
> >> >> >      * @param <U> the function's return type
> >> >> >      * @return the new CompletableFuture
> >> >> >      */
> >> >> >     public static <U> CompletableFuture<U> supplyAsync(Supplier<U>
> >> >> > supplier,
> >> >> >                                                        Executor
> >> >> > executor)
> >> >> >
> >> >>
> >> >> Thanks, Doug,
> >> >>
> >> >> turns out my research was too shallow. This is all I need to get the
> >> >> job
> >> >> done.
> >> >>
> >> >> There's just one minor wrinkle that I can live with. I am designing
> an
> >> >> asynchronous interface whose method should return something that is
> >> >> both a Future and a CompletionStage, but not necessarily a
> >> >> CompletableFuture, i.e. without the complete* methods. In other
> words,
> >> >> the interface should return something that completes on its own and
> >> >> thus doesn't need the complete* methods. I don't want the client of
> >> >> the interface to be able to call the complete* methods.
> >> >>
> >> >> I can accomplish this with
> >> >>
> >> >> interface Foo<T> {
> >> >>     <U, F extends CompletionStage<U> & Future<U>> F foo(Function<T,
> U>
> >> >> f);
> >> >> }
> >> >>
> >> >> which is slightly more verbose than (imaginary)
> >> >>
> >> >> interface Foo<T> {
> >> >>     <U> CompletionFuture<U> foo(Function<T, U> f);
> >> >> }
> >> >>
> >> >> where CompletionFuture is defined as suggested before:
> >> >>
> >> >> interface CompletionFuture<T> extends Future<T>, CompletionStage<T>
> {}
> >> >
> >> >
> >> > May I ask why it needs to implement Future?
> >> >
> >> >>
> >> >>
> >> >> Regards,
> >> >> Tomas
> >> >>
> >> >> >
> >> >> >>
> >> >> >> I imagine a hierarchy like this:
> >> >> >>
> >> >> >> interface CompletionFuture<T> extends Future<T>,
> CompletionStage<T>
> >> >> >> {}
> >> >> >>
> >> >> >> class CompletableFuture<T> implements CompletionFuture<T> {...}
> >> >> >>
> >> >> >> class CompletionFutureTask<T> implements CompletionFuture<T> {
> >> >> >>      public CompletionFutureTask(Callable<T> callable) {...}
> >> >> >>      // or
> >> >> >>      protected abstract T compute();
> >> >> >> }
> >> >> >>
> >> >> >>
> >> >> >> Is there a reason why this is missing? Is there a plan to add
> this?
> >> >> >>
> >> >> >> Thanks,
> >> >> >> Tomas
> >> >> >> _______________________________________________
> >> >> >> Concurrency-interest mailing list
> >> >> >> Concurrency-interest at cs.oswego.edu
> >> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> >>
> >> >> >
> >> >> > _______________________________________________
> >> >> > Concurrency-interest mailing list
> >> >> > Concurrency-interest at cs.oswego.edu
> >> >> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >> _______________________________________________
> >> >> Concurrency-interest mailing list
> >> >> Concurrency-interest at cs.oswego.edu
> >> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Cheers,
> >> > ?
> >> >
> >> > ???????
> >> > Viktor Klang
> >> > Chief Architect - Typesafe
> >> >
> >> > Twitter: @viktorklang
> >
> >
> >
> >
> > --
> > Cheers,
> > ?
> >
> > ???????
> > Viktor Klang
> > Chief Architect - Typesafe
> >
> > Twitter: @viktorklang
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140211/a1696ff6/attachment-0001.html>

From aph at redhat.com  Fri Feb 14 05:41:35 2014
From: aph at redhat.com (Andrew Haley)
Date: Fri, 14 Feb 2014 10:41:35 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
Message-ID: <52FDF2DF.1050403@redhat.com>

What are the semantics of Unsafe.compareAndSwapX?  The javadoc is
rather thin.

I ask because Aarch64 allows a lot of variation.  If you use the
obvious sequence

1:	ldaxr	x0, [B]		// Exclusive load with acquire
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b

which has two half barriers, you don't prevent some reorderings
because memory accesses can move past their half barriers.  For
example,

	// A, B, C are independent memory locations

	<Access [A]>

	// atomic_op (B)
1:	ldaxr	x0, [B]		// Exclusive load with acquire
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b

	<Access [C]>

could result in

      load[B] -> A -> C -> store[B]

Of course I can use a belt and braces approach such as

	dmb	ish		// Full barrier
1:	ldxr	x0, [B]		// Exclusive load
	<op(B)>
	stxr	w1, x0, [B]	// Exclusive store
	cbnz	w1, 1b
	dmb	ish		// Full barrier

but this is rather heavyweight.  Maybe I could get away with

1:	ldxr	x0, [B]		// Exclusive load
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b
	dmb	ish		// Full barrier

but I can't tell because I don't know what Unsafe.compareAndSwap() is
supposed to guarantee.

For what it's worth, GCC 4.8.1's __sync_bool_compare_and_swap() generates
the first sequence:

	ldaxr	x3, [x0]
	cmp	x3, x1
	bne	.L4
	stlxr	w4, x2, [x0]
	cbnz	w4, .L3
.L4:

More discussion at

http://lists.infradead.org/pipermail/linux-arm-kernel/2014-February/229588.html

Andrew.

From davidcholmes at aapt.net.au  Fri Feb 14 06:52:16 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 14 Feb 2014 21:52:16 +1000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <52FDF2DF.1050403@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>

Andrew Haley writes:
>
> What are the semantics of Unsafe.compareAndSwapX?  The javadoc is
> rather thin.

They are the implementation for the associated AtomicX.compareAndSet methods
and so have to adhere to the specification of those methods. But in terms of
memory barriers the key factor is that the variables act as volatiles so the
semantics are of a volatile read combined with a volatile write.

David
-----

> I ask because Aarch64 allows a lot of variation.  If you use the
> obvious sequence
>
> 1:	ldaxr	x0, [B]		// Exclusive load with acquire
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
>
> which has two half barriers, you don't prevent some reorderings
> because memory accesses can move past their half barriers.  For
> example,
>
> 	// A, B, C are independent memory locations
>
> 	<Access [A]>
>
> 	// atomic_op (B)
> 1:	ldaxr	x0, [B]		// Exclusive load with acquire
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
>
> 	<Access [C]>
>
> could result in
>
>       load[B] -> A -> C -> store[B]
>
> Of course I can use a belt and braces approach such as
>
> 	dmb	ish		// Full barrier
> 1:	ldxr	x0, [B]		// Exclusive load
> 	<op(B)>
> 	stxr	w1, x0, [B]	// Exclusive store
> 	cbnz	w1, 1b
> 	dmb	ish		// Full barrier
>
> but this is rather heavyweight.  Maybe I could get away with
>
> 1:	ldxr	x0, [B]		// Exclusive load
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
> 	dmb	ish		// Full barrier
>
> but I can't tell because I don't know what Unsafe.compareAndSwap() is
> supposed to guarantee.
>
> For what it's worth, GCC 4.8.1's __sync_bool_compare_and_swap() generates
> the first sequence:
>
> 	ldaxr	x3, [x0]
> 	cmp	x3, x1
> 	bne	.L4
> 	stlxr	w4, x2, [x0]
> 	cbnz	w4, .L3
> .L4:
>
> More discussion at
>
> http://lists.infradead.org/pipermail/linux-arm-kernel/2014-Februar
y/229588.html

Andrew.
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Fri Feb 14 08:12:12 2014
From: aph at redhat.com (Andrew Haley)
Date: Fri, 14 Feb 2014 13:12:12 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
Message-ID: <52FE162C.9080301@redhat.com>

On 02/14/2014 11:52 AM, David Holmes wrote:
> Andrew Haley writes:
>>
>> What are the semantics of Unsafe.compareAndSwapX?  The javadoc is
>> rather thin.
> 
> They are the implementation for the associated AtomicX.compareAndSet methods
> and so have to adhere to the specification of those methods. But in terms of
> memory barriers the key factor is that the variables act as volatiles so the
> semantics are of a volatile read combined with a volatile write.

Yes, but is that all?  Several of my examples have the semantics of a
volatile read combined with a volatile write.  However, they are not
the same.

With a globally visible int thing, is

   thing = 1;
   bool ok = AtomicX.compareAndSet(expect, update);

allowed to do

   tmp = AtomicX.loadExclusive();  // Exclusive load with acquire
   thing = 1;
   bool ok = (tmp == update);
   if (ok)
     AtomicX.storeExclusive(update);  // Exclusive store with release

?

Strict atomicity forbids this, but AFAICS a volatile read combined
with a volatile write does not.

Andrew.



From dl at cs.oswego.edu  Fri Feb 14 09:46:31 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 14 Feb 2014 09:46:31 -0500
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <52FE162C.9080301@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>
	<52FE162C.9080301@redhat.com>
Message-ID: <52FE2C47.1080904@cs.oswego.edu>

On 02/14/2014 08:12 AM, Andrew Haley wrote:
> On 02/14/2014 11:52 AM, David Holmes wrote:
>> Andrew Haley writes:
>>>
>>> What are the semantics of Unsafe.compareAndSwapX?  The javadoc is
>>> rather thin.
>>
>> They are the implementation for the associated AtomicX.compareAndSet methods
>> and so have to adhere to the specification of those methods. But in terms of
>> memory barriers the key factor is that the variables act as volatiles so the
>> semantics are of a volatile read combined with a volatile write.
>
> Yes, but is that all?

That's all wrt ordering effects, but CAS must also be atomic.
For ARMv8/Aarch64 (which I suspect you have in mind), the best mapping
is likely the one now used in linux.
(http://lists.infradead.org/pipermail/linux-arm-kernel/2014-February/229588.html)

	<Access [A]>

	// atomic_op (B)
1:	ldxr	x0, [B]		// Exclusive load
	<op(B)>
	stlxr	w1, x0, [B]	// Exclusive store with release
	cbnz	w1, 1b
	dmb	ish		// Full barrier

	<Access [C]>

Aside: The JMM update is likely to finally pin down
multiple modes of CAS/WeakCAS (full, acquire, release),
which are not all that common, but are specializable into
more efficient mappings on some processors.

-Doug


From aph at redhat.com  Fri Feb 14 10:27:15 2014
From: aph at redhat.com (Andrew Haley)
Date: Fri, 14 Feb 2014 15:27:15 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <37646254.NdQcvOKZVB@ubuntu>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
Message-ID: <52FE35D3.9090209@redhat.com>

On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
> I am currently following up inside ARM about this, stay tuned.  AFAICS,
> this should still be safe for basic locks.

Please note that this is not so much about locks but about CAS.  I
don't think that locks are such a problem, but (arguably) CAS seems to
require more than locks do because of Java semantics.

Andrew.


From aph at redhat.com  Fri Feb 14 10:31:04 2014
From: aph at redhat.com (Andrew Haley)
Date: Fri, 14 Feb 2014 15:31:04 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <52FE2C47.1080904@cs.oswego.edu>
References: <NFBBKALFDCPFIDBNKAPCEEGFKEAA.davidcholmes@aapt.net.au>	<52FE162C.9080301@redhat.com>
	<52FE2C47.1080904@cs.oswego.edu>
Message-ID: <52FE36B8.7020602@redhat.com>

On 02/14/2014 02:46 PM, Doug Lea wrote:
> On 02/14/2014 08:12 AM, Andrew Haley wrote:
>> On 02/14/2014 11:52 AM, David Holmes wrote:
>>> Andrew Haley writes:
>>>>
>>>> What are the semantics of Unsafe.compareAndSwapX?  The javadoc is
>>>> rather thin.
>>>
>>> They are the implementation for the associated AtomicX.compareAndSet methods
>>> and so have to adhere to the specification of those methods. But in terms of
>>> memory barriers the key factor is that the variables act as volatiles so the
>>> semantics are of a volatile read combined with a volatile write.
>>
>> Yes, but is that all?
> 
> That's all wrt ordering effects, but CAS must also be atomic.
> For ARMv8/Aarch64 (which I suspect you have in mind), the best mapping
> is likely the one now used in linux.
> (http://lists.infradead.org/pipermail/linux-arm-kernel/2014-February/229588.html)
> 
> 	<Access [A]>
> 
> 	// atomic_op (B)
> 1:	ldxr	x0, [B]		// Exclusive load
> 	<op(B)>
> 	stlxr	w1, x0, [B]	// Exclusive store with release
> 	cbnz	w1, 1b
> 	dmb	ish		// Full barrier
> 
> 	<Access [C]>

Okay, but if you have a look at the patch in that email you will see
that the sequence for CAS is different:

static inline long atomic64_cmpxchg(atomic64_t *ptr, long old, long new)
 	long oldval;
 	unsigned long res;

+	smp_mb();
+
 	asm volatile("// atomic64_cmpxchg\n"
-"1:	ldaxr	%1, %2\n"
+"1:	ldxr	%1, %2\n"
 "	cmp	%1, %3\n"
 "	b.ne	2f\n"
-"	stlxr	%w0, %4, %2\n"
+"	stxr	%w0, %4, %2\n"
 "	cbnz	%w0, 1b\n"
 "2:"
 	: "=&r" (res), "=&r" (oldval), "+Q" (ptr->counter)
 	: "Ir" (old), "r" (new)
 	: "cc", "memory");

+	smp_mb();
 	return oldval;

Note that this has a full barrier at each end.

> Aside: The JMM update is likely to finally pin down
> multiple modes of CAS/WeakCAS (full, acquire, release),
> which are not all that common, but are specializable into
> more efficient mappings on some processors.

Ah, good.

Andrew.


From kirk at kodewerk.com  Tue Feb 18 05:08:32 2014
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Tue, 18 Feb 2014 11:08:32 +0100
Subject: [concurrency-interest] [Performance Java User's Group] Our JEP
	proposal to replace sun.misc.Unsafe...
In-Reply-To: <z13bstshnyyhc15lw22bjbzpkvv4ip14104@plus.google.com>
References: <z13bstshnyyhc15lw22bjbzpkvv4ip14104@plus.google.com>
Message-ID: <9695F739-5CA3-4563-BFDE-5DE80E1202F2@kodewerk.com>

Hi,

This has just been posted.

The biggest ?scare? in Unsafe is the need to use direct pointer values for CAS. It would be nice if the CAS operation hid the pointers.

Regards,
Kirk

On Feb 17, 2014, at 8:09 PM, Christoph Engelbert (Google+) <noreply-8bf5f0e7 at plus.google.com> wrote:

> 
> Christoph Engelbert shared a post with Performance Java User's Group
> 
> 	
> Christoph Engelbert shared Christoph Engelbert's post with you.
> 	
> Christoph Engelbert
> Christoph Engelbert:
> Our JEP proposal to replace sun.misc.Unsafe with a public API http://bit.ly/N3b64Y - help us finalizing it - http://bit.ly/N3b4dn
> 
> View post
> You're receiving this email because you are subscribed to Performance Java User's Group on Google+.
> Mute Christoph Engelbert to stop receiving notifications from him. Change what notifications you receive from this community.This notification was sent to kirk at kodewerk.com; Go to your notification delivery settings to update your address. Manage subscriptions to change what emails you receive from Google+.
> Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140218/eebeaf72/attachment.html>

From heinz at javaspecialists.eu  Tue Feb 18 10:36:32 2014
From: heinz at javaspecialists.eu (Dr Heinz M. Kabutz)
Date: Tue, 18 Feb 2014 17:36:32 +0200
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <52ED59E2.7010301@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>
	<52ED59E2.7010301@cs.oswego.edu>
Message-ID: <53037E00.2060702@javaspecialists.eu>

A little newsletter on this subject to warn my readers to never let 
their ThreadLocalRandom instances escape. 

http://www.javaspecialists.eu/archive/Issue218.html

For the young-at-heart amongst you (or generally curious), there is 
another puzzle (along the same theme as before):

What happens when you run this on Java 7?  On Java 8?

import javax.swing.*;
import java.awt.*;
import java.util.concurrent.*;

import static javax.swing.WindowConstants.*;

public class MagicMessage {
  public static void main(final String... args) {
    final ThreadLocalRandom tlr = ThreadLocalRandom.current();
    SwingUtilities.invokeLater(new Runnable() {
      public void run() {
        final JFrame frame = new JFrame();
        final JLabel label = new JLabel(
            generateRandomString(), SwingConstants.CENTER);
        frame.add(label, BorderLayout.NORTH);
        frame.setSize(300, 100);
        frame.setVisible(true);
        frame.setDefaultCloseOperation(EXIT_ON_CLOSE);
      }
      private String generateRandomString() {
        final char[] randomText = "HVTia\u000EDlciP".toCharArray();
        for (int i = 0; i < randomText.length; i++) {
          randomText[i] += tlr.nextInt(26);
        }
        return new String(randomText);
      }
    });
  }
}

Regards

Heinz
-- 
Dr Heinz M. Kabutz (PhD CompSci)
Author of "The Java(tm) Specialists' Newsletter"
Oracle Java Champion 2005-2013
JavaOne Rock Star Speaker 2012
http://www.javaspecialists.eu
Tel: +30 69 75 595 262
Skype: kabutz



Doug Lea wrote:
>
> To summarize, we have the following suggestions (some off-list)
> in response to Heinz's puzzler:
>
> 1. Add documentation to TLR warning not to store TLR.current()
> in a static, or use as an argument to a method that might do so,
> or use as an argument in a method assuming thread-safety.
>
> 2. Add similar documentation to java.lang.ThreadLocal, and then
> refer and add to it in TLR.
>
> 3. Create findBugs rules covering (1) and (2).
>
> 4. Invent new type rules for Java enforcing (1) and (2).
>
> 5. Add an initialization check on each use of TLR.next() and
> throw an exception.
>
> 6. Eagerly initialize TLR seeds. (One reason this was not
> done originally is that it adds measurable time to Thread
> construction even when TLRs are not used in a thread, which
> is the most common case.)
>
> 7. Tell people to use java.util.SplittableRandom instead.
>
> 8. Do nothing.
>
> Considering that this is far from a critical bug, it is
> unlikely to become updated in OpenJDK until JDK9, so we
> seem to have plenty of time for further suggestions!
>
> -Doug
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> .
>

From aph at redhat.com  Tue Feb 18 12:56:16 2014
From: aph at redhat.com (Andrew Haley)
Date: Tue, 18 Feb 2014 17:56:16 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <37646254.NdQcvOKZVB@ubuntu>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
Message-ID: <53039EC0.7060100@redhat.com>

On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
> I am currently following up inside ARM about this, stay tuned.

Any news?

Thanks,
Andrew.


From dl at cs.oswego.edu  Wed Feb 19 08:11:02 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 19 Feb 2014 08:11:02 -0500
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <53037E00.2060702@javaspecialists.eu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>
	<52ED59E2.7010301@cs.oswego.edu>
	<53037E00.2060702@javaspecialists.eu>
Message-ID: <5304AD66.5050304@cs.oswego.edu>

On 02/18/2014 10:36 AM, Dr Heinz M. Kabutz wrote:
> A little newsletter on this subject to warn my readers to never let their
> ThreadLocalRandom instances escape.
> http://www.javaspecialists.eu/archive/Issue218.html

Thanks. Here's added javadoc that should someday be folded
in. We still do not want to specify exactly what happens if
you leak this or any other thread-local, since this might
be subject to change over time in either TLR or ThreadLocal.

    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
    * in parallel in thread pools.
    *
!  * <p>Usages of this class should typically be of the form:
!  * {@code ThreadLocalRandom.current().nextX(...)} (where
!  * {@code X} is {@code Int}, {@code Long}, etc).
!  * When all usages are of this form, it is never possible to
!  * accidently share a {@code ThreadLocalRandom} across multiple threads.
    *
    * <p>This class also provides additional commonly used bounded random
    * generation methods.
--- 33,47 ----
    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
    * in parallel in thread pools.
    *
!  * <p>Usages of this class should typically be of the form: {@code
!  * ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
!  * Int}, {@code Long}, etc).  When all usages are of this form, it is
!  * never possible to accidentally share a {@code ThreadLocalRandom}
!  * across multiple threads.  As is the case for any thread-local
!  * variable, a {@code ThreadLocalRandom} should never be made
!  * accessible to other threads by, for example, holding in a {@code
!  * static} field. A {@code ThreadLocalRandom} used by multiple threads
!  * need not (and typically will not) generate uniform random numbers.
    *


From ppozerov at gmail.com  Wed Feb 19 09:21:14 2014
From: ppozerov at gmail.com (=?KOI8-R?B?98zBxMnNydIg79rF0s/X?=)
Date: Wed, 19 Feb 2014 18:21:14 +0400
Subject: [concurrency-interest] COWList snapshot.
Message-ID: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>

Hi,

I was a little bit suprized when found that there is no convenient way to
get snapshot of COW list.
.
What I need is to get snapshot of the list (in form of either array or
List, doesn't matter) and perform several reads on it (index lookups or
traversals). For this reason I cannot use iterator. Also I would like to
avoid unnecessary array copying since I'm not going to perform writes. So
getting internal array appears to be the best way to do that from
performance perspective. Copying constructor and forEach() method already
employ this technique in JDK8 (
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup
)

For now there is no way to get that array since all access to it are either
private or package-scoped. Could something like "List<T> snapshot()" be
added to COWList API returning unmodifiable wrapper over internal array? Or
at least getArray() could be made protected so that developers can use it
on their own risk :-)

Vladimir.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/13cc21a6/attachment.html>

From jason_mehrens at hotmail.com  Wed Feb 19 10:12:50 2014
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Wed, 19 Feb 2014 09:12:50 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
Message-ID: <BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>

Vladimir,

You can use the COWAL copy constructor which has a fast path for COWAL or use the clone method.

Jason

________________________________
> Date: Wed, 19 Feb 2014 18:21:14 +0400 
> From: ppozerov at gmail.com 
> To: concurrency-interest at cs.oswego.edu 
> Subject: [concurrency-interest] COWList snapshot. 
> 
> Hi, 
> 
> I was a little bit suprized when found that there is no convenient way 
> to get snapshot of COW list. 
> . 
> What I need is to get snapshot of the list (in form of either array or 
> List, doesn't matter) and perform several reads on it (index lookups or 
> traversals). For this reason I cannot use iterator. Also I would like 
> to avoid unnecessary array copying since I'm not going to perform 
> writes. So getting internal array appears to be the best way to do that 
> from performance perspective. Copying constructor and forEach() method 
> already employ this technique in JDK8 
> (http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup) 
> 
> For now there is no way to get that array since all access to it are 
> either private or package-scoped. Could something like "List<T> 
> snapshot()" be added to COWList API returning unmodifiable wrapper over 
> internal array? Or at least getArray() could be made protected so that 
> developers can use it on their own risk :-) 
> 
> Vladimir. 
> 
> _______________________________________________ Concurrency-interest 
> mailing list Concurrency-interest at cs.oswego.edu 
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest 		 	   		  

From kasperni at gmail.com  Wed Feb 19 10:37:50 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Wed, 19 Feb 2014 16:37:50 +0100
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
Message-ID: <CAPs6153pX5BxGkJo_wEgpgWP7FRpBnSibsPEV=cKB95AZ8T14Q@mail.gmail.com>

On Wed, Feb 19, 2014 at 4:12 PM, Jason Mehrens <jason_mehrens at hotmail.com>wrote:

> Vladimir,
>
> You can use the COWAL copy constructor which has a fast path for COWAL or
> use the clone method.
>
> Doesn't really eliminate the unnecessary array copying?

I think an ImmutableList COWAL.snapshot() makes good sense.

- Kasper
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/acff3830/attachment.html>

From jason_mehrens at hotmail.com  Wed Feb 19 11:18:44 2014
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Wed, 19 Feb 2014 10:18:44 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CAPs6153pX5BxGkJo_wEgpgWP7FRpBnSibsPEV=cKB95AZ8T14Q@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>,
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>,
	<CAPs6153pX5BxGkJo_wEgpgWP7FRpBnSibsPEV=cKB95AZ8T14Q@mail.gmail.com>
Message-ID: <BLU175-W1252ABEE22C29C103620FF839B0@phx.gbl>

Kasper, http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005935.html http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?revision=1.115&view=markup Jason
 
 Date: Wed, 19 Feb 2014 16:37:50 +0100
Subject: Re: [concurrency-interest] COWList snapshot.
From: kasperni at gmail.com
To: jason_mehrens at hotmail.com
CC: ppozerov at gmail.com; concurrency-interest at cs.oswego.edu




On Wed, Feb 19, 2014 at 4:12 PM, Jason Mehrens <jason_mehrens at hotmail.com> wrote:

Vladimir,



You can use the COWAL copy constructor which has a fast path for COWAL or use the clone method.

Doesn't really eliminate the unnecessary array copying?

I think an ImmutableList COWAL.snapshot() makes good sense.

- Kasper
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/31f742cb/attachment.html>

From ppozerov at gmail.com  Wed Feb 19 13:41:01 2014
From: ppozerov at gmail.com (=?KOI8-R?B?98zBxMnNydIg79rF0s/X?=)
Date: Wed, 19 Feb 2014 22:41:01 +0400
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
Message-ID: <CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>

Jason,

The main problem with copying constructor is volatile access to array which
is expected to be immutable. Furthermore COWList created from another
COWList breaks snapshot semantics - it can be changed. The same applies for
clone().
Proposed wrapper should be pretty similar to COWIterator - thin wrapper
with final array.reference inside. Old thread with example of this approach
- http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html

Vladimir.


2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:

> Vladimir,
>
> You can use the COWAL copy constructor which has a fast path for COWAL or
> use the clone method.
>
> Jason
>
> ________________________________
> > Date: Wed, 19 Feb 2014 18:21:14 +0400
> > From: ppozerov at gmail.com
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] COWList snapshot.
> >
> > Hi,
> >
> > I was a little bit suprized when found that there is no convenient way
> > to get snapshot of COW list.
> > .
> > What I need is to get snapshot of the list (in form of either array or
> > List, doesn't matter) and perform several reads on it (index lookups or
> > traversals). For this reason I cannot use iterator. Also I would like
> > to avoid unnecessary array copying since I'm not going to perform
> > writes. So getting internal array appears to be the best way to do that
> > from performance perspective. Copying constructor and forEach() method
> > already employ this technique in JDK8
> > (
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup
> )
> >
> > For now there is no way to get that array since all access to it are
> > either private or package-scoped. Could something like "List<T>
> > snapshot()" be added to COWList API returning unmodifiable wrapper over
> > internal array? Or at least getArray() could be made protected so that
> > developers can use it on their own risk :-)
> >
> > Vladimir.
> >
> > _______________________________________________ Concurrency-interest
> > mailing list Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/1e0a5f26/attachment.html>

From zhong.j.yu at gmail.com  Wed Feb 19 14:51:45 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 19 Feb 2014 13:51:45 -0600
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <5304AD66.5050304@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu> <52EAACD3.8000405@oracle.com>
	<52EABDB4.1030409@cs.oswego.edu> <52EAC246.1080606@oracle.com>
	<52EB9050.7050503@cs.oswego.edu>
	<52EB9C47.3080908@javaspecialists.eu>
	<52EBA6E3.2060707@cs.oswego.edu> <52EBB034.3000305@oracle.com>
	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>
	<52EBBB46.5080002@javaspecialists.eu>
	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>
	<52EBE1F9.9030206@javaspecialists.eu>
	<52ED59E2.7010301@cs.oswego.edu>
	<53037E00.2060702@javaspecialists.eu>
	<5304AD66.5050304@cs.oswego.edu>
Message-ID: <CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>

Typically, a thread-local variable could be handed over to another
thread, with proper happens-before edge. The current impl of TLR
cannot do that due to its peculiar mechanism of initialization. So I
don't think it's enough to let users reason about it like a normal
ThreadLocal.

Here's an example:

    static ThreadLocalRandom random;

    public static void main(String[] args) throws Exception
    {
        Thread t1 = new Thread( () ->
            random=ThreadLocalRandom.current()
        );
        t1.start();
        t1.join();

        System.out.println( random.nextInt() ); // is the result random?
    }

Zhong Yu


On Wed, Feb 19, 2014 at 7:11 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> On 02/18/2014 10:36 AM, Dr Heinz M. Kabutz wrote:
>>
>> A little newsletter on this subject to warn my readers to never let their
>> ThreadLocalRandom instances escape.
>> http://www.javaspecialists.eu/archive/Issue218.html
>
>
> Thanks. Here's added javadoc that should someday be folded
> in. We still do not want to specify exactly what happens if
> you leak this or any other thread-local, since this might
> be subject to change over time in either TLR or ThreadLocal.
>
>    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>    * in parallel in thread pools.
>    *
> !  * <p>Usages of this class should typically be of the form:
> !  * {@code ThreadLocalRandom.current().nextX(...)} (where
> !  * {@code X} is {@code Int}, {@code Long}, etc).
> !  * When all usages are of this form, it is never possible to
> !  * accidently share a {@code ThreadLocalRandom} across multiple threads.
>    *
>    * <p>This class also provides additional commonly used bounded random
>    * generation methods.
> --- 33,47 ----
>    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>    * in parallel in thread pools.
>    *
> !  * <p>Usages of this class should typically be of the form: {@code
> !  * ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
> !  * Int}, {@code Long}, etc).  When all usages are of this form, it is
> !  * never possible to accidentally share a {@code ThreadLocalRandom}
> !  * across multiple threads.  As is the case for any thread-local
> !  * variable, a {@code ThreadLocalRandom} should never be made
> !  * accessible to other threads by, for example, holding in a {@code
> !  * static} field. A {@code ThreadLocalRandom} used by multiple threads
> !  * need not (and typically will not) generate uniform random numbers.
>
>    *
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From martinrb at google.com  Wed Feb 19 14:55:16 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Feb 2014 11:55:16 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
Message-ID: <CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>

????????,

I agree that a snapshot method as you propose would be useful.  As always,
implementing the List interface ends up being rather a lot of tedious work,
which may be a reason it never got done.


On Wed, Feb 19, 2014 at 10:41 AM, ???????? ?????? <ppozerov at gmail.com>wrote:

> Jason,
>
> The main problem with copying constructor is volatile access to array
> which is expected to be immutable. Furthermore COWList created from another
> COWList breaks snapshot semantics - it can be changed. The same applies for
> clone().
> Proposed wrapper should be pretty similar to COWIterator - thin wrapper
> with final array.reference inside. Old thread with example of this approach
> -
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html
>
> Vladimir.
>
>
> 2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:
>
> Vladimir,
>>
>> You can use the COWAL copy constructor which has a fast path for COWAL or
>> use the clone method.
>>
>> Jason
>>
>> ________________________________
>> > Date: Wed, 19 Feb 2014 18:21:14 +0400
>> > From: ppozerov at gmail.com
>> > To: concurrency-interest at cs.oswego.edu
>> > Subject: [concurrency-interest] COWList snapshot.
>> >
>> > Hi,
>> >
>> > I was a little bit suprized when found that there is no convenient way
>> > to get snapshot of COW list.
>> > .
>> > What I need is to get snapshot of the list (in form of either array or
>> > List, doesn't matter) and perform several reads on it (index lookups or
>> > traversals). For this reason I cannot use iterator. Also I would like
>> > to avoid unnecessary array copying since I'm not going to perform
>> > writes. So getting internal array appears to be the best way to do that
>> > from performance perspective. Copying constructor and forEach() method
>> > already employ this technique in JDK8
>> > (
>> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup
>> )
>> >
>> > For now there is no way to get that array since all access to it are
>> > either private or package-scoped. Could something like "List<T>
>> > snapshot()" be added to COWList API returning unmodifiable wrapper over
>> > internal array? Or at least getArray() could be made protected so that
>> > developers can use it on their own risk :-)
>> >
>> > Vladimir.
>> >
>> > _______________________________________________ Concurrency-interest
>> > mailing list Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/4b78dffd/attachment.html>

From aleksey.shipilev at oracle.com  Wed Feb 19 15:02:37 2014
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 20 Feb 2014 00:02:37 +0400
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <5304AD66.5050304@cs.oswego.edu>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>	<52ED59E2.7010301@cs.oswego.edu>	<53037E00.2060702@javaspecialists.eu>
	<5304AD66.5050304@cs.oswego.edu>
Message-ID: <53050DDD.3010803@oracle.com>

On 02/19/2014 05:11 PM, Doug Lea wrote:
> On 02/18/2014 10:36 AM, Dr Heinz M. Kabutz wrote:
>> A little newsletter on this subject to warn my readers to never let their
>> ThreadLocalRandom instances escape.
>> http://www.javaspecialists.eu/archive/Issue218.html
> 
> Thanks. Here's added javadoc that should someday be folded
> in. We still do not want to specify exactly what happens if
> you leak this or any other thread-local, since this might
> be subject to change over time in either TLR or ThreadLocal.
> 
>    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>    * in parallel in thread pools.
>    *
> !  * <p>Usages of this class should typically be of the form:
> !  * {@code ThreadLocalRandom.current().nextX(...)} (where
> !  * {@code X} is {@code Int}, {@code Long}, etc).
> !  * When all usages are of this form, it is never possible to
> !  * accidently share a {@code ThreadLocalRandom} across multiple threads.
>    *
>    * <p>This class also provides additional commonly used bounded random
>    * generation methods.
> --- 33,47 ----
>    * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>    * in parallel in thread pools.
>    *
> !  * <p>Usages of this class should typically be of the form: {@code
> !  * ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
> !  * Int}, {@code Long}, etc).  When all usages are of this form, it is
> !  * never possible to accidentally share a {@code ThreadLocalRandom}
> !  * across multiple threads.  As is the case for any thread-local
> !  * variable, a {@code ThreadLocalRandom} should never be made
> !  * accessible to other threads by, for example, holding in a {@code
> !  * static} field. A {@code ThreadLocalRandom} used by multiple threads
> !  * need not (and typically will not) generate uniform random numbers.
>    *

+1 for this update.

-Aleksey.


From zhong.j.yu at gmail.com  Wed Feb 19 15:06:59 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 19 Feb 2014 14:06:59 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
Message-ID: <CACuKZqGCsOxGa_XHhs_kJgkkrRuqpzPQux9yDfnxuP-3zoFCbg@mail.gmail.com>

On Wed, Feb 19, 2014 at 12:41 PM, ???????? ?????? <ppozerov at gmail.com> wrote:
> Jason,
>
> The main problem with copying constructor is volatile access to array which
> is expected to be immutable. Furthermore COWList created from another
> COWList breaks snapshot semantics - it can be changed. The same applies for
> clone().

That doesn't matter, right? Any change to the copy/clone will not
affect the origin. If you must hand over the copy/clone to others as
read-only list, Collections.unmodifiableList() wrapper would work
(unless you don't like the extra overhead)

> Proposed wrapper should be pretty similar to COWIterator - thin wrapper with
> final array.reference inside. Old thread with example of this approach -
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html
>
> Vladimir.
>
>
> 2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:
>
>> Vladimir,
>>
>> You can use the COWAL copy constructor which has a fast path for COWAL or
>> use the clone method.
>>
>> Jason
>>
>> ________________________________
>> > Date: Wed, 19 Feb 2014 18:21:14 +0400
>> > From: ppozerov at gmail.com
>> > To: concurrency-interest at cs.oswego.edu
>> > Subject: [concurrency-interest] COWList snapshot.
>> >
>> > Hi,
>> >
>> > I was a little bit suprized when found that there is no convenient way
>> > to get snapshot of COW list.
>> > .
>> > What I need is to get snapshot of the list (in form of either array or
>> > List, doesn't matter) and perform several reads on it (index lookups or
>> > traversals). For this reason I cannot use iterator. Also I would like
>> > to avoid unnecessary array copying since I'm not going to perform
>> > writes. So getting internal array appears to be the best way to do that
>> > from performance perspective. Copying constructor and forEach() method
>> > already employ this technique in JDK8
>> >
>> > (http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup)
>> >
>> > For now there is no way to get that array since all access to it are
>> > either private or package-scoped. Could something like "List<T>
>> > snapshot()" be added to COWList API returning unmodifiable wrapper over
>> > internal array? Or at least getArray() could be made protected so that
>> > developers can use it on their own risk :-)
>> >
>> > Vladimir.
>> >
>> > _______________________________________________ Concurrency-interest
>> > mailing list Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From zhong.j.yu at gmail.com  Wed Feb 19 15:08:35 2014
From: zhong.j.yu at gmail.com (Zhong Yu)
Date: Wed, 19 Feb 2014 14:08:35 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
Message-ID: <CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>

On Wed, Feb 19, 2014 at 1:55 PM, Martin Buchholz <martinrb at google.com> wrote:
> ????????,
>
> I agree that a snapshot method as you propose would be useful.  As always,
> implementing the List interface ends up being rather a lot of tedious work,
> which may be a reason it never got done.

Interestingly, JDK doesn't not seem to have a method to wrap an array
as a read-only list. A lot of people use Arrays.asList(), which is
wrong...

Zhong Yu

>
>
> On Wed, Feb 19, 2014 at 10:41 AM, ???????? ?????? <ppozerov at gmail.com>
> wrote:
>>
>> Jason,
>>
>> The main problem with copying constructor is volatile access to array
>> which is expected to be immutable. Furthermore COWList created from another
>> COWList breaks snapshot semantics - it can be changed. The same applies for
>> clone().
>> Proposed wrapper should be pretty similar to COWIterator - thin wrapper
>> with final array.reference inside. Old thread with example of this approach
>> - http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html
>>
>> Vladimir.
>>
>>
>> 2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:
>>
>>> Vladimir,
>>>
>>> You can use the COWAL copy constructor which has a fast path for COWAL or
>>> use the clone method.
>>>
>>> Jason
>>>
>>> ________________________________
>>> > Date: Wed, 19 Feb 2014 18:21:14 +0400
>>> > From: ppozerov at gmail.com
>>> > To: concurrency-interest at cs.oswego.edu
>>> > Subject: [concurrency-interest] COWList snapshot.
>>> >
>>> > Hi,
>>> >
>>> > I was a little bit suprized when found that there is no convenient way
>>> > to get snapshot of COW list.
>>> > .
>>> > What I need is to get snapshot of the list (in form of either array or
>>> > List, doesn't matter) and perform several reads on it (index lookups or
>>> > traversals). For this reason I cannot use iterator. Also I would like
>>> > to avoid unnecessary array copying since I'm not going to perform
>>> > writes. So getting internal array appears to be the best way to do that
>>> > from performance perspective. Copying constructor and forEach() method
>>> > already employ this technique in JDK8
>>> >
>>> > (http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup)
>>> >
>>> > For now there is no way to get that array since all access to it are
>>> > either private or package-scoped. Could something like "List<T>
>>> > snapshot()" be added to COWList API returning unmodifiable wrapper over
>>> > internal array? Or at least getArray() could be made protected so that
>>> > developers can use it on their own risk :-)
>>> >
>>> > Vladimir.
>>> >
>>> > _______________________________________________ Concurrency-interest
>>> > mailing list Concurrency-interest at cs.oswego.edu
>>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From martinrb at google.com  Wed Feb 19 15:22:07 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Feb 2014 12:22:07 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>
Message-ID: <CA+kOe0_BCASDMekN=ve_HtzLPObh5JM2s6yPXMesKUg2K8Hd2A@mail.gmail.com>

On Wed, Feb 19, 2014 at 12:08 PM, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Wed, Feb 19, 2014 at 1:55 PM, Martin Buchholz <martinrb at google.com>
> wrote:
> > ????????,
> >
> > I agree that a snapshot method as you propose would be useful.  As
> always,
> > implementing the List interface ends up being rather a lot of tedious
> work,
> > which may be a reason it never got done.
>
> Interestingly, JDK doesn't not seem to have a method to wrap an array
> as a read-only list. A lot of people use Arrays.asList(), which is
> wrong...
>

It's probably a matter of trust.  If you implemented ImmutableArrayList
with a constructor that took an Object[], you would need to trust whoever
handed you the array, or make a copy.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/6a9694ef/attachment.html>

From stephan.diestelhorst at gmail.com  Wed Feb 19 15:40:17 2014
From: stephan.diestelhorst at gmail.com (Stephan Diestelhorst)
Date: Wed, 19 Feb 2014 15:40:17 -0500
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <53039EC0.7060100@redhat.com>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
	<53039EC0.7060100@redhat.com>
Message-ID: <CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>

On 18 February 2014 12:56, Andrew Haley <aph at redhat.com> wrote:
> On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
> > I am currently following up inside ARM about this, stay tuned.
>
> Any news?

Yes, so my original understanding was too simplistic.  In the sequence
of memop_A; ldx.acq(B) ;... ; stx.rel(B); memopp_C we may indeed
observe a lack of ordering between memop_A and memop_C.  So the
instruction sequence is not meant to be a full-fence replacement.
This is, however, consistent with our manuals, and the implementation
of the C++11 atomics, and the notion of sequential consistency of
atomics.

So it really boils down to the semantics of Unsafe.CAS and that was
what you were asking earlier.

Thanks,
  Stephan

From henri.tremblay at gmail.com  Wed Feb 19 16:00:15 2014
From: henri.tremblay at gmail.com (Henri Tremblay)
Date: Wed, 19 Feb 2014 22:00:15 +0100
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>
Message-ID: <CADZL2=ttDJheASyBfXcb-A3CUAHMJw460wUyQFMQ-v7AV-FLEw@mail.gmail.com>

Collections.unmodifiableList(Arrays.asList(...)); ?


On 19 February 2014 21:08, Zhong Yu <zhong.j.yu at gmail.com> wrote:

> On Wed, Feb 19, 2014 at 1:55 PM, Martin Buchholz <martinrb at google.com>
> wrote:
> > ????????,
> >
> > I agree that a snapshot method as you propose would be useful.  As
> always,
> > implementing the List interface ends up being rather a lot of tedious
> work,
> > which may be a reason it never got done.
>
> Interestingly, JDK doesn't not seem to have a method to wrap an array
> as a read-only list. A lot of people use Arrays.asList(), which is
> wrong...
>
> Zhong Yu
>
> >
> >
> > On Wed, Feb 19, 2014 at 10:41 AM, ???????? ?????? <ppozerov at gmail.com>
> > wrote:
> >>
> >> Jason,
> >>
> >> The main problem with copying constructor is volatile access to array
> >> which is expected to be immutable. Furthermore COWList created from
> another
> >> COWList breaks snapshot semantics - it can be changed. The same applies
> for
> >> clone().
> >> Proposed wrapper should be pretty similar to COWIterator - thin wrapper
> >> with final array.reference inside. Old thread with example of this
> approach
> >> -
> http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html
> >>
> >> Vladimir.
> >>
> >>
> >> 2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:
> >>
> >>> Vladimir,
> >>>
> >>> You can use the COWAL copy constructor which has a fast path for COWAL
> or
> >>> use the clone method.
> >>>
> >>> Jason
> >>>
> >>> ________________________________
> >>> > Date: Wed, 19 Feb 2014 18:21:14 +0400
> >>> > From: ppozerov at gmail.com
> >>> > To: concurrency-interest at cs.oswego.edu
> >>> > Subject: [concurrency-interest] COWList snapshot.
> >>> >
> >>> > Hi,
> >>> >
> >>> > I was a little bit suprized when found that there is no convenient
> way
> >>> > to get snapshot of COW list.
> >>> > .
> >>> > What I need is to get snapshot of the list (in form of either array
> or
> >>> > List, doesn't matter) and perform several reads on it (index lookups
> or
> >>> > traversals). For this reason I cannot use iterator. Also I would like
> >>> > to avoid unnecessary array copying since I'm not going to perform
> >>> > writes. So getting internal array appears to be the best way to do
> that
> >>> > from performance perspective. Copying constructor and forEach()
> method
> >>> > already employ this technique in JDK8
> >>> >
> >>> > (
> http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup
> )
> >>> >
> >>> > For now there is no way to get that array since all access to it are
> >>> > either private or package-scoped. Could something like "List<T>
> >>> > snapshot()" be added to COWList API returning unmodifiable wrapper
> over
> >>> > internal array? Or at least getArray() could be made protected so
> that
> >>> > developers can use it on their own risk :-)
> >>> >
> >>> > Vladimir.
> >>> >
> >>> > _______________________________________________ Concurrency-interest
> >>> > mailing list Concurrency-interest at cs.oswego.edu
> >>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >>
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >>
> >
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/3c558e25/attachment.html>

From martinrb at google.com  Wed Feb 19 16:04:33 2014
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 19 Feb 2014 13:04:33 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CADZL2=ttDJheASyBfXcb-A3CUAHMJw460wUyQFMQ-v7AV-FLEw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>
	<CADZL2=ttDJheASyBfXcb-A3CUAHMJw460wUyQFMQ-v7AV-FLEw@mail.gmail.com>
Message-ID: <CA+kOe0-sppG=EpzG04QhYb5WoydwWHrW_XDa7RB=Hr-C8ivjQw@mail.gmail.com>

On Wed, Feb 19, 2014 at 1:00 PM, Henri Tremblay <henri.tremblay at gmail.com>wrote:

> Collections.unmodifiableList(Arrays.asList(...)); ?
>

Sure, it's easy to take a snapshot while making a copy.  But it's nice to
have an O(1) snapshot.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/e7cbfc2d/attachment-0001.html>

From aaron.grunthal at infinite-source.de  Wed Feb 19 16:13:37 2014
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Wed, 19 Feb 2014 22:13:37 +0100
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe0-sppG=EpzG04QhYb5WoydwWHrW_XDa7RB=Hr-C8ivjQw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>	<CACuKZqHeRWidEL-DFgxOPWOVRUoy94bYtR7bav_eLTWyJBH2Vw@mail.gmail.com>	<CADZL2=ttDJheASyBfXcb-A3CUAHMJw460wUyQFMQ-v7AV-FLEw@mail.gmail.com>
	<CA+kOe0-sppG=EpzG04QhYb5WoydwWHrW_XDa7RB=Hr-C8ivjQw@mail.gmail.com>
Message-ID: <53051E81.5040503@infinite-source.de>

Why not combine Collections.unmodifiableList() with the copy constructor?

On 19.02.2014 22:04, Martin Buchholz wrote:
>
>
>
> On Wed, Feb 19, 2014 at 1:00 PM, Henri Tremblay
> <henri.tremblay at gmail.com <mailto:henri.tremblay at gmail.com>> wrote:
>
>     Collections.unmodifiableList(Arrays.asList(...)); ?
>
>
> Sure, it's easy to take a snapshot while making a copy.  But it's nice
> to have an O(1) snapshot.
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From jason_mehrens at hotmail.com  Wed Feb 19 17:22:59 2014
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Wed, 19 Feb 2014 16:22:59 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>,
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>,
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
Message-ID: <BLU175-W311AF9C3CBF262E6E827B4839B0@phx.gbl>




Vladimir, Mutable local scope snapshots are safe.  Clone and copy constructor both meet all of your initial requirements as long as you can resist temptation to modify your local snapshot.  COWAL is optimized for read so if you are concerned that a COWAL snapshot is going to be too slow for reading the COWAL should probably not be used at all. However, I would encourage you to give the clone and or copy constructor a try.  Let us know how it works out.  One can only assume the reason the 2009 thread died and we don't have a snapshot method today is that the alternatives work. http://brooker.co.za/blog/2012/09/10/volatile.html Jason Date: Wed, 19 Feb 2014 22:41:01 +0400
Subject: Re: [concurrency-interest] COWList snapshot.
From: ppozerov at gmail.com
To: jason_mehrens at hotmail.com
CC: concurrency-interest at cs.oswego.edu

Jason,
The main problem with copying constructor is volatile access to array which is expected to be immutable. Furthermore COWList created from another COWList breaks snapshot semantics - it can be changed. The same applies for clone().
Proposed wrapper should be pretty similar to COWIterator - thin wrapper with final array.reference inside. Old thread with example of this approach - http://cs.oswego.edu/pipermail/concurrency-interest/2009-March/005926.html

Vladimir.

2014-02-19 19:12 GMT+04:00 Jason Mehrens <jason_mehrens at hotmail.com>:

Vladimir,



You can use the COWAL copy constructor which has a fast path for COWAL or use the clone method.



Jason



________________________________

> Date: Wed, 19 Feb 2014 18:21:14 +0400

> From: ppozerov at gmail.com

> To: concurrency-interest at cs.oswego.edu

> Subject: [concurrency-interest] COWList snapshot.

>

> Hi,

>

> I was a little bit suprized when found that there is no convenient way

> to get snapshot of COW list.

> .

> What I need is to get snapshot of the list (in form of either array or

> List, doesn't matter) and perform several reads on it (index lookups or

> traversals). For this reason I cannot use iterator. Also I would like

> to avoid unnecessary array copying since I'm not going to perform

> writes. So getting internal array appears to be the best way to do that

> from performance perspective. Copying constructor and forEach() method

> already employ this technique in JDK8

> (http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java?view=markup)


>

> For now there is no way to get that array since all access to it are

> either private or package-scoped. Could something like "List<T>

> snapshot()" be added to COWList API returning unmodifiable wrapper over

> internal array? Or at least getArray() could be made protected so that

> developers can use it on their own risk :-)

>

> Vladimir.

>

> _______________________________________________ Concurrency-interest

> mailing list Concurrency-interest at cs.oswego.edu

> http://cs.oswego.edu/mailman/listinfo/concurrency-interest                                      

 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140219/0e9256d9/attachment.html>

From peter.levart at gmail.com  Thu Feb 20 04:24:21 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 20 Feb 2014 10:24:21 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>	<52ED59E2.7010301@cs.oswego.edu>	<53037E00.2060702@javaspecialists.eu>	<5304AD66.5050304@cs.oswego.edu>
	<CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>
Message-ID: <5305C9C5.6040507@gmail.com>


On 02/19/2014 08:51 PM, Zhong Yu wrote:
> Typically, a thread-local variable could be handed over to another
> thread, with proper happens-before edge.

What *is* a thread-local variable? Java does not have such thing. It 
only has local variables, instance and static fields. If by thread-local 
variable we mean a ThreadLocal object, then such instances are usually 
meant to be shared by multiple threads. Contrary to ThreadLocalRandom 
instance(s) which are better not (considering current implementation and 
possible future changes). If by thread-local variable we mean a state, 
associated with the pair (ThreadLocal object, current thread) then the 
API itself makes it impossible to share this state across threads. So 
the following wording is a little confusing, I think:


<p>Usages of this class should typically be of the form: {@code
ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
Int}, {@code Long}, etc).  When all usages are of this form, it is
never possible to accidentally share a {@code ThreadLocalRandom}
across multiple threads. *As is the case for any thread-local **
**variable, a {@code ThreadLocalRandom} should never be made **
**accessible to other threads* by, for example, holding in a {@code
static} field. A {@code ThreadLocalRandom} used by multiple threads
need not (and typically will not) generate uniform random numbers.


So I think it would be better to remove the "As is the case for any 
thread-local
variable, " part of the sentence. The rest makes perfect sense.


Regards, Peter

> The current impl of TLR
> cannot do that due to its peculiar mechanism of initialization. So I
> don't think it's enough to let users reason about it like a normal
> ThreadLocal.
>
> Here's an example:
>
>      static ThreadLocalRandom random;
>
>      public static void main(String[] args) throws Exception
>      {
>          Thread t1 = new Thread( () ->
>              random=ThreadLocalRandom.current()
>          );
>          t1.start();
>          t1.join();
>
>          System.out.println( random.nextInt() ); // is the result random?
>      }
>
> Zhong Yu
>
>
> On Wed, Feb 19, 2014 at 7:11 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>> On 02/18/2014 10:36 AM, Dr Heinz M. Kabutz wrote:
>>> A little newsletter on this subject to warn my readers to never let their
>>> ThreadLocalRandom instances escape.
>>> http://www.javaspecialists.eu/archive/Issue218.html
>> Thanks. Here's added javadoc that should someday be folded
>> in. We still do not want to specify exactly what happens if
>> you leak this or any other thread-local, since this might
>> be subject to change over time in either TLR or ThreadLocal.
>>
>>     * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>>     * in parallel in thread pools.
>>     *
>> !  * <p>Usages of this class should typically be of the form:
>> !  * {@code ThreadLocalRandom.current().nextX(...)} (where
>> !  * {@code X} is {@code Int}, {@code Long}, etc).
>> !  * When all usages are of this form, it is never possible to
>> !  * accidently share a {@code ThreadLocalRandom} across multiple threads.
>>     *
>>     * <p>This class also provides additional commonly used bounded random
>>     * generation methods.
>> --- 33,47 ----
>>     * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>>     * in parallel in thread pools.
>>     *
>> !  * <p>Usages of this class should typically be of the form: {@code
>> !  * ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
>> !  * Int}, {@code Long}, etc).  When all usages are of this form, it is
>> !  * never possible to accidentally share a {@code ThreadLocalRandom}
>> !  * across multiple threads.  As is the case for any thread-local
>> !  * variable, a {@code ThreadLocalRandom} should never be made
>> !  * accessible to other threads by, for example, holding in a {@code
>> !  * static} field. A {@code ThreadLocalRandom} used by multiple threads
>> !  * need not (and typically will not) generate uniform random numbers.
>>
>>     *
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140220/f82741e6/attachment.html>

From aph at redhat.com  Thu Feb 20 04:48:35 2014
From: aph at redhat.com (Andrew Haley)
Date: Thu, 20 Feb 2014 09:48:35 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>
	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
Message-ID: <5305CF73.7040500@redhat.com>

On 02/19/2014 08:40 PM, Stephan Diestelhorst wrote:
> On 18 February 2014 12:56, Andrew Haley <aph at redhat.com> wrote:
>> On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
>>> I am currently following up inside ARM about this, stay tuned.
>>
>> Any news?
> 
> Yes, so my original understanding was too simplistic.  In the
> sequence of memop_A; ldx.acq(B) ;... ; stx.rel(B); memopp_C we may
> indeed observe a lack of ordering between memop_A and memop_C.  So
> the instruction sequence is not meant to be a full-fence
> replacement.  This is, however, consistent with our manuals, and the
> implementation of the C++11 atomics, and the notion of sequential
> consistency of atomics.

Thank you.

So, GCC's usage of ldaxr ... stlxr for CAS is OK, even though it
doesn't completely enforce a full fence.  This is interesting.  I
wonder how anyone (not on the language committee :-) is expected to
know this.  Maybe they're not, and there is going to be some
interesting confusion when people try to port software from Intel to
ARM.

> So it really boils down to the semantics of Unsafe.CAS and that was
> what you were asking earlier.

OK, thanks.  Thought so.

So, Back to you, Doug: what are the semantics of Unsafe.CAS ?

Andrew.

From davidcholmes at aapt.net.au  Thu Feb 20 05:25:00 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 20 Feb 2014 20:25:00 +1000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <5305CF73.7040500@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCMEINKEAA.davidcholmes@aapt.net.au>

Andrew,

The volatile-read followed by volatile-write implicit in the CAS precludes
any accesses before the cas appearing after, or vice-versa. I would appeal
intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)

David

> -----Original Message-----
> From: concurrency-interest-bounces at cs.oswego.edu
> [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Andrew
> Haley
> Sent: Thursday, 20 February 2014 7:49 PM
> To: Stephan Diestelhorst
> Cc: concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
> Subject: Re: [concurrency-interest] Semantics of compareAndSwapX
>
>
> On 02/19/2014 08:40 PM, Stephan Diestelhorst wrote:
> > On 18 February 2014 12:56, Andrew Haley <aph at redhat.com> wrote:
> >> On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
> >>> I am currently following up inside ARM about this, stay tuned.
> >>
> >> Any news?
> >
> > Yes, so my original understanding was too simplistic.  In the
> > sequence of memop_A; ldx.acq(B) ;... ; stx.rel(B); memopp_C we may
> > indeed observe a lack of ordering between memop_A and memop_C.  So
> > the instruction sequence is not meant to be a full-fence
> > replacement.  This is, however, consistent with our manuals, and the
> > implementation of the C++11 atomics, and the notion of sequential
> > consistency of atomics.
>
> Thank you.
>
> So, GCC's usage of ldaxr ... stlxr for CAS is OK, even though it
> doesn't completely enforce a full fence.  This is interesting.  I
> wonder how anyone (not on the language committee :-) is expected to
> know this.  Maybe they're not, and there is going to be some
> interesting confusion when people try to port software from Intel to
> ARM.
>
> > So it really boils down to the semantics of Unsafe.CAS and that was
> > what you were asking earlier.
>
> OK, thanks.  Thought so.
>
> So, Back to you, Doug: what are the semantics of Unsafe.CAS ?
>
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From paul.sandoz at oracle.com  Thu Feb 20 05:25:31 2014
From: paul.sandoz at oracle.com (Paul Sandoz)
Date: Thu, 20 Feb 2014 11:25:31 +0100
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <5305CF73.7040500@redhat.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>
	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com>
Message-ID: <803695F3-8BE6-4B85-B26B-DFE2BFF12C02@oracle.com>

On Feb 20, 2014, at 10:48 AM, Andrew Haley <aph at redhat.com> wrote:
> 
>> So it really boils down to the semantics of Unsafe.CAS and that was
>> what you were asking earlier.
> 
> OK, thanks.  Thought so.
> 
> So, Back to you, Doug: what are the semantics of Unsafe.CAS ?
> 

Perhaps it would help to look at the implementation?

See method inline_unsafe_load_store in:

  http://hg.openjdk.java.net/jdk9/dev/hotspot/file/tip/src/share/vm/opto/library_call.cpp

Paul.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 841 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140220/cebcec5d/attachment.bin>

From peter.levart at gmail.com  Thu Feb 20 05:28:02 2014
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 20 Feb 2014 11:28:02 +0100
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>
	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>
	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>
	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>	<52ED59E2.7010301@cs.oswego.edu>	<53037E00.2060702@javaspecialists.eu>	<5304AD66.5050304@cs.oswego.edu>
	<CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>
Message-ID: <5305D8B2.5010602@gmail.com>


On 02/19/2014 08:51 PM, Zhong Yu wrote:
>      static ThreadLocalRandom random;
>
>      public static void main(String[] args) throws Exception
>      {
>          Thread t1 = new Thread( () ->
>              random=ThreadLocalRandom.current()
>          );
>          t1.start();
>          t1.join();
>
>          System.out.println( random.nextInt() ); // is the result random?
>      }

A 3rd possibility: If by thread-local variable we mean an object 
referenced by ThreadLocal(s), then Zhong Yu is right, such object(s) can 
often be safely accessed (used) by multiple threads if their access/use 
is synchronized. Not so with ThreadLocalRandom instance(s). So perhaps 
this should be spelled out in the javadoc. What about:

<p>Usages of this class should typically be of the form: {@code
ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
Int}, {@code Long}, etc).  When all usages are of this form, it is
never possible to accidentally *use a {@code ThreadLocalRandom} **instance
**in a thread that did not obtain it via a call to {@code 
ThreadLocalRandom.current()}.*
A {@code ThreadLocalRandom} instance should never be made
accessible to other threads by, for example, holding in a {@code
static} field*, even when access to and use of ***{@code 
ThreadLocalRandom} instance **
* is synchronized.* A {@code ThreadLocalRandom} used by multiple threads
need not (and typically will not) generate uniform random numbers.


Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140220/77386fbe/attachment.html>

From aph at redhat.com  Thu Feb 20 10:35:23 2014
From: aph at redhat.com (Andrew Haley)
Date: Thu, 20 Feb 2014 15:35:23 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCMEINKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCMEINKEAA.davidcholmes@aapt.net.au>
Message-ID: <530620BB.8020900@redhat.com>

On 02/20/2014 10:25 AM, David Holmes wrote:
> The volatile-read followed by volatile-write implicit in the CAS precludes
> any accesses before the cas appearing after, or vice-versa. I would appeal
> intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)

True enough, but that does not preclude, say, a write access to am
unrelated location appearing after the volatile read but before the
volatile write.  Does that matter?  I guess it must not, but it does
mean that the CAS may not be strictly atomic.

Andrew.


From adinn at redhat.com  Thu Feb 20 11:40:22 2014
From: adinn at redhat.com (Andrew Dinn)
Date: Thu, 20 Feb 2014 16:40:22 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530620BB.8020900@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCMEINKEAA.davidcholmes@aapt.net.au>
	<530620BB.8020900@redhat.com>
Message-ID: <53062FF6.5000106@redhat.com>

On 20/02/14 15:35, Andrew Haley wrote:
> On 02/20/2014 10:25 AM, David Holmes wrote:
>> The volatile-read followed by volatile-write implicit in the CAS precludes
>> any accesses before the cas appearing after, or vice-versa. I would appeal
>> intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)
> 
> True enough, but that does not preclude, say, a write access to am
> unrelated location appearing after the volatile read but before the
> volatile write.  Does that matter?  I guess it must not, but it does
> mean that the CAS may not be strictly atomic.

I cannot really see why that should be an issue except for broken code.
If the validity of changing some other location is dependent upon there
being an intermediate state of the thing being modified by the CAS for
some interval between the load acquire and store release then surely
that just means there is already a race?

regards,


Andrew Dinn
-----------


From davidcholmes at aapt.net.au  Thu Feb 20 17:35:08 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Fri, 21 Feb 2014 08:35:08 +1000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530620BB.8020900@redhat.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCKEJAKEAA.davidcholmes@aapt.net.au>

Andrew Haley writes:
> On 02/20/2014 10:25 AM, David Holmes wrote:
> > The volatile-read followed by volatile-write implicit in the
> CAS precludes
> > any accesses before the cas appearing after, or vice-versa. I
> would appeal
> > intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)
>
> True enough, but that does not preclude, say, a write access to am
> unrelated location appearing after the volatile read but before the
> volatile write.  Does that matter?  I guess it must not, but it does
> mean that the CAS may not be strictly atomic.

You raise an interesting point here. If your CAS is actually implemented
using ll/sc and your code has:

cmpxchg(a, oldval, newval);
x = 42;

then the "x=42" seems allowed to move between the ll and sc. Does that
matter? I don't see how.

If there was a conditional involved it would matter:

if (cmpxchg(a, oldval, newval))
  x = 42;

but then the control dependency should ensure that even a speculative store
does not escape. But I'm less clear on exactly what the JMM would say.

Perhaps we do need to say more about the atomicity of CAS with regard to the
associated volatile actions.

In the VM we require that CAS is implemented with a full fence.

David
-----

> Andrew.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Thu Feb 20 19:09:03 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 20 Feb 2014 19:09:03 -0500
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCKEJAKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCKEJAKEAA.davidcholmes@aapt.net.au>
Message-ID: <5306991F.4040200@cs.oswego.edu>

On 02/20/2014 05:35 PM, David Holmes wrote:
> Andrew Haley writes:
>> On 02/20/2014 10:25 AM, David Holmes wrote:
>>> The volatile-read followed by volatile-write implicit in the
>> CAS precludes
>>> any accesses before the cas appearing after, or vice-versa. I
>> would appeal
>>> intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)
>>
>> True enough, but that does not preclude, say, a write access to am
>> unrelated location appearing after the volatile read but before the
>> volatile write.  Does that matter?  I guess it must not, but it does
>> mean that the CAS may not be strictly atomic.
>
> You raise an interesting point here. If your CAS is actually implemented
> using ll/sc and your code has:
>
> cmpxchg(a, oldval, newval);
> x = 42;
>
> then the "x=42" seems allowed to move between the ll and sc. Does that
> matter? I don't see how.

As currently spec'ed (in javadoc, outside of the JMM that doesn't
cover CAS), it is clearly allowed, since the volatile load and
store specs are independently  met. I don't see any reason
this would change in any possible JMM updates.

-Doug

>
> If there was a conditional involved it would matter:
>
> if (cmpxchg(a, oldval, newval))
>    x = 42;
>
> but then the control dependency should ensure that even a speculative store
> does not escape. But I'm less clear on exactly what the JMM would say.
>
> Perhaps we do need to say more about the atomicity of CAS with regard to the
> associated volatile actions.
>
> In the VM we require that CAS is implemented with a full fence.
>
> David
> -----
>
>> Andrew.
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


From aph at redhat.com  Fri Feb 21 04:38:12 2014
From: aph at redhat.com (Andrew Haley)
Date: Fri, 21 Feb 2014 09:38:12 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <53062FF6.5000106@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCMEINKEAA.davidcholmes@aapt.net.au>
	<530620BB.8020900@redhat.com> <53062FF6.5000106@redhat.com>
Message-ID: <53071E84.6050609@redhat.com>

On 02/20/2014 04:40 PM, Andrew Dinn wrote:
> On 20/02/14 15:35, Andrew Haley wrote:
>> On 02/20/2014 10:25 AM, David Holmes wrote:
>>> The volatile-read followed by volatile-write implicit in the CAS precludes
>>> any accesses before the cas appearing after, or vice-versa. I would appeal
>>> intuitively to "roach motel" semantics but Aleksey would jump on me. ;-)
>>
>> True enough, but that does not preclude, say, a write access to am
>> unrelated location appearing after the volatile read but before the
>> volatile write.  Does that matter?  I guess it must not, but it does
>> mean that the CAS may not be strictly atomic.
> 
> I cannot really see why that should be an issue except for broken code.

Me either, but I'm trying to find out what the specification
actually means when it says "atomic".

> If the validity of changing some other location is dependent upon there
> being an intermediate state of the thing being modified by the CAS for
> some interval between the load acquire and store release then surely
> that just means there is already a race?

That sounds plausible.

Andrew.


From oleksandr.otenko at oracle.com  Fri Feb 21 09:50:10 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Fri, 21 Feb 2014 14:50:10 +0000
Subject: [concurrency-interest] TLR Puzzle
In-Reply-To: <5305C9C5.6040507@gmail.com>
References: <52EAA3FF.1020109@javaspecialists.eu>	<52EAACD3.8000405@oracle.com>	<52EABDB4.1030409@cs.oswego.edu>	<52EAC246.1080606@oracle.com>	<52EB9050.7050503@cs.oswego.edu>	<52EB9C47.3080908@javaspecialists.eu>	<52EBA6E3.2060707@cs.oswego.edu>	<52EBB034.3000305@oracle.com>	<CAMyLHFzoZutsZq+dzLo--yHSQL-Rf-JusBq3xLk1LmdGj2+Yjg@mail.gmail.com>	<52EBBB46.5080002@javaspecialists.eu>	<CACuKZqGMiz+CWX7v94ZzKU44chicVKsBZGMFvpcXumV5L3+orA@mail.gmail.com>	<52EBE1F9.9030206@javaspecialists.eu>	<52ED59E2.7010301@cs.oswego.edu>	<53037E00.2060702@javaspecialists.eu>	<5304AD66.5050304@cs.oswego.edu>	<CACuKZqGEZAzKDCfY5v+pSZUnpLKxMwGRau8Y0p7ywcgjfWdquQ@mail.gmail.com>
	<5305C9C5.6040507@gmail.com>
Message-ID: <530767A2.4080104@oracle.com>

+1

Let's not forget that ThreadLocal that "can't be shared" is actually 
just the container. The container, yes, cannot be shared. But the value 
contained therein.... I can't recall any design consideration requiring 
or making it impossible to restrict access to the actual value, over 
which there is no control after ThreadLocal.get(). (also, we have 
ThreadLocal.set() - we can even change the value referenced; and 
InheritableThreadLocal, which by default copies over the Parent's value)

Alex

On 20/02/2014 09:24, Peter Levart wrote:
>
> On 02/19/2014 08:51 PM, Zhong Yu wrote:
>> Typically, a thread-local variable could be handed over to another
>> thread, with proper happens-before edge.
>
> What *is* a thread-local variable? Java does not have such thing. It 
> only has local variables, instance and static fields. If by 
> thread-local variable we mean a ThreadLocal object, then such 
> instances are usually meant to be shared by multiple threads. Contrary 
> to ThreadLocalRandom instance(s) which are better not (considering 
> current implementation and possible future changes). If by 
> thread-local variable we mean a state, associated with the pair 
> (ThreadLocal object, current thread) then the API itself makes it 
> impossible to share this state across threads. So the following 
> wording is a little confusing, I think:
>
>
> <p>Usages of this class should typically be of the form: {@code
> ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
> Int}, {@code Long}, etc).  When all usages are of this form, it is
> never possible to accidentally share a {@code ThreadLocalRandom}
> across multiple threads. *As is the case for any thread-local **
> **variable, a {@code ThreadLocalRandom} should never be made **
> **accessible to other threads* by, for example, holding in a {@code
> static} field. A {@code ThreadLocalRandom} used by multiple threads
> need not (and typically will not) generate uniform random numbers.
>
>
> So I think it would be better to remove the "As is the case for any 
> thread-local
> variable, " part of the sentence. The rest makes perfect sense.
>
>
> Regards, Peter
>
>> The current impl of TLR
>> cannot do that due to its peculiar mechanism of initialization. So I
>> don't think it's enough to let users reason about it like a normal
>> ThreadLocal.
>>
>> Here's an example:
>>
>>      static ThreadLocalRandom random;
>>
>>      public static void main(String[] args) throws Exception
>>      {
>>          Thread t1 = new Thread( () ->
>>              random=ThreadLocalRandom.current()
>>          );
>>          t1.start();
>>          t1.join();
>>
>>          System.out.println( random.nextInt() ); // is the result random?
>>      }
>>
>> Zhong Yu
>>
>>
>> On Wed, Feb 19, 2014 at 7:11 AM, Doug Lea<dl at cs.oswego.edu>  wrote:
>>> On 02/18/2014 10:36 AM, Dr Heinz M. Kabutz wrote:
>>>> A little newsletter on this subject to warn my readers to never let their
>>>> ThreadLocalRandom instances escape.
>>>> http://www.javaspecialists.eu/archive/Issue218.html
>>> Thanks. Here's added javadoc that should someday be folded
>>> in. We still do not want to specify exactly what happens if
>>> you leak this or any other thread-local, since this might
>>> be subject to change over time in either TLR or ThreadLocal.
>>>
>>>     * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>>>     * in parallel in thread pools.
>>>     *
>>> !  * <p>Usages of this class should typically be of the form:
>>> !  * {@code ThreadLocalRandom.current().nextX(...)} (where
>>> !  * {@code X} is {@code Int}, {@code Long}, etc).
>>> !  * When all usages are of this form, it is never possible to
>>> !  * accidently share a {@code ThreadLocalRandom} across multiple threads.
>>>     *
>>>     * <p>This class also provides additional commonly used bounded random
>>>     * generation methods.
>>> --- 33,47 ----
>>>     * tasks (for example, each a {@link ForkJoinTask}) use random numbers
>>>     * in parallel in thread pools.
>>>     *
>>> !  * <p>Usages of this class should typically be of the form: {@code
>>> !  * ThreadLocalRandom.current().nextX(...)} (where {@code X} is {@code
>>> !  * Int}, {@code Long}, etc).  When all usages are of this form, it is
>>> !  * never possible to accidentally share a {@code ThreadLocalRandom}
>>> !  * across multiple threads.  As is the case for any thread-local
>>> !  * variable, a {@code ThreadLocalRandom} should never be made
>>> !  * accessible to other threads by, for example, holding in a {@code
>>> !  * static} field. A {@code ThreadLocalRandom} used by multiple threads
>>> !  * need not (and typically will not) generate uniform random numbers.
>>>
>>>     *
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140221/e5dd50d5/attachment.html>

From martinrb at google.com  Fri Feb 21 14:41:20 2014
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 21 Feb 2014 11:41:20 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
Message-ID: <CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>

Summary: I support ????????'s suggestion of creating COWAList.snapshot().
 I'm the obvious person to implement that, and I hope to do so sometime
during jdk9 development.


On Wed, Feb 19, 2014 at 11:55 AM, Martin Buchholz <martinrb at google.com>wrote:

> ????????,
>
> I agree that a snapshot method as you propose would be useful.  As always,
> implementing the List interface ends up being rather a lot of tedious work,
> which may be a reason it never got done.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140221/077c027c/attachment.html>

From martinrb at google.com  Fri Feb 21 15:12:14 2014
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 21 Feb 2014 12:12:14 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>
Message-ID: <CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>

The v0.1 implementation was surprisingly easy:

Index: src/main/java/util/concurrent/CopyOnWriteArrayList.java
===================================================================
RCS file:
/export/home/jsr166/jsr166/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java,v
retrieving revision 1.115
diff -u -r1.115 CopyOnWriteArrayList.java
--- src/main/java/util/concurrent/CopyOnWriteArrayList.java 31 Jan 2014
17:58:35 -0000 1.115
+++ src/main/java/util/concurrent/CopyOnWriteArrayList.java 21 Feb 2014
20:10:39 -0000
@@ -1644,4 +1644,22 @@
             throw new Error(e);
         }
     }
+
+    // Support for read-only snapshots
+    /**
+     * Returns an immutable list snapshot of this list.
+     * @return an immutable list snapshot of this list
+     */
+    public List<E> snapshot() {
+        return new Snapshot<E>(getArray());
+    }
+
+    @SuppressWarnings("unchecked")
+    private static class Snapshot<E> extends AbstractList<E> {
+        private final Object[] elements;
+        public Snapshot(Object[] elements) { this.elements = elements; }
+        @Override public E get(int index) { return (E) elements[index]; }
+        @Override public int size() { return elements.length; }
+        @Override public Object[] toArray() { return elements.clone(); }
+    }
 }



On Fri, Feb 21, 2014 at 11:41 AM, Martin Buchholz <martinrb at google.com>wrote:

> Summary: I support ????????'s suggestion of creating COWAList.snapshot().
>  I'm the obvious person to implement that, and I hope to do so sometime
> during jdk9 development.
>
>
>
> On Wed, Feb 19, 2014 at 11:55 AM, Martin Buchholz <martinrb at google.com>wrote:
>
>> ????????,
>>
>> I agree that a snapshot method as you propose would be useful.  As
>> always, implementing the List interface ends up being rather a lot of
>> tedious work, which may be a reason it never got done.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140221/d62c7baf/attachment.html>

From jason_mehrens at hotmail.com  Fri Feb 21 18:17:33 2014
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Fri, 21 Feb 2014 17:17:33 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>,
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>,
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>,
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>,
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>,
	<CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
Message-ID: <BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>

Martin,
Looks correct. Since the snapshot can't change I assume it should implement RandomAccess? Maybe override iterator() and listIterator() to return COWIterator for fun and profit?
As Henri pointed out, you can use Collections.unmodifiableList(Arrays.asList(getArray())). Arrays.asList doesn't perform any safe coping of the input array.

Jason
________________________________
> Date: Fri, 21 Feb 2014 12:12:14 -0800
> Subject: Re: [concurrency-interest] COWList snapshot.
> From: martinrb at google.com
> To: ppozerov at gmail.com
> CC: jason_mehrens at hotmail.com; concurrency-interest at cs.oswego.edu
>
> The v0.1 implementation was surprisingly easy:
>
> Index: src/main/java/util/concurrent/CopyOnWriteArrayList.java
> ===================================================================
> RCS file:
> /export/home/jsr166/jsr166/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java,v
> retrieving revision 1.115
> diff -u -r1.115 CopyOnWriteArrayList.java
> --- src/main/java/util/concurrent/CopyOnWriteArrayList.java 31 Jan 2014
> 17:58:35 -0000 1.115
> +++ src/main/java/util/concurrent/CopyOnWriteArrayList.java 21 Feb 2014
> 20:10:39 -0000
> @@ -1644,4 +1644,22 @@
> throw new Error(e);
> }
> }
> +
> + // Support for read-only snapshots
> + /**
> + * Returns an immutable list snapshot of this list.
> + * @return an immutable list snapshot of this list
> + */
> + public List<E> snapshot() {
> + return new Snapshot<E>(getArray());
> + }
> +
> + @SuppressWarnings("unchecked")
> + private static class Snapshot<E> extends AbstractList<E> {
> + private final Object[] elements;
> + public Snapshot(Object[] elements) { this.elements = elements; }
> + @Override public E get(int index) { return (E) elements[index]; }
> + @Override public int size() { return elements.length; }
> + @Override public Object[] toArray() { return elements.clone(); }
> + }
> }
>
>
>
> On Fri, Feb 21, 2014 at 11:41 AM, Martin Buchholz
> <martinrb at google.com<mailto:martinrb at google.com>> wrote:
> Summary: I support ????????'s suggestion of creating
> COWAList.snapshot(). I'm the obvious person to implement that, and I
> hope to do so sometime during jdk9 development.
>
>
>
> On Wed, Feb 19, 2014 at 11:55 AM, Martin Buchholz
> <martinrb at google.com<mailto:martinrb at google.com>> wrote:
> ????????,
>
> I agree that a snapshot method as you propose would be useful. As
> always, implementing the List interface ends up being rather a lot of
> tedious work, which may be a reason it never got done.
> 		 	   		  

From martinrb at google.com  Fri Feb 21 18:44:45 2014
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 21 Feb 2014 15:44:45 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>
	<CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
	<BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>
Message-ID: <CA+kOe08oOhP2j-tKco=nMb10j6Ztev4iYsDkDLJnfJpoW=uuhg@mail.gmail.com>

v 0.2

Amazing how much immutability simplifies the life of a collections
implementer.

Index: src/main/java/util/concurrent/CopyOnWriteArrayList.java
===================================================================
RCS file:
/export/home/jsr166/jsr166/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java,v
retrieving revision 1.115
diff -u -r1.115 CopyOnWriteArrayList.java
--- src/main/java/util/concurrent/CopyOnWriteArrayList.java 31 Jan 2014
17:58:35 -0000 1.115
+++ src/main/java/util/concurrent/CopyOnWriteArrayList.java 21 Feb 2014
23:42:02 -0000
@@ -1628,6 +1628,104 @@
         }
     }

+    // Support for read-only snapshots
+
+    /**
+     * Returns an immutable list snapshot of this list.
+     * @return an immutable list snapshot of this list
+     */
+    public List<E> snapshot() {
+        return new Snapshot<E>(getArray());
+    }
+
+    @SuppressWarnings("unchecked")
+    private static class Snapshot<E> extends AbstractList<E>
+        implements RandomAccess {
+        private final Object[] elements;
+        public Snapshot(Object[] elements) { this.elements = elements; }
+        @Override public E get(int index) { return (E) elements[index]; }
+        @Override public int size() { return elements.length; }
+        @Override public Object[] toArray() { return elements.clone(); }
+        @Override  public <T> T[] toArray(T[] a) {
+            final int size = size();
+            if (a.length < size)
+                return (T[]) Arrays.copyOf(elements, size, a.getClass());
+            System.arraycopy(elements, 0, a, 0, size);
+            if (a.length > size)
+                a[size] = null;
+            return a;
+        }
+        @Override public int indexOf(Object o) {
+            final int size = size();
+            if (o == null) {
+                for (int i = 0; i < size; i++)
+                    if (elements[i] == null)
+                        return i;
+            } else {
+                for (int i = 0; i < size; i++)
+                    if (o.equals(elements[i]))
+                        return i;
+            }
+            return -1;
+        }
+        @Override public int lastIndexOf(Object o) {
+            final int size = size();
+            if (o == null) {
+                for (int i = size - 1; i >= 0; i++)
+                    if (elements[i] == null)
+                        return i;
+            } else {
+                for (int i = size - 1; i >= 0; i++)
+                    if (o.equals(elements[i]))
+                        return i;
+            }
+            return -1;
+        }
+        @Override public boolean contains(Object o) {
+            final int size = size();
+            if (o == null) {
+                for (int i = 0; i < size; i++)
+                    if (elements[i] == null)
+                        return true;
+            } else {
+                for (int i = 0; i < size; i++)
+                    if (o.equals(elements[i]))
+                        return true;
+            }
+            return false;
+        }
+        @Override public Iterator<E> iterator() { return new Itr(0); }
+        @Override public ListIterator<E> listIterator() { return new
Itr(0); }
+        @Override public ListIterator<E> listIterator(int index) { return
new Itr(index); }
+
+        private class Itr implements ListIterator<E> {
+            private int cursor;
+            private int lastRet = -1;
+            Itr(int cursor) { this.cursor = cursor; }
+            @Override public boolean hasNext() { return cursor < size(); }
+            @Override public boolean hasPrevious() { return cursor > 0; }
+            @Override public int nextIndex() { return cursor; }
+            @Override public int previousIndex() { return cursor - 1; }
+            @Override public E next() {
+                if (!hasNext()) throw new NoSuchElementException();
+                return (E) elements[lastRet = ++cursor];
+            }
+            @Override public E previous() {
+                if (!hasPrevious()) throw new NoSuchElementException();
+                return (E) elements[lastRet = --cursor];
+            }
+            @Override public void set(E e) {
+                throw new UnsupportedOperationException();
+            }
+            @Override public void add(E e) {
+                throw new UnsupportedOperationException();
+            }
+            @Override public void remove() {
+                throw new UnsupportedOperationException();
+            }
+        }
+    }
+
     // Support for resetting lock while deserializing
     private void resetLock() {
         UNSAFE.putObjectVolatile(this, lockOffset, new ReentrantLock());



On Fri, Feb 21, 2014 at 3:17 PM, Jason Mehrens <jason_mehrens at hotmail.com>wrote:

> Martin,
> Looks correct. Since the snapshot can't change I assume it should
> implement RandomAccess? Maybe override iterator() and listIterator() to
> return COWIterator for fun and profit?
> As Henri pointed out, you can use
> Collections.unmodifiableList(Arrays.asList(getArray())). Arrays.asList
> doesn't perform any safe coping of the input array.
>
> Jason
> ________________________________
> > Date: Fri, 21 Feb 2014 12:12:14 -0800
> > Subject: Re: [concurrency-interest] COWList snapshot.
> > From: martinrb at google.com
> > To: ppozerov at gmail.com
> > CC: jason_mehrens at hotmail.com; concurrency-interest at cs.oswego.edu
> >
> > The v0.1 implementation was surprisingly easy:
> >
> > Index: src/main/java/util/concurrent/CopyOnWriteArrayList.java
> > ===================================================================
> > RCS file:
> >
> /export/home/jsr166/jsr166/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java,v
> > retrieving revision 1.115
> > diff -u -r1.115 CopyOnWriteArrayList.java
> > --- src/main/java/util/concurrent/CopyOnWriteArrayList.java 31 Jan 2014
> > 17:58:35 -0000 1.115
> > +++ src/main/java/util/concurrent/CopyOnWriteArrayList.java 21 Feb 2014
> > 20:10:39 -0000
> > @@ -1644,4 +1644,22 @@
> > throw new Error(e);
> > }
> > }
> > +
> > + // Support for read-only snapshots
> > + /**
> > + * Returns an immutable list snapshot of this list.
> > + * @return an immutable list snapshot of this list
> > + */
> > + public List<E> snapshot() {
> > + return new Snapshot<E>(getArray());
> > + }
> > +
> > + @SuppressWarnings("unchecked")
> > + private static class Snapshot<E> extends AbstractList<E> {
> > + private final Object[] elements;
> > + public Snapshot(Object[] elements) { this.elements = elements; }
> > + @Override public E get(int index) { return (E) elements[index]; }
> > + @Override public int size() { return elements.length; }
> > + @Override public Object[] toArray() { return elements.clone(); }
> > + }
> > }
> >
> >
> >
> > On Fri, Feb 21, 2014 at 11:41 AM, Martin Buchholz
> > <martinrb at google.com<mailto:martinrb at google.com>> wrote:
> > Summary: I support ????????'s suggestion of creating
> > COWAList.snapshot(). I'm the obvious person to implement that, and I
> > hope to do so sometime during jdk9 development.
> >
> >
> >
> > On Wed, Feb 19, 2014 at 11:55 AM, Martin Buchholz
> > <martinrb at google.com<mailto:martinrb at google.com>> wrote:
> > ????????,
> >
> > I agree that a snapshot method as you propose would be useful. As
> > always, implementing the List interface ends up being rather a lot of
> > tedious work, which may be a reason it never got done.
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140221/dccb8df8/attachment-0001.html>

From martinrb at google.com  Fri Feb 21 18:55:59 2014
From: martinrb at google.com (Martin Buchholz)
Date: Fri, 21 Feb 2014 15:55:59 -0800
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>
	<CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
	<BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>
Message-ID: <CA+kOe0_yFUUrr37mT_NdHuDaBZkuDYkgyakOcfZ+P_DMU3FksQ@mail.gmail.com>

On Fri, Feb 21, 2014 at 3:17 PM, Jason Mehrens <jason_mehrens at hotmail.com>wrote:

> Martin,
> Looks correct. Since the snapshot can't change I assume it should
> implement RandomAccess? Maybe override iterator() and listIterator() to
> return COWIterator for fun and profit?
>

Immutable List iterator is much simpler.


> As Henri pointed out, you can use
> Collections.unmodifiableList(Arrays.asList(getArray())). Arrays.asList
> doesn't perform any safe coping of the input array.
>
>
Ohhh, light bulb just lit up.... ding ding ding ... Yeah, that does indeed
look very simple...

Back to the drawing board.  We add the much more fundamental
Arrays.asImmutableList(T...) that everyone has been asking for elsewhere,
and then
COWAList.snapshot can return Arrays.asImmutableList(getArray())
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140221/a3a5666d/attachment.html>

From kasperni at gmail.com  Sat Feb 22 17:23:44 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Sat, 22 Feb 2014 23:23:44 +0100
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>
	<CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>
Message-ID: <CAPs61512Y5A4-QjnH=ZPRGbxA-yXHuJe5cCuCHnduO-xGQJ_qQ@mail.gmail.com>

For consistency you might also want to add a CopyOnWriteArraySet.snapshot()?
Also unlike CopyOnWriteArrayList, CopyOnWriteArraySet does not implement
Cloneable.
Finally, CopyOnWriteArraySet.eq can be replaced by Objects.equals



On Fri, Feb 21, 2014 at 9:12 PM, Martin Buchholz <martinrb at google.com>wrote:

> The v0.1 implementation was surprisingly easy:
>
> Index: src/main/java/util/concurrent/CopyOnWriteArrayList.java
> ===================================================================
> RCS file:
> /export/home/jsr166/jsr166/jsr166/src/main/java/util/concurrent/CopyOnWriteArrayList.java,v
> retrieving revision 1.115
> diff -u -r1.115 CopyOnWriteArrayList.java
> --- src/main/java/util/concurrent/CopyOnWriteArrayList.java 31 Jan 2014
> 17:58:35 -0000 1.115
> +++ src/main/java/util/concurrent/CopyOnWriteArrayList.java 21 Feb 2014
> 20:10:39 -0000
> @@ -1644,4 +1644,22 @@
>              throw new Error(e);
>          }
>      }
> +
> +    // Support for read-only snapshots
> +    /**
> +     * Returns an immutable list snapshot of this list.
> +     * @return an immutable list snapshot of this list
> +     */
> +    public List<E> snapshot() {
> +        return new Snapshot<E>(getArray());
> +    }
> +
> +    @SuppressWarnings("unchecked")
> +    private static class Snapshot<E> extends AbstractList<E> {
> +        private final Object[] elements;
> +        public Snapshot(Object[] elements) { this.elements = elements; }
> +        @Override public E get(int index) { return (E) elements[index]; }
> +        @Override public int size() { return elements.length; }
> +        @Override public Object[] toArray() { return elements.clone(); }
> +    }
>  }
>
>
>
> On Fri, Feb 21, 2014 at 11:41 AM, Martin Buchholz <martinrb at google.com>wrote:
>
>> Summary: I support ????????'s suggestion of creating COWAList.snapshot().
>>  I'm the obvious person to implement that, and I hope to do so sometime
>> during jdk9 development.
>>
>>
>>
>> On Wed, Feb 19, 2014 at 11:55 AM, Martin Buchholz <martinrb at google.com>wrote:
>>
>>> ????????,
>>>
>>> I agree that a snapshot method as you propose would be useful.  As
>>> always, implementing the List interface ends up being rather a lot of
>>> tedious work, which may be a reason it never got done.
>>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140222/077d41eb/attachment.html>

From bryan at systap.com  Mon Feb 24 07:27:48 2014
From: bryan at systap.com (Bryan Thompson)
Date: Mon, 24 Feb 2014 06:27:48 -0600
Subject: [concurrency-interest] Subject: Re:  ConcurrentHashMapV8
In-Reply-To: <4E903BCA.7090104@cs.oswego.edu>
References: <mailman.43.1318032593.6569.concurrency-interest@cs.oswego.edu>
	<1318069569.1648.24.camel@bluto> <4E903BCA.7090104@cs.oswego.edu>
Message-ID: <CF30A3E0.97528%bryan@systap.com>

Could I get a pointer to how parallel iterators will be introduced into
the existing classes or abstractions?  I am running into an issue now
where the slowest stage of a parallel graph traversal is the sequential
reduction over the visited vertices after the traversal is finished and it
is time to extract an answer.  The visited vertices are stored in a
ConcurrentHashMap during the traversal, but there is no means available to
extract them in parallel right now.

It seems like the short term solution would be to drop them onto stripped
lists at the same time that they are first inserted into the CHM.  I could
then read over those striped lists in parallel during the reduction.

Are there better alternatives in the works?


Thanks,
Bryan

On 10/8/11 8:02 AM, "Doug Lea" <dl at cs.oswego.edu> wrote:

>But with the advent of lambdas and bulk parallel operations,
>it might be worth considering this as a way of supporting
>stream-style processing in addition to forEach-style processing.
>Which would amount to giving people two choices for how they'd
>like to replace all their sequential iterator code. Or,
>to allow gradual adoption at the expense of messiness,
>supporting all three styles.



From kasperni at gmail.com  Mon Feb 24 07:56:01 2014
From: kasperni at gmail.com (Kasper Nielsen)
Date: Mon, 24 Feb 2014 13:56:01 +0100
Subject: [concurrency-interest] Subject: Re: ConcurrentHashMapV8
In-Reply-To: <CF30A3E0.97528%bryan@systap.com>
References: <mailman.43.1318032593.6569.concurrency-interest@cs.oswego.edu>
	<1318069569.1648.24.camel@bluto> <4E903BCA.7090104@cs.oswego.edu>
	<CF30A3E0.97528%bryan@systap.com>
Message-ID: <CAPs6152O37vKSPyz93XkMBcLyvYDE93NgdpE_2u5fgpJeygWMg@mail.gmail.com>

On Mon, Feb 24, 2014 at 1:27 PM, Bryan Thompson <bryan at systap.com> wrote:

> Could I get a pointer to how parallel iterators will be introduced into
> the existing classes or abstractions?  I am running into an issue now
> where the slowest stage of a parallel graph traversal is the sequential
> reduction over the visited vertices after the traversal is finished and it
> is time to extract an answer.  The visited vertices are stored in a
> ConcurrentHashMap during the traversal, but there is no means available to
> extract them in parallel right now.
>

Have you taken a look at CHM in jsr166e/Java8?
Around 20 new methods in CHM for parallel iteration/reduction.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140224/0d049a0d/attachment.html>

From oleksandr.otenko at oracle.com  Mon Feb 24 09:47:23 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 24 Feb 2014 14:47:23 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <5305CF73.7040500@redhat.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com>
Message-ID: <530B5B7B.1050103@oracle.com>

Hmmm...

Can someone clarify this issue? I don't know ARM instructions, yet it 
seems the discussion contradicts itself.

This here observation summarizes that "GCC's usage of ....<instruction 
sequence> is ok" despite it not being a full barrier, and that the 
reordering of memop_A and memop_C before and after CAS respectively, is 
allowed.

Yet further in the discussion Doug mentions it is meant to be a volatile 
read+volatile write, which would preclude the reordering of memop_A and 
memop_C.

So, is that reordering allowed or not?

Alex


On 20/02/2014 09:48, Andrew Haley wrote:
> On 02/19/2014 08:40 PM, Stephan Diestelhorst wrote:
>> On 18 February 2014 12:56, Andrew Haley <aph at redhat.com> wrote:
>>> On 02/14/2014 01:51 PM, Stephan Diestelhorst wrote:
>>>> I am currently following up inside ARM about this, stay tuned.
>>> Any news?
>> Yes, so my original understanding was too simplistic.  In the
>> sequence of memop_A; ldx.acq(B) ;... ; stx.rel(B); memopp_C we may
>> indeed observe a lack of ordering between memop_A and memop_C.  So
>> the instruction sequence is not meant to be a full-fence
>> replacement.  This is, however, consistent with our manuals, and the
>> implementation of the C++11 atomics, and the notion of sequential
>> consistency of atomics.
> Thank you.
>
> So, GCC's usage of ldaxr ... stlxr for CAS is OK, even though it
> doesn't completely enforce a full fence.  This is interesting.  I
> wonder how anyone (not on the language committee :-) is expected to
> know this.  Maybe they're not, and there is going to be some
> interesting confusion when people try to port software from Intel to
> ARM.
>
>> So it really boils down to the semantics of Unsafe.CAS and that was
>> what you were asking earlier.
> OK, thanks.  Thought so.
>
> So, Back to you, Doug: what are the semantics of Unsafe.CAS ?
>
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From jason_mehrens at hotmail.com  Mon Feb 24 10:30:39 2014
From: jason_mehrens at hotmail.com (Jason Mehrens)
Date: Mon, 24 Feb 2014 09:30:39 -0600
Subject: [concurrency-interest] COWList snapshot.
In-Reply-To: <CA+kOe0_yFUUrr37mT_NdHuDaBZkuDYkgyakOcfZ+P_DMU3FksQ@mail.gmail.com>
References: <CAJJmzpWJOqf0o3aEmcQz6jK9j5=YUd11W7Q4wQGxw1FJ6dDtow@mail.gmail.com>,
	<BLU175-W304EE3E8D14D2A28BDA2A3839B0@phx.gbl>,
	<CAJJmzpU8GYUhDdgK3hTpj9-FyqbUmHku5js5f27SvrEiuSpzKw@mail.gmail.com>,
	<CA+kOe08Wk-NiX7eTGBTQAUBFRBjZkiNk32MtQ_tzTtN8kSeZjQ@mail.gmail.com>,
	<CA+kOe0_KTpt-9bE1VZLbyON57+rqpmYWJj9MJEF-t=O8smZx5g@mail.gmail.com>,
	<CA+kOe0-S+GVBJqdT4kzhzHwpfPtp-9PJb4G_ep6CWx9LyJhYWw@mail.gmail.com>,
	<BLU175-W351F17CEB86BD50A23DA2283850@phx.gbl>,
	<CA+kOe0_yFUUrr37mT_NdHuDaBZkuDYkgyakOcfZ+P_DMU3FksQ@mail.gmail.com>
Message-ID: <BLU175-W35139A5C3B78451EB208A083860@phx.gbl>

Martin,
 
Arrays.asImmutableList that seems like the way to go about doing this.
 
My understanding is that COWIterator is a read-only and therefore would have been acceptable for use in the previous case.
=========================================
new CopyOnWriteArrayList().iterator().remove();
=========================================
Exception in thread "main" java.lang.UnsupportedOperationException
 at java.util.concurrent.CopyOnWriteArrayList$COWIterator.remove(CopyOnWriteArrayList.java:1040)
=========================================

Might be worth adding Arrays.asImmutableListIterator which would allow the removal of the COWIterator class.

Jason
 
________________________________
> Date: Fri, 21 Feb 2014 15:55:59 -0800 
> Subject: Re: [concurrency-interest] COWList snapshot. 
> From: martinrb at google.com 
> To: jason_mehrens at hotmail.com 
> CC: concurrency-interest at cs.oswego.edu 
> 
> 
> 
> 
> On Fri, Feb 21, 2014 at 3:17 PM, Jason Mehrens 
> <jason_mehrens at hotmail.com<mailto:jason_mehrens at hotmail.com>> wrote: 
> Martin, 
> Looks correct. Since the snapshot can't change I assume it should 
> implement RandomAccess? Maybe override iterator() and listIterator() to 
> return COWIterator for fun and profit? 
> 
> Immutable List iterator is much simpler. 
> 
> As Henri pointed out, you can use 
> Collections.unmodifiableList(Arrays.asList(getArray())). Arrays.asList 
> doesn't perform any safe coping of the input array. 
> 
> 
> Ohhh, light bulb just lit up.... ding ding ding ... Yeah, that does 
> indeed look very simple... 
> 
> Back to the drawing board. We add the much more fundamental 
> Arrays.asImmutableList(T...) that everyone has been asking for 
> elsewhere, and then 
> COWAList.snapshot can return Arrays.asImmutableList(getArray()) 
> 		 	   		  

From martinrb at google.com  Mon Feb 24 11:08:41 2014
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 24 Feb 2014 08:08:41 -0800
Subject: [concurrency-interest] Subject: Re: ConcurrentHashMapV8
In-Reply-To: <CAKh+yi9Pe0=pAJ9D-B78SuqLc_cKG94+Xi=r6Rh5RZbQ7QfROw@mail.gmail.com>
References: <mailman.43.1318032593.6569.concurrency-interest@cs.oswego.edu>
	<1318069569.1648.24.camel@bluto> <4E903BCA.7090104@cs.oswego.edu>
	<CAKh+yi9Pe0=pAJ9D-B78SuqLc_cKG94+Xi=r6Rh5RZbQ7QfROw@mail.gmail.com>
Message-ID: <CA+kOe08+BygvPG6TNPG9rekpMnTnrLg5+PLc3CLQAytsEbrFaQ@mail.gmail.com>

On Sun, Oct 9, 2011 at 2:32 PM, Jed Wesley-Smith <jwesleysmith at atlassian.com
> wrote:

> The functional/persistent Stream interface is a great alternative that
> doesn't rely on null being magic:
>
> Stream<T> {
>   T get(); // throws if empty aka head()
>   Stream<T> next(); // aka tail()
>   boolean isEmpty();
> }
>
> implementations can be strict or lazy, but each actual instance is
> referentially transparent.
>

I don't quite understand this - it seems to reintroduce the atomicity
problem of Iterator hasNext/next.  Iterators solve this (annoyingly for the
implementer) by creating a one-element buffer to hold the promised next
element, and this would have to do likewise?  Or else isEmpty is just a
hint?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140224/5fc74ae2/attachment.html>

From aph at redhat.com  Mon Feb 24 12:13:06 2014
From: aph at redhat.com (Andrew Haley)
Date: Mon, 24 Feb 2014 17:13:06 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530B5B7B.1050103@oracle.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com> <530B5B7B.1050103@oracle.com>
Message-ID: <530B7DA2.7020704@redhat.com>

On 02/24/2014 02:47 PM, Oleksandr Otenko wrote:
> Hmmm...
> 
> Can someone clarify this issue? I don't know ARM instructions, yet it 
> seems the discussion contradicts itself.
> 
> This here observation summarizes that "GCC's usage of ....<instruction 
> sequence> is ok" despite it not being a full barrier, and that the 
> reordering of memop_A and memop_C before and after CAS respectively, is 
> allowed.
> 
> Yet further in the discussion Doug mentions it is meant to be a volatile 
> read+volatile write, which would preclude the reordering of memop_A and 
> memop_C.
> 
> So, is that reordering allowed or not?

Not by Java, no.  A ldx.acq ... stx.rel is not enough for Java's
compareAndSwap.  We are sure about that.

However, according to Stephan Diestelhorst it *is* enough for the
implementation of the C++11 atomics, and the notion of sequential
consistency of atomics.

I do not know what Stephan bases that claim on.

Andrew.

From boehm at acm.org  Tue Feb 25 11:21:42 2014
From: boehm at acm.org (Hans Boehm)
Date: Tue, 25 Feb 2014 08:21:42 -0800
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530B7DA2.7020704@redhat.com>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
	<53039EC0.7060100@redhat.com>
	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com> <530B5B7B.1050103@oracle.com>
	<530B7DA2.7020704@redhat.com>
Message-ID: <CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>

Could someone post a test case that they think should work, but that
doesn't work with the acquire/release implementation (without added
fences)?  Clearly it does not work as a general purpose fence replacement,
e.g. when used on an object accessed by only one thread.  But I hope that
was not intended.  It does seem to me that it does preserve the property
that properly synchronized programs are sequentially consistent.

It seems to have the same synchronization properties as if all operations
on an atomic class were implemented with locks.  This is clearly allowed
for C++, and I would have presumed that it's intended to be allowed for
j.u.c.

Definitive answers here would be a lot easier if we had more precise
specifications, both for Java and the ARMv8 ISA.

Hans


On Mon, Feb 24, 2014 at 9:13 AM, Andrew Haley <aph at redhat.com> wrote:

> On 02/24/2014 02:47 PM, Oleksandr Otenko wrote:
> > Hmmm...
> >
> > Can someone clarify this issue? I don't know ARM instructions, yet it
> > seems the discussion contradicts itself.
> >
> > This here observation summarizes that "GCC's usage of ....<instruction
> > sequence> is ok" despite it not being a full barrier, and that the
> > reordering of memop_A and memop_C before and after CAS respectively, is
> > allowed.
> >
> > Yet further in the discussion Doug mentions it is meant to be a volatile
> > read+volatile write, which would preclude the reordering of memop_A and
> > memop_C.
> >
> > So, is that reordering allowed or not?
>
> Not by Java, no.  A ldx.acq ... stx.rel is not enough for Java's
> compareAndSwap.  We are sure about that.
>
> However, according to Stephan Diestelhorst it *is* enough for the
> implementation of the C++11 atomics, and the notion of sequential
> consistency of atomics.
>
> I do not know what Stephan bases that claim on.
>
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140225/024ddec0/attachment.html>

From oleksandr.otenko at oracle.com  Tue Feb 25 12:45:20 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Tue, 25 Feb 2014 17:45:20 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>
	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>
Message-ID: <530CD6B0.2050504@oracle.com>

Not sure what you are asking for - a Java or C++ example? (I don't know 
C++ semantics)

But emptying a cyclic buffer is a example where CAS must behave at least 
as a volatile store:

long w_pos; // updated in a synchronized block
AtomicLong r_pos;
Object [] array;
...

long r;
while ((r = r_pos.get()) != w_pos) {
   Object v = array[(int)(r % array.length)];
   if (r_pos.compareAndSet(r, r+1)) return v;
}

If r_pos.compareAndSet does not have barriers of a volatile store, then 
volatile loads are hoistable.

Alex


On 25/02/2014 16:21, Hans Boehm wrote:
> Could someone post a test case that they think should work, but that 
> doesn't work with the acquire/release implementation (without added 
> fences)?  Clearly it does not work as a general purpose fence 
> replacement, e.g. when used on an object accessed by only one thread. 
>  But I hope that was not intended.  It does seem to me that it does 
> preserve the property that properly synchronized programs are 
> sequentially consistent.
>
> It seems to have the same synchronization properties as if all 
> operations on an atomic class were implemented with locks.  This is 
> clearly allowed for C++, and I would have presumed that it's intended 
> to be allowed for j.u.c.
>
> Definitive answers here would be a lot easier if we had more precise 
> specifications, both for Java and the ARMv8 ISA.
>
> Hans
>
>
> On Mon, Feb 24, 2014 at 9:13 AM, Andrew Haley <aph at redhat.com 
> <mailto:aph at redhat.com>> wrote:
>
>     On 02/24/2014 02:47 PM, Oleksandr Otenko wrote:
>     > Hmmm...
>     >
>     > Can someone clarify this issue? I don't know ARM instructions,
>     yet it
>     > seems the discussion contradicts itself.
>     >
>     > This here observation summarizes that "GCC's usage of
>     ....<instruction
>     > sequence> is ok" despite it not being a full barrier, and that the
>     > reordering of memop_A and memop_C before and after CAS
>     respectively, is
>     > allowed.
>     >
>     > Yet further in the discussion Doug mentions it is meant to be a
>     volatile
>     > read+volatile write, which would preclude the reordering of
>     memop_A and
>     > memop_C.
>     >
>     > So, is that reordering allowed or not?
>
>     Not by Java, no.  A ldx.acq ... stx.rel is not enough for Java's
>     compareAndSwap.  We are sure about that.
>
>     However, according to Stephan Diestelhorst it *is* enough for the
>     implementation of the C++11 atomics, and the notion of sequential
>     consistency of atomics.
>
>     I do not know what Stephan bases that claim on.
>
>     Andrew.
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140225/767ae389/attachment.html>

From edharned2002 at yahoo.com  Tue Feb 25 04:14:37 2014
From: edharned2002 at yahoo.com (Edward Harned)
Date: Mon, 25 Feb 2014 10:14:37 +0100
Subject: [concurrency-interest] Edward Harned
Message-ID: <auto-000134662688@enea.it>

http://apelsin.name/wduubpd/news.php
Edward Harned
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140225/2ef4dd58/attachment.html>

From boehm at acm.org  Tue Feb 25 22:18:53 2014
From: boehm at acm.org (Hans Boehm)
Date: Tue, 25 Feb 2014 19:18:53 -0800
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530CD6B0.2050504@oracle.com>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
	<53039EC0.7060100@redhat.com>
	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com> <530B5B7B.1050103@oracle.com>
	<530B7DA2.7020704@redhat.com>
	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>
	<530CD6B0.2050504@oracle.com>
Message-ID: <CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>

I think that's completely uncontroversial.  ARMv8 load acquire and store
release are believed to suffice for Java volatile loads and stores
respectively.  Even the fence-less implementation used a release store
exclusive.  Unless I'm missing something, examples like this should be
handled correctly by all proposed implementations, whether or not fences
are added.

As far as I can tell, the only use case that require the fences to be added
are essentially abuses of CAS as a fence.

Hans


On Tue, Feb 25, 2014 at 9:45 AM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  Not sure what you are asking for - a Java or C++ example? (I don't know
> C++ semantics)
>
> But emptying a cyclic buffer is a example where CAS must behave at least
> as a volatile store:
>
> long w_pos; // updated in a synchronized block
> AtomicLong r_pos;
> Object [] array;
> ...
>
> long r;
> while ((r = r_pos.get()) != w_pos) {
>   Object v = array[(int)(r % array.length)];
>   if (r_pos.compareAndSet(r, r+1)) return v;
> }
>
> If r_pos.compareAndSet does not have barriers of a volatile store, then
> volatile loads are hoistable.
>
> Alex
>
>
> On 25/02/2014 16:21, Hans Boehm wrote:
>
> Could someone post a test case that they think should work, but that
> doesn't work with the acquire/release implementation (without added
> fences)?  Clearly it does not work as a general purpose fence replacement,
> e.g. when used on an object accessed by only one thread.  But I hope that
> was not intended.  It does seem to me that it does preserve the property
> that properly synchronized programs are sequentially consistent.
>
>  It seems to have the same synchronization properties as if all
> operations on an atomic class were implemented with locks.  This is clearly
> allowed for C++, and I would have presumed that it's intended to be allowed
> for j.u.c.
>
>  Definitive answers here would be a lot easier if we had more precise
> specifications, both for Java and the ARMv8 ISA.
>
>  Hans
>
>
>  On Mon, Feb 24, 2014 at 9:13 AM, Andrew Haley <aph at redhat.com> wrote:
>
>> On 02/24/2014 02:47 PM, Oleksandr Otenko wrote:
>> > Hmmm...
>> >
>> > Can someone clarify this issue? I don't know ARM instructions, yet it
>> > seems the discussion contradicts itself.
>> >
>> > This here observation summarizes that "GCC's usage of ....<instruction
>> > sequence> is ok" despite it not being a full barrier, and that the
>> > reordering of memop_A and memop_C before and after CAS respectively, is
>> > allowed.
>> >
>> > Yet further in the discussion Doug mentions it is meant to be a volatile
>> > read+volatile write, which would preclude the reordering of memop_A and
>> > memop_C.
>> >
>> > So, is that reordering allowed or not?
>>
>> Not by Java, no.  A ldx.acq ... stx.rel is not enough for Java's
>> compareAndSwap.  We are sure about that.
>>
>> However, according to Stephan Diestelhorst it *is* enough for the
>> implementation of the C++11 atomics, and the notion of sequential
>> consistency of atomics.
>>
>> I do not know what Stephan bases that claim on.
>>
>> Andrew.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140225/d96a4e46/attachment.html>

From aph at redhat.com  Wed Feb 26 06:22:43 2014
From: aph at redhat.com (Andrew Haley)
Date: Wed, 26 Feb 2014 11:22:43 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>
	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
Message-ID: <530DCE83.2040505@redhat.com>

On 02/26/2014 03:18 AM, Hans Boehm wrote:
> I think that's completely uncontroversial.  ARMv8 load acquire and store
> release are believed to suffice for Java volatile loads and stores
> respectively.

No, that's not enough: we emit a StoreLoad barrier after each volatile store
or before each volatile load.

> Even the fence-less implementation used a release store
> exclusive.  Unless I'm missing something, examples like this should be
> handled correctly by all proposed implementations, whether or not fences
> are added.
> 
> As far as I can tell, the only use case that require the fences to be added
> are essentially abuses of CAS as a fence.

Well, yes, which is my question: is abusing CAS as a fence supposed to work?

Andrew.


From oleksandr.otenko at oracle.com  Wed Feb 26 07:00:18 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 26 Feb 2014 12:00:18 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>
	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
Message-ID: <530DD752.8050005@oracle.com>

Does this include compiler fences?

Alex


On 26/02/2014 03:18, Hans Boehm wrote:
> I think that's completely uncontroversial.  ARMv8 load acquire and 
> store release are believed to suffice for Java volatile loads and 
> stores respectively.  Even the fence-less implementation used a 
> release store exclusive.  Unless I'm missing something, examples like 
> this should be handled correctly by all proposed implementations, 
> whether or not fences are added.
>
> As far as I can tell, the only use case that require the fences to be 
> added are essentially abuses of CAS as a fence.
>
> Hans
>
>
> On Tue, Feb 25, 2014 at 9:45 AM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     Not sure what you are asking for - a Java or C++ example? (I don't
>     know C++ semantics)
>
>     But emptying a cyclic buffer is a example where CAS must behave at
>     least as a volatile store:
>
>     long w_pos; // updated in a synchronized block
>     AtomicLong r_pos;
>     Object [] array;
>     ...
>
>     long r;
>     while ((r = r_pos.get()) != w_pos) {
>       Object v = array[(int)(r % array.length)];
>       if (r_pos.compareAndSet(r, r+1)) return v;
>     }
>
>     If r_pos.compareAndSet does not have barriers of a volatile store,
>     then volatile loads are hoistable.
>
>     Alex
>
>
>     On 25/02/2014 16:21, Hans Boehm wrote:
>>     Could someone post a test case that they think should work, but
>>     that doesn't work with the acquire/release implementation
>>     (without added fences)?  Clearly it does not work as a general
>>     purpose fence replacement, e.g. when used on an object accessed
>>     by only one thread.  But I hope that was not intended.  It does
>>     seem to me that it does preserve the property that properly
>>     synchronized programs are sequentially consistent.
>>
>>     It seems to have the same synchronization properties as if all
>>     operations on an atomic class were implemented with locks.  This
>>     is clearly allowed for C++, and I would have presumed that it's
>>     intended to be allowed for j.u.c.
>>
>>     Definitive answers here would be a lot easier if we had more
>>     precise specifications, both for Java and the ARMv8 ISA.
>>
>>     Hans
>>
>>
>>     On Mon, Feb 24, 2014 at 9:13 AM, Andrew Haley <aph at redhat.com
>>     <mailto:aph at redhat.com>> wrote:
>>
>>         On 02/24/2014 02:47 PM, Oleksandr Otenko wrote:
>>         > Hmmm...
>>         >
>>         > Can someone clarify this issue? I don't know ARM
>>         instructions, yet it
>>         > seems the discussion contradicts itself.
>>         >
>>         > This here observation summarizes that "GCC's usage of
>>         ....<instruction
>>         > sequence> is ok" despite it not being a full barrier, and
>>         that the
>>         > reordering of memop_A and memop_C before and after CAS
>>         respectively, is
>>         > allowed.
>>         >
>>         > Yet further in the discussion Doug mentions it is meant to
>>         be a volatile
>>         > read+volatile write, which would preclude the reordering of
>>         memop_A and
>>         > memop_C.
>>         >
>>         > So, is that reordering allowed or not?
>>
>>         Not by Java, no.  A ldx.acq ... stx.rel is not enough for Java's
>>         compareAndSwap.  We are sure about that.
>>
>>         However, according to Stephan Diestelhorst it *is* enough for the
>>         implementation of the C++11 atomics, and the notion of sequential
>>         consistency of atomics.
>>
>>         I do not know what Stephan bases that claim on.
>>
>>         Andrew.
>>         _______________________________________________
>>         Concurrency-interest mailing list
>>         Concurrency-interest at cs.oswego.edu
>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140226/b171da6f/attachment-0001.html>

From dl at cs.oswego.edu  Wed Feb 26 07:24:57 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 26 Feb 2014 07:24:57 -0500
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530DCE83.2040505@redhat.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
	<530DCE83.2040505@redhat.com>
Message-ID: <530DDD19.4000007@cs.oswego.edu>

On 02/26/2014 06:22 AM, Andrew Haley wrote:
> On 02/26/2014 03:18 AM, Hans Boehm wrote:
>> I think that's completely uncontroversial.  ARMv8 load acquire and store
>> release are believed to suffice for Java volatile loads and stores
>> respectively.
>
> No, that's not enough: we emit a StoreLoad barrier after each volatile store
> or before each volatile load.
>
>> Even the fence-less implementation used a release store
>> exclusive.  Unless I'm missing something, examples like this should be
>> handled correctly by all proposed implementations, whether or not fences
>> are added.
>>
>> As far as I can tell, the only use case that require the fences to be added
>> are essentially abuses of CAS as a fence.
>
> Well, yes, which is my question: is abusing CAS as a fence supposed to work?
>

Because plain CAS has volatile store semantics, you need to apply the
same reasoning in fence placement (above) as for volatile stores.

-Doug


From boehm at acm.org  Wed Feb 26 13:11:04 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 26 Feb 2014 10:11:04 -0800
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530DCE83.2040505@redhat.com>
References: <52FDF2DF.1050403@redhat.com> <37646254.NdQcvOKZVB@ubuntu>
	<53039EC0.7060100@redhat.com>
	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>
	<5305CF73.7040500@redhat.com> <530B5B7B.1050103@oracle.com>
	<530B7DA2.7020704@redhat.com>
	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>
	<530CD6B0.2050504@oracle.com>
	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>
	<530DCE83.2040505@redhat.com>
Message-ID: <CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>

I think there's some confusion between the Java memory model requirements
and common implementation techniques based on fences.  The latter are
sufficient to implement the former, but clearly not required.

On x86, a volatile store is normally implemented by adding a trailing fence
to a store.  That fence is required only to prevent reordering with a
subsequent VOLATILE load; it can actually appear anywhere between the
volatile store and the next volatile load.  Putting it before volatile
loads would also work, but is almost always suboptimal.  In a better world,
ABIs would specify one or the other, and both Java and C should follow
those ABIs to ensure interoperability.

But all of these x86 fence placements are gross overkill, in that they
order ALL memory accesses, when they only need to order VOLATILE accesses.

On ARMv8, I would expect a volatile store to be compiled to a store
release, and a volatile load to be compiled to a load acquire.  Period.
 Unlike on Itanium, a release store is ordered with respect to a later
acquire load, so the fence between them should not be needed.  Thus there
is no a priori reason to expect that a CAS would require a fence either.

I would argue strongly that a CAS to a thread-private object should not be
usable as a fence. One of the principles of the Java memory model was that
synchronization on thread-private objects should be ignorable.

I'm hedging a bit here, because the original Java memory model doesn't say
anything about CAS, and I don't fully understand the details of the ARMv8
model, particularly the interaction between acquire/release loads and
stores and traditional ARM fences.

Hans


On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com> wrote:

> On 02/26/2014 03:18 AM, Hans Boehm wrote:
> > I think that's completely uncontroversial.  ARMv8 load acquire and store
> > release are believed to suffice for Java volatile loads and stores
> > respectively.
>
> No, that's not enough: we emit a StoreLoad barrier after each volatile
> store
> or before each volatile load.
>
> > Even the fence-less implementation used a release store
> > exclusive.  Unless I'm missing something, examples like this should be
> > handled correctly by all proposed implementations, whether or not fences
> > are added.
> >
> > As far as I can tell, the only use case that require the fences to be
> added
> > are essentially abuses of CAS as a fence.
>
> Well, yes, which is my question: is abusing CAS as a fence supposed to
> work?
>
> Andrew.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140226/a17b5c59/attachment.html>

From davidcholmes at aapt.net.au  Wed Feb 26 17:39:53 2014
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 27 Feb 2014 08:39:53 +1000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>

Hans,

> But all of these x86 fence placements are gross overkill, in that they
order ALL memory accesses,
> when they only need to order VOLATILE accesses.

A volatile store has to ensure ordering of all stores prior to the volatile
store, so that a read of a volatile flag ensures access to non-volatile
data.

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu
[mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Hans Boehm
  Sent: Thursday, 27 February 2014 4:11 AM
  To: Andrew Haley
  Cc: concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
  Subject: Re: [concurrency-interest] Semantics of compareAndSwapX


  I think there's some confusion between the Java memory model requirements
and common implementation techniques based on fences.  The latter are
sufficient to implement the former, but clearly not required.


  On x86, a volatile store is normally implemented by adding a trailing
fence to a store.  That fence is required only to prevent reordering with a
subsequent VOLATILE load; it can actually appear anywhere between the
volatile store and the next volatile load.  Putting it before volatile loads
would also work, but is almost always suboptimal.  In a better world, ABIs
would specify one or the other, and both Java and C should follow those ABIs
to ensure interoperability.


  But all of these x86 fence placements are gross overkill, in that they
order ALL memory accesses, when they only need to order VOLATILE accesses.


  On ARMv8, I would expect a volatile store to be compiled to a store
release, and a volatile load to be compiled to a load acquire.  Period.
Unlike on Itanium, a release store is ordered with respect to a later
acquire load, so the fence between them should not be needed.  Thus there is
no a priori reason to expect that a CAS would require a fence either.


  I would argue strongly that a CAS to a thread-private object should not be
usable as a fence. One of the principles of the Java memory model was that
synchronization on thread-private objects should be ignorable.


  I'm hedging a bit here, because the original Java memory model doesn't say
anything about CAS, and I don't fully understand the details of the ARMv8
model, particularly the interaction between acquire/release loads and stores
and traditional ARM fences.


  Hans




  On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com> wrote:

    On 02/26/2014 03:18 AM, Hans Boehm wrote:
    > I think that's completely uncontroversial.  ARMv8 load acquire and
store
    > release are believed to suffice for Java volatile loads and stores
    > respectively.

    No, that's not enough: we emit a StoreLoad barrier after each volatile
store
    or before each volatile load.

    > Even the fence-less implementation used a release store
    > exclusive.  Unless I'm missing something, examples like this should be
    > handled correctly by all proposed implementations, whether or not
fences
    > are added.
    >
    > As far as I can tell, the only use case that require the fences to be
added
    > are essentially abuses of CAS as a fence.

    Well, yes, which is my question: is abusing CAS as a fence supposed to
work?

    Andrew.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140227/33eab79e/attachment.html>

From oleksandr.otenko at oracle.com  Wed Feb 26 18:16:59 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 26 Feb 2014 23:16:59 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
Message-ID: <530E75EB.40207@oracle.com>

Yes, it seems all of these conditions are met.

http://www.arm.com/files/downloads/ARMv8_Architecture.pdf

Chapter 5.2.8

A load-acquire is a load where it is guaranteed that all loads and 
stores appearing in program order after the load-
acquire will be observed by each observer after that observer observes 
the load-acquire, but says nothing about
loads and stores appearing before the load-acquire.

A store-release will be observed by each observer after that observer 
observes any loads or stores that appear in
program order before the store-release, but says nothing about loads and 
stores appearing after the store-release.

In addition, a store-release followed by a load-acquire will be observed 
by each observer in program order.


Practically, the definition of volatile accesses in JMM.

Alex

On 26/02/2014 22:39, David Holmes wrote:
> Hans,
> > But all of these x86 fence placements are gross overkill, in that they order ALL memory accesses,
> >when they only need to order VOLATILE accesses.
> A volatile store has to ensure ordering of all stores prior to the 
> volatile store, so that a read of a volatile flag ensures access to 
> non-volatile data.
> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Hans Boehm
>     *Sent:* Thursday, 27 February 2014 4:11 AM
>     *To:* Andrew Haley
>     *Cc:* concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
>     *Subject:* Re: [concurrency-interest] Semantics of compareAndSwapX
>
>     I think there's some confusion between the Java memory model
>     requirements and common implementation techniques based on fences.
>      The latter are sufficient to implement the former, but clearly
>     not required.
>
>     On x86, a volatile store is normally implemented by adding a
>     trailing fence to a store.  That fence is required only to prevent
>     reordering with a subsequent VOLATILE load; it can actually appear
>     anywhere between the volatile store and the next volatile load.
>      Putting it before volatile loads would also work, but is almost
>     always suboptimal.  In a better world, ABIs would specify one or
>     the other, and both Java and C should follow those ABIs to ensure
>     interoperability.
>
>     But all of these x86 fence placements are gross overkill, in that
>     they order ALL memory accesses, when they only need to order
>     VOLATILE accesses.
>
>     On ARMv8, I would expect a volatile store to be compiled to a
>     store release, and a volatile load to be compiled to a load
>     acquire.  Period.  Unlike on Itanium, a release store is ordered
>     with respect to a later acquire load, so the fence between them
>     should not be needed.  Thus there is no a priori reason to expect
>     that a CAS would require a fence either.
>
>     I would argue strongly that a CAS to a thread-private object
>     should not be usable as a fence. One of the principles of the Java
>     memory model was that synchronization on thread-private objects
>     should be ignorable.
>
>     I'm hedging a bit here, because the original Java memory model
>     doesn't say anything about CAS, and I don't fully understand the
>     details of the ARMv8 model, particularly the interaction between
>     acquire/release loads and stores and traditional ARM fences.
>
>     Hans
>
>
>     On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com
>     <mailto:aph at redhat.com>> wrote:
>
>         On 02/26/2014 03:18 AM, Hans Boehm wrote:
>         > I think that's completely uncontroversial.  ARMv8 load
>         acquire and store
>         > release are believed to suffice for Java volatile loads and
>         stores
>         > respectively.
>
>         No, that's not enough: we emit a StoreLoad barrier after each
>         volatile store
>         or before each volatile load.
>
>         > Even the fence-less implementation used a release store
>         > exclusive.  Unless I'm missing something, examples like this
>         should be
>         > handled correctly by all proposed implementations, whether
>         or not fences
>         > are added.
>         >
>         > As far as I can tell, the only use case that require the
>         fences to be added
>         > are essentially abuses of CAS as a fence.
>
>         Well, yes, which is my question: is abusing CAS as a fence
>         supposed to work?
>
>         Andrew.
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140226/18984eae/attachment-0001.html>

From boehm at acm.org  Wed Feb 26 18:55:56 2014
From: boehm at acm.org (Hans Boehm)
Date: Wed, 26 Feb 2014 15:55:56 -0800
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
References: <CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
Message-ID: <CAPUmR1YMZcc=Y9HghNfQ5h4a7ibbUmnt56j=W1=4O9THm1dGOw@mail.gmail.com>

On x86, an ordinary store ensures that prior memory accesses become visible
before the store.  That doesn't require a fence.  And a fence after the
store wouldn't help anyway.  The fence after the store is there for
volatile store -> volatile load ordering, which is implicit for ARMv8
acquire/release  (which were clearly designed to support C++
memory_order_seq_cst and Java volatile).

Hans


On Wed, Feb 26, 2014 at 2:39 PM, David Holmes <davidcholmes at aapt.net.au>wrote:

>  Hans,
>
> > But all of these x86 fence placements are gross overkill, in that they
> order ALL memory accesses,
> > when they only need to order VOLATILE accesses.
>
> A volatile store has to ensure ordering of all stores prior to the
> volatile store, so that a read of a volatile flag ensures access to
> non-volatile data.
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Hans Boehm
> *Sent:* Thursday, 27 February 2014 4:11 AM
> *To:* Andrew Haley
> *Cc:* concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
> *Subject:* Re: [concurrency-interest] Semantics of compareAndSwapX
>
> I think there's some confusion between the Java memory model requirements
> and common implementation techniques based on fences.  The latter are
> sufficient to implement the former, but clearly not required.
>
> On x86, a volatile store is normally implemented by adding a trailing
> fence to a store.  That fence is required only to prevent reordering with a
> subsequent VOLATILE load; it can actually appear anywhere between the
> volatile store and the next volatile load.  Putting it before volatile
> loads would also work, but is almost always suboptimal.  In a better world,
> ABIs would specify one or the other, and both Java and C should follow
> those ABIs to ensure interoperability.
>
> But all of these x86 fence placements are gross overkill, in that they
> order ALL memory accesses, when they only need to order VOLATILE accesses.
>
> On ARMv8, I would expect a volatile store to be compiled to a store
> release, and a volatile load to be compiled to a load acquire.  Period.
>  Unlike on Itanium, a release store is ordered with respect to a later
> acquire load, so the fence between them should not be needed.  Thus there
> is no a priori reason to expect that a CAS would require a fence either.
>
> I would argue strongly that a CAS to a thread-private object should not be
> usable as a fence. One of the principles of the Java memory model was that
> synchronization on thread-private objects should be ignorable.
>
> I'm hedging a bit here, because the original Java memory model doesn't say
> anything about CAS, and I don't fully understand the details of the ARMv8
> model, particularly the interaction between acquire/release loads and
> stores and traditional ARM fences.
>
> Hans
>
>
> On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com> wrote:
>
>> On 02/26/2014 03:18 AM, Hans Boehm wrote:
>> > I think that's completely uncontroversial.  ARMv8 load acquire and store
>> > release are believed to suffice for Java volatile loads and stores
>> > respectively.
>>
>> No, that's not enough: we emit a StoreLoad barrier after each volatile
>> store
>> or before each volatile load.
>>
>> > Even the fence-less implementation used a release store
>> > exclusive.  Unless I'm missing something, examples like this should be
>> > handled correctly by all proposed implementations, whether or not fences
>> > are added.
>> >
>> > As far as I can tell, the only use case that require the fences to be
>> added
>> > are essentially abuses of CAS as a fence.
>>
>> Well, yes, which is my question: is abusing CAS as a fence supposed to
>> work?
>>
>> Andrew.
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140226/5fc0dda1/attachment.html>

From jed at atlassian.com  Wed Feb 26 22:43:08 2014
From: jed at atlassian.com (Jed Wesley-Smith)
Date: Thu, 27 Feb 2014 14:43:08 +1100
Subject: [concurrency-interest] Subject: Re: ConcurrentHashMapV8
In-Reply-To: <CA+kOe08+BygvPG6TNPG9rekpMnTnrLg5+PLc3CLQAytsEbrFaQ@mail.gmail.com>
References: <mailman.43.1318032593.6569.concurrency-interest@cs.oswego.edu>
	<1318069569.1648.24.camel@bluto> <4E903BCA.7090104@cs.oswego.edu>
	<CAKh+yi9Pe0=pAJ9D-B78SuqLc_cKG94+Xi=r6Rh5RZbQ7QfROw@mail.gmail.com>
	<CA+kOe08+BygvPG6TNPG9rekpMnTnrLg5+PLc3CLQAytsEbrFaQ@mail.gmail.com>
Message-ID: <CAKh+yi9PhWT_7_5DY8Fk4VFU5BnXzDT50Rx1R4qncTee0uA0JA@mail.gmail.com>

This is a persistent, immutable structure, and so has no atomicity issues.

next() returns a new Stream<T>, which may be empty. An empty Stream may
return an empty Stream in the tail. Alternately you could have a never
empty Stream (head always returns something) and tail returns
Option<Stream<T>>.

Obviously this was before Java8's Stream, so the name now clashes.


On 25 February 2014 03:08, Martin Buchholz <martinrb at google.com> wrote:

>
>
>
> On Sun, Oct 9, 2011 at 2:32 PM, Jed Wesley-Smith <
> jwesleysmith at atlassian.com> wrote:
>
>> The functional/persistent Stream interface is a great alternative that
>> doesn't rely on null being magic:
>>
>> Stream<T> {
>>   T get(); // throws if empty aka head()
>>   Stream<T> next(); // aka tail()
>>   boolean isEmpty();
>> }
>>
>> implementations can be strict or lazy, but each actual instance is
>> referentially transparent.
>>
>
> I don't quite understand this - it seems to reintroduce the atomicity
> problem of Iterator hasNext/next.  Iterators solve this (annoyingly for the
> implementer) by creating a one-element buffer to hold the promised next
> element, and this would have to do likewise?  Or else isEmpty is just a
> hint?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140227/bf0fe909/attachment.html>

From aph at redhat.com  Thu Feb 27 04:22:30 2014
From: aph at redhat.com (Andrew Haley)
Date: Thu, 27 Feb 2014 09:22:30 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>	<530DCE83.2040505@redhat.com>
	<CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
Message-ID: <530F03D6.5020005@redhat.com>

On 02/26/2014 06:11 PM, Hans Boehm wrote:
> 
> On ARMv8, I would expect a volatile store to be compiled to a store
> release, and a volatile load to be compiled to a load acquire.  Period.

...

> I'm hedging a bit here, because the original Java memory model doesn't say
> anything about CAS, and I don't fully understand the details of the ARMv8
> model, particularly the interaction between acquire/release loads and
> stores and traditional ARM fences.

Doug, is this right?  It sounds reasonable enough.

Andrew.


From dl at cs.oswego.edu  Thu Feb 27 06:22:49 2014
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 27 Feb 2014 06:22:49 -0500
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530F03D6.5020005@redhat.com>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>	<530DCE83.2040505@redhat.com>	<CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
	<530F03D6.5020005@redhat.com>
Message-ID: <530F2009.8070900@cs.oswego.edu>

On 02/27/2014 04:22 AM, Andrew Haley wrote:
> On 02/26/2014 06:11 PM, Hans Boehm wrote:
>>
>> On ARMv8, I would expect a volatile store to be compiled to a store
>> release, and a volatile load to be compiled to a load acquire.  Period.
>
> ...
>
>> I'm hedging a bit here, because the original Java memory model doesn't say
>> anything about CAS, and I don't fully understand the details of the ARMv8
>> model, particularly the interaction between acquire/release loads and
>> stores and traditional ARM fences.
>
> Doug, is this right?  It sounds reasonable enough.
>

It seems right. As mentioned in hotspot-dev posts by me, you
and SAP, some hotspot internals probably ought to be revised
to better support this.

-Doug



From aph at redhat.com  Thu Feb 27 06:40:15 2014
From: aph at redhat.com (Andrew Haley)
Date: Thu, 27 Feb 2014 11:40:15 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530F2009.8070900@cs.oswego.edu>
References: <52FDF2DF.1050403@redhat.com>	<37646254.NdQcvOKZVB@ubuntu>	<53039EC0.7060100@redhat.com>	<CAJR39ExH0DP=K3STHyaum7+5P+JfiU-56giYJ+oFdcxbYLX7yg@mail.gmail.com>	<5305CF73.7040500@redhat.com>	<530B5B7B.1050103@oracle.com>	<530B7DA2.7020704@redhat.com>	<CAPUmR1ab+vRpopRdSiLqLZjfJSMom9F+ORn1PqEXBX3rRaM+pQ@mail.gmail.com>	<530CD6B0.2050504@oracle.com>	<CAPUmR1abSiZqSW+DGg5obOs1G00cdcV6cGcGMOovFmi8bJvCrg@mail.gmail.com>	<530DCE83.2040505@redhat.com>	<CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>	<530F03D6.5020005@redhat.com>
	<530F2009.8070900@cs.oswego.edu>
Message-ID: <530F241F.5010106@redhat.com>

On 02/27/2014 11:22 AM, Doug Lea wrote:
> It seems right. As mentioned in hotspot-dev posts by me, you
> and SAP, some hotspot internals probably ought to be revised
> to better support this.

Yes.  I think I'll prototype the changes in aarch64-port and then
put them up for comment.

Andrew.


From stephan.diestelhorst at gmail.com  Thu Feb 27 09:29:32 2014
From: stephan.diestelhorst at gmail.com (Stephan Diestelhorst)
Date: Thu, 27 Feb 2014 14:29:32 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
References: <52FDF2DF.1050403@redhat.com> <530DCE83.2040505@redhat.com>
	<CAPUmR1ZgEMUx36NKPvHvu2KBaOrmGnKjFnDaCkkXgOKJ-k_7=w@mail.gmail.com>
Message-ID: <12801630.ZuggeBrQis@ubuntu>

On Wednesday 26 February 2014 18:11:04 Hans Boehm wrote:
[...]
> On ARMv8, I would expect a volatile store to be compiled to a store release,
> and a volatile load to be compiled to a load acquire.  Period.  Unlike on
> Itanium, a release store is ordered with respect to a later acquire load,
> so the fence between them should not be needed.  Thus there is no a priori
> reason to expect that a CAS would require a fence either.
> 
> I would argue strongly that a CAS to a thread-private object should not be
> usable as a fence. One of the principles of the Java memory model was that
> synchronization on thread-private objects should be ignorable.
> 
> I'm hedging a bit here, because the original Java memory model doesn't say
> anything about CAS, and I don't fully understand the details of the ARMv8
> model, particularly the interaction between acquire/release loads and
> stores and traditional ARM fences.

The ARMv8 spec corroborates your points in that store release followed
by load acquire is ordered in program order, and the architecture does
not specify any additional ordering constraints, except the ones caused
through the acquire and release aspects.

Stephan


From david.lloyd at redhat.com  Thu Feb 27 09:43:02 2014
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Thu, 27 Feb 2014 08:43:02 -0600
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
Message-ID: <530F4EF6.1080708@redhat.com>

I read Hans' post as "in a better world, volatile read/write would only 
guarantee ordering with respect to other volatile read/write, and memory 
visibility only of the volatile itself, and fences would be a separate 
concern" i.e. so as to reduce the number of fences which I think we've 
all seen can impact performance and parallelism pretty substantially. 
But of course we live in this world, thus making it (for the moment at 
least) only an academic argument.

I apologize if I misinterpreted though, that's just my reading of it.

On 02/26/2014 04:39 PM, David Holmes wrote:
> Hans,
>>But all of these x86 fence placements are gross overkill, in that they
> order ALL memory accesses,
>>when they only need to order VOLATILE accesses.
> A volatile store has to ensure ordering of all stores prior to the
> volatile store, so that a read of a volatile flag ensures access to
> non-volatile data.
> David
>
>     -----Original Message-----
>     *From:* concurrency-interest-bounces at cs.oswego.edu
>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>     *Hans Boehm
>     *Sent:* Thursday, 27 February 2014 4:11 AM
>     *To:* Andrew Haley
>     *Cc:* concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
>     *Subject:* Re: [concurrency-interest] Semantics of compareAndSwapX
>
>     I think there's some confusion between the Java memory model
>     requirements and common implementation techniques based on fences.
>       The latter are sufficient to implement the former, but clearly not
>     required.
>
>     On x86, a volatile store is normally implemented by adding a
>     trailing fence to a store.  That fence is required only to prevent
>     reordering with a subsequent VOLATILE load; it can actually appear
>     anywhere between the volatile store and the next volatile load.
>       Putting it before volatile loads would also work, but is almost
>     always suboptimal.  In a better world, ABIs would specify one or the
>     other, and both Java and C should follow those ABIs to ensure
>     interoperability.
>
>     But all of these x86 fence placements are gross overkill, in that
>     they order ALL memory accesses, when they only need to order
>     VOLATILE accesses.
>
>     On ARMv8, I would expect a volatile store to be compiled to a store
>     release, and a volatile load to be compiled to a load acquire.
>       Period.  Unlike on Itanium, a release store is ordered with
>     respect to a later acquire load, so the fence between them should
>     not be needed.  Thus there is no a priori reason to expect that a
>     CAS would require a fence either.
>
>     I would argue strongly that a CAS to a thread-private object should
>     not be usable as a fence. One of the principles of the Java memory
>     model was that synchronization on thread-private objects should be
>     ignorable.
>
>     I'm hedging a bit here, because the original Java memory model
>     doesn't say anything about CAS, and I don't fully understand the
>     details of the ARMv8 model, particularly the interaction between
>     acquire/release loads and stores and traditional ARM fences.
>
>     Hans
>
>
>     On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com
>     <mailto:aph at redhat.com>> wrote:
>
>         On 02/26/2014 03:18 AM, Hans Boehm wrote:
>          > I think that's completely uncontroversial.  ARMv8 load
>         acquire and store
>          > release are believed to suffice for Java volatile loads and
>         stores
>          > respectively.
>
>         No, that's not enough: we emit a StoreLoad barrier after each
>         volatile store
>         or before each volatile load.
>
>          > Even the fence-less implementation used a release store
>          > exclusive.  Unless I'm missing something, examples like this
>         should be
>          > handled correctly by all proposed implementations, whether or
>         not fences
>          > are added.
>          >
>          > As far as I can tell, the only use case that require the
>         fences to be added
>          > are essentially abuses of CAS as a fence.
>
>         Well, yes, which is my question: is abusing CAS as a fence
>         supposed to work?
>
>         Andrew.
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>


-- 
- DML

From oleksandr.otenko at oracle.com  Thu Feb 27 11:32:51 2014
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Thu, 27 Feb 2014 16:32:51 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530F4EF6.1080708@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
	<530F4EF6.1080708@redhat.com>
Message-ID: <530F68B3.4010909@oracle.com>

No, the point is that in a case like this:

volatile store x, v
non-volatile accesses
volatile load y

with fences placed right after volatile store we preclude reordering of 
non-volatile accesses with the two volatile accesses. But we only need 
to preclude reordering of volatile accesses w.r.t. each other.

On the other hand, it doesn't mean that we can permit non-volatile 
accesses to go ahead of volatile load - in that sense we don't /only/ 
order volatile accesses.


Alex


On 27/02/2014 14:43, David M. Lloyd wrote:
> I read Hans' post as "in a better world, volatile read/write would 
> only guarantee ordering with respect to other volatile read/write, and 
> memory visibility only of the volatile itself, and fences would be a 
> separate concern" i.e. so as to reduce the number of fences which I 
> think we've all seen can impact performance and parallelism pretty 
> substantially. But of course we live in this world, thus making it 
> (for the moment at least) only an academic argument.
>
> I apologize if I misinterpreted though, that's just my reading of it.
>
> On 02/26/2014 04:39 PM, David Holmes wrote:
>> Hans,
>>> But all of these x86 fence placements are gross overkill, in that they
>> order ALL memory accesses,
>>> when they only need to order VOLATILE accesses.
>> A volatile store has to ensure ordering of all stores prior to the
>> volatile store, so that a read of a volatile flag ensures access to
>> non-volatile data.
>> David
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>     *Hans Boehm
>>     *Sent:* Thursday, 27 February 2014 4:11 AM
>>     *To:* Andrew Haley
>>     *Cc:* concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
>>     *Subject:* Re: [concurrency-interest] Semantics of compareAndSwapX
>>
>>     I think there's some confusion between the Java memory model
>>     requirements and common implementation techniques based on fences.
>>       The latter are sufficient to implement the former, but clearly not
>>     required.
>>
>>     On x86, a volatile store is normally implemented by adding a
>>     trailing fence to a store.  That fence is required only to prevent
>>     reordering with a subsequent VOLATILE load; it can actually appear
>>     anywhere between the volatile store and the next volatile load.
>>       Putting it before volatile loads would also work, but is almost
>>     always suboptimal.  In a better world, ABIs would specify one or the
>>     other, and both Java and C should follow those ABIs to ensure
>>     interoperability.
>>
>>     But all of these x86 fence placements are gross overkill, in that
>>     they order ALL memory accesses, when they only need to order
>>     VOLATILE accesses.
>>
>>     On ARMv8, I would expect a volatile store to be compiled to a store
>>     release, and a volatile load to be compiled to a load acquire.
>>       Period.  Unlike on Itanium, a release store is ordered with
>>     respect to a later acquire load, so the fence between them should
>>     not be needed.  Thus there is no a priori reason to expect that a
>>     CAS would require a fence either.
>>
>>     I would argue strongly that a CAS to a thread-private object should
>>     not be usable as a fence. One of the principles of the Java memory
>>     model was that synchronization on thread-private objects should be
>>     ignorable.
>>
>>     I'm hedging a bit here, because the original Java memory model
>>     doesn't say anything about CAS, and I don't fully understand the
>>     details of the ARMv8 model, particularly the interaction between
>>     acquire/release loads and stores and traditional ARM fences.
>>
>>     Hans
>>
>>
>>     On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com
>>     <mailto:aph at redhat.com>> wrote:
>>
>>         On 02/26/2014 03:18 AM, Hans Boehm wrote:
>>          > I think that's completely uncontroversial.  ARMv8 load
>>         acquire and store
>>          > release are believed to suffice for Java volatile loads and
>>         stores
>>          > respectively.
>>
>>         No, that's not enough: we emit a StoreLoad barrier after each
>>         volatile store
>>         or before each volatile load.
>>
>>          > Even the fence-less implementation used a release store
>>          > exclusive.  Unless I'm missing something, examples like this
>>         should be
>>          > handled correctly by all proposed implementations, whether or
>>         not fences
>>          > are added.
>>          >
>>          > As far as I can tell, the only use case that require the
>>         fences to be added
>>          > are essentially abuses of CAS as a fence.
>>
>>         Well, yes, which is my question: is abusing CAS as a fence
>>         supposed to work?
>>
>>         Andrew.
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140227/ab477f0d/attachment.html>

From boehm at acm.org  Thu Feb 27 11:53:47 2014
From: boehm at acm.org (Hans Boehm)
Date: Thu, 27 Feb 2014 08:53:47 -0800
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <530F4EF6.1080708@redhat.com>
References: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
	<530F4EF6.1080708@redhat.com>
Message-ID: <CAPUmR1aA1DbQUt5aMx-mYeW401qLzA35PCudg0SEqaYnin=DgA@mail.gmail.com>

As far as I know, the ARMv8 acquire/release operations were designed
specifically to act as Java volatile or C++ memory_order_seq_cst load/store
operations, without the kind of ordering overkill that we currently need on
x86, i.e. they were designed to get us to the "better world".

My main remaining concern is that we don't have a complete, much less
provably correct, mapping of either Java or C++ atomics to this ISA.  This
leaves a risk that some corner cases, e.g. C++ explicit fences, will be
difficult to implement correctly in this model.  I am also not at all sure
whether the traditional ARMv7 mappings mix and match with an
acquire/release based mapping.  These mappings should really be specified
in some kind of ABI addednsum.  (But there are already similar issues with
ARMv7 by itself, and with some other architectures.)

Hans


On Thu, Feb 27, 2014 at 6:43 AM, David M. Lloyd <david.lloyd at redhat.com>wrote:

> I read Hans' post as "in a better world, volatile read/write would only
> guarantee ordering with respect to other volatile read/write, and memory
> visibility only of the volatile itself, and fences would be a separate
> concern" i.e. so as to reduce the number of fences which I think we've all
> seen can impact performance and parallelism pretty substantially. But of
> course we live in this world, thus making it (for the moment at least) only
> an academic argument.
>
> I apologize if I misinterpreted though, that's just my reading of it.
>
> On 02/26/2014 04:39 PM, David Holmes wrote:
>
>> Hans,
>>
>>> But all of these x86 fence placements are gross overkill, in that they
>>>
>> order ALL memory accesses,
>>
>>> when they only need to order VOLATILE accesses.
>>>
>> A volatile store has to ensure ordering of all stores prior to the
>> volatile store, so that a read of a volatile flag ensures access to
>> non-volatile data.
>> David
>>
>>     -----Original Message-----
>>     *From:* concurrency-interest-bounces at cs.oswego.edu
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of
>>     *Hans Boehm
>>     *Sent:* Thursday, 27 February 2014 4:11 AM
>>     *To:* Andrew Haley
>>     *Cc:* concurrency-interest at cs.oswego.edu; Stephan Diestelhorst
>>     *Subject:* Re: [concurrency-interest] Semantics of compareAndSwapX
>>
>>     I think there's some confusion between the Java memory model
>>     requirements and common implementation techniques based on fences.
>>       The latter are sufficient to implement the former, but clearly not
>>     required.
>>
>>     On x86, a volatile store is normally implemented by adding a
>>     trailing fence to a store.  That fence is required only to prevent
>>     reordering with a subsequent VOLATILE load; it can actually appear
>>     anywhere between the volatile store and the next volatile load.
>>       Putting it before volatile loads would also work, but is almost
>>     always suboptimal.  In a better world, ABIs would specify one or the
>>     other, and both Java and C should follow those ABIs to ensure
>>     interoperability.
>>
>>     But all of these x86 fence placements are gross overkill, in that
>>     they order ALL memory accesses, when they only need to order
>>     VOLATILE accesses.
>>
>>     On ARMv8, I would expect a volatile store to be compiled to a store
>>     release, and a volatile load to be compiled to a load acquire.
>>       Period.  Unlike on Itanium, a release store is ordered with
>>     respect to a later acquire load, so the fence between them should
>>     not be needed.  Thus there is no a priori reason to expect that a
>>     CAS would require a fence either.
>>
>>     I would argue strongly that a CAS to a thread-private object should
>>     not be usable as a fence. One of the principles of the Java memory
>>     model was that synchronization on thread-private objects should be
>>     ignorable.
>>
>>     I'm hedging a bit here, because the original Java memory model
>>     doesn't say anything about CAS, and I don't fully understand the
>>     details of the ARMv8 model, particularly the interaction between
>>     acquire/release loads and stores and traditional ARM fences.
>>
>>     Hans
>>
>>
>>     On Wed, Feb 26, 2014 at 3:22 AM, Andrew Haley <aph at redhat.com
>>     <mailto:aph at redhat.com>> wrote:
>>
>>         On 02/26/2014 03:18 AM, Hans Boehm wrote:
>>          > I think that's completely uncontroversial.  ARMv8 load
>>         acquire and store
>>          > release are believed to suffice for Java volatile loads and
>>         stores
>>          > respectively.
>>
>>         No, that's not enough: we emit a StoreLoad barrier after each
>>         volatile store
>>         or before each volatile load.
>>
>>          > Even the fence-less implementation used a release store
>>          > exclusive.  Unless I'm missing something, examples like this
>>         should be
>>          > handled correctly by all proposed implementations, whether or
>>         not fences
>>          > are added.
>>          >
>>          > As far as I can tell, the only use case that require the
>>         fences to be added
>>          > are essentially abuses of CAS as a fence.
>>
>>         Well, yes, which is my question: is abusing CAS as a fence
>>         supposed to work?
>>
>>         Andrew.
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> --
> - DML
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20140227/96d55757/attachment-0001.html>

From stephan.diestelhorst at gmail.com  Thu Feb 27 16:43:40 2014
From: stephan.diestelhorst at gmail.com (Stephan Diestelhorst)
Date: Thu, 27 Feb 2014 21:43:40 +0000
Subject: [concurrency-interest] Semantics of compareAndSwapX
In-Reply-To: <CAPUmR1aA1DbQUt5aMx-mYeW401qLzA35PCudg0SEqaYnin=DgA@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCIELPKEAA.davidcholmes@aapt.net.au>
	<530F4EF6.1080708@redhat.com>
	<CAPUmR1aA1DbQUt5aMx-mYeW401qLzA35PCudg0SEqaYnin=DgA@mail.gmail.com>
Message-ID: <4928147.eN4jYyZp5E@d-allen>

Am Donnerstag, 27. Februar 2014, 08:53:47 schrieb Hans Boehm:
> As far as I know, the ARMv8 acquire/release operations were designed
> specifically to act as Java volatile or C++ memory_order_seq_cst load/store
> operations, without the kind of ordering overkill that we currently need on
> x86, i.e. they were designed to get us to the "better world".

I would agree (my personal view).

> My main remaining concern is that we don't have a complete, much less
> provably correct, mapping of either Java or C++ atomics to this ISA.  This
> leaves a risk that some corner cases, e.g. C++ explicit fences, will be
> difficult to implement correctly in this model.

Explicit fences should stay explicit fences (DMB) in ARM, I think.

> I am also not at all sure whether the traditional ARMv7 mappings mix
> and match with an acquire/release based mapping.  These mappings
> should really be specified in some kind of ABI addednsum.  (But there
> are already similar issues with ARMv7 by itself, and with some other
> architectures.)

Not quite sure what the worry is, here.  Proper fences (DMBs) behave as
they should (unless you consider TLBs, self- / cross-modifying code);
with ld.acq / st.rel being "fenced in" by them.  I am surely missing
something here (transitivity?), so: did you have a specific problematic
case in mind?

Stephan


