From oleksandr.otenko at gmail.com  Thu Jun  1 05:35:14 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 1 Jun 2017 10:35:14 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
Message-ID: <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>

There is code that relies on the CAS behaving like a volatile store always. This interpretation is based on direct question “does CAS always behave like a volatile store” to the people working on JVM, not plain reading of javadoc. It very likely predates C++ spec.

The code I know of can be fixed in fairly straightforward ways, but you’d need to ease the introduction of this change of behaviour.


There may be more code that unwittingly relies on such behaviour, because many people see compareAndSet as a way to abstract away x86 LOCK:CMPXCHG - without reading too much what such abstraction means on other platforms.

Alex

> On 1 Jun 2017, at 02:29, Martin Buchholz <martinrb at google.com> wrote:
> 
> 
> 
> On Wed, May 31, 2017 at 5:06 AM, Doug Lea <dl at cs.oswego.edu <mailto:dl at cs.oswego.edu>> wrote:
> On 05/31/2017 07:03 AM, Doug Lea wrote:
> 
> >>
> >> C++ clearly specifies "CAS classic". There is no way to specify
> >> release semantics for a failed CAS, since there is no write.
> >
> > The current C++ spec, sec 29.2 includes versions that do so,
> 
> Except that memory_order_release is specifically disallowed.
> Not that it matters, since the question at hand is about
> volatile/seq_cst.
> 
> The fact that  memory_order_release is specifically disallowed "proves" that Hans is right that this is referring to the semantics of the read alone.
> 
> Please please make the semantics of CAS in Java as close as possible to C++.  In particular, don't make them more expensive for no good reason.
> 
> The volatile read in CAS failure alone ensures that the CAS is a sequentially consistent synchronization action (part of the total order of all such actions).
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170601/636212b8/attachment-0001.html>

From dl at cs.oswego.edu  Thu Jun  1 08:25:48 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 1 Jun 2017 08:25:48 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
Message-ID: <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>


OK, I now see that we should try to solve this in some other way...


On 06/01/2017 05:35 AM, Alex Otenko wrote:
> There is code that relies on the CAS behaving like a volatile store
> always. This interpretation is based on direct question “does CAS always
> behave like a volatile store” to the people working on JVM, not plain
> reading of javadoc. It very likely predates C++ spec.
> 

The statement about CAS acting as both volatile load and store was
the best anyone could come up with in terms of JSR133 spec (which
does not cover CAS).

But the main underlying requirements are that each CAS is atomic and
in the total synchronization order, whether it succeeds or fails.
(This is for regular volatile CAS, not the new weaker variants.)

Maybe we should just say this.

It still implies the main property that Alex has been getting at:
 "A failing CAS is strictly after the (volatile) store that failed it."
But does so without explicitly claiming that a failed CAS
has volatile write semantics.

And further implies that Alex's example still holds.

And for ARM, if ldax is used for load, then no fence on failure seems
to be required?

-Doug



From aph at redhat.com  Thu Jun  1 09:02:14 2017
From: aph at redhat.com (Andrew Haley)
Date: Thu, 1 Jun 2017 14:02:14 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
Message-ID: <66bf3585-1623-63ea-a7c4-0d05d8aa72d6@redhat.com>

On 01/06/17 13:25, Doug Lea wrote:
> Maybe we should just say this.
> 
> It still implies the main property that Alex has been getting at:
>  "A failing CAS is strictly after the (volatile) store that failed it."
> But does so without explicitly claiming that a failed CAS
> has volatile write semantics.
> 
> And further implies that Alex's example still holds.
> 
> And for ARM, if ldax is used for load, then no fence on failure seems
> to be required?

LDARX is used for a seq.cst load.  And, no, I don't think that a fence
on failure is needed to ensure that a failing CAS is strictly after
the (volatile) store that failed it.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From dl at cs.oswego.edu  Thu Jun  1 10:11:59 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 1 Jun 2017 10:11:59 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
Message-ID: <209ee1f2-c6b9-e1d5-7004-13e11bb98660@cs.oswego.edu>

On 06/01/2017 08:25 AM, Doug Lea wrote:

> 
> But the main underlying requirements are that each CAS is atomic and
> in the total synchronization order, whether it succeeds or fails.
> 
> Maybe we should just say this.
> 

If so, we'd need to compromise on the stance in VarHandle specs of
not referring to properties of the non-existent JMM revision.
Instead, they incompletely specify in terms of reorderings.
But it seems possible to improve this without committing to
anything not certain to appear in revised JMM. We could add
the following paragraph to top level VarHandle docs, that
is informative even without rigorous definition of terms.
Comments and suggestions welcome.

 *
 * <p>Access modes may be used to control memory consistency
 * properties.  Atomic <em>Volatile</em> operations are totally
 * ordered with respect to each other. Atomic <em>Release/Acquire</em>
 * operations are partially ordered: acquires and their subsequent
 * accesses are ordered after matching releases and their previous
 * accesses. Atomic <em>Opaque</em> operations are coherently ordered
 * only with respect to accesses to the same variable.  Other
 * <em>Plain</em> accesses are atomic only for references and
 * primitive values of at most 32 bits, and impose no observable
 * ordering constraints with respect to threads other than the
 * executing thread.


...Added before parag starting:
 * <p>Access modes are grouped into the following categories:

From gil at azul.com  Thu Jun  1 11:19:09 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 1 Jun 2017 15:19:09 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>,
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
Message-ID: <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>



Sent from my iPad

> On Jun 1, 2017, at 5:31 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> 
> 
> OK, I now see that we should try to solve this in some other way...
> 
> 
>> On 06/01/2017 05:35 AM, Alex Otenko wrote:
>> There is code that relies on the CAS behaving like a volatile store
>> always. This interpretation is based on direct question “does CAS always
>> behave like a volatile store” to the people working on JVM, not plain
>> reading of javadoc. It very likely predates C++ spec.
> 
> The statement about CAS acting as both volatile load and store was
> the best anyone could come up with in terms of JSR133 spec (which
> does not cover CAS).
> 
> But the main underlying requirements are that each CAS is atomic and
> in the total synchronization order, whether it succeeds or fails.
> (This is for regular volatile CAS, not the new weaker variants.)
> 
> Maybe we should just say this.
> 
> It still implies the main property that Alex has been getting at:
> "A failing CAS is strictly after the (volatile) store that failed it."
> But does so without explicitly claiming that a failed CAS
> has volatile write semantics.

I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile. E.g. The CAS-failing store could be Plain, and it may be separately established to be strictly after some other operation (e.g. it may be conditional on the result of a Volatile or Acquire read of some other field), which would establish that the CAS is strictly after that "other operation" even if nothing else does.

Unfortunately (assuming I'm right in the above paragraph), I think the discussion of the Access modes in the proposed javadoc paragraph is not enough to relay this property if it is only coupled with a simple "each CAS is atomic and in the total synchronization order, whether it succeeds or fails." statement.

> 
> And further implies that Alex's example still holds.
> 
> And for ARM, if ldax is used for load, then no fence on failure seems
> to be required?
> 
> -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From oleksandr.otenko at gmail.com  Thu Jun  1 12:01:14 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 1 Jun 2017 17:01:14 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
Message-ID: <B49FBD09-BA42-42E4-9EF3-22B34144AD0B@gmail.com>

The point about guaranteeing a particular order of a volatile load after a volatile store that failed the CAS is that through such ordering a synchronize-with edge is added to the happens-before order as well. If the store is not volatile, there is no mechanism in JMM that would guarantee non-volatile loads after failing CAS to observe something before any other store except earlier volatile stores to the variable the failing CAS was accessing.

Without the edge non-volatile stores may be observed by non-volatile reads, but also maybe not. With the edge there is no option to not observe the stores.

If we claim only total ordering, but not that CAS is a volatile load, it doesn’t imply a synchronize-with edge.

If we claim the total ordering, and that CAS is a load and a store, but not that they are necessarily volatile, it doesn’t imply a synchronize-with edge.


It seems Doug’s version mentioned both. My only question is about ambiguity: does “(volatile)” mean “volatile or not”, or “which of course is volatile”.


Alex


> On 1 Jun 2017, at 16:19, Gil Tene <gil at azul.com> wrote:
> 
> 
> 
> Sent from my iPad
> 
>> On Jun 1, 2017, at 5:31 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>> 
>> 
>> OK, I now see that we should try to solve this in some other way...
>> 
>> 
>>> On 06/01/2017 05:35 AM, Alex Otenko wrote:
>>> There is code that relies on the CAS behaving like a volatile store
>>> always. This interpretation is based on direct question “does CAS always
>>> behave like a volatile store” to the people working on JVM, not plain
>>> reading of javadoc. It very likely predates C++ spec.
>> 
>> The statement about CAS acting as both volatile load and store was
>> the best anyone could come up with in terms of JSR133 spec (which
>> does not cover CAS).
>> 
>> But the main underlying requirements are that each CAS is atomic and
>> in the total synchronization order, whether it succeeds or fails.
>> (This is for regular volatile CAS, not the new weaker variants.)
>> 
>> Maybe we should just say this.
>> 
>> It still implies the main property that Alex has been getting at:
>> "A failing CAS is strictly after the (volatile) store that failed it."
>> But does so without explicitly claiming that a failed CAS
>> has volatile write semantics.
> 
> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile. E.g. The CAS-failing store could be Plain, and it may be separately established to be strictly after some other operation (e.g. it may be conditional on the result of a Volatile or Acquire read of some other field), which would establish that the CAS is strictly after that "other operation" even if nothing else does.
> 
> Unfortunately (assuming I'm right in the above paragraph), I think the discussion of the Access modes in the proposed javadoc paragraph is not enough to relay this property if it is only coupled with a simple "each CAS is atomic and in the total synchronization order, whether it succeeds or fails." statement.
> 
>> 
>> And further implies that Alex's example still holds.
>> 
>> And for ARM, if ldax is used for load, then no fence on failure seems
>> to be required?
>> 
>> -Doug
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170601/0f3c77b1/attachment.html>

From aph at redhat.com  Thu Jun  1 12:53:59 2017
From: aph at redhat.com (Andrew Haley)
Date: Thu, 1 Jun 2017 17:53:59 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
Message-ID: <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>

On 01/06/17 16:19, Gil Tene wrote:
> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile.

How is that even possible?  The store that fails a CAS can propagate
to different threads later: it's not part of the total order.  Perhaps
I'm missing something.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From gil at azul.com  Thu Jun  1 12:58:22 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 1 Jun 2017 16:58:22 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>
Message-ID: <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>


> On Jun 1, 2017, at 9:53 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 01/06/17 16:19, Gil Tene wrote:
>> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile.
> 
> How is that even possible?  The store that fails a CAS can propagate
> to different threads later: it's not part of the total order.  Perhaps
> I'm missing something.

It can. But the CAS failed *because* of that store [it is not allowed to spuriously fail], so the CAS is after that store. And things that are after the CAS are therefore also after that store.

> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671


From dl at cs.oswego.edu  Thu Jun  1 13:04:29 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 1 Jun 2017 13:04:29 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <B49FBD09-BA42-42E4-9EF3-22B34144AD0B@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <B49FBD09-BA42-42E4-9EF3-22B34144AD0B@gmail.com>
Message-ID: <59521af9-9466-5644-427f-5c9c4bd7f10f@cs.oswego.edu>

On 06/01/2017 12:01 PM, Alex Otenko wrote:

> 
> It seems Doug’s version mentioned both. My only question is about
> ambiguity: does “(volatile)” mean “volatile or not”, or “which of course
> is volatile”.

I should have used square brackets. It was a quote from one of your
posts, adding "(volatile)" to provide context.

In any case, the brief definitional paragraph I since posted seems
to be the best solution, modulo any suggestions for improvement.

-Doug


From gil at azul.com  Thu Jun  1 13:07:52 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 1 Jun 2017 17:07:52 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>
 <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
Message-ID: <7506D0FB-22DD-4D1A-B213-E45F6E2328E2@azul.com>


> On Jun 1, 2017, at 9:58 AM, Gil Tene <gil at azul.com> wrote:
> 
> 
>> On Jun 1, 2017, at 9:53 AM, Andrew Haley <aph at redhat.com> wrote:
>> 
>> On 01/06/17 16:19, Gil Tene wrote:
>>> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile.
>> 
>> How is that even possible?  The store that fails a CAS can propagate
>> to different threads later: it's not part of the total order.  Perhaps
>> I'm missing something.
> 
> It can. But the CAS failed *because* of that store [it is not allowed to spuriously fail], so the CAS is after that store. And things that are after the CAS are therefore also after that store.
> 

BTW, I think this is a way to highlight the meaning of an implied volatile write even on failure:

*If* a failing CAS behaves like it had done a volatile store to the field (of the value that it observed and caused the failure, regardless of whether that value was stored there volatile-ly or not before), then that gives the original store that failed the CAS the impact of a Volatile store (at the CAS point) to other threads, even if that original store was Plain. Other threads that do things that happen-after the CAS will have those same things happen-after the failing store. 

However, if the failing CAS does not carry the behavior of a volatile store on failure, and the store that failed the CAS was Plain, other threads may do things that happen-after the failing CAS, but which may not observe the failing store.

>> 
>> -- 
>> Andrew Haley
>> Java Platform Lead Engineer
>> Red Hat UK Ltd. <https://www.redhat.com>
>> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> 


From aph at redhat.com  Thu Jun  1 13:43:45 2017
From: aph at redhat.com (Andrew Haley)
Date: Thu, 1 Jun 2017 18:43:45 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>
 <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
Message-ID: <169c568f-5048-0a58-4a80-76d50fea202e@redhat.com>

On 01/06/17 17:58, Gil Tene wrote:
> 
>> On Jun 1, 2017, at 9:53 AM, Andrew Haley <aph at redhat.com> wrote:
>>
>> On 01/06/17 16:19, Gil Tene wrote:
>>> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile.
>>
>> How is that even possible?  The store that fails a CAS can propagate
>> to different threads later: it's not part of the total order.  Perhaps
>> I'm missing something.
> 
> It can. But the CAS failed *because* of that store [it is not allowed to spuriously fail], so the CAS is after that store. And things that are after the CAS are therefore also after that store.

OK, I see.  Thanks.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Thu Jun  1 14:10:53 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 1 Jun 2017 19:10:53 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <7073b57d-429e-49bd-82dc-e99c7cd6ead4@redhat.com>
 <99663BD3-D12A-4797-8E26-B6298969659C@azul.com>
Message-ID: <5FB64F89-C1CA-4989-97DF-6BC1B4CA6B69@gmail.com>

After “that” store in which order from JMM?


Alex

> On 1 Jun 2017, at 17:58, Gil Tene <gil at azul.com> wrote:
> 
> 
>> On Jun 1, 2017, at 9:53 AM, Andrew Haley <aph at redhat.com> wrote:
>> 
>> On 01/06/17 16:19, Gil Tene wrote:
>>> I think the property is that a failing CAS is strictly after the store that failed it, period. Regardless of whether or not that store was volatile.
>> 
>> How is that even possible?  The store that fails a CAS can propagate
>> to different threads later: it's not part of the total order.  Perhaps
>> I'm missing something.
> 
> It can. But the CAS failed *because* of that store [it is not allowed to spuriously fail], so the CAS is after that store. And things that are after the CAS are therefore also after that store.
> 
>> 
>> -- 
>> Andrew Haley
>> Java Platform Lead Engineer
>> Red Hat UK Ltd. <https://www.redhat.com>
>> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Fri Jun  2 07:48:22 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 2 Jun 2017 07:48:22 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <66bf3585-1623-63ea-a7c4-0d05d8aa72d6@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <66bf3585-1623-63ea-a7c4-0d05d8aa72d6@redhat.com>
Message-ID: <c0153f65-3c8e-bca2-f86d-21072e7f48c4@cs.oswego.edu>

On 06/01/2017 09:02 AM, Andrew Haley wrote:

> LDARX is used for a seq.cst load.  And, no, I don't think that a fence
> on failure is needed to ensure that a failing CAS is strictly after
> the (volatile) store that failed it.
> 

For completeness (and to hopefully reduce confusion), mappings
using non-acq/rel versions of ld/st on POWER/ARM still require
a fence; easiest as unconditional trailing fence.

Also, here's an update of the proposed VarHandle paragraph.
It's more informative to phrase it in reverse order compared to
previous version:


 * <p>Access modes control atomicity and memory consistency
 * properties.  <em>Plain</em> <tt>get</tt> and <tt>set</tt> accesses
 * are guaranteed to be bitwise atomic only for references and
 * primitive values of at most 32 bits, and impose no observable
 * ordering constraints with respect to threads other than the
 * executing thread. <em>Opaque</em> operations are bitwise atomic and
 * coherently ordered with respect to accesses to the same variable.
 * In addition to obeying Opaque properties, <em>Release/Acquire</em>
 * operations are partially ordered: acquires and their subsequent
 * accesses are ordered after matching releases and their previous
 * accesses.  In addition to obeying Release/Acquire properties,
 * <em>Volatile</em> operations are totally ordered with respect to
 * each other.
 *

From dl at cs.oswego.edu  Fri Jun  2 08:06:45 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 2 Jun 2017 08:06:45 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
Message-ID: <e295a641-6384-5ed1-045c-0eed6f4f9952@cs.oswego.edu>

On 06/01/2017 11:19 AM, Gil Tene wrote:

> 
> I think the property is that a failing CAS is strictly after the
> store that failed it, period. Regardless of whether or not that store
> was volatile. 

Yes, but if it was a plain store, then this need not convey
any information about any other access that could have been
reordered with respect to it. So, even though the read-from
edge can be deduced, we don't need to say anything about it.

-Doug

From openjdk at duigou.org  Mon Jun  5 15:40:57 2017
From: openjdk at duigou.org (Mike Duigou)
Date: Mon, 05 Jun 2017 12:40:57 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating?
In-Reply-To: <mailman.1.1496419201.1185.concurrency-interest@cs.oswego.edu>
References: <mailman.1.1496419201.1185.concurrency-interest@cs.oswego.edu>
Message-ID: <de68976599112c080980798b0a5d616a@duigou.org>

I am glad that my original question led to such a fruitful discussion. 
With the conclusion that the Java 8 semantics will be preserved as much 
as possible and the Java 9 descriptions (and implementations?) will be 
amended to conform is there interest in pursuing the "optimized" 
write-eliminating versions? For algorithms (most?) that don't rely on 
the CAS write happening for unchanged values elimination of the write 
seems like a sizeable win for functions that rarely change the value.

public static <T> boolean compareAndSetOpt(AtomicReference<T> ref, T 
expect, T update) {
   return expect != update
     ? ref.compareAndSet(expect, update)
     : expect == ref.get();
}

public static <V> V updateAndGetOpt(AtomicReference<V> ref, 
UnaryOperator<V> updateFunction) {
      V prev = ref.get(), next = null;
      for (boolean haveNext = false;;) {
          if (!haveNext)
              next = updateFunction.apply(prev);
          if (compareAndSetOpt(ref, prev, next))
              return next;
          haveNext = (prev == (prev = ref.get()));
      }
}

Typical usage for me is a linked list:

class Foo {
   final AtomicReference<Foo> nextFoo = new AtomicReference<>();

   /**
    * Returns the successor Foo to this Foo creating it if necessary
    *
    * @return the next Foo
   */
   public Foo nextFoo() {
     return nextFoo.updateAndGet(e -> null != e ? e : new Foo());
   }
}

For this usage the value of nextFoo is only ever changed once, from null 
to some Foo the first time nextFoo() is called. Because this particular 
usage is extreme with the value only changing once I am actually using a 
slightly different version of nextFoo() currently:

public Foo nextFoo() {
   Foo next = nextFoo.get();
   return null != next ? next : nextFoo.updateAndGet(e -> null != e ? e : 
new Foo());
}

which optimizes for read at the cost of an extra volatile read for 
update. I have other usages that are more balanced between the update 
function returning the original value or a different value and use the 
original version of nextFoo().

From jsampson at guidewire.com  Mon Jun  5 16:10:08 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Mon, 5 Jun 2017 20:10:08 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating?
In-Reply-To: <de68976599112c080980798b0a5d616a@duigou.org>
References: <mailman.1.1496419201.1185.concurrency-interest@cs.oswego.edu>
 <de68976599112c080980798b0a5d616a@duigou.org>
Message-ID: <5A2AEE34-5435-45AE-89D4-F9A47DC9EA97@guidewire.com>

Hi Mike,

That particular use case really sounds like you want something like Guava's Suppliers.memoize(), which has the added benefit of guaranteeing to only invoke the lambda once (thereby avoiding the occasional garbage Foo being created).

Still, it does seem to me that we need some language somewhere in the JDK docs describing the kind of optimized CAS that you're talking about, since there are already two compareAndSet methods in j.u.c.atomic that behave that way.

Cheers,
Justin


On 6/5/17, 12:40 PM, "Concurrency-interest on behalf of Mike Duigou" <concurrency-interest-bounces at cs.oswego.edu on behalf of openjdk at duigou.org> wrote:

    I am glad that my original question led to such a fruitful discussion. 
    With the conclusion that the Java 8 semantics will be preserved as much 
    as possible and the Java 9 descriptions (and implementations?) will be 
    amended to conform is there interest in pursuing the "optimized" 
    write-eliminating versions? For algorithms (most?) that don't rely on 
    the CAS write happening for unchanged values elimination of the write 
    seems like a sizeable win for functions that rarely change the value.
    
    public static <T> boolean compareAndSetOpt(AtomicReference<T> ref, T 
    expect, T update) {
       return expect != update
         ? ref.compareAndSet(expect, update)
         : expect == ref.get();
    }
    
    public static <V> V updateAndGetOpt(AtomicReference<V> ref, 
    UnaryOperator<V> updateFunction) {
          V prev = ref.get(), next = null;
          for (boolean haveNext = false;;) {
              if (!haveNext)
                  next = updateFunction.apply(prev);
              if (compareAndSetOpt(ref, prev, next))
                  return next;
              haveNext = (prev == (prev = ref.get()));
          }
    }
    
    Typical usage for me is a linked list:
    
    class Foo {
       final AtomicReference<Foo> nextFoo = new AtomicReference<>();
    
       /**
        * Returns the successor Foo to this Foo creating it if necessary
        *
        * @return the next Foo
       */
       public Foo nextFoo() {
         return nextFoo.updateAndGet(e -> null != e ? e : new Foo());
       }
    }
    
    For this usage the value of nextFoo is only ever changed once, from null 
    to some Foo the first time nextFoo() is called. Because this particular 
    usage is extreme with the value only changing once I am actually using a 
    slightly different version of nextFoo() currently:
    
    public Foo nextFoo() {
       Foo next = nextFoo.get();
       return null != next ? next : nextFoo.updateAndGet(e -> null != e ? e : 
    new Foo());
    }
    
    which optimizes for read at the cost of an extra volatile read for 
    update. I have other usages that are more balanced between the update 
    function returning the original value or a different value and use the 
    original version of nextFoo().
 


From boehm at acm.org  Mon Jun  5 17:16:21 2017
From: boehm at acm.org (Hans Boehm)
Date: Mon, 5 Jun 2017 14:16:21 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <e295a641-6384-5ed1-045c-0eed6f4f9952@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>
 <4DBD552C-9264-40E2-B5D3-119279C20509@gmail.com>
 <85f0bc84-fb78-baee-8195-a9a50282e704@cs.oswego.edu>
 <D0F22A27-DD6F-4A22-9733-2ED63F265A58@azul.com>
 <e295a641-6384-5ed1-045c-0eed6f4f9952@cs.oswego.edu>
Message-ID: <CAPUmR1atML-_u1gTh9Z1jdXVXZpqPfpYQyhFyw8D_CnZ3Y1sRQ@mail.gmail.com>

Strongly agreed. From a practical implementation perspective, establishing
a happens-before ordering from a plain failing store to a CAS would require
a fence, or release semantics, to be associated with plain stores. Or CAS
would have to use some Linux-membarrier() like heavy-weight one sided
barrier construct. I don't see how to make that at all practical.

If your code has a plain store failing a (volatile) CAS, you are in wizard
territory and better know how to deal with the consequences.

On Fri, Jun 2, 2017 at 5:06 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 06/01/2017 11:19 AM, Gil Tene wrote:
>
> >
> > I think the property is that a failing CAS is strictly after the
> > store that failed it, period. Regardless of whether or not that store
> > was volatile.
>
> Yes, but if it was a plain store, then this need not convey
> any information about any other access that could have been
> reordered with respect to it. So, even though the read-from
> edge can be deduced, we don't need to say anything about it.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170605/334d52d7/attachment.html>

From martinrb at google.com  Mon Jun  5 21:59:11 2017
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 5 Jun 2017 18:59:11 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating?
In-Reply-To: <de68976599112c080980798b0a5d616a@duigou.org>
References: <mailman.1.1496419201.1185.concurrency-interest@cs.oswego.edu>
 <de68976599112c080980798b0a5d616a@duigou.org>
Message-ID: <CA+kOe0_wVdW21iZo2PanN3r+s7JyPh=vYGPA_aWr7iLkAWeoSA@mail.gmail.com>

I'm still hoping for a failed CAS to NOT be equivalent to a volatile write,
but instead a volatile read, as in C++.

For low-level lock-free linked list manipulating code
(LinkedTransferQueue), I would not use updateAndGet but instead write my
own CAS loops.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170605/6476a761/attachment.html>

From jarkko.miettinen at relex.fi  Tue Jun  6 11:32:10 2017
From: jarkko.miettinen at relex.fi (Jarkko Miettinen)
Date: Tue, 6 Jun 2017 18:32:10 +0300
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
	starting a new thread fails?
Message-ID: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>

Hi,

This does seem like something that would've been discussed before here, 
but I could not find anything in the archives or a bug report.

In any case, currently if starting a new thread in 
ForkJoinPool#createWorker fails with an exception (OutOfMemoryError 
being the most common),  the thread that tries to start that new thread 
dies too. In specific situations this can lead to all threads in the 
ForkJoinPool dying out which does seem strictly worse than running just 
those threads and not spawning new ones.

I think OutOfMemoryError is generally be considered something that 
should not be recovered from. But might we here make a different choice 
as Thread#start can throw an OOM if it runs into process limits that 
prevent starting new threads (why, oh why). This also happens in very 
tightly controlled situation and we might want to just continue working 
on the tasks. At least if Thread#start has not been overridden.

As code in ForkJoinPool is a bit dense, I am not quite sure what are the 
exact required conditions. I just know that there should be both tasks 
in the pool and still be room for additional threads in the pool.

The problem will then manifest in stack traces such as this (Oracle JDK 
1.8.0_92):

Exception in thread "ForkJoinPool-3983-worker-33" 
java.lang.OutOfMemoryError: unable to create new native thread
         at java.lang.Thread.start0(Native Method)
         at java.lang.Thread.start(Thread.java:714)
         at 
java.util.concurrent.ForkJoinPool.createWorker(ForkJoinPool.java:1486)
         at 
java.util.concurrent.ForkJoinPool.tryAddWorker(ForkJoinPool.java:1517)
         at 
java.util.concurrent.ForkJoinPool.signalWork(ForkJoinPool.java:1634)
         at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1733)
         at 
java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1691)
         at 
java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)

The little I looked in the latest jsr166 version in the CVS, the 
situation seems to be the same even if the methods have changed quite a 
bit.

My question is: Is there any way to prevent this and would such 
prevention would be beneficial in some or all cases?

At least naively it would seem that Thread#start fails with OOM, we 
could just return false and let the existing thread continue. But this 
probably is not something that's always wanted and can mask other, more 
serious OOMs.

-Jarkko


From nathanila at gmail.com  Tue Jun  6 11:42:26 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Tue, 6 Jun 2017 09:42:26 -0600
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
 starting a new thread fails?
In-Reply-To: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
References: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
Message-ID: <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>

It seems that we have semantic overload here.  There are many factors 
which could prevent a new thread from being created.  One such factor is 
that there is no address space in the process to create the thread's 
stack.  Another such factor is that the process has too many threads.  
It would be great if different exceptions could be thrown based on the 
actual condition.  This would make it easier to diagnose the problem.  
It would also allow for the code to catch OutOfThreadHandlesException 
and simply run with the existing threads in the pool.

I realize that this is going to be tricky since each OS has its own set 
of thread creation problems.  Mapping the disparate sets of problems 
into similar meaningful exceptions is going to take a lot of thought.  
Perhaps, someone can collect the various reasons why thread creation 
could fail for each OS, then then a group can figure out how to map them 
to exceptions.

-Nathan

On 6/6/2017 9:32 AM, Jarkko Miettinen wrote:
> Hi,
>
> This does seem like something that would've been discussed before 
> here, but I could not find anything in the archives or a bug report.
>
> In any case, currently if starting a new thread in 
> ForkJoinPool#createWorker fails with an exception (OutOfMemoryError 
> being the most common),  the thread that tries to start that new 
> thread dies too. In specific situations this can lead to all threads 
> in the ForkJoinPool dying out which does seem strictly worse than 
> running just those threads and not spawning new ones.
>
> I think OutOfMemoryError is generally be considered something that 
> should not be recovered from. But might we here make a different 
> choice as Thread#start can throw an OOM if it runs into process limits 
> that prevent starting new threads (why, oh why). This also happens in 
> very tightly controlled situation and we might want to just continue 
> working on the tasks. At least if Thread#start has not been overridden.
>
> As code in ForkJoinPool is a bit dense, I am not quite sure what are 
> the exact required conditions. I just know that there should be both 
> tasks in the pool and still be room for additional threads in the pool.
>
> The problem will then manifest in stack traces such as this (Oracle 
> JDK 1.8.0_92):
>
> Exception in thread "ForkJoinPool-3983-worker-33" 
> java.lang.OutOfMemoryError: unable to create new native thread
>         at java.lang.Thread.start0(Native Method)
>         at java.lang.Thread.start(Thread.java:714)
>         at 
> java.util.concurrent.ForkJoinPool.createWorker(ForkJoinPool.java:1486)
>         at 
> java.util.concurrent.ForkJoinPool.tryAddWorker(ForkJoinPool.java:1517)
>         at 
> java.util.concurrent.ForkJoinPool.signalWork(ForkJoinPool.java:1634)
>         at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1733)
>         at 
> java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1691)
>         at 
> java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
>
> The little I looked in the latest jsr166 version in the CVS, the 
> situation seems to be the same even if the methods have changed quite 
> a bit.
>
> My question is: Is there any way to prevent this and would such 
> prevention would be beneficial in some or all cases?
>
> At least naively it would seem that Thread#start fails with OOM, we 
> could just return false and let the existing thread continue. But this 
> probably is not something that's always wanted and can mask other, 
> more serious OOMs.
>
> -Jarkko
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From bronee at gmail.com  Tue Jun  6 11:48:19 2017
From: bronee at gmail.com (Brian S O'Neill)
Date: Tue, 6 Jun 2017 08:48:19 -0700
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
 starting a new thread fails?
In-Reply-To: <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>
References: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
 <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>
Message-ID: <430d2e24-3674-e15c-8d10-fd55cba33343@gmail.com>

Complicating things further is the Linux OOM killer. Creating and 
destroying threads at a high rate can increase the likelihood that the 
process gets abruptly killed. So catching the proposed 
OutOfThreadHandlesException and proceeding might make the process become 
more unstable -- quite the opposite of the intended outcome.

On 2017-06-06 08:42 AM, Nathan and Ila Reynolds wrote:
> It seems that we have semantic overload here.  There are many factors 
> which could prevent a new thread from being created.  One such factor is 
> that there is no address space in the process to create the thread's 
> stack.  Another such factor is that the process has too many threads. It 
> would be great if different exceptions could be thrown based on the 
> actual condition.  This would make it easier to diagnose the problem. It 
> would also allow for the code to catch OutOfThreadHandlesException and 
> simply run with the existing threads in the pool.
> 
> I realize that this is going to be tricky since each OS has its own set 
> of thread creation problems.  Mapping the disparate sets of problems 
> into similar meaningful exceptions is going to take a lot of thought. 
> Perhaps, someone can collect the various reasons why thread creation 
> could fail for each OS, then then a group can figure out how to map them 
> to exceptions.
> 
> -Nathan
> 
> On 6/6/2017 9:32 AM, Jarkko Miettinen wrote:
>> Hi,
>>
>> This does seem like something that would've been discussed before 
>> here, but I could not find anything in the archives or a bug report.
>>
>> In any case, currently if starting a new thread in 
>> ForkJoinPool#createWorker fails with an exception (OutOfMemoryError 
>> being the most common),  the thread that tries to start that new 
>> thread dies too. In specific situations this can lead to all threads 
>> in the ForkJoinPool dying out which does seem strictly worse than 
>> running just those threads and not spawning new ones.
>>
>> I think OutOfMemoryError is generally be considered something that 
>> should not be recovered from. But might we here make a different 
>> choice as Thread#start can throw an OOM if it runs into process limits 
>> that prevent starting new threads (why, oh why). This also happens in 
>> very tightly controlled situation and we might want to just continue 
>> working on the tasks. At least if Thread#start has not been overridden.
>>
>> As code in ForkJoinPool is a bit dense, I am not quite sure what are 
>> the exact required conditions. I just know that there should be both 
>> tasks in the pool and still be room for additional threads in the pool.
>>
>> The problem will then manifest in stack traces such as this (Oracle 
>> JDK 1.8.0_92):
>>
>> Exception in thread "ForkJoinPool-3983-worker-33" 
>> java.lang.OutOfMemoryError: unable to create new native thread
>>         at java.lang.Thread.start0(Native Method)
>>         at java.lang.Thread.start(Thread.java:714)
>>         at 
>> java.util.concurrent.ForkJoinPool.createWorker(ForkJoinPool.java:1486)
>>         at 
>> java.util.concurrent.ForkJoinPool.tryAddWorker(ForkJoinPool.java:1517)
>>         at 
>> java.util.concurrent.ForkJoinPool.signalWork(ForkJoinPool.java:1634)
>>         at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1733)
>>         at 
>> java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1691)
>>         at 
>> java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157) 
>>
>>
>> The little I looked in the latest jsr166 version in the CVS, the 
>> situation seems to be the same even if the methods have changed quite 
>> a bit.
>>
>> My question is: Is there any way to prevent this and would such 
>> prevention would be beneficial in some or all cases?
>>
>> At least naively it would seem that Thread#start fails with OOM, we 
>> could just return false and let the existing thread continue. But this 
>> probably is not something that's always wanted and can mask other, 
>> more serious OOMs.
>>
>> -Jarkko
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From nathanila at gmail.com  Tue Jun  6 13:56:31 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Tue, 6 Jun 2017 11:56:31 -0600
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
 starting a new thread fails?
In-Reply-To: <430d2e24-3674-e15c-8d10-fd55cba33343@gmail.com>
References: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
 <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>
 <430d2e24-3674-e15c-8d10-fd55cba33343@gmail.com>
Message-ID: <8c894d57-4d1d-129e-8bc1-432d4d173b55@gmail.com>

By the time OutOfThreadHandlesException is thrown, the likelihood that 
the process gets killed by OOM killer is already at the maximum as far 
as thread count is concerned.  Catching and dealing with 
OutOfThreadHandlesException is already too late for impacting OOM 
killer's decision.  However, if one catches OutOfThreadHandlesException 
and then have several threads terminate, then the process might escape 
OOM killer.

-Nathan

On 6/6/2017 9:48 AM, Brian S O'Neill wrote:
> Complicating things further is the Linux OOM killer. Creating and 
> destroying threads at a high rate can increase the likelihood that the 
> process gets abruptly killed. So catching the proposed 
> OutOfThreadHandlesException and proceeding might make the process 
> become more unstable -- quite the opposite of the intended outcome.
>
> On 2017-06-06 08:42 AM, Nathan and Ila Reynolds wrote:
>> It seems that we have semantic overload here.  There are many factors 
>> which could prevent a new thread from being created.  One such factor 
>> is that there is no address space in the process to create the 
>> thread's stack.  Another such factor is that the process has too many 
>> threads. It would be great if different exceptions could be thrown 
>> based on the actual condition.  This would make it easier to diagnose 
>> the problem. It would also allow for the code to catch 
>> OutOfThreadHandlesException and simply run with the existing threads 
>> in the pool.
>>
>> I realize that this is going to be tricky since each OS has its own 
>> set of thread creation problems.  Mapping the disparate sets of 
>> problems into similar meaningful exceptions is going to take a lot of 
>> thought. Perhaps, someone can collect the various reasons why thread 
>> creation could fail for each OS, then then a group can figure out how 
>> to map them to exceptions.
>>
>> -Nathan
>>
>> On 6/6/2017 9:32 AM, Jarkko Miettinen wrote:
>>> Hi,
>>>
>>> This does seem like something that would've been discussed before 
>>> here, but I could not find anything in the archives or a bug report.
>>>
>>> In any case, currently if starting a new thread in 
>>> ForkJoinPool#createWorker fails with an exception (OutOfMemoryError 
>>> being the most common),  the thread that tries to start that new 
>>> thread dies too. In specific situations this can lead to all threads 
>>> in the ForkJoinPool dying out which does seem strictly worse than 
>>> running just those threads and not spawning new ones.
>>>
>>> I think OutOfMemoryError is generally be considered something that 
>>> should not be recovered from. But might we here make a different 
>>> choice as Thread#start can throw an OOM if it runs into process 
>>> limits that prevent starting new threads (why, oh why). This also 
>>> happens in very tightly controlled situation and we might want to 
>>> just continue working on the tasks. At least if Thread#start has not 
>>> been overridden.
>>>
>>> As code in ForkJoinPool is a bit dense, I am not quite sure what are 
>>> the exact required conditions. I just know that there should be both 
>>> tasks in the pool and still be room for additional threads in the pool.
>>>
>>> The problem will then manifest in stack traces such as this (Oracle 
>>> JDK 1.8.0_92):
>>>
>>> Exception in thread "ForkJoinPool-3983-worker-33" 
>>> java.lang.OutOfMemoryError: unable to create new native thread
>>>         at java.lang.Thread.start0(Native Method)
>>>         at java.lang.Thread.start(Thread.java:714)
>>>         at 
>>> java.util.concurrent.ForkJoinPool.createWorker(ForkJoinPool.java:1486)
>>>         at 
>>> java.util.concurrent.ForkJoinPool.tryAddWorker(ForkJoinPool.java:1517)
>>>         at 
>>> java.util.concurrent.ForkJoinPool.signalWork(ForkJoinPool.java:1634)
>>>         at 
>>> java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1733)
>>>         at 
>>> java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1691)
>>>         at 
>>> java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157) 
>>>
>>>
>>> The little I looked in the latest jsr166 version in the CVS, the 
>>> situation seems to be the same even if the methods have changed 
>>> quite a bit.
>>>
>>> My question is: Is there any way to prevent this and would such 
>>> prevention would be beneficial in some or all cases?
>>>
>>> At least naively it would seem that Thread#start fails with OOM, we 
>>> could just return false and let the existing thread continue. But 
>>> this probably is not something that's always wanted and can mask 
>>> other, more serious OOMs.
>>>
>>> -Jarkko
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From oleksandr.otenko at gmail.com  Tue Jun  6 15:44:59 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 6 Jun 2017 20:44:59 +0100
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
	starting a new thread fails?
In-Reply-To: <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>
References: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
 <7a6f50e2-7d8c-d1bc-f258-6c81967f31c5@gmail.com>
Message-ID: <05558A03-D743-42F8-97D7-6968EA768407@gmail.com>

What is the failure model here?

1. Provisioned a limit of N threads
2. Consumed N threads
3. Creation of N+1 thread fails

What is the limit of N threads based on? Should the thread pools be sized instead to not exceed N? Is the target software creating threads outside pools?

I think there may be a few good engineering practices to take into account first. OOME on thread creation means someone did not heed those practices: did not size the environment, did not size pools, spawned non-pooled threads.

Alex

> On 6 Jun 2017, at 16:42, Nathan and Ila Reynolds <nathanila at gmail.com> wrote:
> 
> It seems that we have semantic overload here.  There are many factors which could prevent a new thread from being created.  One such factor is that there is no address space in the process to create the thread's stack.  Another such factor is that the process has too many threads.  It would be great if different exceptions could be thrown based on the actual condition.  This would make it easier to diagnose the problem.  It would also allow for the code to catch OutOfThreadHandlesException and simply run with the existing threads in the pool.
> 
> I realize that this is going to be tricky since each OS has its own set of thread creation problems.  Mapping the disparate sets of problems into similar meaningful exceptions is going to take a lot of thought.  Perhaps, someone can collect the various reasons why thread creation could fail for each OS, then then a group can figure out how to map them to exceptions.
> 
> -Nathan
> 
> On 6/6/2017 9:32 AM, Jarkko Miettinen wrote:
>> Hi,
>> 
>> This does seem like something that would've been discussed before here, but I could not find anything in the archives or a bug report.
>> 
>> In any case, currently if starting a new thread in ForkJoinPool#createWorker fails with an exception (OutOfMemoryError being the most common),  the thread that tries to start that new thread dies too. In specific situations this can lead to all threads in the ForkJoinPool dying out which does seem strictly worse than running just those threads and not spawning new ones.
>> 
>> I think OutOfMemoryError is generally be considered something that should not be recovered from. But might we here make a different choice as Thread#start can throw an OOM if it runs into process limits that prevent starting new threads (why, oh why). This also happens in very tightly controlled situation and we might want to just continue working on the tasks. At least if Thread#start has not been overridden.
>> 
>> As code in ForkJoinPool is a bit dense, I am not quite sure what are the exact required conditions. I just know that there should be both tasks in the pool and still be room for additional threads in the pool.
>> 
>> The problem will then manifest in stack traces such as this (Oracle JDK 1.8.0_92):
>> 
>> Exception in thread "ForkJoinPool-3983-worker-33" java.lang.OutOfMemoryError: unable to create new native thread
>>        at java.lang.Thread.start0(Native Method)
>>        at java.lang.Thread.start(Thread.java:714)
>>        at java.util.concurrent.ForkJoinPool.createWorker(ForkJoinPool.java:1486)
>>        at java.util.concurrent.ForkJoinPool.tryAddWorker(ForkJoinPool.java:1517)
>>        at java.util.concurrent.ForkJoinPool.signalWork(ForkJoinPool.java:1634)
>>        at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1733)
>>        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1691)
>>        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
>> 
>> The little I looked in the latest jsr166 version in the CVS, the situation seems to be the same even if the methods have changed quite a bit.
>> 
>> My question is: Is there any way to prevent this and would such prevention would be beneficial in some or all cases?
>> 
>> At least naively it would seem that Thread#start fails with OOM, we could just return false and let the existing thread continue. But this probably is not something that's always wanted and can mask other, more serious OOMs.
>> 
>> -Jarkko
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> -- 
> -Nathan
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dl at cs.oswego.edu  Tue Jun  6 18:59:48 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 6 Jun 2017 18:59:48 -0400
Subject: [concurrency-interest] Should old ForkJoinWorkerThread die if
 starting a new thread fails?
In-Reply-To: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
References: <38ea8db5-d15b-aab2-885a-4e788f72991a@relexsolutions.com>
Message-ID: <30208f0d-b790-98b7-e991-7509b01fb75d@cs.oswego.edu>

On 06/06/2017 11:32 AM, Jarkko Miettinen wrote:

> In any case, currently if starting a new thread in
> ForkJoinPool#createWorker fails with an exception (OutOfMemoryError
> being the most common),  the thread that tries to start that new thread
> dies too.

You can catch the exception, and try to cope.
One possibility is to try to help execute tasks that might
not otherwise be run. As in:

try {
   task.fork(); // or
   pool.submit(task); // or similar
} catch (Exception ex) {
   ForkJoinTask.helpQuiesce(); // or
   pool.awaitQuiescence(1, SECONDS); // help run tasks for at most 1 sec
}

(You could then encasulate this as a helper method.)

If the failure is a memory-based OOME, then this might also fail.
And in any case won't execute tasks  asynchronously using the same
scheduling. But it does provide a best-effort fallback.

> I think OutOfMemoryError is generally be considered something that
> should not be recovered from. 

As implied in other replies, one reason for not retrying here
(also ThreadPoolExecutor) is to help avoid infinitely cascading
(and sometimes silent) failures, for which we (in j.u.c) have no
recourse.

-Doug


From valentin.male.kovalenko at gmail.com  Wed Jun  7 13:11:34 2017
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 7 Jun 2017 20:11:34 +0300
Subject: [concurrency-interest] Why does JMM mention sequential consistency
	(SC)?
Message-ID: <CAO-wXwJEdsdZ6eeewDs3UMqe-BLr4ur+pU-QKi3i_yZo71AS_w@mail.gmail.com>

I truly can't understand this because of the following points:

- (1) It's impossible to reason about correctness of a program as a whole,
and programmers always do it by reasoning about correctness of smaller
parts (objects), and then combine objects into something bigger.
Linearizability allows us to do exactly this because of its locality, while
SC only allows to reason about the whole execution, and I can't see how it
may be practical, or even possible.
- (2) Programmers reason about correctness of objects not by using
sequential consistency, but rather by using restrictions JMM imposes on
executions (e.g. well-formed executions, causality requirements).
- (3) For most of existing programs JMM doesn't guarantee that all
executions will appear to be sequentially consistent, because most of
existing programs are incorrectly synchronized (in a benign way). Please
see the explanation why it is so after my question.

So the question is: if programmers don't (and often can't) use SC for
reasoning about correctness of Java programs, then why JMM even mentions
it? Is it for those who write JVM's (i.e. implement Java language
specification)? If so, then can someone explain why is this useful for JVM
writers?


Explanation of the statement (3)
JMM says
- (a) "When a program contains two conflicting accesses that are not
ordered by a happens-before relationship, it is said to contain a data
race."
(btw, strictly speaking, it's not a program, but execution that may have
read/write actions and contain data races; so it's a little bit strange
wording)
- (b) "A program is correctly synchronized if and only if all sequentially
consistent executions are free of data races."
- (c) "If a program is correctly synchronized, then all executions of the
program will appear to be sequentially consistent."

We all know that String.hashCode method is written in such a way that it
allows existence of executions that have data races on the String.hash
variable (benign, but still data races). And it's hard to imagine a program
that doesn't use String.hashCode implicitly (just use String keys in a
HashMap and voila). Thus we can say, that according to JMM all such
programs (i.e. almost all programs) are incorrectly synchronized, and hence
sequential consistency is not guaranteed.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170607/1b1e0991/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Jun  7 14:28:13 2017
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 7 Jun 2017 21:28:13 +0300
Subject: [concurrency-interest] Why does JMM mention sequential consistency
	(SC)?
Message-ID: <CAO-wXwLzdcoLyv65rfbA6z6Px4dzTPmP3f54QTWkV1gUD8-fKA@mail.gmail.com>

Just to clarify my thoughts and question:
JMM defines "conflicting access" just to define "data race". "data race" is
defined just to introduce a criterium for and a concept of "correctly
synchronized program" which, in turn, is only used to say that executions
of such a program is SC. But SC itself adds nothing useful for Java
programmer besides what JMM guarantees anyway. So three concepts
(conflicting access, data race, correctly synchronized program) seem to be
introduced in JMM for nothing?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170607/d1ed1555/attachment.html>

From oleksandr.otenko at gmail.com  Wed Jun  7 15:23:31 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Wed, 7 Jun 2017 20:23:31 +0100
Subject: [concurrency-interest] Why does JMM mention sequential
	consistency (SC)?
In-Reply-To: <CAO-wXwJEdsdZ6eeewDs3UMqe-BLr4ur+pU-QKi3i_yZo71AS_w@mail.gmail.com>
References: <CAO-wXwJEdsdZ6eeewDs3UMqe-BLr4ur+pU-QKi3i_yZo71AS_w@mail.gmail.com>
Message-ID: <399D3B6D-924E-4273-B1D0-8AA4D41AC97B@gmail.com>

All of these definitions are there so you can talk about the correctness of the program in a hardware-agnostic manner. It is the JVM’s job then to establish the bridge between the abstract notion of correctness and the actual code executed by, and effects observed on the hardware platform.

Sequential Consistency is the weakest (or is it strongest?) correctness guarantee you want to be achievable in JMM. (“Can you at least construct sequentially consistent Java programs?”)


“data race” is a useful term when talking about the program. In order to be able to tell what is wrong with the program, you might need new terms.


Establishing whether some executions are possible such that the program will not be sequentially consistent, is a difficult business. Enumerating all possible executions is not practical, and does not establish universal properties of the algorithm. And yet, this only makes the enumeration of possible executions a useless enterprise, not sequential consistency as a property.


Alex

> On 7 Jun 2017, at 18:11, Valentin Kovalenko <valentin.male.kovalenko at gmail.com> wrote:
> 
> I truly can't understand this because of the following points:
> 
> - (1) It's impossible to reason about correctness of a program as a whole, and programmers always do it by reasoning about correctness of smaller parts (objects), and then combine objects into something bigger. Linearizability allows us to do exactly this because of its locality, while SC only allows to reason about the whole execution, and I can't see how it may be practical, or even possible.
> - (2) Programmers reason about correctness of objects not by using sequential consistency, but rather by using restrictions JMM imposes on executions (e.g. well-formed executions, causality requirements).
> - (3) For most of existing programs JMM doesn't guarantee that all executions will appear to be sequentially consistent, because most of existing programs are incorrectly synchronized (in a benign way). Please see the explanation why it is so after my question.
> 
> So the question is: if programmers don't (and often can't) use SC for reasoning about correctness of Java programs, then why JMM even mentions it? Is it for those who write JVM's (i.e. implement Java language specification)? If so, then can someone explain why is this useful for JVM writers?
> 
> 
> Explanation of the statement (3)
> JMM says
> - (a) "When a program contains two conflicting accesses that are not ordered by a happens-before relationship, it is said to contain a data race."
> (btw, strictly speaking, it's not a program, but execution that may have read/write actions and contain data races; so it's a little bit strange wording)
> - (b) "A program is correctly synchronized if and only if all sequentially consistent executions are free of data races."
> - (c) "If a program is correctly synchronized, then all executions of the program will appear to be sequentially consistent."
> 
> We all know that String.hashCode method is written in such a way that it allows existence of executions that have data races on the String.hash variable (benign, but still data races). And it's hard to imagine a program that doesn't use String.hashCode implicitly (just use String keys in a HashMap and voila). Thus we can say, that according to JMM all such programs (i.e. almost all programs) are incorrectly synchronized, and hence sequential consistency is not guaranteed.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From valentin.male.kovalenko at gmail.com  Wed Jun  7 15:40:50 2017
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 7 Jun 2017 22:40:50 +0300
Subject: [concurrency-interest] Why does JMM mention sequential consistency
	(SC)?
Message-ID: <CAO-wXwLJ4i3GAsFJJ=sdS8v1HdiPqx6aM=BqO=qQyA_BsdLvsQ@mail.gmail.com>

Alex, so basically you are saying that SC is mentioned there just to tell
JVM implementors that "if you implement SC as a memory model, then your JVM
will meet the less strict requirements specified in JMM" ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170607/0b1d64a4/attachment.html>

From kensipe at gmail.com  Fri Jun 16 17:36:49 2017
From: kensipe at gmail.com (Ken Sipe)
Date: Fri, 16 Jun 2017 16:36:49 -0500
Subject: [concurrency-interest] Deadlock with when no threads have the lock
In-Reply-To: <5751B2ED.8090405@cs.oswego.edu>
References: <5751B2ED.8090405@cs.oswego.edu>
Message-ID: <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>

We have encountered a strange deadlock scenario in which it appears that all threads are waiting on acquiring a ReentrantLock, but no thread has the lock. 

Any thoughts on this?

https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a <https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a>


Thanks,
ken


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170616/d822a586/attachment.html>

From kirk at kodewerk.com  Fri Jun 16 18:55:31 2017
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sat, 17 Jun 2017 00:55:31 +0200
Subject: [concurrency-interest] Deadlock with when no threads have the
 lock
In-Reply-To: <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
Message-ID: <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>

Hi Ken,

If you have a lock with nothing holding on to it then either a VM thread has the lock. The most common culprit are GC threads. I’ve not taken a deep look at the code but you could set -XX:+PrintConcurrentLocks which would give you an idea if the problem is with the re-enterant lock. Not looked too deeply at the code but I don’t see anything obvious at the moment.

— Kirk

> On Jun 16, 2017, at 11:36 PM, Ken Sipe <kensipe at gmail.com> wrote:
> 
> We have encountered a strange deadlock scenario in which it appears that all threads are waiting on acquiring a ReentrantLock, but no thread has the lock. 
> 
> Any thoughts on this?
> 
> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a <https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a>
> 
> 
> Thanks,
> ken
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170617/5705db4f/attachment.html>

From henri.tremblay at gmail.com  Sat Jun 17 00:03:49 2017
From: henri.tremblay at gmail.com (Henri Tremblay)
Date: Sat, 17 Jun 2017 00:03:49 -0400
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>
Message-ID: <CADZL2=tOYuPHXr9kFUKG+2Y3-EUJL4HE0mYzNuQJnG+Pmsx-Pg@mail.gmail.com>

If you keep doing thread dumps, is the lock and the waiting threads the
same? So a real deadlock. If yes, Kirk suggestion is interesting. And I
would also do a heap dump to have a look at the threads holding a reference
to the reentrant lock.

On 16 June 2017 at 18:55, Kirk Pepperdine <kirk at kodewerk.com> wrote:

> Hi Ken,
>
> If you have a lock with nothing holding on to it then either a VM thread
> has the lock. The most common culprit are GC threads. I’ve not taken a deep
> look at the code but you could set -XX:+PrintConcurrentLocks which would
> give you an idea if the problem is with the re-enterant lock. Not looked
> too deeply at the code but I don’t see anything obvious at the moment.
>
> — Kirk
>
> On Jun 16, 2017, at 11:36 PM, Ken Sipe <kensipe at gmail.com> wrote:
>
> We have encountered a strange deadlock scenario in which it appears that
> all threads are waiting on acquiring a ReentrantLock, but no thread has the
> lock.
>
> Any thoughts on this?
>
> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>
>
> Thanks,
> ken
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170617/59b50438/attachment.html>

From kirk at kodewerk.com  Sat Jun 17 02:12:18 2017
From: kirk at kodewerk.com (Kirk Pepperdine)
Date: Sat, 17 Jun 2017 08:12:18 +0200
Subject: [concurrency-interest] Deadlock with when no threads have the
 lock
In-Reply-To: <CADZL2=tOYuPHXr9kFUKG+2Y3-EUJL4HE0mYzNuQJnG+Pmsx-Pg@mail.gmail.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>
 <CADZL2=tOYuPHXr9kFUKG+2Y3-EUJL4HE0mYzNuQJnG+Pmsx-Pg@mail.gmail.com>
Message-ID: <12189C79-2AB7-4B7D-9BCD-915382B389C3@kodewerk.com>

There are 94 threads that appear to be waiting on 2 different locks. 47 are waiting on a ForkJoinExecutor and are simply idle. From this one would hope that you were on a 48 core machine.

As an example….
"marathon-akka.actor.default-dispatcher-35" #271 prio=5 os_prio=0 tid=0x00007ff868004000 nid=0x11fd4 runnable [0x00007ff8a9be0000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000005c0581aa0> <monitor://<0x00000005c0581aa0>> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

26 are waiting on a ReentantLock. These are probably the threads of interest.

"ForkJoinPool-2-worker-33" #25346 daemon prio=5 os_prio=0 tid=0x00007ff80c11c000 nid=0x5747 waiting on condition [0x00007ff8a91d8000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000005c0af6298> <monitor://<0x00000005c0af6298>> (a java.util.concurrent.locks.ReentrantLock$FairSync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
	at java.util.concurrent.locks.ReentrantLock$FairSync.lock(ReentrantLock.java:224)
	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)
	at mesosphere.marathon.util.RichLock$.apply$extension(Lock.scala:7)
	at mesosphere.marathon.util.Lock.apply(Lock.scala:25)
	at mesosphere.marathon.util.KeyedLock.apply(WorkQueue.scala:94)

Are you waiting on an external signal?

— Kirk




> On Jun 17, 2017, at 6:03 AM, Henri Tremblay <henri.tremblay at gmail.com> wrote:
> 
> If you keep doing thread dumps, is the lock and the waiting threads the same? So a real deadlock. If yes, Kirk suggestion is interesting. And I would also do a heap dump to have a look at the threads holding a reference to the reentrant lock.
> 
> On 16 June 2017 at 18:55, Kirk Pepperdine <kirk at kodewerk.com <mailto:kirk at kodewerk.com>> wrote:
> Hi Ken,
> 
> If you have a lock with nothing holding on to it then either a VM thread has the lock. The most common culprit are GC threads. I’ve not taken a deep look at the code but you could set -XX:+PrintConcurrentLocks which would give you an idea if the problem is with the re-enterant lock. Not looked too deeply at the code but I don’t see anything obvious at the moment.
> 
> — Kirk
> 
>> On Jun 16, 2017, at 11:36 PM, Ken Sipe <kensipe at gmail.com <mailto:kensipe at gmail.com>> wrote:
>> 
>> We have encountered a strange deadlock scenario in which it appears that all threads are waiting on acquiring a ReentrantLock, but no thread has the lock. 
>> 
>> Any thoughts on this?
>> 
>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a <https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a>
>> 
>> 
>> Thanks,
>> ken
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170617/afb4bed1/attachment-0001.html>

From viktor.klang at gmail.com  Sat Jun 17 03:34:35 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Sat, 17 Jun 2017 09:34:35 +0200
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <12189C79-2AB7-4B7D-9BCD-915382B389C3@kodewerk.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>
 <CADZL2=tOYuPHXr9kFUKG+2Y3-EUJL4HE0mYzNuQJnG+Pmsx-Pg@mail.gmail.com>
 <12189C79-2AB7-4B7D-9BCD-915382B389C3@kodewerk.com>
Message-ID: <CANPzfU_dbO7UoL=VssAczF55OPJP3YZPYfd2o98JpozdwEfALA@mail.gmail.com>

There's the possibility that a task which unlocks the lock is stuck in the
executor's submission queue because all the workers are blocked on
obtaining the lock.

-- 
Cheers,
√

On Jun 17, 2017 8:13 AM, "Kirk Pepperdine" <kirk at kodewerk.com> wrote:

> There are 94 threads that appear to be waiting on 2 different locks. 47
> are waiting on a ForkJoinExecutor and are simply idle. From this one would
> hope that you were on a 48 core machine.
>
> As an example….
>
> "marathon-akka.actor.default-dispatcher-35" #271 prio=5 os_prio=0 tid=0x00007ff868004000 nid=0x11fd4 runnable [0x00007ff8a9be0000]
>    java.lang.Thread.State: WAITING (parking)
> 	at sun.misc.Unsafe.park(Native Method)
> 	- parking to wait for  <0x00000005c0581aa0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
> 	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075)
> 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
>
>
> 26 are waiting on a ReentantLock. These are probably the threads of
> interest.
>
> "ForkJoinPool-2-worker-33" #25346 daemon prio=5 os_prio=0 tid=0x00007ff80c11c000 nid=0x5747 waiting on condition [0x00007ff8a91d8000]
>    java.lang.Thread.State: WAITING (parking)
> 	at sun.misc.Unsafe.park(Native Method)
> 	- parking to wait for  <0x00000005c0af6298> (a java.util.concurrent.locks.ReentrantLock$FairSync)
> 	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
> 	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
> 	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
> 	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
> 	at java.util.concurrent.locks.ReentrantLock$FairSync.lock(ReentrantLock.java:224)
> 	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)
> 	at mesosphere.marathon.util.RichLock$.apply$extension(Lock.scala:7)
> 	at mesosphere.marathon.util.Lock.apply(Lock.scala:25)
> 	at mesosphere.marathon.util.KeyedLock.apply(WorkQueue.scala:94)
>
>
> Are you waiting on an external signal?
>
>
> — Kirk
>
>
>
>
>
> On Jun 17, 2017, at 6:03 AM, Henri Tremblay <henri.tremblay at gmail.com>
> wrote:
>
> If you keep doing thread dumps, is the lock and the waiting threads the
> same? So a real deadlock. If yes, Kirk suggestion is interesting. And I
> would also do a heap dump to have a look at the threads holding a reference
> to the reentrant lock.
>
> On 16 June 2017 at 18:55, Kirk Pepperdine <kirk at kodewerk.com> wrote:
>
>> Hi Ken,
>>
>> If you have a lock with nothing holding on to it then either a VM thread
>> has the lock. The most common culprit are GC threads. I’ve not taken a deep
>> look at the code but you could set -XX:+PrintConcurrentLocks which would
>> give you an idea if the problem is with the re-enterant lock. Not looked
>> too deeply at the code but I don’t see anything obvious at the moment.
>>
>> — Kirk
>>
>> On Jun 16, 2017, at 11:36 PM, Ken Sipe <kensipe at gmail.com> wrote:
>>
>> We have encountered a strange deadlock scenario in which it appears that
>> all threads are waiting on acquiring a ReentrantLock, but no thread has the
>> lock.
>>
>> Any thoughts on this?
>>
>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>>
>>
>> Thanks,
>> ken
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170617/cb2b1f27/attachment.html>

From stuart.monteith at linaro.org  Mon Jun 19 06:53:00 2017
From: stuart.monteith at linaro.org (Stuart Monteith)
Date: Mon, 19 Jun 2017 11:53:00 +0100
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <CANPzfU_dbO7UoL=VssAczF55OPJP3YZPYfd2o98JpozdwEfALA@mail.gmail.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <25C6D25B-E14F-4E12-A245-6CEA492601DE@kodewerk.com>
 <CADZL2=tOYuPHXr9kFUKG+2Y3-EUJL4HE0mYzNuQJnG+Pmsx-Pg@mail.gmail.com>
 <12189C79-2AB7-4B7D-9BCD-915382B389C3@kodewerk.com>
 <CANPzfU_dbO7UoL=VssAczF55OPJP3YZPYfd2o98JpozdwEfALA@mail.gmail.com>
Message-ID: <CAEGA6kZGdbArvaVZOJ+oSoKCcq8Nj-VONd5HAAyPUDs0F7X=cg@mail.gmail.com>

I've encountered a similar issue before with park/Unpark. There was
bug where class loading had a hand in causing Unparks to be missed:
    https://bugs.openjdk.java.net/browse/JDK-8074773

There can only be one outstanding unpark at a time, so subsequent
unparks can be lost.


BR,
   Stuart

On 17 June 2017 at 08:34, Viktor Klang <viktor.klang at gmail.com> wrote:
> There's the possibility that a task which unlocks the lock is stuck in the
> executor's submission queue because all the workers are blocked on obtaining
> the lock.
>
> --
> Cheers,
> √
>
> On Jun 17, 2017 8:13 AM, "Kirk Pepperdine" <kirk at kodewerk.com> wrote:
>>
>> There are 94 threads that appear to be waiting on 2 different locks. 47
>> are waiting on a ForkJoinExecutor and are simply idle. From this one would
>> hope that you were on a 48 core machine.
>>
>> As an example….
>>
>> "marathon-akka.actor.default-dispatcher-35" #271 prio=5 os_prio=0
>> tid=0x00007ff868004000 nid=0x11fd4 runnable [0x00007ff8a9be0000]
>>    java.lang.Thread.State: WAITING (parking)
>> 	at sun.misc.Unsafe.park(Native Method)
>> 	- parking to wait for  <0x00000005c0581aa0> (a
>> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
>> 	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075)
>> 	at
>> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
>> 	at
>> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
>>
>>
>> 26 are waiting on a ReentantLock. These are probably the threads of
>> interest.
>>
>> "ForkJoinPool-2-worker-33" #25346 daemon prio=5 os_prio=0
>> tid=0x00007ff80c11c000 nid=0x5747 waiting on condition [0x00007ff8a91d8000]
>>    java.lang.Thread.State: WAITING (parking)
>> 	at sun.misc.Unsafe.park(Native Method)
>> 	- parking to wait for  <0x00000005c0af6298> (a
>> java.util.concurrent.locks.ReentrantLock$FairSync)
>> 	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
>> 	at
>> java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
>> 	at
>> java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
>> 	at
>> java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
>> 	at
>> java.util.concurrent.locks.ReentrantLock$FairSync.lock(ReentrantLock.java:224)
>> 	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)
>> 	at mesosphere.marathon.util.RichLock$.apply$extension(Lock.scala:7)
>> 	at mesosphere.marathon.util.Lock.apply(Lock.scala:25)
>> 	at mesosphere.marathon.util.KeyedLock.apply(WorkQueue.scala:94)
>>
>>
>> Are you waiting on an external signal?
>>
>>
>> — Kirk
>>
>>
>>
>>
>>
>> On Jun 17, 2017, at 6:03 AM, Henri Tremblay <henri.tremblay at gmail.com>
>> wrote:
>>
>> If you keep doing thread dumps, is the lock and the waiting threads the
>> same? So a real deadlock. If yes, Kirk suggestion is interesting. And I
>> would also do a heap dump to have a look at the threads holding a reference
>> to the reentrant lock.
>>
>> On 16 June 2017 at 18:55, Kirk Pepperdine <kirk at kodewerk.com> wrote:
>>>
>>> Hi Ken,
>>>
>>> If you have a lock with nothing holding on to it then either a VM thread
>>> has the lock. The most common culprit are GC threads. I’ve not taken a deep
>>> look at the code but you could set -XX:+PrintConcurrentLocks which would
>>> give you an idea if the problem is with the re-enterant lock. Not looked too
>>> deeply at the code but I don’t see anything obvious at the moment.
>>>
>>> — Kirk
>>>
>>> On Jun 16, 2017, at 11:36 PM, Ken Sipe <kensipe at gmail.com> wrote:
>>>
>>> We have encountered a strange deadlock scenario in which it appears that
>>> all threads are waiting on acquiring a ReentrantLock, but no thread has the
>>> lock.
>>>
>>> Any thoughts on this?
>>>
>>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>>>
>>>
>>> Thanks,
>>> ken
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

From oleksandr.otenko at gmail.com  Tue Jun 20 07:23:04 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 20 Jun 2017 12:23:04 +0100
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
Message-ID: <9B73BA25-7947-4C74-8995-7F8B914F0D3A@gmail.com>

https://github.com/mesosphere/marathon/blob/v1.4.2/src/main/scala/mesosphere/marathon/util/Lock.scala#L29-L30 <https://github.com/mesosphere/marathon/blob/v1.4.2/src/main/scala/mesosphere/marathon/util/Lock.scala#L29-L30> - your equals method can deadlock.

(not saying that this is the cause...)

Alex


> On 16 Jun 2017, at 22:36, Ken Sipe <kensipe at gmail.com> wrote:
> 
> We have encountered a strange deadlock scenario in which it appears that all threads are waiting on acquiring a ReentrantLock, but no thread has the lock. 
> 
> Any thoughts on this?
> 
> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a <https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a>
> 
> 
> Thanks,
> ken
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170620/4e3a4b63/attachment.html>

From david.lloyd at redhat.com  Tue Jun 20 08:14:08 2017
From: david.lloyd at redhat.com (David M. Lloyd)
Date: Tue, 20 Jun 2017 07:14:08 -0500
Subject: [concurrency-interest] Deadlock with when no threads have the
 lock
In-Reply-To: <9B73BA25-7947-4C74-8995-7F8B914F0D3A@gmail.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <9B73BA25-7947-4C74-8995-7F8B914F0D3A@gmail.com>
Message-ID: <927b0266-3c29-fa41-e651-f103ef3c0eae@redhat.com>

You say *all* threads, but it's not true: all threads are not waiting on 
the lock.

Aside from that though, if threads are waiting, then a thread must own 
the lock, and furthermore it must be a thread that is not waiting on the 
lock (because they're reentrant and such an acquisition would have 
succeeded and would appear in the stack trace).  So, somehow the scala 
block may have failed in a way that prevented the finally block from 
running (stack overflow maybe, or maybe some Scala bug).

It should be possible to reflectively invoke the "getOwner()" method of 
the ReentrantLock to see what thread had acquired the lock.

On 06/20/2017 06:23 AM, Alex Otenko wrote:
> https://github.com/mesosphere/marathon/blob/v1.4.2/src/main/scala/mesosphere/marathon/util/Lock.scala#L29-L30 - 
> your equals method can deadlock.
> 
> (not saying that this is the cause...)
> 
> Alex
> 
> 
>> On 16 Jun 2017, at 22:36, Ken Sipe <kensipe at gmail.com 
>> <mailto:kensipe at gmail.com>> wrote:
>>
>> We have encountered a strange deadlock scenario in which it appears 
>> that all threads are waiting on acquiring a ReentrantLock, but no 
>> thread has the lock.
>>
>> Any thoughts on this?
>>
>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>>
>>
>> Thanks,
>> ken
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu 
>> <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


-- 
- DML

From viktor.klang at gmail.com  Tue Jun 20 08:33:29 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Tue, 20 Jun 2017 14:33:29 +0200
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <927b0266-3c29-fa41-e651-f103ef3c0eae@redhat.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <9B73BA25-7947-4C74-8995-7F8B914F0D3A@gmail.com>
 <927b0266-3c29-fa41-e651-f103ef3c0eae@redhat.com>
Message-ID: <CANPzfU_A+WxQqn3fveSifOHD8uYW50Z25pONwekETynJO-i-3Q@mail.gmail.com>

As an aside, to avoid deadlocks for that `equals`-implementation, you need
to make sure that all comparisons take the locks in the same order, so
like, the one with the lowest identityHashCode or something like that.

(as well as special casing the situation where `o` == this)

On Tue, Jun 20, 2017 at 2:14 PM, David M. Lloyd <david.lloyd at redhat.com>
wrote:

> You say *all* threads, but it's not true: all threads are not waiting on
> the lock.
>
> Aside from that though, if threads are waiting, then a thread must own the
> lock, and furthermore it must be a thread that is not waiting on the lock
> (because they're reentrant and such an acquisition would have succeeded and
> would appear in the stack trace).  So, somehow the scala block may have
> failed in a way that prevented the finally block from running (stack
> overflow maybe, or maybe some Scala bug).
>
> It should be possible to reflectively invoke the "getOwner()" method of
> the ReentrantLock to see what thread had acquired the lock.
>
> On 06/20/2017 06:23 AM, Alex Otenko wrote:
>
>> https://github.com/mesosphere/marathon/blob/v1.4.2/src/main/
>> scala/mesosphere/marathon/util/Lock.scala#L29-L30 - your equals method
>> can deadlock.
>>
>> (not saying that this is the cause...)
>>
>> Alex
>>
>>
>> On 16 Jun 2017, at 22:36, Ken Sipe <kensipe at gmail.com <mailto:
>>> kensipe at gmail.com>> wrote:
>>>
>>> We have encountered a strange deadlock scenario in which it appears that
>>> all threads are waiting on acquiring a ReentrantLock, but no thread has the
>>> lock.
>>>
>>> Any thoughts on this?
>>>
>>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>>>
>>>
>>> Thanks,
>>> ken
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at c
>>> s.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> --
> - DML
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170620/4ec2b5a4/attachment.html>

From stephan.diestelhorst at gmail.com  Tue Jun 20 08:34:41 2017
From: stephan.diestelhorst at gmail.com (Stephan Diestelhorst)
Date: Tue, 20 Jun 2017 13:34:41 +0100
Subject: [concurrency-interest] Deadlock with when no threads have the
	lock
In-Reply-To: <927b0266-3c29-fa41-e651-f103ef3c0eae@redhat.com>
References: <5751B2ED.8090405@cs.oswego.edu>
 <03C640D2-091A-4B89-AB3C-6B7E42C4EBB8@gmail.com>
 <9B73BA25-7947-4C74-8995-7F8B914F0D3A@gmail.com>
 <927b0266-3c29-fa41-e651-f103ef3c0eae@redhat.com>
Message-ID: <CAJR39Eymn4k4CRCJvqk_rEtHqH8oaF=gpPNezfYRp_zztjHUjw@mail.gmail.com>

(Transferring some knowledge from other domains)

I've seen a case where no one had the lock, yet the application was
deadlocking.  The thing that caused it then was a lost wakeup from the last
guy freeing the lock needing to prod the threads that wanted to enter the
lock, but stopped spinning on it (and went to sleep, got stashed away, get
marked as blocked).

Is there any chance the same thing could be happening here?

Stephan

On 20 June 2017 at 13:14, David M. Lloyd <david.lloyd at redhat.com> wrote:

> You say *all* threads, but it's not true: all threads are not waiting on
> the lock.
>
> Aside from that though, if threads are waiting, then a thread must own the
> lock, and furthermore it must be a thread that is not waiting on the lock
> (because they're reentrant and such an acquisition would have succeeded and
> would appear in the stack trace).  So, somehow the scala block may have
> failed in a way that prevented the finally block from running (stack
> overflow maybe, or maybe some Scala bug).
>
> It should be possible to reflectively invoke the "getOwner()" method of
> the ReentrantLock to see what thread had acquired the lock.
>
> On 06/20/2017 06:23 AM, Alex Otenko wrote:
>
>> https://github.com/mesosphere/marathon/blob/v1.4.2/src/main/
>> scala/mesosphere/marathon/util/Lock.scala#L29-L30 - your equals method
>> can deadlock.
>>
>> (not saying that this is the cause...)
>>
>> Alex
>>
>>
>> On 16 Jun 2017, at 22:36, Ken Sipe <kensipe at gmail.com <mailto:
>>> kensipe at gmail.com>> wrote:
>>>
>>> We have encountered a strange deadlock scenario in which it appears that
>>> all threads are waiting on acquiring a ReentrantLock, but no thread has the
>>> lock.
>>>
>>> Any thoughts on this?
>>>
>>> https://gist.github.com/timcharper/9ab4fea9da4669e620507e85e764d94a
>>>
>>>
>>> Thanks,
>>> ken
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at c
>>> s.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
> --
> - DML
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170620/a13e0fd2/attachment-0001.html>

From Maciej.Bobrowski at morganstanley.com  Thu Jun 29 09:43:23 2017
From: Maciej.Bobrowski at morganstanley.com (Bobrowski, Maciej)
Date: Thu, 29 Jun 2017 13:43:23 +0000
Subject: [concurrency-interest] non-volatile vs volatile reads
Message-ID: <9838003A10254741BC6FFADE2ED02B4586408BD8@OZWEX0205N1.msad.ms.com>

Let's consider the class:

Foo{

   int x = 0;
   volatile int y = 0;

  void write(int newVal) {
     x = newVal;
     y = newVal;
  }
}

Let's assume one writer calls write(1) , potentially multiple times.

I understand that result of calling just foo.x is not defined under JMM (it could be 0, it could be 1). However:

foo.y // this returns 1
foo.x

According to the full-fence characteristics of volatile read, foo.x is guaranteed to be 1. How is this achieved? Let's assume x is on a different cache-line or is stored in local registers?


________________________________

NOTICE: Morgan Stanley is not acting as a municipal advisor and the opinions or views contained herein are not intended to be, and do not constitute, advice within the meaning of Section 975 of the Dodd-Frank Wall Street Reform and Consumer Protection Act. If you have received this communication in error, please destroy all electronic and paper copies and notify the sender immediately. Mistransmission is not intended to waive confidentiality or privilege. Morgan Stanley reserves the right, to the extent permitted under applicable law, to monitor electronic communications. This message is subject to terms available at the following link: http://www.morganstanley.com/disclaimers  If you cannot access these links, please notify us by reply message and we will send the contents to you. By communicating with Morgan Stanley you consent to the foregoing and to the voice recording of conversations with personnel of Morgan Stanley.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170629/766f5fad/attachment.html>

