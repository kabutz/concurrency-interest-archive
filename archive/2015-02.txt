From gergg at cox.net  Sun Feb  1 21:10:21 2015
From: gergg at cox.net (Gregg Wonderly)
Date: Sun, 1 Feb 2015 20:10:21 -0600
Subject: [concurrency-interest] unpark/park memory visibility
In-Reply-To: <m8mE1p00V02hR0p018mGQ4>
References: <1420743543652-11812.post@n7.nabble.com>
	<CAHjP37GP=E8Z5rkvk8HiB9JM9MVhkS7cnuNDmc93exOGaCX0hA@mail.gmail.com>
	<54B7D57A.6000703@oracle.com>
	<CAHjP37F2Z0t9o-=5TfcT6AGBd2YLb-K0AEbFtbwUTvDQM22RRg@mail.gmail.com>
	<54B7EC2A.1040409@oracle.com>
	<CAHjP37HWzWnGpVvN0GV4nkwt4K_6QLutWRGyTtM6-WNn1LuR7g@mail.gmail.com>
	<54B7FC50.7020108@oracle.com> <54B80729.7030609@cs.oswego.edu>
	<0FD072A166C6DC4C851F6115F37DDD2783D83956@sm-ex-01-vm.guidewire.com>
	<54B8399F.6000106@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83A4C@sm-ex-01-vm.guidewire.com>
	<54B84055.2000701@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83B20@sm-ex-01-vm.guidewire.com>
	<54B928DF.80106@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83EA6@sm-ex-01-vm.guidewire.com>
	<gmPL1p01B02hR! 0p01mPNPG>
	<F350C472-C399-444A-84E1-C3D1308B39F6@cox.net>
	<hqKe1p00m02hR0p01qKjmt>
	<129D2A38-A415-4A10-AD3D-6D77FF055651@cox.ne! ! t>
	<iaaH1p00P02hR0p01aaJlj>
	<B8AD1A1F-A978-45D4-82A8-7BD602926370@cox.net>
	<m8mE1p00V02hR0p018mGQ4>
Message-ID: <F3DCDD17-A62A-4091-A81B-A486E27F3697@cox.net>


> On Jan 30, 2015, at 2:44 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 30/01/15 06:33, Gregg Wonderly wrote:
>> 
>>> Sure, those of us who have been around the block a few times
>>> sometimes wish that the world were as simple as we think it used to
>>> be.  But people who do not know where to make variables volatile
>>> are unlikely to write correct multi-threaded code which accesses
>>> shared state in memory, even without needing volatile annotations.
>>> Sure, they might test it on x86 and declare it to be correct, but
>>> that's not the same thing at all.
>> 
>> This is the statement that demonstrates the issue for me.  Why are
>> we using a language full of sequential flow control constructs and
>> statements, and trying to artificially fit concurrency into it, in a
>> way that continuous to be full of failure modes that create
>> problematic software systems?
> 
> There's nothing artificial about concurrency in Java.  It is one of the
> first mainstream languages to make a real stab at supporting
> concurrency.
> 
> You're making a fundamental category error: the structures we're
> discussing are precisely those that any language designer must use in
> order to create secure abstractions for application programmers to
> use.  Shared variables are very difficult to manage in large-scale
> software, so we are providing the essential tools people need.  To do
> that we need to deal with the low-level reality of synchronization.

Yes the structures are often the helpful part.  But, there is a completely orthogonal issue
to using the structures.  That issue is that program flow is expressed with a sequential
programming language.  Language logic constructs can be altered by the JIT into 
structures which do not result in the same logic being visible in the execution of the 
program.  This is what wastes developers time.  They are having to create ?data flow?
based execution graphs by manipulation of ?declaration? instead of by true data flow,
when sharing data.  

Yes, JUC helps with this in a big way. For example, FJ provides a way to present 
non-sequential program execution to the developer in a way where optimizations of task
order are expected.  Having the JIT do even more of this is where the problems
present themselves by confusing developers with results which the software structure
(not declarations) does not represent as happening.

> 
>> Concurrency is hard when expressed in terms of sequential software
>> constructs that promote ?observation? instead of demanding
>> rendezvous for sharing.  The lambda work and some other things, like
>> the callback/messaging designs that Doug is working on, are the ways
>> to promote software systems that work in concurrent environments.
>> 
>> We need concurrency constructs that promote sound software systems.
> 
> Of course.  That's what we're creating.  Where have you been?

Artificial reordering of instructions which then creates broken programs does not
create sound software systems.  That creates more wasted time than it does
working software.

We didn?t choose to scale on multiple ALUs.  Cores won.  VLIW did not get
much traction.  Yes, those concepts exist in things like hyper threading and
complex instructions for data movement and math.  But practically developers
could best use sequential execution better that they could use data flow multipliers.
JUC is a big help in expression of concurrency in ?work? rather than ?flow?.

But, we still have cores?   JUC is not the problem.  Non-volatile optimizations
are the problem because they are surprises to developers.  Again, everything
should be shared based on visibility.  Functional interfaces are what developers
need to worry about, along with flow control statements.  Not all this nonsense
that volatile is causing to permeate software systems.

def: volatile: liable to change rapidly and unpredictably, especially for the worse.

To me, volatile has never been about ?sharing? data.

> 
>> All of the focus and interest in micro optimizing the software
>> around the ?behavior? of the hardware, which is orthogonal to the
>> language?s sequential software constructs seems problematic to me,
>> and appears to becoming very hard to get ?right? for developers and
>> implementations both.
> 
> Yes.  It's hard.  But people need better and higher-level constructs,
> so we need to write them.  And we cannot do that without getting the
> low-level details exactly right.

Believe me, I understand this.  Data sharing should be more like messaging
and less like a room full of old ladies writing notes on cards and passing
them around.  We are content with helping the ladies be faster (fences are
like ropes on polls guiding them where to go next).

Right now, yes, this is what we need to do, because we have to deal with the
situation that exists.  But, I worry about how we are trying to make this
about ?the ropes?.

Instead, the JMM needs to be fixed so that we are just concerned that the
cards exist and that there is a consistent way to share.  Where the ropes
are, what color they are and how many times you have to turn is where
volatile?s current definition leaves us, because there are just too many
ways that volatile can be exploited to make the program execution 
unpredictable.

Gregg

> 
> Andrew.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150201/708075f9/attachment.html>

From oleksandr.otenko at oracle.com  Mon Feb  2 08:29:56 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 02 Feb 2015 13:29:56 +0000
Subject: [concurrency-interest] AtomicReference CAS signatures
In-Reply-To: <1422725597589-12338.post@n7.nabble.com>
References: <1420840643988-11820.post@n7.nabble.com>	<54B07067.30103@cs.oswego.edu>	<0FD072A166C6DC4C851F6115F37DDD2783D818DA@sm-ex-01-vm.guidewire.com>	<1420904890038-11835.post@n7.nabble.com>	<54C8DE46.1050900@oracle.com>
	<1422725597589-12338.post@n7.nabble.com>
Message-ID: <54CF7BD4.4020200@oracle.com>

I do understand they are not identical. But you are looking at it the 
wrong way around.

Show me a proof of something using CMPXCHG that is stronger than vread 
followed by compare-and-set.

CMPXCHG is a vread followed by compare-and-set. The only difference is 
that it is atomic; it doesn't allow any other synchronization action to 
appear between the vread and the compare-and-set. Well, we aren't 
bothered about any synchronization action, only the vwrites to the same 
variable; so CMPXCHG guarantees that both the vread and compare-and-set 
synchronize-with the same vwrite. But since this is a possible outcome 
for the weaker notion of non-atomic sequence of vread followed by 
compare-and-set, you must show what can be proven from this restriction 
that compare-and-set /*cannot*/ synchronize-with any other vwrite.

I can't see what useful thing you can prove there. I have a hunch you 
will want a property that should hold true for a longer span - from the 
vread all the way to the first vwrite /in the same thread/, which, of 
course, is a successful compare-and-set, but /has to be some *other* 
vwrite/ on the failure branch. CMPXCHG alone does not give you such 
guarantees. There are obvious guarantees that hold for all values from 
vread - like, "compare-and-set failed implies someone, and only one, 
else succeeded", which can be used to build exclusive access (because 
one /and only/ one) to /the/ value read by vread /on the successful/ 
branch (obviously, the success is /the witness/ that no vwrites occurred 
between vread and compare-and-set) - but you know that value even 
without returning it. Ok? Now try to express what you get on the failure 
branch from knowing there were no vwrites between the vread and 
compare-and-set - meaning, even failure being a witness there were no 
vwrites between vread and compare-and-set.


Alex

On 31/01/2015 17:33, thurstonn wrote:
> Sigh.
> You must not be understanding my point; usually I find (pseudo) code to be
> the most effective way,but I'll try to put it in English.
>
> a native compare-and-swap:  (T, T) -> T
>
> is the **only** way to answer this question:
>
> "What was the value of the memory location that caused the conditional-set
> to *fail*"?
>
> I repeat, the only way.
>
>
> The following two lines of code are **not semantically equivalent**
>
> assert compare-and-set(..., ...) : "oops - should have succeeded but failed
> due to " + get()
>
> assert (T result = compare-and-swap(..., ...)) == (T) expected : "oops -
> should have succeeded but failed due to " + result
>
> That should be obvious, and no presumption of a CAS-spin or some other loop
> is relevant.
>
>
> A compare-and-swap **failure** is semantically equivalent to a
> **standalone** get().  In fact, a semantically equivalent implementation of
> #get would be:
>
> T get()
> {
>       return compare-and-swap(new Object(), new Object()) //guaranteed to
> 'fail'
>
> }
>   
>
> The designers of CMPXCHG understand this (as well as C++11, and openjdk's
> Atomic::cmpxchg(),et al), after all, it could just update some boolean flag
> in a register (indeed it does this), but in addition it places the value of
> the memory location in a register - it is wasteful to have to issue a
> subsequent load of the same memory location, when in some circumstances, a
> user knows (from context) that the same value will be returned (think state
> machine).
>
> You need to free yourself from the assumption that CAS is only useful as
> part of a user-defined CAS spin. Yes, in most cases that is true, but not in
> all
>
>
>
>
>
>
>
> --
> View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/AtomicReference-CAS-signatures-tp11820p12338.html
> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150202/2cff5dd2/attachment.html>

From oleksandr.otenko at oracle.com  Mon Feb  2 09:05:38 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 02 Feb 2015 14:05:38 +0000
Subject: [concurrency-interest] AtomicReference CAS signatures
In-Reply-To: <54CF7BD4.4020200@oracle.com>
References: <1420840643988-11820.post@n7.nabble.com>	<54B07067.30103@cs.oswego.edu>	<0FD072A166C6DC4C851F6115F37DDD2783D818DA@sm-ex-01-vm.guidewire.com>	<1420904890038-11835.post@n7.nabble.com>	<54C8DE46.1050900@oracle.com>
	<1422725597589-12338.post@n7.nabble.com>
	<54CF7BD4.4020200@oracle.com>
Message-ID: <54CF8432.6020607@oracle.com>

On 02/02/2015 13:29, Oleksandr Otenko wrote:
> I do understand they are not identical. But you are looking at it the 
> wrong way around.
>
> Show me a proof of something using CMPXCHG that is stronger than vread 
> followed by compare-and-set.
>
> CMPXCHG is a vread followed by compare-and-set. The only difference is 
> that it is atomic; it doesn't allow any other synchronization action 
> to appear between the vread and the compare-and-set. Well, we aren't 
> bothered about any synchronization action, only the vwrites to the 
> same variable; so CMPXCHG guarantees that both the vread and 
> compare-and-set synchronize-with the same vwrite. But since this is a 
> possible outcome for the weaker notion of non-atomic sequence of vread 
> followed by compare-and-set, you must show what can be proven from 
> this restriction that compare-and-set /*cannot*/ synchronize-with any 
> other vwrite.
>
> I can't see what useful thing you can prove there. I have a hunch you 
> will want a property that should hold true for a longer span - from 
> the vread all the way to the first vwrite /in the same thread/, which, 
> of course, is a successful compare-and-set, but /has to be some 
> *other* vwrite/ on the failure branch. CMPXCHG alone does not give you 
> such guarantees. There are obvious guarantees that hold for all values 
> from vread - like, "compare-and-set failed implies someone, and only 
> one, else succeeded", which can be used to build exclusive access 
> (because one /and only/ one) to /the/ value read by vread /on the 
> successful/ branch (obviously, the success is /the witness/ that no 
> vwrites occurred between vread and compare-and-set) - but you know 
> that value even without returning it. Ok? Now try to express what you 
> get on the failure branch from knowing there were no vwrites between 
> the vread and compare-and-set - meaning, even failure being a witness 
> there were no vwrites between vread and compare-and-set.

But that of course defeats the purpose of having the "compare" in 
compare-and-set. The compare-and-set fails /because/ there was a vwrite 
between some vread before compare-and-set (the one we deduce the 
expected value from), and the compare-and-set. So wanting to exclude a 
vwrite between the last vread and compare-and-set does not give you much 
- you only push all vwrites between two vreads, which should always be 
allowed, if that vwrite otherwise be allowed to appear between the vread 
and compare-and-set.

(I am thinking of the following:

vread expected              vread expected
CMPXCHG                     vread what CMPXCHG would return
                             compare-and-set

So really we have more than one vread, and you want to forbid the vwrite 
between the last two operations)

The "compare" in compare-and-set already means that you /assume/ some 
vwrite may occur between the vread (or perhaps some other 
synchronization action) from which the expected value is deduced, and 
the compare-and-set.


Alex


>
>
> Alex
>
> On 31/01/2015 17:33, thurstonn wrote:
>> Sigh.
>> You must not be understanding my point; usually I find (pseudo) code to be
>> the most effective way,but I'll try to put it in English.
>>
>> a native compare-and-swap:  (T, T) -> T
>>
>> is the **only** way to answer this question:
>>
>> "What was the value of the memory location that caused the conditional-set
>> to *fail*"?
>>
>> I repeat, the only way.
>>
>>
>> The following two lines of code are **not semantically equivalent**
>>
>> assert compare-and-set(..., ...) : "oops - should have succeeded but failed
>> due to " + get()
>>
>> assert (T result = compare-and-swap(..., ...)) == (T) expected : "oops -
>> should have succeeded but failed due to " + result
>>
>> That should be obvious, and no presumption of a CAS-spin or some other loop
>> is relevant.
>>
>>
>> A compare-and-swap **failure** is semantically equivalent to a
>> **standalone** get().  In fact, a semantically equivalent implementation of
>> #get would be:
>>
>> T get()
>> {
>>       return compare-and-swap(new Object(), new Object()) //guaranteed to
>> 'fail'
>>
>> }
>>   
>>
>> The designers of CMPXCHG understand this (as well as C++11, and openjdk's
>> Atomic::cmpxchg(),et al), after all, it could just update some boolean flag
>> in a register (indeed it does this), but in addition it places the value of
>> the memory location in a register - it is wasteful to have to issue a
>> subsequent load of the same memory location, when in some circumstances, a
>> user knows (from context) that the same value will be returned (think state
>> machine).
>>
>> You need to free yourself from the assumption that CAS is only useful as
>> part of a user-defined CAS spin. Yes, in most cases that is true, but not in
>> all
>>
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context:http://jsr166-concurrency.10961.n7.nabble.com/AtomicReference-CAS-signatures-tp11820p12338.html
>> Sent from the JSR166 Concurrency mailing list archive at Nabble.com.
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150202/0f30eeb9/attachment-0001.html>

From jsampson at guidewire.com  Mon Feb  2 12:57:49 2015
From: jsampson at guidewire.com (Justin Sampson)
Date: Mon, 2 Feb 2015 17:57:49 +0000
Subject: [concurrency-interest] unpark/park memory visibility
In-Reply-To: <F3DCDD17-A62A-4091-A81B-A486E27F3697@cox.net>
References: <1420743543652-11812.post@n7.nabble.com>
	<CAHjP37GP=E8Z5rkvk8HiB9JM9MVhkS7cnuNDmc93exOGaCX0hA@mail.gmail.com>
	<54B7D57A.6000703@oracle.com>
	<CAHjP37F2Z0t9o-=5TfcT6AGBd2YLb-K0AEbFtbwUTvDQM22RRg@mail.gmail.com>
	<54B7EC2A.1040409@oracle.com>
	<CAHjP37HWzWnGpVvN0GV4nkwt4K_6QLutWRGyTtM6-WNn1LuR7g@mail.gmail.com>
	<54B7FC50.7020108@oracle.com> <54B80729.7030609@cs.oswego.edu>
	<0FD072A166C6DC4C851F6115F37DDD2783D83956@sm-ex-01-vm.guidewire.com>
	<54B8399F.6000106@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83A4C@sm-ex-01-vm.guidewire.com>
	<54B84055.2000701@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83B20@sm-ex-01-vm.guidewire.com>
	<54B928DF.80106@oracle.com>
	<0FD072A166C6DC4C851F6115F37DDD2783D83EA6@sm-ex-01-vm.guidewire.com>
	<gmPL1p01B02hR!
	0p01mPNPG>	<F350C472-C399-444A-84E1-C3D1308B39F6@cox.net>
	<hqKe1p00m02hR0p01qKjmt>	<129D2A38-A415-4A10-AD3D-6D77FF055651@cox.ne!
	! t>
	<iaaH1p00P02hR0p01aaJlj>	<B8AD1A1F-A978-45D4-82A8-7BD602926370@cox.net>
	<m8mE1p00V02hR0p018mGQ4> <F3DCDD17-A62A-4091-A81B-A486E27F3697@cox.net>
Message-ID: <0FD072A166C6DC4C851F6115F37DDD2783D96B3D@sm-ex-01-vm.guidewire.com>

Gregg Wonderly wrote:

> Yes the structures are often the helpful part. But, there is a
> completely orthogonal issue to using the structures. That issue is
> that program flow is expressed with a sequential programming
> language. Language logic constructs can be altered by the JIT into
> structures which do not result in the same logic being visible in
> the execution of the program. This is what wastes developers time.
> They are having to create "data flow" based execution graphs by
> manipulation of "declaration" instead of by true data flow, when
> sharing data.

The Java memory model goes to quite laudable lengths to ensure the
appearance of sequential consistency as long as a program is free of
data races, so the typical developer shouldn't have to think about
reordering at all, as long as they never share data between threads
without some kind of synchronization.

So the interesting question to me is, how do we get that message
across to the typical developer, if it's not getting across already?

> def: volatile: liable to change rapidly and unpredictably,
> especially for the worse.
>
> To me, volatile has never been about "sharing" data.

I'm pretty sure that's _all_ that 'volatile' is about in Java. The
compiler can even eliminate the volatile memory barriers if it can
prove that some data isn't shared between threads!

> [...] there are just too many ways that volatile can be exploited
> to make the program execution unpredictable.

Are you saying that you think there are ways that adding 'volatile'
to a program makes the execution of the program _less_ predictable?
I think of 'volatile' precisely as providing sequential guarantees
that aren't there otherwise, which should always make a program more
predictable, not less.

Puzzled,
Justin


From thurston at nomagicsoftware.com  Mon Feb  2 16:40:02 2015
From: thurston at nomagicsoftware.com (thurstonn)
Date: Mon, 2 Feb 2015 14:40:02 -0700 (MST)
Subject: [concurrency-interest] Q. Stealing in fully strict applications
In-Reply-To: <54CB7B72.6030700@cs.oswego.edu>
References: <CAB4+JYJS1EO6aPfOa6Oku5U6etsjOSVO1cKaUHsk3iSseV7vgQ@mail.gmail.com>
	<54C7F882.7000500@cs.oswego.edu>
	<CAB4+JYJ-WGmrYXVx--a1_oSB=3MuRvigf-ijxbEajdOV-O5DcQ@mail.gmail.com>
	<CA+kOe09rkamQN2Uehk=Kbw815RQHRhqZHM8ODYR=VZfgJGFk+w@mail.gmail.com>
	<CAB4+JYK1mdoNi5L-k+UaDyfMXDhN2SoALpZcn0a=xaQApGSm9w@mail.gmail.com>
	<54C8E805.1010402@cs.oswego.edu>
	<1422536614543-12302.post@n7.nabble.com>
	<54CB7B72.6030700@cs.oswego.edu>
Message-ID: <1422913202868-12344.post@n7.nabble.com>

Doug Lea wrote
> On 01/29/2015 08:03 AM, thurstonn wrote:
> 
>> But my understanding of your response to an earlier question I  posed
>> &lt;http://jsr166-concurrency.10961.n7.nabble.com/FJ-stack-bounds-td11552.html&gt;
>> regarding the max stack height of a FJWT was:
>> msh + (msh - 1) + . . . + 1, where msh := max sequential stack height,
>> which
>> is more aggressive (less conservative) than leapfrogging, where msh's are
>> ==
>> (P2 in the leapfrogging paper)
> 
> When FJ uses leap-frogging, it has the same msh bound. It
> also handles a few additional cases that amount to
> stealing a sibling in a local deque, at the cost of
> more stack frames but fewer threads. Almost none of these
> cases are good programming practice, but are not illegal.
> For example, the infamously bad out-of-order-join case:
>    a.fork(); b.fork(); a.join(); b.join();
> 
> -Doug

So is the following accurate:

If all fj worker threads join tasks in the **opposite** order in which it
forks them, the worst-case maximum stack height == maximum stack height of a
sequential execution?




--
View this message in context: http://jsr166-concurrency.10961.n7.nabble.com/Q-Stealing-in-fully-strict-applications-tp12250p12344.html
Sent from the JSR166 Concurrency mailing list archive at Nabble.com.

From valentin.male.kovalenko at gmail.com  Tue Feb  3 18:45:19 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 03:45:19 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
Message-ID: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>

Hi
I'm looking for a fixed rate executor service, and would be glad if someone
could give me a hint.

I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this
method doesn't guarantees that actual rate will be not less that the
desired one: "If any execution of this task takes longer than its period,
then subsequent executions may start late".

What I want is something like
scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
FailedRatePolicy frp),
where rate==10_000L and unit==SECONDS means 10_000 actions/second,
and FailedRatePolicy determines what to do if during some second executor
failed to satisfy the specified rate (i.e. if at that second it had
completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
log a warning; throw an exception. Note also that at the next second after
the second where rate wasn't satisfied executor doesn't try to execute
10_000 actions plus those actions that weren't executed, it tries to
execute exactly 10_000 actions during the new second.

Does anyone know an executor which have such a functionality?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/fdc3f4cc/attachment.html>

From davidcholmes at aapt.net.au  Tue Feb  3 19:08:15 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 4 Feb 2015 10:08:15 +1000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEEAKNAA.davidcholmes@aapt.net.au>

Hi Valentin,

Normal schedule-at-fixed-rate sets up a periodic release time: S + nT where S is the start time, T is the period and n = 0,1,2 .... So the task is scheduled for release at times S, S+T, S+2T etc. The main issue here is that if one release is not complete before the next is due to start then what do you do? Given we don't have guaranteed cancellation mechanisms, and that generally you do not want two releases of the task to execute concurrently, we just go into an overrun condition with ScheduledThreadPoolExecutor and delay the next release.

>From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right? Or did you intend to distribute the execution of the tasks evenly throughout the time period?

David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Valentin Kovalenko
  Sent: Wednesday, 4 February 2015 9:45 AM
  To: concurrency-interest at cs.oswego.edu
  Subject: [concurrency-interest] Fixed Rate Executor Service


  Hi
  I'm looking for a fixed rate executor service, and would be glad if someone could give me a hint.


  I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this method doesn't guarantees that actual rate will be not less that the desired one: "If any execution of this task takes longer than its period, then subsequent executions may start late".


  What I want is something like
  scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit, FailedRatePolicy frp),

  where rate==10_000L and unit==SECONDS means 10_000 actions/second,
  and FailedRatePolicy determines what to do if during some second executor failed to satisfy the specified rate (i.e. if at that second it had completed 6_000 actions). Examples of FailedRatePolicy: silently ignore; log a warning; throw an exception. Note also that at the next second after the second where rate wasn't satisfied executor doesn't try to execute 10_000 actions plus those actions that weren't executed, it tries to execute exactly 10_000 actions during the new second.


  Does anyone know an executor which have such a functionality?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/c74e42c4/attachment.html>

From valentin.male.kovalenko at gmail.com  Tue Feb  3 19:51:22 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 04:51:22 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
Message-ID: <CAO-wXwKuoo=9GCusjsqtKY8+0QeegS++C2ffdjo+91HWqmhfkQ@mail.gmail.com>

>>the task is scheduled for release at times S, S+T, S+2T etc.
This approach is only suitable for single-thread executor, which fires
actions in a sequence. If executor have more that one thread it can fire
actions in parallel, but must try to execute exactly RATE actions per time
unit (period).

>>From your description it sounds like concurrent executions would be okay,
so at the start of each period we would just release all RATE instances of
the task - is that right?
Yes, but we can only do it if we have RATE (or more) threads in executor.
Otherwise not all (not RATE) actions will be fired at the start of each
period (obviously).

>>Or did you intend to distribute the execution of the tasks evenly
throughout the time period?
That's another story of which I'm thinking, but for start I prefer to not
focus on the "inside period distribution strategy".

>>Given we don't have guaranteed cancellation mechanisms
Yep, we don't.
So if we have requested rate 1 action per second, duration of the action
varies [1s; 2.5s], and 2 threads in executor then:
0) at period [0s; 1s) execution rate 0 (failed rate)
1) at period [1s; 2s) execution rate 0 (failed rate)
2) at period [2s; 3s) execution rate 2, because action started at 0) have
completed in say 2.2s and action started at 1) have completed in 1.5s
So at the period [2s; 3s) we have rate 2 instead of 1, is this what you've
called overrun? If so then it seems like such cases should also be handled
by FailedRatePolicy, so a user can be notified that he should specify rate
with a more coarse grained time unit (e.g. 60 actions/minute instead of 1
action/second).

On Wed, Feb 4, 2015 at 3:08 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

>  Hi Valentin,
>
> Normal schedule-at-fixed-rate sets up a periodic release time: S + nT
> where S is the start time, T is the period and n = 0,1,2 .... So the task
> is scheduled for release at times S, S+T, S+2T etc. The main issue here is
> that if one release is not complete before the next is due to start then
> what do you do? Given we don't have guaranteed cancellation mechanisms, and
> that generally you do not want two releases of the task to execute
> concurrently, we just go into an overrun condition with
> ScheduledThreadPoolExecutor and delay the next release.
>
> From your description it sounds like concurrent executions would be okay,
> so at the start of each period we would just release all RATE instances of
> the task - is that right? Or did you intend to distribute the execution of
> the tasks evenly throughout the time period?
>
> David
>
> -----Original Message-----
> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Valentin
> Kovalenko
> *Sent:* Wednesday, 4 February 2015 9:45 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Fixed Rate Executor Service
>
> Hi
> I'm looking for a fixed rate executor service, and would be glad if
> someone could give me a hint.
>
> I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this
> method doesn't guarantees that actual rate will be not less that the
> desired one: "If any execution of this task takes longer than its period,
> then subsequent executions may start late".
>
> What I want is something like
> scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
> FailedRatePolicy frp),
> where rate==10_000L and unit==SECONDS means 10_000 actions/second,
> and FailedRatePolicy determines what to do if during some second executor
> failed to satisfy the specified rate (i.e. if at that second it had
> completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
> log a warning; throw an exception. Note also that at the next second after
> the second where rate wasn't satisfied executor doesn't try to execute
> 10_000 actions plus those actions that weren't executed, it tries to
> execute exactly 10_000 actions during the new second.
>
> Does anyone know an executor which have such a functionality?
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/2cb54bf9/attachment.html>

From davidcholmes at aapt.net.au  Tue Feb  3 20:05:53 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 4 Feb 2015 11:05:53 +1000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXwKuoo=9GCusjsqtKY8+0QeegS++C2ffdjo+91HWqmhfkQ@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCOEEBKNAA.davidcholmes@aapt.net.au>

If your tasks can run in parallel (which implies they are independent and non-interfering) then you don't need RATE threads in the executor, you just need sufficient threads to execute RATE tasks within the time unit. If a task takes UNIT time to execute then you need RATE threads. If a task takes UNIT/10 time to execute then you only need RATE/10 threads (plus allow for task management overhead).

But simple answer: I know of no existing Executor that will do what you want.

David
  -----Original Message-----
  From: Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
  Sent: Wednesday, 4 February 2015 10:51 AM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Fixed Rate Executor Service


  >>the task is scheduled for release at times S, S+T, S+2T etc.

  This approach is only suitable for single-thread executor, which fires actions in a sequence. If executor have more that one thread it can fire actions in parallel, but must try to execute exactly RATE actions per time unit (period).


  >>From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right?

  Yes, but we can only do it if we have RATE (or more) threads in executor. Otherwise not all (not RATE) actions will be fired at the start of each period (obviously).


  >>Or did you intend to distribute the execution of the tasks evenly throughout the time period?

  That's another story of which I'm thinking, but for start I prefer to not focus on the "inside period distribution strategy".



  >>Given we don't have guaranteed cancellation mechanisms

  Yep, we don't.
  So if we have requested rate 1 action per second, duration of the action varies [1s; 2.5s], and 2 threads in executor then:
  0) at period [0s; 1s) execution rate 0 (failed rate)
  1) at period [1s; 2s) execution rate 0 (failed rate)
  2) at period [2s; 3s) execution rate 2, because action started at 0) have completed in say 2.2s and action started at 1) have completed in 1.5s
  So at the period [2s; 3s) we have rate 2 instead of 1, is this what you've called overrun? If so then it seems like such cases should also be handled by FailedRatePolicy, so a user can be notified that he should specify rate with a more coarse grained time unit (e.g. 60 actions/minute instead of 1 action/second).


  On Wed, Feb 4, 2015 at 3:08 AM, David Holmes <davidcholmes at aapt.net.au> wrote:

    Hi Valentin,

    Normal schedule-at-fixed-rate sets up a periodic release time: S + nT where S is the start time, T is the period and n = 0,1,2 .... So the task is scheduled for release at times S, S+T, S+2T etc. The main issue here is that if one release is not complete before the next is due to start then what do you do? Given we don't have guaranteed cancellation mechanisms, and that generally you do not want two releases of the task to execute concurrently, we just go into an overrun condition with ScheduledThreadPoolExecutor and delay the next release.

    From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right? Or did you intend to distribute the execution of the tasks evenly throughout the time period?

    David
      -----Original Message-----
      From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Valentin Kovalenko
      Sent: Wednesday, 4 February 2015 9:45 AM
      To: concurrency-interest at cs.oswego.edu
      Subject: [concurrency-interest] Fixed Rate Executor Service


      Hi 
      I'm looking for a fixed rate executor service, and would be glad if someone could give me a hint.


      I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this method doesn't guarantees that actual rate will be not less that the desired one: "If any execution of this task takes longer than its period, then subsequent executions may start late".


      What I want is something like
      scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit, FailedRatePolicy frp),

      where rate==10_000L and unit==SECONDS means 10_000 actions/second,
      and FailedRatePolicy determines what to do if during some second executor failed to satisfy the specified rate (i.e. if at that second it had completed 6_000 actions). Examples of FailedRatePolicy: silently ignore; log a warning; throw an exception. Note also that at the next second after the second where rate wasn't satisfied executor doesn't try to execute 10_000 actions plus those actions that weren't executed, it tries to execute exactly 10_000 actions during the new second.


      Does anyone know an executor which have such a functionality?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/c086440b/attachment-0001.html>

From martinrb at google.com  Tue Feb  3 22:02:43 2015
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 3 Feb 2015 19:02:43 -0800
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>
Message-ID: <CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>

See also Guava RateLimiter
http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html

On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko <
valentin.male.kovalenko at gmail.com> wrote:

> Hi
> I'm looking for a fixed rate executor service, and would be glad if
> someone could give me a hint.
>
> I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this
> method doesn't guarantees that actual rate will be not less that the
> desired one: "If any execution of this task takes longer than its period,
> then subsequent executions may start late".
>
> What I want is something like
> scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
> FailedRatePolicy frp),
> where rate==10_000L and unit==SECONDS means 10_000 actions/second,
> and FailedRatePolicy determines what to do if during some second executor
> failed to satisfy the specified rate (i.e. if at that second it had
> completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
> log a warning; throw an exception. Note also that at the next second after
> the second where rate wasn't satisfied executor doesn't try to execute
> 10_000 actions plus those actions that weren't executed, it tries to
> execute exactly 10_000 actions during the new second.
>
> Does anyone know an executor which have such a functionality?
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150203/dcceeade/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Feb  4 04:44:28 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 13:44:28 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <NFBBKALFDCPFIDBNKAPCOEEBKNAA.davidcholmes@aapt.net.au>
References: <CAO-wXwKuoo=9GCusjsqtKY8+0QeegS++C2ffdjo+91HWqmhfkQ@mail.gmail.com>
	<NFBBKALFDCPFIDBNKAPCOEEBKNAA.davidcholmes@aapt.net.au>
Message-ID: <CAO-wXwJKmPckNMym93ju7YjoFkvDFoT2WUqgHgQkGQ234JTWtA@mail.gmail.com>

>>then you don't need RATE threads in the executor
but if rate is for example 100_000 then it's not the right approach

>>If a task takes UNIT/10 time to execute then you only need RATE/10
threads (plus allow for task management overhead)
I believe no one can tell for any action performed in Java that it takes
exactly T to execute. The best what could be told is some approximation
interval [t1; t2]

On Wed, Feb 4, 2015 at 4:05 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

>  If your tasks can run in parallel (which implies they are independent
> and non-interfering) then you don't need RATE threads in the executor, you
> just need sufficient threads to execute RATE tasks within the time unit. If
> a task takes UNIT time to execute then you need RATE threads. If a task
> takes UNIT/10 time to execute then you only need RATE/10 threads (plus
> allow for task management overhead).
>
> But simple answer: I know of no existing Executor that will do what you
> want.
>
> David
>
> -----Original Message-----
> *From:* Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
> *Sent:* Wednesday, 4 February 2015 10:51 AM
> *To:* dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> *Subject:* Re: [concurrency-interest] Fixed Rate Executor Service
>
> >>the task is scheduled for release at times S, S+T, S+2T etc.
> This approach is only suitable for single-thread executor, which fires
> actions in a sequence. If executor have more that one thread it can fire
> actions in parallel, but must try to execute exactly RATE actions per time
> unit (period).
>
> >>From your description it sounds like concurrent executions would be
> okay, so at the start of each period we would just release all RATE
> instances of the task - is that right?
> Yes, but we can only do it if we have RATE (or more) threads in executor.
> Otherwise not all (not RATE) actions will be fired at the start of each
> period (obviously).
>
> >>Or did you intend to distribute the execution of the tasks evenly
> throughout the time period?
> That's another story of which I'm thinking, but for start I prefer to not
> focus on the "inside period distribution strategy".
>
> >>Given we don't have guaranteed cancellation mechanisms
> Yep, we don't.
> So if we have requested rate 1 action per second, duration of the action
> varies [1s; 2.5s], and 2 threads in executor then:
> 0) at period [0s; 1s) execution rate 0 (failed rate)
> 1) at period [1s; 2s) execution rate 0 (failed rate)
> 2) at period [2s; 3s) execution rate 2, because action started at 0) have
> completed in say 2.2s and action started at 1) have completed in 1.5s
> So at the period [2s; 3s) we have rate 2 instead of 1, is this what you've
> called overrun? If so then it seems like such cases should also be handled
> by FailedRatePolicy, so a user can be notified that he should specify
> rate with a more coarse grained time unit (e.g. 60 actions/minute instead
> of 1 action/second).
>
> On Wed, Feb 4, 2015 at 3:08 AM, David Holmes <davidcholmes at aapt.net.au>
> wrote:
>
>>  Hi Valentin,
>>
>> Normal schedule-at-fixed-rate sets up a periodic release time: S + nT
>> where S is the start time, T is the period and n = 0,1,2 .... So the task
>> is scheduled for release at times S, S+T, S+2T etc. The main issue here is
>> that if one release is not complete before the next is due to start then
>> what do you do? Given we don't have guaranteed cancellation mechanisms, and
>> that generally you do not want two releases of the task to execute
>> concurrently, we just go into an overrun condition with
>> ScheduledThreadPoolExecutor and delay the next release.
>>
>> From your description it sounds like concurrent executions would be okay,
>> so at the start of each period we would just release all RATE instances of
>> the task - is that right? Or did you intend to distribute the execution of
>> the tasks evenly throughout the time period?
>>
>> David
>>
>> -----Original Message-----
>> *From:* concurrency-interest-bounces at cs.oswego.edu [mailto:
>> concurrency-interest-bounces at cs.oswego.edu]*On Behalf Of *Valentin
>> Kovalenko
>> *Sent:* Wednesday, 4 February 2015 9:45 AM
>> *To:* concurrency-interest at cs.oswego.edu
>> *Subject:* [concurrency-interest] Fixed Rate Executor Service
>>
>> Hi
>> I'm looking for a fixed rate executor service, and would be glad if
>> someone could give me a hint.
>>
>> I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this
>> method doesn't guarantees that actual rate will be not less that the
>> desired one: "If any execution of this task takes longer than its period,
>> then subsequent executions may start late".
>>
>> What I want is something like
>> scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>> FailedRatePolicy frp),
>> where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>> and FailedRatePolicy determines what to do if during some second executor
>> failed to satisfy the specified rate (i.e. if at that second it had
>> completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
>> log a warning; throw an exception. Note also that at the next second after
>> the second where rate wasn't satisfied executor doesn't try to execute
>> 10_000 actions plus those actions that weren't executed, it tries to
>> execute exactly 10_000 actions during the new second.
>>
>> Does anyone know an executor which have such a functionality?
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/16d1ab1f/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Feb  4 04:46:08 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 13:46:08 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>
	<CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>
Message-ID: <CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>

Thanks! I've already found RateLimiter but unfortunately it doesn't check
if the rate is actually satisfied.

On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com> wrote:

> See also Guava RateLimiter
>
> http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
>
> On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko <
> valentin.male.kovalenko at gmail.com> wrote:
>
>> Hi
>> I'm looking for a fixed rate executor service, and would be glad if
>> someone could give me a hint.
>>
>> I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this
>> method doesn't guarantees that actual rate will be not less that the
>> desired one: "If any execution of this task takes longer than its period,
>> then subsequent executions may start late".
>>
>> What I want is something like
>> scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>> FailedRatePolicy frp),
>> where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>> and FailedRatePolicy determines what to do if during some second executor
>> failed to satisfy the specified rate (i.e. if at that second it had
>> completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
>> log a warning; throw an exception. Note also that at the next second after
>> the second where rate wasn't satisfied executor doesn't try to execute
>> 10_000 actions plus those actions that weren't executed, it tries to
>> execute exactly 10_000 actions during the new second.
>>
>> Does anyone know an executor which have such a functionality?
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/ed556228/attachment-0001.html>

From davidcholmes at aapt.net.au  Wed Feb  4 04:53:22 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 4 Feb 2015 19:53:22 +1000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXwJKmPckNMym93ju7YjoFkvDFoT2WUqgHgQkGQ234JTWtA@mail.gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>

The point is that you are governed by the potential utilization of your tasks. Even if your RATE is 100_000 you are not going to be able to (nor want to!) create 100_000 threads.

David
  -----Original Message-----
  From: Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
  Sent: Wednesday, 4 February 2015 7:44 PM
  To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
  Subject: Re: [concurrency-interest] Fixed Rate Executor Service


  >>then you don't need RATE threads in the executor
  but if rate is for example 100_000 then it's not the right approach


  >>If a task takes UNIT/10 time to execute then you only need RATE/10 threads (plus allow for task management overhead)

  I believe no one can tell for any action performed in Java that it takes exactly T to execute. The best what could be told is some approximation interval [t1; t2]


  On Wed, Feb 4, 2015 at 4:05 AM, David Holmes <davidcholmes at aapt.net.au> wrote:

    If your tasks can run in parallel (which implies they are independent and non-interfering) then you don't need RATE threads in the executor, you just need sufficient threads to execute RATE tasks within the time unit. If a task takes UNIT time to execute then you need RATE threads. If a task takes UNIT/10 time to execute then you only need RATE/10 threads (plus allow for task management overhead).

    But simple answer: I know of no existing Executor that will do what you want.

    David
      -----Original Message-----
      From: Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
      Sent: Wednesday, 4 February 2015 10:51 AM
      To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
      Subject: Re: [concurrency-interest] Fixed Rate Executor Service


      >>the task is scheduled for release at times S, S+T, S+2T etc.

      This approach is only suitable for single-thread executor, which fires actions in a sequence. If executor have more that one thread it can fire actions in parallel, but must try to execute exactly RATE actions per time unit (period).


      >>From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right?

      Yes, but we can only do it if we have RATE (or more) threads in executor. Otherwise not all (not RATE) actions will be fired at the start of each period (obviously).


      >>Or did you intend to distribute the execution of the tasks evenly throughout the time period?

      That's another story of which I'm thinking, but for start I prefer to not focus on the "inside period distribution strategy".



      >>Given we don't have guaranteed cancellation mechanisms

      Yep, we don't.
      So if we have requested rate 1 action per second, duration of the action varies [1s; 2.5s], and 2 threads in executor then:
      0) at period [0s; 1s) execution rate 0 (failed rate)
      1) at period [1s; 2s) execution rate 0 (failed rate)
      2) at period [2s; 3s) execution rate 2, because action started at 0) have completed in say 2.2s and action started at 1) have completed in 1.5s
      So at the period [2s; 3s) we have rate 2 instead of 1, is this what you've called overrun? If so then it seems like such cases should also be handled by FailedRatePolicy, so a user can be notified that he should specify rate with a more coarse grained time unit (e.g. 60 actions/minute instead of 1 action/second).


      On Wed, Feb 4, 2015 at 3:08 AM, David Holmes <davidcholmes at aapt.net.au> wrote:

        Hi Valentin,

        Normal schedule-at-fixed-rate sets up a periodic release time: S + nT where S is the start time, T is the period and n = 0,1,2 .... So the task is scheduled for release at times S, S+T, S+2T etc. The main issue here is that if one release is not complete before the next is due to start then what do you do? Given we don't have guaranteed cancellation mechanisms, and that generally you do not want two releases of the task to execute concurrently, we just go into an overrun condition with ScheduledThreadPoolExecutor and delay the next release.

        From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right? Or did you intend to distribute the execution of the tasks evenly throughout the time period?

        David
          -----Original Message-----
          From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Valentin Kovalenko
          Sent: Wednesday, 4 February 2015 9:45 AM
          To: concurrency-interest at cs.oswego.edu
          Subject: [concurrency-interest] Fixed Rate Executor Service


          Hi 
          I'm looking for a fixed rate executor service, and would be glad if someone could give me a hint.


          I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this method doesn't guarantees that actual rate will be not less that the desired one: "If any execution of this task takes longer than its period, then subsequent executions may start late".


          What I want is something like
          scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit, FailedRatePolicy frp),

          where rate==10_000L and unit==SECONDS means 10_000 actions/second,
          and FailedRatePolicy determines what to do if during some second executor failed to satisfy the specified rate (i.e. if at that second it had completed 6_000 actions). Examples of FailedRatePolicy: silently ignore; log a warning; throw an exception. Note also that at the next second after the second where rate wasn't satisfied executor doesn't try to execute 10_000 actions plus those actions that weren't executed, it tries to execute exactly 10_000 actions during the new second.


          Does anyone know an executor which have such a functionality?



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/0978d428/attachment.html>

From aleksey.shipilev at oracle.com  Wed Feb  4 06:11:54 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 04 Feb 2015 14:11:54 +0300
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>	<CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>
	<CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>
Message-ID: <54D1FE7A.4000404@oracle.com>

My 2c. One time I just put the TokenBucket-like limiter in front of the
regular executor, and was done with it.

Something along the lines of (GPLv2 code inside. The idea is to track
the <current-second, available-tokens> "quantum" tuple and update it in
a lock-free way):
 http://cr.openjdk.java.net/~shade/scratch/jcp/src/main/java/org/openjdk/TokenBucket.java

Such a token bucket should never over-reach the rate, and I think it can
be amended with FailedRatePolicy by detecting the current quantum is not
depleted before installing a new one.

I'm speculating Guava's RateLimiter does something like that, but from
the look over the javadoc, it seems to have a smooth refill strategy,
which may alleviate the microbursts on the quanta edges.

-Aleksey.

On 02/04/2015 12:46 PM, Valentin Kovalenko wrote:
> Thanks! I've already found RateLimiter but unfortunately it doesn't
> check if the rate is actually satisfied.
> 
> On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com
> <mailto:martinrb at google.com>> wrote:
> 
>     See also Guava RateLimiter
>     http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
> 
>     On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko
>     <valentin.male.kovalenko at gmail.com
>     <mailto:valentin.male.kovalenko at gmail.com>> wrote:
> 
>         Hi
>         I'm looking for a fixed rate executor service, and would be glad
>         if someone could give me a hint.
> 
>         I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate,
>         but this method doesn't guarantees that actual rate will be not
>         less that the desired one: "If any execution of this task takes
>         longer than its period, then subsequent executions may start late".
> 
>         What I want is something like
>         scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>         FailedRatePolicy frp),
>         where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>         and FailedRatePolicy determines what to do if during some second
>         executor failed to satisfy the specified rate (i.e. if at that
>         second it had completed 6_000 actions). Examples of
>         FailedRatePolicy: silently ignore; log a warning; throw an
>         exception. Note also that at the next second after the second
>         where rate wasn't satisfied executor doesn't try to execute
>         10_000 actions plus those actions that weren't executed, it
>         tries to execute exactly 10_000 actions during the new second.
> 
>         Does anyone know an executor which have such a functionality?
> 
>         _______________________________________________
>         Concurrency-interest mailing list
>         Concurrency-interest at cs.oswego.edu
>         <mailto:Concurrency-interest at cs.oswego.edu>
>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> 
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/c0ebeee2/attachment.bin>

From fedos.serg at gmail.com  Wed Feb  4 06:33:56 2015
From: fedos.serg at gmail.com (Sergey Fedoseenkov)
Date: Wed, 4 Feb 2015 17:03:56 +0530
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 121,
	Issue 5
In-Reply-To: <mailman.347.1423043178.1180.concurrency-interest@cs.oswego.edu>
References: <mailman.347.1423043178.1180.concurrency-interest@cs.oswego.edu>
Message-ID: <CAB8u120vezUE2FKAHR+O=LH=dkf9NsYN-Hf=kOX1SSLn-7PSAg@mail.gmail.com>

Hi Valya,
these guys have their own implementation -
http://svn.apache.org/repos/asf/jmeter/trunk/src/components/org/apache/jmeter/control/ThroughputController.java
May be it will be helpful.

On Wed, Feb 4, 2015 at 3:16 PM, <concurrency-interest-request at cs.oswego.edu>
wrote:

>
> Date: Wed, 4 Feb 2015 13:46:08 +0400
> From: Valentin Kovalenko <valentin.male.kovalenko at gmail.com>
> To: Martin Buchholz <martinrb at google.com>,      concurrency-interest
>         <concurrency-interest at cs.oswego.edu>
> Subject: Re: [concurrency-interest] Fixed Rate Executor Service
> Message-ID:
>         <CAO-wXwKBbanTbdTQznFuL9=1uoW=
> z76_jx6O1KO9_H4C3OzD+Q at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Thanks! I've already found RateLimiter but unfortunately it doesn't check
> if the rate is actually satisfied.
>
> On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com>
> wrote:
>
> > See also Guava RateLimiter
> >
> >
> http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
> >
> > On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko <
> > valentin.male.kovalenko at gmail.com> wrote:
> >
> >> Hi
> >> I'm looking for a fixed rate executor service, and would be glad if
> >> someone could give me a hint.
> >>
> >> I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but
> this
> >> method doesn't guarantees that actual rate will be not less that the
> >> desired one: "If any execution of this task takes longer than its
> period,
> >> then subsequent executions may start late".
> >>
> >> What I want is something like
> >> scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
> >> FailedRatePolicy frp),
> >> where rate==10_000L and unit==SECONDS means 10_000 actions/second,
> >> and FailedRatePolicy determines what to do if during some second
> executor
> >> failed to satisfy the specified rate (i.e. if at that second it had
> >> completed 6_000 actions). Examples of FailedRatePolicy: silently ignore;
> >> log a warning; throw an exception. Note also that at the next second
> after
> >> the second where rate wasn't satisfied executor doesn't try to execute
> >> 10_000 actions plus those actions that weren't executed, it tries to
> >> execute exactly 10_000 actions during the new second.
> >>
> >> Does anyone know an executor which have such a functionality?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/f32fc84b/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Feb  4 06:45:54 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Feb 2015 11:45:54 +0000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D1FE7A.4000404@oracle.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>	<CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>	<CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>
	<54D1FE7A.4000404@oracle.com>
Message-ID: <54D20672.4020201@oracle.com>

Why would you need current-second? Is the task that didn't return a 
token yet not consuming the resource any more? (Or if the concern is not 
the resource consumption, then what's the point of rate limiting?)

Alex

On 04/02/2015 11:11, Aleksey Shipilev wrote:
> My 2c. One time I just put the TokenBucket-like limiter in front of the
> regular executor, and was done with it.
>
> Something along the lines of (GPLv2 code inside. The idea is to track
> the <current-second, available-tokens> "quantum" tuple and update it in
> a lock-free way):
>   http://cr.openjdk.java.net/~shade/scratch/jcp/src/main/java/org/openjdk/TokenBucket.java
>
> Such a token bucket should never over-reach the rate, and I think it can
> be amended with FailedRatePolicy by detecting the current quantum is not
> depleted before installing a new one.
>
> I'm speculating Guava's RateLimiter does something like that, but from
> the look over the javadoc, it seems to have a smooth refill strategy,
> which may alleviate the microbursts on the quanta edges.
>
> -Aleksey.
>
> On 02/04/2015 12:46 PM, Valentin Kovalenko wrote:
>> Thanks! I've already found RateLimiter but unfortunately it doesn't
>> check if the rate is actually satisfied.
>>
>> On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com
>> <mailto:martinrb at google.com>> wrote:
>>
>>      See also Guava RateLimiter
>>      http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
>>
>>      On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko
>>      <valentin.male.kovalenko at gmail.com
>>      <mailto:valentin.male.kovalenko at gmail.com>> wrote:
>>
>>          Hi
>>          I'm looking for a fixed rate executor service, and would be glad
>>          if someone could give me a hint.
>>
>>          I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate,
>>          but this method doesn't guarantees that actual rate will be not
>>          less that the desired one: "If any execution of this task takes
>>          longer than its period, then subsequent executions may start late".
>>
>>          What I want is something like
>>          scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>>          FailedRatePolicy frp),
>>          where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>>          and FailedRatePolicy determines what to do if during some second
>>          executor failed to satisfy the specified rate (i.e. if at that
>>          second it had completed 6_000 actions). Examples of
>>          FailedRatePolicy: silently ignore; log a warning; throw an
>>          exception. Note also that at the next second after the second
>>          where rate wasn't satisfied executor doesn't try to execute
>>          10_000 actions plus those actions that weren't executed, it
>>          tries to execute exactly 10_000 actions during the new second.
>>
>>          Does anyone know an executor which have such a functionality?
>>
>>          _______________________________________________
>>          Concurrency-interest mailing list
>>          Concurrency-interest at cs.oswego.edu
>>          <mailto:Concurrency-interest at cs.oswego.edu>
>>          http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/9839803e/attachment.html>

From peter.levart at gmail.com  Wed Feb  4 06:55:44 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 04 Feb 2015 12:55:44 +0100
Subject: [concurrency-interest] Safe publishing,
	final fields and deserialization
In-Reply-To: <54C7F54C.9060401@gmail.com>
References: <CAO9V1MLuybVESz6Z=FC=Whs8zXypF_eixK49=KLRKxQG_motPQ@mail.gmail.com>	<CA+kOe08APW2kLwdrOvgiGxMtzEwLUP-nv22fS3ks-OiXgnJs-Q@mail.gmail.com>	<CAHjP37G+b_vEtM3Xwg2nvZfo_LSapTECoCKO_6DwCX7-XqQ2=A@mail.gmail.com>	<CAO9V1MJ3NMvcttR1GRCFYF+6J=bKwDnJqsD9+4AGJZHi5yaKxg@mail.gmail.com>	<54C28686.60306@oracle.com>	<CAO9V1MJyNrayWrn5krvQVTZ53ks1xKaJh6hEToDFAaj4nfpL9Q@mail.gmail.com>	<54C28BEE.8010201@oracle.com>	<CAO9V1MK-LNj8oWDBJgACUOVBssF2SoCedsHdp2PQVPufrGFM_g@mail.gmail.com>	<0FD072A166C6DC4C851F6115F37DDD2783D8E4CB@sm-ex-01-vm.guidewire.com>	<54C2A085.5090808@oracle.com>	<CAO9V1M+HFGti_q-9BL4+VuL=VrctE23Oq-xu_fqCtZWky16+BQ@mail.gmail.com>
	<54C2AEEE.3060607@oracle.com> <54C7F54C.9060401@gmail.com>
Message-ID: <54D208C0.9060804@gmail.com>

Hi,

I'm asking this because there is a possibility for ObjectInputStream API 
to be extended to facilitate easier manipulation of final fields when 
deserialization is using "private readObject(ObjectInputStream in)" 
methods which act as a kind of deserialization constructors. Is relying 
on current reflection implementation still enough considering all new 
platforms that were introduced recently (PowerPC/AIX, ARM/Linux, 
ARM64/Linux) or should the deserialization infrastructure be "fixed" to 
invoke Unsafe.storeFence() after writing to final fields 
(Unsafe.putXXXVolatile) declared by a particular class to achieve 
analogue to "freeze" action in constructors.

Or maybe reflection could be changed for final fields only. Currently it 
uses the same code as volatile fields, meaning: Field.set() -> 
Unsafe.putXXXVolatile() and Field.get() -> Unsafe.getXXXVolatile(). 
Would some combination of relaxed Unsafe writes and/or reads in 
combination with explicit fences more accurately simulate final field 
behaviour?

Regards, Peter

On 01/27/2015 09:30 PM, Peter Levart wrote:
> The JLS in the following paragraph:
>
> http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.5.3
>
> Says:
>
> "In some cases, such as deserialization, the system will need to 
> change the final fields of an object after construction. final fields 
> can be changed via reflection and other implementation-dependent 
> means. The only pattern in which this has reasonable semantics is one 
> in which an object is constructed and then the final fields of the 
> object are updated. The object should not be made visible to other 
> threads, nor should the final fields be read, until all updates to the 
> final fields of the object are complete. Freezes of a final field 
> occur both at the end of the constructor in which the final field is 
> set, and immediately after each modification of a final field via 
> reflection or other special mechanism."
>
> I'm interested in last paragraph which says: "Freezes of a final field 
> occur both at the end of the constructor in which the final field is 
> set, and immediately after each modification of a final field via 
> reflection or other special mechanism."
>
> But we know that "freeze" at the end of constructor includes a 
> StoreStore fence, which prevents subsequent relaxed stores (of a 
> reference to the constructed object for example) to be reordered 
> before stores to final fields in constructor, but writing to final 
> fields with reflection is implemented with simple 
> Unsafe.putXXXVolatile().
>
> So the question is: Does Unsafe.putVolatileXXX() provide a grater 
> guarantee (that subsequent relaxed stores are not reordered before 
> it), or does it behave the same as normal Java bytecode volatile field 
> store, where no such guarantee is provided and consequently the 
> implementation of reflection is not following JLS?
>
> Regards, Peter
>
>


From aleksey.shipilev at oracle.com  Wed Feb  4 07:16:53 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Wed, 04 Feb 2015 15:16:53 +0300
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D20672.4020201@oracle.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>	<CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>	<CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>
	<54D1FE7A.4000404@oracle.com> <54D20672.4020201@oracle.com>
Message-ID: <54D20DB5.5020200@oracle.com>

Um... Because that's a one-sided rate limiter, not a two-sided
"semaphore" guarding a section. As far as I can see, OP does not talk
about limiting the number of concurrent tasks (that translates to
limiting the resources used at a given time).

-Aleksey.

On 02/04/2015 02:45 PM, Oleksandr Otenko wrote:
> Why would you need current-second? Is the task that didn't return a
> token yet not consuming the resource any more? (Or if the concern is not
> the resource consumption, then what's the point of rate limiting?)
> 
> Alex
> 
> On 04/02/2015 11:11, Aleksey Shipilev wrote:
>> My 2c. One time I just put the TokenBucket-like limiter in front of the
>> regular executor, and was done with it.
>>
>> Something along the lines of (GPLv2 code inside. The idea is to track
>> the <current-second, available-tokens> "quantum" tuple and update it in
>> a lock-free way):
>>  http://cr.openjdk.java.net/~shade/scratch/jcp/src/main/java/org/openjdk/TokenBucket.java
>>
>> Such a token bucket should never over-reach the rate, and I think it can
>> be amended with FailedRatePolicy by detecting the current quantum is not
>> depleted before installing a new one.
>>
>> I'm speculating Guava's RateLimiter does something like that, but from
>> the look over the javadoc, it seems to have a smooth refill strategy,
>> which may alleviate the microbursts on the quanta edges.
>>
>> -Aleksey.
>>
>> On 02/04/2015 12:46 PM, Valentin Kovalenko wrote:
>>> Thanks! I've already found RateLimiter but unfortunately it doesn't
>>> check if the rate is actually satisfied.
>>>
>>> On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com
>>> <mailto:martinrb at google.com>> wrote:
>>>
>>>     See also Guava RateLimiter
>>>     http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
>>>
>>>     On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko
>>>     <valentin.male.kovalenko at gmail.com
>>>     <mailto:valentin.male.kovalenko at gmail.com>> wrote:
>>>
>>>         Hi
>>>         I'm looking for a fixed rate executor service, and would be glad
>>>         if someone could give me a hint.
>>>
>>>         I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate,
>>>         but this method doesn't guarantees that actual rate will be not
>>>         less that the desired one: "If any execution of this task takes
>>>         longer than its period, then subsequent executions may start late".
>>>
>>>         What I want is something like
>>>         scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>>>         FailedRatePolicy frp),
>>>         where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>>>         and FailedRatePolicy determines what to do if during some second
>>>         executor failed to satisfy the specified rate (i.e. if at that
>>>         second it had completed 6_000 actions). Examples of
>>>         FailedRatePolicy: silently ignore; log a warning; throw an
>>>         exception. Note also that at the next second after the second
>>>         where rate wasn't satisfied executor doesn't try to execute
>>>         10_000 actions plus those actions that weren't executed, it
>>>         tries to execute exactly 10_000 actions during the new second.
>>>
>>>         Does anyone know an executor which have such a functionality?
>>>
>>>         _______________________________________________
>>>         Concurrency-interest mailing list
>>>         Concurrency-interest at cs.oswego.edu
>>>         <mailto:Concurrency-interest at cs.oswego.edu>
>>>         http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/f0758d0a/attachment.bin>

From peter.levart at gmail.com  Wed Feb  4 07:43:20 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 04 Feb 2015 13:43:20 +0100
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>
Message-ID: <54D213E8.7060103@gmail.com>

What about the following strategy:

Have a submission thread submit tasks at a fixed rate (your desired 
rate) to a ThreadPoolExecutor with some limit on max. number of threads 
(using RateLimiter if you like or some other means).
Let this ThreadPoolExecutor have a SynchonousQueue.
When the Executor starts rejecting executions, it means your rate can't 
be satisfied with given max. number of threads.

Regards, Peter

On 02/04/2015 10:53 AM, David Holmes wrote:
> The point is that you are governed by the potential utilization of your tasks. Even if your RATE is 100_000 you are not going to be able to (nor want to!) create 100_000 threads.
>
> David
>    -----Original Message-----
>    From: Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
>    Sent: Wednesday, 4 February 2015 7:44 PM
>    To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>    Subject: Re: [concurrency-interest] Fixed Rate Executor Service
>
>
>    >>then you don't need RATE threads in the executor
>    but if rate is for example 100_000 then it's not the right approach
>
>
>    >>If a task takes UNIT/10 time to execute then you only need RATE/10 threads (plus allow for task management overhead)
>
>    I believe no one can tell for any action performed in Java that it takes exactly T to execute. The best what could be told is some approximation interval [t1; t2]
>
>
>    On Wed, Feb 4, 2015 at 4:05 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>
>      If your tasks can run in parallel (which implies they are independent and non-interfering) then you don't need RATE threads in the executor, you just need sufficient threads to execute RATE tasks within the time unit. If a task takes UNIT time to execute then you need RATE threads. If a task takes UNIT/10 time to execute then you only need RATE/10 threads (plus allow for task management overhead).
>
>      But simple answer: I know of no existing Executor that will do what you want.
>
>      David
>        -----Original Message-----
>        From: Valentin Kovalenko [mailto:valentin.male.kovalenko at gmail.com]
>        Sent: Wednesday, 4 February 2015 10:51 AM
>        To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
>        Subject: Re: [concurrency-interest] Fixed Rate Executor Service
>
>
>        >>the task is scheduled for release at times S, S+T, S+2T etc.
>
>        This approach is only suitable for single-thread executor, which fires actions in a sequence. If executor have more that one thread it can fire actions in parallel, but must try to execute exactly RATE actions per time unit (period).
>
>
>        >>From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right?
>
>        Yes, but we can only do it if we have RATE (or more) threads in executor. Otherwise not all (not RATE) actions will be fired at the start of each period (obviously).
>
>
>        >>Or did you intend to distribute the execution of the tasks evenly throughout the time period?
>
>        That's another story of which I'm thinking, but for start I prefer to not focus on the "inside period distribution strategy".
>
>
>
>        >>Given we don't have guaranteed cancellation mechanisms
>
>        Yep, we don't.
>        So if we have requested rate 1 action per second, duration of the action varies [1s; 2.5s], and 2 threads in executor then:
>        0) at period [0s; 1s) execution rate 0 (failed rate)
>        1) at period [1s; 2s) execution rate 0 (failed rate)
>        2) at period [2s; 3s) execution rate 2, because action started at 0) have completed in say 2.2s and action started at 1) have completed in 1.5s
>        So at the period [2s; 3s) we have rate 2 instead of 1, is this what you've called overrun? If so then it seems like such cases should also be handled by FailedRatePolicy, so a user can be notified that he should specify rate with a more coarse grained time unit (e.g. 60 actions/minute instead of 1 action/second).
>
>
>        On Wed, Feb 4, 2015 at 3:08 AM, David Holmes <davidcholmes at aapt.net.au> wrote:
>
>          Hi Valentin,
>
>          Normal schedule-at-fixed-rate sets up a periodic release time: S + nT where S is the start time, T is the period and n = 0,1,2 .... So the task is scheduled for release at times S, S+T, S+2T etc. The main issue here is that if one release is not complete before the next is due to start then what do you do? Given we don't have guaranteed cancellation mechanisms, and that generally you do not want two releases of the task to execute concurrently, we just go into an overrun condition with ScheduledThreadPoolExecutor and delay the next release.
>
>          From your description it sounds like concurrent executions would be okay, so at the start of each period we would just release all RATE instances of the task - is that right? Or did you intend to distribute the execution of the tasks evenly throughout the time period?
>
>          David
>            -----Original Message-----
>            From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Valentin Kovalenko
>            Sent: Wednesday, 4 February 2015 9:45 AM
>            To: concurrency-interest at cs.oswego.edu
>            Subject: [concurrency-interest] Fixed Rate Executor Service
>
>
>            Hi
>            I'm looking for a fixed rate executor service, and would be glad if someone could give me a hint.
>
>
>            I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate, but this method doesn't guarantees that actual rate will be not less that the desired one: "If any execution of this task takes longer than its period, then subsequent executions may start late".
>
>
>            What I want is something like
>            scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit, FailedRatePolicy frp),
>
>            where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>            and FailedRatePolicy determines what to do if during some second executor failed to satisfy the specified rate (i.e. if at that second it had completed 6_000 actions). Examples of FailedRatePolicy: silently ignore; log a warning; throw an exception. Note also that at the next second after the second where rate wasn't satisfied executor doesn't try to execute 10_000 actions plus those actions that weren't executed, it tries to execute exactly 10_000 actions during the new second.
>
>
>            Does anyone know an executor which have such a functionality?
>
>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/fc0faa07/attachment-0001.html>

From oleksandr.otenko at oracle.com  Wed Feb  4 07:55:53 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Feb 2015 12:55:53 +0000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D20DB5.5020200@oracle.com>
References: <CAO-wXw+1+Q+6rCm3FtuF87-nKdBDmuL0STckJ-L=3-zaLFJaTg@mail.gmail.com>	<CA+kOe0_1Vr61NjTof-R2ZysWCvNHHrsVzRupGkD-nOHvjajPxg@mail.gmail.com>	<CAO-wXwKBbanTbdTQznFuL9=1uoW=z76_jx6O1KO9_H4C3OzD+Q@mail.gmail.com>
	<54D1FE7A.4000404@oracle.com> <54D20672.4020201@oracle.com>
	<54D20DB5.5020200@oracle.com>
Message-ID: <54D216D9.9000907@oracle.com>

Yes, so my question then is what is the use-case for rate-limiter, the 
limiter of ingress of requests into the pool. Also, I suppose that when 
the limit is reached, the requests.....ermmm.... wait somewhere in a 
queue? So is the purpose of rate limiter to control contention on the 
executor thread pool /task queue/?


Alex


On 04/02/2015 12:16, Aleksey Shipilev wrote:
> Um... Because that's a one-sided rate limiter, not a two-sided
> "semaphore" guarding a section. As far as I can see, OP does not talk
> about limiting the number of concurrent tasks (that translates to
> limiting the resources used at a given time).
>
> -Aleksey.
>
> On 02/04/2015 02:45 PM, Oleksandr Otenko wrote:
>> Why would you need current-second? Is the task that didn't return a
>> token yet not consuming the resource any more? (Or if the concern is not
>> the resource consumption, then what's the point of rate limiting?)
>>
>> Alex
>>
>> On 04/02/2015 11:11, Aleksey Shipilev wrote:
>>> My 2c. One time I just put the TokenBucket-like limiter in front of the
>>> regular executor, and was done with it.
>>>
>>> Something along the lines of (GPLv2 code inside. The idea is to track
>>> the <current-second, available-tokens> "quantum" tuple and update it in
>>> a lock-free way):
>>>   http://cr.openjdk.java.net/~shade/scratch/jcp/src/main/java/org/openjdk/TokenBucket.java
>>>
>>> Such a token bucket should never over-reach the rate, and I think it can
>>> be amended with FailedRatePolicy by detecting the current quantum is not
>>> depleted before installing a new one.
>>>
>>> I'm speculating Guava's RateLimiter does something like that, but from
>>> the look over the javadoc, it seems to have a smooth refill strategy,
>>> which may alleviate the microbursts on the quanta edges.
>>>
>>> -Aleksey.
>>>
>>> On 02/04/2015 12:46 PM, Valentin Kovalenko wrote:
>>>> Thanks! I've already found RateLimiter but unfortunately it doesn't
>>>> check if the rate is actually satisfied.
>>>>
>>>> On Wed, Feb 4, 2015 at 6:02 AM, Martin Buchholz <martinrb at google.com
>>>> <mailto:martinrb at google.com>> wrote:
>>>>
>>>>      See also Guava RateLimiter
>>>>      http://docs.guava-libraries.googlecode.com/git-history/master/javadoc/com/google/common/util/concurrent/RateLimiter.html
>>>>
>>>>      On Tue, Feb 3, 2015 at 3:45 PM, Valentin Kovalenko
>>>>      <valentin.male.kovalenko at gmail.com
>>>>      <mailto:valentin.male.kovalenko at gmail.com>> wrote:
>>>>
>>>>          Hi
>>>>          I'm looking for a fixed rate executor service, and would be glad
>>>>          if someone could give me a hint.
>>>>
>>>>          I'm aware of j.u.c.ScheduledExecutorService.scheduleAtFixedRate,
>>>>          but this method doesn't guarantees that actual rate will be not
>>>>          less that the desired one: "If any execution of this task takes
>>>>          longer than its period, then subsequent executions may start late".
>>>>
>>>>          What I want is something like
>>>>          scheduleAtFixedRate(Runnable action, long rate, TimeUnit unit,
>>>>          FailedRatePolicy frp),
>>>>          where rate==10_000L and unit==SECONDS means 10_000 actions/second,
>>>>          and FailedRatePolicy determines what to do if during some second
>>>>          executor failed to satisfy the specified rate (i.e. if at that
>>>>          second it had completed 6_000 actions). Examples of
>>>>          FailedRatePolicy: silently ignore; log a warning; throw an
>>>>          exception. Note also that at the next second after the second
>>>>          where rate wasn't satisfied executor doesn't try to execute
>>>>          10_000 actions plus those actions that weren't executed, it
>>>>          tries to execute exactly 10_000 actions during the new second.
>>>>
>>>>          Does anyone know an executor which have such a functionality?
>>>>
>>>>          _______________________________________________
>>>>          Concurrency-interest mailing list
>>>>          Concurrency-interest at cs.oswego.edu
>>>>          <mailto:Concurrency-interest at cs.oswego.edu>
>>>>          http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/436866c9/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Feb  4 08:58:04 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 17:58:04 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D213E8.7060103@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>
	<54D213E8.7060103@gmail.com>
Message-ID: <CAO-wXwJxZ0hvgYai_Y5szm5X7kw9b6tgwqD5DQ4MOyaX0dcHfg@mail.gmail.com>

At first look it seems like a good idea! :)

On Wed, Feb 4, 2015 at 3:43 PM, Peter Levart <peter.levart at gmail.com> wrote:

>  What about the following strategy:
>
> Have a submission thread submit tasks at a fixed rate (your desired rate)
> to a ThreadPoolExecutor with some limit on max. number of threads (using
> RateLimiter if you like or some other means).
> Let this ThreadPoolExecutor have a SynchonousQueue.
> When the Executor starts rejecting executions, it means your rate can't be
> satisfied with given max. number of threads.
>
> Regards, Peter
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/dcc3c9d3/attachment.html>

From peter.levart at gmail.com  Wed Feb  4 09:01:38 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 04 Feb 2015 15:01:38 +0100
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXwJxZ0hvgYai_Y5szm5X7kw9b6tgwqD5DQ4MOyaX0dcHfg@mail.gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>	<54D213E8.7060103@gmail.com>
	<CAO-wXwJxZ0hvgYai_Y5szm5X7kw9b6tgwqD5DQ4MOyaX0dcHfg@mail.gmail.com>
Message-ID: <54D22642.5040806@gmail.com>

On 02/04/2015 02:58 PM, Valentin Kovalenko wrote:
> At first look it seems like a good idea! :)
>
> On Wed, Feb 4, 2015 at 3:43 PM, Peter Levart <peter.levart at gmail.com> wrote:
>
>>   What about the following strategy:
>>
>> Have a submission thread submit tasks at a fixed rate (your desired rate)
>> to a ThreadPoolExecutor with some limit on max. number of threads (using
>> RateLimiter if you like or some other means).
>> Let this ThreadPoolExecutor have a SynchonousQueue.
>> When the Executor starts rejecting executions, it means your rate can't be
>> satisfied with given max. number of threads.
>>
>> Regards, Peter
>>


Here's also some meat:

public classFixedRateExecutor {

     finalThreadPoolExecutorworkerExec;
     finalScheduledExecutorServiceschedExec;

     publicFixedRateExecutor(
         intcorePoolSize, intmaximumPoolSize,
         longkeepAliveTime,TimeUnit unit) {

         workerExec=newThreadPoolExecutor(
             corePoolSize,maximumPoolSize,
             keepAliveTime,unit,
             newSynchronousQueue<>()
         );
         schedExec= Executors.newScheduledThreadPool(1);
     }

     publicScheduledFuture<?>scheduleAtFixedRate(
         Runnable command,
         longinitialDelay, longperiod,TimeUnit unit,
         FailedRatePolicy failedRatePolicy) {

         returnschedExec.scheduleAtFixedRate(() -> {
                 try{
                     workerExec.execute(command);
                 }catch(RejectedExecutionException e) {
                     failedRatePolicy.failedRate(e);
                 }
             },
             initialDelay,period,unit
         );
     }

     public interfaceFailedRatePolicy {
         FailedRatePolicyIGNORE= e -> {};
         FailedRatePolicyTHROW= e -> {throwe;};

         voidfailedRate(RejectedExecutionException e);
     }
}

Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/4426a8fc/attachment.html>

From peter.levart at gmail.com  Wed Feb  4 09:03:10 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Wed, 04 Feb 2015 15:03:10 +0100
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D22642.5040806@gmail.com>
References: <NFBBKALFDCPFIDBNKAPCEEEDKNAA.davidcholmes@aapt.net.au>	<54D213E8.7060103@gmail.com>
	<CAO-wXwJxZ0hvgYai_Y5szm5X7kw9b6tgwqD5DQ4MOyaX0dcHfg@mail.gmail.com>
	<54D22642.5040806@gmail.com>
Message-ID: <54D2269E.8040401@gmail.com>

Ah, the list and HTML formatting. Here's in plain ASCII:


public class FixedRateExecutor {

     final ThreadPoolExecutor workerExec;
     final ScheduledExecutorService schedExec;

     public FixedRateExecutor(
         int corePoolSize, int maximumPoolSize,
         long keepAliveTime, TimeUnit unit) {

         workerExec = new ThreadPoolExecutor(
             corePoolSize, maximumPoolSize,
             keepAliveTime, unit,
             new SynchronousQueue<>()
         );
         schedExec = Executors.newScheduledThreadPool(1);
     }

     public ScheduledFuture<?> scheduleAtFixedRate(
         Runnable command,
         long initialDelay, long period, TimeUnit unit,
         FailedRatePolicy failedRatePolicy) {

         return schedExec.scheduleAtFixedRate(() -> {
                 try {
                     workerExec.execute(command);
                 } catch (RejectedExecutionException e) {
                     failedRatePolicy.failedRate(e);
                 }
             },
             initialDelay, period, unit
         );
     }

     public interface FailedRatePolicy {
         FailedRatePolicy IGNORE = e -> {};
         FailedRatePolicy THROW = e -> { throw e; };

         void failedRate(RejectedExecutionException e);
     }
}


Peter

On 02/04/2015 03:01 PM, Peter Levart wrote:
> On 02/04/2015 02:58 PM, Valentin Kovalenko wrote:
>> At first look it seems like a good idea! :)
>>
>> On Wed, Feb 4, 2015 at 3:43 PM, Peter Levart <peter.levart at gmail.com> 
>> wrote:
>>
>>>   What about the following strategy:
>>>
>>> Have a submission thread submit tasks at a fixed rate (your desired 
>>> rate)
>>> to a ThreadPoolExecutor with some limit on max. number of threads 
>>> (using
>>> RateLimiter if you like or some other means).
>>> Let this ThreadPoolExecutor have a SynchonousQueue.
>>> When the Executor starts rejecting executions, it means your rate 
>>> can't be
>>> satisfied with given max. number of threads.
>>>
>>> Regards, Peter
>>>
>
>
> Here's also some meat:
>
> public classFixedRateExecutor {
>
>     finalThreadPoolExecutorworkerExec;
>     finalScheduledExecutorServiceschedExec;
>
>     publicFixedRateExecutor(
>         intcorePoolSize, intmaximumPoolSize,
>         longkeepAliveTime,TimeUnit unit) {
>
>         workerExec=newThreadPoolExecutor(
>             corePoolSize,maximumPoolSize,
>             keepAliveTime,unit,
>             newSynchronousQueue<>()
>         );
>         schedExec= Executors.newScheduledThreadPool(1);
>     }
>
>     publicScheduledFuture<?>scheduleAtFixedRate(
>         Runnable command,
>         longinitialDelay, longperiod,TimeUnit unit,
>         FailedRatePolicy failedRatePolicy) {
>
>         returnschedExec.scheduleAtFixedRate(() -> {
>                 try{
>                     workerExec.execute(command);
>                 }catch(RejectedExecutionException e) {
>                     failedRatePolicy.failedRate(e);
>                 }
>             },
>             initialDelay,period,unit
>         );
>     }
>
>     public interfaceFailedRatePolicy {
>         FailedRatePolicyIGNORE= e -> {};
>         FailedRatePolicyTHROW= e -> {throwe;};
>
>         voidfailedRate(RejectedExecutionException e);
>     }
> }
>
> Regards, Peter
>
>


From valentin.male.kovalenko at gmail.com  Wed Feb  4 10:53:58 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 19:53:58 +0400
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 121,
	Issue 8
Message-ID: <CAO-wXwLUDcnQNVY9PAqygtsBKTpkWO3iMNeSyH76gRGdnYadoA@mail.gmail.com>

>>is the purpose of rate limiter to control contention on the
executor thread pool /task queue/?
The purpose of fixed rate executor is exactly the following: to fire
actions at the specified rate (not with higher rate, not with lower rate).

>>when the limit is reached, the requests.....ermmm.... wait somewhere in a
queue?
When the limit is reached, executor becomes idle till the start of next
period.
Could you explain what do you mean by "requests?" I don't understand
because there are no requests, there is only executor that fires actions
(calls action.run()) and ensures that at each period not more that RATE
actions were completed.


> Date: Wed, 04 Feb 2015 12:55:53 +0000
> From: Oleksandr Otenko <oleksandr.otenko at oracle.com>
> To: Aleksey Shipilev <aleksey.shipilev at oracle.com>,
>         concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Fixed Rate Executor Service
> Message-ID: <54D216D9.9000907 at oracle.com>
> Content-Type: text/plain; charset="windows-1252"; Format="flowed"
>
> Yes, so my question then is what is the use-case for rate-limiter, the
> limiter of ingress of requests into the pool. Also, I suppose that when
> the limit is reached, the requests.....ermmm.... wait somewhere in a
> queue? So is the purpose of rate limiter to control contention on the
> executor thread pool /task queue/?
>
>
> Alex
>
>
> On 04/02/2015 12:16, Aleksey Shipilev wrote:
> > Um... Because that's a one-sided rate limiter, not a two-sided
> > "semaphore" guarding a section. As far as I can see, OP does not talk
> > about limiting the number of concurrent tasks (that translates to
> > limiting the resources used at a given time).
> >
> > -Aleksey.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/f1e688f0/attachment.html>

From oleksandr.otenko at oracle.com  Wed Feb  4 12:04:57 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Feb 2015 17:04:57 +0000
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 121,
 Issue 8
In-Reply-To: <CAO-wXwLUDcnQNVY9PAqygtsBKTpkWO3iMNeSyH76gRGdnYadoA@mail.gmail.com>
References: <CAO-wXwLUDcnQNVY9PAqygtsBKTpkWO3iMNeSyH76gRGdnYadoA@mail.gmail.com>
Message-ID: <54D25139.4000804@oracle.com>

On 04/02/2015 15:53, Valentin Kovalenko wrote:
> >>is the purpose of rate limiter to control contention on the
> executor thread pool /task queue/?
> The purpose of fixed rate executor is exactly the following: to fire 
> actions at the specified rate (not with higher rate, not with lower rate).
>
> >>when the limit is reached, the requests.....ermmm.... wait somewhere 
> in a
> queue?
> When the limit is reached, executor becomes idle till the start of 
> next period.
> Could you explain what do you mean by "requests?" I don't understand 
> because there are no requests, there is only executor that fires 
> actions (calls action.run()) and ensures that at each period not more 
> that RATE actions were completed.

ok, actions then.

You need to explain the meaning of "action". Because I expect the 
actions last for some time, do you count the action for the duration of 
the action, or you only count the start of action. If you count the 
action for the whole duration of the actions, then there is no meaning 
in "per second", because you really are looking at the number of actions 
"in flight". If you only count the starts of actions, then depending on 
the granularity an the action duration you will get some spread of the 
number of actions really "in flight". I am wondering about the use case 
for this second interpretation, if that's what is meant.

Alex


>
>
>     Date: Wed, 04 Feb 2015 12:55:53 +0000
>     From: Oleksandr Otenko <oleksandr.otenko at oracle.com
>     <mailto:oleksandr.otenko at oracle.com>>
>     To: Aleksey Shipilev <aleksey.shipilev at oracle.com
>     <mailto:aleksey.shipilev at oracle.com>>,
>     concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     Subject: Re: [concurrency-interest] Fixed Rate Executor Service
>     Message-ID: <54D216D9.9000907 at oracle.com
>     <mailto:54D216D9.9000907 at oracle.com>>
>     Content-Type: text/plain; charset="windows-1252"; Format="flowed"
>
>     Yes, so my question then is what is the use-case for rate-limiter, the
>     limiter of ingress of requests into the pool. Also, I suppose that
>     when
>     the limit is reached, the requests.....ermmm.... wait somewhere in a
>     queue? So is the purpose of rate limiter to control contention on the
>     executor thread pool /task queue/?
>
>
>     Alex
>
>
>     On 04/02/2015 12:16, Aleksey Shipilev wrote:
>     > Um... Because that's a one-sided rate limiter, not a two-sided
>     > "semaphore" guarding a section. As far as I can see, OP does not
>     talk
>     > about limiting the number of concurrent tasks (that translates to
>     > limiting the resources used at a given time).
>     >
>     > -Aleksey.
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/48b58281/attachment.html>

From valentin.male.kovalenko at gmail.com  Wed Feb  4 12:23:26 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Wed, 4 Feb 2015 21:23:26 +0400
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 121,
 Issue 8
In-Reply-To: <54D25139.4000804@oracle.com>
References: <CAO-wXwLUDcnQNVY9PAqygtsBKTpkWO3iMNeSyH76gRGdnYadoA@mail.gmail.com>
	<54D25139.4000804@oracle.com>
Message-ID: <CAO-wXwLLA2DyXt1Xsc1KX=6Hqw8xDm=twJOKpTD3Z6MLX4LbwQ@mail.gmail.com>

>>the actions last for some time
yes

>>do you count the action for the duration of the action, or you only count
the start of action
My bad. FixedRateExecutor must start (fire) RATE actions per period and
must ensure that all actions started during a period were completed during
the same period. If any of these requirements are violated, it must precess
the situation by using FailedRatePolicy. Does it make sense for you?

On Wed, Feb 4, 2015 at 8:04 PM, Oleksandr Otenko <
oleksandr.otenko at oracle.com> wrote:

>  On 04/02/2015 15:53, Valentin Kovalenko wrote:
>
>  >>is the purpose of rate limiter to control contention on the
> executor thread pool /task queue/?
>  The purpose of fixed rate executor is exactly the following: to fire
> actions at the specified rate (not with higher rate, not with lower rate).
>
>  >>when the limit is reached, the requests.....ermmm.... wait somewhere
> in a
> queue?
>  When the limit is reached, executor becomes idle till the start of next
> period.
> Could you explain what do you mean by "requests?" I don't understand
> because there are no requests, there is only executor that fires actions
> (calls action.run()) and ensures that at each period not more that RATE
> actions were completed.
>
>
> ok, actions then.
>
> You need to explain the meaning of "action". Because I expect the actions
> last for some time, do you count the action for the duration of the action,
> or you only count the start of action. If you count the action for the
> whole duration of the actions, then there is no meaning in "per second",
> because you really are looking at the number of actions "in flight". If you
> only count the starts of actions, then depending on the granularity an the
> action duration you will get some spread of the number of actions really
> "in flight". I am wondering about the use case for this second
> interpretation, if that's what is meant.
>
> Alex
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/c0341a0a/attachment.html>

From oleksandr.otenko at oracle.com  Wed Feb  4 13:28:28 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Wed, 04 Feb 2015 18:28:28 +0000
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 121,
 Issue 8
In-Reply-To: <CAO-wXwLLA2DyXt1Xsc1KX=6Hqw8xDm=twJOKpTD3Z6MLX4LbwQ@mail.gmail.com>
References: <CAO-wXwLUDcnQNVY9PAqygtsBKTpkWO3iMNeSyH76gRGdnYadoA@mail.gmail.com>	<54D25139.4000804@oracle.com>
	<CAO-wXwLLA2DyXt1Xsc1KX=6Hqw8xDm=twJOKpTD3Z6MLX4LbwQ@mail.gmail.com>
Message-ID: <54D264CC.9030705@oracle.com>

It seems most of this is covered by a plain Semaphore: if the next 
permit is not available, the rate has failed.

Alex

On 04/02/2015 17:23, Valentin Kovalenko wrote:
> >>the actions last for some time
> yes
>
> >>do you count the action for the duration of the action, or you only 
> count the start of action
> My bad. FixedRateExecutor must start (fire) RATE actions per period 
> and must ensure that all actions started during a period were 
> completed during the same period. If any of these requirements are 
> violated, it must precess the situation by using FailedRatePolicy. 
> Does it make sense for you?
>
> On Wed, Feb 4, 2015 at 8:04 PM, Oleksandr Otenko 
> <oleksandr.otenko at oracle.com <mailto:oleksandr.otenko at oracle.com>> wrote:
>
>     On 04/02/2015 15:53, Valentin Kovalenko wrote:
>>     >>is the purpose of rate limiter to control contention on the
>>     executor thread pool /task queue/?
>>     The purpose of fixed rate executor is exactly the following: to
>>     fire actions at the specified rate (not with higher rate, not
>>     with lower rate).
>>
>>     >>when the limit is reached, the requests.....ermmm.... wait
>>     somewhere in a
>>     queue?
>>     When the limit is reached, executor becomes idle till the start
>>     of next period.
>>     Could you explain what do you mean by "requests?" I don't
>>     understand because there are no requests, there is only executor
>>     that fires actions (calls action.run()) and ensures that at each
>>     period not more that RATE actions were completed.
>
>     ok, actions then.
>
>     You need to explain the meaning of "action". Because I expect the
>     actions last for some time, do you count the action for the
>     duration of the action, or you only count the start of action. If
>     you count the action for the whole duration of the actions, then
>     there is no meaning in "per second", because you really are
>     looking at the number of actions "in flight". If you only count
>     the starts of actions, then depending on the granularity an the
>     action duration you will get some spread of the number of actions
>     really "in flight". I am wondering about the use case for this
>     second interpretation, if that's what is meant.
>
>     Alex
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/09ae13c7/attachment.html>

From davidcholmes at aapt.net.au  Wed Feb  4 15:39:51 2015
From: davidcholmes at aapt.net.au (David Holmes)
Date: Thu, 5 Feb 2015 06:39:51 +1000
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <54D22642.5040806@gmail.com>
Message-ID: <NFBBKALFDCPFIDBNKAPCGEEHKNAA.davidcholmes@aapt.net.au>

Peter,

I don't see how this applies the RATE in the way Valentin wants. 1000 per second gives an average "rate" of 1ms, but that isn't way Valentin described the requirements. Really every UNIT time units you want a task that tries to submit RATE actions within UNIT time as quickly as possible. You submit to a nicely tuned executor with the "right" number of threads and suitable queue. But then you still have the problem of detecting that not all actions completed within UNIT time. And if they didn't then for the next UNIT you have additional interference on the submission and execution of the next RATE tasks (even if you cancel the non-completed ones from the previous "period".

Cheers,
David
  -----Original Message-----
  From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter Levart
  Sent: Thursday, 5 February 2015 12:02 AM
  To: Valentin Kovalenko; concurrency-interest
  Subject: Re: [concurrency-interest] Fixed Rate Executor Service


  On 02/04/2015 02:58 PM, Valentin Kovalenko wrote:

At first look it seems like a good idea! :)

On Wed, Feb 4, 2015 at 3:43 PM, Peter Levart <peter.levart at gmail.com> wrote:

 What about the following strategy:

Have a submission thread submit tasks at a fixed rate (your desired rate)
to a ThreadPoolExecutor with some limit on max. number of threads (using
RateLimiter if you like or some other means).
Let this ThreadPoolExecutor have a SynchonousQueue.
When the Executor starts rejecting executions, it means your rate can't be
satisfied with given max. number of threads.

Regards, Peter



  Here's also some meat:


public class FixedRateExecutor {

    final ThreadPoolExecutor workerExec;
    final ScheduledExecutorService schedExec;

    public FixedRateExecutor(
        int corePoolSize, int maximumPoolSize,
        long keepAliveTime, TimeUnit unit) {

        workerExec = new ThreadPoolExecutor(
            corePoolSize, maximumPoolSize,
            keepAliveTime, unit,
            new SynchronousQueue<>()
        );
        schedExec = Executors.newScheduledThreadPool(1);
    }

    public ScheduledFuture<?> scheduleAtFixedRate(
        Runnable command,
        long initialDelay, long period, TimeUnit unit,
        FailedRatePolicy failedRatePolicy) {

        return schedExec.scheduleAtFixedRate(() -> {
                try {
                    workerExec.execute(command);
                } catch (RejectedExecutionException e) {
                    failedRatePolicy.failedRate(e);
                }
            },
            initialDelay, period, unit
        );
    }

    public interface FailedRatePolicy {
        FailedRatePolicy IGNORE = e -> {};
        FailedRatePolicy THROW = e -> { throw e; };

        void failedRate(RejectedExecutionException e);
    }
}

Regards, Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150205/d32e7327/attachment-0001.html>

From yu.lin.86 at gmail.com  Wed Feb  4 22:48:04 2015
From: yu.lin.86 at gmail.com (Yu Lin)
Date: Wed, 4 Feb 2015 21:48:04 -0600
Subject: [concurrency-interest] Potential projects/code that should use Rx
Message-ID: <CAAL-3PYXy=0ojUzmGbtY+MsqjT5dUYGqpea=Z6nYbN+T5kPqCA@mail.gmail.com>

Hello,

I saw that Rx will be included in Java9:
http://cs.oswego.edu/pipermail/concurrency-interest/2015-January/013641.html

I'm starting to learn when and how to use Rx. Some tutorials say that the
advantage of Rx (compared with CompletableFuture) is that it can emit
multiple values asynchronously  instead of just one value, plus the
declarative operators. But the tutorials only show toy examples.

I'm still wondering when should we definitely use Rx. Is there any real
code (not toy examples) shows the advantage of Rx? And do you guys know any
projects could potentially (or should) use Rx but they haven't done so yet?

Thanks,
Yu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150204/fa137524/attachment.html>

From richard.warburton at gmail.com  Thu Feb  5 03:01:47 2015
From: richard.warburton at gmail.com (Richard Warburton)
Date: Thu, 5 Feb 2015 08:01:47 +0000
Subject: [concurrency-interest] Split of methods between CompletableFuture
	and Future
Message-ID: <CAMaYbv+O4dTqGEMLu=aueMW1zvNfOa=O3qwViVkrsFoe4weL3w@mail.gmail.com>

Hi,

The join() and getNow() methods on CompletableFuture, but not on Future,
are operations that are related to extracting a value, rather than
performing operations on it. Is there any reason why they were never added
to the Future interface?

I'm less interested in join(), but getNow() seems like it would have some
value and it looks like an default implementation could be provided for its
functionality.

regards,

  Richard Warburton

  http://insightfullogic.com
  @RichardWarburto <http://twitter.com/richardwarburto>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150205/f8044c25/attachment.html>

From peter.levart at gmail.com  Thu Feb  5 04:46:28 2015
From: peter.levart at gmail.com (Peter Levart)
Date: Thu, 05 Feb 2015 10:46:28 +0100
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <NFBBKALFDCPFIDBNKAPCGEEHKNAA.davidcholmes@aapt.net.au>
References: <NFBBKALFDCPFIDBNKAPCGEEHKNAA.davidcholmes@aapt.net.au>
Message-ID: <54D33BF4.8020006@gmail.com>

On 02/04/2015 09:39 PM, David Holmes wrote:
> Peter,
>
> I don't see how this applies the RATE in the way Valentin wants. 1000 per second gives an average "rate" of 1ms, but that isn't way Valentin described the requirements. Really every UNIT time units you want a task that tries to submit RATE actions within UNIT time as quickly as possible. You submit to a nicely tuned executor with the "right" number of threads and suitable queue. But then you still have the problem of detecting that not all actions completed within UNIT time. And if they didn't then for the next UNIT you have additional interference on the submission and execution of the next RATE tasks (even if you cancel the non-completed ones from the previous "period".

Valentins's requirements and explanation appeared to me as unrealistic. 
As I understand, he explained the functionality of some kind of "bursty" 
executor, where at the start of each UNIT (period), the execution queue 
is filled with RATE tasks and at the end of period, the queue is checked 
whether it is empty or not (what to do with tasks, that are still 
executing is not defined).

So I thought that he actually wanted something else and he just 
described it in a way he thought it might be implemented.

Valentins, do you really want a "bursty" executor?

Regards, peter

>
> Cheers,
> David
>    -----Original Message-----
>    From: concurrency-interest-bounces at cs.oswego.edu [mailto:concurrency-interest-bounces at cs.oswego.edu]On Behalf Of Peter Levart
>    Sent: Thursday, 5 February 2015 12:02 AM
>    To: Valentin Kovalenko; concurrency-interest
>    Subject: Re: [concurrency-interest] Fixed Rate Executor Service
>
>
>    On 02/04/2015 02:58 PM, Valentin Kovalenko wrote:
>
> At first look it seems like a good idea! :)
>
> On Wed, Feb 4, 2015 at 3:43 PM, Peter Levart <peter.levart at gmail.com> wrote:
>
>   What about the following strategy:
>
> Have a submission thread submit tasks at a fixed rate (your desired rate)
> to a ThreadPoolExecutor with some limit on max. number of threads (using
> RateLimiter if you like or some other means).
> Let this ThreadPoolExecutor have a SynchonousQueue.
> When the Executor starts rejecting executions, it means your rate can't be
> satisfied with given max. number of threads.
>
> Regards, Peter
>
>
>
>    Here's also some meat:
>
>
> public class FixedRateExecutor {
>
>      final ThreadPoolExecutor workerExec;
>      final ScheduledExecutorService schedExec;
>
>      public FixedRateExecutor(
>          int corePoolSize, int maximumPoolSize,
>          long keepAliveTime, TimeUnit unit) {
>
>          workerExec = new ThreadPoolExecutor(
>              corePoolSize, maximumPoolSize,
>              keepAliveTime, unit,
>              new SynchronousQueue<>()
>          );
>          schedExec = Executors.newScheduledThreadPool(1);
>      }
>
>      public ScheduledFuture<?> scheduleAtFixedRate(
>          Runnable command,
>          long initialDelay, long period, TimeUnit unit,
>          FailedRatePolicy failedRatePolicy) {
>
>          return schedExec.scheduleAtFixedRate(() -> {
>                  try {
>                      workerExec.execute(command);
>                  } catch (RejectedExecutionException e) {
>                      failedRatePolicy.failedRate(e);
>                  }
>              },
>              initialDelay, period, unit
>          );
>      }
>
>      public interface FailedRatePolicy {
>          FailedRatePolicy IGNORE = e -> {};
>          FailedRatePolicy THROW = e -> { throw e; };
>
>          void failedRate(RejectedExecutionException e);
>      }
> }
>
> Regards, Peter
>
>


From valentin.male.kovalenko at gmail.com  Thu Feb  5 07:33:55 2015
From: valentin.male.kovalenko at gmail.com (Valentin Kovalenko)
Date: Thu, 5 Feb 2015 16:33:55 +0400
Subject: [concurrency-interest] Fixed Rate Executor Service
Message-ID: <CAO-wXw+88AyWk4nc4d0X2dTHr5kRZE-hERe84V6XSv-x7+JamQ@mail.gmail.com>

>>at the end of period, the queue is checked whether it is empty or not
(what to do with tasks, that are still executing is not defined)
>>...if they didn't then for the next UNIT you have additional interference
on the submission and execution of the next RATE tasks
Executor checks if actions are still executing, because it doesn't want
tasks to be finished in the period different from the period in which
actions where started. If actions aren't completed, executor uses
FailedRatePolicy

Now I'll try to present another wording of my thoughts. I need something
like
http://jmeter.apache.org/usermanual/component_reference.html#Constant_Throughput_Timer,
but if throughput can't be sustained I want to be notified. This is needed
for tests in which jmeter is inconvenient/hard/impossible to use.
Actually it would be great to have such a throttling mechanism in the JMH
(by Alexey Shipilev), so that we could use JMH not only to "measure time"
but also in load tests.  Alexey, what do you think about this?:)

On Thu, Feb 5, 2015 at 12:46 PM, Peter Levart <peter.levart at gmail.com>
wrote:

> On 02/04/2015 09:39 PM, David Holmes wrote:
>
>> Peter,
>>
>> I don't see how this applies the RATE in the way Valentin wants. 1000 per
>> second gives an average "rate" of 1ms, but that isn't way Valentin
>> described the requirements. Really every UNIT time units you want a task
>> that tries to submit RATE actions within UNIT time as quickly as possible.
>> You submit to a nicely tuned executor with the "right" number of threads
>> and suitable queue. But then you still have the problem of detecting that
>> not all actions completed within UNIT time. And if they didn't then for the
>> next UNIT you have additional interference on the submission and execution
>> of the next RATE tasks (even if you cancel the non-completed ones from the
>> previous "period".
>>
>
> Valentins's requirements and explanation appeared to me as unrealistic. As
> I understand, he explained the functionality of some kind of "bursty"
> executor, where at the start of each UNIT (period), the execution queue is
> filled with RATE tasks and at the end of period, the queue is checked
> whether it is empty or not (what to do with tasks, that are still executing
> is not defined).
>
> So I thought that he actually wanted something else and he just described
> it in a way he thought it might be implemented.
>
> Valentins, do you really want a "bursty" executor?
>
> Regards, peter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150205/9881dc21/attachment.html>

From aleksey.shipilev at oracle.com  Thu Feb  5 07:57:59 2015
From: aleksey.shipilev at oracle.com (Aleksey Shipilev)
Date: Thu, 05 Feb 2015 15:57:59 +0300
Subject: [concurrency-interest] Fixed Rate Executor Service
In-Reply-To: <CAO-wXw+88AyWk4nc4d0X2dTHr5kRZE-hERe84V6XSv-x7+JamQ@mail.gmail.com>
References: <CAO-wXw+88AyWk4nc4d0X2dTHr5kRZE-hERe84V6XSv-x7+JamQ@mail.gmail.com>
Message-ID: <54D368D7.2070100@oracle.com>

On 05.02.2015 15:33, Valentin Kovalenko wrote:
> Actually it would be great to have such a throttling mechanism in the
> JMH (by Alexey Shipilev), so that we could use JMH not only to "measure
> time" but also in load tests.  Alexey, what do you think about this?:)

We would gladly work with interested contributors who wish to implement
fixed-load generators in JMH. We have some experiences building such the
generators in SPECjbb2013 (it looked a bit like a token bucket limiter I
already outlined here).

-Aleksey.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150205/a1add5c0/attachment.bin>

From godmar at gmail.com  Thu Feb  5 11:02:43 2015
From: godmar at gmail.com (Godmar Back)
Date: Thu, 5 Feb 2015 11:02:43 -0500
Subject: [concurrency-interest] Q. Practical workloads for which work
	stealing outperforms work sharing?
Message-ID: <CAB4+JY+=io7g8Bi2ofNaDzrhN-0C=JwLdS05SPac0JxhK_3JiQ@mail.gmail.com>

Hi,

what are practical workloads/example parallel implementations for which
work stealing exhibits the highest performance advantages when compared to
work sharing?

 - Godmar
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150205/76e192e7/attachment.html>

From smaldini at pivotal.io  Mon Feb  9 06:30:00 2015
From: smaldini at pivotal.io (Stephane Maldini)
Date: Mon, 9 Feb 2015 11:30:00 +0000
Subject: [concurrency-interest] Q. Practical workloads for which work
 stealing outperforms work sharing?
In-Reply-To: <CAB4+JY+=io7g8Bi2ofNaDzrhN-0C=JwLdS05SPac0JxhK_3JiQ@mail.gmail.com>
References: <CAB4+JY+=io7g8Bi2ofNaDzrhN-0C=JwLdS05SPac0JxhK_3JiQ@mail.gmail.com>
Message-ID: <CAFm0joGn_tG6eqmhfR=ZQVouQki=a6V0bsozes_9p0++3-v3OQ@mail.gmail.com>

Related/Unrelated:

Speaking of Streams (as in Reactor Streams/ Reactive Streams or even Rx
Serializer) , my experience is that work stealing work greats for
relatively 'low latency' merge operations where the consumer might submit
some IO. In the case of Reactive Streams, its also useful to serialize
requested demand upstream from N downstream threads.

If this takes too long, the stealing 'queue' might expand quickly and never
give a chance for this thread to return, basically transforming your flow
into a Shared workload where the first thread reaching out to the end will
just dequeue further work.
If that is the case I'd envision switching back to shared workload, which
often happens where IO work is related to database write for instance. I
find the work steal less manageable as you might want to tune the pool.

Hope it helps the discussion, its a general concern so I thought I could
give my 2c here.

On Thu, Feb 5, 2015 at 4:02 PM, Godmar Back <godmar at gmail.com> wrote:

> Hi,
>
> what are practical workloads/example parallel implementations for which
> work stealing exhibits the highest performance advantages when compared to
> work sharing?
>
>  - Godmar
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Stephane Maldini | Solutions Architect, CSO EMEA | London | Pivotal
W: pivotal.io | T: @smaldini <https://twitter.com/smaldini>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150209/7ba85c58/attachment.html>

From godmar at gmail.com  Mon Feb  9 10:20:52 2015
From: godmar at gmail.com (Godmar Back)
Date: Mon, 9 Feb 2015 10:20:52 -0500
Subject: [concurrency-interest] Q. Practical workloads for which work
 stealing outperforms work sharing?
In-Reply-To: <CAFm0joGn_tG6eqmhfR=ZQVouQki=a6V0bsozes_9p0++3-v3OQ@mail.gmail.com>
References: <CAB4+JY+=io7g8Bi2ofNaDzrhN-0C=JwLdS05SPac0JxhK_3JiQ@mail.gmail.com>
	<CAFm0joGn_tG6eqmhfR=ZQVouQki=a6V0bsozes_9p0++3-v3OQ@mail.gmail.com>
Message-ID: <CAB4+JYKGfygV+z6nxVHKcnYcLJCbji9s39+5uCT4e5-5N6vnoA@mail.gmail.com>

Thanks for your reply.  I wasn't necessarily thinking of workloads where
some tasks might block due to I/O - though as FJ frameworks are used for
those, those are of course important. I'm thinking for now of purely CPU
bound tasks.

My (admittedly somewhat naive) understanding is that work-stealing can beat
work-sharing for two reasons:

a) by finding a shorter schedule overall. Here, a work-sharing scheduler
would make a "wrong" assignment that later means the worker is idle and
can't help.

b) by working in a decentralized fashion, in a way that requires fewer -
possibly contended -thread-to-thread interactions. My reading of Blumofe's
paper is that that what they mean by 'thread-to-thread communication'. In
this case, the performance gain would be directly related to the cost of
these thread-to-thread synchronizations, and would depend on the
granularity of the workload. Workloads of fine granularity, with many small
tasks, would - conceivably - create high contention on the shared data
structures of a work-sharing scheduler, whereas the common case
synchronization overhead in the work-stealing implementation (pulling off
the bottom in Blumofe's terminology) would be small as it does not require
atomic operations (implemented using THE, for instance.)

My question is what are applications in which a problem can be divided into
tasks of a level of granularity such that this effect of a work-stealing
scheduler is most pronounced. (After all, for coarse-grained tasks the
drawback of having a shared lock (or whichever synchronization construct is
used) would be less.

 - Godmar
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150209/0324d191/attachment.html>

From andrew_nuss at yahoo.com  Sun Feb 22 04:59:58 2015
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Sun, 22 Feb 2015 09:59:58 +0000 (UTC)
Subject: [concurrency-interest] using volatile to create immutable objects
Message-ID: <20897433.6543450.1424599198799.JavaMail.yahoo@mail.yahoo.com>

Lets say I have a class that maps to an int[] by indirection to illustrate my question.? With getters and setters.

class MyIntArrayRef {???? private int[]??? ar;
}
Lets assume that an instance of this object is being used by various threads with synchronized(...), taking all necessary precautions.
Now, lets say one thread knows the the current "ar" member is *not* going to have either all, or some subrange of its data changed, but that the reference itself to the MyIntArrayRef "ar" member will be changed.? So it decides, using synchronized properly on the MyIntArrayRef that is has to created an instance of the following similar class that satisfies the getters interface of MyIntArrayRef:
class MyVolatileIntArrayRef {????? private volatile int[]?? ar;???? // syntactically, final would compile here, but not work properly?!

????? MyVolatileIntArrayRef (int[] ar) {
????????? this.ar = ar;????? }
}
The ar member passed to its constructor is from the current "ar" of MyIntArrayRef.? Assuming that this object has no setters, neither for "ar" itself, nor any of its data, is it threadsafe without any synchronized methods?? Especially to pass back to threads that have been working with the MyIntArrayRef instance on which this "clone" was based?

My guess is yes.? This "ar" member is volatile, so the JMM says to use a memory barrier when using this class's getters to get elements of the array.? Note that I do not think this would work if the member was declared as just "final", even though for this class, "ar" never changes.? The reason is that the underlying array memory may have already been seen by several cores.
What scares me though is that I've read that on x86 architectures, the volatile read has zero performance cost in some cases, though I've never understood that.? It seems though that you can't have zero performance cost for volatile reads and still have the above use of volatile to create an immutable read only object from an underlying array that has already been seen by several threads.? Can someone explain if the above coding idea works, and if so, how that fits with the volatile implementation on x86?

Andy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150222/c22aec9d/attachment.html>

From andrew_nuss at yahoo.com  Sun Feb 22 10:09:30 2015
From: andrew_nuss at yahoo.com (Andy Nuss)
Date: Sun, 22 Feb 2015 15:09:30 +0000 (UTC)
Subject: [concurrency-interest] are my messages bouncing?
Message-ID: <1915088169.6634093.1424617770157.JavaMail.yahoo@mail.yahoo.com>

I sent a question on use of volatile last night and I don't see it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150222/f6b4fb24/attachment.html>

From dl at cs.oswego.edu  Sun Feb 22 11:05:04 2015
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 22 Feb 2015 11:05:04 -0500
Subject: [concurrency-interest] Fwd: easiest way to force a write membar in
	jdk7 and 8
In-Reply-To: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>
References: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54E9FE30.9000105@cs.oswego.edu>


Forwarding for Andy..

-------- Forwarded Message --------
Subject: 	easiest way to force a write membar in jdk7 and 8
Date: 	Sun, 22 Feb 2015 15:52:41 +0000 (UTC)
From: 	Andy Nuss <andrew_nuss at yahoo.com>
Reply-To: 	Andy Nuss <andrew_nuss at yahoo.com>
To: 	Hotspot Compiler <hotspot-compiler-dev at openjdk.java.net>



Hi,

I tried posting a related question on the concurrency-interest mailing list but
for some reason my messages are bouncing there but not here.

Basically, the idea is that some thread has been working with an int[] and
filling it with values.  From some range such as [0,8) of the array, that thread
is sure never again to change those values.  Now it wishes to publish the int[]
range in a threadsafe way in some new wrapper object.

It cannot construct simply this (I believe), especially if somehow another
thread has seen the "ar":

class IntArray {
      final int[] ar;
      final int from;
      final int to;
      IntArray (int[] ar, int from, int to) {
          this.ar = ar; this.from = from; this.to = to;
      }
}

Would it work to use this:

class IntArrayVolatile {
      volatile int[] ar;
      final int from;
      final int to;
      IntArrayVolatile (int[] ar, int from, int to) {
          this.ar = ar; this.from = from; this.to = to;
      }
      IntArray publish () {
          return new IntArray(ar, from, to);
      }
}

and then in the thread do this:
     int[] ar = new int[100];
     ... fill values from [0, 8) never again to change
     IntArray publishar = new IntArrayVolatile(ar, from, to).publish();
     ... give publishar to other threads
     ... keep filling values from position 8 and higher in "ar" and publishing
further ranges in a similar way

Obviously, this is alot about the internal workings of hotspot with the membars
for volatile variables.

Andy



From oleksandr.otenko at oracle.com  Mon Feb 23 15:26:55 2015
From: oleksandr.otenko at oracle.com (Oleksandr Otenko)
Date: Mon, 23 Feb 2015 20:26:55 +0000
Subject: [concurrency-interest] Fwd: easiest way to force a write membar
 in jdk7 and 8
In-Reply-To: <54E9FE30.9000105@cs.oswego.edu>
References: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>
	<54E9FE30.9000105@cs.oswego.edu>
Message-ID: <54EB8D0F.3000903@oracle.com>

Can someone explain what becomes a problem when some other thread "sees 
the ar", when clone is created with finals?

Alex

On 22/02/2015 16:05, Doug Lea wrote:
>
> Forwarding for Andy..
>
> -------- Forwarded Message --------
> Subject:     easiest way to force a write membar in jdk7 and 8
> Date:     Sun, 22 Feb 2015 15:52:41 +0000 (UTC)
> From:     Andy Nuss <andrew_nuss at yahoo.com>
> Reply-To:     Andy Nuss <andrew_nuss at yahoo.com>
> To:     Hotspot Compiler <hotspot-compiler-dev at openjdk.java.net>
>
>
>
> Hi,
>
> I tried posting a related question on the concurrency-interest mailing 
> list but
> for some reason my messages are bouncing there but not here.
>
> Basically, the idea is that some thread has been working with an int[] 
> and
> filling it with values.  From some range such as [0,8) of the array, 
> that thread
> is sure never again to change those values.  Now it wishes to publish 
> the int[]
> range in a threadsafe way in some new wrapper object.
>
> It cannot construct simply this (I believe), especially if somehow 
> another
> thread has seen the "ar":
>
> class IntArray {
>      final int[] ar;
>      final int from;
>      final int to;
>      IntArray (int[] ar, int from, int to) {
>          this.ar = ar; this.from = from; this.to = to;
>      }
> }
>
> Would it work to use this:
>
> class IntArrayVolatile {
>      volatile int[] ar;
>      final int from;
>      final int to;
>      IntArrayVolatile (int[] ar, int from, int to) {
>          this.ar = ar; this.from = from; this.to = to;
>      }
>      IntArray publish () {
>          return new IntArray(ar, from, to);
>      }
> }
>
> and then in the thread do this:
>     int[] ar = new int[100];
>     ... fill values from [0, 8) never again to change
>     IntArray publishar = new IntArrayVolatile(ar, from, to).publish();
>     ... give publishar to other threads
>     ... keep filling values from position 8 and higher in "ar" and 
> publishing
> further ranges in a similar way
>
> Obviously, this is alot about the internal workings of hotspot with 
> the membars
> for volatile variables.
>
> Andy
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From sitnikov.vladimir at gmail.com  Mon Feb 23 16:22:59 2015
From: sitnikov.vladimir at gmail.com (Vladimir Sitnikov)
Date: Tue, 24 Feb 2015 01:22:59 +0400
Subject: [concurrency-interest] Fwd: easiest way to force a write membar
 in jdk7 and 8
In-Reply-To: <54EB8D0F.3000903@oracle.com>
References: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>
	<54E9FE30.9000105@cs.oswego.edu> <54EB8D0F.3000903@oracle.com>
Message-ID: <CAB=Je-H-Tver3YSTARp5xpU59473a=PFuerKPyGYbCdxthkMxw@mail.gmail.com>

> Now it wishes to publish the int[] range in a thread-safe way in some new
wrapper object.

JMM does not work like that. You can't create multiple "thread-safe
wrappers" that are safe for use across data races.
Here's theoretical minimum:
1) volatile field does not result in a "safe publishing wrapper". For
instance, you could get 0 if publish new AtomicInteger(42) via data race.
2) "final wrappers" do not work if you publish the base object (not the
wrapper) multiple times.
You do not have a second chance to publish an "a bit updated object" via
"final wrapper".

See http://shipilev.net/blog/2014/jmm-pragmatics/#_part_v_finals and
http://www.slideshare.net/VladimirSitnikv/final-field-semantics (slides 77,
88, etc)

> give publishar to other threads

Can you clarify if any of your consumer threads need to have at least two
views of the same base "ar"?
In other words: do you always publish object to a fresh thread?

If a thread needs to consume "ar" at least twice, you'd better have some
reasonable happens-before edge.

Vladimir
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150224/a097a0ee/attachment.html>

From tmjee1 at gmail.com  Fri Feb 27 01:53:48 2015
From: tmjee1 at gmail.com (tm jee)
Date: Fri, 27 Feb 2015 17:53:48 +1100
Subject: [concurrency-interest] Fwd: easiest way to force a write membar
 in jdk7 and 8
In-Reply-To: <CAB=Je-H-Tver3YSTARp5xpU59473a=PFuerKPyGYbCdxthkMxw@mail.gmail.com>
References: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>
	<54E9FE30.9000105@cs.oswego.edu> <54EB8D0F.3000903@oracle.com>
	<CAB=Je-H-Tver3YSTARp5xpU59473a=PFuerKPyGYbCdxthkMxw@mail.gmail.com>
Message-ID: <CAMaajQxchK-qkn1A05fW+e3dpbMk2P8ToOQdd4ui-wfeegVNJg@mail.gmail.com>

This should work, can someone confirm this.

class IntArray {

   final int[] iiAr;
   final int from, to;
   IntArrayVolatile(int[] iAr, int from, int to) {
       int[] temp = iAr;
       iiAr = System.arraycopy(....); // copy from temp to iiAr
        this.from = from;
       this.to=to;
   }
}

class IntArrayVolatile {

   volatile int[] w = ....

   // the same only one thread execute this
   public IntArray[] publish(...) {
       int[] _w = w;
       return new IntArrayVolatile(._w...);
   }

   // the same and only one thread execute this
   public void modify(....) {
       int[] _w = System.arraycopy(....); // copy of w
       // modify _w
       w = _w;
   }
}





On Tue, Feb 24, 2015 at 8:22 AM, Vladimir Sitnikov <
sitnikov.vladimir at gmail.com> wrote:

> > Now it wishes to publish the int[] range in a thread-safe way in some
> new wrapper object.
>
> JMM does not work like that. You can't create multiple "thread-safe
> wrappers" that are safe for use across data races.
> Here's theoretical minimum:
> 1) volatile field does not result in a "safe publishing wrapper". For
> instance, you could get 0 if publish new AtomicInteger(42) via data race.
> 2) "final wrappers" do not work if you publish the base object (not the
> wrapper) multiple times.
> You do not have a second chance to publish an "a bit updated object" via
> "final wrapper".
>
> See http://shipilev.net/blog/2014/jmm-pragmatics/#_part_v_finals and
> http://www.slideshare.net/VladimirSitnikv/final-field-semantics (slides
> 77, 88, etc)
>
> > give publishar to other threads
>
> Can you clarify if any of your consumer threads need to have at least two
> views of the same base "ar"?
> In other words: do you always publish object to a fresh thread?
>
> If a thread needs to consume "ar" at least twice, you'd better have some
> reasonable happens-before edge.
>
> Vladimir
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20150227/8318ca0d/attachment.html>

From aph at redhat.com  Fri Feb 27 04:48:12 2015
From: aph at redhat.com (Andrew Haley)
Date: Fri, 27 Feb 2015 09:48:12 +0000
Subject: [concurrency-interest] Fwd: easiest way to force a write membar
 in jdk7 and 8
In-Reply-To: <CAMaajQxchK-qkn1A05fW+e3dpbMk2P8ToOQdd4ui-wfeegVNJg@mail.gmail.com>
References: <1242690642.6766857.1424620361986.JavaMail.yahoo@mail.yahoo.com>	<54E9FE30.9000105@cs.oswego.edu>
	<54EB8D0F.3000903@oracle.com>	<CAB=Je-H-Tver3YSTARp5xpU59473a=PFuerKPyGYbCdxthkMxw@mail.gmail.com>
	<CAMaajQxchK-qkn1A05fW+e3dpbMk2P8ToOQdd4ui-wfeegVNJg@mail.gmail.com>
Message-ID: <54F03D5C.7070200@redhat.com>

On 27/02/15 06:53, tm jee wrote:
> This should work, can someone confirm this.

It's hard to understand exactly what your example is supposed
to do, but I see no happens-before edge between the writer
and the reader.

Andrew.


