From rl.stpuu at gmail.com  Tue May  2 08:30:19 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Tue, 2 May 2017 14:30:19 +0200
Subject: [concurrency-interest] CfP: LACompLing2017 Extended Deadline: * May
 10 (any time on Earth), 2017 *
Message-ID: <CACAe74jwwTNZ6hp2LzPtM=CqKs8GLEmi9nPDFEY42F2yTbnTNw@mail.gmail.com>

                         CALL FOR PAPERS

                          Workshop on
Logic and Algorithms in Computational Linguistics 2017 (LACompLing2017)
                   Stockholm, August 16-19, 2017

        http://staff.math.su.se/rloukanova/LACompLing17.html

     * Extended submission deadline for regular papers *
               ** May 10 (any time on Earth), 2017 **
================================================
                      Affiliated with the
26th Annual EACSL Conference on Computer Science Logic CSL'2017
                   Stockholm, 20--26 August 2017

                     Co-located with:
               Logic in Stockholm 2017
https://www.math-stockholm.se/en/konferenser-och-akti/logic-in-stockholm-2
=================================================

DESCRIPTION
==
Computational linguistics studies natural language in its various
manifestations from a computational point of view, both on the theoretical
level (modeling grammar modules dealing with natural language form and
meaning, and the relation between these two) and on the practical level
(developing applications for language and speech technology). Right from
the start in the 1950ties, there have been strong links with computer
science, logic, and many areas of mathematics - one can think of Chomsky's
contributions to the theory of formal languages and automata, or Lambek's
logical modeling of natural language syntax. The workshop assesses the
place of logic, mathematics, and computer science in present day
computational linguistics. It intends to be a forum for presenting new
results as well as work in progress.
--------------------------------

SCOPE
==
The workshop focuses mainly on logical approaches to computational
processing of natural language, and on the applicability of methods and
techniques from the study of artificial languages (programming/logic) in
computational linguistics. We invite participation and submissions from
other relevant approaches too, especially if they can inspire new work and
approaches.

The topics of LACompLing2017 include, but are not limited to:

- Computational theories of human language
- Computational syntax
- Computational semantics
- Computational syntax-semantics interface
- Interfaces between morphology, lexicon, syntax, semantics, speech, text,
pragmatics
- Computational grammar
- Logic and reasoning systems for linguistics
- Type theories for linguistics
- Models of computation and algorithms for linguistics
- Language processing
- Parsing algorithms
- Generation of language from semantic representations
- Large-scale grammars of natural languages
- Multilingual processing
- Data science in language processing
- Machine learning of language
- Interdisciplinary methods
- Integration of formal, computational, model theoretic, graphical,
diagrammatic, statistical, and other related methods
- Logic for information extraction or expression in written and spoken
language
- Language theories based on biological fundamentals of information and
languages
- Computational neuroscience of language

IMPORTANT DATES
==
Submission deadline for regular papers: ** May 10 (any time on Earth), 2017
**
Notification of paper acceptance: May 31, 2017
Abstracts of short presentations:  June 4, 2017
Notifications for short presentations: June 12, 2017
Deadline for final submissions: June 25, 2017
Workshop: August 16-19, 2017

SUBMISSION INSTRUCTIONS
==
- Regular papers: between 10-15 pages, including figures and references, by
using LaTeX, with article.sty:
\documentclass[a4paper,11pt]{article}

- Abstracts of short presentations: not more than 1 page, by using LaTeX,
with article.sty:
\documentclass[a4paper,11pt]{article}

- We invite original papers that are not submitted concurrently to another
conference or for publication elsewhere

- The submissions of proposed papers and abstracts of short presentations
have to be in pdf

- The camera-ready submissions require the pdf of the papers and their
LaTeX sources

The submissions are via the EasyChair management system of LACompLing2017:

https://easychair.org/conferences/?conf=lacompling2017

PUBLICATIONS
==
- The proceedings of LACompLing2017 will be published digitally by the DiVA
system of Stockholm University:
http://su.diva-portal.org

- Improved and extended versions of selected papers, which have been
presented at the workshop LACompLing2017, will be published by the Journal
of Logic, Language and Information, JoLLI, after the workshop.

FEATURED INVITED SPEAKERS
==
Robin Cooper, University of Gothenburg, Sweden
Ann Copestake, University of Cambridge, UK
Lars Hellan, Norwegian University of Science and Technology, Norway
Lucas Champollion, New York University, USA
Nikola Kompa, University of Osnabrück, Germany
Louise McNally, Universitat Pompeu Fabra, Spain
Joakim Nivre, Uppsala University, Sweden
Mila Vulchanova,  Norwegian University of Science and Technology, Norway
Markus Werning, Ruhr University Bochum, Germany
and more ...

ORGANIZERS
==
Krasimir Angelov, University of Gothenburg, Sweden
Valeria de Paiva, Nuance Communications, USA
Kristina Liefke, Ludwig-Maximilians-University Munich, Germany
Roussanka Loukanova, Stockholm University, Sweden (chair)
Michael Moortgat, Utrecht University, The Netherlands
Reinhard Muskens, Tilburg University, The Netherlands

CONTACT
==
Roussanka Loukanova (rloukanova at gmail.com)
Valeria de Paiva (valeria.depaiva at gmail.com)
--------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170502/402b0a5c/attachment.html>

From ablacktshirt at gmail.com  Mon May  8 10:22:19 2017
From: ablacktshirt at gmail.com (Yubin Ruan)
Date: Mon, 8 May 2017 22:22:19 +0800
Subject: [concurrency-interest] Make the double-checked lock idiom broken on
	x86
Message-ID: <20170508142216.GB3463@HP>

Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is
broken. Bill Pugh gave an example:

    // Broken multithreaded version
    // "Double-Checked Locking" idiom
    class Foo { 
      private Helper helper = null;
      public Helper getHelper() {
        if (helper == null) 
          synchronized(this) {
            if (helper == null) 
              helper = new Helper();
        }    
        return helper;
      }
      // other functions and members...
    }

His analysis is convincing, but the code he gave[2] work *well* on x86.
That is expected to break sometimes. But, running it from time to time,
I never see it break.

How to verify that the double-check lock idiom will break on x86?

---
Yubin

[1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
[2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java

From oleksandr.otenko at gmail.com  Mon May  8 04:55:53 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 8 May 2017 09:55:53 +0100
Subject: [concurrency-interest] Make the double-checked lock idiom
	broken on x86
In-Reply-To: <20170508142216.GB3463@HP>
References: <20170508142216.GB3463@HP>
Message-ID: <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com>

I’d start with using the same version and brand of the JVM Bill used at the time of writing the article, which was probably written over 15 years ago.

Alex

> On 8 May 2017, at 15:22, Yubin Ruan <ablacktshirt at gmail.com> wrote:
> 
> Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is
> broken. Bill Pugh gave an example:
> 
>    // Broken multithreaded version
>    // "Double-Checked Locking" idiom
>    class Foo { 
>      private Helper helper = null;
>      public Helper getHelper() {
>        if (helper == null) 
>          synchronized(this) {
>            if (helper == null) 
>              helper = new Helper();
>        }    
>        return helper;
>      }
>      // other functions and members...
>    }
> 
> His analysis is convincing, but the code he gave[2] work *well* on x86.
> That is expected to break sometimes. But, running it from time to time,
> I never see it break.
> 
> How to verify that the double-check lock idiom will break on x86?
> 
> ---
> Yubin
> 
> [1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
> [2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From radhakrishnan.mohan at gmail.com  Mon May  8 05:07:55 2017
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 8 May 2017 14:37:55 +0530
Subject: [concurrency-interest] Make the double-checked lock idiom
 broken on x86
In-Reply-To: <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com>
References: <20170508142216.GB3463@HP>
 <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com>
Message-ID: <CAOoXFP9Qrxthx7PLLmQcFeM9XgErCCRoUWRHDYat-uGn5wYmzw@mail.gmail.com>

Hi,

How about a JCStress test ?

Something like
http://hg.openjdk.java.net/code-tools/jcstress/file/9cbe23132d16/jcstress-samples/src/main/java/org/openjdk/jcstress/samples/JMMSample_03_Coherence.java


Mohan

On 8 May 2017 at 14:25, Alex Otenko <oleksandr.otenko at gmail.com> wrote:

> I’d start with using the same version and brand of the JVM Bill used at
> the time of writing the article, which was probably written over 15 years
> ago.
>
> Alex
>
> > On 8 May 2017, at 15:22, Yubin Ruan <ablacktshirt at gmail.com> wrote:
> >
> > Hi, from Bill Pugh's website[1] I read that the double-checked lock
> idiom is
> > broken. Bill Pugh gave an example:
> >
> >    // Broken multithreaded version
> >    // "Double-Checked Locking" idiom
> >    class Foo {
> >      private Helper helper = null;
> >      public Helper getHelper() {
> >        if (helper == null)
> >          synchronized(this) {
> >            if (helper == null)
> >              helper = new Helper();
> >        }
> >        return helper;
> >      }
> >      // other functions and members...
> >    }
> >
> > His analysis is convincing, but the code he gave[2] work *well* on x86.
> > That is expected to break sometimes. But, running it from time to time,
> > I never see it break.
> >
> > How to verify that the double-check lock idiom will break on x86?
> >
> > ---
> > Yubin
> >
> > [1]: https://www.cs.umd.edu/~pugh/java/memoryModel/
> DoubleCheckedLocking.html
> > [2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170508/b9e0f690/attachment.html>

From Sebastian.Millies at softwareag.com  Mon May  8 05:13:18 2017
From: Sebastian.Millies at softwareag.com (Millies, Sebastian)
Date: Mon, 8 May 2017 09:13:18 +0000
Subject: [concurrency-interest] Make the double-checked lock idiom
 broken on	x86
In-Reply-To: <20170508142216.GB3463@HP>
References: <20170508142216.GB3463@HP>
Message-ID: <32F15738E8E5524DA4F01A0FA4A8E490010B792136@daeexmbx1.eur.ad.sag>

You may find the following article by Aleksey Shipilev extremely helpful in understanding DCL (and related idioms)
http://shipilev.net/blog/2014/safe-public-construction
It has been sometimes mentioned on the list.

-- Sebastian

-----Original Message-----
From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Yubin Ruan
Sent: Monday, May 08, 2017 4:22 PM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Make the double-checked lock idiom broken on x86

Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is broken. Bill Pugh gave an example:

    // Broken multithreaded version
    // "Double-Checked Locking" idiom
    class Foo {
      private Helper helper = null;
      public Helper getHelper() {
        if (helper == null)
          synchronized(this) {
            if (helper == null)
              helper = new Helper();
        }
        return helper;
      }
      // other functions and members...
    }

His analysis is convincing, but the code he gave[2] work *well* on x86.
That is expected to break sometimes. But, running it from time to time, I never see it break.

How to verify that the double-check lock idiom will break on x86?

---
Yubin

[1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
[2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

Software AG – Sitz/Registered office: Uhlandstraße 12, 64297 Darmstadt, Germany – Registergericht/Commercial register: Darmstadt HRB 1562 - Vorstand/Management Board: Karl-Heinz Streibich (Vorsitzender/Chairman), Eric Duffaut, Dr. Wolfram Jost, Arnd Zinnhardt, Dr. Stefan Sigg; - Aufsichtsratsvorsitzender/Chairman of the Supervisory Board: Dr. Andreas Bereczky - http://www.softwareag.com


From ablacktshirt at gmail.com  Mon May  8 14:56:08 2017
From: ablacktshirt at gmail.com (Yubin Ruan)
Date: Tue, 9 May 2017 02:56:08 +0800
Subject: [concurrency-interest] Make the double-checked lock idiom
 broken on x86
In-Reply-To: <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com>
References: <20170508142216.GB3463@HP>
 <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com>
Message-ID: <20170508185606.GA9253@HP>

On Mon, May 08, 2017 at 09:55:53AM +0100, Alex Otenko wrote:
> I’d start with using the same version and brand of the JVM Bill used at the time of writing the article, which was probably written over 15 years ago.

Hmm...You mean what he said is not correct now? We don't need the `volatile'
keyword?

--
Yubin

> 
> > On 8 May 2017, at 15:22, Yubin Ruan <ablacktshirt at gmail.com> wrote:
> > 
> > Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is
> > broken. Bill Pugh gave an example:
> > 
> >    // Broken multithreaded version
> >    // "Double-Checked Locking" idiom
> >    class Foo { 
> >      private Helper helper = null;
> >      public Helper getHelper() {
> >        if (helper == null) 
> >          synchronized(this) {
> >            if (helper == null) 
> >              helper = new Helper();
> >        }    
> >        return helper;
> >      }
> >      // other functions and members...
> >    }
> > 
> > His analysis is convincing, but the code he gave[2] work *well* on x86.
> > That is expected to break sometimes. But, running it from time to time,
> > I never see it break.
> > 
> > How to verify that the double-check lock idiom will break on x86?
> > 
> > ---
> > Yubin
> > 
> > [1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
> > [2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 

From oleksandr.otenko at gmail.com  Mon May  8 08:00:56 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 8 May 2017 13:00:56 +0100
Subject: [concurrency-interest] Make the double-checked lock idiom
	broken on x86
In-Reply-To: <20170508185606.GA9253@HP>
References: <20170508142216.GB3463@HP>
 <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com> <20170508185606.GA9253@HP>
Message-ID: <F107D28A-2990-4250-97B2-24E0D7F5B995@gmail.com>

No, I mean that the VM + execution environment may no longer produce the same side-effects that would quickly fail the reproducer in the olden days - so the published reproducer would need modification to demonstrate the problem on the modern hardware and the VM.

For example, if the cost of synchronized is totally different, the threads no longer race in a way they used to. Suppose, the locks are biased now - one thread does the job, the rest of the threads are catching up, and after upgrade of the lock they all have to yield. When they wake up, the race effects are gone. So one thread does the job, and the others sleep.

Not saying that’s what happens, but just to give an idea how the evolution of the JVM could affect the reproducer (but not the claim).

Alex

> On 8 May 2017, at 19:56, Yubin Ruan <ablacktshirt at gmail.com> wrote:
> 
> On Mon, May 08, 2017 at 09:55:53AM +0100, Alex Otenko wrote:
>> I’d start with using the same version and brand of the JVM Bill used at the time of writing the article, which was probably written over 15 years ago.
> 
> Hmm...You mean what he said is not correct now? We don't need the `volatile'
> keyword?
> 
> --
> Yubin
> 
>> 
>>> On 8 May 2017, at 15:22, Yubin Ruan <ablacktshirt at gmail.com> wrote:
>>> 
>>> Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is
>>> broken. Bill Pugh gave an example:
>>> 
>>>   // Broken multithreaded version
>>>   // "Double-Checked Locking" idiom
>>>   class Foo { 
>>>     private Helper helper = null;
>>>     public Helper getHelper() {
>>>       if (helper == null) 
>>>         synchronized(this) {
>>>           if (helper == null) 
>>>             helper = new Helper();
>>>       }    
>>>       return helper;
>>>     }
>>>     // other functions and members...
>>>   }
>>> 
>>> His analysis is convincing, but the code he gave[2] work *well* on x86.
>>> That is expected to break sometimes. But, running it from time to time,
>>> I never see it break.
>>> 
>>> How to verify that the double-check lock idiom will break on x86?
>>> 
>>> ---
>>> Yubin
>>> 
>>> [1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
>>> [2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 


From concurrency at kuli.org  Mon May  8 08:11:05 2017
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Mon, 8 May 2017 14:11:05 +0200
Subject: [concurrency-interest] Make the double-checked lock idiom
 broken on x86
In-Reply-To: <F107D28A-2990-4250-97B2-24E0D7F5B995@gmail.com>
References: <20170508142216.GB3463@HP>
 <F14504A3-9910-4110-83AB-FC844C24587A@gmail.com> <20170508185606.GA9253@HP>
 <F107D28A-2990-4250-97B2-24E0D7F5B995@gmail.com>
Message-ID: <dc1b7f99-9954-00c1-b110-5db3f1e707ca@kuli.org>

@Yubin:

BTW I'm suspicious that the mentioned Helper class isn't mutable at all.
At least that would be surprising, I wouldn't expect a stateful helper
class (but I wouldn't even expect helper classes to be instantiable).

If Helper has no instance variables, or at least one of them is final,
then your code is already correct. At least since Java 5.

-Michael

Am 08.05.2017 um 14:00 schrieb Alex Otenko:
> No, I mean that the VM + execution environment may no longer produce the same side-effects that would quickly fail the reproducer in the olden days - so the published reproducer would need modification to demonstrate the problem on the modern hardware and the VM.
> 
> For example, if the cost of synchronized is totally different, the threads no longer race in a way they used to. Suppose, the locks are biased now - one thread does the job, the rest of the threads are catching up, and after upgrade of the lock they all have to yield. When they wake up, the race effects are gone. So one thread does the job, and the others sleep.
> 
> Not saying that’s what happens, but just to give an idea how the evolution of the JVM could affect the reproducer (but not the claim).
> 
> Alex
> 
>> On 8 May 2017, at 19:56, Yubin Ruan <ablacktshirt at gmail.com> wrote:
>>
>> On Mon, May 08, 2017 at 09:55:53AM +0100, Alex Otenko wrote:
>>> I’d start with using the same version and brand of the JVM Bill used at the time of writing the article, which was probably written over 15 years ago.
>>
>> Hmm...You mean what he said is not correct now? We don't need the `volatile'
>> keyword?
>>
>> --
>> Yubin
>>
>>>
>>>> On 8 May 2017, at 15:22, Yubin Ruan <ablacktshirt at gmail.com> wrote:
>>>>
>>>> Hi, from Bill Pugh's website[1] I read that the double-checked lock idiom is
>>>> broken. Bill Pugh gave an example:
>>>>
>>>>   // Broken multithreaded version
>>>>   // "Double-Checked Locking" idiom
>>>>   class Foo { 
>>>>     private Helper helper = null;
>>>>     public Helper getHelper() {
>>>>       if (helper == null) 
>>>>         synchronized(this) {
>>>>           if (helper == null) 
>>>>             helper = new Helper();
>>>>       }    
>>>>       return helper;
>>>>     }
>>>>     // other functions and members...
>>>>   }
>>>>
>>>> His analysis is convincing, but the code he gave[2] work *well* on x86.
>>>> That is expected to break sometimes. But, running it from time to time,
>>>> I never see it break.
>>>>
>>>> How to verify that the double-check lock idiom will break on x86?
>>>>
>>>> ---
>>>> Yubin
>>>>
>>>> [1]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html
>>>> [2]: https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckTest.java
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From dileep.mandapam at gmail.com  Tue May 16 08:43:18 2017
From: dileep.mandapam at gmail.com (Dileep Mandapam)
Date: Tue, 16 May 2017 18:13:18 +0530
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
Message-ID: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>

Hi

Environment details:-
java version "1.8.0_131"
Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)



 Removing an element while traversal . Sometimes elements are not removing
from concurrentskiplistset.

for( Element e : concurrentskiplistsetcollection) {

     if ( e is to be removed) {
            concurrentskiplistset.remove(e);
    }

}

My question is safe to use above to pattern to remove elements ?
-- 
Regards
Dileep M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170516/4904e8b1/attachment.html>

From concurrency at kuli.org  Tue May 16 09:54:51 2017
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Tue, 16 May 2017 15:54:51 +0200
Subject: [concurrency-interest] Traversal and removing elements from
 ConcurrentskipListSet
In-Reply-To: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
Message-ID: <b6aba11f-e35c-6e9a-07c7-74a6d6acd2c2@kuli.org>

Hi Dileep,

please read the JavaDoc of ConcurrentSkipListSet. It refers to the
"weakly consistent" section of the package JavaDoc. This states:

***
[Iterators] are guaranteed to traverse elements as they existed upon
construction exactly once, and may (but are not guaranteed to) reflect
any modifications subsequent to construction.
***

So yes, this should work as expected as long as every e is unique.
However, it's always better to directly use the Iterator instead of the
short for loop, and call remove() on the iterator. This will work for
all modifiable Iterable implementations, and it will work for multiple
entries which are equal to each other.

-Michael


Am 16.05.2017 um 14:43 schrieb Dileep Mandapam:
> Hi 
> 
> Environment details:-
> java version "1.8.0_131"
> Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
> Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)
> 
> 
> 
>  Removing an element while traversal . Sometimes elements are not
> removing from concurrentskiplistset. 
> 
> for( Element e : concurrentskiplistsetcollection) {
>  
>      if ( e is to be removed) {
>             concurrentskiplistset.remove(e);
>     }
> 
> }
> 
> My question is safe to use above to pattern to remove elements ?
> -- 
> Regards
> Dileep M
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From martinrb at google.com  Tue May 16 21:02:46 2017
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 16 May 2017 18:02:46 -0700
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
In-Reply-To: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
Message-ID: <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>

There's a new API for what you're trying to do - removeIf
(and probably there's work to be done on our part making it optimal)

On Tue, May 16, 2017 at 5:43 AM, Dileep Mandapam <dileep.mandapam at gmail.com>
wrote:

> Hi
>
> Environment details:-
> java version "1.8.0_131"
> Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
> Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)
>
>
>
>  Removing an element while traversal . Sometimes elements are not removing
> from concurrentskiplistset.
>
> for( Element e : concurrentskiplistsetcollection) {
>
>      if ( e is to be removed) {
>             concurrentskiplistset.remove(e);
>     }
>
> }
>
> My question is safe to use above to pattern to remove elements ?
> --
> Regards
> Dileep M
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170516/747aa3b5/attachment.html>

From dileep.mandapam at gmail.com  Tue May 16 22:36:05 2017
From: dileep.mandapam at gmail.com (Dileep Mandapam)
Date: Wed, 17 May 2017 08:06:05 +0530
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
In-Reply-To: <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
Message-ID: <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>

Thanks for your answers..

I wrote a test program to verify.

import java.util.Comparator;
import java.util.Iterator;
import java.util.concurrent.ConcurrentSkipListSet;
import java.util.concurrent.Executors;

/**
 * Created by dmandapam on 5/16/17.
 */
public class ConcurrentSj {
    static final ConcurrentSkipListSet<MyBug> concurrentSkipListSet = new
ConcurrentSkipListSet<>(new Comparator<MyBug>() {
        @Override
        public int compare(MyBug o1, MyBug o2) {
            return 1;
        }
    });
    public static void main(String... rag) throws InterruptedException {
        Executors.newSingleThreadExecutor().execute(() -> {
            while (true) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                MyBug bug = new MyBug((int) (Math.random() * 10000));
                concurrentSkipListSet.add(bug);
                System.out.println("added bug" + bug);
            }
        });
        while (true) {
            boolean flag = false;
            System.out.println("weak iterators");
            for(MyBug bug : concurrentSkipListSet) {
                if (flag) {
                    boolean remove = concurrentSkipListSet.remove(bug);
                    System.out.println("removed = "+ bug + " result = "+
remove);
                }
                flag = !flag;
            }
            /*Iterator<MyBug> iterator = concurrentSkipListSet.iterator();
            while (iterator.hasNext()) {
                MyBug bug = iterator.next();
                if (flag) {
                    boolean remove = concurrentSkipListSet.remove(bug);
                    System.out.println("removed = "+ bug + " result = "+
remove);
                }
                flag = !flag;
            }*/
            Thread.sleep(1000);
        }
    }

    static class MyBug {
        int id;

        public MyBug(int id) {
            this.id = id;
        }

        @Override
        public String toString() {
            return "id=" + id ;
        }

        /*@Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;

            MyBug bug = (MyBug) o;

            return id == bug.id;
        }

        @Override
        public int hashCode() {
            return id;
        }*/
    }
}


Looks like there is a bug in ConcurrentskipListSet.

On Wed, May 17, 2017 at 6:32 AM, Martin Buchholz <martinrb at google.com>
wrote:

> There's a new API for what you're trying to do - removeIf
> (and probably there's work to be done on our part making it optimal)
>
> On Tue, May 16, 2017 at 5:43 AM, Dileep Mandapam <
> dileep.mandapam at gmail.com> wrote:
>
>> Hi
>>
>> Environment details:-
>> java version "1.8.0_131"
>> Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
>> Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)
>>
>>
>>
>>  Removing an element while traversal . Sometimes elements are not
>> removing from concurrentskiplistset.
>>
>> for( Element e : concurrentskiplistsetcollection) {
>>
>>      if ( e is to be removed) {
>>             concurrentskiplistset.remove(e);
>>     }
>>
>> }
>>
>> My question is safe to use above to pattern to remove elements ?
>> --
>> Regards
>> Dileep M
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>


-- 
Regards
Dileep M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170517/32c7a805/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ConcurrentSj.java
Type: application/octet-stream
Size: 2393 bytes
Desc: not available
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170517/32c7a805/attachment.obj>

From martinrb at google.com  Tue May 16 23:01:09 2017
From: martinrb at google.com (Martin Buchholz)
Date: Tue, 16 May 2017 20:01:09 -0700
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
In-Reply-To: <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
Message-ID: <CA+kOe0_2vgM+nqFj8g3w5TCp_=s+mKc6EoF9fDDAB8YFjQ8B9A@mail.gmail.com>

On Tue, May 16, 2017 at 7:36 PM, Dileep Mandapam <dileep.mandapam at gmail.com>
wrote:

>        public int compare(MyBug o1, MyBug o2) {
>             return 1;
>

That's not a valid compare method.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170516/d8c27906/attachment.html>

From blackdrag at gmx.org  Wed May 17 02:15:05 2017
From: blackdrag at gmx.org (Jochen Theodorou)
Date: Wed, 17 May 2017 08:15:05 +0200
Subject: [concurrency-interest] Queue with interrupt
Message-ID: <591BEA69.9030403@gmx.org>

Hi all,

yesterday I was looking for a certain behaviour, but was not finding one 
and I am wondering if I did overlook something.

Situation:

I have 1 Thread - lets call it worker, that needs to execute a series of 
tasks. If there are no tasks this thread has to wait for a maximum of 5 
seconds. After this time I have to send something like an update from 
this thread (has to be the same thread) to later continue on waiting for 
tasks or handle the new ones. At this point I will not car if processing 
the tasks takes longer than 5 seconds. And now the specialty: A second 
thread must be able to send an interrupt to the worker thread, which 
than has to stop waiting for new jobs and send the update right away, to 
then get back to waiting for jobs. I cannot send the update from the 
interrupting thread.

Now I was expecting to find something in a Queue implementation, but 
while I did find a way to wait for new elements, I did not find a wait 
to interrupt that waiting. We solved this by using a BlockingQueue, plus 
some signaling, but it really does not feel right to me.

Any idea how to do this better?

bye Jochen

From davidcholmes at aapt.net.au  Wed May 17 02:31:46 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 17 May 2017 16:31:46 +1000
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <591BEA69.9030403@gmx.org>
References: <591BEA69.9030403@gmx.org>
Message-ID: <016301d2ced7$42325110$c696f330$@aapt.net.au>

Hi Jochen,

How are you "waiting for tasks"? As you note a Queue has no notion of blocking on empty. Using a BlockingQueue you can either interrupt the worker thread or send a sentinel task that simply indicates "do the other processing now". Of course I can't tell you know whether the worker is waiting or working - you can't arbitrarily "interrupt" the execution of a task.

David

> -----Original Message-----
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Jochen Theodorou
> Sent: Wednesday, May 17, 2017 4:15 PM
> To: concurrency-interest at cs.oswego.edu
> Subject: [concurrency-interest] Queue with interrupt
> 
> Hi all,
> 
> yesterday I was looking for a certain behaviour, but was not finding one and I am wondering if I did overlook something.
> 
> Situation:
> 
> I have 1 Thread - lets call it worker, that needs to execute a series of tasks. If there are no tasks this thread has to wait for a maximum
> of 5 seconds. After this time I have to send something like an update from this thread (has to be the same thread) to later continue on
> waiting for tasks or handle the new ones. At this point I will not car if processing the tasks takes longer than 5 seconds. And now the
> specialty: A second thread must be able to send an interrupt to the worker thread, which than has to stop waiting for new jobs and
> send the update right away, to then get back to waiting for jobs. I cannot send the update from the interrupting thread.
> 
> Now I was expecting to find something in a Queue implementation, but while I did find a way to wait for new elements, I did not find a
> wait to interrupt that waiting. We solved this by using a BlockingQueue, plus some signaling, but it really does not feel right to me.
> 
> Any idea how to do this better?
> 
> bye Jochen
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From viktor.klang at gmail.com  Wed May 17 02:40:27 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Wed, 17 May 2017 08:40:27 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <016301d2ced7$42325110$c696f330$@aapt.net.au>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
Message-ID: <CANPzfU_x5znEkE1Y=-U_g6GgJxwdTmBHcyqzKRKb_EbDwq_iEg@mail.gmail.com>

If I interpret the email correctly, if the queue elements are of type `Job
| Wakeup`, then the second thread could offer a Wakeup if it wants to
interrupt the worker without having a Job.

On Wed, May 17, 2017 at 8:31 AM, David Holmes <davidcholmes at aapt.net.au>
wrote:

> Hi Jochen,
>
> How are you "waiting for tasks"? As you note a Queue has no notion of
> blocking on empty. Using a BlockingQueue you can either interrupt the
> worker thread or send a sentinel task that simply indicates "do the other
> processing now". Of course I can't tell you know whether the worker is
> waiting or working - you can't arbitrarily "interrupt" the execution of a
> task.
>
> David
>
> > -----Original Message-----
> > From: Concurrency-interest [mailto:concurrency-interest-
> bounces at cs.oswego.edu] On Behalf Of Jochen Theodorou
> > Sent: Wednesday, May 17, 2017 4:15 PM
> > To: concurrency-interest at cs.oswego.edu
> > Subject: [concurrency-interest] Queue with interrupt
> >
> > Hi all,
> >
> > yesterday I was looking for a certain behaviour, but was not finding one
> and I am wondering if I did overlook something.
> >
> > Situation:
> >
> > I have 1 Thread - lets call it worker, that needs to execute a series of
> tasks. If there are no tasks this thread has to wait for a maximum
> > of 5 seconds. After this time I have to send something like an update
> from this thread (has to be the same thread) to later continue on
> > waiting for tasks or handle the new ones. At this point I will not car
> if processing the tasks takes longer than 5 seconds. And now the
> > specialty: A second thread must be able to send an interrupt to the
> worker thread, which than has to stop waiting for new jobs and
> > send the update right away, to then get back to waiting for jobs. I
> cannot send the update from the interrupting thread.
> >
> > Now I was expecting to find something in a Queue implementation, but
> while I did find a way to wait for new elements, I did not find a
> > wait to interrupt that waiting. We solved this by using a BlockingQueue,
> plus some signaling, but it really does not feel right to me.
> >
> > Any idea how to do this better?
> >
> > bye Jochen
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170517/95113daa/attachment.html>

From concurrency at kuli.org  Wed May 17 03:29:39 2017
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Wed, 17 May 2017 09:29:39 +0200
Subject: [concurrency-interest] Traversal and removing elements from
 ConcurrentskipListSet
In-Reply-To: <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
Message-ID: <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>

And in addition to Martin's comments, which already named the issue,
this is not what I meant with the iterator:

Am 17.05.2017 um 04:36 schrieb Dileep Mandapam:
>             /*Iterator<MyBug> iterator = concurrentSkipListSet.iterator();
>             while (iterator.hasNext()) {
>                 MyBug bug = iterator.next();
>                 if (flag) {
>                     boolean remove = concurrentSkipListSet.remove(bug);
>                     System.out.println("removed = "+ bug + " result = "+
> remove);
>                 }
>                 flag = !flag;
>             }*/

Of course you should call remove() on the iterator itself, otherwise
that part of your code would do nothing different than the previous.

Anyway, fix your comparator, and do something with your main() method,
whatever you're expecting - currently it's stuck in an endless loop,
totally independent of your list instance and whatever you do with it.

-Michael

From blackdrag at gmx.org  Wed May 17 05:25:43 2017
From: blackdrag at gmx.org (Jochen Theodorou)
Date: Wed, 17 May 2017 11:25:43 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <016301d2ced7$42325110$c696f330$@aapt.net.au>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
Message-ID: <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>



On 17.05.2017 08:31, David Holmes wrote:
> Hi Jochen,
>
> How are you "waiting for tasks"? As you note a Queue has no notion of
> blocking on empty. Using a BlockingQueue you can either interrupt the
> worker thread or send a sentinel task that simply indicates "do the
> other processing now". Of course I can't tell you know whether the
> worker is waiting or working - you can't arbitrarily "interrupt" the
> execution of a task.
>

I think maybe it is better to show some code...
See 
https://github.com/canoo/dolphin-platform/blob/master/platform/dolphin-platform-server/src/main/java/com/canoo/dolphin/server/context/DolphinContextTaskQueue.java

addTasks and interrupt are called from a different thread than 
executeTasks. executeTasks is responsible for one iteration of task 
executions, not a continuously blocking worker.

I do not want to interrupt task execution of course, only the waiting.

So your suggestion is to add a sentinel task... I guess that works, as 
long as I can add the task before already existing tasks, that may be 
still in the queue, so that it can interrupt between task executions ( 
not during of course)

bye Jochen

From davidcholmes at aapt.net.au  Wed May 17 05:29:33 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 17 May 2017 19:29:33 +1000
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
Message-ID: <017101d2cef0$186e7250$494b56f0$@aapt.net.au>

> -----Original Message-----
> From: Jochen Theodorou [mailto:blackdrag at gmx.org]
> Sent: Wednesday, May 17, 2017 7:26 PM
> To: dholmes at ieee.org; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] Queue with interrupt
> 
> 
> 
> On 17.05.2017 08:31, David Holmes wrote:
> > Hi Jochen,
> >
> > How are you "waiting for tasks"? As you note a Queue has no notion of
> > blocking on empty. Using a BlockingQueue you can either interrupt the
> > worker thread or send a sentinel task that simply indicates "do the
> > other processing now". Of course I can't tell you know whether the
> > worker is waiting or working - you can't arbitrarily "interrupt" the
> > execution of a task.
> >
> 
> I think maybe it is better to show some code...
> See
> https://github.com/canoo/dolphin-platform/blob/master/platform/dolphin-platform-
> server/src/main/java/com/canoo/dolphin/server/context/DolphinContextTaskQueue.java
> 
> addTasks and interrupt are called from a different thread than executeTasks. executeTasks is responsible for one iteration of task
> executions, not a continuously blocking worker.
> 
> I do not want to interrupt task execution of course, only the waiting.
> 
> So your suggestion is to add a sentinel task... I guess that works, as long as I can add the task before already existing tasks, that may be
> still in the queue, so that it can interrupt between task executions ( not during of course)

If there are tasks in the queue then the worker is not waiting for new tasks to do - so you've changed your requirements. You would need a deque to allow sentinel tasks to be forced to the head of the queue.

David

 
> bye Jochen


From blackdrag at gmx.org  Wed May 17 05:33:32 2017
From: blackdrag at gmx.org (Jochen Theodorou)
Date: Wed, 17 May 2017 11:33:32 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <CANPzfU_x5znEkE1Y=-U_g6GgJxwdTmBHcyqzKRKb_EbDwq_iEg@mail.gmail.com>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <CANPzfU_x5znEkE1Y=-U_g6GgJxwdTmBHcyqzKRKb_EbDwq_iEg@mail.gmail.com>
Message-ID: <7b458287-c20d-87b6-2e2b-41f232c10214@gmx.org>

But the Wakeup needs to be ordered in before any Job. Plus I have to 
retain the insertion order of the Jobs. I do not see 
PriorityBlockingQueue here, since I cannot tell if the sorting will 
retain insertion order... unless maybe if the elements get now wrapped 
in something with a count, then I sort according to this count 
ascending, and Wakeup would have the lowest possible count.... there is 
really no more simple solution?

bye Jochen

On 17.05.2017 08:40, Viktor Klang wrote:
> If I interpret the email correctly, if the queue elements are of type
> `Job | Wakeup`, then the second thread could offer a Wakeup if it wants
> to interrupt the worker without having a Job.
>
> On Wed, May 17, 2017 at 8:31 AM, David Holmes <davidcholmes at aapt.net.au
> <mailto:davidcholmes at aapt.net.au>> wrote:
>
>     Hi Jochen,
>
>     How are you "waiting for tasks"? As you note a Queue has no notion
>     of blocking on empty. Using a BlockingQueue you can either interrupt
>     the worker thread or send a sentinel task that simply indicates "do
>     the other processing now". Of course I can't tell you know whether
>     the worker is waiting or working - you can't arbitrarily "interrupt"
>     the execution of a task.
>
>     David
>
>     > -----Original Message-----
>     > From: Concurrency-interest
>     [mailto:concurrency-interest-bounces at cs.oswego.edu
>     <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of
>     Jochen Theodorou
>     > Sent: Wednesday, May 17, 2017 4:15 PM
>     > To: concurrency-interest at cs.oswego.edu
>     <mailto:concurrency-interest at cs.oswego.edu>
>     > Subject: [concurrency-interest] Queue with interrupt
>     >
>     > Hi all,
>     >
>     > yesterday I was looking for a certain behaviour, but was not
>     finding one and I am wondering if I did overlook something.
>     >
>     > Situation:
>     >
>     > I have 1 Thread - lets call it worker, that needs to execute a
>     series of tasks. If there are no tasks this thread has to wait for a
>     maximum
>     > of 5 seconds. After this time I have to send something like an
>     update from this thread (has to be the same thread) to later continue on
>     > waiting for tasks or handle the new ones. At this point I will not
>     car if processing the tasks takes longer than 5 seconds. And now the
>     > specialty: A second thread must be able to send an interrupt to
>     the worker thread, which than has to stop waiting for new jobs and
>     > send the update right away, to then get back to waiting for jobs.
>     I cannot send the update from the interrupting thread.
>     >
>     > Now I was expecting to find something in a Queue implementation,
>     but while I did find a way to wait for new elements, I did not find a
>     > wait to interrupt that waiting. We solved this by using a
>     BlockingQueue, plus some signaling, but it really does not feel
>     right to me.
>     >
>     > Any idea how to do this better?
>     >
>     > bye Jochen
>     > _______________________________________________
>     > Concurrency-interest mailing list
>     > Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> --
> Cheers,
> √

From blackdrag at gmx.org  Wed May 17 06:07:06 2017
From: blackdrag at gmx.org (Jochen Theodorou)
Date: Wed, 17 May 2017 12:07:06 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
 <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
Message-ID: <50468206-1423-7e69-73e8-b206995f14a0@gmx.org>



On 17.05.2017 11:29, David Holmes wrote:
[...]
> If there are tasks in the queue then the worker is not waiting for new tasks to do - so you've changed your requirements. You would need a deque to allow sentinel tasks to be forced to the head of the queue.


ah... now I see what I have overlooked.. I should have been using 
Dequeue/LinkedBlockingDeque instead.

yes, that explains also why I had the feeling I am doing something stupid ;)

Thanks

bye Jochen

From aaron.grunthal at infinite-source.de  Wed May 17 06:33:00 2017
From: aaron.grunthal at infinite-source.de (Aaron Grunthal)
Date: Wed, 17 May 2017 12:33:00 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <7b458287-c20d-87b6-2e2b-41f232c10214@gmx.org>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <CANPzfU_x5znEkE1Y=-U_g6GgJxwdTmBHcyqzKRKb_EbDwq_iEg@mail.gmail.com>
 <7b458287-c20d-87b6-2e2b-41f232c10214@gmx.org>
Message-ID: <08d11ebf-7c2b-4868-2acf-1716c0657434@infinite-source.de>

You could simply drain all available tasks from the queue into a local list, then look for the wakeup before processing the rest.

On 17.05.2017 11:33, Jochen Theodorou wrote:
> But the Wakeup needs to be ordered in before any Job. Plus I have to retain the insertion order of the Jobs. I do not see PriorityBlockingQueue here, since I cannot tell if the sorting will retain
> insertion order... unless maybe if the elements get now wrapped in something with a count, then I sort according to this count ascending, and Wakeup would have the lowest possible count.... there is
> really no more simple solution?
> 
> bye Jochen
> 
> On 17.05.2017 08:40, Viktor Klang wrote:
>> If I interpret the email correctly, if the queue elements are of type
>> `Job | Wakeup`, then the second thread could offer a Wakeup if it wants
>> to interrupt the worker without having a Job.
>>
>> On Wed, May 17, 2017 at 8:31 AM, David Holmes <davidcholmes at aapt.net.au
>> <mailto:davidcholmes at aapt.net.au>> wrote:
>>
>>     Hi Jochen,
>>
>>     How are you "waiting for tasks"? As you note a Queue has no notion
>>     of blocking on empty. Using a BlockingQueue you can either interrupt
>>     the worker thread or send a sentinel task that simply indicates "do
>>     the other processing now". Of course I can't tell you know whether
>>     the worker is waiting or working - you can't arbitrarily "interrupt"
>>     the execution of a task.
>>
>>     David
>>
>>     > -----Original Message-----
>>     > From: Concurrency-interest
>>     [mailto:concurrency-interest-bounces at cs.oswego.edu
>>     <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of
>>     Jochen Theodorou
>>     > Sent: Wednesday, May 17, 2017 4:15 PM
>>     > To: concurrency-interest at cs.oswego.edu
>>     <mailto:concurrency-interest at cs.oswego.edu>
>>     > Subject: [concurrency-interest] Queue with interrupt
>>     >
>>     > Hi all,
>>     >
>>     > yesterday I was looking for a certain behaviour, but was not
>>     finding one and I am wondering if I did overlook something.
>>     >
>>     > Situation:
>>     >
>>     > I have 1 Thread - lets call it worker, that needs to execute a
>>     series of tasks. If there are no tasks this thread has to wait for a
>>     maximum
>>     > of 5 seconds. After this time I have to send something like an
>>     update from this thread (has to be the same thread) to later continue on
>>     > waiting for tasks or handle the new ones. At this point I will not
>>     car if processing the tasks takes longer than 5 seconds. And now the
>>     > specialty: A second thread must be able to send an interrupt to
>>     the worker thread, which than has to stop waiting for new jobs and
>>     > send the update right away, to then get back to waiting for jobs.
>>     I cannot send the update from the interrupting thread.
>>     >
>>     > Now I was expecting to find something in a Queue implementation,
>>     but while I did find a way to wait for new elements, I did not find a
>>     > wait to interrupt that waiting. We solved this by using a
>>     BlockingQueue, plus some signaling, but it really does not feel
>>     right to me.
>>     >
>>     > Any idea how to do this better?
>>     >
>>     > bye Jochen
>>     > _______________________________________________
>>     > Concurrency-interest mailing list
>>     > Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>     _______________________________________________
>>     Concurrency-interest mailing list
>>     Concurrency-interest at cs.oswego.edu
>>     <mailto:Concurrency-interest at cs.oswego.edu>
>>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>
>>
>>
>>
>> -- 
>> Cheers,
>> √
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dileep.mandapam at gmail.com  Wed May 17 10:10:53 2017
From: dileep.mandapam at gmail.com (Dileep Mandapam)
Date: Wed, 17 May 2017 19:40:53 +0530
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
In-Reply-To: <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
 <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>
Message-ID: <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>

Thanks, I rewrote the program. I ran into a strange situation. I am
mutating a field which is used in the comparator.  Now remove method is
returning false for most of the times.


import java.util.Comparator;
import java.util.concurrent.ConcurrentSkipListSet;

/**
 * Created by dmandapam on 5/17/17.
 */
public class RemoveTest {
    static final ConcurrentSkipListSet<MyBug> concurrentSkipListSet =
new ConcurrentSkipListSet<>(new Comparator<MyBug>() {
        @Override
        public int compare(MyBug o1, MyBug o2) {
            int result = Integer.compare(o1.getId(), o2.getId());
            return result;
        }
    });
    public static void main(String... args) {
        MyBug bug1 = new MyBug(10);
        concurrentSkipListSet.add(bug1);
        concurrentSkipListSet.add(new MyBug(20));
        concurrentSkipListSet.add(new MyBug(30));
        bug1.setId(50);
        boolean remove = concurrentSkipListSet.remove(new MyBug(30));
        System.out.println("remove " + remove);

    }
    static class MyBug {
        int id;

        public MyBug(int id) {
            this.id = id;
        }

        @Override
        public String toString() {
            return "id=" + id ;
        }

        public void setId(int id) {
            this.id = id;
        }

        public int getId() {
            return id;
        }
    }



*But if i try  with TreeSet then remove method always returns true.
Could you guys help me in uderstanding the problem.*


On Wed, May 17, 2017 at 12:59 PM, Michael Kuhlmann <concurrency at kuli.org>
wrote:

> And in addition to Martin's comments, which already named the issue,
> this is not what I meant with the iterator:
>
> Am 17.05.2017 um 04:36 schrieb Dileep Mandapam:
> >             /*Iterator<MyBug> iterator = concurrentSkipListSet.
> iterator();
> >             while (iterator.hasNext()) {
> >                 MyBug bug = iterator.next();
> >                 if (flag) {
> >                     boolean remove = concurrentSkipListSet.remove(bug);
> >                     System.out.println("removed = "+ bug + " result = "+
> > remove);
> >                 }
> >                 flag = !flag;
> >             }*/
>
> Of course you should call remove() on the iterator itself, otherwise
> that part of your code would do nothing different than the previous.
>
> Anyway, fix your comparator, and do something with your main() method,
> whatever you're expecting - currently it's stuck in an endless loop,
> totally independent of your list instance and whatever you do with it.
>
> -Michael
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Regards
Dileep M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170517/bc8b9390/attachment.html>

From concurrency at kuli.org  Wed May 17 10:22:14 2017
From: concurrency at kuli.org (Michael Kuhlmann)
Date: Wed, 17 May 2017 16:22:14 +0200
Subject: [concurrency-interest] Traversal and removing elements from
 ConcurrentskipListSet
In-Reply-To: <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
 <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>
 <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>
Message-ID: <44b5758c-2124-7c52-2330-522da82c4213@kuli.org>

You mustn't change the internal state of already inserted elements so
that compare() (or hash() in other cases) changes. This is true for all
cases where such a state is used to balance a structure, like HashMap
and TreeMap and such. The internal ordering in this container will be
wrong then.

This is not really an issue with the ConcurrentSkipListSet, or with
concurrency in general. I recommend you to learn about the correct usage
of Java's basic collection classes before you start with this.

Good luck,
Michael


Am 17.05.2017 um 16:10 schrieb Dileep Mandapam:
> Thanks, I rewrote the program. I ran into a strange situation. I am
> mutating a field which is used in the comparator.  Now remove method is
> returning false for most of the times. 
> 
> 
> import java.util.Comparator;
> import java.util.concurrent.ConcurrentSkipListSet;
> 
> /**
> * Created by dmandapam on 5/17/17.
> */
> public class RemoveTest {
> static final ConcurrentSkipListSet<MyBug> concurrentSkipListSet = new ConcurrentSkipListSet<>(new Comparator<MyBug>() {
> @Override
> public int compare(MyBug o1, MyBug o2) {
> int result = Integer.compare(o1.getId(), o2.getId());
>             return result;
>         }
> });
>     public static void main(String... args) {
> MyBug bug1 = new MyBug(10);
>         concurrentSkipListSet.add(bug1);
>         concurrentSkipListSet.add(new MyBug(20));
>         concurrentSkipListSet.add(new MyBug(30));
>         bug1.setId(50);
>         boolean remove = concurrentSkipListSet.remove(new MyBug(30));
>         System.out.println("remove " + remove);
> 
>     }
> static class MyBug {
> int id;
> 
>         public MyBug(int id) {
> this.id = id;
>         }
> 
> @Override
> public String toString() {
> return "id=" + id ;
>         }
> 
> public void setId(int id) {
> this.id = id;
>         }
> 
> public int getId() {
> return id;
>         }
> }
> 
> 
> 
> *But if i try with TreeSet then remove method always returns true. Could
> you guys help me in uderstanding the problem.*
> 
> 
> On Wed, May 17, 2017 at 12:59 PM, Michael Kuhlmann <concurrency at kuli.org
> <mailto:concurrency at kuli.org>> wrote:
> 
>     And in addition to Martin's comments, which already named the issue,
>     this is not what I meant with the iterator:
> 
>     Am 17.05.2017 um 04:36 schrieb Dileep Mandapam:
>     >             /*Iterator<MyBug> iterator = concurrentSkipListSet.iterator();
>     >             while (iterator.hasNext()) {
>     >                 MyBug bug = iterator.next();
>     >                 if (flag) {
>     >                     boolean remove = concurrentSkipListSet.remove(bug);
>     >                     System.out.println("removed = "+ bug + " result = "+
>     > remove);
>     >                 }
>     >                 flag = !flag;
>     >             }*/
> 
>     Of course you should call remove() on the iterator itself, otherwise
>     that part of your code would do nothing different than the previous.
> 
>     Anyway, fix your comparator, and do something with your main() method,
>     whatever you're expecting - currently it's stuck in an endless loop,
>     totally independent of your list instance and whatever you do with it.
> 
>     -Michael
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> 
> 
> -- 
> Regards
> Dileep M


From bronee at gmail.com  Wed May 17 10:23:50 2017
From: bronee at gmail.com (Brian S O'Neill)
Date: Wed, 17 May 2017 07:23:50 -0700
Subject: [concurrency-interest] Traversal and removing elements from
 ConcurrentskipListSet
In-Reply-To: <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
 <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>
 <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>
Message-ID: <59d46805-9ac9-7e7c-c1ab-1bac387eaa7d@gmail.com>

What are you trying to do exactly? Identify how the set fails when the 
behavior it depends is broken? When an entry is added to the set with a 
specific comparator result, the result must not change for as long as 
the entry exists in the set. In general, comparators must not depend on 
mutable state. Your comparator is broken.

On 2017-05-17 07:10 AM, Dileep Mandapam wrote:
> Thanks, I rewrote the program. I ran into a strange situation. I am 
> mutating a field which is used in the comparator.  Now remove method is 
> returning false for most of the times.
> 
> 
> import java.util.Comparator;
> import java.util.concurrent.ConcurrentSkipListSet;
> 
> /**
> * Created by dmandapam on 5/17/17.
> */
> public class RemoveTest {
> static final ConcurrentSkipListSet<MyBug> concurrentSkipListSet =new ConcurrentSkipListSet<>(new Comparator<MyBug>() {
> @Override
> public int compare(MyBug o1,MyBug o2) {
> int result =Integer.compare(o1.getId(),o2.getId());
>              return result;
>          }
> });
>      public static void main(String...args) {
> MyBug bug1 =new MyBug(10);
>          concurrentSkipListSet.add(bug1);
>          concurrentSkipListSet.add(new MyBug(20));
>          concurrentSkipListSet.add(new MyBug(30));
>          bug1.setId(50);
>          boolean remove =concurrentSkipListSet.remove(new MyBug(30));
>          System.out.println("remove " + remove);
> 
>      }
> static class MyBug {
> int id;
> 
>          public MyBug(int id) {
> this.id =id;
>          }
> 
> @Override
> public String toString() {
> return "id=" +id ;
>          }
> 
> public void setId(int id) {
> this.id =id;
>          }
> 
> public int getId() {
> return id;
>          }
> }
> 
> 
> 
> *But if i try with TreeSet then remove method always returns true. Could 
> you guys help me in uderstanding the problem.*
> 
> 

From dileep.mandapam at gmail.com  Wed May 17 22:36:35 2017
From: dileep.mandapam at gmail.com (Dileep Mandapam)
Date: Thu, 18 May 2017 08:06:35 +0530
Subject: [concurrency-interest] Traversal and removing elements from
	ConcurrentskipListSet
In-Reply-To: <59d46805-9ac9-7e7c-c1ab-1bac387eaa7d@gmail.com>
References: <CAPAHzu1fW61cJEhofZjrsXGidHZGsYA7iN=ejtZ=6bvMp-M6rQ@mail.gmail.com>
 <CA+kOe0_9jBRsMigHFMKA_hAfPy47s5UBEcvvmo1s8EiL0T_VFA@mail.gmail.com>
 <CAPAHzu3JjFL+MEKpOQ-F4rz1ZXYeum1-60wae8mTZ_OkvmwcdQ@mail.gmail.com>
 <ed06cb2b-8ebd-726c-e0b2-878d194678e6@kuli.org>
 <CAPAHzu2+kQChuNOyz9H6Xrc9LvDxp8MZ3xkbaE1jKN_iv82GMw@mail.gmail.com>
 <59d46805-9ac9-7e7c-c1ab-1bac387eaa7d@gmail.com>
Message-ID: <CAPAHzu0POiZc8f0YKRFoVVy0wPVbxihLhsYN9Z_cdogCuifGJg@mail.gmail.com>

Ok thanks

On 17-May-2017 8:01 PM, "Brian S O'Neill" <bronee at gmail.com> wrote:

> What are you trying to do exactly? Identify how the set fails when the
> behavior it depends is broken? When an entry is added to the set with a
> specific comparator result, the result must not change for as long as the
> entry exists in the set. In general, comparators must not depend on mutable
> state. Your comparator is broken.
>
> On 2017-05-17 07:10 AM, Dileep Mandapam wrote:
>
>> Thanks, I rewrote the program. I ran into a strange situation. I am
>> mutating a field which is used in the comparator.  Now remove method is
>> returning false for most of the times.
>>
>>
>> import java.util.Comparator;
>> import java.util.concurrent.ConcurrentSkipListSet;
>>
>> /**
>> * Created by dmandapam on 5/17/17.
>> */
>> public class RemoveTest {
>> static final ConcurrentSkipListSet<MyBug> concurrentSkipListSet =new
>> ConcurrentSkipListSet<>(new Comparator<MyBug>() {
>> @Override
>> public int compare(MyBug o1,MyBug o2) {
>> int result =Integer.compare(o1.getId(),o2.getId());
>>              return result;
>>          }
>> });
>>      public static void main(String...args) {
>> MyBug bug1 =new MyBug(10);
>>          concurrentSkipListSet.add(bug1);
>>          concurrentSkipListSet.add(new MyBug(20));
>>          concurrentSkipListSet.add(new MyBug(30));
>>          bug1.setId(50);
>>          boolean remove =concurrentSkipListSet.remove(new MyBug(30));
>>          System.out.println("remove " + remove);
>>
>>      }
>> static class MyBug {
>> int id;
>>
>>          public MyBug(int id) {
>> this.id =id;
>>          }
>>
>> @Override
>> public String toString() {
>> return "id=" +id ;
>>          }
>>
>> public void setId(int id) {
>> this.id =id;
>>          }
>>
>> public int getId() {
>> return id;
>>          }
>> }
>>
>>
>>
>> *But if i try with TreeSet then remove method always returns true. Could
>> you guys help me in uderstanding the problem.*
>>
>>
>> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170518/fce4798e/attachment.html>

From chris.hegarty at oracle.com  Thu May 18 07:43:25 2017
From: chris.hegarty at oracle.com (Chris Hegarty)
Date: Thu, 18 May 2017 12:43:25 +0100
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
 <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
Message-ID: <124A3365-D377-494F-AC32-4A15C6AA0B15@oracle.com>


> On 17 May 2017, at 10:29, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> ...
> If there are tasks in the queue then the worker is not waiting for new tasks to do - so you've changed your requirements. You would need a deque to allow sentinel tasks to be forced to the head of the queue.

I’ve always wished that we could somehow squeeze a sentinel into the
implementation in order to provide a “CloseableBlockingQueue” with a
blocking takeOrNull(), or similarly named, method. Rather than folk having
to roll their own.

-Chris.


From viktor.klang at gmail.com  Thu May 18 07:56:38 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 18 May 2017 13:56:38 +0200
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <124A3365-D377-494F-AC32-4A15C6AA0B15@oracle.com>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
 <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
 <124A3365-D377-494F-AC32-4A15C6AA0B15@oracle.com>
Message-ID: <CANPzfU9p9j1R+yjYXci3riUy6ppzYiMkiNDTe63oTaN2ryFivA@mail.gmail.com>

OTOH, I'd rather avoid Blocking* whenever possible.

On Thu, May 18, 2017 at 1:43 PM, Chris Hegarty <chris.hegarty at oracle.com>
wrote:

>
> > On 17 May 2017, at 10:29, David Holmes <davidcholmes at aapt.net.au> wrote:
> >
> > ...
> > If there are tasks in the queue then the worker is not waiting for new
> tasks to do - so you've changed your requirements. You would need a deque
> to allow sentinel tasks to be forced to the head of the queue.
>
> I’ve always wished that we could somehow squeeze a sentinel into the
> implementation in order to provide a “CloseableBlockingQueue” with a
> blocking takeOrNull(), or similarly named, method. Rather than folk having
> to roll their own.
>
> -Chris.
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170518/af278e4f/attachment.html>

From martinrb at google.com  Mon May 22 15:44:22 2017
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 22 May 2017 12:44:22 -0700
Subject: [concurrency-interest] curious if there is a Local.java in the
 works for CompletableFutures like scala has
In-Reply-To: <45779887-D9E2-463B-948A-458BB6F02CDA@oracle.com>
References: <CAN1v_zrLYFBRHDnnacr0FFx5ZFSx2=R397s59JxCGa_HySYG9Q@mail.gmail.com>
 <45779887-D9E2-463B-948A-458BB6F02CDA@oracle.com>
Message-ID: <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>

There's not likely to be any support for local context anywhere in
java.util.concurrent, but it seems not too hard to roll your own support
with a custom executor to be used with CompletableFuture that kept track of
any local context.

On Fri, May 19, 2017 at 1:16 PM, Pavel Rappo <pavel.rappo at oracle.com> wrote:

> General questions on concurrency in Java should be asked here:
>
>    http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> > On 18 May 2017, at 21:57, Dean Hiller <dhiller at twitter.com> wrote:
> >
> > Way more detail here...
> >
> > http://stackoverflow.com/questions/37933713/does-
> completablefuture-have-a-corresponding-local-context
> >
> > So I was wondering if this was going to be added at some point to the jdk
> > as I could not figure out how to set something so it was still available
> on
> > the thread at a later time when traversing async thenCompose, thenAccept.
> >
> > thanks,
> > Dean
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170522/04c56b8e/attachment.html>

From viktor.klang at gmail.com  Mon May 22 15:58:37 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Mon, 22 May 2017 21:58:37 +0200
Subject: [concurrency-interest] curious if there is a Local.java in the
 works for CompletableFutures like scala has
In-Reply-To: <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
References: <CAN1v_zrLYFBRHDnnacr0FFx5ZFSx2=R397s59JxCGa_HySYG9Q@mail.gmail.com>
 <45779887-D9E2-463B-948A-458BB6F02CDA@oracle.com>
 <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
Message-ID: <CANPzfU-cQoc5-JZrQBMOoUKo8VdmL8rL=ApTUPL8pFO4JgiwKg@mail.gmail.com>

Ah, this question comes up once in a while, the biggest questions in my
mind are:
1) It's easy to lose context when intermediate libraries/Executors get
involved, how does the developer detect and fix it?
2) It's unclear what fan-in behaviors like zip, merge etc mean in terms of
what the local values should be?
3) It's unclear what fan-out behaviors like split, route, broadcast mean in
terms of what the local values should be?

On Mon, May 22, 2017 at 9:44 PM, Martin Buchholz <martinrb at google.com>
wrote:

> There's not likely to be any support for local context anywhere in
> java.util.concurrent, but it seems not too hard to roll your own support
> with a custom executor to be used with CompletableFuture that kept track of
> any local context.
>
> On Fri, May 19, 2017 at 1:16 PM, Pavel Rappo <pavel.rappo at oracle.com>
> wrote:
>
>> General questions on concurrency in Java should be asked here:
>>
>>    http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> > On 18 May 2017, at 21:57, Dean Hiller <dhiller at twitter.com> wrote:
>> >
>> > Way more detail here...
>> >
>> > http://stackoverflow.com/questions/37933713/does-completable
>> future-have-a-corresponding-local-context
>> >
>> > So I was wondering if this was going to be added at some point to the
>> jdk
>> > as I could not figure out how to set something so it was still
>> available on
>> > the thread at a later time when traversing async thenCompose,
>> thenAccept.
>> >
>> > thanks,
>> > Dean
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>


-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170522/93547f11/attachment.html>

From jhump at bluegosling.com  Mon May 22 16:01:41 2017
From: jhump at bluegosling.com (Josh Humphries)
Date: Mon, 22 May 2017 16:01:41 -0400
Subject: [concurrency-interest] curious if there is a Local.java in the
 works for CompletableFutures like scala has
In-Reply-To: <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
References: <CAN1v_zrLYFBRHDnnacr0FFx5ZFSx2=R397s59JxCGa_HySYG9Q@mail.gmail.com>
 <45779887-D9E2-463B-948A-458BB6F02CDA@oracle.com>
 <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
Message-ID: <CAO78j+KgCNkP5VxUB-7SYjZ9yjU4bQHgcEi1am3v44eVpmXtHg@mail.gmail.com>

Pavel,
It sounds like you want something like this
<https://github.com/jhump/bluegosling/blob/master/src/com/bluegosling/concurrent/executors/ContextPropagatingExecutor.java>
and this
<https://github.com/jhump/bluegosling/blob/master/src/com/bluegosling/concurrent/executors/ContextPropagator.java#L124>,
and specify the former as the Executor parameter to the CompletionStage
chaining methods. Java 9 adds new overridable methods to CompletableFuture
so that you could sub-class it and override defaultExecutor(), so the
context is always correctly propagated for your sub-classed kind of future.

----
*Josh Humphries*
jhump at bluegosling.com

On Mon, May 22, 2017 at 3:44 PM, Martin Buchholz <martinrb at google.com>
wrote:

> There's not likely to be any support for local context anywhere in
> java.util.concurrent, but it seems not too hard to roll your own support
> with a custom executor to be used with CompletableFuture that kept track of
> any local context.
>
> On Fri, May 19, 2017 at 1:16 PM, Pavel Rappo <pavel.rappo at oracle.com>
> wrote:
>
>> General questions on concurrency in Java should be asked here:
>>
>>    http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> > On 18 May 2017, at 21:57, Dean Hiller <dhiller at twitter.com> wrote:
>> >
>> > Way more detail here...
>> >
>> > http://stackoverflow.com/questions/37933713/does-completable
>> future-have-a-corresponding-local-context
>> >
>> > So I was wondering if this was going to be added at some point to the
>> jdk
>> > as I could not figure out how to set something so it was still
>> available on
>> > the thread at a later time when traversing async thenCompose,
>> thenAccept.
>> >
>> > thanks,
>> > Dean
>>
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170522/c9242112/attachment.html>

From oleksandr.otenko at gmail.com  Tue May 23 05:12:39 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 23 May 2017 10:12:39 +0100
Subject: [concurrency-interest] curious if there is a Local.java in the
	works for CompletableFutures like scala has
In-Reply-To: <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
References: <CAN1v_zrLYFBRHDnnacr0FFx5ZFSx2=R397s59JxCGa_HySYG9Q@mail.gmail.com>
 <45779887-D9E2-463B-948A-458BB6F02CDA@oracle.com>
 <CA+kOe0_HbTZ5UmRZ9KcJShEYQOFejun_LCUMsRJhYebVzU=YmA@mail.gmail.com>
Message-ID: <ABFA075A-BAE6-499F-A9B8-0638B636B9F2@gmail.com>

Why would someone want to rely on state they cannot control?

Is the idea to subvert some API that does not provide a way to pass state? This is strange especially in the context of Scala, where you can easily form tuples.

Alex

> On 22 May 2017, at 20:44, Martin Buchholz <martinrb at google.com> wrote:
> 
> There's not likely to be any support for local context anywhere in java.util.concurrent, but it seems not too hard to roll your own support with a custom executor to be used with CompletableFuture that kept track of any local context.
> 
> On Fri, May 19, 2017 at 1:16 PM, Pavel Rappo <pavel.rappo at oracle.com <mailto:pavel.rappo at oracle.com>> wrote:
> General questions on concurrency in Java should be asked here:
> 
>    http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest <http://altair.cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> > On 18 May 2017, at 21:57, Dean Hiller <dhiller at twitter.com <mailto:dhiller at twitter.com>> wrote:
> >
> > Way more detail here...
> >
> > http://stackoverflow.com/questions/37933713/does-completablefuture-have-a-corresponding-local-context <http://stackoverflow.com/questions/37933713/does-completablefuture-have-a-corresponding-local-context>
> >
> > So I was wondering if this was going to be added at some point to the jdk
> > as I could not figure out how to set something so it was still available on
> > the thread at a later time when traversing async thenCompose, thenAccept.
> >
> > thanks,
> > Dean
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170523/6f26ffd4/attachment-0001.html>

From gergg at cox.net  Tue May 23 16:49:22 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 23 May 2017 15:49:22 -0500
Subject: [concurrency-interest] Queue with interrupt
In-Reply-To: <Mo0R1v01K02hR0p01o0Udt>
References: <591BEA69.9030403@gmx.org>
 <016301d2ced7$42325110$c696f330$@aapt.net.au>
 <baa63233-765f-36c9-8086-6a861b9ac191@gmx.org>
 <017101d2cef0$186e7250$494b56f0$@aapt.net.au>
 <124A3365-D377-494F-AC32-4A15C6AA0B15@oracle.com> <Mo0R1v01K02hR0p01o0Udt>
Message-ID: <6A0E2969-0C3D-4B89-9847-C82A72101374@cox.net>

Many times I use a subclass of one of the queue implementations that I pass a signaling Object to.  That subclass overrides all methods that mutate the state of the queue, and the overriding methods have

	synchronized( lockObj ) {
		super.XXXXX();
		lockObj.notifyAll();
	}

in each of them so that they tell the lock waiters that something has changed.  The lack of a value to account for false signaling can be remedied by using a functional interface to signally instead of the literal Object signaling.

Then, I will also have a timer that fires to signal periodically to the same signal object, perhaps using a secondary signal type.

public interface ActionSignalHandler<E> {
	void QueueModified( SignallingQueue queue );
	void TimerFired( Timer which );
	void WorkCompleted( E work );
}

or some such.   This style of API provides the functionality I need generally when I have one or more queues interactive with one or more timers and have an environment such as Swing/JavaFX/AWT which needs a specific thread type against background tasks managing data values and the occasional ‘ticking’ task needed for progress indication or other change of state recognition or remote service integration.

Gregg

> On May 18, 2017, at 6:56 AM, Viktor Klang <viktor.klang at gmail.com> wrote:
> 
> OTOH, I'd rather avoid Blocking* whenever possible.
> 
> On Thu, May 18, 2017 at 1:43 PM, Chris Hegarty <chris.hegarty at oracle.com <mailto:chris.hegarty at oracle.com>> wrote:
> 
> > On 17 May 2017, at 10:29, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
> >
> > ...
> > If there are tasks in the queue then the worker is not waiting for new tasks to do - so you've changed your requirements. You would need a deque to allow sentinel tasks to be forced to the head of the queue.
> 
> I’ve always wished that we could somehow squeeze a sentinel into the
> implementation in order to provide a “CloseableBlockingQueue” with a
> blocking takeOrNull(), or similarly named, method. Rather than folk having
> to roll their own.
> 
> -Chris.
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 
> 
> -- 
> Cheers,
> √
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170523/4a921c52/attachment.html>

From openjdk at duigou.org  Tue May 23 19:58:40 2017
From: openjdk at duigou.org (Mike Duigou)
Date: Tue, 23 May 2017 16:58:40 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
Message-ID: <e49ebd14d48265128a06ff5558664c36@duigou.org>

Currently the AtomicReference updateAndGet implementation will 
unconditionally perform a compareAndSet using the result of the update 
function.

public final V updateAndGet(UnaryOperator<V> updateFunction) {
   V prev, next;
   do {
     prev = get();
     next = updateFunction.apply(prev);
   } while (!compareAndSet(prev, next));
   return next;
}

I find that I write a lot of update functions which only occasionally 
change the value. For these cases I wonder if it would be reasonable to 
skip the update if the value of next is unchanged from previous. A 
proposed alternative (there are analogues for Integer and Long).

public final V updateAndGet(UnaryOperator<V> updateFunction) {
   V prev, next;
   do {
     prev = get();
     next = updateFunction.apply(prev);
   } while (prev != next && !compareAndSet(prev, next));
   return next;
}

The cases to consider are:

1. prev == value == next :: Nothing changed.

In this case omitting the compareAndSet is a useful optimization. No 
difference for external observer.


2. (prev == value) != next :: Only next changed

In this case the compareAndSet would be performed and succeed as prev == 
value. No difference for external observer.


3. prev != value != next :: Both next and value changed. A concurrent 
modification.

In this case the compareAndSet would be performed and will fail as prev 
!= val. No difference for external observer.


4. (prev == next) != value :: Only value changed. A concurrent 
modification.

In the original implementation the compareAndSet would fail resulting in 
another update attempt. In proposed implementation the compareAndSet 
would not be attempted and the value returned would be unchanged. The 
concurrent modification of value is ignored. Surely this is wrong! It 
appears wrong because some other thread beat us and updated the value. 
The question is whether our thread could tell the difference between the 
call it made to updateAndGet completing first and a concurrent update 
being ignored. Other than via side-effects in updateFunction it does not 
appear that it could. To an external observer this case is 
indistinguishable from the first where there was no concurrent update. 
Even if there is a concurrent update it will appear to callers that 
non-mutating updates always completed first.

Useful? Wrongheaded?

Mike

From davidcholmes at aapt.net.au  Tue May 23 20:12:57 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 24 May 2017 10:12:57 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet()
	mandatory	updating
In-Reply-To: <e49ebd14d48265128a06ff5558664c36@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
Message-ID: <04ad01d2d422$7f901010$7eb03030$@aapt.net.au>

Hi Mike,

What you suggest is too racy. As soon as you call get() the value may change such that you do want to update it - even if back to what it was previously. Only by doing the CAS can you be sure that nothing changed and you truly updated things in the manner expected.

Cheers,
David

> -----Original Message-----
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Mike Duigou
> Sent: Wednesday, May 24, 2017 9:59 AM
> To: Concurrency Interest <concurrency-interest at cs.oswego.edu>
> Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
> 
> Currently the AtomicReference updateAndGet implementation will unconditionally perform a compareAndSet using the result of the
> update function.
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (!compareAndSet(prev, next));
>    return next;
> }
> 
> I find that I write a lot of update functions which only occasionally change the value. For these cases I wonder if it would be reasonable
> to skip the update if the value of next is unchanged from previous. A proposed alternative (there are analogues for Integer and Long).
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (prev != next && !compareAndSet(prev, next));
>    return next;
> }
> 
> The cases to consider are:
> 
> 1. prev == value == next :: Nothing changed.
> 
> In this case omitting the compareAndSet is a useful optimization. No difference for external observer.
> 
> 
> 2. (prev == value) != next :: Only next changed
> 
> In this case the compareAndSet would be performed and succeed as prev ==
> value. No difference for external observer.
> 
> 
> 3. prev != value != next :: Both next and value changed. A concurrent
> modification.
> 
> In this case the compareAndSet would be performed and will fail as prev
> != val. No difference for external observer.
> 
> 
> 4. (prev == next) != value :: Only value changed. A concurrent
> modification.
> 
> In the original implementation the compareAndSet would fail resulting in
> another update attempt. In proposed implementation the compareAndSet
> would not be attempted and the value returned would be unchanged. The
> concurrent modification of value is ignored. Surely this is wrong! It
> appears wrong because some other thread beat us and updated the value.
> The question is whether our thread could tell the difference between the
> call it made to updateAndGet completing first and a concurrent update
> being ignored. Other than via side-effects in updateFunction it does not
> appear that it could. To an external observer this case is
> indistinguishable from the first where there was no concurrent update.
> Even if there is a concurrent update it will appear to callers that
> non-mutating updates always completed first.
> 
> Useful? Wrongheaded?
> 
> Mike
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From dmitry.zaslavsky at gmail.com  Tue May 23 20:20:21 2017
From: dmitry.zaslavsky at gmail.com (Dmitry Zaslavsky)
Date: Tue, 23 May 2017 20:20:21 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet()
 mandatoryupdating
In-Reply-To: <04ad01d2d422$7f901010$7eb03030$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <04ad01d2d422$7f901010$7eb03030$@aapt.net.au>
Message-ID: <5924d1c5.944e370a.7d9a6.aa2d@mx.google.com>

I don’t see how this is more racy than the original code…
As soon as you call compareAndSet() the value might have changed.

I have a place in my code, where this make a significant performance difference on x86.
Volatile read is just a read and a single compare with predicted branch returns most of the time.

Sent from Mail for Windows 10

From: David Holmes
Sent: Tuesday, May 23, 2017 8:16 PM
To: 'Mike Duigou'; 'Concurrency Interest'
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

Hi Mike,

What you suggest is too racy. As soon as you call get() the value may change such that you do want to update it - even if back to what it was previously. Only by doing the CAS can you be sure that nothing changed and you truly updated things in the manner expected.

Cheers,
David

> -----Original Message-----
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Mike Duigou
> Sent: Wednesday, May 24, 2017 9:59 AM
> To: Concurrency Interest <concurrency-interest at cs.oswego.edu>
> Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
> 
> Currently the AtomicReference updateAndGet implementation will unconditionally perform a compareAndSet using the result of the
> update function.
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (!compareAndSet(prev, next));
>    return next;
> }
> 
> I find that I write a lot of update functions which only occasionally change the value. For these cases I wonder if it would be reasonable
> to skip the update if the value of next is unchanged from previous. A proposed alternative (there are analogues for Integer and Long).
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (prev != next && !compareAndSet(prev, next));
>    return next;
> }
> 
> The cases to consider are:
> 
> 1. prev == value == next :: Nothing changed.
> 
> In this case omitting the compareAndSet is a useful optimization. No difference for external observer.
> 
> 
> 2. (prev == value) != next :: Only next changed
> 
> In this case the compareAndSet would be performed and succeed as prev ==
> value. No difference for external observer.
> 
> 
> 3. prev != value != next :: Both next and value changed. A concurrent
> modification.
> 
> In this case the compareAndSet would be performed and will fail as prev
> != val. No difference for external observer.
> 
> 
> 4. (prev == next) != value :: Only value changed. A concurrent
> modification.
> 
> In the original implementation the compareAndSet would fail resulting in
> another update attempt. In proposed implementation the compareAndSet
> would not be attempted and the value returned would be unchanged. The
> concurrent modification of value is ignored. Surely this is wrong! It
> appears wrong because some other thread beat us and updated the value.
> The question is whether our thread could tell the difference between the
> call it made to updateAndGet completing first and a concurrent update
> being ignored. Other than via side-effects in updateFunction it does not
> appear that it could. To an external observer this case is
> indistinguishable from the first where there was no concurrent update.
> Even if there is a concurrent update it will appear to callers that
> non-mutating updates always completed first.
> 
> Useful? Wrongheaded?
> 
> Mike
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170523/2b030afa/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue May 23 20:29:11 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 24 May 2017 10:29:11 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet()
	mandatoryupdating
In-Reply-To: <5924d1c5.944e370a.7d9a6.aa2d@mx.google.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <04ad01d2d422$7f901010$7eb03030$@aapt.net.au>
 <5924d1c5.944e370a.7d9a6.aa2d@mx.google.com>
Message-ID: <04b501d2d424$c41223c0$4c366b40$@aapt.net.au>

The value may change as soon as compareAndSet succeeds but at least you know that the value did not change after the get() and you did not miss an update that you should have “corrected”. Obviously depending on how you use this API this may be a non-issue, but the API doesn’t know your usecase.

 

David

 

From: Dmitry Zaslavsky [mailto:dmitry.zaslavsky at gmail.com] 
Sent: Wednesday, May 24, 2017 10:20 AM
To: dholmes at ieee.org; 'Mike Duigou' <openjdk at duigou.org>; 'Concurrency Interest' <concurrency-interest at cs.oswego.edu>
Subject: RE: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

 

I don’t see how this is more racy than the original code…

As soon as you call compareAndSet() the value might have changed.

 

I have a place in my code, where this make a significant performance difference on x86.

Volatile read is just a read and a single compare with predicted branch returns most of the time.

 

Sent from Mail <https://go.microsoft.com/fwlink/?LinkId=550986>  for Windows 10

 

From: David Holmes <mailto:davidcholmes at aapt.net.au> 
Sent: Tuesday, May 23, 2017 8:16 PM
To: 'Mike Duigou' <mailto:openjdk at duigou.org> ; 'Concurrency Interest' <mailto:concurrency-interest at cs.oswego.edu> 
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

 

Hi Mike,

 

What you suggest is too racy. As soon as you call get() the value may change such that you do want to update it - even if back to what it was previously. Only by doing the CAS can you be sure that nothing changed and you truly updated things in the manner expected.

 

Cheers,

David

 

> -----Original Message-----

> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Mike Duigou

> Sent: Wednesday, May 24, 2017 9:59 AM

> To: Concurrency Interest <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> >

> Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

> 

> Currently the AtomicReference updateAndGet implementation will unconditionally perform a compareAndSet using the result of the

> update function.

> 

> public final V updateAndGet(UnaryOperator<V> updateFunction) {

>    V prev, next;

>    do {

>      prev = get();

>      next = updateFunction.apply(prev);

>    } while (!compareAndSet(prev, next));

>    return next;

> }

> 

> I find that I write a lot of update functions which only occasionally change the value. For these cases I wonder if it would be reasonable

> to skip the update if the value of next is unchanged from previous. A proposed alternative (there are analogues for Integer and Long).

> 

> public final V updateAndGet(UnaryOperator<V> updateFunction) {

>    V prev, next;

>    do {

>      prev = get();

>      next = updateFunction.apply(prev);

>    } while (prev != next && !compareAndSet(prev, next));

>    return next;

> }

> 

> The cases to consider are:

> 

> 1. prev == value == next :: Nothing changed.

> 

> In this case omitting the compareAndSet is a useful optimization. No difference for external observer.

> 

> 

> 2. (prev == value) != next :: Only next changed

> 

> In this case the compareAndSet would be performed and succeed as prev ==

> value. No difference for external observer.

> 

> 

> 3. prev != value != next :: Both next and value changed. A concurrent

> modification.

> 

> In this case the compareAndSet would be performed and will fail as prev

> != val. No difference for external observer.

> 

> 

> 4. (prev == next) != value :: Only value changed. A concurrent

> modification.

> 

> In the original implementation the compareAndSet would fail resulting in

> another update attempt. In proposed implementation the compareAndSet

> would not be attempted and the value returned would be unchanged. The

> concurrent modification of value is ignored. Surely this is wrong! It

> appears wrong because some other thread beat us and updated the value.

> The question is whether our thread could tell the difference between the

> call it made to updateAndGet completing first and a concurrent update

> being ignored. Other than via side-effects in updateFunction it does not

> appear that it could. To an external observer this case is

> indistinguishable from the first where there was no concurrent update.

> Even if there is a concurrent update it will appear to callers that

> non-mutating updates always completed first.

> 

> Useful? Wrongheaded?

> 

> Mike

> _______________________________________________

> Concurrency-interest mailing list

> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 

> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170524/03685481/attachment.html>

From rl.stpuu at gmail.com  Tue May 23 20:31:17 2017
From: rl.stpuu at gmail.com (Roussanka Loukanova)
Date: Wed, 24 May 2017 02:31:17 +0200
Subject: [concurrency-interest] CfP: LACompLing2017 Extended Deadline: *
	June 9, 2017 *
Message-ID: <CACAe74gJkwpSWuA2C1PpaCYoKrd=BKDjFXQ8jxAYrxmOk5m2Kg@mail.gmail.com>

                            CALL FOR PAPERS
              * Extended submission deadline *
                           *** June 9, 2017 ***
          for papers and abstracts (due to requests)
=================================================
                               Workshop on
Logic and Algorithms in Computational Linguistics 2017 (LACompLing2017)
                   Stockholm, August 16-19, 2017

        http://staff.math.su.se/rloukanova/LACompLing17.html

================================================
                      Affiliated with the
26th Annual EACSL Conference on Computer Science Logic CSL'2017
                   Stockholm, 20--26 August 2017

                     Co-located with:
               Logic in Stockholm 2017
https://www.math-stockholm.se/en/konferenser-och-akti/logic-in-stockholm-2
=================================================

DESCRIPTION
==
Computational linguistics studies natural language in its various
manifestations from a computational point of view, both on the theoretical
level (modeling grammar modules dealing with natural language form and
meaning, and the relation between these two) and on the practical level
(developing applications for language and speech technology). Right from
the start in the 1950ties, there have been strong links with computer
science, logic, and many areas of mathematics - one can think of Chomsky's
contributions to the theory of formal languages and automata, or Lambek's
logical modeling of natural language syntax. The workshop assesses the
place of logic, mathematics, and computer science in present day
computational linguistics. It intends to be a forum for presenting new
results as well as work in progress.
--------------------------------

SCOPE
==
The workshop focuses mainly on logical approaches to computational
processing of natural language, and on the applicability of methods and
techniques from the study of artificial languages (programming/logic) in
computational linguistics. We invite participation and submissions from
other relevant approaches too, especially if they can inspire new work and
approaches.

The topics of LACompLing2017 include, but are not limited to:

- Computational theories of human language
- Computational syntax
- Computational semantics
- Computational syntax-semantics interface
- Interfaces between morphology, lexicon, syntax, semantics, speech, text,
pragmatics
- Computational grammar
- Logic and reasoning systems for linguistics
- Type theories for linguistics
- Models of computation and algorithms for linguistics
- Language processing
- Parsing algorithms
- Generation of language from semantic representations
- Large-scale grammars of natural languages
- Multilingual processing
- Data science in language processing
- Machine learning of language
- Interdisciplinary methods
- Integration of formal, computational, model theoretic, graphical,
diagrammatic, statistical, and other related methods
- Logic for information extraction or expression in written and spoken
language
- Language theories based on biological fundamentals of information and
languages
- Computational neuroscience of language

IMPORTANT DATES
==
Submission deadline for regular papers: ** June 9 (any time on Earth), 2017
**
Abstracts of short presentations:  ** June 9 (any time on Earth), 2017 **
Notification of acceptance: June 15, 2017
Deadline for final submissions: June 25, 2017
Workshop: August 16-19, 2017

SUBMISSION INSTRUCTIONS
==
- Regular papers: between 10-15 pages, including figures and references, by
using LaTeX, with article.sty:
\documentclass[a4paper,11pt]{article}

- Abstracts of short presentations: not more than 1 page, by using LaTeX,
with article.sty:
\documentclass[a4paper,11pt]{article}

- We invite original papers that are not submitted concurrently to another
conference or for publication elsewhere

- The submissions of proposed papers and abstracts of short presentations
have to be in pdf

- The camera-ready submissions require the pdf of the papers and their
LaTeX sources

The submissions are via the EasyChair management system of LACompLing2017:

https://easychair.org/conferences/?conf=lacompling2017

PUBLICATIONS
==
- The proceedings of LACompLing2017 will be published digitally by the DiVA
system of Stockholm University:
http://su.diva-portal.org

- Improved and extended versions of selected papers, which have been
presented at the workshop LACompLing2017, will be published by the Journal
of Logic, Language and Information, JoLLI, after the workshop.

FEATURED INVITED SPEAKERS
==
Lucas Champollion, New York University, USA
Robin Cooper, University of Gothenburg, Sweden
Ann Copestake, University of Cambridge, UK
Fredrik Engström, University of Gothenburg, Sweden
Gintare Grigonyte, Stockholm University, Sweden
Lars Hellan, Norwegian University of Science and Technology, Norway
Valia Kordoni, Humboldt University Berlin, Germany
Henriette de Swart, Utrecht Institute of Linguistics OTS - Language, logic
and information, The Netherlands
Nikola Kompa, University of Osnabrück, Germany
Torbjörn Lager, University of Gothenburg, Sweden
Staffan Larsson, University of Gothenburg, Sweden
Louise McNally, Universitat Pompeu Fabra, Spain
Richard Moot, CNRS, France
Glyn Morrill, Universitat Politècnica de Catalunya, Spain
Joakim Nivre, Uppsala University, Sweden
Rainer Osswald, Heinrich-Heine-Universität Düsseldorf, Germany
Peter Pagin, Stockholm University, Sweden
Gerald Penn, University of Toronto, Canada
Sam Sanders, Ludwig-Maximilian-University of Munich, Germany
Mila Vulchanova,  Norwegian University of Science and Technology, Norway
Markus Werning, Ruhr University Bochum, Germany
and more ...

ORGANIZERS
==
Krasimir Angelov, University of Gothenburg, Sweden
Valeria de Paiva, Nuance Communications, USA
Kristina Liefke, Ludwig-Maximilians-University Munich, Germany
Roussanka Loukanova, Stockholm University, Sweden (chair)
Michael Moortgat, Utrecht University, The Netherlands
Reinhard Muskens, Tilburg University, The Netherlands

CONTACT
==
Roussanka Loukanova (rloukanova at gmail.com)
Valeria de Paiva (valeria.depaiva at gmail.com)
--------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170524/38febc9e/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue May 23 20:47:58 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 24 May 2017 10:47:58 +1000
Subject: [concurrency-interest]
	AtomicReference.updateAndGet()	mandatoryupdating
In-Reply-To: <04b501d2d424$c41223c0$4c366b40$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <04ad01d2d422$7f901010$7eb03030$@aapt.net.au>
 <5924d1c5.944e370a.7d9a6.aa2d@mx.google.com>
 <04b501d2d424$c41223c0$4c366b40$@aapt.net.au>
Message-ID: <04c401d2d427$6451ef30$2cf5cd90$@aapt.net.au>

No you are right – the difference in behavior is not observable (except perhaps by the updateFunction – which would be odd in itself).

 

I’m used to cases where there will always be a change in value. 😊

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of David Holmes
Sent: Wednesday, May 24, 2017 10:29 AM
To: 'Dmitry Zaslavsky' <dmitry.zaslavsky at gmail.com>; 'Mike Duigou' <openjdk at duigou.org>; 'Concurrency Interest' <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

 

The value may change as soon as compareAndSet succeeds but at least you know that the value did not change after the get() and you did not miss an update that you should have “corrected”. Obviously depending on how you use this API this may be a non-issue, but the API doesn’t know your usecase.

 

David

 

From: Dmitry Zaslavsky [mailto:dmitry.zaslavsky at gmail.com] 
Sent: Wednesday, May 24, 2017 10:20 AM
To: dholmes at ieee.org <mailto:dholmes at ieee.org> ; 'Mike Duigou' <openjdk at duigou.org <mailto:openjdk at duigou.org> >; 'Concurrency Interest' <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> >
Subject: RE: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

 

I don’t see how this is more racy than the original code…

As soon as you call compareAndSet() the value might have changed.

 

I have a place in my code, where this make a significant performance difference on x86.

Volatile read is just a read and a single compare with predicted branch returns most of the time.

 

Sent from Mail <https://go.microsoft.com/fwlink/?LinkId=550986>  for Windows 10

 

From: David Holmes <mailto:davidcholmes at aapt.net.au> 
Sent: Tuesday, May 23, 2017 8:16 PM
To: 'Mike Duigou' <mailto:openjdk at duigou.org> ; 'Concurrency Interest' <mailto:concurrency-interest at cs.oswego.edu> 
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatoryupdating

 

Hi Mike,

 

What you suggest is too racy. As soon as you call get() the value may change such that you do want to update it - even if back to what it was previously. Only by doing the CAS can you be sure that nothing changed and you truly updated things in the manner expected.

 

Cheers,

David

 

> -----Original Message-----

> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Mike Duigou

> Sent: Wednesday, May 24, 2017 9:59 AM

> To: Concurrency Interest <concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> >

> Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

> 

> Currently the AtomicReference updateAndGet implementation will unconditionally perform a compareAndSet using the result of the

> update function.

> 

> public final V updateAndGet(UnaryOperator<V> updateFunction) {

>    V prev, next;

>    do {

>      prev = get();

>      next = updateFunction.apply(prev);

>    } while (!compareAndSet(prev, next));

>    return next;

> }

> 

> I find that I write a lot of update functions which only occasionally change the value. For these cases I wonder if it would be reasonable

> to skip the update if the value of next is unchanged from previous. A proposed alternative (there are analogues for Integer and Long).

> 

> public final V updateAndGet(UnaryOperator<V> updateFunction) {

>    V prev, next;

>    do {

>      prev = get();

>      next = updateFunction.apply(prev);

>    } while (prev != next && !compareAndSet(prev, next));

>    return next;

> }

> 

> The cases to consider are:

> 

> 1. prev == value == next :: Nothing changed.

> 

> In this case omitting the compareAndSet is a useful optimization. No difference for external observer.

> 

> 

> 2. (prev == value) != next :: Only next changed

> 

> In this case the compareAndSet would be performed and succeed as prev ==

> value. No difference for external observer.

> 

> 

> 3. prev != value != next :: Both next and value changed. A concurrent

> modification.

> 

> In this case the compareAndSet would be performed and will fail as prev

> != val. No difference for external observer.

> 

> 

> 4. (prev == next) != value :: Only value changed. A concurrent

> modification.

> 

> In the original implementation the compareAndSet would fail resulting in

> another update attempt. In proposed implementation the compareAndSet

> would not be attempted and the value returned would be unchanged. The

> concurrent modification of value is ignored. Surely this is wrong! It

> appears wrong because some other thread beat us and updated the value.

> The question is whether our thread could tell the difference between the

> call it made to updateAndGet completing first and a concurrent update

> being ignored. Other than via side-effects in updateFunction it does not

> appear that it could. To an external observer this case is

> indistinguishable from the first where there was no concurrent update.

> Even if there is a concurrent update it will appear to callers that

> non-mutating updates always completed first.

> 

> Useful? Wrongheaded?

> 

> Mike

> _______________________________________________

> Concurrency-interest mailing list

> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 

> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________

Concurrency-interest mailing list

Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 

http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170524/f2a13b9b/attachment.html>

From aph at redhat.com  Wed May 24 04:23:15 2017
From: aph at redhat.com (Andrew Haley)
Date: Wed, 24 May 2017 09:23:15 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <e49ebd14d48265128a06ff5558664c36@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
Message-ID: <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>

On 24/05/17 00:58, Mike Duigou wrote:
> I find that I write a lot of update functions which only occasionally 
> change the value. For these cases I wonder if it would be reasonable to 
> skip the update if the value of next is unchanged from previous. 

I don't think so, because the update has the effect of a volatile
write.  If you skip the update you lose the happens-before ordering
of that write.

Andrew.

From jsampson at guidewire.com  Wed May 24 15:38:35 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Wed, 24 May 2017 19:38:35 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
Message-ID: <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>

Andrew Haley wrote:
> Mike Duigou wrote:
> > I find that I write a lot of update functions which only occasionally
> > change the value. For these cases I wonder if it would be reasonable to
> > skip the update if the value of next is unchanged from previous.
>
> I don't think so, because the update has the effect of a volatile
> write. If you skip the update you lose the happens-before ordering
> of that write.

That's strictly true (the memory barriers come out different), but no
algorithm could actually rely on the difference. The reading thread can't
tell if it's reading after the write (and therefore can depend on the
happens-before) or reading before the write (and therefore cannot), since
it sees the same value in either case.

This kind of optimization is already done in some places in the JDK, such
as AtomicStampedReference and AtomicMarkableReference, both of which skip
the write if the current value is already equal to the new value in set(),
compareAndSet(), etc.

Cheers,
Justin


From openjdk at duigou.org  Wed May 24 17:50:50 2017
From: openjdk at duigou.org (Mike Duigou)
Date: Wed, 24 May 2017 14:50:50 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
Message-ID: <2b791c10538264930c33034b97218e77@duigou.org>

That's my view of this optimization as well; the writes that occur do 
change but only in ways that nobody should be able to rely upon. 
Assuming the proposed change to getAndUpdate seemed reasonable to folks 
I planned to next suggest:

replace:

public final boolean compareAndSet(V expect, V update) {
    return unsafe.compareAndSwapObject(this, valueOffset, expect, 
update);
}

with:

public final boolean compareAndSet(V expect, V update) {
     return expect != update
        ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
        : expect != value ? false : true;
}

For both the proposed updateAndGet and compareAndSet the goal is to 
avoid expensive volatile writes when the value is not actually changing.

Mike

On 2017-05-24 12:38, Justin Sampson wrote:
> Andrew Haley wrote:
>> Mike Duigou wrote:
>> > I find that I write a lot of update functions which only occasionally
>> > change the value. For these cases I wonder if it would be reasonable to
>> > skip the update if the value of next is unchanged from previous.
>> 
>> I don't think so, because the update has the effect of a volatile
>> write. If you skip the update you lose the happens-before ordering
>> of that write.
> 
> That's strictly true (the memory barriers come out different), but no
> algorithm could actually rely on the difference. The reading thread 
> can't
> tell if it's reading after the write (and therefore can depend on the
> happens-before) or reading before the write (and therefore cannot), 
> since
> it sees the same value in either case.
> 
> This kind of optimization is already done in some places in the JDK, 
> such
> as AtomicStampedReference and AtomicMarkableReference, both of which 
> skip
> the write if the current value is already equal to the new value in 
> set(),
> compareAndSet(), etc.
> 
> Cheers,
> Justin

From gergg at cox.net  Wed May 24 18:21:19 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Wed, 24 May 2017 17:21:19 -0500
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <QMud1v01l02hR0p01MueF1>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com> <QMud1v01l02hR0p01MueF1>
Message-ID: <BE4641EB-6621-4C5C-BD6E-270F8CABBB0D@cox.net>

One of the things that ends up happening, is that people to start trying to do the optimizations that you are doing here, in their own code, knowing what other fences are guaranteed to be happening.  As soon as you make this a conditional fence, you force the user to always use their own fence if they were relying on this fence, and now they have two fences that are dropped when they only ever needed one.  And, if you force them to wrap this operation into an object that can mediate the details of whether or not a fence was actually encountered in the actions of the API, they are recreating exactly the logic you have in your code, and then they will simply be prepared to just go ahead and skip out on providing the JRE provided implementation because it is now a barrier to simple programming models that have simple, dependable behavior.

At some level, there is only so many optimizations that should be done behind the users back.  Surprises like this with disappearing fences will suddenly break a lot of software for nearly unexplainable reasons without deep dives into implementation details and other nuances of behavior which just used to work because the fence was always there.

To put this another way, if the runtime environment is ever going to provide fences than the circumstance of doing that or not doing that should be completely controllable by the developer so that there are no surprises and no change in correctness happening because of things like this going on behind the scenes.

Gregg

> On May 24, 2017, at 4:50 PM, Mike Duigou <openjdk at duigou.org> wrote:
> 
> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
> 
> replace:
> 
> public final boolean compareAndSet(V expect, V update) {
>   return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
> }
> 
> with:
> 
> public final boolean compareAndSet(V expect, V update) {
>    return expect != update
>       ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>       : expect != value ? false : true;
> }
> 
> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
> 
> Mike
> 
> On 2017-05-24 12:38, Justin Sampson wrote:
>> Andrew Haley wrote:
>>> Mike Duigou wrote:
>>> > I find that I write a lot of update functions which only occasionally
>>> > change the value. For these cases I wonder if it would be reasonable to
>>> > skip the update if the value of next is unchanged from previous.
>>> I don't think so, because the update has the effect of a volatile
>>> write. If you skip the update you lose the happens-before ordering
>>> of that write.
>> That's strictly true (the memory barriers come out different), but no
>> algorithm could actually rely on the difference. The reading thread can't
>> tell if it's reading after the write (and therefore can depend on the
>> happens-before) or reading before the write (and therefore cannot), since
>> it sees the same value in either case.
>> This kind of optimization is already done in some places in the JDK, such
>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>> the write if the current value is already equal to the new value in set(),
>> compareAndSet(), etc.
>> Cheers,
>> Justin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gil at azul.com  Wed May 24 18:33:27 2017
From: gil at azul.com (Gil Tene)
Date: Wed, 24 May 2017 22:33:27 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <2b791c10538264930c33034b97218e77@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
Message-ID: <5D953E8B-8AF7-4BA2-BC64-CC43B3E8734B@azul.com>

The memory semantics of updateAndGet() need to be captured in its JavaDoc. In this sense it is no different from compareAndSet(), which currently defines the memory semantics:

http://download.java.net/java/jdk9/docs/api/java/util/concurrent/atomic/AtomicReference.html#compareAndSet-V-V- says:
"Atomically sets the value to newValue if the current value == expectedValue, with memory effects as specified by VarHandle.compareAndSet(java.lang.Object…)."

and under compareAndSet in VarHandle (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html#compareAndSet-java.lang.Object…- ) it currently says:
"Atomically sets the value of a variable to the newValue with the memory semantics of setVolatile(java.lang.Object...) if the variable's current value, referred to as the witness value, == the expectedValue, as accessed with the memory semantics of getVolatile(java.lang.Object…)."

However, 
http://download.java.net/java/jdk9/docs/api/java/util/concurrent/atomic/AtomicReference.html#updateAndGet-java.util.function.UnaryOperator- says nothing about the memory semantics. It should. And it should probably say it either like this:

"Atomically updates the current value with the results of applying the given function with memory semntics of VarHandle.setVolatile(java.lang.Object..), returning the updated value, as accessed with the memory semantics of getVolatile(java.lang.Object…). The function should be side-effect-free, since it may be re-applied when attempted updates fail due to contention among threads."

or like this:

"Atomically updates the current value with the results of applying the given function with memory semntics of VarHandle.setVolatile(java.lang.Object..) if the variable's current value, referred to as the witness value, != the existing value, as accessed with the memory semantics of getVolatile(java.lang.Object…), returning the updated value. The function should be side-effect-free, since it may be re-applied when attempted updates fail due to contention among threads."

The choice between the two above definitions will determine whether or not the suggested optimization is allowed...

Once could argue that the backwards compatible (with java 8) version would be the first form (i.e. always equivalent to both a volatile write and a volatile read), since the Java 8 semantics are defined that way for all of of j.u.c.atomic ((https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html): "… 	• compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables. ". However, since Java 9 seems to be relaxing the semantics for compareAndSet() [in an arguably not-fully-compatible way, since the new Java 9 compareAndSet semantics are somewhat weaker], we can/should do that consistently across the board.

In any case, all of the various atomic operations *should* have defined memory semantics. These used to be globally captured in the j.u.c.atomic JavaDoc in Java 8. But with Java 9, the memory semantics notes were removed from j.u.c.atomic and are "punted" by most individual method definitions to VarHandle. However, this punting is not universal, and arguably leaves the memory semantics of several operations in j.u.c.atomic classes unspecified, including getAndUpdate, upodateAndGet, getAndAccumulate, accumulateAndGet [all of which did have a defined memory semantics behavior in Java 8, since they all fit under the "...all other read-and-update.." catchall in j.u.c.atomic].

— Gil.

> On May 24, 2017, at 2:50 PM, Mike Duigou <openjdk at duigou.org> wrote:
> 
> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
> 
> replace:
> 
> public final boolean compareAndSet(V expect, V update) {
>   return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
> }
> 
> with:
> 
> public final boolean compareAndSet(V expect, V update) {
>    return expect != update
>       ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>       : expect != value ? false : true;
> }
> 
> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
> 
> Mike
> 
> On 2017-05-24 12:38, Justin Sampson wrote:
>> Andrew Haley wrote:
>>> Mike Duigou wrote:
>>> > I find that I write a lot of update functions which only occasionally
>>> > change the value. For these cases I wonder if it would be reasonable to
>>> > skip the update if the value of next is unchanged from previous.
>>> I don't think so, because the update has the effect of a volatile
>>> write. If you skip the update you lose the happens-before ordering
>>> of that write.
>> That's strictly true (the memory barriers come out different), but no
>> algorithm could actually rely on the difference. The reading thread can't
>> tell if it's reading after the write (and therefore can depend on the
>> happens-before) or reading before the write (and therefore cannot), since
>> it sees the same value in either case.
>> This kind of optimization is already done in some places in the JDK, such
>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>> the write if the current value is already equal to the new value in set(),
>> compareAndSet(), etc.
>> Cheers,
>> Justin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From bronee at gmail.com  Wed May 24 18:51:16 2017
From: bronee at gmail.com (Brian S O'Neill)
Date: Wed, 24 May 2017 15:51:16 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <e49ebd14d48265128a06ff5558664c36@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
Message-ID: <418d1a55-59e9-0c9a-81a3-26d905645a78@gmail.com>

Have you had a chance to take a look at the Java 9 version of this method?

     public final V updateAndGet(UnaryOperator<V> updateFunction) {
         V prev = get(), next = null;
         for (boolean haveNext = false;;) {
             if (!haveNext)
                 next = updateFunction.apply(prev);
             if (weakCompareAndSetVolatile(prev, next))
                 return next;
             haveNext = (prev == (prev = get()));
         }
     }

It doesn't omit the CAS, but it does omit calling the function 
needlessly if prev hasn't changed. I wonder what effect the weak CAS 
has. For which platforms does it make a difference?


On 2017-05-23 04:58 PM, Mike Duigou wrote:
> Currently the AtomicReference updateAndGet implementation will 
> unconditionally perform a compareAndSet using the result of the update 
> function.
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (!compareAndSet(prev, next));
>    return next;
> }
> 
> I find that I write a lot of update functions which only occasionally 
> change the value. For these cases I wonder if it would be reasonable to 
> skip the update if the value of next is unchanged from previous. A 
> proposed alternative (there are analogues for Integer and Long).
> 
> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>    V prev, next;
>    do {
>      prev = get();
>      next = updateFunction.apply(prev);
>    } while (prev != next && !compareAndSet(prev, next));
>    return next;
> }
> 
> The cases to consider are:
> 
> 1. prev == value == next :: Nothing changed.
> 
> In this case omitting the compareAndSet is a useful optimization. No 
> difference for external observer.
> 
> 
> 2. (prev == value) != next :: Only next changed
> 
> In this case the compareAndSet would be performed and succeed as prev == 
> value. No difference for external observer.
> 
> 
> 3. prev != value != next :: Both next and value changed. A concurrent 
> modification.
> 
> In this case the compareAndSet would be performed and will fail as prev 
> != val. No difference for external observer.
> 
> 
> 4. (prev == next) != value :: Only value changed. A concurrent 
> modification.
> 
> In the original implementation the compareAndSet would fail resulting in 
> another update attempt. In proposed implementation the compareAndSet 
> would not be attempted and the value returned would be unchanged. The 
> concurrent modification of value is ignored. Surely this is wrong! It 
> appears wrong because some other thread beat us and updated the value. 
> The question is whether our thread could tell the difference between the 
> call it made to updateAndGet completing first and a concurrent update 
> being ignored. Other than via side-effects in updateFunction it does not 
> appear that it could. To an external observer this case is 
> indistinguishable from the first where there was no concurrent update. 
> Even if there is a concurrent update it will appear to callers that 
> non-mutating updates always completed first.
> 
> Useful? Wrongheaded?
> 
> Mike
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From gil at azul.com  Wed May 24 21:01:25 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 25 May 2017 01:01:25 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <418d1a55-59e9-0c9a-81a3-26d905645a78@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <418d1a55-59e9-0c9a-81a3-26d905645a78@gmail.com>
Message-ID: <734F91C7-6C91-495B-B8E1-7082552A846D@azul.com>


> On May 24, 2017, at 3:51 PM, Brian S O'Neill <bronee at gmail.com> wrote:
> 
> Have you had a chance to take a look at the Java 9 version of this method?
> 
>    public final V updateAndGet(UnaryOperator<V> updateFunction) {
>        V prev = get(), next = null;
>        for (boolean haveNext = false;;) {
>            if (!haveNext)
>                next = updateFunction.apply(prev);
>            if (weakCompareAndSetVolatile(prev, next))
>                return next;
>            haveNext = (prev == (prev = get()));
>        }
>    }
> 
> It doesn't omit the CAS, but it does omit calling the function needlessly if prev hasn't changed. I wonder what effect the weak CAS has. For which platforms does it make a difference?

The weak CAS is allowed to spuriously fail (i.e. fail even when the the expected value matches). On architectures that do not directly support a non-spuriously-failing CAS in hardware (e.g. architectures that only have LL/SC variants, such as ARM pre-v8, and some PowerPC and MIPS, etc.) this is cheaper to implement than a proper CAS. 

> 
> 
> On 2017-05-23 04:58 PM, Mike Duigou wrote:
>> Currently the AtomicReference updateAndGet implementation will unconditionally perform a compareAndSet using the result of the update function.
>> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>>   V prev, next;
>>   do {
>>     prev = get();
>>     next = updateFunction.apply(prev);
>>   } while (!compareAndSet(prev, next));
>>   return next;
>> }
>> I find that I write a lot of update functions which only occasionally change the value. For these cases I wonder if it would be reasonable to skip the update if the value of next is unchanged from previous. A proposed alternative (there are analogues for Integer and Long).
>> public final V updateAndGet(UnaryOperator<V> updateFunction) {
>>   V prev, next;
>>   do {
>>     prev = get();
>>     next = updateFunction.apply(prev);
>>   } while (prev != next && !compareAndSet(prev, next));
>>   return next;
>> }
>> The cases to consider are:
>> 1. prev == value == next :: Nothing changed.
>> In this case omitting the compareAndSet is a useful optimization. No difference for external observer.
>> 2. (prev == value) != next :: Only next changed
>> In this case the compareAndSet would be performed and succeed as prev == value. No difference for external observer.
>> 3. prev != value != next :: Both next and value changed. A concurrent modification.
>> In this case the compareAndSet would be performed and will fail as prev != val. No difference for external observer.
>> 4. (prev == next) != value :: Only value changed. A concurrent modification.
>> In the original implementation the compareAndSet would fail resulting in another update attempt. In proposed implementation the compareAndSet would not be attempted and the value returned would be unchanged. The concurrent modification of value is ignored. Surely this is wrong! It appears wrong because some other thread beat us and updated the value. The question is whether our thread could tell the difference between the call it made to updateAndGet completing first and a concurrent update being ignored. Other than via side-effects in updateFunction it does not appear that it could. To an external observer this case is indistinguishable from the first where there was no concurrent update. Even if there is a concurrent update it will appear to callers that non-mutating updates always completed first.
>> Useful? Wrongheaded?
>> Mike
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Thu May 25 03:35:09 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 08:35:09 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <2b791c10538264930c33034b97218e77@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
Message-ID: <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>

This is a bad idea.

Now there is no guarantee that the synchronizes-with edge exists.

Alex

> On 24 May 2017, at 22:50, Mike Duigou <openjdk at duigou.org> wrote:
> 
> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
> 
> replace:
> 
> public final boolean compareAndSet(V expect, V update) {
>   return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
> }
> 
> with:
> 
> public final boolean compareAndSet(V expect, V update) {
>    return expect != update
>       ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>       : expect != value ? false : true;
> }
> 
> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
> 
> Mike
> 
> On 2017-05-24 12:38, Justin Sampson wrote:
>> Andrew Haley wrote:
>>> Mike Duigou wrote:
>>> > I find that I write a lot of update functions which only occasionally
>>> > change the value. For these cases I wonder if it would be reasonable to
>>> > skip the update if the value of next is unchanged from previous.
>>> I don't think so, because the update has the effect of a volatile
>>> write. If you skip the update you lose the happens-before ordering
>>> of that write.
>> That's strictly true (the memory barriers come out different), but no
>> algorithm could actually rely on the difference. The reading thread can't
>> tell if it's reading after the write (and therefore can depend on the
>> happens-before) or reading before the write (and therefore cannot), since
>> it sees the same value in either case.
>> This kind of optimization is already done in some places in the JDK, such
>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>> the write if the current value is already equal to the new value in set(),
>> compareAndSet(), etc.
>> Cheers,
>> Justin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gil at azul.com  Thu May 25 04:16:33 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 25 May 2017 08:16:33 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
Message-ID: <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>


> On May 25, 2017, at 12:35 AM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> This is a bad idea.
> 
> Now there is no guarantee that the synchronizes-with edge exists.

The current Java 9 specification (in the JavaDoc) of AtomicReference.updateAndGet() doesn't say there is such an edge (the Java 8 one did, but the current Java 9 one doesn't). So this is valid with the current spec'ed behavior. The spec is probably wrong and should be changed to document the expected memory semantics in any case, and depending on what those are, the suggested optimization will either be ok or wrong to do.

> 
> Alex
> 
>> On 24 May 2017, at 22:50, Mike Duigou <openjdk at duigou.org> wrote:
>> 
>> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
>> 
>> replace:
>> 
>> public final boolean compareAndSet(V expect, V update) {
>>  return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
>> }
>> 
>> with:
>> 
>> public final boolean compareAndSet(V expect, V update) {
>>   return expect != update
>>      ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>>      : expect != value ? false : true;
>> }
>> 
>> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
>> 
>> Mike
>> 
>> On 2017-05-24 12:38, Justin Sampson wrote:
>>> Andrew Haley wrote:
>>>> Mike Duigou wrote:
>>>>> I find that I write a lot of update functions which only occasionally
>>>>> change the value. For these cases I wonder if it would be reasonable to
>>>>> skip the update if the value of next is unchanged from previous.
>>>> I don't think so, because the update has the effect of a volatile
>>>> write. If you skip the update you lose the happens-before ordering
>>>> of that write.
>>> That's strictly true (the memory barriers come out different), but no
>>> algorithm could actually rely on the difference. The reading thread can't
>>> tell if it's reading after the write (and therefore can depend on the
>>> happens-before) or reading before the write (and therefore cannot), since
>>> it sees the same value in either case.
>>> This kind of optimization is already done in some places in the JDK, such
>>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>>> the write if the current value is already equal to the new value in set(),
>>> compareAndSet(), etc.
>>> Cheers,
>>> Justin
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Thu May 25 04:23:28 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 09:23:28 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
Message-ID: <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>

How quickly you arrived at “no algorithm whatsoever”! :-)

x=1;
y.compareAndSet(e,v)

Under assumption that there are infinitely many volatile reads of y, the return from compareAndSet is a witness that there exists a read in the future that synchronizes-with this invocation of compareAndSet.

You cannot argue that sometimes you can skip the volatile store semantics on what would be a successful compareAndSet - because then the stores preceding compareAndSet are not guaranteed to be visible - ever. This optimization is a platform-specific decision.


You can argue about what happens if compareAndSet fails. My take is it should still have volatile store semantics - ie should be equivalent to the store of the value that is already there, so it appears unmodified, but synchronizes-with edges can be established.


Alex

> On 24 May 2017, at 20:38, Justin Sampson <jsampson at guidewire.com> wrote:
> 
> Andrew Haley wrote:
>> Mike Duigou wrote:
>>> I find that I write a lot of update functions which only occasionally
>>> change the value. For these cases I wonder if it would be reasonable to
>>> skip the update if the value of next is unchanged from previous.
>> 
>> I don't think so, because the update has the effect of a volatile
>> write. If you skip the update you lose the happens-before ordering
>> of that write.
> 
> That's strictly true (the memory barriers come out different), but no
> algorithm could actually rely on the difference. The reading thread can't
> tell if it's reading after the write (and therefore can depend on the
> happens-before) or reading before the write (and therefore cannot), since
> it sees the same value in either case.
> 
> This kind of optimization is already done in some places in the JDK, such
> as AtomicStampedReference and AtomicMarkableReference, both of which skip
> the write if the current value is already equal to the new value in set(),
> compareAndSet(), etc.
> 
> Cheers,
> Justin
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Thu May 25 04:30:08 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 09:30:08 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
Message-ID: <8F7BF45B-CD45-4AF7-A184-CDF4ADDB3EC4@gmail.com>

Yes, your quote is a rather weak guarantee. That’s a shame.

The API should provide strong guarantees. Those who want them weaker, should do their own checks. eg expected == stored value is easy to test to skip compareAndSet call, but is not easy (if possible at all!) to enforce a strong guarantee, if the API is unable to provide one: how do I make sure the edge exists, without ruining the value?

Besides, the old implementation of getAndSet() used to invoke compareAndSet() inside. That’s another very subtle gotcha.


Alex


> On 25 May 2017, at 09:16, Gil Tene <gil at azul.com> wrote:
> 
> 
>> On May 25, 2017, at 12:35 AM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>> 
>> This is a bad idea.
>> 
>> Now there is no guarantee that the synchronizes-with edge exists.
> 
> The current Java 9 specification (in the JavaDoc) of AtomicReference.updateAndGet() doesn't say there is such an edge (the Java 8 one did, but the current Java 9 one doesn't). So this is valid with the current spec'ed behavior. The spec is probably wrong and should be changed to document the expected memory semantics in any case, and depending on what those are, the suggested optimization will either be ok or wrong to do.
> 
>> 
>> Alex
>> 
>>> On 24 May 2017, at 22:50, Mike Duigou <openjdk at duigou.org> wrote:
>>> 
>>> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
>>> 
>>> replace:
>>> 
>>> public final boolean compareAndSet(V expect, V update) {
>>> return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
>>> }
>>> 
>>> with:
>>> 
>>> public final boolean compareAndSet(V expect, V update) {
>>>  return expect != update
>>>     ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>>>     : expect != value ? false : true;
>>> }
>>> 
>>> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
>>> 
>>> Mike
>>> 
>>> On 2017-05-24 12:38, Justin Sampson wrote:
>>>> Andrew Haley wrote:
>>>>> Mike Duigou wrote:
>>>>>> I find that I write a lot of update functions which only occasionally
>>>>>> change the value. For these cases I wonder if it would be reasonable to
>>>>>> skip the update if the value of next is unchanged from previous.
>>>>> I don't think so, because the update has the effect of a volatile
>>>>> write. If you skip the update you lose the happens-before ordering
>>>>> of that write.
>>>> That's strictly true (the memory barriers come out different), but no
>>>> algorithm could actually rely on the difference. The reading thread can't
>>>> tell if it's reading after the write (and therefore can depend on the
>>>> happens-before) or reading before the write (and therefore cannot), since
>>>> it sees the same value in either case.
>>>> This kind of optimization is already done in some places in the JDK, such
>>>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>>>> the write if the current value is already equal to the new value in set(),
>>>> compareAndSet(), etc.
>>>> Cheers,
>>>> Justin
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From oleksandr.otenko at gmail.com  Thu May 25 05:54:28 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 10:54:28 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <2b791c10538264930c33034b97218e77@duigou.org>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
Message-ID: <8DEE0D75-C582-4517-9EDB-6F0CC560A230@gmail.com>

More than that, you are replacing a volatile read-and-store with a volatile read, so the ordering with respect to other operations will also suffer.

It is a really bad idea.

Alex

> On 24 May 2017, at 22:50, Mike Duigou <openjdk at duigou.org> wrote:
> 
> That's my view of this optimization as well; the writes that occur do change but only in ways that nobody should be able to rely upon. Assuming the proposed change to getAndUpdate seemed reasonable to folks I planned to next suggest:
> 
> replace:
> 
> public final boolean compareAndSet(V expect, V update) {
>   return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
> }
> 
> with:
> 
> public final boolean compareAndSet(V expect, V update) {
>    return expect != update
>       ? unsafe.compareAndSwapObject(this, valueOffset, expect, update)
>       : expect != value ? false : true;
> }
> 
> For both the proposed updateAndGet and compareAndSet the goal is to avoid expensive volatile writes when the value is not actually changing.
> 
> Mike
> 
> On 2017-05-24 12:38, Justin Sampson wrote:
>> Andrew Haley wrote:
>>> Mike Duigou wrote:
>>> > I find that I write a lot of update functions which only occasionally
>>> > change the value. For these cases I wonder if it would be reasonable to
>>> > skip the update if the value of next is unchanged from previous.
>>> I don't think so, because the update has the effect of a volatile
>>> write. If you skip the update you lose the happens-before ordering
>>> of that write.
>> That's strictly true (the memory barriers come out different), but no
>> algorithm could actually rely on the difference. The reading thread can't
>> tell if it's reading after the write (and therefore can depend on the
>> happens-before) or reading before the write (and therefore cannot), since
>> it sees the same value in either case.
>> This kind of optimization is already done in some places in the JDK, such
>> as AtomicStampedReference and AtomicMarkableReference, both of which skip
>> the write if the current value is already equal to the new value in set(),
>> compareAndSet(), etc.
>> Cheers,
>> Justin
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Thu May 25 06:16:30 2017
From: aph at redhat.com (Andrew Haley)
Date: Thu, 25 May 2017 11:16:30 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
Message-ID: <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>

On 25/05/17 09:16, Gil Tene wrote:
> 
>> On May 25, 2017, at 12:35 AM, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
>>
>> This is a bad idea.
>>
>> Now there is no guarantee that the synchronizes-with edge exists.
> 
> The current Java 9 specification (in the JavaDoc) of AtomicReference.updateAndGet() doesn't say there is such an edge (the Java 8 one did, but the current Java 9 one doesn't). So this is valid with the current spec'ed behavior. The spec is probably wrong and should be changed to document the expected memory semantics in any case, and depending on what those are, the suggested optimization will either be 
ok or wrong to do.

Ah, I see:

"compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables. "
seems to have gone.  That's a breaking spec change if there's nothing anywhere else.

Andrew.




From dl at cs.oswego.edu  Thu May 25 06:39:22 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 25 May 2017 06:39:22 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
Message-ID: <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>

On 05/25/2017 06:16 AM, Andrew Haley wrote:
> On 25/05/17 09:16, Gil Tene wrote:
>> 
>>> On May 25, 2017, at 12:35 AM, Alex Otenko
>>> <oleksandr.otenko at gmail.com> wrote:
>>> 
>>> This is a bad idea.
>>> 
>>> Now there is no guarantee that the synchronizes-with edge
>>> exists.
>> 
>> The current Java 9 specification (in the JavaDoc) of
>> AtomicReference.updateAndGet() doesn't say there is such an edge
>> (the Java 8 one did, but the current Java 9 one doesn't).
> 
> Ah, I see:
> 
> "compareAndSet and all other read-and-update operations such as
> getAndIncrement have the memory effects of both reading and writing
> volatile variables. " seems to have gone.  

Thanks for pointing this out!
The "...and all other read-and-update operations" clause
inadvertently disappeared while meshing j.u.c.atomic specs
with jdk9 VarHandles
(http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)

The updateAndGet method is not a part of VarHandles, so is no longer
covered by any existing statement. We will need to somehow do so.

And so, Mike: Some existing code might rely on this, so the best we
could so here is replace elided volatile-write with a fullFence,
which would probably not be detectably faster.

-Doug

From jsampson at guidewire.com  Thu May 25 11:03:53 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Thu, 25 May 2017 15:03:53 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
Message-ID: <F82C7195-9ED2-481C-9229-B53B026E16F9@guidewire.com>

Are AtomicStampedReference and AtomicMarkableReference going to have this optimization removed from all of their methods for consistency, or will they be called out differently in the docs?

Cheers,
Justin


On 5/25/17, 3:39 AM, "Concurrency-interest on behalf of Doug Lea" <concurrency-interest-bounces at cs.oswego.edu on behalf of dl at cs.oswego.edu> wrote:

    On 05/25/2017 06:16 AM, Andrew Haley wrote:
    > On 25/05/17 09:16, Gil Tene wrote:
    >> 
    >>> On May 25, 2017, at 12:35 AM, Alex Otenko
    >>> <oleksandr.otenko at gmail.com> wrote:
    >>> 
    >>> This is a bad idea.
    >>> 
    >>> Now there is no guarantee that the synchronizes-with edge
    >>> exists.
    >> 
    >> The current Java 9 specification (in the JavaDoc) of
    >> AtomicReference.updateAndGet() doesn't say there is such an edge
    >> (the Java 8 one did, but the current Java 9 one doesn't).
    > 
    > Ah, I see:
    > 
    > "compareAndSet and all other read-and-update operations such as
    > getAndIncrement have the memory effects of both reading and writing
    > volatile variables. " seems to have gone.  
    
    Thanks for pointing this out!
    The "...and all other read-and-update operations" clause
    inadvertently disappeared while meshing j.u.c.atomic specs
    with jdk9 VarHandles
    (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)
    
    The updateAndGet method is not a part of VarHandles, so is no longer
    covered by any existing statement. We will need to somehow do so.
    
    And so, Mike: Some existing code might rely on this, so the best we
    could so here is replace elided volatile-write with a fullFence,
    which would probably not be detectably faster.
    
    -Doug
 


From oleksandr.otenko at gmail.com  Thu May 25 11:30:31 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 16:30:31 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <F82C7195-9ED2-481C-9229-B53B026E16F9@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <F82C7195-9ED2-481C-9229-B53B026E16F9@guidewire.com>
Message-ID: <9A3FE908-B91C-44A4-91C0-C5CBFC30E3EE@gmail.com>

It looks like AtomicStampedReference does a completely different thing. The important difference there is the presence of Stamp. The presence of the Stamp determines the semantics of when should a volatile store be observed.

Alex

> On 25 May 2017, at 16:03, Justin Sampson <jsampson at guidewire.com> wrote:
> 
> Are AtomicStampedReference and AtomicMarkableReference going to have this optimization removed from all of their methods for consistency, or will they be called out differently in the docs?
> 
> Cheers,
> Justin
> 
> 
> On 5/25/17, 3:39 AM, "Concurrency-interest on behalf of Doug Lea" <concurrency-interest-bounces at cs.oswego.edu on behalf of dl at cs.oswego.edu> wrote:
> 
>    On 05/25/2017 06:16 AM, Andrew Haley wrote:
>> On 25/05/17 09:16, Gil Tene wrote:
>>> 
>>>> On May 25, 2017, at 12:35 AM, Alex Otenko
>>>> <oleksandr.otenko at gmail.com> wrote:
>>>> 
>>>> This is a bad idea.
>>>> 
>>>> Now there is no guarantee that the synchronizes-with edge
>>>> exists.
>>> 
>>> The current Java 9 specification (in the JavaDoc) of
>>> AtomicReference.updateAndGet() doesn't say there is such an edge
>>> (the Java 8 one did, but the current Java 9 one doesn't).
>> 
>> Ah, I see:
>> 
>> "compareAndSet and all other read-and-update operations such as
>> getAndIncrement have the memory effects of both reading and writing
>> volatile variables. " seems to have gone.  
> 
>    Thanks for pointing this out!
>    The "...and all other read-and-update operations" clause
>    inadvertently disappeared while meshing j.u.c.atomic specs
>    with jdk9 VarHandles
>    (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)
> 
>    The updateAndGet method is not a part of VarHandles, so is no longer
>    covered by any existing statement. We will need to somehow do so.
> 
>    And so, Mike: Some existing code might rely on this, so the best we
>    could so here is replace elided volatile-write with a fullFence,
>    which would probably not be detectably faster.
> 
>    -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gil at azul.com  Thu May 25 13:15:24 2017
From: gil at azul.com (Gil Tene)
Date: Thu, 25 May 2017 17:15:24 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>,
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
Message-ID: <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>



Sent from my iPad

> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> 
>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>>> On 25/05/17 09:16, Gil Tene wrote:
>>> 
>>>> On May 25, 2017, at 12:35 AM, Alex Otenko
>>>> <oleksandr.otenko at gmail.com> wrote:
>>>> 
>>>> This is a bad idea.
>>>> 
>>>> Now there is no guarantee that the synchronizes-with edge
>>>> exists.
>>> 
>>> The current Java 9 specification (in the JavaDoc) of
>>> AtomicReference.updateAndGet() doesn't say there is such an edge
>>> (the Java 8 one did, but the current Java 9 one doesn't).
>> 
>> Ah, I see:
>> 
>> "compareAndSet and all other read-and-update operations such as
>> getAndIncrement have the memory effects of both reading and writing
>> volatile variables. " seems to have gone.  
> 
> Thanks for pointing this out!
> The "...and all other read-and-update operations" clause
> inadvertently disappeared while meshing j.u.c.atomic specs
> with jdk9 VarHandles
> (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)

While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 

In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.

> 
> The updateAndGet method is not a part of VarHandles, so is no longer
> covered by any existing statement. We will need to somehow do so.
> 
> And so, Mike: Some existing code might rely on this, so the best we
> could so here is replace elided volatile-write with a fullFence,
> which would probably not be detectably faster.
> 
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From dl at cs.oswego.edu  Thu May 25 13:27:02 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Thu, 25 May 2017 13:27:02 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
Message-ID: <110e5c95-2fe4-15d4-0e49-7c6ac8813f78@cs.oswego.edu>

On 05/25/2017 01:15 PM, Gil Tene wrote:

>> (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)

> While on this subject, was the relative "weakening" of compareAndSet
> (and other) memory semantics between Java 8 and java 9 discussed
> elsewhere?

The was no intention to weaken CAS specs. But in an attempt to clarify
distinctions across new variants (compareAndExchangeRelease
etc), the fact that the volatile-write property is unconditional
here got lost. This also needs to be fixed.

-Doug

From openjdk at duigou.org  Thu May 25 16:01:41 2017
From: openjdk at duigou.org (Mike Duigou)
Date: Thu, 25 May 2017 13:01:41 -0700
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 148,
	Issue 16
In-Reply-To: <mailman.3.1495728001.10581.concurrency-interest@cs.oswego.edu>
References: <mailman.3.1495728001.10581.concurrency-interest@cs.oswego.edu>
Message-ID: <ea47d8d29ec789c6a210e17a451a26d3@duigou.org>


> And so, Mike: Some existing code might rely on this, so the best we
> could so here is replace elided volatile-write with a fullFence,
> which would probably not be detectably faster.

Another one bites the dust. A disappointing and frustrating but familiar 
conclusion--being blocked from reasonable beneficial improvements by the 
specification making unnecessary promises or by what some weird program 
that may or might expect. Having been there I am not envious of those 
working the JDK libraries.

Mike

From oleksandr.otenko at gmail.com  Thu May 25 17:24:33 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 22:24:33 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 148,
	Issue 16
In-Reply-To: <ea47d8d29ec789c6a210e17a451a26d3@duigou.org>
References: <mailman.3.1495728001.10581.concurrency-interest@cs.oswego.edu>
 <ea47d8d29ec789c6a210e17a451a26d3@duigou.org>
Message-ID: <F0E3ECA2-B192-4246-994D-5C3B0D83CDEB@gmail.com>

This is an absolutely necessary promise.

The programs that benefit from such promise can reduce contention by detecting contenders (failed CAS does not mean you have to hammer it until you get a successful CAS) and by facilitating cooperation (if you can distinguish a CAS in the past from the CAS in the future, you can stop contending for resources).

Alex

> On 25 May 2017, at 21:01, Mike Duigou <openjdk at duigou.org> wrote:
> 
> 
>> And so, Mike: Some existing code might rely on this, so the best we
>> could so here is replace elided volatile-write with a fullFence,
>> which would probably not be detectably faster.
> 
> Another one bites the dust. A disappointing and frustrating but familiar conclusion--being blocked from reasonable beneficial improvements by the specification making unnecessary promises or by what some weird program that may or might expect. Having been there I am not envious of those working the JDK libraries.
> 
> Mike
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Thu May 25 17:30:22 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 22:30:22 +0100
Subject: [concurrency-interest] Concurrency-interest Digest, Vol 148,
	Issue 16
In-Reply-To: <F0E3ECA2-B192-4246-994D-5C3B0D83CDEB@gmail.com>
References: <mailman.3.1495728001.10581.concurrency-interest@cs.oswego.edu>
 <ea47d8d29ec789c6a210e17a451a26d3@duigou.org>
 <F0E3ECA2-B192-4246-994D-5C3B0D83CDEB@gmail.com>
Message-ID: <A208C82D-5303-488E-9A16-D1DCF6B4E4FF@gmail.com>

Also, a FullFence only after the CAS won’t do. You also need the fence to make sure the volatile read does not reorder with anything preceding CAS.

Alex
 
> On 25 May 2017, at 22:24, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> This is an absolutely necessary promise.
> 
> The programs that benefit from such promise can reduce contention by detecting contenders (failed CAS does not mean you have to hammer it until you get a successful CAS) and by facilitating cooperation (if you can distinguish a CAS in the past from the CAS in the future, you can stop contending for resources).
> 
> Alex
> 
>> On 25 May 2017, at 21:01, Mike Duigou <openjdk at duigou.org> wrote:
>> 
>> 
>>> And so, Mike: Some existing code might rely on this, so the best we
>>> could so here is replace elided volatile-write with a fullFence,
>>> which would probably not be detectably faster.
>> 
>> Another one bites the dust. A disappointing and frustrating but familiar conclusion--being blocked from reasonable beneficial improvements by the specification making unnecessary promises or by what some weird program that may or might expect. Having been there I am not envious of those working the JDK libraries.
>> 
>> Mike
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 


From boehm at acm.org  Thu May 25 18:01:22 2017
From: boehm at acm.org (Hans Boehm)
Date: Thu, 25 May 2017 15:01:22 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>
Message-ID: <CAPUmR1bVRDmpdPYjh10vRQi2m54EKE2U4r14FVu-1TG7_YFm3g@mail.gmail.com>

IIUC, you're arguing that this transformation is valid only if we know that
the implementation does not indefinitely delay the store to x past the
do-while loop implementing compareAndSet()? E.g. if the compareAndSet
thread subsequently prints something, and then goes into an infinite loop,
I still have a guarantee that a thread that alternately reads x and y will
eventually see x == 1?

I'm inclined to agree with that, though I expect that implementations
violating this assumption are really rare.

On Thu, May 25, 2017 at 1:23 AM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> How quickly you arrived at “no algorithm whatsoever”! :-)
>
> x=1;
> y.compareAndSet(e,v)
>
> Under assumption that there are infinitely many volatile reads of y, the
> return from compareAndSet is a witness that there exists a read in the
> future that synchronizes-with this invocation of compareAndSet.
>
> You cannot argue that sometimes you can skip the volatile store semantics
> on what would be a successful compareAndSet - because then the stores
> preceding compareAndSet are not guaranteed to be visible - ever. This
> optimization is a platform-specific decision.
>
>
> You can argue about what happens if compareAndSet fails. My take is it
> should still have volatile store semantics - ie should be equivalent to the
> store of the value that is already there, so it appears unmodified, but
> synchronizes-with edges can be established.
>
>
> Alex
>
> > On 24 May 2017, at 20:38, Justin Sampson <jsampson at guidewire.com> wrote:
> >
> > Andrew Haley wrote:
> >> Mike Duigou wrote:
> >>> I find that I write a lot of update functions which only occasionally
> >>> change the value. For these cases I wonder if it would be reasonable to
> >>> skip the update if the value of next is unchanged from previous.
> >>
> >> I don't think so, because the update has the effect of a volatile
> >> write. If you skip the update you lose the happens-before ordering
> >> of that write.
> >
> > That's strictly true (the memory barriers come out different), but no
> > algorithm could actually rely on the difference. The reading thread can't
> > tell if it's reading after the write (and therefore can depend on the
> > happens-before) or reading before the write (and therefore cannot), since
> > it sees the same value in either case.
> >
> > This kind of optimization is already done in some places in the JDK, such
> > as AtomicStampedReference and AtomicMarkableReference, both of which skip
> > the write if the current value is already equal to the new value in
> set(),
> > compareAndSet(), etc.
> >
> > Cheers,
> > Justin
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170525/1a5cb4d1/attachment-0001.html>

From nathanila at gmail.com  Thu May 25 09:59:59 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Thu, 25 May 2017 07:59:59 -0600
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
Message-ID: <35259bfe-ffc4-6457-702c-50007c346997@gmail.com>

 > The best we could so here is replace elided volatile write with a 
full fence, which would probably not be detectably faster.

I definitely agree with Alex Otenko's position of keeping the 
synchronizes-with edge.  I can think of several places in code where 
removing this edge would cause all sorts of wacky hard-to-reproduce 
issues.  Doug's suggestion I quoted above seems like a good solution.  
 From my limited perspective, his suggestion seems to keep the 
synchronizes-with edge yet avoid the volatile write.  I can assure you 
that replacing a volatile write with a full fence is definitely faster.  
On a highly contended cache line, eliding a volatile write will definite 
improve scalability. I can think of one place in code where each write 
to the cache line is very costly in terms of scalability.  I've spent a 
lot of time optimizing that code to reduce the number of writes to 1 
cache line.  Before this optimization, cores would sit at 100% 
utilization but the internal execution pipelines were stalled waiting 
for a highly contended cache line.

-Nathan

On 5/25/2017 4:39 AM, Doug Lea wrote:
> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>> On 25/05/17 09:16, Gil Tene wrote:
>>>> On May 25, 2017, at 12:35 AM, Alex Otenko
>>>> <oleksandr.otenko at gmail.com> wrote:
>>>>
>>>> This is a bad idea.
>>>>
>>>> Now there is no guarantee that the synchronizes-with edge
>>>> exists.
>>> The current Java 9 specification (in the JavaDoc) of
>>> AtomicReference.updateAndGet() doesn't say there is such an edge
>>> (the Java 8 one did, but the current Java 9 one doesn't).
>> Ah, I see:
>>
>> "compareAndSet and all other read-and-update operations such as
>> getAndIncrement have the memory effects of both reading and writing
>> volatile variables. " seems to have gone.
> Thanks for pointing this out!
> The "...and all other read-and-update operations" clause
> inadvertently disappeared while meshing j.u.c.atomic specs
> with jdk9 VarHandles
> (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)
>
> The updateAndGet method is not a part of VarHandles, so is no longer
> covered by any existing statement. We will need to somehow do so.
>
> And so, Mike: Some existing code might rely on this, so the best we
> could so here is replace elided volatile-write with a fullFence,
> which would probably not be detectably faster.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From oleksandr.otenko at gmail.com  Thu May 25 18:41:37 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 23:41:37 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1bVRDmpdPYjh10vRQi2m54EKE2U4r14FVu-1TG7_YFm3g@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>
 <CAPUmR1bVRDmpdPYjh10vRQi2m54EKE2U4r14FVu-1TG7_YFm3g@mail.gmail.com>
Message-ID: <3E225380-5698-47B5-ADA7-C6B548083C3E@gmail.com>

Ok, if this is rare, then isn’t also a CAS with expected == new value rare?

It is not just about delaying the stores, but also about seeing them all at the same time.

x=1
y=2
z.CAS(…)

guarantees that another thread reading z after CAS will observe *both* y=2 and x=1.

If we make the case z.CAS(e, e) special (not a store, or no barrier before the volatile load in the “optimized” version), then this no longer can be guaranteed.

If the store is eliminated from CAS, then another thread does not synchronize-with the thread performing this CAS. In real terms this means it will not guarantee visibility of *both* y=2 and x=1.

Alex

> On 25 May 2017, at 23:01, Hans Boehm <boehm at acm.org> wrote:
> 
> IIUC, you're arguing that this transformation is valid only if we know that the implementation does not indefinitely delay the store to x past the do-while loop implementing compareAndSet()? E.g. if the compareAndSet thread subsequently prints something, and then goes into an infinite loop, I still have a guarantee that a thread that alternately reads x and y will eventually see x == 1?
> 
> I'm inclined to agree with that, though I expect that implementations violating this assumption are really rare.
> 
> On Thu, May 25, 2017 at 1:23 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> How quickly you arrived at “no algorithm whatsoever”! :-)
> 
> x=1;
> y.compareAndSet(e,v)
> 
> Under assumption that there are infinitely many volatile reads of y, the return from compareAndSet is a witness that there exists a read in the future that synchronizes-with this invocation of compareAndSet.
> 
> You cannot argue that sometimes you can skip the volatile store semantics on what would be a successful compareAndSet - because then the stores preceding compareAndSet are not guaranteed to be visible - ever. This optimization is a platform-specific decision.
> 
> 
> You can argue about what happens if compareAndSet fails. My take is it should still have volatile store semantics - ie should be equivalent to the store of the value that is already there, so it appears unmodified, but synchronizes-with edges can be established.
> 
> 
> Alex
> 
> > On 24 May 2017, at 20:38, Justin Sampson <jsampson at guidewire.com <mailto:jsampson at guidewire.com>> wrote:
> >
> > Andrew Haley wrote:
> >> Mike Duigou wrote:
> >>> I find that I write a lot of update functions which only occasionally
> >>> change the value. For these cases I wonder if it would be reasonable to
> >>> skip the update if the value of next is unchanged from previous.
> >>
> >> I don't think so, because the update has the effect of a volatile
> >> write. If you skip the update you lose the happens-before ordering
> >> of that write.
> >
> > That's strictly true (the memory barriers come out different), but no
> > algorithm could actually rely on the difference. The reading thread can't
> > tell if it's reading after the write (and therefore can depend on the
> > happens-before) or reading before the write (and therefore cannot), since
> > it sees the same value in either case.
> >
> > This kind of optimization is already done in some places in the JDK, such
> > as AtomicStampedReference and AtomicMarkableReference, both of which skip
> > the write if the current value is already equal to the new value in set(),
> > compareAndSet(), etc.
> >
> > Cheers,
> > Justin
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170525/4790cff3/attachment.html>

From oleksandr.otenko at gmail.com  Thu May 25 18:46:45 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Thu, 25 May 2017 23:46:45 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <35259bfe-ffc4-6457-702c-50007c346997@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <35259bfe-ffc4-6457-702c-50007c346997@gmail.com>
Message-ID: <9D19578E-C768-407E-81F5-DBEED85E3073@gmail.com>

We also need to keep the StoreLoad barrier before the CAS.

While it is not needed when the atomic is used (preemptive read is only a guess; making a wrong guess still keeps the barriers of the atomic), in the “optimized” version preemptive read of the expected value can reorder things.

Alex
 
> On 25 May 2017, at 14:59, Nathan and Ila Reynolds <nathanila at gmail.com> wrote:
> 
> > The best we could so here is replace elided volatile write with a full fence, which would probably not be detectably faster.
> 
> I definitely agree with Alex Otenko's position of keeping the synchronizes-with edge.  I can think of several places in code where removing this edge would cause all sorts of wacky hard-to-reproduce issues.  Doug's suggestion I quoted above seems like a good solution.  From my limited perspective, his suggestion seems to keep the synchronizes-with edge yet avoid the volatile write.  I can assure you that replacing a volatile write with a full fence is definitely faster.  On a highly contended cache line, eliding a volatile write will definite improve scalability. I can think of one place in code where each write to the cache line is very costly in terms of scalability.  I've spent a lot of time optimizing that code to reduce the number of writes to 1 cache line.  Before this optimization, cores would sit at 100% utilization but the internal execution pipelines were stalled waiting for a highly contended cache line.
> 
> -Nathan
> 
> On 5/25/2017 4:39 AM, Doug Lea wrote:
>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>>> On 25/05/17 09:16, Gil Tene wrote:
>>>>> On May 25, 2017, at 12:35 AM, Alex Otenko
>>>>> <oleksandr.otenko at gmail.com> wrote:
>>>>> 
>>>>> This is a bad idea.
>>>>> 
>>>>> Now there is no guarantee that the synchronizes-with edge
>>>>> exists.
>>>> The current Java 9 specification (in the JavaDoc) of
>>>> AtomicReference.updateAndGet() doesn't say there is such an edge
>>>> (the Java 8 one did, but the current Java 9 one doesn't).
>>> Ah, I see:
>>> 
>>> "compareAndSet and all other read-and-update operations such as
>>> getAndIncrement have the memory effects of both reading and writing
>>> volatile variables. " seems to have gone.
>> Thanks for pointing this out!
>> The "...and all other read-and-update operations" clause
>> inadvertently disappeared while meshing j.u.c.atomic specs
>> with jdk9 VarHandles
>> (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html)
>> 
>> The updateAndGet method is not a part of VarHandles, so is no longer
>> covered by any existing statement. We will need to somehow do so.
>> 
>> And so, Mike: Some existing code might rely on this, so the best we
>> could so here is replace elided volatile-write with a fullFence,
>> which would probably not be detectably faster.
>> 
>> -Doug
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> -- 
> -Nathan
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From boehm at acm.org  Thu May 25 19:44:07 2017
From: boehm at acm.org (Hans Boehm)
Date: Thu, 25 May 2017 16:44:07 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <9D19578E-C768-407E-81F5-DBEED85E3073@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <35259bfe-ffc4-6457-702c-50007c346997@gmail.com>
 <9D19578E-C768-407E-81F5-DBEED85E3073@gmail.com>
Message-ID: <CAPUmR1bhk5-Lpu0-XUAU3NdLV6Lro6G+yW-Ha5TQbzHD6gXbbA@mail.gmail.com>

Hopefully CAS no more guarantees a barrier than a volatile access does. The
intent was always to allow all barriers to be elided if the atomic is
thread-local.

If CAS were to guarantee a barrier, neither a lock-based implementation,
not the standard ARMv8 implementation would work.

On Thu, May 25, 2017 at 3:46 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> We also need to keep the StoreLoad barrier before the CAS.
>
> While it is not needed when the atomic is used (preemptive read is only a
> guess; making a wrong guess still keeps the barriers of the atomic), in the
> “optimized” version preemptive read of the expected value can reorder
> things.
>
> Alex
>
> > On 25 May 2017, at 14:59, Nathan and Ila Reynolds <nathanila at gmail.com>
> wrote:
> >
> > > The best we could so here is replace elided volatile write with a full
> fence, which would probably not be detectably faster.
> >
> > I definitely agree with Alex Otenko's position of keeping the
> synchronizes-with edge.  I can think of several places in code where
> removing this edge would cause all sorts of wacky hard-to-reproduce
> issues.  Doug's suggestion I quoted above seems like a good solution.  From
> my limited perspective, his suggestion seems to keep the synchronizes-with
> edge yet avoid the volatile write.  I can assure you that replacing a
> volatile write with a full fence is definitely faster.  On a highly
> contended cache line, eliding a volatile write will definite improve
> scalability. I can think of one place in code where each write to the cache
> line is very costly in terms of scalability.  I've spent a lot of time
> optimizing that code to reduce the number of writes to 1 cache line.
> Before this optimization, cores would sit at 100% utilization but the
> internal execution pipelines were stalled waiting for a highly contended
> cache line.
> >
> > -Nathan
> >
> > On 5/25/2017 4:39 AM, Doug Lea wrote:
> >> On 05/25/2017 06:16 AM, Andrew Haley wrote:
> >>> On 25/05/17 09:16, Gil Tene wrote:
> >>>>> On May 25, 2017, at 12:35 AM, Alex Otenko
> >>>>> <oleksandr.otenko at gmail.com> wrote:
> >>>>>
> >>>>> This is a bad idea.
> >>>>>
> >>>>> Now there is no guarantee that the synchronizes-with edge
> >>>>> exists.
> >>>> The current Java 9 specification (in the JavaDoc) of
> >>>> AtomicReference.updateAndGet() doesn't say there is such an edge
> >>>> (the Java 8 one did, but the current Java 9 one doesn't).
> >>> Ah, I see:
> >>>
> >>> "compareAndSet and all other read-and-update operations such as
> >>> getAndIncrement have the memory effects of both reading and writing
> >>> volatile variables. " seems to have gone.
> >> Thanks for pointing this out!
> >> The "...and all other read-and-update operations" clause
> >> inadvertently disappeared while meshing j.u.c.atomic specs
> >> with jdk9 VarHandles
> >> (http://download.java.net/java/jdk9/docs/api/java/lang/
> invoke/VarHandle.html)
> >>
> >> The updateAndGet method is not a part of VarHandles, so is no longer
> >> covered by any existing statement. We will need to somehow do so.
> >>
> >> And so, Mike: Some existing code might rely on this, so the best we
> >> could so here is replace elided volatile-write with a fullFence,
> >> which would probably not be detectably faster.
> >>
> >> -Doug
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> > --
> > -Nathan
> >
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170525/f310ec9f/attachment-0001.html>

From boehm at acm.org  Thu May 25 19:44:27 2017
From: boehm at acm.org (Hans Boehm)
Date: Thu, 25 May 2017 16:44:27 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <3E225380-5698-47B5-ADA7-C6B548083C3E@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>
 <CAPUmR1bVRDmpdPYjh10vRQi2m54EKE2U4r14FVu-1TG7_YFm3g@mail.gmail.com>
 <3E225380-5698-47B5-ADA7-C6B548083C3E@gmail.com>
Message-ID: <CAPUmR1YCYauR+W_dYEFK=guHgsvmbH=pRvjFLeU8bBmy_A3w7Q@mail.gmail.com>

Full counterexamples, with both threads, would be extremely useful here.

"guarantees that another thread reading z after CAS will observe *both* y=2
and x=1"

Only if it can somehow tell that it read z after the CAS. If the CAS didn't
change the value of z, that's exceedingly hard to tell. Even if we presume
there is a (non-volatile) store to w after the CAS, and the other thread
sees the store to w, this is not guaranteed if e.g. the CAS is implemented
with a critical section.

On Thu, May 25, 2017 at 3:41 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> Ok, if this is rare, then isn’t also a CAS with expected == new value rare?
>
> It is not just about delaying the stores, but also about seeing them all
> at the same time.
>
> x=1
> y=2
> z.CAS(…)
>
> guarantees that another thread reading z after CAS will observe *both* y=2
> and x=1.
>
> If we make the case z.CAS(e, e) special (not a store, or no barrier before
> the volatile load in the “optimized” version), then this no longer can be
> guaranteed.
>
> If the store is eliminated from CAS, then another thread does not
> synchronize-with the thread performing this CAS. In real terms this means
> it will not guarantee visibility of *both* y=2 and x=1.
>
> Alex
>
> On 25 May 2017, at 23:01, Hans Boehm <boehm at acm.org> wrote:
>
> IIUC, you're arguing that this transformation is valid only if we know
> that the implementation does not indefinitely delay the store to x past the
> do-while loop implementing compareAndSet()? E.g. if the compareAndSet
> thread subsequently prints something, and then goes into an infinite loop,
> I still have a guarantee that a thread that alternately reads x and y will
> eventually see x == 1?
>
> I'm inclined to agree with that, though I expect that implementations
> violating this assumption are really rare.
>
> On Thu, May 25, 2017 at 1:23 AM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> How quickly you arrived at “no algorithm whatsoever”! :-)
>>
>> x=1;
>> y.compareAndSet(e,v)
>>
>> Under assumption that there are infinitely many volatile reads of y, the
>> return from compareAndSet is a witness that there exists a read in the
>> future that synchronizes-with this invocation of compareAndSet.
>>
>> You cannot argue that sometimes you can skip the volatile store semantics
>> on what would be a successful compareAndSet - because then the stores
>> preceding compareAndSet are not guaranteed to be visible - ever. This
>> optimization is a platform-specific decision.
>>
>>
>> You can argue about what happens if compareAndSet fails. My take is it
>> should still have volatile store semantics - ie should be equivalent to the
>> store of the value that is already there, so it appears unmodified, but
>> synchronizes-with edges can be established.
>>
>>
>> Alex
>>
>> > On 24 May 2017, at 20:38, Justin Sampson <jsampson at guidewire.com>
>> wrote:
>> >
>> > Andrew Haley wrote:
>> >> Mike Duigou wrote:
>> >>> I find that I write a lot of update functions which only occasionally
>> >>> change the value. For these cases I wonder if it would be reasonable
>> to
>> >>> skip the update if the value of next is unchanged from previous.
>> >>
>> >> I don't think so, because the update has the effect of a volatile
>> >> write. If you skip the update you lose the happens-before ordering
>> >> of that write.
>> >
>> > That's strictly true (the memory barriers come out different), but no
>> > algorithm could actually rely on the difference. The reading thread
>> can't
>> > tell if it's reading after the write (and therefore can depend on the
>> > happens-before) or reading before the write (and therefore cannot),
>> since
>> > it sees the same value in either case.
>> >
>> > This kind of optimization is already done in some places in the JDK,
>> such
>> > as AtomicStampedReference and AtomicMarkableReference, both of which
>> skip
>> > the write if the current value is already equal to the new value in
>> set(),
>> > compareAndSet(), etc.
>> >
>> > Cheers,
>> > Justin
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170525/daa6c5a5/attachment.html>

From oleksandr.otenko at gmail.com  Fri May 26 03:31:19 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 26 May 2017 08:31:19 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1YCYauR+W_dYEFK=guHgsvmbH=pRvjFLeU8bBmy_A3w7Q@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <36DD29DF-D2B6-48CE-8C99-3219DC40EA5C@gmail.com>
 <CAPUmR1bVRDmpdPYjh10vRQi2m54EKE2U4r14FVu-1TG7_YFm3g@mail.gmail.com>
 <3E225380-5698-47B5-ADA7-C6B548083C3E@gmail.com>
 <CAPUmR1YCYauR+W_dYEFK=guHgsvmbH=pRvjFLeU8bBmy_A3w7Q@mail.gmail.com>
Message-ID: <E2BF3D61-E94D-44F4-A2A2-723C8E4B6886@gmail.com>

It does not matter how CAS is implemented, as long as atomicity is guaranteed. Atomicity means that all other volatile stores are totally ordered with respect to CAS as a whole - whether it is implemented as a critical section or not.

I cannot quote full counterexamples, because they are proprietary. But we used CAS to 1. detect contention; 2. facilitate cooperation.

Detecting contention:

if (z.CAS(e, v)) {
  // I am the slave, and need to pick up the work
  // the other contenders left
} else {
  // I am the master,
  // the slave will pick up the work I left -
  // but of course the slave needs to observe
  // the work in its entirety, so the barrier is
  // expected (as was the case per earlier javadocs)
}


Facilitate cooperation:

if (z.CAS(e, e)) {
  // the update of z by slave is in the future,
  // so the slave will detect new work,
  // but of course the slave needs to observe
  // the work in its entirety, so the barrier is
  // expected
} else {
  // the update of z by slave is in the past,
  // contend to see who should do the work
}

It may not be obvious how one can use a store to z to coordinate (not necessarily a conditional store), but there are ways with arrays and atomic integers.


Of course, if JMM spec is leaning towards some new hardware trends (and perhaps CAS in hardware becoming more and more relaxed about barriers), we’d have to furnish barriers that are expected, but places like these would have to be fished out, which is not trivial. We couldn’t do this earlier, because the barrier API was not available in Java.

Eg “if(z.CAS(e,e))” is the same as “StoreLoad; LoadLoad; if (z==e)”, but there was no way to do that in Java 7.


Alex


> On 26 May 2017, at 00:44, Hans Boehm <boehm at acm.org> wrote:
> 
> Full counterexamples, with both threads, would be extremely useful here.
> 
> "guarantees that another thread reading z after CAS will observe *both* y=2 and x=1"
> 
> Only if it can somehow tell that it read z after the CAS. If the CAS didn't change the value of z, that's exceedingly hard to tell. Even if we presume there is a (non-volatile) store to w after the CAS, and the other thread sees the store to w, this is not guaranteed if e.g. the CAS is implemented with a critical section.
> 
> On Thu, May 25, 2017 at 3:41 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> Ok, if this is rare, then isn’t also a CAS with expected == new value rare?
> 
> It is not just about delaying the stores, but also about seeing them all at the same time.
> 
> x=1
> y=2
> z.CAS(…)
> 
> guarantees that another thread reading z after CAS will observe *both* y=2 and x=1.
> 
> If we make the case z.CAS(e, e) special (not a store, or no barrier before the volatile load in the “optimized” version), then this no longer can be guaranteed.
> 
> If the store is eliminated from CAS, then another thread does not synchronize-with the thread performing this CAS. In real terms this means it will not guarantee visibility of *both* y=2 and x=1.
> 
> Alex
> 
>> On 25 May 2017, at 23:01, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>> 
>> IIUC, you're arguing that this transformation is valid only if we know that the implementation does not indefinitely delay the store to x past the do-while loop implementing compareAndSet()? E.g. if the compareAndSet thread subsequently prints something, and then goes into an infinite loop, I still have a guarantee that a thread that alternately reads x and y will eventually see x == 1?
>> 
>> I'm inclined to agree with that, though I expect that implementations violating this assumption are really rare.
>> 
>> On Thu, May 25, 2017 at 1:23 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> How quickly you arrived at “no algorithm whatsoever”! :-)
>> 
>> x=1;
>> y.compareAndSet(e,v)
>> 
>> Under assumption that there are infinitely many volatile reads of y, the return from compareAndSet is a witness that there exists a read in the future that synchronizes-with this invocation of compareAndSet.
>> 
>> You cannot argue that sometimes you can skip the volatile store semantics on what would be a successful compareAndSet - because then the stores preceding compareAndSet are not guaranteed to be visible - ever. This optimization is a platform-specific decision.
>> 
>> 
>> You can argue about what happens if compareAndSet fails. My take is it should still have volatile store semantics - ie should be equivalent to the store of the value that is already there, so it appears unmodified, but synchronizes-with edges can be established.
>> 
>> 
>> Alex
>> 
>> > On 24 May 2017, at 20:38, Justin Sampson <jsampson at guidewire.com <mailto:jsampson at guidewire.com>> wrote:
>> >
>> > Andrew Haley wrote:
>> >> Mike Duigou wrote:
>> >>> I find that I write a lot of update functions which only occasionally
>> >>> change the value. For these cases I wonder if it would be reasonable to
>> >>> skip the update if the value of next is unchanged from previous.
>> >>
>> >> I don't think so, because the update has the effect of a volatile
>> >> write. If you skip the update you lose the happens-before ordering
>> >> of that write.
>> >
>> > That's strictly true (the memory barriers come out different), but no
>> > algorithm could actually rely on the difference. The reading thread can't
>> > tell if it's reading after the write (and therefore can depend on the
>> > happens-before) or reading before the write (and therefore cannot), since
>> > it sees the same value in either case.
>> >
>> > This kind of optimization is already done in some places in the JDK, such
>> > as AtomicStampedReference and AtomicMarkableReference, both of which skip
>> > the write if the current value is already equal to the new value in set(),
>> > compareAndSet(), etc.
>> >
>> > Cheers,
>> > Justin
>> >
>> > _______________________________________________
>> > Concurrency-interest mailing list
>> > Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170526/43d3ca6f/attachment-0001.html>

From aph at redhat.com  Fri May 26 04:44:12 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 09:44:12 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
Message-ID: <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>

On 25/05/17 18:15, Gil Tene wrote:
> 
> 
> Sent from my iPad
> 
>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>
>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
> 
> While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 
> 
> In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.
That property of compareAndSet is very ugly, and is a pain to implement.
Most of the CAS instructions I know about don't have such a property,
and making it work requires either an unconditional full fence after every
CAS or a conditional one if it fails.  Either way sucks mightily and
is unlikely to be useful except in the most pathological cases.

Besides, how does it ever make sense to synchronize with a store that
never happened?

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Fri May 26 04:52:42 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 26 May 2017 09:52:42 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
Message-ID: <AC186EB6-8967-4378-A635-DF70DC69966A@gmail.com>

A store is not never happened, it is a store of the same value that is already there.

Boolean response of CAS in the Java 8 semantics provided witness of mutual exclusion. weakCompareAndSet doesn’t provide such a witness. Use weakCompareAndSet, when you don’t care about the visibility of prior stores on fail.

Alex


> On 26 May 2017, at 09:44, Andrew Haley <aph at redhat.com> wrote:
> 
> On 25/05/17 18:15, Gil Tene wrote:
>> 
>> 
>> Sent from my iPad
>> 
>>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>> 
>>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>> 
>> While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 
>> 
>> In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.
> That property of compareAndSet is very ugly, and is a pain to implement.
> Most of the CAS instructions I know about don't have such a property,
> and making it work requires either an unconditional full fence after every
> CAS or a conditional one if it fails.  Either way sucks mightily and
> is unlikely to be useful except in the most pathological cases.
> 
> Besides, how does it ever make sense to synchronize with a store that
> never happened?
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Fri May 26 05:03:13 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 10:03:13 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <AC186EB6-8967-4378-A635-DF70DC69966A@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <AC186EB6-8967-4378-A635-DF70DC69966A@gmail.com>
Message-ID: <c167bd9b-b2d8-ac02-bcbd-cb85e681cc26@redhat.com>

On 26/05/17 09:52, Alex Otenko wrote:
> A store is not never happened, it is a store of the same value that is already there
This part of the discussion is about a failing CAS: the store does not take
place.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Fri May 26 05:09:18 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 26 May 2017 10:09:18 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <c167bd9b-b2d8-ac02-bcbd-cb85e681cc26@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <AC186EB6-8967-4378-A635-DF70DC69966A@gmail.com>
 <c167bd9b-b2d8-ac02-bcbd-cb85e681cc26@redhat.com>
Message-ID: <8E9B250C-50DE-4156-B731-E69A7E31F974@gmail.com>

Yes, I know what hardware does, but it is not a problem to model it as a “always store”. What is “stored" on CAS fail? The value that is already there.

The key point is still about guaranteeing mutual exclusion (false indicates the existence of a concurrent mutator).

If you don’t want to guarantee mutual exclusion (false does not indicate existence of a concurrent mutator), then how is it different from weakCompareAndSet (can fail spuriously)? What are the reasons to not use weakCompareAndSet?

Alex

> On 26 May 2017, at 10:03, Andrew Haley <aph at redhat.com> wrote:
> 
> On 26/05/17 09:52, Alex Otenko wrote:
>> A store is not never happened, it is a store of the same value that is already there
> This part of the discussion is about a failing CAS: the store does not take
> place.
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671


From oleksandr.otenko at gmail.com  Fri May 26 06:31:25 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Fri, 26 May 2017 11:31:25 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <8E9B250C-50DE-4156-B731-E69A7E31F974@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <AC186EB6-8967-4378-A635-DF70DC69966A@gmail.com>
 <c167bd9b-b2d8-ac02-bcbd-cb85e681cc26@redhat.com>
 <8E9B250C-50DE-4156-B731-E69A7E31F974@gmail.com>
Message-ID: <D97F7891-BD90-4539-9096-582B74F570AC@gmail.com>

Perhaps, I’ve skipped a bit of reasoning here.

    x=1
    y=2
------------     other threads are possibly doing:
    CAS              CAS            volatile store
------------    ------------        --------------
False   True    False   True              |
  |       |       |       |               |
  A       B      ...      B               B

Broad guarantee is that no more than one thread will follow branch B. The strong version of CAS also guarantees that at least one thread will follow branch B (so False is a constructive proof of existence of a mutator).

Java 8 CAS is always a store. This means that x=1 and y=2 are both visible to both A and B, irrespective of the outcome. This means that I can move responsibility for observing and processing the x=1 and y=2 between A and B.


If we do not guarantee a store when CAS fails, then I cannot move responsibility for observing and processing the x=1 and y=2 from A to B. In this respect CAS becomes similar to, if not the same as weakCompareAndSet - False no longer guarantees mutually exclusive processing of x=1 and y=2, and no longer needs to be a constructive proof of existence of a mutator.

Alex


> On 26 May 2017, at 10:09, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> Yes, I know what hardware does, but it is not a problem to model it as a “always store”. What is “stored" on CAS fail? The value that is already there.
> 
> The key point is still about guaranteeing mutual exclusion (false indicates the existence of a concurrent mutator).
> 
> If you don’t want to guarantee mutual exclusion (false does not indicate existence of a concurrent mutator), then how is it different from weakCompareAndSet (can fail spuriously)? What are the reasons to not use weakCompareAndSet?
> 
> Alex
> 
>> On 26 May 2017, at 10:03, Andrew Haley <aph at redhat.com> wrote:
>> 
>> On 26/05/17 09:52, Alex Otenko wrote:
>>> A store is not never happened, it is a store of the same value that is already there
>> This part of the discussion is about a failing CAS: the store does not take
>> place.
>> 
>> -- 
>> Andrew Haley
>> Java Platform Lead Engineer
>> Red Hat UK Ltd. <https://www.redhat.com>
>> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170526/f35e91ba/attachment-0001.html>

From dl at cs.oswego.edu  Fri May 26 08:46:32 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 26 May 2017 08:46:32 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
Message-ID: <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>

On 05/26/2017 04:44 AM, Andrew Haley wrote:

>> a compareAndSet has the memory semantics of a volatile
>> write regardless of whether or not the write occurred. 
> That property of compareAndSet is very ugly, and is a pain to
> implement. Most of the CAS instructions I know about don't have such
> a property, and making it work requires either an unconditional full
> fence after every CAS or a conditional one if it fails.  Either way
> sucks mightily and is unlikely to be useful except in the most
> pathological cases.
> 

Initially (in Java5) requiring it has led to some questionable reliance.
 So we cannot change it. But there's not much motivation to do so anyway:
As implied by Nathan Reynolds, encountering some (local) fence overhead
on CAS failure typically reduces contention and may improve throughput.

-Doug



From adinn at redhat.com  Fri May 26 08:56:21 2017
From: adinn at redhat.com (Andrew Dinn)
Date: Fri, 26 May 2017 13:56:21 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
Message-ID: <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>

On 26/05/17 13:46, Doug Lea wrote:
> On 05/26/2017 04:44 AM, Andrew Haley wrote:
> 
>>> a compareAndSet has the memory semantics of a volatile
>>> write regardless of whether or not the write occurred. 
>> That property of compareAndSet is very ugly, and is a pain to
>> implement. Most of the CAS instructions I know about don't have such
>> a property, and making it work requires either an unconditional full
>> fence after every CAS or a conditional one if it fails.  Either way
>> sucks mightily and is unlikely to be useful except in the most
>> pathological cases.
>>
> 
> Initially (in Java5) requiring it has led to some questionable reliance.
>  So we cannot change it. But there's not much motivation to do so anyway:
> As implied by Nathan Reynolds, encountering some (local) fence overhead
> on CAS failure typically reduces contention and may improve throughput.

It would be useful to know if that reduction in contention is specific
to, say, x86 hardware or also occurs on weak memory architectures like
AArch64 or ppc. Perhaps Nathan could clarify that?

regards,


Andrew Dinn
-----------
Senior Principal Software Engineer
Red Hat UK Ltd
Registered in England and Wales under Company Registration No. 03798903
Directors: Michael Cunningham, Michael ("Mike") O'Neill, Eric Shander

From aph at redhat.com  Fri May 26 09:35:09 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 14:35:09 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
Message-ID: <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>

On 26/05/17 13:56, Andrew Dinn wrote:
> On 26/05/17 13:46, Doug Lea wrote:
>> On 05/26/2017 04:44 AM, Andrew Haley wrote:
>>
>>>> a compareAndSet has the memory semantics of a volatile
>>>> write regardless of whether or not the write occurred. 
>>> That property of compareAndSet is very ugly, and is a pain to
>>> implement. Most of the CAS instructions I know about don't have such
>>> a property, and making it work requires either an unconditional full
>>> fence after every CAS or a conditional one if it fails.  Either way
>>> sucks mightily and is unlikely to be useful except in the most
>>> pathological cases.
>>
>> Initially (in Java5) requiring it has led to some questionable reliance.
>>  So we cannot change it. But there's not much motivation to do so anyway:
>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>> on CAS failure typically reduces contention and may improve throughput.
> 
> It would be useful to know if that reduction in contention is specific
> to, say, x86 hardware or also occurs on weak memory architectures like
> AArch64 or ppc. Perhaps Nathan could clarify that?

Just thinking about AArch64, and how to implement such a thing as well
as possible.  We can't do a store release to the variable involved in
the CAS, but perhaps we could do a store release to something local to
the thread.  That would be better than a full fence, which would be
overkill for this purpose.  Unlike x86 we can't do an access outside
the stack.  I'm trying to think of something in memory, probably in
the local cache, that can be clobbered, but nothing comes to mind.
OK, here's a mad idea: we could allocate an extra stack slot in a
method which uses

It's definitely faster to do a branch around a full fence than
unconditionally executing the fence, so that may be the best we can
do, but I cannot tell you how much I hate the idea of putting a branch
in hot-path code.  Still, this is only j.u.c. atomics and not used in
things like synchronized blocks, so perhaps it doesn't much matter.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From dl at cs.oswego.edu  Fri May 26 09:56:03 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 26 May 2017 09:56:03 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
Message-ID: <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>

On 05/26/2017 09:35 AM, Andrew Haley wrote:
> On 26/05/17 13:56, Andrew Dinn wrote:

>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>  So we cannot change it. But there's not much motivation to do so anyway:
>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>> on CAS failure typically reduces contention and may improve throughput.
>>
>> It would be useful to know if that reduction in contention is specific
>> to, say, x86 hardware or also occurs on weak memory architectures like
>> AArch64 or ppc. Perhaps Nathan could clarify that?

The main issues are not tightly bound to architecture.
In the vast majority of cases, the response to CAS failure is
some sort of retry (although perhaps with some intermediate
processing). The fence here plays a similar role to
Thread.onSpinWait. And in fact, on ARM, is likely to be
exactly the same implementation as onSpinWait.

As Alex mentioned, in the uncommon cases where this
is a performance issue, people can use one of the weak CAS
variants.

> 
> Just thinking about AArch64, and how to implement such a thing as well
> as possible. 

"As well as possible" may be just to unconditionally issue fence,
at least for plain CAS; maybe differently for the variants.

-Doug



From adinn at redhat.com  Fri May 26 10:03:31 2017
From: adinn at redhat.com (Andrew Dinn)
Date: Fri, 26 May 2017 15:03:31 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
Message-ID: <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>

On 26/05/17 14:35, Andrew Haley wrote:
> On 26/05/17 13:56, Andrew Dinn wrote:
>> On 26/05/17 13:46, Doug Lea wrote:
>>> On 05/26/2017 04:44 AM, Andrew Haley wrote:
>>>
>>>>> a compareAndSet has the memory semantics of a volatile
>>>>> write regardless of whether or not the write occurred. 
>>>> That property of compareAndSet is very ugly, and is a pain to
>>>> implement. Most of the CAS instructions I know about don't have such
>>>> a property, and making it work requires either an unconditional full
>>>> fence after every CAS or a conditional one if it fails.  Either way
>>>> sucks mightily and is unlikely to be useful except in the most
>>>> pathological cases.
>>>
>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>  So we cannot change it. But there's not much motivation to do so anyway:
>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>> on CAS failure typically reduces contention and may improve throughput.
>>
>> It would be useful to know if that reduction in contention is specific
>> to, say, x86 hardware or also occurs on weak memory architectures like
>> AArch64 or ppc. Perhaps Nathan could clarify that?
> 
> Just thinking about AArch64, and how to implement such a thing as well
> as possible.  We can't do a store release to the variable involved in
> the CAS, but perhaps we could do a store release to something local to
> the thread.  That would be better than a full fence, which would be
> overkill for this purpose.  Unlike x86 we can't do an access outside
> the stack.  I'm trying to think of something in memory, probably in
> the local cache, that can be clobbered, but nothing comes to mind.
> OK, here's a mad idea: we could allocate an extra stack slot in a
> method which uses

Would a store release into a dummy field of the JavaThread instance be
better? This would avoid wasting stack space.

regards,


Andrew Dinn
-----------
Senior Principal Software Engineer
Red Hat UK Ltd
Registered in England and Wales under Company Registration No. 03798903
Directors: Michael Cunningham, Michael ("Mike") O'Neill, Eric Shander

From aph at redhat.com  Fri May 26 10:53:28 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 15:53:28 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
Message-ID: <ef92bbcd-f2ae-850d-d922-4c9264bf1493@redhat.com>

On 26/05/17 15:03, Andrew Dinn wrote:
> Would a store release into a dummy field of the JavaThread instance be
> better? This would avoid wasting stack space.

Yes, of course!  Thanks  :-)

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From aph at redhat.com  Fri May 26 11:05:53 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 16:05:53 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
Message-ID: <c6e2fa91-8ca2-9f45-8739-9df6ee29fa8e@redhat.com>

On 26/05/17 14:56, Doug Lea wrote:
> On 05/26/2017 09:35 AM, Andrew Haley wrote:
>> On 26/05/17 13:56, Andrew Dinn wrote:
> 
>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>>  So we cannot change it. But there's not much motivation to do so anyway:
>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>> on CAS failure typically reduces contention and may improve throughput.
>>>
>>> It would be useful to know if that reduction in contention is specific
>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>> AArch64 or ppc. Perhaps Nathan could clarify that?
> 
> The main issues are not tightly bound to architecture.
> In the vast majority of cases, the response to CAS failure is
> some sort of retry (although perhaps with some intermediate
> processing). The fence here plays a similar role to
> Thread.onSpinWait. And in fact, on ARM, is likely to be
> exactly the same implementation as onSpinWait.

onSpinWait is null, and unless ARM does something to the architecture
that's probably what it'll remain.

> As Alex mentioned, in the uncommon cases where this
> is a performance issue, people can use one of the weak CAS
> variants.
> 
>>
>> Just thinking about AArch64, and how to implement such a thing as well
>> as possible. 
> 
> "As well as possible" may be just to unconditionally issue fence,
> at least for plain CAS; maybe differently for the variants.

I doubt that: I've done some measurements, and it always pays to branch
conditionally around a fence if it's not needed.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From gil at azul.com  Fri May 26 11:19:38 2017
From: gil at azul.com (Gil Tene)
Date: Fri, 26 May 2017 15:19:38 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>,
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
Message-ID: <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>



Sent from Gil's iPhone

> On May 26, 2017, at 7:07 AM, Andrew Dinn <adinn at redhat.com> wrote:
> 
>> On 26/05/17 14:35, Andrew Haley wrote:
>>> On 26/05/17 13:56, Andrew Dinn wrote:
>>>> On 26/05/17 13:46, Doug Lea wrote:
>>>> On 05/26/2017 04:44 AM, Andrew Haley wrote:
>>>> 
>>>>>> a compareAndSet has the memory semantics of a volatile
>>>>>> write regardless of whether or not the write occurred. 
>>>>> That property of compareAndSet is very ugly, and is a pain to
>>>>> implement. Most of the CAS instructions I know about don't have such
>>>>> a property, and making it work requires either an unconditional full
>>>>> fence after every CAS or a conditional one if it fails.  Either way
>>>>> sucks mightily and is unlikely to be useful except in the most
>>>>> pathological cases.
>>>> 
>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>> on CAS failure typically reduces contention and may improve throughput.
>>> 
>>> It would be useful to know if that reduction in contention is specific
>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>> AArch64 or ppc. Perhaps Nathan could clarify that?
>> 
>> Just thinking about AArch64, and how to implement such a thing as well
>> as possible.  We can't do a store release to the variable involved in
>> the CAS, but perhaps we could do a store release to something local to
>> the thread.  That would be better than a full fence, which would be
>> overkill for this purpose.  Unlike x86 we can't do an access outside
>> the stack.  I'm trying to think of something in memory, probably in
>> the local cache, that can be clobbered, but nothing comes to mind.
>> OK, here's a mad idea: we could allocate an extra stack slot in a
>> method which uses
> 
> Would a store release into a dummy field of the JavaThread instance be
> better? This would avoid wasting stack space.

I believe that making the hardware perform a store release [or equivalent] to a different location is not sufficient to emulate a volatile write's memory semantics, since it e.g. does not prevent subsequent volatile loads of other fields from floating backwards past the store release point, and then e.g. past prior non-volatile stores to the compareAndSet'ed field.

Basically, there is no StoreLoad ordering [that is required to be] enforced on the hardware by a store release, which makes it insufficient.

Unfortunately, to provide the spec'ed (and the often expected by lay people) behavior, you need to force the hardware to impose a StoreLoad order with the compareAndSet even if the CAS instruction never wrote. If the hardware does not do that in a compare-failing CAS instruction, the code surrounding the CAS obstruction needs to...
 
> 
> regards,
> 
> 
> Andrew Dinn
> -----------
> Senior Principal Software Engineer
> Red Hat UK Ltd
> Registered in England and Wales under Company Registration No. 03798903
> Directors: Michael Cunningham, Michael ("Mike") O'Neill, Eric Shander
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From gil at azul.com  Fri May 26 11:25:14 2017
From: gil at azul.com (Gil Tene)
Date: Fri, 26 May 2017 15:25:14 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>,
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>,
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
Message-ID: <B902D754-7D2D-41C4-99BE-EAC1D9051069@azul.com>



Sent from Gil's iPhone

> On May 26, 2017, at 8:19 AM, Gil Tene <gil at azul.com> wrote:
> 
> 
> 
> Sent from Gil's iPhone
> 
>>> On May 26, 2017, at 7:07 AM, Andrew Dinn <adinn at redhat.com> wrote:
>>> 
>>>> On 26/05/17 14:35, Andrew Haley wrote:
>>>>> On 26/05/17 13:56, Andrew Dinn wrote:
>>>>> On 26/05/17 13:46, Doug Lea wrote:
>>>>> On 05/26/2017 04:44 AM, Andrew Haley wrote:
>>>>> 
>>>>>>> a compareAndSet has the memory semantics of a volatile
>>>>>>> write regardless of whether or not the write occurred. 
>>>>>> That property of compareAndSet is very ugly, and is a pain to
>>>>>> implement. Most of the CAS instructions I know about don't have such
>>>>>> a property, and making it work requires either an unconditional full
>>>>>> fence after every CAS or a conditional one if it fails.  Either way
>>>>>> sucks mightily and is unlikely to be useful except in the most
>>>>>> pathological cases.
>>>>> 
>>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>>> on CAS failure typically reduces contention and may improve throughput.
>>>> 
>>>> It would be useful to know if that reduction in contention is specific
>>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>>> AArch64 or ppc. Perhaps Nathan could clarify that?
>>> 
>>> Just thinking about AArch64, and how to implement such a thing as well
>>> as possible.  We can't do a store release to the variable involved in
>>> the CAS, but perhaps we could do a store release to something local to
>>> the thread.  That would be better than a full fence, which would be
>>> overkill for this purpose.  Unlike x86 we can't do an access outside
>>> the stack.  I'm trying to think of something in memory, probably in
>>> the local cache, that can be clobbered, but nothing comes to mind.
>>> OK, here's a mad idea: we could allocate an extra stack slot in a
>>> method which uses
>> 
>> Would a store release into a dummy field of the JavaThread instance be
>> better? This would avoid wasting stack space.
> 
> I believe that making the hardware perform a store release [or equivalent] to a different location is not sufficient to emulate a volatile write's memory semantics, since it e.g. does not prevent subsequent volatile loads of other fields from floating backwards past the store release point, and then e.g. past prior non-volatile stores to the compareAndSet'ed field.
> 
> Basically, there is no StoreLoad ordering [that is required to be] enforced on the hardware by a store release, which makes it insufficient.
> 
> Unfortunately, to provide the spec'ed (and the often expected by lay people) behavior, you need to force the hardware to impose a StoreLoad order with the compareAndSet even if the CAS instruction never wrote. If the hardware does not do that in a compare-failing CAS instruction, the code surrounding the CAS obstruction needs to..

Obviously, this is assuming that the compareAndSet memory semantics on VarHandles are changed back to what j.u.c.atomic semantics were for compareAndSet in Java 8... before this fix, a StoreLoad on a compare-failing CAS instruction is not required.

>> 
>> regards,
>> 
>> 
>> Andrew Dinn
>> -----------
>> Senior Principal Software Engineer
>> Red Hat UK Ltd
>> Registered in England and Wales under Company Registration No. 03798903
>> Directors: Michael Cunningham, Michael ("Mike") O'Neill, Eric Shander
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

From aph at redhat.com  Fri May 26 11:36:20 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 16:36:20 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
Message-ID: <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>

On 26/05/17 16:19, Gil Tene wrote:

> I bellieve that making the hardware perform a store release [or
> equivalent] to a different location is not sufficient to emulate a
> volatile write's memory semantics, since it e.g. does not prevent
> subsequent volatile loads of other fields from floating backwards
> past the store release point, and then e.g. past prior non-volatile
> stores to the compareAndSet'ed field.

I'm not quite sure I understand this.  ARMv8's store release and load
acquire are sequentially consistent.  So, as far as I can see there is
no way that a subsequent volatile load could possibly float backwards
past such a store.

> Basically, there is no StoreLoad ordering [that is required to be]
> enforced on the hardware by a store release, which makes it
> insufficient.

Oh yuck, this is *so* *horrible*, but I guess I'll stop worrying about
it.  The Java spec is what it is, for whatever reasons.

I've been through denial and anger and there's no point bargaining.
I'm going to try to make depression as short as possible...

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From nathanila at gmail.com  Fri May 26 11:44:25 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Fri, 26 May 2017 09:44:25 -0600
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
 <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
Message-ID: <d981d8e2-db9f-8c0f-c625-55a0f0b1e448@gmail.com>

 > I've been through denial and anger and there's no point bargaining.  
I'm going to try to make depression as short as possible...

After depression, are you going to try avoidance?  ;)  I hope you can 
move to acceptance and peace with the outcome.

-Nathan

On 5/26/2017 9:36 AM, Andrew Haley wrote:
> On 26/05/17 16:19, Gil Tene wrote:
>
>> I bellieve that making the hardware perform a store release [or
>> equivalent] to a different location is not sufficient to emulate a
>> volatile write's memory semantics, since it e.g. does not prevent
>> subsequent volatile loads of other fields from floating backwards
>> past the store release point, and then e.g. past prior non-volatile
>> stores to the compareAndSet'ed field.
> I'm not quite sure I understand this.  ARMv8's store release and load
> acquire are sequentially consistent.  So, as far as I can see there is
> no way that a subsequent volatile load could possibly float backwards
> past such a store.
>
>> Basically, there is no StoreLoad ordering [that is required to be]
>> enforced on the hardware by a store release, which makes it
>> insufficient.
> Oh yuck, this is *so* *horrible*, but I guess I'll stop worrying about
> it.  The Java spec is what it is, for whatever reasons.
>
> I've been through denial and anger and there's no point bargaining.
> I'm going to try to make depression as short as possible...
>

-- 
-Nathan


From gil at azul.com  Fri May 26 12:09:23 2017
From: gil at azul.com (Gil Tene)
Date: Fri, 26 May 2017 16:09:23 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
 <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
Message-ID: <A296A4AF-3C65-4B26-AE06-BADDC067283F@azul.com>


> On May 26, 2017, at 8:36 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 26/05/17 16:19, Gil Tene wrote:
> 
>> I bellieve that making the hardware perform a store release [or
>> equivalent] to a different location is not sufficient to emulate a
>> volatile write's memory semantics, since it e.g. does not prevent
>> subsequent volatile loads of other fields from floating backwards
>> past the store release point, and then e.g. past prior non-volatile
>> stores to the compareAndSet'ed field.
> 
> I'm not quite sure I understand this.  ARMv8's store release and load
> acquire are sequentially consistent.  So, as far as I can see there is
> no way that a subsequent volatile load could possibly float backwards
> past such a store.

For ARMv8, there may still be "hope":

Per the ARM ARM Instruction Set Overview (e.g. https://www.element14.com/community/servlet/JiveServlet/previewBody/41836-102-1-229511/ARM.Reference_Manual.pdf) store release and load
acquire provide Release Consistency (RCsc), [not sequential consistency]. (See 3.5.3, page 12).

Section 5.2.8 (page 29) says:

"A store-release will be observed by each observer after that observer observes any loads or stores that appear in program order before the store-release, but says nothing about loads and stores appearing after the store-release."

However, it also says:

"In addition, a store-release followed by a load-acquire will be observed by each observer in program order."

And combining this with the earlier:

"A load-acquire is a load where it is guaranteed that all loads and stores appearing in program order after the load- acquire will be observed by each observer after that observer observes the load-acquire, but says nothing about loads and stores appearing before the load-acquire."

would mean [transitively, by my interpretation] that "all loads and stores appearing in program order after a load-aquire that follows a store-release will be observed by each observer after the observer observes any loads or stores that appear in program order before the store-release"

So ***for ARMv8*** a store-release followed by a load-aquire (e.g. both the a thread local) will impose a StoreLoad order.

[This is not a general property of store-release and load-aquire]

> 
>> Basically, there is no StoreLoad ordering [that is required to be]
>> enforced on the hardware by a store release, which makes it
>> insufficient.
> 
> Oh yuck, this is *so* *horrible*, but I guess I'll stop worrying about
> it.  The Java spec is what it is, for whatever reasons.
> 
> I've been through denial and anger and there's no point bargaining.
> I'm going to try to make depression as short as possible...
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671


From nathanila at gmail.com  Fri May 26 12:15:17 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Fri, 26 May 2017 10:15:17 -0600
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
Message-ID: <0b1cb71b-f186-fc59-38c0-7c938755cfa8@gmail.com>

The particular situation I encountered was on x86 hardware. However, 
even on other memory architectures, replacing writes with full fences is 
definitely faster.  Here's why.  x86 hardware implements MESI cache 
protocol.  These other architectures implement MERSI cache protocol.

Background information:  On some (all?) x86 architectures, CAS is 
implemented in L3 cache.  The core executing CAS has to send a message 
to the L3 cache and wait for the L3 cache to reply stating if the 
operation succeed or failed.  This explains why CAS takes so many 
cycles.  The benefit is that the L3 cache can keep the only copy of the 
cache line and all of the cores on the processor can send CAS operations 
and get higher throughput.  If CAS were implemented in L1 cache and the 
core's pipeline, then it would take about 9 cycles.  3 cycles to load 
the data into the core's pipeline.  3 cycles to execute the comparison.  
3 cycles to store data into the cache line.  This would yield higher 
performance (lower CAS latency) but would lower overall throughput since 
the cache line would have to travel among the cores in the processor.

In both cache protocols, a write forces the cache line into the M 
(modified) state.  Thus, the cache line can only exist in 1 cache and 
hence must move from L3 cache to L3 cache in order to be modified by the 
cores in each processor.  This will cause cores to stall while they 
attempt to get the cache line into its own L3 cache in the E (exclusive) 
or M (modified) states.

Instead, if we replace the write with a full fence, then the cache line 
can stay longer in the S (shared) state.  Thus, the cache line can exist 
in all caches.  All of the cores can progress at a higher throughput.  
The penalty is that they have to implement a full fence.  The number of 
cycles to implement a full fence is less than or equal to stalling 
waiting for a highly contended cache line.  It depends on the case.  In 
the case where the loads and stores can proceed quickly because all of 
the cache lines are available, the full fence will have very little to 
no impact.  In the case where a load or store before the full fence is 
waiting for a cache line, then the pipeline will stall.  If the load or 
store is waiting for that highly contended cache line, then the full 
fence will be no faster (or slower).

So, if we can replace writes with full fences, we will get faster 
performance and better cache scalability since the cache line doesn't 
have to travel among processors.

-Nathan

On 5/26/2017 6:56 AM, Andrew Dinn wrote:
> On 26/05/17 13:46, Doug Lea wrote:
>> On 05/26/2017 04:44 AM, Andrew Haley wrote:
>>
>>>> a compareAndSet has the memory semantics of a volatile
>>>> write regardless of whether or not the write occurred.
>>> That property of compareAndSet is very ugly, and is a pain to
>>> implement. Most of the CAS instructions I know about don't have such
>>> a property, and making it work requires either an unconditional full
>>> fence after every CAS or a conditional one if it fails.  Either way
>>> sucks mightily and is unlikely to be useful except in the most
>>> pathological cases.
>>>
>> Initially (in Java5) requiring it has led to some questionable reliance.
>>   So we cannot change it. But there's not much motivation to do so anyway:
>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>> on CAS failure typically reduces contention and may improve throughput.
> It would be useful to know if that reduction in contention is specific
> to, say, x86 hardware or also occurs on weak memory architectures like
> AArch64 or ppc. Perhaps Nathan could clarify that?
>
> regards,
>
>
> Andrew Dinn
> -----------
> Senior Principal Software Engineer
> Red Hat UK Ltd
> Registered in England and Wales under Company Registration No. 03798903
> Directors: Michael Cunningham, Michael ("Mike") O'Neill, Eric Shander
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From gil at azul.com  Fri May 26 12:22:07 2017
From: gil at azul.com (Gil Tene)
Date: Fri, 26 May 2017 16:22:07 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
Message-ID: <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>


> On May 26, 2017, at 6:56 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> 
> On 05/26/2017 09:35 AM, Andrew Haley wrote:
>> On 26/05/17 13:56, Andrew Dinn wrote:
> 
>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>> on CAS failure typically reduces contention and may improve throughput.
>>> 
>>> It would be useful to know if that reduction in contention is specific
>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>> AArch64 or ppc. Perhaps Nathan could clarify that?
> 
> The main issues are not tightly bound to architecture.
> In the vast majority of cases, the response to CAS failure is
> some sort of retry (although perhaps with some intermediate
> processing). The fence here plays a similar role to
> Thread.onSpinWait. And in fact, on ARM, is likely to be
> exactly the same implementation as onSpinWait.
> 
> As Alex mentioned, in the uncommon cases where this
> is a performance issue, people can use one of the weak CAS
> variants.

Actually this is another case where the Java 9 spec needs to be adjusted…

In Java 8, weakCompareAnbdSet is explicitly discussed in the j.u.c.atomic JavaDoc package description with this sentence:
"weakCompareAndSet atomically reads and conditionally writes a variable but does not create any happens-before orderings, so provides no guarantees with respect to previous or subsequent reads and writes of any variables other than the target of the weakCompareAndSet."

However, the current JavaDoc for VarHandle.weakCompareAndSet() (http://download.java.net/java/jdk9/docs/api/java/lang/invoke/VarHandle.html#weakCompareAndSet-java.lang.Object…- ) says:

"Possibly atomically sets the value of a variable to the newValue with the memory semantics of setVolatile(java.lang.Object...) if the variable's current value, referred to as the witness value, == the expectedValue, as accessed with the memory semantics of getVolatile(java.lang.Object…)."

It also mentions setVolatile(Object...), getVolatile(Object…) in the "see also" section.

This should probably be changed to drop the mentions of memory semantics requirement from weakCompareAnbdSet, and maybe even explicitly state that it makes no memory semantics guarantees (like the language in Java 8 did).

> 
>> 
>> Just thinking about AArch64, and how to implement such a thing as well
>> as possible. 
> 
> "As well as possible" may be just to unconditionally issue fence,
> at least for plain CAS; maybe differently for the variants.
> 
> -Doug
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From aph at redhat.com  Fri May 26 12:43:41 2017
From: aph at redhat.com (Andrew Haley)
Date: Fri, 26 May 2017 17:43:41 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <A296A4AF-3C65-4B26-AE06-BADDC067283F@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
 <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
 <A296A4AF-3C65-4B26-AE06-BADDC067283F@azul.com>
Message-ID: <bac310b2-df6f-6f64-50b6-f84b3e079d85@redhat.com>

On 26/05/17 17:09, Gil Tene wrote:
> loads or stores that appear in program order before the store-release"
> 
> So ***for ARMv8*** a store-release followed by a load-aquire (e.g. both the a thread local) will impose a StoreLoad order.
> 
> [This is not a general property of store-release and load-aquire]

That's right.  By the way, the memory model for ARM has been rewritten,
and the engineer who wrote it promises me absolutely and truly that the
instructions are sequentially consistent, and were always intended to be.

https://developer.arm.com/docs/ddi0487/latest/arm-architecture-reference-manual-armv8-for-armv8-a-architecture-profile

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From boehm at acm.org  Fri May 26 14:19:48 2017
From: boehm at acm.org (Hans Boehm)
Date: Fri, 26 May 2017 11:19:48 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <bac310b2-df6f-6f64-50b6-f84b3e079d85@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
 <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
 <A296A4AF-3C65-4B26-AE06-BADDC067283F@azul.com>
 <bac310b2-df6f-6f64-50b6-f84b3e079d85@redhat.com>
Message-ID: <CAPUmR1Zy=_-KmhWssGkxEDSOiYw=xO6Jt1ZuyrDKRAA3xq2vvw@mail.gmail.com>

Someone from ARM should chime in here, but my understanding is that ARMv8
acquire/release loads and stores are designed to exactly model C++
memory_order_seq_cst (NOT memory_order_acquire/memory_order_release) loads
and stores. They do NOT imply fences. They are not intended to implement
fences. They should not be used to implement fences. The architecture still
has fences, so there is no need to.

For example,

r1 = x;
store release to v;
r2 = y;

Does not order the accesses to x and y any more than a C++ sequentially
consistent store would order relaxed accesses to x and y.

Atomic RMW operations implemented with ARM acquire/release primitives have
roughly the memory ordering semantics of a RMW operation implemented with a
lock. They are NOT fences, should NOT be used to implement fences, etc. For
example,

r1 = x;
x.lock();
...
x.unlock();
r2 = y;

does NOT order the accesses to x and y, since both can move into the
critical section and pass each other. The same applies to ARMv8 RMW
operations.

My reading of the spec is that a sequentially consistent store followed by
a sequentially consistent load is still not sufficient to generate the
equivalent of a fence. (I would guess that on current hardware it probably
is, but I don't know.) If there are no observers of the release store, it
promises essentially no ordering. There is no good reason to that anyway.

AFAICT, the discussion about atomic RMW as fence replacement is entirely
x86-specific. I'm not sure, but it seems to be caused by the fact that an
x86 MFENCE makes all sorts of other guarantees about write-coalescing
memory, etc., that we don't really care about. The RMW operations do not,
and are thus often faster. My guess is that the problem originates from the
fact that x86 doesn't have a suitably plain vanilla fence instruction.

I'm not sure how this interacts with the original discussion. There's still
the interesting question of whether a volatile write that doesn't change
the value of an object is observable.

On Fri, May 26, 2017 at 9:43 AM, Andrew Haley <aph at redhat.com> wrote:

> On 26/05/17 17:09, Gil Tene wrote:
> > loads or stores that appear in program order before the store-release"
> >
> > So ***for ARMv8*** a store-release followed by a load-aquire (e.g. both
> the a thread local) will impose a StoreLoad order.
> >
> > [This is not a general property of store-release and load-aquire]
>
> That's right.  By the way, the memory model for ARM has been rewritten,
> and the engineer who wrote it promises me absolutely and truly that the
> instructions are sequentially consistent, and were always intended to be.
>
> https://developer.arm.com/docs/ddi0487/latest/arm-
> architecture-reference-manual-armv8-for-armv8-a-architecture-profile
>
> --
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170526/1e1c947a/attachment-0001.html>

From dl at cs.oswego.edu  Fri May 26 15:59:10 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Fri, 26 May 2017 15:59:10 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
Message-ID: <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>

On 05/26/2017 12:22 PM, Gil Tene wrote:

> 
> Actually this is another case where the Java 9 spec needs to be adjusted…

The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
  https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
  "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
  "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug




From nathanila at gmail.com  Fri May 26 16:08:50 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Fri, 26 May 2017 14:08:50 -0600
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
Message-ID: <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>

 > "The memory effects of a write occur regardless of outcome."
 > "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere 
in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the 
modified state even if an actual write doesn't occur?  Or does memory 
effects have to do with ordering of memory operations with respect to 
the method's operation?

-Nathan
On 5/26/2017 1:59 PM, Doug Lea wrote:
> On 05/26/2017 12:22 PM, Gil Tene wrote:
>
>> Actually this is another case where the Java 9 spec needs to be adjusted…
> The pre-jdk9 method for weak CAS is now available in four
> flavors: weakCompareAndSetPlain, weakCompareAndSet,
> weakCompareAndSetAcquire, weakCompareAndSetRelease.
> They have different read/write access modes. The specs reflect this.
> The one keeping the name weakCompareAndSet is stronger, the others
> weaker than before (this is the only naming scheme that works).
>
> About those specs... see JBS JDK-8181104
>    https://bugs.openjdk.java.net/browse/JDK-8181104
> The plan is for all CAS VarHandle methods to include the sentence
>    "The memory effects of a write occur regardless of outcome."
> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
> getAndAccumulate, accumulateAndGet to include the sentence:
>    "This method has memory effects of at least one volatile read and write."
>
> Which should clear up confusion.
>
> -Doug
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan


From boehm at acm.org  Fri May 26 17:35:47 2017
From: boehm at acm.org (Hans Boehm)
Date: Fri, 26 May 2017 14:35:47 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
Message-ID: <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>

Could we please get an example (i.e. litmus test) of how the "memory effect
of at least one volatile ... write" is visible, and where it's useful?
Since some people seem really attached to it, it shouldn't be that hard to
generate a litmus test.

So far we have a claim that it could affect progress guarantees, i.e.
whether prior writes eventually become visible without further
synchronization. I kind of, sort of, half-way believe that.

I haven't been able to make sense out of the subsequent illustration
attempts. I really don't think it makes sense to require such weird
behavior unless we can at least clearly define exactly what the weird
behavior buys us. We really need a concise, or at least precise and
understandable, rationale.

As has been pointed out before, a volatile write W by T1 to x of the same
value that was there before is not easily observable. If I read that value
in another thread T2, I can't tell which write I'm seeing, and hence hence
a failure to see prior T1 writes is OK; I might have not seen the final
write to x. Thus I would need to communicate the  fact that T1 completed W
without actually looking at x. That seems to involve another
synchronization of T1 with T2, which by itself would ensure the visibility
of prior writes to T2.

Thus, aside from possible really obscure progress/liveness issues, I really
don't see the difference. I think this requirement, if it is indeed not
vacuous and completely ignorable, would lengthen the ARMv8 code sequence
for a CAS by at least 2 instructions, and introduce a very obscure
divergence from C and C++.

I'm worried that we're adding something to make RMW operations behave more
like fences. They don't, they can't, and they shouldn't.

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <
nathanila at gmail.com> wrote:

> > "The memory effects of a write occur regardless of outcome."
> > "This method has memory effects of at least one volatile read and write."
>
> I am not sure what memory effects means.  If this is defined somewhere in
> the specs, then ignore this since I haven't read JDK 9 specs.
>
> Does memory effects mean the cache line will be switched into the modified
> state even if an actual write doesn't occur?  Or does memory effects have
> to do with ordering of memory operations with respect to the method's
> operation?
>
> -Nathan
>
> On 5/26/2017 1:59 PM, Doug Lea wrote:
>
>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>
>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>
>> The pre-jdk9 method for weak CAS is now available in four
>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>> They have different read/write access modes. The specs reflect this.
>> The one keeping the name weakCompareAndSet is stronger, the others
>> weaker than before (this is the only naming scheme that works).
>>
>> About those specs... see JBS JDK-8181104
>>    https://bugs.openjdk.java.net/browse/JDK-8181104
>> The plan is for all CAS VarHandle methods to include the sentence
>>    "The memory effects of a write occur regardless of outcome."
>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>> getAndAccumulate, accumulateAndGet to include the sentence:
>>    "This method has memory effects of at least one volatile read and
>> write."
>>
>> Which should clear up confusion.
>>
>> -Doug
>>
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> --
> -Nathan
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170526/2491e958/attachment.html>

From aph at redhat.com  Sat May 27 01:58:49 2017
From: aph at redhat.com (Andrew Haley)
Date: Sat, 27 May 2017 06:58:49 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
Message-ID: <046c9835-da0e-ecc5-9363-c6db0d42d69f@redhat.com>

On 26/05/17 22:35, Hans Boehm wrote:

> Thus, aside from possible really obscure progress/liveness issues, I
> really don't see the difference. I think this requirement, if it is
> indeed not vacuous and completely ignorable, would lengthen the
> ARMv8 code sequence for a CAS by at least 2 instructions, and
> introduce a very obscure divergence from C and C++.

It's the latter, the divergence from C and C++, that seems most
unfortunate to me.  The extra fence will cost everyone, but most
people won't be aware of it.  And code which does take advantage
of the fence will be *very* obscure.  If there is any such code...

> I'm worried that we're adding something to make RMW operations
  behave more like fences. They don't, they can't, and they shouldn't.

I couldn't agree more.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From aph at redhat.com  Sat May 27 02:39:03 2017
From: aph at redhat.com (Andrew Haley)
Date: Sat, 27 May 2017 07:39:03 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
Message-ID: <7af0b326-7ade-b92a-5bc8-9f261691ee26@redhat.com>

On 26/05/17 21:08, Nathan and Ila Reynolds wrote:
> Does memory effects mean the cache line will be switched into the 
> modified state even if an actual write doesn't occur?  Or does memory 
> effects have to do with ordering of memory operations with respect to 
> the method's operation?

Cache line states aren't visible to a program, so all we can see
are ordering relationships between reads and writes.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Sat May 27 02:42:28 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sat, 27 May 2017 07:42:28 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
Message-ID: <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>

Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

if( ! z.CAS(i, j) ) {
  k = z.get();
  if(k < j) {
    // i < k < j
    // whoever mutated z from i to k, should also negotiate mutation of z from k to j
    // with someone else, and they should observe whatever stores precede z.CAS
    // because I won’t contend.

    // of course, I need to check they are still at it - but that, too, does not require
    // stores or CASes
    ...
    return;
  }
}

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.


In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?


Alex


> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org> wrote:
> 
> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
> 
> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
> 
> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
> 
> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
> 
> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
> 
> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
> 
> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
> > "The memory effects of a write occur regardless of outcome."
> > "This method has memory effects of at least one volatile read and write."
> 
> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
> 
> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
> 
> -Nathan
> 
> On 5/26/2017 1:59 PM, Doug Lea wrote:
> On 05/26/2017 12:22 PM, Gil Tene wrote:
> 
> Actually this is another case where the Java 9 spec needs to be adjusted…
> The pre-jdk9 method for weak CAS is now available in four
> flavors: weakCompareAndSetPlain, weakCompareAndSet,
> weakCompareAndSetAcquire, weakCompareAndSetRelease.
> They have different read/write access modes. The specs reflect this.
> The one keeping the name weakCompareAndSet is stronger, the others
> weaker than before (this is the only naming scheme that works).
> 
> About those specs... see JBS JDK-8181104
>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
> The plan is for all CAS VarHandle methods to include the sentence
>    "The memory effects of a write occur regardless of outcome."
> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
> getAndAccumulate, accumulateAndGet to include the sentence:
>    "This method has memory effects of at least one volatile read and write."
> 
> Which should clear up confusion.
> 
> -Doug
> 
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> -- 
> -Nathan
> 
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/77e45a4c/attachment.html>

From gergg at cox.net  Sat May 27 03:05:42 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Sat, 27 May 2017 02:05:42 -0500
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <Qwnq1v00l02hR0p01wnuCt>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com> <Qwnq1v00l02hR0p01wnuCt>
Message-ID: <44D3C0CF-6520-4215-828B-52B866EE7509@cox.net>

The “visibility” part of the JMM, since 1.5, has plagued many applications by requiring viral use of synchronization or fences or large scale happens before studies.  This happened because hardware cache line abuse was horribly expensive and so people tried to avoid synchronized after seeing how much faster HashMap and ArrayList were, compared to Hashtable and Vector.   So, people first just avoided synchronized, and lost edges that cause visibility to suddenly be a problem.

Add to that, the deadly optimization of non-volatile loop control parameters into if() { while(true){} }, and suddenly the recommendation everywhere as “volatile” or “final” on every class variable so that loops would start working again.

As people learned more and more about how java.util.concurrent worked, and stared at source, and read comments and tried to comprehend things, suddenly Unsafe.XXX was being used in lots of places to try and “fix” problems where “synchronized” was too expensive, but happens before was needed for visibility.

In the end, I think it was a pretty grave error to not make “volatile” the default and require some annotation to say, I know how to manage the visibility of this variable.  

We are at the point now, that all of these kinds of discussions with disgust and confusion, point to the wrong path having been taken.  There is way too much wiring and way too much of it visible as cross-domain side effects.   Side effects across objects and those which when removed invalidate unrelated software, are exactly the problems we really don’t need.

Gregg

> On May 26, 2017, at 3:44 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 25/05/17 18:15, Gil Tene wrote:
>> 
>> 
>> Sent from my iPad
>> 
>>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>> 
>>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>> 
>> While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 
>> 
>> In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.
> That property of compareAndSet is very ugly, and is a pain to implement.
> Most of the CAS instructions I know about don't have such a property,
> and making it work requires either an unconditional full fence after every
> CAS or a conditional one if it fails.  Either way sucks mightily and
> is unlikely to be useful except in the most pathological cases.
> 
> Besides, how does it ever make sense to synchronize with a store that
> never happened?
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gil at azul.com  Sat May 27 11:14:55 2017
From: gil at azul.com (Gil Tene)
Date: Sat, 27 May 2017 15:14:55 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <CAPUmR1Zy=_-KmhWssGkxEDSOiYw=xO6Jt1ZuyrDKRAA3xq2vvw@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <5d9518d7-af56-4d32-7915-dedc00a5499d@redhat.com>
 <9FAB58E6-EAF0-4F9A-B576-FC7C9C888334@azul.com>
 <e84e0d70-f923-96de-9ac8-ed4d98bb7377@redhat.com>
 <A296A4AF-3C65-4B26-AE06-BADDC067283F@azul.com>
 <bac310b2-df6f-6f64-50b6-f84b3e079d85@redhat.com>
 <CAPUmR1Zy=_-KmhWssGkxEDSOiYw=xO6Jt1ZuyrDKRAA3xq2vvw@mail.gmail.com>
Message-ID: <640C4701-E306-49A5-A21F-B05C47CD96A6@azul.com>



Sent from my iPad

On May 26, 2017, at 11:19 AM, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Someone from ARM should chime in here, but my understanding is that ARMv8 acquire/release loads and stores are designed to exactly model C++ memory_order_seq_cst (NOT memory_order_acquire/memory_order_release) loads and stores. They do NOT imply fences. They are not intended to implement fences. They should not be used to implement fences. The architecture still has fences, so there is no need to.

I see my mistake. My transitive interpretation omitted the requirement for an observer of the store-release and load-aquire.  Since the ordering guarantees of the load-acquire and Store-release statements in the ARM spec involve only the observers of the load-acquire or store-release in question, the processor is allowed to e.g. optimize them away in cases where it can prove that no such observer exists.

E.g. In a practical/possible way, in the following sequence:

  r1 = a
  b = r2
store release r3 to v
r4 = load-acquire from v
  r5 = c
  d = r6
v = r7

The processor, knowing that v will be stomped with the value of r7, and that it is possible that no observer would see the store release of r3 to v before that stomp happens, could ensure that no observer would see the store-release by (somehow) folding the two stores. Similarly, since it is also possible that no observer would interfere with the value of v between the store release and the load acquire, it can fold that away, assign the value of r4 to r3, and eliminate the load-aquire operation. Altogether it validly transform the sequence to and execute it as:

r4 = r3
 d = r6
 r5 = c
 b = r2
 r1 = a
v = r7

eliminating all ordering implication of the load-acquire or store-release, since both can be prevented from ever having any observers,


For example,

r1 = x;
store release to v;
r2 = y;

Does not order the accesses to x and y any more than a C++ sequentially consistent store would order relaxed accesses to x and y.

Atomic RMW operations implemented with ARM acquire/release primitives have roughly the memory ordering semantics of a RMW operation implemented with a lock. They are NOT fences, should NOT be used to implement fences, etc. For example,

r1 = x;
x.lock();
...
x.unlock();
r2 = y;

does NOT order the accesses to x and y, since both can move into the critical section and pass each other. The same applies to ARMv8 RMW operations.

My reading of the spec is that a sequentially consistent store followed by a sequentially consistent load is still not sufficient to generate the equivalent of a fence. (I would guess that on current hardware it probably is, but I don't know.) If there are no observers of the release store, it promises essentially no ordering. There is no good reason to that anyway.

AFAICT, the discussion about atomic RMW as fence replacement is entirely x86-specific. I'm not sure, but it seems to be caused by the fact that an x86 MFENCE makes all sorts of other guarantees about write-coalescing memory, etc., that we don't really care about. The RMW operations do not, and are thus often faster. My guess is that the problem originates from the fact that x86 doesn't have a suitably plain vanilla fence instruction.

I'm not sure how this interacts with the original discussion. There's still the interesting question of whether a volatile write that doesn't change the value of an object is observable.

On Fri, May 26, 2017 at 9:43 AM, Andrew Haley <aph at redhat.com<mailto:aph at redhat.com>> wrote:
On 26/05/17 17:09, Gil Tene wrote:
> loads or stores that appear in program order before the store-release"
>
> So ***for ARMv8*** a store-release followed by a load-aquire (e.g. both the a thread local) will impose a StoreLoad order.
>
> [This is not a general property of store-release and load-aquire]

That's right.  By the way, the memory model for ARM has been rewritten,
and the engineer who wrote it promises me absolutely and truly that the
instructions are sequentially consistent, and were always intended to be.

https://developer.arm.com/docs/ddi0487/latest/arm-architecture-reference-manual-armv8-for-armv8-a-architecture-profile

--
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com<https://www.redhat.com/>>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/7ec9bf02/attachment-0001.html>

From jsampson at guidewire.com  Sat May 27 13:13:41 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Sat, 27 May 2017 17:13:41 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
Message-ID: <21987417-24BC-4551-AB98-9FADC63F1F55@guidewire.com>

Alex Otenko wrote:

> If whoever mutated z from i to k cannot observe stores that precede z.CAS,
> they won’t attempt to mutate z to j.

In your example, how does that other thread know that it is responsible for mutating z to j? What if it has gone on to other things before z.CAS(i, j) even happens?

> In return can someone explain what the difference is between a
> weakCompareAndSet failing spuriously and compareAndSet not guaranteeing
> volatile store semantics on fail? Why should we weaken the promise, if there
> is already a weak promise to not guarantee visibility on fail?

Spurious failure is more about the read than the write, I think. With spurious failure, you can't even rely on volatile read semantics if the CAS fails, because failure doesn't give any information at all about the current value. Without spurious failure, at the very least you know that the current value != the expected value if the CAS fails.

Consider the following levels of CAS strength, off the top of my head:

1. Volatile read always, volatile write always, no spurious failures.
2. Volatile read always, volatile write only if successful, no spurious failures.
3. Volatile read always, volatile write only if value changed, no spurious failures.
4. Volatile read only if successful, volatile write only if value changed, spurious failures allowed.
5. No volatile read, no volatile write, spurious failures allowed.

In JDK 8, compareAndSet was spec'd as #1 and weakCompareAndSet was spec'd as #5, whereas e.g. AtomicStampedReference's compareAndSet method was actually implemented as #3. In my limited concurrency coding, I don't think I've ever wanted something stronger than #3 or weaker than #4. I will be curious to learn whether any of the CAS versions in JDK 9 match those two particular levels.

Cheers,
Justin


From boehm at acm.org  Sat May 27 13:34:55 2017
From: boehm at acm.org (Hans Boehm)
Date: Sat, 27 May 2017 10:34:55 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
Message-ID: <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>

This still makes no sense to me. Nobody is suggesting that we remove the
volatile read guarantee on failure (unlike the weak... version). If the CAS
fails, you are guaranteed to see memory affects that happen before the
successful change to z. We're talking about the "volatile write semantics"
for the write that didn't happen.

This would all be much easier if we had a litmus test (including code
snippets for all involved threads) that could distinguish between the two
behaviors. I conjecture that all such tests involve potentially infinite
loops, and that none of them reflect real programming concerns.

I also conjecture that there exists real code that relies on CAS acting as
a fence. We should be crystal clear that such code is broken.

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> Integers provide extra structure to plain boolean “failed/succeeded”.
> Linked data structures with extra dependencies of their contents can also
> offer extra structure.
>
> if( ! z.CAS(i, j) ) {
>   k = z.get();
>   if(k < j) {
>     // i < k < j
>     // whoever mutated z from i to k, should also negotiate mutation of z
> from k to j
>     // with someone else, and they should observe whatever stores precede
> z.CAS
>     // because I won’t contend.
>
>     // of course, I need to check they are still at it - but that, too,
> does not require
>     // stores or CASes
>     ...
>     return;
>   }
> }
>
> If whoever mutated z from i to k cannot observe stores that precede z.CAS,
> they won’t attempt to mutate z to j.
>
>
> In return can someone explain what the difference is between a
> weakCompareAndSet failing spuriously and compareAndSet not guaranteeing
> volatile store semantics on fail? Why should we weaken the promise, if
> there is already a weak promise to not guarantee visibility on fail?
>
>
> Alex
>
>
> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org> wrote:
>
> Could we please get an example (i.e. litmus test) of how the "memory
> effect of at least one volatile ... write" is visible, and where it's
> useful? Since some people seem really attached to it, it shouldn't be that
> hard to generate a litmus test.
>
> So far we have a claim that it could affect progress guarantees, i.e.
> whether prior writes eventually become visible without further
> synchronization. I kind of, sort of, half-way believe that.
>
> I haven't been able to make sense out of the subsequent illustration
> attempts. I really don't think it makes sense to require such weird
> behavior unless we can at least clearly define exactly what the weird
> behavior buys us. We really need a concise, or at least precise and
> understandable, rationale.
>
> As has been pointed out before, a volatile write W by T1 to x of the same
> value that was there before is not easily observable. If I read that value
> in another thread T2, I can't tell which write I'm seeing, and hence hence
> a failure to see prior T1 writes is OK; I might have not seen the final
> write to x. Thus I would need to communicate the  fact that T1 completed W
> without actually looking at x. That seems to involve another
> synchronization of T1 with T2, which by itself would ensure the visibility
> of prior writes to T2.
>
> Thus, aside from possible really obscure progress/liveness issues, I
> really don't see the difference. I think this requirement, if it is indeed
> not vacuous and completely ignorable, would lengthen the ARMv8 code
> sequence for a CAS by at least 2 instructions, and introduce a very obscure
> divergence from C and C++.
>
> I'm worried that we're adding something to make RMW operations behave more
> like fences. They don't, they can't, and they shouldn't.
>
> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <
> nathanila at gmail.com> wrote:
>
>> > "The memory effects of a write occur regardless of outcome."
>> > "This method has memory effects of at least one volatile read and
>> write."
>>
>> I am not sure what memory effects means.  If this is defined somewhere in
>> the specs, then ignore this since I haven't read JDK 9 specs.
>>
>> Does memory effects mean the cache line will be switched into the
>> modified state even if an actual write doesn't occur?  Or does memory
>> effects have to do with ordering of memory operations with respect to the
>> method's operation?
>>
>> -Nathan
>>
>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>
>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>
>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>
>>> The pre-jdk9 method for weak CAS is now available in four
>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>> They have different read/write access modes. The specs reflect this.
>>> The one keeping the name weakCompareAndSet is stronger, the others
>>> weaker than before (this is the only naming scheme that works).
>>>
>>> About those specs... see JBS JDK-8181104
>>>    https://bugs.openjdk.java.net/browse/JDK-8181104
>>> The plan is for all CAS VarHandle methods to include the sentence
>>>    "The memory effects of a write occur regardless of outcome."
>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>    "This method has memory effects of at least one volatile read and
>>> write."
>>>
>>> Which should clear up confusion.
>>>
>>> -Doug
>>>
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> --
>> -Nathan
>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/bed38100/attachment.html>

From boehm at acm.org  Sat May 27 13:53:57 2017
From: boehm at acm.org (Hans Boehm)
Date: Sat, 27 May 2017 10:53:57 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <44D3C0CF-6520-4215-828B-52B866EE7509@cox.net>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <44D3C0CF-6520-4215-828B-52B866EE7509@cox.net>
Message-ID: <CAPUmR1Y5QfMjQCTokwf-OJMbgAnqWKmdD66UY4w9bKnKubJsFQ@mail.gmail.com>

I continue to disagree. Most code should not be using racing variable
accesses to start with. It's really hard to get such code correct, volatile
semantics or not. And surprisingly often it ends up being slower than just
using locks. Especially on something like ARM, where lock-based code often
requires fewer fences than clever lock-free code.

If you ignore that advice, and you know which variable accesses are racing,
you should declare them volatile or atomic, because readers of the code
will want to know, too. And you're back to sequentially consistent
semantics. If you don't know which variable accesses are racing, odds are
about 99.9% that your code is broken anyway.

If just using volatile semantics is still too slow, then you are indeed
stuck with reasoning about visibility, and correctness arguments will be a
mess, stuff may not compose well, etc. But if you're in that situation,
volatile-by-default wouldn't have helped you either.

On Sat, May 27, 2017 at 12:05 AM, Gregg Wonderly <gergg at cox.net> wrote:

> The “visibility” part of the JMM, since 1.5, has plagued many applications
> by requiring viral use of synchronization or fences or large scale happens
> before studies.  This happened because hardware cache line abuse was
> horribly expensive and so people tried to avoid synchronized after seeing
> how much faster HashMap and ArrayList were, compared to Hashtable and
> Vector.   So, people first just avoided synchronized, and lost edges that
> cause visibility to suddenly be a problem.
>
> Add to that, the deadly optimization of non-volatile loop control
> parameters into if() { while(true){} }, and suddenly the recommendation
> everywhere as “volatile” or “final” on every class variable so that loops
> would start working again.
>
> As people learned more and more about how java.util.concurrent worked, and
> stared at source, and read comments and tried to comprehend things,
> suddenly Unsafe.XXX was being used in lots of places to try and “fix”
> problems where “synchronized” was too expensive, but happens before was
> needed for visibility.
>
> In the end, I think it was a pretty grave error to not make “volatile” the
> default and require some annotation to say, I know how to manage the
> visibility of this variable.
>
> We are at the point now, that all of these kinds of discussions with
> disgust and confusion, point to the wrong path having been taken.  There is
> way too much wiring and way too much of it visible as cross-domain side
> effects.   Side effects across objects and those which when removed
> invalidate unrelated software, are exactly the problems we really don’t
> need.
>
> Gregg
>
> > On May 26, 2017, at 3:44 AM, Andrew Haley <aph at redhat.com> wrote:
> >
> > On 25/05/17 18:15, Gil Tene wrote:
> >>
> >>
> >> Sent from my iPad
> >>
> >>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
> >>>
> >>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
> >>
> >> While on this subject, was the relative "weakening" of compareAndSet
> (and other) memory semantics between Java 8 and java 9 discussed elsewhere?
> >>
> >> In java 8, a compareAndSet has the memory semantics of a volatile write
> regardless of whether or not the write occurred. In java 9 it only has a
> volatile write effect if the write occurs. While the loosening in the
> non-writing case may allow for additional optimizations, I worry that it
> may break existing code that could rely on the previous behavior.
> > That property of compareAndSet is very ugly, and is a pain to implement.
> > Most of the CAS instructions I know about don't have such a property,
> > and making it work requires either an unconditional full fence after
> every
> > CAS or a conditional one if it fails.  Either way sucks mightily and
> > is unlikely to be useful except in the most pathological cases.
> >
> > Besides, how does it ever make sense to synchronize with a store that
> > never happened?
> >
> > --
> > Andrew Haley
> > Java Platform Lead Engineer
> > Red Hat UK Ltd. <https://www.redhat.com>
> > EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> > _______________________________________________
> > Concurrency-interest mailing list
> > Concurrency-interest at cs.oswego.edu
> > http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/0d776db4/attachment-0001.html>

From oleksandr.otenko at gmail.com  Sat May 27 18:26:31 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sat, 27 May 2017 23:26:31 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
Message-ID: <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>

Not sure what you mean by “acting as a fence” being broken.

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.


int x=0; // non-volatile
volatile int z=0;
volatile boolean b=false;

Thread1:
if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  }
}
return x;

Thread2:
x=1;
if (!CAS(z, 0, 2)) {
  return b;
}
return true;

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.


Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)


Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.


Alex

> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org> wrote:
> 
> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
> 
> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
> 
> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
> 
> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
> 
> if( ! z.CAS(i, j) ) {
>   k = z.get();
>   if(k < j) {
>     // i < k < j
>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>     // with someone else, and they should observe whatever stores precede z.CAS
>     // because I won’t contend.
> 
>     // of course, I need to check they are still at it - but that, too, does not require
>     // stores or CASes
>     ...
>     return;
>   }
> }
> 
> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
> 
> 
> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
> 
> 
> Alex
> 
> 
>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>> 
>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>> 
>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>> 
>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>> 
>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>> 
>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>> 
>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>> 
>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>> > "The memory effects of a write occur regardless of outcome."
>> > "This method has memory effects of at least one volatile read and write."
>> 
>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>> 
>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>> 
>> -Nathan
>> 
>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>> 
>> Actually this is another case where the Java 9 spec needs to be adjusted…
>> The pre-jdk9 method for weak CAS is now available in four
>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>> They have different read/write access modes. The specs reflect this.
>> The one keeping the name weakCompareAndSet is stronger, the others
>> weaker than before (this is the only naming scheme that works).
>> 
>> About those specs... see JBS JDK-8181104
>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>> The plan is for all CAS VarHandle methods to include the sentence
>>    "The memory effects of a write occur regardless of outcome."
>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>> getAndAccumulate, accumulateAndGet to include the sentence:
>>    "This method has memory effects of at least one volatile read and write."
>> 
>> Which should clear up confusion.
>> 
>> -Doug
>> 
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
>> -- 
>> -Nathan
>> 
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/efed9147/attachment.html>

From oleksandr.otenko at gmail.com  Sat May 27 18:36:52 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sat, 27 May 2017 23:36:52 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <21987417-24BC-4551-AB98-9FADC63F1F55@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <21987417-24BC-4551-AB98-9FADC63F1F55@guidewire.com>
Message-ID: <920DCFCC-237D-483C-8BDD-1CE1F75181A1@gmail.com>


> On 27 May 2017, at 18:13, Justin Sampson <jsampson at guidewire.com> wrote:
> 
> Alex Otenko wrote:
> 
>> If whoever mutated z from i to k cannot observe stores that precede z.CAS,
>> they won’t attempt to mutate z to j.
> 
> In your example, how does that other thread know that it is responsible for mutating z to j? What if it has gone on to other things before z.CAS(i, j) even happens?

That’s not a hard problem. Extra flag can deal with that, but most of the time you only check its value.


>> In return can someone explain what the difference is between a
>> weakCompareAndSet failing spuriously and compareAndSet not guaranteeing
>> volatile store semantics on fail? Why should we weaken the promise, if there
>> is already a weak promise to not guarantee visibility on fail?
> 
> Spurious failure is more about the read than the write, I think. With spurious failure, you can't even rely on volatile read semantics if the CAS fails, because failure doesn't give any information at all about the current value. Without spurious failure, at the very least you know that the current value != the expected value if the CAS fails.

No, that’s not spurious enough failure.

Spurious failure can mean CAS failed because the cache line from which the value was read got invalidated (available on some weak memory platforms). So you can’t tell even whether the value was != expected or not, or whether someone modified a different value that happens to share the cache line - hence spurious.

In this setting it does not seem possible to detect whether the read was volatile or not.


Alex

> Consider the following levels of CAS strength, off the top of my head:
> 
> 1. Volatile read always, volatile write always, no spurious failures.
> 2. Volatile read always, volatile write only if successful, no spurious failures.
> 3. Volatile read always, volatile write only if value changed, no spurious failures.
> 4. Volatile read only if successful, volatile write only if value changed, spurious failures allowed.
> 5. No volatile read, no volatile write, spurious failures allowed.
> 
> In JDK 8, compareAndSet was spec'd as #1 and weakCompareAndSet was spec'd as #5, whereas e.g. AtomicStampedReference's compareAndSet method was actually implemented as #3. In my limited concurrency coding, I don't think I've ever wanted something stronger than #3 or weaker than #4. I will be curious to learn whether any of the CAS versions in JDK 9 match those two particular levels.
> 
> Cheers,
> Justin
> 


From boehm at acm.org  Sat May 27 19:43:45 2017
From: boehm at acm.org (Hans Boehm)
Date: Sat, 27 May 2017 16:43:45 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
Message-ID: <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>

I gather the interesting scenario here is the one in which the Thread 2 CAS
fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

The correctness argument here relies on the fact that the load of x in
Thread 1 must, in this scenario, see the store of x in Thread 2? This
assumes the load of z in the failing CAS in Thread 2 can't be reordered
with the ordinary (and racey!) store to x by the same thread. I agree that
the j.u.c.atomic spec was not clear in this respect, but I don't think it
was ever the intent to guarantee that. It's certainly false for either a
lock-based or ARMv8 implementation of CAS. Requiring it would raise serious
questions about practical implementability on several architectures.

The C++ standard is quite clear that this is not required; atomicity means
only that the load of a RMW operation sees the immediately prior write in
the coherence order for that location. It doesn't guarantee anything about
other accesses somehow appearing to be performed in the middle of the
operation. It's completely analogous to the kind of atomicity you get in a
lock-based implementation.

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> Not sure what you mean by “acting as a fence” being broken.
>
> There’s probably even more code that relies on atomicity of CAS - that is,
> when the write happened on successful CAS, it happened atomically with the
> read; it constitutes a single operation in the total order of all volatile
> stores.
>
>
> int x=0; // non-volatile
> volatile int z=0;
> volatile boolean b=false;
>
> Thread1:
> if (CAS(z, 0, 1)) {
>   if (x == 0) {
>     b=true;
>     CAS(z, 1, 2);
>   }
> }
> return x;
>
> Thread2:
> x=1;
> if (!CAS(z, 0, 2)) {
>   return b;
> }
> return true;
>
> In essence, if CAS failure is caused by a real mismatch of z (not a
> spurious failure), then we can guarantee there is a return 1 or a further
> CAS in the future from the point of the first successful CAS (by program
> order), and we can get a witness b whether that CAS is in the future from
> the point of the failing CAS (by total order of operations).
>
> If failing CAS in Thread2 does not have store semantics, then nothing in
> Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1
> even if Thread2 returns false.
>
> If failing CAS in Thread2 does have store semantics, then if Thread2
> returns false, Thread1 returns 1.
>
>
> Not sure what you mean by “real programming concerns”. It sounds a bit
> like “true Scotsman”. The concern I am trying to convey, is that Java 8
> semantics offer a very strong CAS that can be used to enforce mutual
> exclusion using a single CAS call, and that this can be combined with
> inductive types to produce strong guarantees of correctness. Having set the
> field right, I can make sure most contenders execute less than a single CAS
> after mutation. Sounds real enough concern to me :)
>
>
> Anyhow, I also appreciate that most designs do not look that deep into the
> spec, and won’t notice the meaning getting closer to the actual hardware
> trends. If Java 8 CAS semantics gets deprecated, the algorithm will become
> obsolete, and will need modification with extra fences in the proprietary
> code that needs it, or whatever is not broken in the new JMM that will lay
> the memory semantics of CAS to rest.
>
>
> Alex
>
> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org> wrote:
>
> This still makes no sense to me. Nobody is suggesting that we remove the
> volatile read guarantee on failure (unlike the weak... version). If the CAS
> fails, you are guaranteed to see memory affects that happen before the
> successful change to z. We're talking about the "volatile write semantics"
> for the write that didn't happen.
>
> This would all be much easier if we had a litmus test (including code
> snippets for all involved threads) that could distinguish between the two
> behaviors. I conjecture that all such tests involve potentially infinite
> loops, and that none of them reflect real programming concerns.
>
> I also conjecture that there exists real code that relies on CAS acting as
> a fence. We should be crystal clear that such code is broken.
>
> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> Integers provide extra structure to plain boolean “failed/succeeded”.
>> Linked data structures with extra dependencies of their contents can also
>> offer extra structure.
>>
>> if( ! z.CAS(i, j) ) {
>>   k = z.get();
>>   if(k < j) {
>>     // i < k < j
>>     // whoever mutated z from i to k, should also negotiate mutation of z
>> from k to j
>>     // with someone else, and they should observe whatever stores precede
>> z.CAS
>>     // because I won’t contend.
>>
>>     // of course, I need to check they are still at it - but that, too,
>> does not require
>>     // stores or CASes
>>     ...
>>     return;
>>   }
>> }
>>
>> If whoever mutated z from i to k cannot observe stores that precede
>> z.CAS, they won’t attempt to mutate z to j.
>>
>>
>> In return can someone explain what the difference is between a
>> weakCompareAndSet failing spuriously and compareAndSet not guaranteeing
>> volatile store semantics on fail? Why should we weaken the promise, if
>> there is already a weak promise to not guarantee visibility on fail?
>>
>>
>> Alex
>>
>>
>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org> wrote:
>>
>> Could we please get an example (i.e. litmus test) of how the "memory
>> effect of at least one volatile ... write" is visible, and where it's
>> useful? Since some people seem really attached to it, it shouldn't be that
>> hard to generate a litmus test.
>>
>> So far we have a claim that it could affect progress guarantees, i.e.
>> whether prior writes eventually become visible without further
>> synchronization. I kind of, sort of, half-way believe that.
>>
>> I haven't been able to make sense out of the subsequent illustration
>> attempts. I really don't think it makes sense to require such weird
>> behavior unless we can at least clearly define exactly what the weird
>> behavior buys us. We really need a concise, or at least precise and
>> understandable, rationale.
>>
>> As has been pointed out before, a volatile write W by T1 to x of the same
>> value that was there before is not easily observable. If I read that value
>> in another thread T2, I can't tell which write I'm seeing, and hence hence
>> a failure to see prior T1 writes is OK; I might have not seen the final
>> write to x. Thus I would need to communicate the  fact that T1 completed W
>> without actually looking at x. That seems to involve another
>> synchronization of T1 with T2, which by itself would ensure the visibility
>> of prior writes to T2.
>>
>> Thus, aside from possible really obscure progress/liveness issues, I
>> really don't see the difference. I think this requirement, if it is indeed
>> not vacuous and completely ignorable, would lengthen the ARMv8 code
>> sequence for a CAS by at least 2 instructions, and introduce a very obscure
>> divergence from C and C++.
>>
>> I'm worried that we're adding something to make RMW operations behave
>> more like fences. They don't, they can't, and they shouldn't.
>>
>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <
>> nathanila at gmail.com> wrote:
>>
>>> > "The memory effects of a write occur regardless of outcome."
>>> > "This method has memory effects of at least one volatile read and
>>> write."
>>>
>>> I am not sure what memory effects means.  If this is defined somewhere
>>> in the specs, then ignore this since I haven't read JDK 9 specs.
>>>
>>> Does memory effects mean the cache line will be switched into the
>>> modified state even if an actual write doesn't occur?  Or does memory
>>> effects have to do with ordering of memory operations with respect to the
>>> method's operation?
>>>
>>> -Nathan
>>>
>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>
>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>
>>>> Actually this is another case where the Java 9 spec needs to be
>>>>> adjusted…
>>>>>
>>>> The pre-jdk9 method for weak CAS is now available in four
>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>> They have different read/write access modes. The specs reflect this.
>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>> weaker than before (this is the only naming scheme that works).
>>>>
>>>> About those specs... see JBS JDK-8181104
>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104
>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>    "The memory effects of a write occur regardless of outcome."
>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>    "This method has memory effects of at least one volatile read and
>>>> write."
>>>>
>>>> Which should clear up confusion.
>>>>
>>>> -Doug
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> --
>>> -Nathan
>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170527/c34a6410/attachment.html>

From oleksandr.otenko at gmail.com  Sat May 27 19:49:27 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 28 May 2017 00:49:27 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
Message-ID: <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>

That’s right.

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

Alex

> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org> wrote:
> 
> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
> 
> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
> 
> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
> 
> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> Not sure what you mean by “acting as a fence” being broken.
> 
> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
> 
> 
> int x=0; // non-volatile
> volatile int z=0;
> volatile boolean b=false;
> 
> Thread1:
> if (CAS(z, 0, 1)) {
>   if (x == 0) {
>     b=true;
>     CAS(z, 1, 2);
>   }
> }
> return x;
> 
> Thread2:
> x=1;
> if (!CAS(z, 0, 2)) {
>   return b;
> }
> return true;
> 
> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
> 
> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
> 
> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
> 
> 
> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
> 
> 
> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
> 
> 
> Alex
> 
>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>> 
>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>> 
>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>> 
>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>> 
>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>> 
>> if( ! z.CAS(i, j) ) {
>>   k = z.get();
>>   if(k < j) {
>>     // i < k < j
>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>     // with someone else, and they should observe whatever stores precede z.CAS
>>     // because I won’t contend.
>> 
>>     // of course, I need to check they are still at it - but that, too, does not require
>>     // stores or CASes
>>     ...
>>     return;
>>   }
>> }
>> 
>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>> 
>> 
>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>> 
>> 
>> Alex
>> 
>> 
>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>> 
>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>> 
>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>> 
>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>> 
>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>> 
>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>> 
>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>> 
>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>> > "The memory effects of a write occur regardless of outcome."
>>> > "This method has memory effects of at least one volatile read and write."
>>> 
>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>> 
>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>> 
>>> -Nathan
>>> 
>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>> 
>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>> The pre-jdk9 method for weak CAS is now available in four
>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>> They have different read/write access modes. The specs reflect this.
>>> The one keeping the name weakCompareAndSet is stronger, the others
>>> weaker than before (this is the only naming scheme that works).
>>> 
>>> About those specs... see JBS JDK-8181104
>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>> The plan is for all CAS VarHandle methods to include the sentence
>>>    "The memory effects of a write occur regardless of outcome."
>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>    "This method has memory effects of at least one volatile read and write."
>>> 
>>> Which should clear up confusion.
>>> 
>>> -Doug
>>> 
>>> 
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>> 
>>> -- 
>>> -Nathan
>>> 
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>> 
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
>> 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170528/061c534e/attachment-0001.html>

From gergg at cox.net  Sat May 27 21:19:44 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Sat, 27 May 2017 20:19:44 -0500
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <Qwnq1v00l02hR0p01wnuCt>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com> <Qwnq1v00l02hR0p01wnuCt>
Message-ID: <C07F22A4-7CE1-499B-96FE-C4B5E0DC3C67@cox.net>

If there are 5 stores before that store, and it’s those values, plus the CAS target that move your state forward, then the fence on CAS can be vital to correct software.  Since the MM interactions are costly, they are always targets for elimination by systems architects and developers who are aware of those details.  Processors with huge, costly MM interactions are the bigger concern.  Why are we still fighting against the processor, instead of having highly performant systems which don’t care about the processor?  That’s a big question that I’ve asked for more than a decade now.  We keep coming back around to micromanaging cache lines and other MM interactions in our software because that model of core to core data synchronization has never really proven to be a solution as much as it is a reason why software can be randomly wrong.

Gregg


> On May 26, 2017, at 3:44 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 25/05/17 18:15, Gil Tene wrote:
>> 
>> 
>> Sent from my iPad
>> 
>>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>> 
>>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>> 
>> While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 
>> 
>> In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.
> That property of compareAndSet is very ugly, and is a pain to implement.
> Most of the CAS instructions I know about don't have such a property,
> and making it work requires either an unconditional full fence after every
> CAS or a conditional one if it fails.  Either way sucks mightily and
> is unlikely to be useful except in the most pathological cases.
> 
> Besides, how does it ever make sense to synchronize with a store that
> never happened?
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From gergg at cox.net  Sat May 27 21:27:26 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Sat, 27 May 2017 20:27:26 -0500
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <R39P1v04C02hR0p0139WM5>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu> <R39P1v04C02hR0p0139WM5>
Message-ID: <54922133-4757-4A75-BA34-2FC3E611810C@cox.net>


> On May 26, 2017, at 10:05 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 26/05/17 14:56, Doug Lea wrote:
>> On 05/26/2017 09:35 AM, Andrew Haley wrote:
>>> On 26/05/17 13:56, Andrew Dinn wrote:
>> 
>>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>>> on CAS failure typically reduces contention and may improve throughput.
>>>> 
>>>> It would be useful to know if that reduction in contention is specific
>>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>>> AArch64 or ppc. Perhaps Nathan could clarify that?
>> 
>> The main issues are not tightly bound to architecture.
>> In the vast majority of cases, the response to CAS failure is
>> some sort of retry (although perhaps with some intermediate
>> processing). The fence here plays a similar role to
>> Thread.onSpinWait. And in fact, on ARM, is likely to be
>> exactly the same implementation as onSpinWait.
> 
> onSpinWait is null, and unless ARM does something to the architecture
> that's probably what it'll remain.
> 
>> As Alex mentioned, in the uncommon cases where this
>> is a performance issue, people can use one of the weak CAS
>> variants.
>> 
>>> 
>>> Just thinking about AArch64, and how to implement such a thing as well
>>> as possible. 
>> 
>> "As well as possible" may be just to unconditionally issue fence,
>> at least for plain CAS; maybe differently for the variants.
> 
> I doubt that: I've done some measurements, and it always pays to branch
> conditionally around a fence if it's not needed.

Since the fence is part of the happens before controls that developers encounter, how can a library routine know what the developer needs, to know how to “randomly” optimize with a branch around the fence?  Are you aware of no software that exists where developers are actively counting MM interactions trying to minimize them?  Here you are trying to do it yourself because you “See” an optimization that is so localized, away from any explicit code intent, that you can’t tell ahead of time (during development of your optimization), what other developers have actually done around the fact that this fence was unconditional before right?

Help me understand how you know that no software that works correctly now, will start working randomly, incorrectly, because sometimes the fence never happens.

Gregg

From jsampson at guidewire.com  Sun May 28 01:23:06 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Sun, 28 May 2017 05:23:06 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <920DCFCC-237D-483C-8BDD-1CE1F75181A1@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <21987417-24BC-4551-AB98-9FADC63F1F55@guidewire.com>
 <920DCFCC-237D-483C-8BDD-1CE1F75181A1@gmail.com>
Message-ID: <453286AB-BFA0-4F1F-B3B1-04C75C4B4324@guidewire.com>

Alex Otenko wrote:

> Justin Sampson wrote:
>
> > Spurious failure is more about the read than the write, I think. With spurious
> > failure, you can't even rely on volatile read semantics if the CAS fails, because
> > failure doesn't give any information at all about the current value. Without
> > spurious failure, at the very least you know that the current value != the
> > expected value if the CAS fails.
>
> No, that’s not spurious enough failure.
>
> Spurious failure can mean CAS failed because the cache line from which the
> value was read got invalidated (available on some weak memory platforms).
> So you can’t tell even whether the value was != expected or not, or whether
> someone modified a different value that happens to share the cache line -
> hence spurious.
>
> In this setting it does not seem possible to detect whether the read was
> volatile or not.

I think that's what I said: If spurious failure is allowed, failure doesn't tell you
anything about the current state of the variable, and doesn't count as a
volatile read. If spurious failure is not allowed, failure does tell you something
about the current state of the variable, and should count as a volatile read.
That's clearly a different concern from whether a failure counts as a volatile
_write_, which is the difference I thought you were asking about.

(And thanks for fleshing out your example to the point where we can see the
whole sequence of actions in both threads.)

Cheers,
Justin


From oleksandr.otenko at gmail.com  Sun May 28 05:12:33 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 28 May 2017 10:12:33 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <C07F22A4-7CE1-499B-96FE-C4B5E0DC3C67@cox.net>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com> <Qwnq1v00l02hR0p01wnuCt>
 <C07F22A4-7CE1-499B-96FE-C4B5E0DC3C67@cox.net>
Message-ID: <E15F00D0-6AF3-4641-BD25-ED004CD755E7@gmail.com>

I think the answer to your question is in the absence of such systems.

Also, I can agree to a statement that “that model of core to core data synchronization has never really proven to be THE solution” (implying universal quantifier), but I find the statement with “…to be A solution” not self-consistent (can’t eliminate existential quantifier in the presence of the evidence of existence).

Our processors are working at latencies where the speed of light vs the size of the die becomes a limiting factor - until we find a way for spatially separated physical bodies to interact at speeds faster than light, or for the space around the die to become radically warped. Until then we can only learn to take advantage of local interactions being observed sooner than remote interactions.

Alex


> On 28 May 2017, at 02:19, Gregg Wonderly <gergg at cox.net> wrote:
> 
> If there are 5 stores before that store, and it’s those values, plus the CAS target that move your state forward, then the fence on CAS can be vital to correct software.  Since the MM interactions are costly, they are always targets for elimination by systems architects and developers who are aware of those details.  Processors with huge, costly MM interactions are the bigger concern.  Why are we still fighting against the processor, instead of having highly performant systems which don’t care about the processor?  That’s a big question that I’ve asked for more than a decade now.  We keep coming back around to micromanaging cache lines and other MM interactions in our software because that model of core to core data synchronization has never really proven to be a solution as much as it is a reason why software can be randomly wrong.
> 
> Gregg
> 
> 
>> On May 26, 2017, at 3:44 AM, Andrew Haley <aph at redhat.com> wrote:
>> 
>> On 25/05/17 18:15, Gil Tene wrote:
>>> 
>>> 
>>> Sent from my iPad
>>> 
>>>> On May 25, 2017, at 3:42 AM, Doug Lea <dl at cs.oswego.edu> wrote:
>>>> 
>>>>> On 05/25/2017 06:16 AM, Andrew Haley wrote:
>>> 
>>> While on this subject, was the relative "weakening" of compareAndSet (and other) memory semantics between Java 8 and java 9 discussed elsewhere? 
>>> 
>>> In java 8, a compareAndSet has the memory semantics of a volatile write regardless of whether or not the write occurred. In java 9 it only has a volatile write effect if the write occurs. While the loosening in the non-writing case may allow for additional optimizations, I worry that it may break existing code that could rely on the previous behavior.
>> That property of compareAndSet is very ugly, and is a pain to implement.
>> Most of the CAS instructions I know about don't have such a property,
>> and making it work requires either an unconditional full fence after every
>> CAS or a conditional one if it fails.  Either way sucks mightily and
>> is unlikely to be useful except in the most pathological cases.
>> 
>> Besides, how does it ever make sense to synchronize with a store that
>> never happened?
>> 
>> -- 
>> Andrew Haley
>> Java Platform Lead Engineer
>> Red Hat UK Ltd. <https://www.redhat.com>
>> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> 
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest


From oleksandr.otenko at gmail.com  Sun May 28 09:44:42 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 28 May 2017 14:44:42 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
Message-ID: <501F0087-D049-4CCB-8440-0C681AB4E779@gmail.com>

Then if CAS is modified to not guarantee a store on failure, the original design can be modified to still obtain the necessary guarantees, at the expense of one dummy volatile read before each CAS (so if value is unused, only the barriers remain, which can be fused with the barriers of the CAS) and a dummy volatile store after CAS failure.


However, one of the suggested optimizations was to not store if the value stored is the same as value expected - this is completely different from making the store optional in CAS fail case, and cannot be rectified by some extra volatiles around CAS. Not sure if that is considered seriously, as the scope of applicability of that optimization is not obviously great.


Alex

> On 28 May 2017, at 00:49, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> That’s right.
> 
> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
> 
> Alex
> 
>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>> 
>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>> 
>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>> 
>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>> 
>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> Not sure what you mean by “acting as a fence” being broken.
>> 
>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>> 
>> 
>> int x=0; // non-volatile
>> volatile int z=0;
>> volatile boolean b=false;
>> 
>> Thread1:
>> if (CAS(z, 0, 1)) {
>>   if (x == 0) {
>>     b=true;
>>     CAS(z, 1, 2);
>>   }
>> }
>> return x;
>> 
>> Thread2:
>> x=1;
>> if (!CAS(z, 0, 2)) {
>>   return b;
>> }
>> return true;
>> 
>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>> 
>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>> 
>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>> 
>> 
>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>> 
>> 
>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>> 
>> 
>> Alex
>> 
>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>> 
>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>> 
>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>> 
>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>> 
>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>> 
>>> if( ! z.CAS(i, j) ) {
>>>   k = z.get();
>>>   if(k < j) {
>>>     // i < k < j
>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>     // because I won’t contend.
>>> 
>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>     // stores or CASes
>>>     ...
>>>     return;
>>>   }
>>> }
>>> 
>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>> 
>>> 
>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>> 
>>> 
>>> Alex
>>> 
>>> 
>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>> 
>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>> 
>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>> 
>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>> 
>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>> 
>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>> 
>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>> 
>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>> > "The memory effects of a write occur regardless of outcome."
>>>> > "This method has memory effects of at least one volatile read and write."
>>>> 
>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>> 
>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>> 
>>>> -Nathan
>>>> 
>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>> 
>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>> The pre-jdk9 method for weak CAS is now available in four
>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>> They have different read/write access modes. The specs reflect this.
>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>> weaker than before (this is the only naming scheme that works).
>>>> 
>>>> About those specs... see JBS JDK-8181104
>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>    "The memory effects of a write occur regardless of outcome."
>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>    "This method has memory effects of at least one volatile read and write."
>>>> 
>>>> Which should clear up confusion.
>>>> 
>>>> -Doug
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> 
>>>> -- 
>>>> -Nathan
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>> 
>>> 
>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170528/faaab81d/attachment-0001.html>

From boehm at acm.org  Sun May 28 13:30:43 2017
From: boehm at acm.org (Hans Boehm)
Date: Sun, 28 May 2017 10:30:43 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
Message-ID: <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2
CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately
reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b.
Thus the second (successful) CAS in Thread 1 must follow the unsuccessful
Thread 2 CAS in synchronization order. So any write to z by the failed CAS
synchronizes with the second successful CAS in Thread 1, and we could thus
conclude that x is 1 in the Thread 1 return.

This relies critically on the assumption that the Thread 2 failed CAS has
the semantics of a volatile write to z.

I think the actual relevant spec text is:

1) "compareAndSet and all other read-and-update operations such as
getAndIncrement have the memory effects of both reading and writing volatile
 variables."

2) "Atomically sets the value to the given updated value if the current
value == the expected value."

I would not read this as guaranteeing that property. But I agree the spec
doesn't make much sense; I read (2) as saying there is no write at all if
the CAS fails, as I would expect. Thus it seems like a stretch to assume
that the write from (1) is to z, though I have no idea what write it would
refer to.

The prior implementation discussion now does make sense to me. I don't
think this is an issue for lock-based implementations. But the only
reasonable way to support it on ARMv8 seems to be with a conditionally
executed fence in the failing case. That adds two instructions, as well as
a large amount of time overhead for algorithms that don't retry on a strong
CAS. My impression is that those algorithms are frequent enough to be a
concern.


On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com>
wrote:

> That’s right.
>
> Atomicity (for some definition of atomicity - ie atomic with respect to
> which operations) is not needed here. As long as the store in CAS occurs
> always, x=1 is not “reordered” (certainly, not entirely - can’t escape the
> “store” that is declared in the spec).
>
> Alex
>
> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org> wrote:
>
> I gather the interesting scenario here is the one in which the Thread 2
> CAS fails and Thread 2 returns false, while the initial Thread 1 CAS
> succeeds?
>
> The correctness argument here relies on the fact that the load of x in
> Thread 1 must, in this scenario, see the store of x in Thread 2? This
> assumes the load of z in the failing CAS in Thread 2 can't be reordered
> with the ordinary (and racey!) store to x by the same thread. I agree that
> the j.u.c.atomic spec was not clear in this respect, but I don't think it
> was ever the intent to guarantee that. It's certainly false for either a
> lock-based or ARMv8 implementation of CAS. Requiring it would raise serious
> questions about practical implementability on several architectures.
>
> The C++ standard is quite clear that this is not required; atomicity means
> only that the load of a RMW operation sees the immediately prior write in
> the coherence order for that location. It doesn't guarantee anything about
> other accesses somehow appearing to be performed in the middle of the
> operation. It's completely analogous to the kind of atomicity you get in a
> lock-based implementation.
>
> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com>
> wrote:
>
>> Not sure what you mean by “acting as a fence” being broken.
>>
>> There’s probably even more code that relies on atomicity of CAS - that
>> is, when the write happened on successful CAS, it happened atomically with
>> the read; it constitutes a single operation in the total order of all
>> volatile stores.
>>
>>
>> int x=0; // non-volatile
>> volatile int z=0;
>> volatile boolean b=false;
>>
>> Thread1:
>> if (CAS(z, 0, 1)) {
>>   if (x == 0) {
>>     b=true;
>>     CAS(z, 1, 2);
>>   }
>> }
>> return x;
>>
>> Thread2:
>> x=1;
>> if (!CAS(z, 0, 2)) {
>>   return b;
>> }
>> return true;
>>
>> In essence, if CAS failure is caused by a real mismatch of z (not a
>> spurious failure), then we can guarantee there is a return 1 or a further
>> CAS in the future from the point of the first successful CAS (by program
>> order), and we can get a witness b whether that CAS is in the future from
>> the point of the failing CAS (by total order of operations).
>>
>> If failing CAS in Thread2 does not have store semantics, then nothing in
>> Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1
>> even if Thread2 returns false.
>>
>> If failing CAS in Thread2 does have store semantics, then if Thread2
>> returns false, Thread1 returns 1.
>>
>>
>> Not sure what you mean by “real programming concerns”. It sounds a bit
>> like “true Scotsman”. The concern I am trying to convey, is that Java 8
>> semantics offer a very strong CAS that can be used to enforce mutual
>> exclusion using a single CAS call, and that this can be combined with
>> inductive types to produce strong guarantees of correctness. Having set the
>> field right, I can make sure most contenders execute less than a single CAS
>> after mutation. Sounds real enough concern to me :)
>>
>>
>> Anyhow, I also appreciate that most designs do not look that deep into
>> the spec, and won’t notice the meaning getting closer to the actual
>> hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm
>> will become obsolete, and will need modification with extra fences in the
>> proprietary code that needs it, or whatever is not broken in the new JMM
>> that will lay the memory semantics of CAS to rest.
>>
>>
>> Alex
>>
>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org> wrote:
>>
>> This still makes no sense to me. Nobody is suggesting that we remove the
>> volatile read guarantee on failure (unlike the weak... version). If the CAS
>> fails, you are guaranteed to see memory affects that happen before the
>> successful change to z. We're talking about the "volatile write semantics"
>> for the write that didn't happen.
>>
>> This would all be much easier if we had a litmus test (including code
>> snippets for all involved threads) that could distinguish between the two
>> behaviors. I conjecture that all such tests involve potentially infinite
>> loops, and that none of them reflect real programming concerns.
>>
>> I also conjecture that there exists real code that relies on CAS acting
>> as a fence. We should be crystal clear that such code is broken.
>>
>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com
>> > wrote:
>>
>>> Integers provide extra structure to plain boolean “failed/succeeded”.
>>> Linked data structures with extra dependencies of their contents can also
>>> offer extra structure.
>>>
>>> if( ! z.CAS(i, j) ) {
>>>   k = z.get();
>>>   if(k < j) {
>>>     // i < k < j
>>>     // whoever mutated z from i to k, should also negotiate mutation of
>>> z from k to j
>>>     // with someone else, and they should observe whatever stores
>>> precede z.CAS
>>>     // because I won’t contend.
>>>
>>>     // of course, I need to check they are still at it - but that, too,
>>> does not require
>>>     // stores or CASes
>>>     ...
>>>     return;
>>>   }
>>> }
>>>
>>> If whoever mutated z from i to k cannot observe stores that precede
>>> z.CAS, they won’t attempt to mutate z to j.
>>>
>>>
>>> In return can someone explain what the difference is between a
>>> weakCompareAndSet failing spuriously and compareAndSet not guaranteeing
>>> volatile store semantics on fail? Why should we weaken the promise, if
>>> there is already a weak promise to not guarantee visibility on fail?
>>>
>>>
>>> Alex
>>>
>>>
>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org> wrote:
>>>
>>> Could we please get an example (i.e. litmus test) of how the "memory
>>> effect of at least one volatile ... write" is visible, and where it's
>>> useful? Since some people seem really attached to it, it shouldn't be that
>>> hard to generate a litmus test.
>>>
>>> So far we have a claim that it could affect progress guarantees, i.e.
>>> whether prior writes eventually become visible without further
>>> synchronization. I kind of, sort of, half-way believe that.
>>>
>>> I haven't been able to make sense out of the subsequent illustration
>>> attempts. I really don't think it makes sense to require such weird
>>> behavior unless we can at least clearly define exactly what the weird
>>> behavior buys us. We really need a concise, or at least precise and
>>> understandable, rationale.
>>>
>>> As has been pointed out before, a volatile write W by T1 to x of the
>>> same value that was there before is not easily observable. If I read that
>>> value in another thread T2, I can't tell which write I'm seeing, and hence
>>> hence a failure to see prior T1 writes is OK; I might have not seen the
>>> final write to x. Thus I would need to communicate the  fact that T1
>>> completed W without actually looking at x. That seems to involve another
>>> synchronization of T1 with T2, which by itself would ensure the visibility
>>> of prior writes to T2.
>>>
>>> Thus, aside from possible really obscure progress/liveness issues, I
>>> really don't see the difference. I think this requirement, if it is indeed
>>> not vacuous and completely ignorable, would lengthen the ARMv8 code
>>> sequence for a CAS by at least 2 instructions, and introduce a very obscure
>>> divergence from C and C++.
>>>
>>> I'm worried that we're adding something to make RMW operations behave
>>> more like fences. They don't, they can't, and they shouldn't.
>>>
>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <
>>> nathanila at gmail.com> wrote:
>>>
>>>> > "The memory effects of a write occur regardless of outcome."
>>>> > "This method has memory effects of at least one volatile read and
>>>> write."
>>>>
>>>> I am not sure what memory effects means.  If this is defined somewhere
>>>> in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>
>>>> Does memory effects mean the cache line will be switched into the
>>>> modified state even if an actual write doesn't occur?  Or does memory
>>>> effects have to do with ordering of memory operations with respect to the
>>>> method's operation?
>>>>
>>>> -Nathan
>>>>
>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>
>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>
>>>>> Actually this is another case where the Java 9 spec needs to be
>>>>>> adjusted…
>>>>>>
>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>> They have different read/write access modes. The specs reflect this.
>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>> weaker than before (this is the only naming scheme that works).
>>>>>
>>>>> About those specs... see JBS JDK-8181104
>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104
>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>    "This method has memory effects of at least one volatile read and
>>>>> write."
>>>>>
>>>>> Which should clear up confusion.
>>>>>
>>>>> -Doug
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> Concurrency-interest mailing list
>>>>> Concurrency-interest at cs.oswego.edu
>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>>
>>>>
>>>> --
>>>> -Nathan
>>>>
>>>>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>>
>>>
>>> _______________________________________________
>>> Concurrency-interest mailing list
>>> Concurrency-interest at cs.oswego.edu
>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170528/82c5d455/attachment-0001.html>

From oleksandr.otenko at gmail.com  Sun May 28 17:39:56 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Sun, 28 May 2017 22:39:56 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
Message-ID: <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.


The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).


It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

Alex


> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org> wrote:
> 
> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
> 
> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
> 
> I think the actual relevant spec text is:
> 
> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
> 
> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
> 
> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
> 
> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
> 
> 
> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> That’s right.
> 
> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
> 
> Alex
> 
>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>> 
>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>> 
>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>> 
>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>> 
>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> Not sure what you mean by “acting as a fence” being broken.
>> 
>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>> 
>> 
>> int x=0; // non-volatile
>> volatile int z=0;
>> volatile boolean b=false;
>> 
>> Thread1:
>> if (CAS(z, 0, 1)) {
>>   if (x == 0) {
>>     b=true;
>>     CAS(z, 1, 2);
>>   }
>> }
>> return x;
>> 
>> Thread2:
>> x=1;
>> if (!CAS(z, 0, 2)) {
>>   return b;
>> }
>> return true;
>> 
>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>> 
>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>> 
>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>> 
>> 
>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>> 
>> 
>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>> 
>> 
>> Alex
>> 
>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>> 
>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>> 
>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>> 
>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>> 
>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>> 
>>> if( ! z.CAS(i, j) ) {
>>>   k = z.get();
>>>   if(k < j) {
>>>     // i < k < j
>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>     // because I won’t contend.
>>> 
>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>     // stores or CASes
>>>     ...
>>>     return;
>>>   }
>>> }
>>> 
>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>> 
>>> 
>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>> 
>>> 
>>> Alex
>>> 
>>> 
>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>> 
>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>> 
>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>> 
>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>> 
>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>> 
>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>> 
>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>> 
>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>> > "The memory effects of a write occur regardless of outcome."
>>>> > "This method has memory effects of at least one volatile read and write."
>>>> 
>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>> 
>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>> 
>>>> -Nathan
>>>> 
>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>> 
>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>> The pre-jdk9 method for weak CAS is now available in four
>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>> They have different read/write access modes. The specs reflect this.
>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>> weaker than before (this is the only naming scheme that works).
>>>> 
>>>> About those specs... see JBS JDK-8181104
>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>    "The memory effects of a write occur regardless of outcome."
>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>    "This method has memory effects of at least one volatile read and write."
>>>> 
>>>> Which should clear up confusion.
>>>> 
>>>> -Doug
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> 
>>>> -- 
>>>> -Nathan
>>>> 
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> 
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>> 
>>> 
>> 
>> 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170528/f15f7b00/attachment-0001.html>

From davidcholmes at aapt.net.au  Sun May 28 18:52:57 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 29 May 2017 08:52:57 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet()
	mandatory	updating
In-Reply-To: <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
Message-ID: <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>

Alex,

 

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org>
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.

 

 

The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

 

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).

 

 

It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

 

Alex

 

 

On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> > wrote:

 

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

 

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

 

I think the actual relevant spec text is:

 

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

 

2) "Atomically sets the value to the given updated value if the current value == the expected value."

 

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

 

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.

 

 

On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com> > wrote:

That’s right.

 

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

 

Alex

 

On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> > wrote:

 

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

 

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

 

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

 

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com> > wrote:

Not sure what you mean by “acting as a fence” being broken.

 

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.

 

 

int x=0; // non-volatile

volatile int z=0;

volatile boolean b=false;

 

Thread1:

if (CAS(z, 0, 1)) {

  if (x == 0) {

    b=true;

    CAS(z, 1, 2);

  }

}

return x;

 

Thread2:

x=1;

if (!CAS(z, 0, 2)) {

  return b;

}

return true;

 

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

 

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

 

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.

 

 

Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)

 

 

Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.

 

 

Alex

 

On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> > wrote:

 

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

 

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

 

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

 

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com> > wrote:

Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

 

if( ! z.CAS(i, j) ) {

  k = z.get();

  if(k < j) {

    // i < k < j

    // whoever mutated z from i to k, should also negotiate mutation of z from k to j

    // with someone else, and they should observe whatever stores precede z.CAS

    // because I won’t contend.

 

    // of course, I need to check they are still at it - but that, too, does not require

    // stores or CASes

    ...

    return;

  }

}

 

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.

 

 

In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?

 

 

Alex

 

 

On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> > wrote:

 

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

 

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

 

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

 

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

 

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

 

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

 

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com> > wrote:

> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan


On 5/26/2017 1:59 PM, Doug Lea wrote:

On 05/26/2017 12:22 PM, Gil Tene wrote:

Actually this is another case where the Java 9 spec needs to be adjusted…

The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
   https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-- 
-Nathan



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu> 
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

 

 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/338a388c/attachment-0001.html>

From oleksandr.otenko at gmail.com  Sun May 28 19:26:06 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 00:26:06 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
Message-ID: <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

The gist of atomicity:

int x=0;
volatile int z=0;

Thread 1:
if (! CAS(z, 0, 1)) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 

Alex



> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> Alex,
>  
> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>  
> David
>  
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
> Sent: Monday, May 29, 2017 7:40 AM
> To: Hans Boehm <boehm at acm.org>
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>  
> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>  
>  
> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>  
> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>  
>  
> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>  
> Alex
>  
>  
>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>  
>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>  
>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>  
>> I think the actual relevant spec text is:
>>  
>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>  
>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>  
>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>  
>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>  
>>  
>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>> That’s right.
>>>  
>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>  
>>> Alex
>>>  
>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>  
>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>  
>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>  
>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>  
>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>  
>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>  
>>>>>  
>>>>> int x=0; // non-volatile
>>>>> volatile int z=0;
>>>>> volatile boolean b=false;
>>>>>  
>>>>> Thread1:
>>>>> if (CAS(z, 0, 1)) {
>>>>>   if (x == 0) {
>>>>>     b=true;
>>>>>     CAS(z, 1, 2);
>>>>>   }
>>>>> }
>>>>> return x;
>>>>>  
>>>>> Thread2:
>>>>> x=1;
>>>>> if (!CAS(z, 0, 2)) {
>>>>>   return b;
>>>>> }
>>>>> return true;
>>>>>  
>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>  
>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>  
>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>  
>>>>>  
>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>  
>>>>>  
>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>  
>>>>>  
>>>>> Alex
>>>>>  
>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>  
>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>  
>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>  
>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>  
>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>  
>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>   k = z.get();
>>>>>>>   if(k < j) {
>>>>>>>     // i < k < j
>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>     // because I won’t contend.
>>>>>>>  
>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>     // stores or CASes
>>>>>>>     ...
>>>>>>>     return;
>>>>>>>   }
>>>>>>> }
>>>>>>>  
>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>  
>>>>>>>  
>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>  
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>  
>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>  
>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>  
>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>  
>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>  
>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>  
>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>  
>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>  
>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>> 
>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>> 
>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>> 
>>>>>>>>> -Nathan
>>>>>>>>> 
>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>> 
>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>> 
>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>> 
>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>> 
>>>>>>>>>> -Doug
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________
>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>> -- 
>>>>>>>>> -Nathan
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> _______________________________________________
>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>  
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/e94392ec/attachment-0001.html>

From oleksandr.otenko at gmail.com  Mon May 29 03:54:56 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 08:54:56 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
Message-ID: <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

So I am asking whether the *failing* CAS promises atomicity.


Alex


> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com> wrote:
> 
> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
> 
> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
> 
> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
> 
> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
> 
> The gist of atomicity:
> 
> int x=0;
> volatile int z=0;
> 
> Thread 1:
> if (! CAS(z, 0, 1)) {
>   return x;
> }
> return 1;
> 
> Thread 2:
> x=1;
> z=1;
> 
> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
> 
> Alex
> 
> 
> 
>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>> 
>> Alex,
>>  
>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>  
>> David
>>  
>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>> Sent: Monday, May 29, 2017 7:40 AM
>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>  
>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>  
>>  
>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>  
>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>  
>>  
>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>  
>> Alex
>>  
>>  
>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>  
>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>  
>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>  
>>> I think the actual relevant spec text is:
>>>  
>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>  
>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>  
>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>  
>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>  
>>>  
>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>> That’s right.
>>>>  
>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>  
>>>> Alex
>>>>  
>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>  
>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>  
>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>  
>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>  
>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>  
>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>  
>>>>>>  
>>>>>> int x=0; // non-volatile
>>>>>> volatile int z=0;
>>>>>> volatile boolean b=false;
>>>>>>  
>>>>>> Thread1:
>>>>>> if (CAS(z, 0, 1)) {
>>>>>>   if (x == 0) {
>>>>>>     b=true;
>>>>>>     CAS(z, 1, 2);
>>>>>>   }
>>>>>> }
>>>>>> return x;
>>>>>>  
>>>>>> Thread2:
>>>>>> x=1;
>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>   return b;
>>>>>> }
>>>>>> return true;
>>>>>>  
>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>  
>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>  
>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>  
>>>>>>  
>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>  
>>>>>>  
>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>  
>>>>>>  
>>>>>> Alex
>>>>>>  
>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>  
>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>  
>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>  
>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>  
>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>  
>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>   k = z.get();
>>>>>>>>   if(k < j) {
>>>>>>>>     // i < k < j
>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>     // because I won’t contend.
>>>>>>>>  
>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>     // stores or CASes
>>>>>>>>     ...
>>>>>>>>     return;
>>>>>>>>   }
>>>>>>>> }
>>>>>>>>  
>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>  
>>>>>>>>  
>>>>>>>> Alex
>>>>>>>>  
>>>>>>>>  
>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>  
>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>  
>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>  
>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>  
>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>  
>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>  
>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>  
>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>> 
>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>> 
>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>> 
>>>>>>>>>> -Nathan
>>>>>>>>>> 
>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>> 
>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>> 
>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>> 
>>>>>>>>>>> -Doug
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>> -- 
>>>>>>>>>> -Nathan
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________
>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>  
>>>>>>>>> _______________________________________________
>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/cd7ed6da/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon May 29 04:03:11 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 29 May 2017 18:03:11 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
Message-ID: <015301d2d852$0498b400$0dca1c00$@aapt.net.au>

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

 

David

 

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com] 
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org
Cc: Hans Boehm <boehm at acm.org>; concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

 

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

 

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

 

So I am asking whether the *failing* CAS promises atomicity.

 

 

Alex

 

 

On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com> > wrote:

 

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

 

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

 

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

 

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

 

The gist of atomicity:

 

int x=0;

volatile int z=0;

 

Thread 1:

if (! CAS(z, 0, 1)) {

  return x;

}

return 1;

 

Thread 2:

x=1;

z=1;

 

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 

 

Alex

 

 

 

On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au> > wrote:

 

Alex,

 

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> >
Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> 
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.

 

 

The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

 

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).

 

 

It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

 

Alex

 

 

On 28 May 2017, at 18:30, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

 

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

 

I think the actual relevant spec text is:

 

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

 

2) "Atomically sets the value to the given updated value if the current value == the expected value."

 

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

 

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.

 

 

On Sat, May 27, 2017 at 4:49 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

That’s right.

 

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

 

Alex

 

On 28 May 2017, at 00:43, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

 

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

 

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

 

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Not sure what you mean by “acting as a fence” being broken.

 

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.

 

 

int x=0; // non-volatile

volatile int z=0;

volatile boolean b=false;

 

Thread1:

if (CAS(z, 0, 1)) {

  if (x == 0) {

    b=true;

    CAS(z, 1, 2);

  }

}

return x;

 

Thread2:

x=1;

if (!CAS(z, 0, 2)) {

  return b;

}

return true;

 

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

 

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

 

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.

 

 

Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)

 

 

Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.

 

 

Alex

 

On 27 May 2017, at 18:34, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

 

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

 

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

 

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

 

if( ! z.CAS(i, j) ) {

  k = z.get();

  if(k < j) {

    // i < k < j

    // whoever mutated z from i to k, should also negotiate mutation of z from k to j

    // with someone else, and they should observe whatever stores precede z.CAS

    // because I won’t contend.

 

    // of course, I need to check they are still at it - but that, too, does not require

    // stores or CASes

    ...

    return;

  }

}

 

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.

 

 

In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?

 

 

Alex

 

 

On 26 May 2017, at 22:35, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

 

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

 

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

 

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

 

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

 

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

 

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds < <mailto:nathanila at gmail.com> nathanila at gmail.com> wrote:

> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan


On 5/26/2017 1:59 PM, Doug Lea wrote:

On 05/26/2017 12:22 PM, Gil Tene wrote:

Actually this is another case where the Java 9 spec needs to be adjusted…

The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
    <https://bugs.openjdk.java.net/browse/JDK-8181104> https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-- 
-Nathan



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/a0e516d9/attachment-0001.html>

From aph at redhat.com  Mon May 29 04:04:37 2017
From: aph at redhat.com (Andrew Haley)
Date: Mon, 29 May 2017 09:04:37 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <54922133-4757-4A75-BA34-2FC3E611810C@cox.net>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu> <R39P1v04C02hR0p0139WM5>
 <54922133-4757-4A75-BA34-2FC3E611810C@cox.net>
Message-ID: <069a7a7a-d803-901e-85e5-2242887fdc82@redhat.com>

On 28/05/17 02:27, Gregg Wonderly wrote:
> 
>> On May 26, 2017, at 10:05 AM, Andrew Haley <aph at redhat.com> wrote:
>>
>> On 26/05/17 14:56, Doug Lea wrote:
>>> On 05/26/2017 09:35 AM, Andrew Haley wrote:
>>>> On 26/05/17 13:56, Andrew Dinn wrote:
>>>
>>>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>>>> on CAS failure typically reduces contention and may improve throughput.
>>>>>
>>>>> It would be useful to know if that reduction in contention is specific
>>>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>>>> AArch64 or ppc. Perhaps Nathan could clarify that?
>>>
>>> The main issues are not tightly bound to architecture.
>>> In the vast majority of cases, the response to CAS failure is
>>> some sort of retry (although perhaps with some intermediate
>>> processing). The fence here plays a similar role to
>>> Thread.onSpinWait. And in fact, on ARM, is likely to be
>>> exactly the same implementation as onSpinWait.
>>
>> onSpinWait is null, and unless ARM does something to the architecture
>> that's probably what it'll remain.
>>
>>> As Alex mentioned, in the uncommon cases where this
>>> is a performance issue, people can use one of the weak CAS
>>> variants.
>>>
>>>> Just thinking about AArch64, and how to implement such a thing as well
>>>> as possible. 
>>>
>>> "As well as possible" may be just to unconditionally issue fence,
>>> at least for plain CAS; maybe differently for the variants.
>>
>> I doubt that: I've done some measurements, and it always pays to branch
>> conditionally around a fence if it's not needed.
> 
> Since the fence is part of the happens before controls that
> developers encounter, how can a library routine know what the
> developer needs, to know how to “randomly” optimize with a branch
> around the fence?  Are you aware of no software that exists where
> developers are actively counting MM interactions trying to minimize
> them?  Here you are trying to do it yourself because you “See” an
> optimization that is so localized, away from any explicit code
> intent, that you can’t tell ahead of time (during development of
> your optimization), what other developers have actually done around
> the fact that this fence was unconditional before right?
> 
> Help me understand how you know that no software that works
> correctly now, will start working randomly, incorrectly, because
> sometimes the fence never happens.

It's in the specification.  If a fence is required by the
specification, we must execute one. If not, the question is whether
it's faster to execute a fence unconditionally or to branch around it.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Mon May 29 04:14:33 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 09:14:33 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
Message-ID: <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>

Thanks.

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

Example where you can claim atomicity of a failing CAS:

do{
  tmp = load_linked(z);
} while(tmp == expected && store_conditional(z, updated));

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.


Alex


> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>  
> David
>  
> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com] 
> Sent: Monday, May 29, 2017 5:55 PM
> To: dholmes at ieee.org
> Cc: Hans Boehm <boehm at acm.org>; concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>  
> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>  
> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>  
> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>  
> So I am asking whether the *failing* CAS promises atomicity.
>  
>  
> Alex
>  
>  
>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>  
>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>  
>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>  
>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>  
>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>  
>> The gist of atomicity:
>>  
>> int x=0;
>> volatile int z=0;
>>  
>> Thread 1:
>> if (! CAS(z, 0, 1)) {
>>   return x;
>> }
>> return 1;
>>  
>> Thread 2:
>> x=1;
>> z=1;
>>  
>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>  
>> Alex
>>  
>>  
>>  
>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>  
>>> Alex,
>>>  
>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>  
>>> David
>>>  
>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>> Sent: Monday, May 29, 2017 7:40 AM
>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>  
>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>  
>>>  
>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>  
>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>  
>>>  
>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>  
>>> Alex
>>>  
>>>  
>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>  
>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>  
>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>  
>>>> I think the actual relevant spec text is:
>>>>  
>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>  
>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>  
>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>  
>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>  
>>>>  
>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>> That’s right.
>>>>>  
>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>  
>>>>> Alex
>>>>>  
>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>  
>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>  
>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>  
>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>  
>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>  
>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>  
>>>>>>>  
>>>>>>> int x=0; // non-volatile
>>>>>>> volatile int z=0;
>>>>>>> volatile boolean b=false;
>>>>>>>  
>>>>>>> Thread1:
>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>   if (x == 0) {
>>>>>>>     b=true;
>>>>>>>     CAS(z, 1, 2);
>>>>>>>   }
>>>>>>> }
>>>>>>> return x;
>>>>>>>  
>>>>>>> Thread2:
>>>>>>> x=1;
>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>   return b;
>>>>>>> }
>>>>>>> return true;
>>>>>>>  
>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>  
>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>  
>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>  
>>>>>>>  
>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>  
>>>>>>>  
>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>  
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>  
>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>  
>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>  
>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>  
>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>  
>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>   k = z.get();
>>>>>>>>>   if(k < j) {
>>>>>>>>>     // i < k < j
>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>     // because I won’t contend.
>>>>>>>>>  
>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>     // stores or CASes
>>>>>>>>>     ...
>>>>>>>>>     return;
>>>>>>>>>   }
>>>>>>>>> }
>>>>>>>>>  
>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>  
>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>  
>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>  
>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>  
>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>  
>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>  
>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>  
>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>> 
>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>> 
>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>> 
>>>>>>>>>>> -Nathan
>>>>>>>>>>> 
>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>> 
>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>> 
>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>> 
>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>> 
>>>>>>>>>>>> -Doug
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>> -- 
>>>>>>>>>>> -Nathan
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>  
>>>>>>>>>> _______________________________________________
>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/76e92a58/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon May 29 04:31:34 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 29 May 2017 18:31:34 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet()
	mandatory	updating
In-Reply-To: <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
Message-ID: <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Thanks.

 

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

 

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

 

Example where you can claim atomicity of a failing CAS:

 

do{

  tmp = load_linked(z);

} while(tmp == expected && store_conditional(z, updated));

 

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.

 

 

Alex

 

 

On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au> > wrote:

 

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

 

David

 

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com] 
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org <mailto:dholmes at ieee.org> 
Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org> >; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> 
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

 

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

 

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

 

So I am asking whether the *failing* CAS promises atomicity.

 

 

Alex

 

 

On 29 May 2017, at 00:26, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

 

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

 

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

 

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

 

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

 

The gist of atomicity:

 

int x=0;

volatile int z=0;

 

Thread 1:

if (! CAS(z, 0, 1)) {

  return x;

}

return 1;

 

Thread 2:

x=1;

z=1;

 

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 

 

Alex

 

 

 

On 28 May 2017, at 23:52, David Holmes < <mailto:davidcholmes at aapt.net.au> davidcholmes at aapt.net.au> wrote:

 

Alex,

 

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

 

David

 

From: Concurrency-interest [ <mailto:concurrency-interest-bounces at cs.oswego.edu> mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org>
Cc:  <mailto:concurrency-interest at cs.oswego.edu> concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.

 

 

The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

 

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).

 

 

It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

 

Alex

 

 

On 28 May 2017, at 18:30, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

 

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

 

I think the actual relevant spec text is:

 

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

 

2) "Atomically sets the value to the given updated value if the current value == the expected value."

 

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

 

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.

 

 

On Sat, May 27, 2017 at 4:49 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

That’s right.

 

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

 

Alex

 

On 28 May 2017, at 00:43, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

 

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

 

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

 

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Not sure what you mean by “acting as a fence” being broken.

 

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.

 

 

int x=0; // non-volatile

volatile int z=0;

volatile boolean b=false;

 

Thread1:

if (CAS(z, 0, 1)) {

  if (x == 0) {

    b=true;

    CAS(z, 1, 2);

  }

}

return x;

 

Thread2:

x=1;

if (!CAS(z, 0, 2)) {

  return b;

}

return true;

 

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

 

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

 

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.

 

 

Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)

 

 

Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.

 

 

Alex

 

On 27 May 2017, at 18:34, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

 

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

 

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

 

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

 

if( ! z.CAS(i, j) ) {

  k = z.get();

  if(k < j) {

    // i < k < j

    // whoever mutated z from i to k, should also negotiate mutation of z from k to j

    // with someone else, and they should observe whatever stores precede z.CAS

    // because I won’t contend.

 

    // of course, I need to check they are still at it - but that, too, does not require

    // stores or CASes

    ...

    return;

  }

}

 

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.

 

 

In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?

 

 

Alex

 

 

On 26 May 2017, at 22:35, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

 

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

 

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

 

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

 

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

 

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

 

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds < <mailto:nathanila at gmail.com> nathanila at gmail.com> wrote:

> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan


On 5/26/2017 1:59 PM, Doug Lea wrote:

On 05/26/2017 12:22 PM, Gil Tene wrote:

Actually this is another case where the Java 9 spec needs to be adjusted…

The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
    <https://bugs.openjdk.java.net/browse/JDK-8181104> https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-- 
-Nathan



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/e25898c7/attachment-0001.html>

From oleksandr.otenko at gmail.com  Mon May 29 05:42:46 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 10:42:46 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
Message-ID: <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

Successful CAS atomic        Successful CAS not atomic
store z 0                    store z 0
CAS z 0 1                    load z
                             store z 1
store z 2                    store z 2

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.


There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

Failing CAS atomic intrinsic          Failing CAS not atomic
                             Not detectable    Detectable             Not detectable
store z 0                    store z 0         store z 0              store z 0
store z 2                    store z 2         load z                 load z
CAS z 0 1                    load z              store z 2              store z 2
                                               // store z 1 skipped   // store z 2 triggers retry
                                                                      load z
                                                                      // store z 1 skipped

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?


Alex

> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>  
> David
>  
> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
> Sent: Monday, May 29, 2017 6:15 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>  
> Thanks.
>  
> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>  
> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>  
> Example where you can claim atomicity of a failing CAS:
>  
> do{
>   tmp = load_linked(z);
> } while(tmp == expected && store_conditional(z, updated));
>  
> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>  
>  
> Alex
>  
>  
>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>  
>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>  
>> David
>>  
>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>> Sent: Monday, May 29, 2017 5:55 PM
>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>  
>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>  
>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>  
>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>  
>> So I am asking whether the *failing* CAS promises atomicity.
>>  
>>  
>> Alex
>>  
>>  
>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>  
>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>  
>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>  
>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>  
>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>  
>>> The gist of atomicity:
>>>  
>>> int x=0;
>>> volatile int z=0;
>>>  
>>> Thread 1:
>>> if (! CAS(z, 0, 1)) {
>>>   return x;
>>> }
>>> return 1;
>>>  
>>> Thread 2:
>>> x=1;
>>> z=1;
>>>  
>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>  
>>> Alex
>>>  
>>>  
>>>  
>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>  
>>>> Alex,
>>>>  
>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>  
>>>> David
>>>>  
>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>  
>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>  
>>>>  
>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>  
>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>  
>>>>  
>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>  
>>>> Alex
>>>>  
>>>>  
>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>  
>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>  
>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>  
>>>>> I think the actual relevant spec text is:
>>>>>  
>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>  
>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>  
>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>  
>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>  
>>>>>  
>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>> That’s right.
>>>>>>  
>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>  
>>>>>> Alex
>>>>>>  
>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>  
>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>  
>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>  
>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>  
>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>  
>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> int x=0; // non-volatile
>>>>>>>> volatile int z=0;
>>>>>>>> volatile boolean b=false;
>>>>>>>>  
>>>>>>>> Thread1:
>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>   if (x == 0) {
>>>>>>>>     b=true;
>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>   }
>>>>>>>> }
>>>>>>>> return x;
>>>>>>>>  
>>>>>>>> Thread2:
>>>>>>>> x=1;
>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>   return b;
>>>>>>>> }
>>>>>>>> return true;
>>>>>>>>  
>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>  
>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>  
>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>  
>>>>>>>>  
>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> Alex
>>>>>>>>  
>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>  
>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>  
>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>>  
>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>  
>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>  
>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>   k = z.get();
>>>>>>>>>>   if(k < j) {
>>>>>>>>>>     // i < k < j
>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>  
>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>     // stores or CASes
>>>>>>>>>>     ...
>>>>>>>>>>     return;
>>>>>>>>>>   }
>>>>>>>>>> }
>>>>>>>>>>  
>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>> Alex
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>  
>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>  
>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>  
>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>  
>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>  
>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>  
>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>  
>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>> 
>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>> 
>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>> 
>>>>>>>>>>>> -Nathan
>>>>>>>>>>>> 
>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>> 
>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>> -- 
>>>>>>>>>>>> -Nathan
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>  
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/b5e872f7/attachment-0001.html>

From davidcholmes at aapt.net.au  Mon May 29 07:10:15 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Mon, 29 May 2017 21:10:15 +1000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
Message-ID: <018201d2d86c$272b1c50$758154f0$@aapt.net.au>

The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.

 

David

 

 

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com] 
Sent: Monday, May 29, 2017 7:43 PM
To: dholmes at ieee.org
Cc: concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

 

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

 

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

 

Successful CAS atomic        Successful CAS not atomic

store z 0                    store z 0

CAS z 0 1                    load z

                             store z 1

store z 2                    store z 2

 

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.

 

 

There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

 

Failing CAS atomic intrinsic          Failing CAS not atomic

                             Not detectable    Detectable             Not detectable

store z 0                    store z 0         store z 0              store z 0

store z 2                    store z 2         load z                 load z

CAS z 0 1                    load z              store z 2              store z 2

                                               // store z 1 skipped   // store z 2 triggers retry

                                                                      load z

                                                                      // store z 1 skipped

 

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

 

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?

 

 

Alex

 

On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au> > wrote:

 

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org <mailto:dholmes at ieee.org> 
Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> 
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Thanks.

 

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

 

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

 

Example where you can claim atomicity of a failing CAS:

 

do{

  tmp = load_linked(z);

} while(tmp == expected && store_conditional(z, updated));

 

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.

 

 

Alex

 

 

On 29 May 2017, at 09:03, David Holmes < <mailto:davidcholmes at aapt.net.au> davidcholmes at aapt.net.au> wrote:

 

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

 

David

 

From: Alex Otenko [ <mailto:oleksandr.otenko at gmail.com> mailto:oleksandr.otenko at gmail.com] 
Sent: Monday, May 29, 2017 5:55 PM
To:  <mailto:dholmes at ieee.org> dholmes at ieee.org
Cc: Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org>;  <mailto:concurrency-interest at cs.oswego.edu> concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

 

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

 

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

 

So I am asking whether the *failing* CAS promises atomicity.

 

 

Alex

 

 

On 29 May 2017, at 00:26, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

 

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

 

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

 

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

 

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

 

The gist of atomicity:

 

int x=0;

volatile int z=0;

 

Thread 1:

if (! CAS(z, 0, 1)) {

  return x;

}

return 1;

 

Thread 2:

x=1;

z=1;

 

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 

 

Alex

 

 

 

On 28 May 2017, at 23:52, David Holmes < <mailto:davidcholmes at aapt.net.au> davidcholmes at aapt.net.au> wrote:

 

Alex,

 

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

 

David

 

From: Concurrency-interest [ <mailto:concurrency-interest-bounces at cs.oswego.edu> mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org>
Cc:  <mailto:concurrency-interest at cs.oswego.edu> concurrency-interest at cs.oswego.edu
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

 

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.

 

 

The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

 

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).

 

 

It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

 

Alex

 

 

On 28 May 2017, at 18:30, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

 

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

 

I think the actual relevant spec text is:

 

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

 

2) "Atomically sets the value to the given updated value if the current value == the expected value."

 

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

 

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.

 

 

On Sat, May 27, 2017 at 4:49 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

That’s right.

 

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

 

Alex

 

On 28 May 2017, at 00:43, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

 

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

 

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

 

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Not sure what you mean by “acting as a fence” being broken.

 

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.

 

 

int x=0; // non-volatile

volatile int z=0;

volatile boolean b=false;

 

Thread1:

if (CAS(z, 0, 1)) {

  if (x == 0) {

    b=true;

    CAS(z, 1, 2);

  }

}

return x;

 

Thread2:

x=1;

if (!CAS(z, 0, 2)) {

  return b;

}

return true;

 

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

 

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

 

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.

 

 

Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)

 

 

Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.

 

 

Alex

 

On 27 May 2017, at 18:34, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

 

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

 

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

 

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko < <mailto:oleksandr.otenko at gmail.com> oleksandr.otenko at gmail.com> wrote:

Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

 

if( ! z.CAS(i, j) ) {

  k = z.get();

  if(k < j) {

    // i < k < j

    // whoever mutated z from i to k, should also negotiate mutation of z from k to j

    // with someone else, and they should observe whatever stores precede z.CAS

    // because I won’t contend.

 

    // of course, I need to check they are still at it - but that, too, does not require

    // stores or CASes

    ...

    return;

  }

}

 

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.

 

 

In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?

 

 

Alex

 

 

On 26 May 2017, at 22:35, Hans Boehm < <mailto:boehm at acm.org> boehm at acm.org> wrote:

 

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

 

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

 

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

 

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

 

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

 

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

 

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds < <mailto:nathanila at gmail.com> nathanila at gmail.com> wrote:

> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan


On 5/26/2017 1:59 PM, Doug Lea wrote:

On 05/26/2017 12:22 PM, Gil Tene wrote:

Actually this is another case where the Java 9 spec needs to be adjusted…

The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
    <https://bugs.openjdk.java.net/browse/JDK-8181104> https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-- 
-Nathan



_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

_______________________________________________
Concurrency-interest mailing list
 <mailto:Concurrency-interest at cs.oswego.edu> Concurrency-interest at cs.oswego.edu
 <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/a41d2f91/attachment-0001.html>

From oleksandr.otenko at gmail.com  Mon May 29 07:35:44 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 12:35:44 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
Message-ID: <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>

I also have this intuition, but this looks like a proof by example, not a specification.

A specification would look something like:
1. CAS executes a volatile load unconditionally.
2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.

In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.

That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).

A strong CAS also has:

3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.

This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)

The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)


Alex


> On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au> wrote:
> 
> The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.
>  
> David
>  
>  
> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com] 
> Sent: Monday, May 29, 2017 7:43 PM
> To: dholmes at ieee.org
> Cc: concurrency-interest at cs.oswego.edu
> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>  
> Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)
>  
> I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.
>  
> Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.
>  
> Successful CAS atomic        Successful CAS not atomic
> store z 0                    store z 0
> CAS z 0 1                    load z
>                              store z 1
> store z 2                    store z 2
>  
> Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.
>  
>  
> There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.
>  
> Failing CAS atomic intrinsic          Failing CAS not atomic
>                              Not detectable    Detectable             Not detectable
> store z 0                    store z 0         store z 0              store z 0
> store z 2                    store z 2         load z                 load z
> CAS z 0 1                    load z              store z 2              store z 2
>                                                // store z 1 skipped   // store z 2 triggers retry
>                                                                       load z
>                                                                       // store z 1 skipped
>  
> If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.
>  
> I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?
>  
>  
> Alex
>  
>> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>  
>> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>>  
>> David
>>  
>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>> Sent: Monday, May 29, 2017 6:15 PM
>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>  
>> Thanks.
>>  
>> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>>  
>> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>>  
>> Example where you can claim atomicity of a failing CAS:
>>  
>> do{
>>   tmp = load_linked(z);
>> } while(tmp == expected && store_conditional(z, updated));
>>  
>> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>>  
>>  
>> Alex
>>  
>>  
>>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>  
>>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>>  
>>> David
>>>  
>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>> Sent: Monday, May 29, 2017 5:55 PM
>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>  
>>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>>  
>>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>>  
>>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>>  
>>> So I am asking whether the *failing* CAS promises atomicity.
>>>  
>>>  
>>> Alex
>>>  
>>>  
>>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>  
>>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>>  
>>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>>  
>>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>>  
>>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>>  
>>>> The gist of atomicity:
>>>>  
>>>> int x=0;
>>>> volatile int z=0;
>>>>  
>>>> Thread 1:
>>>> if (! CAS(z, 0, 1)) {
>>>>   return x;
>>>> }
>>>> return 1;
>>>>  
>>>> Thread 2:
>>>> x=1;
>>>> z=1;
>>>>  
>>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>>  
>>>> Alex
>>>>  
>>>>  
>>>>  
>>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>  
>>>>> Alex,
>>>>>  
>>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>>  
>>>>> David
>>>>>  
>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>  
>>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>>  
>>>>>  
>>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>>  
>>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>>  
>>>>>  
>>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>>  
>>>>> Alex
>>>>>  
>>>>>  
>>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>  
>>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>>  
>>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>>  
>>>>>> I think the actual relevant spec text is:
>>>>>>  
>>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>>  
>>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>>  
>>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>>  
>>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>>  
>>>>>>  
>>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>> That’s right.
>>>>>>>  
>>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>  
>>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>>  
>>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>>  
>>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>>  
>>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>>  
>>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> int x=0; // non-volatile
>>>>>>>>> volatile int z=0;
>>>>>>>>> volatile boolean b=false;
>>>>>>>>>  
>>>>>>>>> Thread1:
>>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>>   if (x == 0) {
>>>>>>>>>     b=true;
>>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>>   }
>>>>>>>>> }
>>>>>>>>> return x;
>>>>>>>>>  
>>>>>>>>> Thread2:
>>>>>>>>> x=1;
>>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>>   return b;
>>>>>>>>> }
>>>>>>>>> return true;
>>>>>>>>>  
>>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>>  
>>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>>  
>>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>  
>>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>>  
>>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>>>  
>>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>>  
>>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>>  
>>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>>   k = z.get();
>>>>>>>>>>>   if(k < j) {
>>>>>>>>>>>     // i < k < j
>>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>>  
>>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>>     // stores or CASes
>>>>>>>>>>>     ...
>>>>>>>>>>>     return;
>>>>>>>>>>>   }
>>>>>>>>>>> }
>>>>>>>>>>>  
>>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> Alex
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>  
>>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>>  
>>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>>  
>>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>>  
>>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>>  
>>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>>  
>>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>>  
>>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>> 
>>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>> 
>>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>>> -- 
>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>>  
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/8a92fa67/attachment-0001.html>

From gil at azul.com  Mon May 29 10:42:58 2017
From: gil at azul.com (Gil Tene)
Date: Mon, 29 May 2017 14:42:58 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet()
	mandatory	updating
In-Reply-To: <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>,
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
Message-ID: <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>

Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.

With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).

An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.

There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.

E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).

In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.

The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.

Sent from my iPad

On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

I also have this intuition, but this looks like a proof by example, not a specification.

A specification would look something like:
1. CAS executes a volatile load unconditionally.
2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.

In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.

That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).

A strong CAS also has:

3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.

This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)

The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)


Alex


On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.

David


From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 7:43 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

Successful CAS atomic        Successful CAS not atomic
store z 0                    store z 0
CAS z 0 1                    load z
                             store z 1
store z 2                    store z 2

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.


There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

Failing CAS atomic intrinsic          Failing CAS not atomic
                             Not detectable    Detectable             Not detectable
store z 0                    store z 0         store z 0              store z 0
store z 2                    store z 2         load z                 load z
CAS z 0 1                    load z              store z 2              store z 2
                                               // store z 1 skipped   // store z 2 triggers retry
                                                                      load z
                                                                      // store z 1 skipped

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?


Alex

On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Thanks.

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

Example where you can claim atomicity of a failing CAS:

do{
  tmp = load_linked(z);
} while(tmp == expected && store_conditional(z, updated));

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.


Alex


On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

David

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

So I am asking whether the *failing* CAS promises atomicity.


Alex


On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

The gist of atomicity:

int x=0;
volatile int z=0;

Thread 1:
if (! CAS(z, 0, 1)) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1.

Alex



On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Alex,

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.


The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).


It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

Alex


On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

I think the actual relevant spec text is:

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

2) "Atomically sets the value to the given updated value if the current value == the expected value."

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.


On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
That’s right.

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

Alex

On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Not sure what you mean by “acting as a fence” being broken.

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.


int x=0; // non-volatile
volatile int z=0;
volatile boolean b=false;

Thread1:
if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  }
}
return x;

Thread2:
x=1;
if (!CAS(z, 0, 2)) {
  return b;
}
return true;

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.


Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)


Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.


Alex

On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

if( ! z.CAS(i, j) ) {
  k = z.get();
  if(k < j) {
    // i < k < j
    // whoever mutated z from i to k, should also negotiate mutation of z from k to j
    // with someone else, and they should observe whatever stores precede z.CAS
    // because I won’t contend.

    // of course, I need to check they are still at it - but that, too, does not require
    // stores or CASes
    ...
    return;
  }
}

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.


In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?


Alex


On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com<mailto:nathanila at gmail.com>> wrote:
> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan

On 5/26/2017 1:59 PM, Doug Lea wrote:
On 05/26/2017 12:22 PM, Gil Tene wrote:
Actually this is another case where the Java 9 spec needs to be adjusted…
The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
   https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
-Nathan


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/c65a02b8/attachment-0001.html>

From jsampson at guidewire.com  Mon May 29 13:57:17 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Mon, 29 May 2017 17:57:17 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
Message-ID: <F8F5B149-326B-4B98-9899-B2CD425D9BCA@guidewire.com>

Gil Tene wrote:

> The recent discussion here is focused on whether a relaxing of the memory
> ordering semantics of compareAndSet, from the volatile write semantics
> being unconditional to being conditional (on the write actually occurring) is
> advisable. The claim is that there is existing Java software out there that
> may rely on the existing unconditional definition for correctness, and that
> relaxing the definition will break such software. Examples of how the
> conditional/unconditional behavior difference can be observed by a
> concurrent algorithm were given (I believe) as proof that such software
> can (and likely does) exist.

Thank you for your helpful definitions. As for examples, yes, Alex gave an
example of a racy program that relies on the unconditional volatile write
semantics of a strong CAS. I also gave examples of existing CAS methods in
j.u.c.atomic that do not have this property, so we know for certain that
JDK implementers have not had a consistent understanding of it being
required, even though it does seem pretty clear in the JDK 8 docs. That
leads me to presume that I shouldn't rely on that property being provided
by the various native implementations across platforms -- which is okay
with me because I've personally never _needed_ to rely on it -- but that
does cause problems for programs like Alex's.

Cheers,
Justin


From oleksandr.otenko at gmail.com  Mon May 29 14:43:48 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Mon, 29 May 2017 19:43:48 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
Message-ID: <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>


> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com> wrote:
> 
> When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them

When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.

ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.

Alex


> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com> wrote:
> 
> Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.
> 
> With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).
> 
> An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.
> 
> There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.
> 
> E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).
> 
> In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.
> 
> The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.
> 
> Sent from my iPad
> 
> On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> 
>> I also have this intuition, but this looks like a proof by example, not a specification.
>> 
>> A specification would look something like:
>> 1. CAS executes a volatile load unconditionally.
>> 2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.
>> 
>> In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.
>> 
>> That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).
>> 
>> A strong CAS also has:
>> 
>> 3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.
>> 
>> This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)
>> 
>> The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)
>> 
>> 
>> Alex
>> 
>> 
>>> On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>> 
>>> The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.
>>>  
>>> David
>>>  
>>>  
>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>> Sent: Monday, May 29, 2017 7:43 PM
>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>  
>>> Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)
>>>  
>>> I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.
>>>  
>>> Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.
>>>  
>>> Successful CAS atomic        Successful CAS not atomic
>>> store z 0                    store z 0
>>> CAS z 0 1                    load z
>>>                              store z 1
>>> store z 2                    store z 2
>>>  
>>> Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.
>>>  
>>>  
>>> There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.
>>>  
>>> Failing CAS atomic intrinsic          Failing CAS not atomic
>>>                              Not detectable    Detectable             Not detectable
>>> store z 0                    store z 0         store z 0              store z 0
>>> store z 2                    store z 2         load z                 load z
>>> CAS z 0 1                    load z              store z 2              store z 2
>>>                                                // store z 1 skipped   // store z 2 triggers retry
>>>                                                                       load z
>>>                                                                       // store z 1 skipped
>>>  
>>> If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.
>>>  
>>> I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?
>>>  
>>>  
>>> Alex
>>>  
>>>> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>  
>>>> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>>>>  
>>>> David
>>>>  
>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>> Sent: Monday, May 29, 2017 6:15 PM
>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>  
>>>> Thanks.
>>>>  
>>>> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>>>>  
>>>> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>>>>  
>>>> Example where you can claim atomicity of a failing CAS:
>>>>  
>>>> do{
>>>>   tmp = load_linked(z);
>>>> } while(tmp == expected && store_conditional(z, updated));
>>>>  
>>>> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>>>>  
>>>>  
>>>> Alex
>>>>  
>>>>  
>>>>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>  
>>>>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>>>>  
>>>>> David
>>>>>  
>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>> Sent: Monday, May 29, 2017 5:55 PM
>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>  
>>>>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>>>>  
>>>>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>>>>  
>>>>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>>>>  
>>>>> So I am asking whether the *failing* CAS promises atomicity.
>>>>>  
>>>>>  
>>>>> Alex
>>>>>  
>>>>>  
>>>>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>  
>>>>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>>>>  
>>>>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>>>>  
>>>>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>>>>  
>>>>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>>>>  
>>>>>> The gist of atomicity:
>>>>>>  
>>>>>> int x=0;
>>>>>> volatile int z=0;
>>>>>>  
>>>>>> Thread 1:
>>>>>> if (! CAS(z, 0, 1)) {
>>>>>>   return x;
>>>>>> }
>>>>>> return 1;
>>>>>>  
>>>>>> Thread 2:
>>>>>> x=1;
>>>>>> z=1;
>>>>>>  
>>>>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>>>>  
>>>>>> Alex
>>>>>>  
>>>>>>  
>>>>>>  
>>>>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>  
>>>>>>> Alex,
>>>>>>>  
>>>>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>>>>  
>>>>>>> David
>>>>>>>  
>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>  
>>>>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>>>>  
>>>>>>>  
>>>>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>>>>  
>>>>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>>>>  
>>>>>>>  
>>>>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>  
>>>>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>  
>>>>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>>>>  
>>>>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>>>>  
>>>>>>>> I think the actual relevant spec text is:
>>>>>>>>  
>>>>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>>>>  
>>>>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>>>>  
>>>>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>>>>  
>>>>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>> That’s right.
>>>>>>>>>  
>>>>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>  
>>>>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>>>>  
>>>>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>>>>  
>>>>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>>>>  
>>>>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>>>>  
>>>>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> int x=0; // non-volatile
>>>>>>>>>>> volatile int z=0;
>>>>>>>>>>> volatile boolean b=false;
>>>>>>>>>>>  
>>>>>>>>>>> Thread1:
>>>>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>>>>   if (x == 0) {
>>>>>>>>>>>     b=true;
>>>>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>>>>   }
>>>>>>>>>>> }
>>>>>>>>>>> return x;
>>>>>>>>>>>  
>>>>>>>>>>> Thread2:
>>>>>>>>>>> x=1;
>>>>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>>>>   return b;
>>>>>>>>>>> }
>>>>>>>>>>> return true;
>>>>>>>>>>>  
>>>>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>>>>  
>>>>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>>>>  
>>>>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> Alex
>>>>>>>>>>>  
>>>>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>  
>>>>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>>>>  
>>>>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>>>>>  
>>>>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>>>>  
>>>>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>>>>   k = z.get();
>>>>>>>>>>>>>   if(k < j) {
>>>>>>>>>>>>>     // i < k < j
>>>>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>>>>     // stores or CASes
>>>>>>>>>>>>>     ...
>>>>>>>>>>>>>     return;
>>>>>>>>>>>>>   }
>>>>>>>>>>>>> }
>>>>>>>>>>>>>  
>>>>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/5df37a6b/attachment-0001.html>

From gil at azul.com  Mon May 29 16:20:04 2017
From: gil at azul.com (Gil Tene)
Date: Mon, 29 May 2017 20:20:04 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
Message-ID: <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>


On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them

When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.

Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.

If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.

ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.

ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic. A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.

I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them.


Alex


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.

With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).

An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.

There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.

E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).

In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.

The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.

Sent from my iPad

On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

I also have this intuition, but this looks like a proof by example, not a specification.

A specification would look something like:
1. CAS executes a volatile load unconditionally.
2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.

In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.

That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).

A strong CAS also has:

3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.

This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)

The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)


Alex


On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.

David


From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 7:43 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

Successful CAS atomic        Successful CAS not atomic
store z 0                    store z 0
CAS z 0 1                    load z
                             store z 1
store z 2                    store z 2

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.


There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

Failing CAS atomic intrinsic          Failing CAS not atomic
                             Not detectable    Detectable             Not detectable
store z 0                    store z 0         store z 0              store z 0
store z 2                    store z 2         load z                 load z
CAS z 0 1                    load z              store z 2              store z 2
                                               // store z 1 skipped   // store z 2 triggers retry
                                                                      load z
                                                                      // store z 1 skipped

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?


Alex

On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Thanks.

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

Example where you can claim atomicity of a failing CAS:

do{
  tmp = load_linked(z);
} while(tmp == expected && store_conditional(z, updated));

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.


Alex


On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

David

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

So I am asking whether the *failing* CAS promises atomicity.


Alex


On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

The gist of atomicity:

int x=0;
volatile int z=0;

Thread 1:
if (! CAS(z, 0, 1)) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1.

Alex



On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Alex,

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.


The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).


It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

Alex


On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

I think the actual relevant spec text is:

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

2) "Atomically sets the value to the given updated value if the current value == the expected value."

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.


On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
That’s right.

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

Alex

On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Not sure what you mean by “acting as a fence” being broken.

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.


int x=0; // non-volatile
volatile int z=0;
volatile boolean b=false;

Thread1:
if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  }
}
return x;

Thread2:
x=1;
if (!CAS(z, 0, 2)) {
  return b;
}
return true;

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.


Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)


Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.


Alex

On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

if( ! z.CAS(i, j) ) {
  k = z.get();
  if(k < j) {
    // i < k < j
    // whoever mutated z from i to k, should also negotiate mutation of z from k to j
    // with someone else, and they should observe whatever stores precede z.CAS
    // because I won’t contend.

    // of course, I need to check they are still at it - but that, too, does not require
    // stores or CASes
    ...
    return;
  }
}

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.


In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?


Alex


On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com<mailto:nathanila at gmail.com>> wrote:
> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan

On 5/26/2017 1:59 PM, Doug Lea wrote:
On 05/26/2017 12:22 PM, Gil Tene wrote:
Actually this is another case where the Java 9 spec needs to be adjusted…
The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
   https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
-Nathan


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170529/b5646631/attachment-0001.html>

From jsampson at guidewire.com  Tue May 30 03:47:32 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Tue, 30 May 2017 07:47:32 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
Message-ID: <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>

Alex Otenko wrote:

> int x=0; // non-volatile
> volatile int z=0;
> volatile boolean b=false;
>
> Thread1:
> if (CAS(z, 0, 1)) {
>  if (x == 0) {
>    b=true;
>    CAS(z, 1, 2);
>  }
> }
> return x;
>
> Thread2:
> x=1;
> if (!CAS(z, 0, 2)) {
>  return b;
> }
> return true;

I keep going over this code in my head. The data race is tricky.

In particular, the conclusion that "if Thread2 returns false then Thread1 returns 1" seems to rely on an assumption that if the read of x in "x == 0" sees 1 then the read of x in "return x" will also see 1. What part of the JMM justifies that assumption? Both reads are racy, _unless_ the first read does _not_ see 1. If the first read _does_ see 1, then the second read is still racy and it's possible for it to see 0. Non-volatile reads can be reordered freely, can't they?

Cheers,
Justin



From oleksandr.otenko at gmail.com  Tue May 30 04:42:58 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 09:42:58 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>
Message-ID: <6B230B20-FFB4-49C7-865F-0926F306D6DD@gmail.com>

Racy reads can’t observe just any writes, only those that won’t contradict the happens-before partial order.

So you still need a write of 0 that you can place after the write of 1 in Thread 1. The initial write of 0 can’t be observed after any write observed after Thread 1 start.


Alex

> On 30 May 2017, at 08:47, Justin Sampson <jsampson at guidewire.com> wrote:
> 
> Alex Otenko wrote:
> 
>> int x=0; // non-volatile
>> volatile int z=0;
>> volatile boolean b=false;
>> 
>> Thread1:
>> if (CAS(z, 0, 1)) {
>>   if (x == 0) {
>>     b=true;
>>     CAS(z, 1, 2);
>>   }
>> }
>> return x;
>> 
>> Thread2:
>> x=1;
>> if (!CAS(z, 0, 2)) {
>>   return b;
>> }
>> return true;
> 
> I keep going over this code in my head. The data race is tricky.
> 
> In particular, the conclusion that "if Thread2 returns false then Thread1 returns 1" seems to rely on an assumption that if the read of x in "x == 0" sees 1 then the read of x in "return x" will also see 1. What part of the JMM justifies that assumption? Both reads are racy, _unless_ the first read does _not_ see 1. If the first read _does_ see 1, then the second read is still racy and it's possible for it to see 0. Non-volatile reads can be reordered freely, can't they?
> 
> Cheers,
> Justin
> 
> 


From oleksandr.otenko at gmail.com  Tue May 30 05:12:40 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 10:12:40 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
 <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>
Message-ID: <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>


> On 29 May 2017, at 21:20, Gil Tene <gil at azul.com> wrote:
> 
> 
>> On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> 
>> 
>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>> 
>>> When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them
>> 
>> When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.
> 
> Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.
> 
> If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.
> 
>> ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.
> 
> ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic.

It has, potentially.

Let me recap the diagram I’ve posted before.

A weak CAS:

   store z 0
load z
   store z 2
// skip store z 1

Here the weak CAS managed to execute a load, then observed something it believes to be an interleaving store, and skipped store of 1. Weak CAS does not synchronize-with the store that failed it, so it can be detected to be non-atomic. (Weak CAS is allowed to also fail for other reasons, but that’s not part of the problem)

A version of a strong CAS:

   store z 0
load z
   store z 2
// interleaving store triggers retry - ll/sc-based primitive has to ascertain it is not a “spurious” failure
load z
// skip store z 1

Here the strong CAS managed to execute a load, then observed something happened, then loaded again to be sure it was not due to false sharing but a true interleaving store to z. This second load synchronizes-with the store that failed it. This version of strong CAS is no less atomic than a successful CAS - as in “a single entity in the total order of all stores to z”, because it behaves like a CAS that was scheduled strictly after the store that failed it and before any other stores.


So my big question is: can a strong CAS detect the presence of an interleaving store without synchronizing-with it? Can it tell it is an interleaving store and not something else, without issuing a load or having effect of such a load?


Alex

> A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.
> 
> I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them. 
> 
>> 
>> Alex
>> 
>> 
>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>> 
>>> Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.
>>> 
>>> With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).
>>> 
>>> An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.
>>> 
>>> There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.
>>> 
>>> E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).
>>> 
>>> In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.
>>> 
>>> The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.
>>> 
>>> Sent from my iPad
>>> 
>>> On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>> 
>>>> I also have this intuition, but this looks like a proof by example, not a specification.
>>>> 
>>>> A specification would look something like:
>>>> 1. CAS executes a volatile load unconditionally.
>>>> 2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.
>>>> 
>>>> In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.
>>>> 
>>>> That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).
>>>> 
>>>> A strong CAS also has:
>>>> 
>>>> 3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.
>>>> 
>>>> This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)
>>>> 
>>>> The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)
>>>> 
>>>> 
>>>> Alex
>>>> 
>>>> 
>>>>> On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>> 
>>>>> The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.
>>>>>  
>>>>> David
>>>>>  
>>>>>  
>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>> Sent: Monday, May 29, 2017 7:43 PM
>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>  
>>>>> Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)
>>>>>  
>>>>> I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.
>>>>>  
>>>>> Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.
>>>>>  
>>>>> Successful CAS atomic        Successful CAS not atomic
>>>>> store z 0                    store z 0
>>>>> CAS z 0 1                    load z
>>>>>                              store z 1
>>>>> store z 2                    store z 2
>>>>>  
>>>>> Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.
>>>>>  
>>>>>  
>>>>> There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.
>>>>>  
>>>>> Failing CAS atomic intrinsic          Failing CAS not atomic
>>>>>                              Not detectable    Detectable             Not detectable
>>>>> store z 0                    store z 0         store z 0              store z 0
>>>>> store z 2                    store z 2         load z                 load z
>>>>> CAS z 0 1                    load z              store z 2              store z 2
>>>>>                                                // store z 1 skipped   // store z 2 triggers retry
>>>>>                                                                       load z
>>>>>                                                                       // store z 1 skipped
>>>>>  
>>>>> If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.
>>>>>  
>>>>> I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?
>>>>>  
>>>>>  
>>>>> Alex
>>>>>  
>>>>>> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>  
>>>>>> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>>>>>>  
>>>>>> David
>>>>>>  
>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>> Sent: Monday, May 29, 2017 6:15 PM
>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>  
>>>>>> Thanks.
>>>>>>  
>>>>>> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>>>>>>  
>>>>>> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>>>>>>  
>>>>>> Example where you can claim atomicity of a failing CAS:
>>>>>>  
>>>>>> do{
>>>>>>   tmp = load_linked(z);
>>>>>> } while(tmp == expected && store_conditional(z, updated));
>>>>>>  
>>>>>> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>>>>>>  
>>>>>>  
>>>>>> Alex
>>>>>>  
>>>>>>  
>>>>>>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>  
>>>>>>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>>>>>>  
>>>>>>> David
>>>>>>>  
>>>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>>>> Sent: Monday, May 29, 2017 5:55 PM
>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>  
>>>>>>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>>>>>>  
>>>>>>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>>>>>>  
>>>>>>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>>>>>>  
>>>>>>> So I am asking whether the *failing* CAS promises atomicity.
>>>>>>>  
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>  
>>>>>>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>  
>>>>>>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>>>>>>  
>>>>>>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>>>>>>  
>>>>>>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>>>>>>  
>>>>>>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>>>>>>  
>>>>>>>> The gist of atomicity:
>>>>>>>>  
>>>>>>>> int x=0;
>>>>>>>> volatile int z=0;
>>>>>>>>  
>>>>>>>> Thread 1:
>>>>>>>> if (! CAS(z, 0, 1)) {
>>>>>>>>   return x;
>>>>>>>> }
>>>>>>>> return 1;
>>>>>>>>  
>>>>>>>> Thread 2:
>>>>>>>> x=1;
>>>>>>>> z=1;
>>>>>>>>  
>>>>>>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>>>>>>  
>>>>>>>> Alex
>>>>>>>>  
>>>>>>>>  
>>>>>>>>  
>>>>>>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>  
>>>>>>>>> Alex,
>>>>>>>>>  
>>>>>>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>>>>>>  
>>>>>>>>> David
>>>>>>>>>  
>>>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>>>>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>  
>>>>>>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>>>>>>  
>>>>>>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>  
>>>>>>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>>>>>>  
>>>>>>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>>>>>>  
>>>>>>>>>> I think the actual relevant spec text is:
>>>>>>>>>>  
>>>>>>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>>>>>>  
>>>>>>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>>>>>>  
>>>>>>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>>>>>>  
>>>>>>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>> That’s right.
>>>>>>>>>>>  
>>>>>>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>>>>>>  
>>>>>>>>>>> Alex
>>>>>>>>>>>  
>>>>>>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>  
>>>>>>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>>>>>>  
>>>>>>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>>>>>>  
>>>>>>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>>>>>>  
>>>>>>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> int x=0; // non-volatile
>>>>>>>>>>>>> volatile int z=0;
>>>>>>>>>>>>> volatile boolean b=false;
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Thread1:
>>>>>>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>>>>>>   if (x == 0) {
>>>>>>>>>>>>>     b=true;
>>>>>>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>>>>>>   }
>>>>>>>>>>>>> }
>>>>>>>>>>>>> return x;
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Thread2:
>>>>>>>>>>>>> x=1;
>>>>>>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>>>>>>   return b;
>>>>>>>>>>>>> }
>>>>>>>>>>>>> return true;
>>>>>>>>>>>>>  
>>>>>>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>>>>>>  
>>>>>>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real  programming concerns.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>>>>>>   k = z.get();
>>>>>>>>>>>>>>>   if(k < j) {
>>>>>>>>>>>>>>>     // i < k < j
>>>>>>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>>>>>>     // stores or CASes
>>>>>>>>>>>>>>>     ...
>>>>>>>>>>>>>>>     return;
>>>>>>>>>>>>>>>   }
>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> _______________________________________________
>>>> Concurrency-interest mailing list
>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/e3731a1b/attachment-0001.html>

From aph at redhat.com  Tue May 30 09:24:35 2017
From: aph at redhat.com (Andrew Haley)
Date: Tue, 30 May 2017 14:24:35 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
 <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>
 <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
Message-ID: <7fe01fb2-fab5-1d41-1e17-8ed00e9717a3@redhat.com>

On 30/05/17 10:12, Alex Otenko wrote:

> So my big question is: can a strong CAS detect the presence of an
> interleaving store without synchronizing-with it?

Surely yes: what if the interleaving store is not a volatile store?
I may be misunderstanding the question.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From oleksandr.otenko at gmail.com  Tue May 30 09:52:14 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 14:52:14 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <7fe01fb2-fab5-1d41-1e17-8ed00e9717a3@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
 <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>
 <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
 <7fe01fb2-fab5-1d41-1e17-8ed00e9717a3@redhat.com>
Message-ID: <5D00AF00-6674-4BE8-87C0-D1EE822FC926@gmail.com>

But then a successful CAS does not guarantee it synchronizes-with the store that makes it succeed - in case it was not a volatile store.

So if we leave out the non-volatile stores to the same variable that may be interacting with CAS, for a moment…

Alex

> On 30 May 2017, at 14:24, Andrew Haley <aph at redhat.com> wrote:
> 
> On 30/05/17 10:12, Alex Otenko wrote:
> 
>> So my big question is: can a strong CAS detect the presence of an
>> interleaving store without synchronizing-with it?
> 
> Surely yes: what if the interleaving store is not a volatile store?
> I may be misunderstanding the question.
> 
> -- 
> Andrew Haley
> Java Platform Lead Engineer
> Red Hat UK Ltd. <https://www.redhat.com>
> EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671


From dl at cs.oswego.edu  Tue May 30 10:06:47 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Tue, 30 May 2017 10:06:47 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
Message-ID: <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>


Catching up...

On 05/26/2017 04:08 PM, Nathan and Ila Reynolds wrote:
>> "The memory effects of a write occur regardless of outcome."
>> "This method has memory effects of at least one volatile read and write."
> 
> I am not sure what memory effects means.  If this is defined somewhere
> in the specs, then ignore this since I haven't read JDK 9 specs.

Thanks; it would be better to say:
"The memory consistency effects of a write occur regardless of outcome."

About the controversy surrounding ARM mappings for Volatile-mode CAS:
The main underlying intent is to ensure that Volatile mode operations
act atomically and as if globally totally ordered wrt each other.
With single instruction CAS (as on x86 etc), this is easy to arrange.
Plus there are cases like CAS of thread-confined variables in which,
in principle they could be optimized to conditional stores; plus other
similar weakenings. In the absence of weakening, when emulated using
ARM/POWER LL/SC, this further interacts with whether implementations
use trailing-fence vs leading-fence conventions. If using trailing
fence (which most if not all Java implementations do), then it seems
that the only good decision is to issue a fence on comparison failure;
perhaps differently depending on whether using AArch64 LDAX/STRX
vs explicit fences inside CAS loop.

At least some C/C++ ARM and POWER mappings use leading-fence
convention, which could lead to differences here. Also, there
are version of C++ compare_exchange_strong that take a second
memory_order argument controlling the consistency effects on
failure (by default seq_cst/volatile). Although implementations
elide fence here only on comparison failure, not on contention
failure. There's no Java equivalent, so people would need to
use one of the weak variants and add fences.

-Doug



From gil at azul.com  Tue May 30 11:27:38 2017
From: gil at azul.com (Gil Tene)
Date: Tue, 30 May 2017 15:27:38 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
 <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>,
 <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
Message-ID: <2BAE6463-EB5D-44AF-8F87-CBCD0909E828@azul.com>



Sent from my iPad

On May 30, 2017, at 2:12 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


On 29 May 2017, at 21:20, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:


On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them

When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.

Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.

If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.

ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.

ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic.

It has, potentially.

Let me recap the diagram I’ve posted before.

A weak CAS:

   store z 0
load z
   store z 2
// skip store z 1

Here the weak CAS managed to execute a load, then observed something it believes to be an interleaving store, and skipped store of 1. Weak CAS does not synchronize-with the store that failed it, so it can be detected to be non-atomic. (Weak CAS is allowed to also fail for other reasons, but that’s not part of the problem)

A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".

But you can't *detect* an interleaving store here. There is nothing that lets you know that there was actually an interleaving store. A failure certainly doesn't tell you that's what happened. The failure could have been caused by something else (spurious) with no store at all. And it could also be caused by a preceding store. No way to tell.

A version of a strong CAS:

   store z 0
load z
   store z 2
// interleaving store triggers retry - ll/sc-based primitive has to ascertain it is not a “spurious” failure
load z
// skip store z 1

Here the strong CAS managed to execute a load, then observed something happened, then loaded again to be sure it was not due to false sharing but a true interleaving store to z. This second load synchronizes-with the store that failed it. This version of strong CAS is no less atomic than a successful CAS - as in “a single entity in the total order of all stores to z”, because it behaves like a CAS that was scheduled strictly after the store that failed it and before any other stores.

You are mixing atomicity of the CAS sub-operations (the indivisibility of the read and the write if the write occurs) with ordering against other operations. Nothing about atomicity implies ordering. And failing CAS is no more or less atomic than a single load operation.

A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store. But it is not necessarily before any other stores. That second part depends on ordering promises and on program order. Nothing to do with atomicity.

A failing strong compareAndSet (e.g. in Java 8) is strictly before any loads and stores that follow it in program order. That's true because of its memory ordering semantics promises. Not because of atomicity.

So my big question is: can a strong CAS detect the presence of an interleaving store without synchronizing-with it? Can it tell it is an interleaving store and not something else, without issuing a load or having effect of such a load?

A successful atomic CAS instruction (weak or strong) guarantees that no interleaving store occurred. That not the same as being able to detect that one occurs.

A CAS can't detect an interleaving store in either case (strong or weak). The reason for failure in weak CAS is "I felt like it", and the reason for failure in strong CAS is "the value in the field did not match the expected value". Both reasons can occur with no interleaving store (e.g. the store could have occurred in the past). Since there is no "interleaving store detection" mechanism to begin with, the rest of the question is therefore not relevant.



Alex

A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.

I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them.


Alex


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.

With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).

An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.

There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.

E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).

In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.

The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.

Sent from my iPad

On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

I also have this intuition, but this looks like a proof by example, not a specification.

A specification would look something like:
1. CAS executes a volatile load unconditionally.
2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.

In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.

That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).

A strong CAS also has:

3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.

This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)

The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)


Alex


On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.

David


From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 7:43 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

Successful CAS atomic        Successful CAS not atomic
store z 0                    store z 0
CAS z 0 1                    load z
                             store z 1
store z 2                    store z 2

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.


There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

Failing CAS atomic intrinsic          Failing CAS not atomic
                             Not detectable    Detectable             Not detectable
store z 0                    store z 0         store z 0              store z 0
store z 2                    store z 2         load z                 load z
CAS z 0 1                    load z              store z 2              store z 2
                                               // store z 1 skipped   // store z 2 triggers retry
                                                                      load z
                                                                      // store z 1 skipped

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?


Alex

On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Thanks.

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

Example where you can claim atomicity of a failing CAS:

do{
  tmp = load_linked(z);
} while(tmp == expected && store_conditional(z, updated));

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.


Alex


On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

David

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

So I am asking whether the *failing* CAS promises atomicity.


Alex


On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

The gist of atomicity:

int x=0;
volatile int z=0;

Thread 1:
if (! CAS(z, 0, 1)) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1.

Alex



On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Alex,

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.


The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).


It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

Alex


On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

I think the actual relevant spec text is:

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

2) "Atomically sets the value to the given updated value if the current value == the expected value."

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.


On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
That’s right.

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

Alex

On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Not sure what you mean by “acting as a fence” being broken.

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.


int x=0; // non-volatile
volatile int z=0;
volatile boolean b=false;

Thread1:
if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  }
}
return x;

Thread2:
x=1;
if (!CAS(z, 0, 2)) {
  return b;
}
return true;

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.


Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)


Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.


Alex

On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

if( ! z.CAS(i, j) ) {
  k = z.get();
  if(k < j) {
    // i < k < j
    // whoever mutated z from i to k, should also negotiate mutation of z from k to j
    // with someone else, and they should observe whatever stores precede z.CAS
    // because I won’t contend.

    // of course, I need to check they are still at it - but that, too, does not require
    // stores or CASes
    ...
    return;
  }
}

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.


In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?


Alex


On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com<mailto:nathanila at gmail.com>> wrote:
> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan

On 5/26/2017 1:59 PM, Doug Lea wrote:
On 05/26/2017 12:22 PM, Gil Tene wrote:
Actually this is another case where the Java 9 spec needs to be adjusted…
The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
   https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
-Nathan


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/849c9a7b/attachment-0001.html>

From oleksandr.otenko at gmail.com  Tue May 30 12:26:41 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 17:26:41 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <2BAE6463-EB5D-44AF-8F87-CBCD0909E828@azul.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKne
 nz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <CAPUmR1a1FVFDPgm5Jk9A8G4mwDLVE9geOktJaP6V4HwqHbXsxg@mail.gmail.com>
 <F61873B5-62C8-474F-B339-78A1CCE94A48@gmail.com>
 <CAPUmR1bxtyjKtfxy14jHs3qtcXzW4X3=4obdx6x=HkJuMHM8eQ@mail.gmail.com>
 <C376DDED-8F0E-42B1-8F99-DD90C28C22D5@gmail.com>
 <010901d2d805$26defdf0$749cf9d0$@aapt.net.au>
 <D4DCA5CA-3BC7-4E20-8AA4-DC921AE0B364@gmail.com>
 <C60FC38D-B8DC-43E1-A865-1D71B5FB0707@gmail.com>
 <015301d2d852$0498b400$0dca1c00$@aapt.net.au>
 <6B54BFE3-1A40-4E67-9750-90DAB6D02F2E@gmail.com>
 <016401d2d855$fba7bea0$f2f73be0$@aapt.net.au>
 <B22B556A-C824-44AD-8676-7C1F3B171D8C@gmail.com>
 <018201d2d86c$272b1c50$758154f0$@aapt.net.au>
 <7E966DD0-E8CB-41DB-B8F1-BF59672D9DF2@gmail.com>
 <43D790A7-CE62-4108-AC01-506DECEAC04A@azul.com>
 <0F107240-DE17-4032-B2B0-C754450BAC1A@gmail.com>
 <9711D3B8-5F79-4676-8B9D-DF32392C1B79@azul.com>
 <96CC940C-EB78-4067-A5D2-1BA8E18157FB@gmail.com>
 <2BAE6463-EB5D-44AF-8F87-CBCD0909E828@azul.com>
Message-ID: <D67F6D35-7F24-4646-915B-1F8CE2CF0340@gmail.com>


> A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".


Sure. I only took it a bit further, and explored the hypothetical implementation that didn’t fail sc spuriously (suppose, variables are cache-aligned, and no other variables reside on the same cache line, and no other events cause cache invalidation). The weak CAS would then be detectable as non-atomic - you can detect the load is not strictly after the store that failed the CAS. This is essentially what the litmus test for atomicity establishes (see one of previous messages proposing such a test, when we switched to discussing atomicity).


> A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store.


Excellent. Then it synchronizes-with it. Then it is observed as a atomic - not distinguishable from atomic.


> But it is not necessarily before any other stores.


Yes, I realize this detail. But such ordering is not detectable - not distinguishable from those other stores being strictly after or strictly before the failing strong CAS.


Alex

> On 30 May 2017, at 16:27, Gil Tene <gil at azul.com> wrote:
> 
> 
> 
> Sent from my iPad
> 
> On May 30, 2017, at 2:12 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
> 
>> 
>>> On 29 May 2017, at 21:20, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>> 
>>> 
>>>> On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>> 
>>>> 
>>>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>>>> 
>>>>> When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them
>>>> 
>>>> When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.
>>> 
>>> Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.
>>> 
>>> If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.
>>> 
>>>> ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.
>>> 
>>> ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic.
>> 
>> It has, potentially.
>> 
>> Let me recap the diagram I’ve posted before.
>> 
>> A weak CAS:
>> 
>>    store z 0
>> load z
>>    store z 2
>> // skip store z 1
>> 
>> Here the weak CAS managed to execute a load, then observed something it believes to be an interleaving store, and skipped store of 1. Weak CAS does not synchronize-with the store that failed it, so it can be detected to be non-atomic. (Weak CAS is allowed to also fail for other reasons, but that’s not part of the problem)
> 
> A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".
> 
> But you can't *detect* an interleaving store here. There is nothing that lets you know that there was actually an interleaving store. A failure certainly doesn't tell you that's what happened. The failure could have been caused by something else (spurious) with no store at all. And it could also be caused by a preceding store. No way to tell.
> 
>> A version of a strong CAS:
>> 
>>    store z 0
>> load z
>>    store z 2
>> // interleaving store triggers retry - ll/sc-based primitive has to ascertain it is not a “spurious” failure
>> load z
>> // skip store z 1
>> 
>> Here the strong CAS managed to execute a load, then observed something happened, then loaded again to be sure it was not due to false sharing but a true interleaving store to z. This second load synchronizes-with the store that failed it. This version of strong CAS is no less atomic than a successful CAS - as in “a single entity in the total order of all stores to z”, because it behaves like a CAS that was scheduled strictly after the store that failed it and before any other stores.
> 
> You are mixing atomicity of the CAS sub-operations (the indivisibility of the read and the write if the write occurs) with ordering against other operations. Nothing about atomicity implies ordering. And failing CAS is no more or less atomic than a single load operation.
> 
> A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store. But it is not necessarily before any other stores. That second part depends on ordering promises and on program order. Nothing to do with atomicity.
> 
> A failing strong compareAndSet (e.g. in Java 8) is strictly before any loads and stores that follow it in program order. That's true because of its memory ordering semantics promises. Not because of atomicity.
> 
>> So my big question is: can a strong CAS detect the presence of an interleaving store without synchronizing-with it? Can it tell it is an interleaving store and not something else, without issuing a load or having effect of such a load?
> 
> A successful atomic CAS instruction (weak or strong) guarantees that no interleaving store occurred. That not the same as being able to detect that one occurs.
> 
> A CAS can't detect an interleaving store in either case (strong or weak). The reason for failure in weak CAS is "I felt like it", and the reason for failure in strong CAS is "the value in the field did not match the expected value". Both reasons can occur with no interleaving store (e.g. the store could have occurred in the past). Since there is no "interleaving store detection" mechanism to begin with, the rest of the question is therefore not relevant.
> 
>> 
>> 
>> Alex
>> 
>>> A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.
>>> 
>>> I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them. 
>>> 
>>>> 
>>>> Alex
>>>> 
>>>> 
>>>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>>>> 
>>>>> Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.
>>>>> 
>>>>> With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).
>>>>> 
>>>>> An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.
>>>>> 
>>>>> There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.
>>>>> 
>>>>> E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).
>>>>> 
>>>>> In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.
>>>>> 
>>>>> The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.
>>>>> 
>>>>> Sent from my iPad
>>>>> 
>>>>> On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>> 
>>>>>> I also have this intuition, but this looks like a proof by example, not a specification.
>>>>>> 
>>>>>> A specification would look something like:
>>>>>> 1. CAS executes a volatile load unconditionally.
>>>>>> 2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.
>>>>>> 
>>>>>> In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.
>>>>>> 
>>>>>> That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).
>>>>>> 
>>>>>> A strong CAS also has:
>>>>>> 
>>>>>> 3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.
>>>>>> 
>>>>>> This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)
>>>>>> 
>>>>>> The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)
>>>>>> 
>>>>>> 
>>>>>> Alex
>>>>>> 
>>>>>> 
>>>>>>> On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>> 
>>>>>>> The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.
>>>>>>>  
>>>>>>> David
>>>>>>>  
>>>>>>>  
>>>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>>>> Sent: Monday, May 29, 2017 7:43 PM
>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>  
>>>>>>> Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)
>>>>>>>  
>>>>>>> I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.
>>>>>>>  
>>>>>>> Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.
>>>>>>>  
>>>>>>> Successful CAS atomic        Successful CAS not atomic
>>>>>>> store z 0                    store z 0
>>>>>>> CAS z 0 1                    load z
>>>>>>>                              store z 1
>>>>>>> store z 2                    store z 2
>>>>>>>  
>>>>>>> Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.
>>>>>>>  
>>>>>>>  
>>>>>>> There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.
>>>>>>>  
>>>>>>> Failing CAS atomic intrinsic          Failing CAS not atomic
>>>>>>>                              Not detectable    Detectable             Not detectable
>>>>>>> store z 0                    store z 0         store z 0              store z 0
>>>>>>> store z 2                    store z 2         load z                 load z
>>>>>>> CAS z 0 1                    load z              store z 2              store z 2
>>>>>>>                                                // store z 1 skipped   // store z 2 triggers retry
>>>>>>>                                                                       load z
>>>>>>>                                                                       // store z 1 skipped
>>>>>>>  
>>>>>>> If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.
>>>>>>>  
>>>>>>> I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?
>>>>>>>  
>>>>>>>  
>>>>>>> Alex
>>>>>>>  
>>>>>>>> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>  
>>>>>>>> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>>>>>>>>  
>>>>>>>> David
>>>>>>>>  
>>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>>> Sent: Monday, May 29, 2017 6:15 PM
>>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>  
>>>>>>>> Thanks.
>>>>>>>>  
>>>>>>>> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>>>>>>>>  
>>>>>>>> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>>>>>>>>  
>>>>>>>> Example where you can claim atomicity of a failing CAS:
>>>>>>>>  
>>>>>>>> do{
>>>>>>>>   tmp = load_linked(z);
>>>>>>>> } while(tmp == expected && store_conditional(z, updated));
>>>>>>>>  
>>>>>>>> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>>>>>>>>  
>>>>>>>>  
>>>>>>>> Alex
>>>>>>>>  
>>>>>>>>  
>>>>>>>>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>  
>>>>>>>>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>>>>>>>>  
>>>>>>>>> David
>>>>>>>>>  
>>>>>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>>>>>> Sent: Monday, May 29, 2017 5:55 PM
>>>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>  
>>>>>>>>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>>>>>>>>  
>>>>>>>>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>>>>>>>>  
>>>>>>>>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>>>>>>>>  
>>>>>>>>> So I am asking whether the *failing* CAS promises atomicity.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>  
>>>>>>>>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>>>>>>>>  
>>>>>>>>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>>>>>>>>  
>>>>>>>>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>>>>>>>>  
>>>>>>>>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>>>>>>>>  
>>>>>>>>>> The gist of atomicity:
>>>>>>>>>>  
>>>>>>>>>> int x=0;
>>>>>>>>>> volatile int z=0;
>>>>>>>>>>  
>>>>>>>>>> Thread 1:
>>>>>>>>>> if (! CAS(z, 0, 1)) {
>>>>>>>>>>   return x;
>>>>>>>>>> }
>>>>>>>>>> return 1;
>>>>>>>>>>  
>>>>>>>>>> Thread 2:
>>>>>>>>>> x=1;
>>>>>>>>>> z=1;
>>>>>>>>>>  
>>>>>>>>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>>>>>>>>  
>>>>>>>>>> Alex
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>>  
>>>>>>>>>>> Alex,
>>>>>>>>>>>  
>>>>>>>>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>>>>>>>>  
>>>>>>>>>>> David
>>>>>>>>>>>  
>>>>>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>>>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>>>>>>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>>>  
>>>>>>>>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>>>>>>>>  
>>>>>>>>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>>>>>>>>  
>>>>>>>>>>> Alex
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>  
>>>>>>>>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS  in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>>>>>>>>  
>>>>>>>>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>>>>>>>>  
>>>>>>>>>>>> I think the actual relevant spec text is:
>>>>>>>>>>>>  
>>>>>>>>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>>>>>>>>  
>>>>>>>>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>>>>>>>>  
>>>>>>>>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>>>>>>>>  
>>>>>>>>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>>>>>>>>  
>>>>>>>>>>>>  
>>>>>>>>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>> That’s right.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> int x=0; // non-volatile
>>>>>>>>>>>>>>> volatile int z=0;
>>>>>>>>>>>>>>> volatile boolean b=false;
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Thread1:
>>>>>>>>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>>>>>>>>   if (x == 0) {
>>>>>>>>>>>>>>>     b=true;
>>>>>>>>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>>>>>>>>   }
>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>> return x;
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Thread2:
>>>>>>>>>>>>>>> x=1;
>>>>>>>>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>>>>>>>>   return b;
>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>> return true;
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>>>>>>>>   k = z.get();
>>>>>>>>>>>>>>>>>   if(k < j) {
>>>>>>>>>>>>>>>>>     // i < k < j
>>>>>>>>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>>>>>>>>     // stores or CASes
>>>>>>>>>>>>>>>>>     ...
>>>>>>>>>>>>>>>>>     return;
>>>>>>>>>>>>>>>>>   }
>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>> _______________________________________________
>>>>>> Concurrency-interest mailing list
>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>> 
>>> 
>> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/98080a4c/attachment-0001.html>

From gergg at cox.net  Tue May 30 12:31:53 2017
From: gergg at cox.net (Gregg Wonderly)
Date: Tue, 30 May 2017 11:31:53 -0500
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <S84g1v00B0dAWJx0184ht0>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu> <R39P1v04C02hR0p0139WM5>
 <54922133-4757-4A75-BA34-2FC3E611810C@cox.net> <S84g1v00B0dAWJx0184ht0>
Message-ID: <8E74BB09-BBB1-429E-8592-0CDDF6A8708B@cox.net>


> On May 29, 2017, at 3:04 AM, Andrew Haley <aph at redhat.com> wrote:
> 
> On 28/05/17 02:27, Gregg Wonderly wrote:
>> 
>>> On May 26, 2017, at 10:05 AM, Andrew Haley <aph at redhat.com> wrote:
>>> 
>>> On 26/05/17 14:56, Doug Lea wrote:
>>>> On 05/26/2017 09:35 AM, Andrew Haley wrote:
>>>>> On 26/05/17 13:56, Andrew Dinn wrote:
>>>> 
>>>>>>> Initially (in Java5) requiring it has led to some questionable reliance.
>>>>>>> So we cannot change it. But there's not much motivation to do so anyway:
>>>>>>> As implied by Nathan Reynolds, encountering some (local) fence overhead
>>>>>>> on CAS failure typically reduces contention and may improve throughput.
>>>>>> 
>>>>>> It would be useful to know if that reduction in contention is specific
>>>>>> to, say, x86 hardware or also occurs on weak memory architectures like
>>>>>> AArch64 or ppc. Perhaps Nathan could clarify that?
>>>> 
>>>> The main issues are not tightly bound to architecture.
>>>> In the vast majority of cases, the response to CAS failure is
>>>> some sort of retry (although perhaps with some intermediate
>>>> processing). The fence here plays a similar role to
>>>> Thread.onSpinWait. And in fact, on ARM, is likely to be
>>>> exactly the same implementation as onSpinWait.
>>> 
>>> onSpinWait is null, and unless ARM does something to the architecture
>>> that's probably what it'll remain.
>>> 
>>>> As Alex mentioned, in the uncommon cases where this
>>>> is a performance issue, people can use one of the weak CAS
>>>> variants.
>>>> 
>>>>> Just thinking about AArch64, and how to implement such a thing as well
>>>>> as possible. 
>>>> 
>>>> "As well as possible" may be just to unconditionally issue fence,
>>>> at least for plain CAS; maybe differently for the variants.
>>> 
>>> I doubt that: I've done some measurements, and it always pays to branch
>>> conditionally around a fence if it's not needed.
>> 
>> Since the fence is part of the happens before controls that
>> developers encounter, how can a library routine know what the
>> developer needs, to know how to “randomly” optimize with a branch
>> around the fence?  Are you aware of no software that exists where
>> developers are actively counting MM interactions trying to minimize
>> them?  Here you are trying to do it yourself because you “See” an
>> optimization that is so localized, away from any explicit code
>> intent, that you can’t tell ahead of time (during development of
>> your optimization), what other developers have actually done around
>> the fact that this fence was unconditional before right?
>> 
>> Help me understand how you know that no software that works
>> correctly now, will start working randomly, incorrectly, because
>> sometimes the fence never happens.
> 
> It's in the specification.  If a fence is required by the
> specification, we must execute one. If not, the question is whether
> it's faster to execute a fence unconditionally or to branch around it.

But that’s not my point.  My point is that once there is a fence, and since now developers are having to program according to “fences” explicit or implicit in the API implementation, you are going to find developers counting and demanding specific fences to be in specific places, because they create happens before events which are precisely what developers must manage.   And, just like you are adamant that performance can be improved by not always providing this fence, developers and engineers are trying to do exactly the same thing by looking at the complete picture of their application (which you have no view into from the point of this optimization).   They are saying to themselves, hey, theirs a write fence in this API, so if we use that to, for example assign a value via CAS, as a work item counter, then we don’t have to worry about all the other state before that, it will be visible.

As soon as you take out the fence, they now have to put in synchronization themselves, and if the fence is always dropped by their code and mostly by the CAS implementation, there are too many write fences, and by spec, they can’t eliminate one of them, they always have to have two.

It’s this kind of optimization where behaviors are unpredictable for essential programming paradigms that make it impossible to find solutions that are optimal, without completely writing everything yourself with unsafe and/or JNI.  Everything about happens-before rides the front side of the wave for https://en.wikipedia.org/wiki/Principle_of_least_astonishment <https://en.wikipedia.org/wiki/Principle_of_least_astonishment>.  Many developers who aren’t working in a single threaded platform environment, are constantly having to manage this issue.  AWT/Swing and background work tasks are plagued with making sure that the AWT thread(s) environment is shared with worker threads, in both directions.  In this environment, volatile everything is the primary solution to keep from having every assignment turn into a whole block of code.

If happens-before is really a necessary part of “Java the Language”, then JDK libraries need to stop making it a hidden feature with random behaviors around edges that the developer is not in explicit control of.   It has become a bigger and bigger rash that is swollen and ugly because there is not a complete solution across the language implementation that provides the explicit view (like checked exceptions do for unrecoverable errors) into the required behavior.   Instead, we have subsets of the runtime which provide many details of control which are seamless.  

ConcurrentHashMap makes data sharing work reliably with no worries, because the APIs do the right thing.

I can see that you’d feel that CAS shouldn’t drop the fence if it didn’t write the value.  However, because that is a costly event that you are trying to remove, some developers may be using CAS as a fence for themselves because it was happening every time already.  I mean, they may be using CAS in a single writer, multiple reader environment where the fence would always drop with or without your change.  But, think of what happens when they add a second writer.  Now, the fence would not always drop because of the race, and thus other visibility issues may arise that would make it very difficult for someone unfamiliar with the “use the fence” optimization to figure out what is going on. Regardless of what the ‘spec’ says, it’s what the implementation does, which become the legacy that has to be supported for the future.  

Would you be happy to break their code with an optimization that is awesome for super racy code, but can break code that is not super racy and ends up with a 1 in 10000 event failure mode that no-one can figure out?

Gregg

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/75f743e1/attachment.html>

From gil at azul.com  Tue May 30 12:34:53 2017
From: gil at azul.com (Gil Tene)
Date: Tue, 30 May 2017 16:34:53 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <D67F6D35-7F24-4646-915B-1F8CE2CF0340@gmail.com>
Message-ID: <2B18F1A8-A639-45AD-8F96-23D31E426077@azul.com>


On May 30, 2017, at 9:26 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".

Sure. I only took it a bit further, and explored the hypothetical implementation that didn’t fail sc spuriously (suppose, variables are cache-aligned, and no other variables reside on the same cache line, and no other events cause cache invalidation). The weak CAS would then be detectable as non-atomic - you can detect the load is not strictly after the store that failed the CAS. This is essentially what the litmus test for atomicity establishes (see one of previous messages proposing such a test, when we switched to discussing atomicity).

*How* would you determine that is is not strictly after the store?

You seem to be discounting the various other things that are allowed to fail a weak CAS. Like interrupts, faults, and "I don't feel like it". You can't tell why the failure happened (in a weak CAS), and therefore cannot make any statements about the ordering of the operation with relation to other operations.

Not that it's relevant, since a failing case makes no atomicity statements. So nothing to prove/disprove.



A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store.

Excellent. Then it synchronizes-with it. Then it is observed as a atomic - not distinguishable from atomic.

Not distinguishable from a load either. A single operation instruction is atomic, period. It is indivisible from itself.



But it is not necessarily before any other stores.

Yes, I realize this detail. But such ordering is not detectable - not distinguishable from those other stores being strictly after or strictly before the failing strong CAS.


Alex

On 30 May 2017, at 16:27, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:



Sent from my iPad

On May 30, 2017, at 2:12 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


On 29 May 2017, at 21:20, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:


On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them

When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.

Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.

If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.

ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.

ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic.

It has, potentially.

Let me recap the diagram I’ve posted before.

A weak CAS:

   store z 0
load z
   store z 2
// skip store z 1

Here the weak CAS managed to execute a load, then observed something it believes to be an interleaving store, and skipped store of 1. Weak CAS does not synchronize-with the store that failed it, so it can be detected to be non-atomic. (Weak CAS is allowed to also fail for other reasons, but that’s not part of the problem)

A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".

But you can't *detect* an interleaving store here. There is nothing that lets you know that there was actually an interleaving store. A failure certainly doesn't tell you that's what happened. The failure could have been caused by something else (spurious) with no store at all. And it could also be caused by a preceding store. No way to tell.

A version of a strong CAS:

   store z 0
load z
   store z 2
// interleaving store triggers retry - ll/sc-based primitive has to ascertain it is not a “spurious” failure
load z
// skip store z 1

Here the strong CAS managed to execute a load, then observed something happened, then loaded again to be sure it was not due to false sharing but a true interleaving store to z. This second load synchronizes-with the store that failed it. This version of strong CAS is no less atomic than a successful CAS - as in “a single entity in the total order of all stores to z”, because it behaves like a CAS that was scheduled strictly after the store that failed it and before any other stores.

You are mixing atomicity of the CAS sub-operations (the indivisibility of the read and the write if the write occurs) with ordering against other operations. Nothing about atomicity implies ordering. And failing CAS is no more or less atomic than a single load operation.

A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store. But it is not necessarily before any other stores. That second part depends on ordering promises and on program order. Nothing to do with atomicity.

A failing strong compareAndSet (e.g. in Java 8) is strictly before any loads and stores that follow it in program order. That's true because of its memory ordering semantics promises. Not because of atomicity.

So my big question is: can a strong CAS detect the presence of an interleaving store without synchronizing-with it? Can it tell it is an interleaving store and not something else, without issuing a load or having effect of such a load?

A successful atomic CAS instruction (weak or strong) guarantees that no interleaving store occurred. That not the same as being able to detect that one occurs.

A CAS can't detect an interleaving store in either case (strong or weak). The reason for failure in weak CAS is "I felt like it", and the reason for failure in strong CAS is "the value in the field did not match the expected value". Both reasons can occur with no interleaving store (e.g. the store could have occurred in the past). Since there is no "interleaving store detection" mechanism to begin with, the rest of the question is therefore not relevant.



Alex

A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.

I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them.


Alex


On 29 May 2017, at 15:42, Gil Tene <gil at azul.com<mailto:gil at azul.com>> wrote:

Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.

With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).

An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.

There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.

E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).

In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.

The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.

Sent from my iPad

On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

I also have this intuition, but this looks like a proof by example, not a specification.

A specification would look something like:
1. CAS executes a volatile load unconditionally.
2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.

In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.

That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).

A strong CAS also has:

3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.

This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)

The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)


Alex


On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.

David


From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 7:43 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)

I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.

Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.

Successful CAS atomic        Successful CAS not atomic
store z 0                    store z 0
CAS z 0 1                    load z
                             store z 1
store z 2                    store z 2

Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.


There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.

Failing CAS atomic intrinsic          Failing CAS not atomic
                             Not detectable    Detectable             Not detectable
store z 0                    store z 0         store z 0              store z 0
store z 2                    store z 2         load z                 load z
CAS z 0 1                    load z              store z 2              store z 2
                                               // store z 1 skipped   // store z 2 triggers retry
                                                                      load z
                                                                      // store z 1 skipped

If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.

I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?


Alex

On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 6:15 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Thanks.

No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.

Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.

Example where you can claim atomicity of a failing CAS:

do{
  tmp = load_linked(z);
} while(tmp == expected && store_conditional(z, updated));

Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.


Alex


On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.

David

From: Alex Otenko [mailto:oleksandr.otenko at gmail.com]
Sent: Monday, May 29, 2017 5:55 PM
To: dholmes at ieee.org<mailto:dholmes at ieee.org>
Cc: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.

The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.

ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.

So I am asking whether the *failing* CAS promises atomicity.


Alex


On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:

Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.

Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.

Unless there are extra volatile loads upon failure of (strong) compareAndSet.

It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.

The gist of atomicity:

int x=0;
volatile int z=0;

Thread 1:
if (! CAS(z, 0, 1)) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;

If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1.

Alex



On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au<mailto:davidcholmes at aapt.net.au>> wrote:

Alex,

I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).

David

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Alex Otenko
Sent: Monday, May 29, 2017 7:40 AM
To: Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>>
Cc: concurrency-interest at cs.oswego.edu<mailto:concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating

Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.


The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.

Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).


It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.

Alex


On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.

This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.

I think the actual relevant spec text is:

1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."

2) "Atomically sets the value to the given updated value if the current value == the expected value."

I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.

The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.


On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
That’s right.

Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).

Alex

On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?

The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.

The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.

On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Not sure what you mean by “acting as a fence” being broken.

There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.


int x=0; // non-volatile
volatile int z=0;
volatile boolean b=false;

Thread1:
if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  }
}
return x;

Thread2:
x=1;
if (!CAS(z, 0, 2)) {
  return b;
}
return true;

In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).

If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.

If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.


Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)


Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.


Alex

On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.

This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.

I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.

On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com<mailto:oleksandr.otenko at gmail.com>> wrote:
Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.

if( ! z.CAS(i, j) ) {
  k = z.get();
  if(k < j) {
    // i < k < j
    // whoever mutated z from i to k, should also negotiate mutation of z from k to j
    // with someone else, and they should observe whatever stores precede z.CAS
    // because I won’t contend.

    // of course, I need to check they are still at it - but that, too, does not require
    // stores or CASes
    ...
    return;
  }
}

If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.


In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?


Alex


On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org<mailto:boehm at acm.org>> wrote:

Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.

So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.

I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.

As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.

Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.

I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.

On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com<mailto:nathanila at gmail.com>> wrote:
> "The memory effects of a write occur regardless of outcome."
> "This method has memory effects of at least one volatile read and write."

I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.

Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?

-Nathan

On 5/26/2017 1:59 PM, Doug Lea wrote:
On 05/26/2017 12:22 PM, Gil Tene wrote:
Actually this is another case where the Java 9 spec needs to be adjusted…
The pre-jdk9 method for weak CAS is now available in four
flavors: weakCompareAndSetPlain, weakCompareAndSet,
weakCompareAndSetAcquire, weakCompareAndSetRelease.
They have different read/write access modes. The specs reflect this.
The one keeping the name weakCompareAndSet is stronger, the others
weaker than before (this is the only naming scheme that works).

About those specs... see JBS JDK-8181104
   https://bugs.openjdk.java.net/browse/JDK-8181104
The plan is for all CAS VarHandle methods to include the sentence
   "The memory effects of a write occur regardless of outcome."
And for j.u.c.atomic methods getAndUpdate, updateAndGet,
getAndAccumulate, accumulateAndGet to include the sentence:
   "This method has memory effects of at least one volatile read and write."

Which should clear up confusion.

-Doug



_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

--
-Nathan


_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest

_______________________________________________
Concurrency-interest mailing list
Concurrency-interest at cs.oswego.edu<mailto:Concurrency-interest at cs.oswego.edu>
http://cs.oswego.edu/mailman/listinfo/concurrency-interest





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/6fd801bc/attachment-0001.html>

From oleksandr.otenko at gmail.com  Tue May 30 12:52:34 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 17:52:34 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <2B18F1A8-A639-45AD-8F96-23D31E426077@azul.com>
References: <2B18F1A8-A639-45AD-8F96-23D31E426077@azul.com>
Message-ID: <9A0129BB-CBD7-4663-88AE-304D1342CC0F@gmail.com>


> On 30 May 2017, at 17:34, Gil Tene <gil at azul.com> wrote:
> 
> 
>> On May 30, 2017, at 9:26 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>> 
>> 
>>> A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".
>> 
>> 
>> Sure. I only took it a bit further, and explored the hypothetical implementation that didn’t fail sc spuriously (suppose, variables are cache-aligned, and no other variables reside on the same cache line, and no other events cause cache invalidation). The weak CAS would then be detectable as non-atomic - you can detect the load is not strictly after the store that failed the CAS. This is essentially what the litmus test for atomicity establishes (see one of previous messages proposing such a test, when we switched to discussing atomicity).
> 
> *How* would you determine that is is not strictly after the store?
> 
> You seem to be discounting the various other things that are allowed to fail a weak CAS. Like interrupts, faults, and "I don't feel like it". You can't tell why the failure happened (in a weak CAS), and therefore cannot make any statements about the ordering of the operation with relation to other operations.
> 
> Not that it's relevant, since a failing case makes no atomicity statements. So nothing to prove/disprove.

The weak one is in the discussion only for the sake of contrast.

The strong one doesn’t explicitly state that atomicity claim is for a successful CAS only. This branch of the discussion started with a claim that it is atomic only if successful. But if the strong CAS always places a load after the store that failed it, then it is atomic.


Here’s how you can determine whether a failing CAS places a load strictly after the store that failed it:

int x=0;
volatile int z=0;

Thread 1:
if ( ! CAS(z, 0, 1) ) {
  return x;
}
return 1;

Thread 2:
x=1;
z=1;


If failing CAS always places a load after the store that failed it, Thread 1 always returns 1.

If you have a weaker notion of CAS, then even if by divine intervention CAS fails in a particular way - the value did match at first, but got modified just before sc started - Thread 1 is still not guaranteed to return 1 - because the weaker CAS does not place load after the store, so no synchronizes-with between the failing CAS and the store that failed it, and no happens-before between the write and read of x.


>> 
>>> A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store.
>> 
>> 
>> Excellent. Then it synchronizes-with it. Then it is observed as a atomic - not distinguishable from atomic.
> 
> Not distinguishable from a load either. A single operation instruction is atomic, period. It is indivisible from itself.

That’s good!

If that statement can be recorded like that in the spec, then I am satisfied.


Alex


> 
>> 
>> 
>>> But it is not necessarily before any other stores.
>> 
>> 
>> Yes, I realize this detail. But such ordering is not detectable - not distinguishable from those other stores being strictly after or strictly before the failing strong CAS.
>> 
>> 
>> Alex
>> 
>>> On 30 May 2017, at 16:27, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>> 
>>> 
>>> 
>>> Sent from my iPad
>>> 
>>> On May 30, 2017, at 2:12 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>> 
>>>> 
>>>>> On 29 May 2017, at 21:20, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>>>> 
>>>>> 
>>>>>> On May 29, 2017, at 11:43 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>> 
>>>>>> 
>>>>>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>>>>>> 
>>>>>>> When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them
>>>>>> 
>>>>>> When you said “no opportunity … to interleave”, you defined a total order: the operations are not allowed to start before something atomic has finished, and something atomic is not allowed to start, if any other operation hasn’t finished - this is equivalent to defining a total order of operations.
>>>>> 
>>>>> Nothing about "any other operation" is implied. Only about operations on the field(s) involved in the atomic operation. That's a key difference, and the reason there is no total order implied or involved here. There is no implied order or relationship whatsoever with operations involving any other fields. So no order of any sort.
>>>>> 
>>>>> If you are referring to some "total order" that only applies to the the field involved in the CAS (and not in relationship to any other operations or fields), I'd buy that a a possible statemewnt. But it is not a very meaningful one because it would be orthogonal to any ordering statements in the rest of the program.
>>>>> 
>>>>>> ll/sc sequence does not create atomicity, that’s a very important point. ll/sc does not *stop* interleavings from happening. ll/sc only *witnesses* whether any interleavings happened. So it is meaningless to say “a successful ll/sc is atomic”.
>>>>> 
>>>>> ll/sc (on a successful sc) is no less atomic with regards to the field involved than a successful CAS is. Successes are always atomic. And failures in both cases are not. A failed CAS performed only one operation (the read), so it has nothing to be atomic.
>>>> 
>>>> It has, potentially.
>>>> 
>>>> Let me recap the diagram I’ve posted before.
>>>> 
>>>> A weak CAS:
>>>> 
>>>>    store z 0
>>>> load z
>>>>    store z 2
>>>> // skip store z 1
>>>> 
>>>> Here the weak CAS managed to execute a load, then observed something it believes to be an interleaving store, and skipped store of 1. Weak CAS does not synchronize-with the store that failed it, so it can be detected to be non-atomic. (Weak CAS is allowed to also fail for other reasons, but that’s not part of the problem)
>>> 
>>> A failing atomic CAS (of any kind) has nothing to be atomic about. So "detecting non-atomic" simply means "it failed".
>>> 
>>> But you can't *detect* an interleaving store here. There is nothing that lets you know that there was actually an interleaving store. A failure certainly doesn't tell you that's what happened. The failure could have been caused by something else (spurious) with no store at all. And it could also be caused by a preceding store. No way to tell.
>>> 
>>>> A version of a strong CAS:
>>>> 
>>>>    store z 0
>>>> load z
>>>>    store z 2
>>>> // interleaving store triggers retry - ll/sc-based primitive has to ascertain it is not a “spurious” failure
>>>> load z
>>>> // skip store z 1
>>>> 
>>>> Here the strong CAS managed to execute a load, then observed something happened, then loaded again to be sure it was not due to false sharing but a true interleaving store to z. This second load synchronizes-with the store that failed it. This version of strong CAS is no less atomic than a successful CAS - as in “a single entity in the total order of all stores to z”, because it behaves like a CAS that was scheduled strictly after the store that failed it and before any other stores.
>>> 
>>> You are mixing atomicity of the CAS sub-operations (the indivisibility of the read and the write if the write occurs) with ordering against other operations. Nothing about atomicity implies ordering. And failing CAS is no more or less atomic than a single load operation.
>>> 
>>> A failing strong CAS instruction on field z is strictly after the store that failed it, just like any load that would observe that store. But it is not necessarily before any other stores. That second part depends on ordering promises and on program order. Nothing to do with atomicity.
>>> 
>>> A failing strong compareAndSet (e.g. in Java 8) is strictly before any loads and stores that follow it in program order. That's true because of its memory ordering semantics promises. Not because of atomicity.
>>> 
>>>> So my big question is: can a strong CAS detect the presence of an interleaving store without synchronizing-with it? Can it tell it is an interleaving store and not something else, without issuing a load or having effect of such a load?
>>> 
>>> A successful atomic CAS instruction (weak or strong) guarantees that no interleaving store occurred. That not the same as being able to detect that one occurs.
>>> 
>>> A CAS can't detect an interleaving store in either case (strong or weak). The reason for failure in weak CAS is "I felt like it", and the reason for failure in strong CAS is "the value in the field did not match the expected value". Both reasons can occur with no interleaving store (e.g. the store could have occurred in the past). Since there is no "interleaving store detection" mechanism to begin with, the rest of the question is therefore not relevant.
>>> 
>>>> 
>>>> 
>>>> Alex
>>>> 
>>>>> A successful sc ensures no "witnessing" of interleaving occurred, just like a successful CAS does. The (additional potential) causes of failure [where no atomicity is provided] may vary between ll/sc, strong CAS, and weak CAS, but the knowledge upon success is the same. Success is atomic.
>>>>> 
>>>>> I have previously worked on a weakly ordered architecture that implemented an atomic but completely unordered CAS instruction. That implementation, being weakly ordered, simply froze the L1 cache coherence protocol for the duration of the atomic operation after establishing the cache line exclusive in L1. By ensuring the protocol could not proceed with respect to the field involved, it trivially ensured atomicity without making any ordering requirements about nay other operations. Ordering was controlled separately, with explicit fences for combinations of ldld, ldst, stst, and stld. Any amount of reordering was allowed if fences were not there to prevent it, so a CAS was not guaranteed to be ordered against any other operations unless one or more of those fences actually existed in the instruction flow between them. 
>>>>> 
>>>>>> 
>>>>>> Alex
>>>>>> 
>>>>>> 
>>>>>>> On 29 May 2017, at 15:42, Gil Tene <gil at azul.com <mailto:gil at azul.com>> wrote:
>>>>>>> 
>>>>>>> Atomicity has nothing to do with order. Atomicity only applies to the locations it refers to (e.g. a field, a cache line, a set of fields or cache lines [with HTM for example]), and it either is or isn't. When a set of accesses is atomic, they appear to happen instantaneously, with no opportunity for any external observer or mutator to interleave within them. This has absolutely nothing to do with the order in which those accesses appear in relation to accesses (by this thread or others) to values that are not included in the atomic operation.
>>>>>>> 
>>>>>>> With no relation to atomicity (there are plenty of ways to perform non-atomic CAS), a "weak" CAS means that the store to the field will occur only if the value observed in the field is equal to the expected value. A "strong" CAS means that the store to the field will occur if and only if the value observed in the field is equal to the expected value. Neither of those descriptions have anything to do with atomicity. The difference between them is that a strong CAS must write to the field if it observes the right value in the field, while a weak CAS may spuriously decide not to write (no IFF requirement).
>>>>>>> 
>>>>>>> An atomic CAS (weak or strong) simply makes the observation and write (if the write happens) occur atomically. The atomicity property prevents external interference in the sequence. Nothing else. Atomicity does not affect the weak/strong part (a weak CAS may still fail spuriously, even without external interference with the observed value). Atomicity has no implications on the memory ordering semantics of the operations in the sequence with respect to location not covered by the atomicity property, and other than the atomicity property, it makes no claims about memory ordering with respect to other threads.
>>>>>>> 
>>>>>>> There are plenty of atomic but non-ordered CAS implementations out there. Including some hardware CAS instruction implementations, as well as the hardware instruction combinations commonly used to construct a CAS operation on some architectures.
>>>>>>> 
>>>>>>> E.g. a ll/sc sequence where the sc was successful guarantees atomicity for the combination of the ll and sc operations performed on the same memory location. This primitive can be used to construct a weak CAS directly, and typically requires a loop to construct a strong CAS (since many things, including interrupts, can cause spurious failures). A ll/sc does not in itself imply ordering against accesses to other memory locations (unless the specific architecture defines it that way).
>>>>>>> 
>>>>>>> In Java, compareAndSet has been previously defined to to mean a strong (non-spuriously-failing) CAS with unconditional memory ordering semantics of a volatile read and a volatile write. weakCompareAndSet was previously defined as a weak (may spuriously fail) CAS with no implied memory ordering semantics. Both are atomic.
>>>>>>> 
>>>>>>> The recent discussion here is focused on whether a relaxing of the memory ordering semantics of compareAndSet, from the volatile write semantics being unconditional to being conditional (on the write actually occurring) is advisable. The claim is that there is existing Java software out there that may rely on the existing unconditional definition for correctness, and that relaxing the definition will break such software. Examples of how the conditional/unconditional behavior difference can be observed by a concurrent algorithm were given (I believe) as proof that such software can (and likely does) exist.
>>>>>>> 
>>>>>>> Sent from my iPad
>>>>>>> 
>>>>>>> On May 29, 2017, at 4:39 AM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>> 
>>>>>>>> I also have this intuition, but this looks like a proof by example, not a specification.
>>>>>>>> 
>>>>>>>> A specification would look something like:
>>>>>>>> 1. CAS executes a volatile load unconditionally.
>>>>>>>> 2. CAS executes a volatile store conditionally. The store is added to the total order of all operations if and only if the value loaded is equal to the expected value, and no other store appears in the total order of accesses to the same volatile variable after the load and before the volatile store.
>>>>>>>> 
>>>>>>>> In this way CAS store is not atomic - the correct description is closer to “*exclusive* with other stores”.
>>>>>>>> 
>>>>>>>> That is a weak CAS. It does not say anything about when it fails, so is allowed to fail at will (spuriously fail).
>>>>>>>> 
>>>>>>>> A strong CAS also has:
>>>>>>>> 
>>>>>>>> 3. If there are no volatile stores to the variable after the load in step 1, the volatile store is always executed.
>>>>>>>> 
>>>>>>>> This makes the CAS store “*mutually* exclusive with other strong CASes”. (Still, “atomic” is a wrong term.)
>>>>>>>> 
>>>>>>>> The question then is - in order to fail, it has to observe a volatile store; is it able to ascertain the presence of volatile stores to the variable without establishing a synchronizes-with relationship to such a store? It does not seem possible, and atomicity of the failing strong CAS follows. (That is, non-atomicity of implementation is not observable.)
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Alex
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> On 29 May 2017, at 12:10, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>> 
>>>>>>>>> The atomicity property of CAS ensures that the value being CAS’d updates in the manner proscribed by the application logic. If I want all threads to get a unique Id they can CAS a global “int id” and always increment the value. The atomicity of CAS ensures no two threads get the same Id and that there are no gaps in the assigned id values. The CAS may be the only means by which the variable is accessed so no other stores even enter into the picture.
>>>>>>>>>  
>>>>>>>>> David
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>>>>>> Sent: Monday, May 29, 2017 7:43 PM
>>>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>  
>>>>>>>>> Sorry, but I don’t see how you separate synchronization properties of CAS and atomicity :-)
>>>>>>>>>  
>>>>>>>>> I don’t see how you could describe atomicity without specifying the place of CAS with respect to the other stores. Once you placed it somewhere among the other stores, it synchronizes-with those preceding it.
>>>>>>>>>  
>>>>>>>>> Now, atomicity of a succeeding CAS is not falsifiable. It can just as well be non-atomic, and succeed, if the other stores were ordered in the same way. There is no meaning whatsoever in declaring a succeeding CAS atomic.
>>>>>>>>>  
>>>>>>>>> Successful CAS atomic        Successful CAS not atomic
>>>>>>>>> store z 0                    store z 0
>>>>>>>>> CAS z 0 1                    load z
>>>>>>>>>                              store z 1
>>>>>>>>> store z 2                    store z 2
>>>>>>>>>  
>>>>>>>>> Can you detect the effects of a successful CAS being not atomic? What does atomicity of a successful CAS promise? I see nothing.
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> There is a difference between atomic and non-atomic failing CAS - that’s where it makes sense to specify whether it is atomic or not.
>>>>>>>>>  
>>>>>>>>> Failing CAS atomic intrinsic          Failing CAS not atomic
>>>>>>>>>                              Not detectable    Detectable             Not detectable
>>>>>>>>> store z 0                    store z 0         store z 0              store z 0
>>>>>>>>> store z 2                    store z 2         load z                 load z
>>>>>>>>> CAS z 0 1                    load z              store z 2              store z 2
>>>>>>>>>                                                // store z 1 skipped   // store z 2 triggers retry
>>>>>>>>>                                                                       load z
>>>>>>>>>                                                                       // store z 1 skipped
>>>>>>>>>  
>>>>>>>>> If non-atomicity of a failing CAS can be detected, it becomes even closer to weakCompareAndSet, which fails spuriously, and is a concern. On the other hand, it may just as well promise atomicity even of a failing CAS, because it needs to distinguish a spurious failure of the underlying ll/sc primitive, and the procedure for distinguishing that possibly necessarily establishes the synchronizes-with edge with the store that failed it.
>>>>>>>>>  
>>>>>>>>> I don’t see all ends, so maybe someone wants to not promise atomicity of the failing strong CAS. But in that case there is no need to promise atomicity at all, because the promise of atomicity of a succeeding CAS gives you nothing. Unless you can show how a non-atomic successful CAS could be detected?
>>>>>>>>>  
>>>>>>>>>  
>>>>>>>>> Alex
>>>>>>>>>  
>>>>>>>>>> On 29 May 2017, at 09:31, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>  
>>>>>>>>>> Sorry but I don’t see what you describe as atomicity. The atomicity of a successful CAS is the only atomicity the API is concerned about. The memory synchronization properties of CAS are distinct from its atomicity property.
>>>>>>>>>>  
>>>>>>>>>> David
>>>>>>>>>>  
>>>>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>>>>> Sent: Monday, May 29, 2017 6:15 PM
>>>>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>>  
>>>>>>>>>> Thanks.
>>>>>>>>>>  
>>>>>>>>>> No, I am not concerned about the atomicity of hardware instructions. I am concerned about atomicity as the property of the memory model.
>>>>>>>>>>  
>>>>>>>>>> Claiming atomicity of a successful CAS is pointless. If CAS is not atomic on failure, then there is no need to claim it is atomic at all.
>>>>>>>>>>  
>>>>>>>>>> Example where you can claim atomicity of a failing CAS:
>>>>>>>>>>  
>>>>>>>>>> do{
>>>>>>>>>>   tmp = load_linked(z);
>>>>>>>>>> } while(tmp == expected && store_conditional(z, updated));
>>>>>>>>>>  
>>>>>>>>>> Here if store_conditional fails, it is followed by another volatile load, so the construct will synchronize-with the write that failed it, and it will appear atomic to the observer.
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>> Alex
>>>>>>>>>>  
>>>>>>>>>>  
>>>>>>>>>>> On 29 May 2017, at 09:03, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>>  
>>>>>>>>>>> Sorry Alex but you are using “atomicity” in a way that doesn’t make sense to me. The only thing that is atomic is the successful CAS. I see what you are trying to say about a failing ll/sc CAS and the write that caused it to fail, but that is not “atomicity” to me – at least from the API perspective. You seem to be concerned about the atomicity of a sequence of hardware instructions. The API doesn’t tell you anything about how the implementation is done, only that the result of a successful operation is atomic with respect to any other update of the variable.
>>>>>>>>>>>  
>>>>>>>>>>> David
>>>>>>>>>>>  
>>>>>>>>>>> From: Alex Otenko [mailto:oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>] 
>>>>>>>>>>> Sent: Monday, May 29, 2017 5:55 PM
>>>>>>>>>>> To: dholmes at ieee.org <mailto:dholmes at ieee.org>
>>>>>>>>>>> Cc: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>; concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>>>  
>>>>>>>>>>> This came out a bit garbled. So, here it goes a bit clearer why the spec and the “ubiquitous terminology” are not enough, perhaps.
>>>>>>>>>>>  
>>>>>>>>>>> The claim of “atomicity” for succeeding CAS is not interesting, because it is not falsifiable: if CAS succeeded, it is evidence in itself that no volatile write appeared between the read and write parts of CAS, not evidence of atomicity as the property of the construct. We cannot explain atomicity of CAS by giving the specification of effects of the successful CAS. But Javadocs does just that, and *only* that.
>>>>>>>>>>>  
>>>>>>>>>>> ll/sc as a construct does not synchronize-with the write failing the sc instruction. So if CAS that uses ll/sc does not make efforts to synchronize-with that write, we can detect it is not atomic - we can detect that it cannot be seen as an operation that appeared entirely before or after all stores to the same variable.
>>>>>>>>>>>  
>>>>>>>>>>> So I am asking whether the *failing* CAS promises atomicity.
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>> Alex
>>>>>>>>>>>  
>>>>>>>>>>>  
>>>>>>>>>>>> On 29 May 2017, at 00:26, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>  
>>>>>>>>>>>> Yeah, I know what atomicity means in x86. But since the “write semantics” of the CAS are questioned, I have to also ask whether the other formulations are precise enough.
>>>>>>>>>>>>  
>>>>>>>>>>>> Atomicity means “indivisible”. It means that it either appears before a store, or after a store. If it appears after the store, then it synchronizes-with that store, and I am bound to observe stores preceding it. But not so in the weaker semantics Hans talks about! If the failure occurs during the sc part, you have to assume the load is before that store (but why does it fail then), or you have to assume it overlaps with a concurrent store. Either way, the core function is *not* atomic.
>>>>>>>>>>>>  
>>>>>>>>>>>> Unless there are extra volatile loads upon failure of (strong) compareAndSet.
>>>>>>>>>>>>  
>>>>>>>>>>>> It’s not just the “no intervening store”, meaning “if it’s stored, the condition expected=actual was not violated by any other store”.
>>>>>>>>>>>>  
>>>>>>>>>>>> The gist of atomicity:
>>>>>>>>>>>>  
>>>>>>>>>>>> int x=0;
>>>>>>>>>>>> volatile int z=0;
>>>>>>>>>>>>  
>>>>>>>>>>>> Thread 1:
>>>>>>>>>>>> if (! CAS(z, 0, 1)) {
>>>>>>>>>>>>   return x;
>>>>>>>>>>>> }
>>>>>>>>>>>> return 1;
>>>>>>>>>>>>  
>>>>>>>>>>>> Thread 2:
>>>>>>>>>>>> x=1;
>>>>>>>>>>>> z=1;
>>>>>>>>>>>>  
>>>>>>>>>>>> If CAS is atomic, failing CAS synchronizes-with the volatile write that fails it, and Thread 1 will always return 1. 
>>>>>>>>>>>>  
>>>>>>>>>>>> Alex
>>>>>>>>>>>>  
>>>>>>>>>>>>  
>>>>>>>>>>>>  
>>>>>>>>>>>>> On 28 May 2017, at 23:52, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au>> wrote:
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Alex,
>>>>>>>>>>>>>  
>>>>>>>>>>>>> I don’t recall anyone ever questioning what the atomic means in these atomic operations – it is ubiquitous terminology. If the store happens it is because the current value was the expected value. That is indivisible ie atomic. There can be no intervening store. This is either the semantics of the hardware instruction (e.g. cmpxchg) or else must be emulated using whatever is available e.g. ll/sc instructions (where an intervening store, in the strong CAS, must cause a retry).
>>>>>>>>>>>>>  
>>>>>>>>>>>>> David
>>>>>>>>>>>>>  
>>>>>>>>>>>>> From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu>] On Behalf Of Alex Otenko
>>>>>>>>>>>>> Sent: Monday, May 29, 2017 7:40 AM
>>>>>>>>>>>>> To: Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>>
>>>>>>>>>>>>> Cc: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>> Subject: Re: [concurrency-interest] AtomicReference.updateAndGet() mandatory updating
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Yes, you could read it both ways. You see, lock-based implementations and x86 LOCK:CMPXCHG semantics inspire to interpret the statement such that there is at least some write-like semantics (hence “memory *effects*”) - not necessarily a write to z, but fences or whatever that imitates a volatile write to z from JMM.
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> The other source of confusion is the claim of atomicity. Is it “atomically (sets the value) (to the given updated value if the current value = the expected value)” or “atomically (sets the value to the given updated value if the current value == the expected value)”? Does atomicity imply it is a single item in total order of all operations? Or all stores? Or just stores to that variable? If you know how it’s implemented, it turns out it is far from atomic.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Does it at least *implement* atomic behaviour, does it *appear* atomic to an observer? For example, if a concurrent store appears between the load and “the store”  (in quotes, because it may not be executed - so in that case it is no longer “between”), do we get synchronizes-with edge with the store that preceded the load, or also the store that intervened? If we don’t get synchronizes-with edge to the store that intervened (which I suspect it doesn’t), then it is not atomic in any of those senses (but x86 and lock-based implementations create false analogies, so we get “atomic” in the method description).
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>> It needs to be specced out, best of all formally in JMM as the source of authority, rather than higher-level API javadocs, spread all over the place.
>>>>>>>>>>>>>  
>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>  
>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On 28 May 2017, at 18:30, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> Thanks. I think I understand now. If Thread 2 returns false, the Thread 2 CAS failed, and the initial CAS in Thread 1 succeeds. Either x immediately reads back as 1 in Thread 1, or we set b to true after Thread 2 returns b. Thus the second (successful) CAS in Thread 1 must follow the unsuccessful Thread 2 CAS in synchronization order. So any write to z by the failed CAS synchronizes with the second successful CAS in Thread 1, and we could thus conclude that x is 1 in the Thread 1 return.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> This relies critically on the assumption that the Thread 2 failed CAS has the semantics of a volatile write to z.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I think the actual relevant spec text is:
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> 1) "compareAndSet and all other read-and-update operations such as getAndIncrement have the memory effects of both reading and writing volatile variables."
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> 2) "Atomically sets the value to the given updated value if the current value == the expected value."
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> I would not read this as guaranteeing that property. But I agree the spec doesn't make much sense; I read (2) as saying there is no write at all if the CAS fails, as I would expect. Thus it seems like a stretch to assume that the write from (1) is to z, though I have no idea what write it would refer to.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> The prior implementation discussion now does make sense to me. I don't think this is an issue for lock-based implementations. But the only reasonable way to support it on ARMv8 seems to be with a conditionally executed fence in the failing case. That adds two instructions, as well as a large amount of time overhead for algorithms that don't retry on a strong CAS. My impression is that those algorithms are frequent enough to be a concern.
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>  
>>>>>>>>>>>>>> On Sat, May 27, 2017 at 4:49 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>> That’s right.
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Atomicity (for some definition of atomicity - ie atomic with respect to which operations) is not needed here. As long as the store in CAS occurs always, x=1 is not “reordered” (certainly, not entirely - can’t escape the “store” that is declared in the spec).
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On 28 May 2017, at 00:43, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> I gather the interesting scenario here is the one in which the Thread 2 CAS fails and Thread 2 returns false, while the initial Thread 1 CAS succeeds?
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> The correctness argument here relies on the fact that the load of x in Thread 1 must, in this scenario, see the store of x in Thread 2? This assumes the load of z in the failing CAS in Thread 2 can't be reordered with the ordinary (and racey!) store to x by the same thread. I agree that the j.u.c.atomic spec was not clear in this respect, but I don't think it was ever the intent to guarantee that. It's certainly false for either a lock-based or ARMv8 implementation of CAS. Requiring it would raise serious questions about practical implementability on several architectures.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> The C++ standard is quite clear that this is not required; atomicity means only that the load of a RMW operation sees the immediately prior write in the coherence order for that location. It doesn't guarantee anything about other accesses somehow appearing to be performed in the middle of the operation. It's completely analogous to the kind of atomicity you get in a lock-based implementation.
>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>> On Sat, May 27, 2017 at 3:26 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>>>> Not sure what you mean by “acting as a fence” being broken.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> There’s probably even more code that relies on atomicity of CAS - that is, when the write happened on successful CAS, it happened atomically with the read; it constitutes a single operation in the total order of all volatile stores.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> int x=0; // non-volatile
>>>>>>>>>>>>>>>>> volatile int z=0;
>>>>>>>>>>>>>>>>> volatile boolean b=false;
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Thread1:
>>>>>>>>>>>>>>>>> if (CAS(z, 0, 1)) {
>>>>>>>>>>>>>>>>>   if (x == 0) {
>>>>>>>>>>>>>>>>>     b=true;
>>>>>>>>>>>>>>>>>     CAS(z, 1, 2);
>>>>>>>>>>>>>>>>>   }
>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>> return x;
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Thread2:
>>>>>>>>>>>>>>>>> x=1;
>>>>>>>>>>>>>>>>> if (!CAS(z, 0, 2)) {
>>>>>>>>>>>>>>>>>   return b;
>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>> return true;
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> In essence, if CAS failure is caused by a real mismatch of z (not a spurious failure), then we can guarantee there is a return 1 or a further CAS in the future from the point of the first successful CAS (by program order), and we can get a witness b whether that CAS is in the future from the point of the failing CAS (by total order of operations).
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> If failing CAS in Thread2 does not have store semantics, then nothing in Thread1 synchronizes-with it, and Thread1 is not guaranteed to return 1 even if Thread2 returns false.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> If failing CAS in Thread2 does have store semantics, then if Thread2 returns false, Thread1 returns 1.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Not sure what you mean by “real programming concerns”. It sounds a bit like “true Scotsman”. The concern I am trying to convey, is that Java 8 semantics offer a very strong CAS that can be used to enforce mutual exclusion using a single CAS call, and that this can be combined with inductive types to produce strong guarantees of correctness. Having set the field right, I can make sure most contenders execute less than a single CAS after mutation. Sounds real enough concern to me :)
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Anyhow, I also appreciate that most designs do not look that deep into the spec, and won’t notice the meaning getting closer to the actual hardware trends. If Java 8 CAS semantics gets deprecated, the algorithm will become obsolete, and will need modification with extra fences in the proprietary code that needs it, or whatever is not broken in the new JMM that will lay the memory semantics of CAS to rest.
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> On 27 May 2017, at 18:34, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> This still makes no sense to me. Nobody is suggesting that we remove the volatile read guarantee on failure (unlike the weak... version). If the CAS fails, you are guaranteed to see memory affects that happen before the successful change to z. We're talking about the "volatile write semantics" for the write that didn't happen.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> This would all be much easier if we had a litmus test (including code snippets for all involved threads) that could distinguish between the two behaviors. I conjecture that all such tests involve potentially infinite loops, and that none of them reflect real programming concerns.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> I also conjecture that there exists real code that relies on CAS acting as a fence. We should be crystal clear that such code is broken.
>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>> On Fri, May 26, 2017 at 11:42 PM, Alex Otenko <oleksandr.otenko at gmail.com <mailto:oleksandr.otenko at gmail.com>> wrote:
>>>>>>>>>>>>>>>>>>> Integers provide extra structure to plain boolean “failed/succeeded”. Linked data structures with extra dependencies of their contents can also offer extra structure.
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>> if( ! z.CAS(i, j) ) {
>>>>>>>>>>>>>>>>>>>   k = z.get();
>>>>>>>>>>>>>>>>>>>   if(k < j) {
>>>>>>>>>>>>>>>>>>>     // i < k < j
>>>>>>>>>>>>>>>>>>>     // whoever mutated z from i to k, should also negotiate mutation of z from k to j
>>>>>>>>>>>>>>>>>>>     // with someone else, and they should observe whatever stores precede z.CAS
>>>>>>>>>>>>>>>>>>>     // because I won’t contend.
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>     // of course, I need to check they are still at it - but that, too, does not require
>>>>>>>>>>>>>>>>>>>     // stores or CASes
>>>>>>>>>>>>>>>>>>>     ...
>>>>>>>>>>>>>>>>>>>     return;
>>>>>>>>>>>>>>>>>>>   }
>>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>> If whoever mutated z from i to k cannot observe stores that precede z.CAS, they won’t attempt to mutate z to j.
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>> In return can someone explain what the difference is between a weakCompareAndSet failing spuriously and compareAndSet not guaranteeing volatile store semantics on fail? Why should we weaken the promise, if there is already a weak promise to not guarantee visibility on fail?
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>> Alex
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> On 26 May 2017, at 22:35, Hans Boehm <boehm at acm.org <mailto:boehm at acm.org>> wrote:
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> Could we please get an example (i.e. litmus test) of how the "memory effect of at least one volatile ... write" is visible, and where it's useful? Since some people seem really attached to it, it shouldn't be that hard to generate a litmus test.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> So far we have a claim that it could affect progress guarantees, i.e. whether prior writes eventually become visible without further synchronization. I kind of, sort of, half-way believe that.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> I haven't been able to make sense out of the subsequent illustration attempts. I really don't think it makes sense to require such weird behavior unless we can at least clearly define exactly what the weird behavior buys us. We really need a concise, or at least precise and understandable, rationale.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> As has been pointed out before, a volatile write W by T1 to x of the same value that was there before is not easily observable. If I read that value in another thread T2, I can't tell which write I'm seeing, and hence hence a failure to see prior T1 writes is OK; I might have not seen the final write to x. Thus I would need to communicate the  fact that T1 completed W without actually looking at x. That seems to involve another synchronization of T1 with T2, which by itself would ensure the visibility of prior writes to T2.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> Thus, aside from possible really obscure progress/liveness issues, I really don't see the difference. I think this requirement, if it is indeed not vacuous and completely ignorable, would lengthen the ARMv8 code sequence for a CAS by at least 2 instructions, and introduce a very obscure divergence from C and C++.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> I'm worried that we're adding something to make RMW operations behave more like fences. They don't, they can't, and they shouldn't.
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> On Fri, May 26, 2017 at 1:08 PM, Nathan and Ila Reynolds <nathanila at gmail.com <mailto:nathanila at gmail.com>> wrote:
>>>>>>>>>>>>>>>>>>>>> > "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>>>>>> > "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> I am not sure what memory effects means.  If this is defined somewhere in the specs, then ignore this since I haven't read JDK 9 specs.
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> Does memory effects mean the cache line will be switched into the modified state even if an actual write doesn't occur?  Or does memory effects have to do with ordering of memory operations with respect to the method's operation?
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> On 5/26/2017 1:59 PM, Doug Lea wrote:
>>>>>>>>>>>>>>>>>>>>>> On 05/26/2017 12:22 PM, Gil Tene wrote:
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>>> Actually this is another case where the Java 9 spec needs to be adjusted…
>>>>>>>>>>>>>>>>>>>>>> The pre-jdk9 method for weak CAS is now available in four
>>>>>>>>>>>>>>>>>>>>>> flavors: weakCompareAndSetPlain, weakCompareAndSet,
>>>>>>>>>>>>>>>>>>>>>> weakCompareAndSetAcquire, weakCompareAndSetRelease.
>>>>>>>>>>>>>>>>>>>>>> They have different read/write access modes. The specs reflect this.
>>>>>>>>>>>>>>>>>>>>>> The one keeping the name weakCompareAndSet is stronger, the others
>>>>>>>>>>>>>>>>>>>>>> weaker than before (this is the only naming scheme that works).
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> About those specs... see JBS JDK-8181104
>>>>>>>>>>>>>>>>>>>>>>    https://bugs.openjdk.java.net/browse/JDK-8181104 <https://bugs.openjdk.java.net/browse/JDK-8181104>
>>>>>>>>>>>>>>>>>>>>>> The plan is for all CAS VarHandle methods to include the sentence
>>>>>>>>>>>>>>>>>>>>>>    "The memory effects of a write occur regardless of outcome."
>>>>>>>>>>>>>>>>>>>>>> And for j.u.c.atomic methods getAndUpdate, updateAndGet,
>>>>>>>>>>>>>>>>>>>>>> getAndAccumulate, accumulateAndGet to include the sentence:
>>>>>>>>>>>>>>>>>>>>>>    "This method has memory effects of at least one volatile read and write."
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> Which should clear up confusion.
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> -Doug
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest> 
>>>>>>>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>>>>>>>> -Nathan
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>>>>>>>>>>>>>>  
>>>>>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>>>>>> Concurrency-interest mailing list
>>>>>>>>>>>>>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>>>>>>>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>>>> _______________________________________________
>>>>>>>> Concurrency-interest mailing list
>>>>>>>> Concurrency-interest at cs.oswego.edu <mailto:Concurrency-interest at cs.oswego.edu>
>>>>>>>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>>>>>> 
>>>>> 
>>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/4ebd7315/attachment-0001.html>

From jsampson at guidewire.com  Tue May 30 12:57:28 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Tue, 30 May 2017 16:57:28 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <6B230B20-FFB4-49C7-865F-0926F306D6DD@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>
 <6B230B20-FFB4-49C7-865F-0926F306D6DD@gmail.com>
Message-ID: <C3ACE72E-44EB-4F52-A1B8-6EFD9EE0C205@guidewire.com>

Non-volatile reads can be reordered. There's no happens-before relation between the write and either of those reads, so it doesn't contradict happens-before consistency for the second read to not see the write. What part of the JMM says otherwise?

Thanks,
Justin


On 5/30/17, 1:42 AM, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:

    Racy reads can’t observe just any writes, only those that won’t contradict the happens-before partial order.
    
    So you still need a write of 0 that you can place after the write of 1 in Thread 1. The initial write of 0 can’t be observed after any write observed after Thread 1 start.
    
    
    Alex
    
    > On 30 May 2017, at 08:47, Justin Sampson <jsampson at guidewire.com> wrote:
    > 
    > Alex Otenko wrote:
    > 
    >> int x=0; // non-volatile
    >> volatile int z=0;
    >> volatile boolean b=false;
    >> 
    >> Thread1:
    >> if (CAS(z, 0, 1)) {
    >>   if (x == 0) {
    >>     b=true;
    >>     CAS(z, 1, 2);
    >>   }
    >> }
    >> return x;
    >> 
    >> Thread2:
    >> x=1;
    >> if (!CAS(z, 0, 2)) {
    >>   return b;
    >> }
    >> return true;
    > 
    > I keep going over this code in my head. The data race is tricky.
    > 
    > In particular, the conclusion that "if Thread2 returns false then Thread1 returns 1" seems to rely on an assumption that if the read of x in "x == 0" sees 1 then the read of x in "return x" will also see 1. What part of the JMM justifies that assumption? Both reads are racy, _unless_ the first read does _not_ see 1. If the first read _does_ see 1, then the second read is still racy and it's possible for it to see 0. Non-volatile reads can be reordered freely, can't they?
    > 
    > Cheers,
    > Justin
    > 
    > 
    
    


From aph at redhat.com  Tue May 30 13:10:18 2017
From: aph at redhat.com (Andrew Haley)
Date: Tue, 30 May 2017 18:10:18 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <8E74BB09-BBB1-429E-8592-0CDDF6A8708B@cox.net>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu> <R39P1v04C02hR0p0139WM5>
 <54922133-4757-4A75-BA34-2FC3E611810C@cox.net> <S84g1v00B0dAWJx0184ht0>
 <8E74BB09-BBB1-429E-8592-0CDDF6A8708B@cox.net>
Message-ID: <0ff8ff02-837a-379c-74c8-dc11aadcf222@redhat.com>

On 30/05/17 17:31, Gregg Wonderly wrote:
> 
>> On May 29, 2017, at 3:04 AM, Andrew Haley <aph at redhat.com> wrote:
>>
>> On 28/05/17 02:27, Gregg Wonderly wrote:
>>>
>>>> On May 26, 2017, at 10:05 AM, Andrew Haley <aph at redhat.com> wrote:
>>>>
>>>> On 26/05/17 14:56, Doug Lea wrote:
>>>>
>>>>> "As well as possible" may be just to unconditionally issue fence,
>>>>> at least for plain CAS; maybe differently for the variants.
>>>>
>>>> I doubt that: I've done some measurements, and it always pays to branch
>>>> conditionally around a fence if it's not needed.
>>>
>>> Since the fence is part of the happens before controls that
>>> developers encounter, how can a library routine know what the
>>> developer needs, to know how to “randomly” optimize with a branch
>>> around the fence?  Are you aware of no software that exists where
>>> developers are actively counting MM interactions trying to minimize
>>> them?  Here you are trying to do it yourself because you “See” an
>>> optimization that is so localized, away from any explicit code
>>> intent, that you can’t tell ahead of time (during development of
>>> your optimization), what other developers have actually done around
>>> the fact that this fence was unconditional before right?
>>>
>>> Help me understand how you know that no software that works
>>> correctly now, will start working randomly, incorrectly, because
>>> sometimes the fence never happens.
>>
>> It's in the specification.  If a fence is required by the
>> specification, we must execute one. If not, the question is whether
>> it's faster to execute a fence unconditionally or to branch around
>> it.
> 
> But that’s not my point.  My point is that once there is a fence,
> and since now developers are having to program according to “fences”
> explicit or implicit in the API implementation, you are going to
> find developers counting and demanding specific fences to be in
> specific places, because they create happens before events which are
> precisely what developers must manage.  And, just like you are
> adamant that performance can be improved by not always providing
> this fence, developers and engineers are trying to do exactly the
> same thing by looking at the complete picture of their application
> (which you have no view into from the point of this optimization).

I will always meet the specification as well as I can.  That involves
generating whatever code is necessary, but no more.

> They are saying to themselves, hey, theirs a write fence in this
> API, so if we use that to, for example assign a value via CAS, as a
> work item counter, then we don’t have to worry about all the other
> state before that, it will be visible.

There isn't a write fence in this API: there is only the rule that we
always have a volatile read and a volatile write.  (Although I'm not
entirely sure that there even is that, given the way the specification
has always been worded.)

> As soon as you take out the fence, they now have to put in
> synchronization themselves,

No they don't, because if the CAS succeeds we have a volatile write
anyway.  The fence is only proposed for the case when the CAS fails.

> Would you be happy to break their code with an optimization that is
> awesome for super racy code, but can break code that is not super
> racy and ends up with a 1 in 10000 event failure mode that no-one
> can figure out?

I'm doing no such thing: I'm saying that because there is a volatile
store on CAS success we don't need an unconditional fence as well.
That's all.

-- 
Andrew Haley
Java Platform Lead Engineer
Red Hat UK Ltd. <https://www.redhat.com>
EAC8 43EB D3EF DB98 CC77 2FAD A5CD 6035 332F A671

From boehm at acm.org  Tue May 30 14:23:32 2017
From: boehm at acm.org (Hans Boehm)
Date: Tue, 30 May 2017 11:23:32 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
Message-ID: <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>

The memory model does not define "the memory consistency effects of a
write". It only defines the effect of a volatile write to a specific field;
the "memory consistency effects" depend entirely on the location being
written. The problem here is that there normally is no write to associate
the "memory consistency effect" with.

I think the question essentially comes down to which of the following are
performed atomically by a CAS:

(CAS classic:)
old = x;
if (old == expected) {
    x = new; return true;
} else {
    return false;
}

or

(CAS revised:)
old = x;
x = (old == expected ? new : x);
return old == expected;

>From my perspective, there are many architectures that matter, but the two
I expect to be the most widely used with the Java language in the
appropriate time frame are x86 and ARMv8.  (Depending on your metric,
perhaps in the other order.) ARMv8 CAS will use LDAX/STRX rather than
fences. I expect Android's Java language runtime to generate fences (mostly
DMB ISHST) essentially only at the end of constructors, though we're not
quite there yet.

I'm not convinced this decision matters significantly in terms of
programmability. Alex convinced me that it is, unfortunately, observable,
because there are examples in which you can deduce that code is  after a
failed CAS. There may be code that relies on it, but I've never personally
seen such code in production.

On x86, I think this decision doesn't matter for performance; the
implementation is the same either way, and "CAS revised" won't really write
to x in the failure case.

On ARMv8, it does matter. I think Andrew is right that we can replace the
actual assignment on failure with a conditionally executed fence on failure
to avoid adding contention on failure. (This is another case in which a
more careful correctness argument is clearly called for.) But I believe
that requires an additional branch and a fence, making it less attractive
to inline the CAS. And certainly it slows down the failure path when the
LDAX reads the wrong value, and the release operation would normally be
omitted. In the absence of contention, I'd expect the slowdown for the
failure path to be roughly a factor of two now, and perhaps more as the
implementations evolve.

C++ clearly specifies "CAS classic". There is no way to specify release
semantics for a failed CAS, since there is no write.

On Tue, May 30, 2017 at 7:06 AM, Doug Lea <dl at cs.oswego.edu> wrote:

>
> Catching up...
>
> On 05/26/2017 04:08 PM, Nathan and Ila Reynolds wrote:
> >> "The memory effects of a write occur regardless of outcome."
> >> "This method has memory effects of at least one volatile read and
> write."
> >
> > I am not sure what memory effects means.  If this is defined somewhere
> > in the specs, then ignore this since I haven't read JDK 9 specs.
>
> Thanks; it would be better to say:
> "The memory consistency effects of a write occur regardless of outcome."
>
> About the controversy surrounding ARM mappings for Volatile-mode CAS:
> The main underlying intent is to ensure that Volatile mode operations
> act atomically and as if globally totally ordered wrt each other.
> With single instruction CAS (as on x86 etc), this is easy to arrange.
> Plus there are cases like CAS of thread-confined variables in which,
> in principle they could be optimized to conditional stores; plus other
> similar weakenings. In the absence of weakening, when emulated using
> ARM/POWER LL/SC, this further interacts with whether implementations
> use trailing-fence vs leading-fence conventions. If using trailing
> fence (which most if not all Java implementations do), then it seems
> that the only good decision is to issue a fence on comparison failure;
> perhaps differently depending on whether using AArch64 LDAX/STRX
> vs explicit fences inside CAS loop.
>
> At least some C/C++ ARM and POWER mappings use leading-fence
> convention, which could lead to differences here. Also, there
> are version of C++ compare_exchange_strong that take a second
> memory_order argument controlling the consistency effects on
> failure (by default seq_cst/volatile). Although implementations
> elide fence here only on comparison failure, not on contention
> failure. There's no Java equivalent, so people would need to
> use one of the weak variants and add fences.
>
> -Doug
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/c1acaff7/attachment-0001.html>

From shade at redhat.com  Tue May 30 14:56:45 2017
From: shade at redhat.com (Aleksey Shipilev)
Date: Tue, 30 May 2017 20:56:45 +0200
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
Message-ID: <db5a8d1e-9e3a-463f-1bb1-cd55d9291226@redhat.com>

On 05/30/2017 08:23 PM, Hans Boehm wrote:
> C++ clearly specifies "CAS classic". There is no way to specify release
> semantics for a failed CAS, since there is no write.

To add to the snowball of confusion here, x86 seems to always do the write with
CAS, even on failure:

Intel SDM, Vol 2A, ISA Reference, "CMPXCHG — Compare and Exchange":

"This instruction can be used with a LOCK prefix to allow the instruction to be
executed atomically. To simplify the interface to the processor’s bus, the
destination operand receives a write cycle without regard to the result of the
comparison. The destination operand is written back if the comparison fails;
otherwise, the source operand is written into the destination. (The processor
never produces a locked read without also producing a locked write.)"

So in x86 work, there *is* a write, but that does not really help us, because it
writes the indistinguishably old value back...

-Aleksey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/fd46438d/attachment.sig>

From oleksandr.otenko at gmail.com  Tue May 30 15:10:35 2017
From: oleksandr.otenko at gmail.com (Alex Otenko)
Date: Tue, 30 May 2017 20:10:35 +0100
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <C3ACE72E-44EB-4F52-A1B8-6EFD9EE0C205@guidewire.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>
 <6B230B20-FFB4-49C7-865F-0926F306D6DD@gmail.com>
 <C3ACE72E-44EB-4F52-A1B8-6EFD9EE0C205@guidewire.com>
Message-ID: <472D834F-79FF-4F91-8672-B46D954C0BBF@gmail.com>

The write of the default value (zero, false, or null) to each variable synchronizes-with the first action in every thread.

But it is immaterial here. The test can be extended so that both threads start from the state where both are started, both observed x=0 write, then start racing.

Alex

> On 30 May 2017, at 17:57, Justin Sampson <jsampson at guidewire.com> wrote:
> 
> Non-volatile reads can be reordered. There's no happens-before relation between the write and either of those reads, so it doesn't contradict happens-before consistency for the second read to not see the write. What part of the JMM says otherwise?
> 
> Thanks,
> Justin
> 
> 
> On 5/30/17, 1:42 AM, "Alex Otenko" <oleksandr.otenko at gmail.com> wrote:
> 
>    Racy reads can’t observe just any writes, only those that won’t contradict the happens-before partial order.
> 
>    So you still need a write of 0 that you can place after the write of 1 in Thread 1. The initial write of 0 can’t be observed after any write observed after Thread 1 start.
> 
> 
>    Alex
> 
>> On 30 May 2017, at 08:47, Justin Sampson <jsampson at guidewire.com> wrote:
>> 
>> Alex Otenko wrote:
>> 
>>> int x=0; // non-volatile
>>> volatile int z=0;
>>> volatile boolean b=false;
>>> 
>>> Thread1:
>>> if (CAS(z, 0, 1)) {
>>>  if (x == 0) {
>>>    b=true;
>>>    CAS(z, 1, 2);
>>>  }
>>> }
>>> return x;
>>> 
>>> Thread2:
>>> x=1;
>>> if (!CAS(z, 0, 2)) {
>>>  return b;
>>> }
>>> return true;
>> 
>> I keep going over this code in my head. The data race is tricky.
>> 
>> In particular, the conclusion that "if Thread2 returns false then Thread1 returns 1" seems to rely on an assumption that if the read of x in "x == 0" sees 1 then the read of x in "return x" will also see 1. What part of the JMM justifies that assumption? Both reads are racy, _unless_ the first read does _not_ see 1. If the first read _does_ see 1, then the second read is still racy and it's possible for it to see 0. Non-volatile reads can be reordered freely, can't they?
>> 
>> Cheers,
>> Justin
>> 
>> 
> 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/7ae57a2f/attachment.html>

From jsampson at guidewire.com  Tue May 30 16:28:53 2017
From: jsampson at guidewire.com (Justin Sampson)
Date: Tue, 30 May 2017 20:28:53 +0000
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <472D834F-79FF-4F91-8672-B46D954C0BBF@gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <CAPUmR1aXWdLumwy446ccZYDh9=8DRgi2_pWc_aS8wyJd+546Xg@mail.gmail.com>
 <A179B0CB-4F3A-40F2-9832-21B71E0DA344@gmail.com>
 <CAPUmR1aMk_1n5_W3pESCytsQb-pjKnenz6gWXVY7k7FMmfpRYQ@mail.gmail.com>
 <E5F8F2BC-E2A9-4682-BD71-CAE9541C4776@gmail.com>
 <F6C5E055-097A-467E-B2A1-4BDEED15A617@guidewire.com>
 <6B230B20-FFB4-49C7-865F-0926F306D6DD@gmail.com>
 <C3ACE72E-44EB-4F52-A1B8-6EFD9EE0C205@guidewire.com>
 <472D834F-79FF-4F91-8672-B46D954C0BBF@gmail.com>
Message-ID: <3E9578C9-8E38-4CCE-9170-0B435F41DC9A@guidewire.com>

Alex Otenko wrote:

> The write of the default value (zero, false, or null) to each
> variable synchronizes-with the first action in every thread.

That's not the write I'm talking about: There's no happens-before
relationship between the x=1 and either of the reads, so both
reads are independently permitted to see either 0 or 1 without
violating happens-before consistency.

But now I see that my concern would be addressed by simply
changing the code to eliminate the second read in Thread1:

if (CAS(z, 0, 1)) {
  if (x == 0) {
    b=true;
    CAS(z, 1, 2);
  } else {
    return 1; // instead of falling through to return x
  }
}
return x;

Cheers,
Justin



From boehm at acm.org  Tue May 30 17:48:53 2017
From: boehm at acm.org (Hans Boehm)
Date: Tue, 30 May 2017 14:48:53 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <db5a8d1e-9e3a-463f-1bb1-cd55d9291226@redhat.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <db5a8d1e-9e3a-463f-1bb1-cd55d9291226@redhat.com>
Message-ID: <CAPUmR1bnSKaAOvBrYYyS7j1Yo80xFcNo7ovC2Su9yC9jaHwQMw@mail.gmail.com>

The details here seem to be a statement about ancient history, at least
where it pertains to write-back cacheable memory.

The "LOCK" prefix description says:

"Beginning with the P6 family processors, when the LOCK prefix is prefixed
to an instruction and the memory area
being accessed is cached internally in the processor, the LOCK# signal is
generally not asserted. Instead, only the
processor’s cache is locked. Here, the processor’s cache coherency
mechanism ensures that the operation is
carried out atomically with regards to memory. See “Effects of a Locked
Operation on Internal Processor Caches”
in Chapter 8 of Intel® 64 and IA-32 Architectures Software Developer’s
Manual, Volume 3A, the for more informa-
tion on locking of caches."

Note that the P6 was introduced in 1995.

I would guess that it does still get exclusive access to the cache line,
even if the compare fails. So I expect that in
some very abstract sense this still applies.

On Tue, May 30, 2017 at 11:56 AM, Aleksey Shipilev <shade at redhat.com> wrote:

> On 05/30/2017 08:23 PM, Hans Boehm wrote:
> > C++ clearly specifies "CAS classic". There is no way to specify release
> > semantics for a failed CAS, since there is no write.
>
> To add to the snowball of confusion here, x86 seems to always do the write
> with
> CAS, even on failure:
>
> Intel SDM, Vol 2A, ISA Reference, "CMPXCHG — Compare and Exchange":
>
> "This instruction can be used with a LOCK prefix to allow the instruction
> to be
> executed atomically. To simplify the interface to the processor’s bus, the
> destination operand receives a write cycle without regard to the result of
> the
> comparison. The destination operand is written back if the comparison
> fails;
> otherwise, the source operand is written into the destination. (The
> processor
> never produces a locked read without also producing a locked write.)"
>
> So in x86 work, there *is* a write, but that does not really help us,
> because it
> writes the indistinguishably old value back...
>
> -Aleksey
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170530/0db9aaec/attachment-0001.html>

From dl at cs.oswego.edu  Wed May 31 07:03:35 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 31 May 2017 07:03:35 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <f802e248-5677-f693-e8a0-abd25f9f5ba4@redhat.com>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
Message-ID: <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>

On 05/30/2017 02:23 PM, Hans Boehm wrote:
> The memory model does not define "the memory consistency effects of
> a write". It only defines the effect of a volatile write to a
> specific field; the "memory consistency effects" depend entirely on
> the location being written.

OK. To be pedantic, this should read:
"The memory consistency effects of a write to the variable occur
regardless of outcome."

> The problem here is that there normally is no write to associate the
> "memory consistency effect" with.

But as an implementation-level concern, issuing full dmb
fence on ARM has memory consistency effects at least at strong.

> 
> I'm not convinced this decision matters significantly in terms of 
> programmability. Alex convinced me that it is, unfortunately, 
> observable, because there are examples in which you can deduce that
> code is  after a failed CAS. There may be code that relies on it, but
> I've never personally seen such code in production.

I agree in all senses. I think we have to do this, even though
it is unlikely to matter in practice. Given that the fence
only occurs on the fail path, the only possible negative
performance impact I can imagine is code bulk (adding two
instructions) and in turn possibly inlinability.

> 
> C++ clearly specifies "CAS classic". There is no way to specify
> release semantics for a failed CAS, since there is no write.

The current C++ spec, sec 29.2 includes versions that do so,
including:

bool atomic_compare_exchange_strong_explicit(volatile atomic-type *, T*,
T, memory_order, memory_order);

(BTW, there's a typo (a stray paren) in this decl on page 1130
of the draft available at http://www.open-std.org/jtc1/sc22/wg21/)

See also the easier-to-read version at
http://www.cplusplus.com/reference/atomic/atomic/compare_exchange_strong/

The second  memory_order parameter is:
"Synchronization mode for the operation in case expected does not match
the contained value."

Both memory_order parameters default to seq_cst.


-Doug


From dl at cs.oswego.edu  Wed May 31 08:06:04 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Wed, 31 May 2017 08:06:04 -0400
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
 updating
In-Reply-To: <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
Message-ID: <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>

On 05/31/2017 07:03 AM, Doug Lea wrote:

>>
>> C++ clearly specifies "CAS classic". There is no way to specify
>> release semantics for a failed CAS, since there is no write.
> 
> The current C++ spec, sec 29.2 includes versions that do so,

Except that memory_order_release is specifically disallowed.
Not that it matters, since the question at hand is about
volatile/seq_cst.

-Doug

From boehm at acm.org  Wed May 31 19:33:51 2017
From: boehm at acm.org (Hans Boehm)
Date: Wed, 31 May 2017 16:33:51 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
Message-ID: <CAPUmR1b3zSZfVLMs3WoFwJ_JuKep0skkP1d2HhyJiMZyGm-XEA@mail.gmail.com>

In C++, memory_order_seq_cst as the failure ordering for CAS means it has
volatile load semantics, since there is no store. See 29.3.

A fair fraction of code I've seen, though certainly not the majority, does
not retry CAS on failure. (Admittedly this is usually C++ code.) Often the
failure case is still rare, but that's not always the case. For example,
the code may be looping over a small array trying to find and replace a
non-null array entry. Or the programmer may be trying to set a bit and have
the first setter do some other work. (I don't know whether a plain exchange
would be better; it probably depends on cache line dirtying behavior.)

"compareAndSet and all other read-and-update operations such as
getAndIncrement have the memory effects of both reading and writing
volatile variables." strikes me as sufficiently unclear that it's not
obvious to me we have to do anything. I would probably not have read that
as implying a write for failing CAS.

On Wed, May 31, 2017 at 5:06 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/31/2017 07:03 AM, Doug Lea wrote:
>
> >>
> >> C++ clearly specifies "CAS classic". There is no way to specify
> >> release semantics for a failed CAS, since there is no write.
> >
> > The current C++ spec, sec 29.2 includes versions that do so,
>
> Except that memory_order_release is specifically disallowed.
> Not that it matters, since the question at hand is about
> volatile/seq_cst.
>
> -Doug
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170531/2564fea3/attachment.html>

From martinrb at google.com  Wed May 31 21:29:45 2017
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 31 May 2017 18:29:45 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
Message-ID: <CA+kOe0-8eEybt=Ktdzxibi9zSPmGq_89V7M3zNZJqdE5=GkHNw@mail.gmail.com>

On Wed, May 31, 2017 at 5:06 AM, Doug Lea <dl at cs.oswego.edu> wrote:

> On 05/31/2017 07:03 AM, Doug Lea wrote:
>
> >>
> >> C++ clearly specifies "CAS classic". There is no way to specify
> >> release semantics for a failed CAS, since there is no write.
> >
> > The current C++ spec, sec 29.2 includes versions that do so,
>
> Except that memory_order_release is specifically disallowed.
> Not that it matters, since the question at hand is about
> volatile/seq_cst.


The fact that  memory_order_release is specifically disallowed "proves"
that Hans is right that this is referring to the semantics of the read
alone.

Please please make the semantics of CAS in Java as close as possible to
C++.  In particular, don't make them more expensive for no good reason.

The volatile read in CAS failure alone ensures that the CAS is a
sequentially consistent synchronization action (part of the total order of
all such actions).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170531/349297bf/attachment.html>

From martinrb at google.com  Wed May 31 21:34:33 2017
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 31 May 2017 18:34:33 -0700
Subject: [concurrency-interest] AtomicReference.updateAndGet() mandatory
	updating
In-Reply-To: <CAPUmR1b3zSZfVLMs3WoFwJ_JuKep0skkP1d2HhyJiMZyGm-XEA@mail.gmail.com>
References: <e49ebd14d48265128a06ff5558664c36@duigou.org>
 <5EECB68B-81E6-462F-A118-5A9111D6EF52@guidewire.com>
 <2b791c10538264930c33034b97218e77@duigou.org>
 <88C480C6-CA86-48C7-B611-B782B68F02A6@gmail.com>
 <ECBD4F49-C101-4D44-82C1-C67FEF102F81@azul.com>
 <34c467ef-7a13-99ac-ab26-8432352e3c36@redhat.com>
 <31c2613c-12b4-aa39-389d-4d047571a466@cs.oswego.edu>
 <4D4E560F-0E8D-477A-A9A9-58CE8A2065F9@azul.com>
 <8b130f2c-6835-fcc7-04ef-db8f98b87c17@redhat.com>
 <b6930e02-c7e7-7521-3c48-e9a392499c22@cs.oswego.edu>
 <6e2adf6a-54e4-0e29-e3f2-3e56085bbb97@redhat.com>
 <02846691-5d2a-85d4-5a83-f6d73b82c50a@redhat.com>
 <1dbd8ba7-910f-e14c-3764-a08f80e4a875@cs.oswego.edu>
 <BBF22E8A-7C71-442A-98C8-B049F7E48EA8@azul.com>
 <41a79ae8-3159-35a5-35ff-1e2dd9970b1d@cs.oswego.edu>
 <5952b6c7-9d51-3b00-3c87-23034c41c1ce@gmail.com>
 <3f4e409c-b7bc-f8d0-6e7d-0e70c1cdc925@cs.oswego.edu>
 <CAPUmR1YsN0-f00NsP3dxwZP7KPHQz3pohudJmVzO2J2NFjG84g@mail.gmail.com>
 <d379be29-bc05-64b9-28f3-7bb00de8c0df@cs.oswego.edu>
 <89145379-2907-e528-a9d2-add2b954bb82@cs.oswego.edu>
 <CAPUmR1b3zSZfVLMs3WoFwJ_JuKep0skkP1d2HhyJiMZyGm-XEA@mail.gmail.com>
Message-ID: <CA+kOe08aL-yr+a5SNEJBKo+woWTNvM9LfwHXWJu7z6aUDTgLoA@mail.gmail.com>

On Wed, May 31, 2017 at 4:33 PM, Hans Boehm <boehm at acm.org> wrote:

>
> "compareAndSet and all other read-and-update operations such as
> getAndIncrement have the memory effects of both reading and writing
> volatile variables." strikes me as sufficiently unclear that it's not
> obvious to me we have to do anything. I would probably not have read that
> as implying a write for failing CAS.
>

I agree.  The natural interpretation is that __if__ a write is necessary,
it will have the semantics of a volatile write.

I fully support Hans in this discussion.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20170531/5db6f261/attachment.html>

