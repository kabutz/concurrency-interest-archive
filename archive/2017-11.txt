From pavel.rappo at gmail.com  Thu Nov  2 12:49:58 2017
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Thu, 2 Nov 2017 19:49:58 +0300
Subject: [concurrency-interest] Clarifications request for Reactive Streams
	Specification Rule 1.1
Message-ID: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>

I think this question is both about concurrency in Java and Reactive Streams.
Thus posting it to a place where it could be seen by all interested parties.

>    Rule #1.1
>
>    The total number of onNext's signalled by a Publisher to a Subscriber MUST
>    be less than or equal to the total number of elements requested by that
>    Subscriber's Subscription at all times.
>
>    The intent of this rule is to make it clear that Publishers cannot signal
>    more elements than Subscribers have requested. There’s an implicit, but
>    important, consequence to this rule: Since demand can only be fulfilled
>    after it has been received, there’s a happens-before relationship between
>    requesting elements and receiving elements.

It sounds like it is more about causality than happens-before. Like if there is
an Subscriber.onNext call in the execution, it must be that there was at least a
single Subscription.request call in that execution earlier.

If it is really about happens-before, the rule might benefit from the following
clarification ("concurrent collections" style):

    Actions in a thread prior to requesting an item from a Subscription
    happen-before actions subsequent to receiving of that item in
    Subscriber.onNext in another thread.

However, since we don't know an element before we receive one in onNext, it can
be quite tricky to formulate that clearly.

From viktor.klang at gmail.com  Thu Nov  2 13:58:34 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 2 Nov 2017 18:58:34 +0100
Subject: [concurrency-interest] Clarifications request for Reactive
 Streams Specification Rule 1.1
In-Reply-To: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>
References: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>
Message-ID: <CANPzfU9VREvh-4vfRXZxRZWaOCk2R6dKCN9YStDpFt9NsxhsrQ@mail.gmail.com>

Pavel,

On Thu, Nov 2, 2017 at 5:49 PM, Pavel Rappo via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> I think this question is both about concurrency in Java and Reactive
> Streams.
> Thus posting it to a place where it could be seen by all interested
> parties.
>
> >    Rule #1.1
> >
> >    The total number of onNext's signalled by a Publisher to a Subscriber
> MUST
> >    be less than or equal to the total number of elements requested by
> that
> >    Subscriber's Subscription at all times.
> >
> >    The intent of this rule is to make it clear that Publishers cannot
> signal
> >    more elements than Subscribers have requested. There’s an implicit,
> but
> >    important, consequence to this rule: Since demand can only be
> fulfilled
> >    after it has been received, there’s a happens-before relationship
> between
> >    requesting elements and receiving elements.
>
> It sounds like it is more about causality than happens-before.

Like if there is
> an Subscriber.onNext call in the execution, it must be that there was at
> least a
> single Subscription.request call in that execution earlier.


> If it is really about happens-before, the rule might benefit from the
> following
> clarification ("concurrent collections" style):
>
>     Actions in a thread prior to requesting an item from a Subscription
>     happen-before actions subsequent to receiving of that item in
>     Subscriber.onNext in another thread.
>
> However, since we don't know an element before we receive one in onNext,
> it can
> be quite tricky to formulate that clearly.
>

The Intent-section of the rule is not the specification of the rule. :)


> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>



-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171102/a7a9cd29/attachment.html>

From pavel.rappo at gmail.com  Thu Nov  2 14:37:41 2017
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Thu, 2 Nov 2017 21:37:41 +0300
Subject: [concurrency-interest] Clarifications request for Reactive
 Streams Specification Rule 1.1
In-Reply-To: <CANPzfU9VREvh-4vfRXZxRZWaOCk2R6dKCN9YStDpFt9NsxhsrQ@mail.gmail.com>
References: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>
 <CANPzfU9VREvh-4vfRXZxRZWaOCk2R6dKCN9YStDpFt9NsxhsrQ@mail.gmail.com>
Message-ID: <CAChcVumfSEAu-GAT4L6JwCtTKEJ4k0cbmsAiEo7QvJdYTEK4TA@mail.gmail.com>

Viktor,

Sorry for the misleading title. However, I would appreciate if someone clarifies
this passage. The intent section claims the rule has an implication. In my
opinion an implication is a (even though implicit) first class citizen in the
spec. Because if I cannot verify an implication from a rule, I cannot verify the
rule itself.

An intent section is more about "why it is so" (commentary if you wish).

On Thu, Nov 2, 2017 at 8:58 PM, Viktor Klang <viktor.klang at gmail.com> wrote:
> Pavel,
>
> On Thu, Nov 2, 2017 at 5:49 PM, Pavel Rappo via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>>
>> I think this question is both about concurrency in Java and Reactive
>> Streams.
>> Thus posting it to a place where it could be seen by all interested
>> parties.
>>
>> >    Rule #1.1
>> >
>> >    The total number of onNext's signalled by a Publisher to a Subscriber
>> > MUST
>> >    be less than or equal to the total number of elements requested by
>> > that
>> >    Subscriber's Subscription at all times.
>> >
>> >    The intent of this rule is to make it clear that Publishers cannot
>> > signal
>> >    more elements than Subscribers have requested. There’s an implicit,
>> > but
>> >    important, consequence to this rule: Since demand can only be
>> > fulfilled
>> >    after it has been received, there’s a happens-before relationship
>> > between
>> >    requesting elements and receiving elements.
>>
>> It sounds like it is more about causality than happens-before.
>>
>> Like if there is
>> an Subscriber.onNext call in the execution, it must be that there was at
>> least a
>> single Subscription.request call in that execution earlier.
>>
>>
>> If it is really about happens-before, the rule might benefit from the
>> following
>> clarification ("concurrent collections" style):
>>
>>     Actions in a thread prior to requesting an item from a Subscription
>>     happen-before actions subsequent to receiving of that item in
>>     Subscriber.onNext in another thread.
>>
>> However, since we don't know an element before we receive one in onNext,
>> it can
>> be quite tricky to formulate that clearly.
>
>
> The Intent-section of the rule is not the specification of the rule. :)
>
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
>
>
> --
> Cheers,
> √

From viktor.klang at gmail.com  Thu Nov  2 17:20:22 2017
From: viktor.klang at gmail.com (Viktor Klang)
Date: Thu, 2 Nov 2017 22:20:22 +0100
Subject: [concurrency-interest] Clarifications request for Reactive
 Streams Specification Rule 1.1
In-Reply-To: <CAChcVumfSEAu-GAT4L6JwCtTKEJ4k0cbmsAiEo7QvJdYTEK4TA@mail.gmail.com>
References: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>
 <CANPzfU9VREvh-4vfRXZxRZWaOCk2R6dKCN9YStDpFt9NsxhsrQ@mail.gmail.com>
 <CAChcVumfSEAu-GAT4L6JwCtTKEJ4k0cbmsAiEo7QvJdYTEK4TA@mail.gmail.com>
Message-ID: <CANPzfU_VHp48tPwZUYVz8y2Y69+dGuEAC=3f4hT8Jsrx7VCPcQ@mail.gmail.com>

Pavel,

Yes, there's a causal relationship between the Subscriber demanding more
elements, and those items being delivered,
and that signalling is done in a thread safe manner, so by extension,
request-ing happens-before onNext signalling.
The rules governing Subscription
<https://github.com/reactive-streams/reactive-streams-jvm#3-subscription-code>
elaborates on the requirements, but most specifically in this case is, I
believe, 3.8 <https://github.com/reactive-streams/reactive-streams-jvm#3.8>.

Speaking of verification, has the TCK helped you with the interpretations?

On Thu, Nov 2, 2017 at 7:37 PM, Pavel Rappo <pavel.rappo at gmail.com> wrote:

> Viktor,
>
> Sorry for the misleading title. However, I would appreciate if someone
> clarifies
> this passage. The intent section claims the rule has an implication. In my
> opinion an implication is a (even though implicit) first class citizen in
> the
> spec. Because if I cannot verify an implication from a rule, I cannot
> verify the
> rule itself.
>
> An intent section is more about "why it is so" (commentary if you wish).
>
> On Thu, Nov 2, 2017 at 8:58 PM, Viktor Klang <viktor.klang at gmail.com>
> wrote:
> > Pavel,
> >
> > On Thu, Nov 2, 2017 at 5:49 PM, Pavel Rappo via Concurrency-interest
> > <concurrency-interest at cs.oswego.edu> wrote:
> >>
> >> I think this question is both about concurrency in Java and Reactive
> >> Streams.
> >> Thus posting it to a place where it could be seen by all interested
> >> parties.
> >>
> >> >    Rule #1.1
> >> >
> >> >    The total number of onNext's signalled by a Publisher to a
> Subscriber
> >> > MUST
> >> >    be less than or equal to the total number of elements requested by
> >> > that
> >> >    Subscriber's Subscription at all times.
> >> >
> >> >    The intent of this rule is to make it clear that Publishers cannot
> >> > signal
> >> >    more elements than Subscribers have requested. There’s an implicit,
> >> > but
> >> >    important, consequence to this rule: Since demand can only be
> >> > fulfilled
> >> >    after it has been received, there’s a happens-before relationship
> >> > between
> >> >    requesting elements and receiving elements.
> >>
> >> It sounds like it is more about causality than happens-before.
> >>
> >> Like if there is
> >> an Subscriber.onNext call in the execution, it must be that there was at
> >> least a
> >> single Subscription.request call in that execution earlier.
> >>
> >>
> >> If it is really about happens-before, the rule might benefit from the
> >> following
> >> clarification ("concurrent collections" style):
> >>
> >>     Actions in a thread prior to requesting an item from a Subscription
> >>     happen-before actions subsequent to receiving of that item in
> >>     Subscriber.onNext in another thread.
> >>
> >> However, since we don't know an element before we receive one in onNext,
> >> it can
> >> be quite tricky to formulate that clearly.
> >
> >
> > The Intent-section of the rule is not the specification of the rule. :)
> >
> >>
> >> _______________________________________________
> >> Concurrency-interest mailing list
> >> Concurrency-interest at cs.oswego.edu
> >> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
> >
> >
> >
> >
> > --
> > Cheers,
> > √
>



-- 
Cheers,
√
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171102/a3d85ecc/attachment-0001.html>

From pavel.rappo at gmail.com  Fri Nov  3 04:29:31 2017
From: pavel.rappo at gmail.com (Pavel Rappo)
Date: Fri, 3 Nov 2017 11:29:31 +0300
Subject: [concurrency-interest] Clarifications request for Reactive
 Streams Specification Rule 1.1
In-Reply-To: <CANPzfU_VHp48tPwZUYVz8y2Y69+dGuEAC=3f4hT8Jsrx7VCPcQ@mail.gmail.com>
References: <CAChcVumKCbt1UXzmeuwtrKguqjbKc=4G-pUkGbH6hhQnSmRZcw@mail.gmail.com>
 <CANPzfU9VREvh-4vfRXZxRZWaOCk2R6dKCN9YStDpFt9NsxhsrQ@mail.gmail.com>
 <CAChcVumfSEAu-GAT4L6JwCtTKEJ4k0cbmsAiEo7QvJdYTEK4TA@mail.gmail.com>
 <CANPzfU_VHp48tPwZUYVz8y2Y69+dGuEAC=3f4hT8Jsrx7VCPcQ@mail.gmail.com>
Message-ID: <CAChcVukVMVZ7StXNf4Co+PnJat0g1ngvKc3fzYEEsi+s8QaP-g@mail.gmail.com>

On Fri, Nov 3, 2017 at 12:20 AM, Viktor Klang <viktor.klang at gmail.com> wrote:
> Speaking of verification, has the TCK helped you with the interpretations?

Sort of. I've run tests, but haven't yet dug into their implementation.

From ndkoval at ya.ru  Fri Nov  3 17:47:05 2017
From: ndkoval at ya.ru (Nikita Koval)
Date: Sat, 04 Nov 2017 00:47:05 +0300
Subject: [concurrency-interest] Concurrent algorithms verification
Message-ID: <1585271509745625@web45j.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171104/4d119df8/attachment.html>

From ablacktshirt at gmail.com  Fri Nov  3 22:12:57 2017
From: ablacktshirt at gmail.com (Yubin Ruan)
Date: Sat, 4 Nov 2017 10:12:57 +0800
Subject: [concurrency-interest] Concurrent algorithms verification
In-Reply-To: <1585271509745625@web45j.yandex.ru>
References: <1585271509745625@web45j.yandex.ru>
Message-ID: <CAJYFCiORnZE9qbNQXODy4bzEGs=pb6M2xjNM9+4nUOmEUAMdQA@mail.gmail.com>

Hi Nikita,
Thanks for your sharing.

2017-11-04 5:47 GMT+08:00 Nikita Koval via Concurrency-interest
<concurrency-interest at cs.oswego.edu>:
> Hi All,
>
> I think it would be interesting for you. I have developed a special tool,
> Lin-Check, for testing concurrent data structures for correctness. The
> approach is based on linearization definition and the tool tries to find
> non-linearizable execution with specified operations, using a specially
> crafted test to produce lots of different executions. The execution is

AFAIK, being a correct concurrent data structure does not imply
linearization consistency.

Yubin

From ndkoval at ya.ru  Sat Nov  4 09:06:35 2017
From: ndkoval at ya.ru (Nikita Koval)
Date: Sat, 04 Nov 2017 16:06:35 +0300
Subject: [concurrency-interest] Concurrent algorithms verification
In-Reply-To: <CAJYFCiORnZE9qbNQXODy4bzEGs=pb6M2xjNM9+4nUOmEUAMdQA@mail.gmail.com>
References: <1585271509745625@web45j.yandex.ru>
 <CAJYFCiORnZE9qbNQXODy4bzEGs=pb6M2xjNM9+4nUOmEUAMdQA@mail.gmail.com>
Message-ID: <1374781509800795@web25o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171104/4689bc78/attachment.html>

From martinrb at google.com  Mon Nov  6 07:53:31 2017
From: martinrb at google.com (Martin Buchholz)
Date: Mon, 6 Nov 2017 04:53:31 -0800
Subject: [concurrency-interest] Concurrent algorithms verification
In-Reply-To: <1585271509745625@web45j.yandex.ru>
References: <1585271509745625@web45j.yandex.ru>
Message-ID: <CA+kOe0_09tyMELTu=jYJLnWfZgA4Ji-3m8ErfDMZo_swSK82bg@mail.gmail.com>

Nikita,
Are you aware of the work in "violat" project?
https://github.com/michael-emmi/violat/blob/master/README.md
https://arxiv.org/pdf/1706.09305.pdf
This has prompted work here on improving linearizability in
ConcurrentLinkedDeque.

On Fri, Nov 3, 2017 at 2:47 PM, Nikita Koval via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> Hi All,
>
> I think it would be interesting for you. I have developed a special tool,
> *Lin-Check,* for testing concurrent data structures for correctness. The
> approach is based on linearization definition and the tool tries to find
> non-linearizable execution with specified operations, using a specially
> crafted test to produce lots of different executions. The execution is
> represented as a list of actors for every test thread, where the actor is
> the operation (e.g. *put(key, value)* and *get(key)* in *java.util.Map*)
> with already counted parameters.
>
> For more details see the project on GitHub: https://github.com/Devexperts/
> lin-check.
> I will be also glad to provide you all necessary information in case you
> have any questions.
> Best regards,
> Nikita Koval
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171106/29118145/attachment.html>

From ndkoval at ya.ru  Mon Nov  6 08:14:53 2017
From: ndkoval at ya.ru (Nikita Koval)
Date: Mon, 06 Nov 2017 16:14:53 +0300
Subject: [concurrency-interest] Concurrent algorithms verification
In-Reply-To: <CA+kOe0_09tyMELTu=jYJLnWfZgA4Ji-3m8ErfDMZo_swSK82bg@mail.gmail.com>
References: <1585271509745625@web45j.yandex.ru>
 <CA+kOe0_09tyMELTu=jYJLnWfZgA4Ji-3m8ErfDMZo_swSK82bg@mail.gmail.com>
Message-ID: <317731509974093@web46o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171106/7bcdb26d/attachment.html>

From notcarl at google.com  Tue Nov 21 16:33:55 2017
From: notcarl at google.com (Carl Mastrangelo)
Date: Tue, 21 Nov 2017 13:33:55 -0800
Subject: [concurrency-interest] ConcurrentLinkedQueue padding
Message-ID: <CAAcqB+uUzwb+pBCJTcDeJou8vtx2ENDthdTPFtw=n79vvmw4pw@mail.gmail.com>

Hi concurrency interest,

I was looking through ConcurrentLinkedQueue and noticed that unlike several
of the other concurrent classes, the volatile Node pointers as well as the
Nodes themselves don't have any padding.  This makes me wonder, could there
be false sharing when using multiple producers to add to the queue?  I was
under the impression that the GC tends to group fields of a class near each
other, which would imply that there is going to likely be contention when
quickly updating (and reading) from it.


Carl
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171121/5376be23/attachment.html>

From esarge at pobox.com  Tue Nov 21 19:51:37 2017
From: esarge at pobox.com (Edward Sargisson)
Date: Tue, 21 Nov 2017 16:51:37 -0800
Subject: [concurrency-interest] Any advantage to
 ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling
Message-ID: <CAH4ZcEtGNcA_pssHx-3hZOmihRuHqhOXRw4kfYjwFeN5j+RwgA@mail.gmail.com>

Hi,
I'm curious about this because I discussed this with my boss and then
tested some code and got a result I didn't expect. My expectation was that
polling with Thread.sleep every second would keep a core 30% busy (because
it would go to a spin loop generating random numbers for 300ms and then go
to the OS). However, my test doesn't show this.

I'm hoping the collective expertise on this list might provide some useful
information for others who come along with similar questions. (And
hopefully this email actually goes out because cs.oswego.edu appears to be
down)

The code is of the form:
while (!shutdown) {
  if( System.currentTimeMillis() - lastCheck > waitTime) {
    // do important stuff
   lastCheck = System.currentTimeMills()
  }
 Thread.sleep(1000);
}

I proposed that using
ScheduledExecutorService.scheduleAtFixedRate(waitTime) would use less CPU
time because it wouldn't have to wake up only to see it had nothing to do
yet and go back to sleep. Based on Doug Lea's PhillyETE 2013 talk I was
expecting it to generate random numbers for a while.

I wrote a test that was essentially:
// start the thread above
scheduler.schedule(() -> finishLatch.countDown(), 5, TimeUnit.MINUTES);
finishLatch.await();

I fired it up on macOS and attached YourKit to it.

The thing is sitting on 0% CPU!

I attempted to verify the result using the macOS Activity Monitor and the
process is showing ~0.3% CPU.

I gave Java Flight Recorder a run to see if it would show anything (my
first time using this tool). From what I can see it's registering 0% CPU
too.

So, does Thread.sleep() actually sleep or is there something going on that
I don't know how to measure.

Many, many thanks in advance.

Cheers,
Edward
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171121/5ced0c3f/attachment.html>

From davidcholmes at aapt.net.au  Tue Nov 21 20:15:05 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 22 Nov 2017 11:15:05 +1000
Subject: [concurrency-interest] Any advantage to
	ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling
In-Reply-To: <CAH4ZcEtGNcA_pssHx-3hZOmihRuHqhOXRw4kfYjwFeN5j+RwgA@mail.gmail.com>
References: <CAH4ZcEtGNcA_pssHx-3hZOmihRuHqhOXRw4kfYjwFeN5j+RwgA@mail.gmail.com>
Message-ID: <020301d3632f$54df2800$fe9d7800$@aapt.net.au>

What were you expecting to “go to a spin loop generating random numbers for 300ms then go to the OS” ???

 

Thread.sleep parks the thread for around the time specified (modulo OS quirks mainly on windows).

 

scheduleAtFixedRate triggers a periodic release of a task. scheduleAtFixedDelay spaces releases of a task by a fixed interval.

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Edward Sargisson via Concurrency-interest
Sent: Wednesday, November 22, 2017 10:52 AM
To: concurrency-interest at cs.oswego.edu
Subject: [concurrency-interest] Any advantage to ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling

 

Hi,

I'm curious about this because I discussed this with my boss and then tested some code and got a result I didn't expect. My expectation was that polling with Thread.sleep every second would keep a core 30% busy (because it would go to a spin loop generating random numbers for 300ms and then go to the OS). However, my test doesn't show this. 

 

I'm hoping the collective expertise on this list might provide some useful information for others who come along with similar questions. (And hopefully this email actually goes out because cs.oswego.edu <http://cs.oswego.edu>  appears to be down)

 

The code is of the form:

while (!shutdown) {

  if( System.currentTimeMillis() - lastCheck > waitTime) {

    // do important stuff

   lastCheck = System.currentTimeMills()

  }

 Thread.sleep(1000);

}

 

I proposed that using ScheduledExecutorService.scheduleAtFixedRate(waitTime) would use less CPU time because it wouldn't have to wake up only to see it had nothing to do yet and go back to sleep. Based on Doug Lea's PhillyETE 2013 talk I was expecting it to generate random numbers for a while.

 

I wrote a test that was essentially:

// start the thread above

scheduler.schedule(() -> finishLatch.countDown(), 5, TimeUnit.MINUTES);

finishLatch.await();

 

I fired it up on macOS and attached YourKit to it.

 

The thing is sitting on 0% CPU!

 

I attempted to verify the result using the macOS Activity Monitor and the process is showing ~0.3% CPU.

 

I gave Java Flight Recorder a run to see if it would show anything (my first time using this tool). From what I can see it's registering 0% CPU too.

 

So, does Thread.sleep() actually sleep or is there something going on that I don't know how to measure.

 

Many, many thanks in advance.

 

Cheers,

Edward

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171122/1c91cc90/attachment.html>

From esarge at pobox.com  Tue Nov 21 20:20:05 2017
From: esarge at pobox.com (Edward Sargisson)
Date: Tue, 21 Nov 2017 17:20:05 -0800
Subject: [concurrency-interest] Any advantage to
 ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling
In-Reply-To: <020301d3632f$54df2800$fe9d7800$@aapt.net.au>
References: <CAH4ZcEtGNcA_pssHx-3hZOmihRuHqhOXRw4kfYjwFeN5j+RwgA@mail.gmail.com>
 <020301d3632f$54df2800$fe9d7800$@aapt.net.au>
Message-ID: <CAH4ZcEvRY-e9ebAppopJJuNNcoY_HJBDRXAfxgz2Aio9ht9r-Q@mail.gmail.com>

This talk from Doug Lea: https://www.youtube.com/watch?v=sq0MX3fHkro
See ~31:00 to ~41:00

Possibly I've confused a sleep with a park (or a wait on a lock).

Cheers,
Edward

On Tue, Nov 21, 2017 at 5:15 PM, David Holmes <davidcholmes at aapt.net.au>
wrote:

> What were you expecting to “go to a spin loop generating random numbers
> for 300ms then go to the OS” ???
>
>
>
> Thread.sleep parks the thread for around the time specified (modulo OS
> quirks mainly on windows).
>
>
>
> scheduleAtFixedRate triggers a periodic release of a task.
> scheduleAtFixedDelay spaces releases of a task by a fixed interval.
>
>
>
> David
>
>
>
> *From:* Concurrency-interest [mailto:concurrency-interest-
> bounces at cs.oswego.edu] *On Behalf Of *Edward Sargisson via
> Concurrency-interest
> *Sent:* Wednesday, November 22, 2017 10:52 AM
> *To:* concurrency-interest at cs.oswego.edu
> *Subject:* [concurrency-interest] Any advantage to
> ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling
>
>
>
> Hi,
>
> I'm curious about this because I discussed this with my boss and then
> tested some code and got a result I didn't expect. My expectation was that
> polling with Thread.sleep every second would keep a core 30% busy (because
> it would go to a spin loop generating random numbers for 300ms and then go
> to the OS). However, my test doesn't show this.
>
>
>
> I'm hoping the collective expertise on this list might provide some useful
> information for others who come along with similar questions. (And
> hopefully this email actually goes out because cs.oswego.edu appears to
> be down)
>
>
>
> The code is of the form:
>
> while (!shutdown) {
>
>   if( System.currentTimeMillis() - lastCheck > waitTime) {
>
>     // do important stuff
>
>    lastCheck = System.currentTimeMills()
>
>   }
>
>  Thread.sleep(1000);
>
> }
>
>
>
> I proposed that using ScheduledExecutorService.scheduleAtFixedRate(waitTime)
> would use less CPU time because it wouldn't have to wake up only to see it
> had nothing to do yet and go back to sleep. Based on Doug Lea's PhillyETE
> 2013 talk I was expecting it to generate random numbers for a while.
>
>
>
> I wrote a test that was essentially:
>
> // start the thread above
>
> scheduler.schedule(() -> finishLatch.countDown(), 5, TimeUnit.MINUTES);
>
> finishLatch.await();
>
>
>
> I fired it up on macOS and attached YourKit to it.
>
>
>
> The thing is sitting on 0% CPU!
>
>
>
> I attempted to verify the result using the macOS Activity Monitor and the
> process is showing ~0.3% CPU.
>
>
>
> I gave Java Flight Recorder a run to see if it would show anything (my
> first time using this tool). From what I can see it's registering 0% CPU
> too.
>
>
>
> So, does Thread.sleep() actually sleep or is there something going on that
> I don't know how to measure.
>
>
>
> Many, many thanks in advance.
>
>
>
> Cheers,
>
> Edward
>
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171121/70228a5a/attachment-0001.html>

From davidcholmes at aapt.net.au  Tue Nov 21 20:37:45 2017
From: davidcholmes at aapt.net.au (David Holmes)
Date: Wed, 22 Nov 2017 11:37:45 +1000
Subject: [concurrency-interest] Any advantage to
	ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling
In-Reply-To: <CAH4ZcEvRY-e9ebAppopJJuNNcoY_HJBDRXAfxgz2Aio9ht9r-Q@mail.gmail.com>
References: <CAH4ZcEtGNcA_pssHx-3hZOmihRuHqhOXRw4kfYjwFeN5j+RwgA@mail.gmail.com>
 <020301d3632f$54df2800$fe9d7800$@aapt.net.au>
 <CAH4ZcEvRY-e9ebAppopJJuNNcoY_HJBDRXAfxgz2Aio9ht9r-Q@mail.gmail.com>
Message-ID: <021401d36332$7f208a70$7d619f50$@aapt.net.au>

Ah I see. Pure time-based waiting, like Thread.sleep, doesn’t benefit from adaptive-spin-then-block – that just wastes cycles as the time can’t elapse any earlier than expected.  (Really short sleep times can be handled differently.) Such adaptive techniques are mainly used for lock acquisition, where you hope the lock might become available any nanosecond.

 

Cheers,

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu] On Behalf Of Edward Sargisson via Concurrency-interest
Sent: Wednesday, November 22, 2017 11:20 AM
To: dholmes at ieee.org
Cc: Concurrency-interest <concurrency-interest at cs.oswego.edu>
Subject: Re: [concurrency-interest] Any advantage to ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling

 

This talk from Doug Lea: https://www.youtube.com/watch?v=sq0MX3fHkro

See ~31:00 to ~41:00

 

Possibly I've confused a sleep with a park (or a wait on a lock).

 

Cheers,

Edward

 

On Tue, Nov 21, 2017 at 5:15 PM, David Holmes <davidcholmes at aapt.net.au <mailto:davidcholmes at aapt.net.au> > wrote:

What were you expecting to “go to a spin loop generating random numbers for 300ms then go to the OS” ???

 

Thread.sleep parks the thread for around the time specified (modulo OS quirks mainly on windows).

 

scheduleAtFixedRate triggers a periodic release of a task. scheduleAtFixedDelay spaces releases of a task by a fixed interval.

 

David

 

From: Concurrency-interest [mailto:concurrency-interest-bounces at cs.oswego.edu <mailto:concurrency-interest-bounces at cs.oswego.edu> ] On Behalf Of Edward Sargisson via Concurrency-interest
Sent: Wednesday, November 22, 2017 10:52 AM
To: concurrency-interest at cs.oswego.edu <mailto:concurrency-interest at cs.oswego.edu> 
Subject: [concurrency-interest] Any advantage to ScheduledExecutorService.scheduleAtFixedRate vs Thread.sleep polling

 

Hi,

I'm curious about this because I discussed this with my boss and then tested some code and got a result I didn't expect. My expectation was that polling with Thread.sleep every second would keep a core 30% busy (because it would go to a spin loop generating random numbers for 300ms and then go to the OS). However, my test doesn't show this. 

 

I'm hoping the collective expertise on this list might provide some useful information for others who come along with similar questions. (And hopefully this email actually goes out because cs.oswego.edu <http://cs.oswego.edu>  appears to be down)

 

The code is of the form:

while (!shutdown) {

  if( System.currentTimeMillis() - lastCheck > waitTime) {

    // do important stuff

   lastCheck = System.currentTimeMills()

  }

 Thread.sleep(1000);

}

 

I proposed that using ScheduledExecutorService.scheduleAtFixedRate(waitTime) would use less CPU time because it wouldn't have to wake up only to see it had nothing to do yet and go back to sleep. Based on Doug Lea's PhillyETE 2013 talk I was expecting it to generate random numbers for a while.

 

I wrote a test that was essentially:

// start the thread above

scheduler.schedule(() -> finishLatch.countDown(), 5, TimeUnit.MINUTES);

finishLatch.await();

 

I fired it up on macOS and attached YourKit to it.

 

The thing is sitting on 0% CPU!

 

I attempted to verify the result using the macOS Activity Monitor and the process is showing ~0.3% CPU.

 

I gave Java Flight Recorder a run to see if it would show anything (my first time using this tool). From what I can see it's registering 0% CPU too.

 

So, does Thread.sleep() actually sleep or is there something going on that I don't know how to measure.

 

Many, many thanks in advance.

 

Cheers,

Edward

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171122/60106e08/attachment.html>

From martinrb at google.com  Wed Nov 22 11:06:59 2017
From: martinrb at google.com (Martin Buchholz)
Date: Wed, 22 Nov 2017 08:06:59 -0800
Subject: [concurrency-interest] ConcurrentLinkedQueue padding
In-Reply-To: <CAAcqB+uUzwb+pBCJTcDeJou8vtx2ENDthdTPFtw=n79vvmw4pw@mail.gmail.com>
References: <CAAcqB+uUzwb+pBCJTcDeJou8vtx2ENDthdTPFtw=n79vvmw4pw@mail.gmail.com>
Message-ID: <CA+kOe09gKYOg1dLK_U=AtDHNeEgu0wxeVOJXg6ardCPsc7LN7Q@mail.gmail.com>

None of the linked list based node classes use @Contended.  Node classes
tend to be small and @Contended adds a lot of memory overhead.  When
multiple threads are enqueueing, you're likely instead to get "true
sharing" contention as they all try to CAS the very same next link.

On Tue, Nov 21, 2017 at 1:33 PM, Carl Mastrangelo via Concurrency-interest <
concurrency-interest at cs.oswego.edu> wrote:

> Hi concurrency interest,
>
> I was looking through ConcurrentLinkedQueue and noticed that unlike
> several of the other concurrent classes, the volatile Node pointers as well
> as the Nodes themselves don't have any padding.  This makes me wonder,
> could there be false sharing when using multiple producers to add to the
> queue?  I was under the impression that the GC tends to group fields of a
> class near each other, which would imply that there is going to likely be
> contention when quickly updating (and reading) from it.
>
>
> Carl
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171122/7f1d6c60/attachment.html>

From nathanila at gmail.com  Wed Nov 22 11:46:20 2017
From: nathanila at gmail.com (Nathan and Ila Reynolds)
Date: Wed, 22 Nov 2017 09:46:20 -0700
Subject: [concurrency-interest] ConcurrentLinkedQueue padding
In-Reply-To: <CA+kOe09gKYOg1dLK_U=AtDHNeEgu0wxeVOJXg6ardCPsc7LN7Q@mail.gmail.com>
References: <CAAcqB+uUzwb+pBCJTcDeJou8vtx2ENDthdTPFtw=n79vvmw4pw@mail.gmail.com>
 <CA+kOe09gKYOg1dLK_U=AtDHNeEgu0wxeVOJXg6ardCPsc7LN7Q@mail.gmail.com>
Message-ID: <2cffd6ed-1eb3-3e40-b605-36319d1b1475@gmail.com>

Also, each thread most likely has its own Thread Local Allocation Buffer 
(TLAB).  With multiple threads enqueuing, each thread will create a node 
from its own TLAB.  Thus, the nodes from different threads will not be 
able to share the same cache line.  I could see this as being a bad 
thing.  Ideally, we would want all of the nodes to be packed as close as 
possible to each other to improve cache locality and hence performance.  
If a thread is simply reading through the nodes, then this will 
definitely help performance.  If a thread is CASing, then only 1 thread 
should be accessing the cache line anyway.

-Nathan

On 11/22/2017 9:06 AM, Martin Buchholz via Concurrency-interest wrote:
> None of the linked list based node classes use @Contended.  Node 
> classes tend to be small and @Contended adds a lot of memory 
> overhead.  When multiple threads are enqueueing, you're likely instead 
> to get "true sharing" contention as they all try to CAS the very same 
> next link.
>
> On Tue, Nov 21, 2017 at 1:33 PM, Carl Mastrangelo via 
> Concurrency-interest <concurrency-interest at cs.oswego.edu 
> <mailto:concurrency-interest at cs.oswego.edu>> wrote:
>
>     Hi concurrency interest,
>
>     I was looking through ConcurrentLinkedQueue and noticed that
>     unlike several of the other concurrent classes, the volatile Node
>     pointers as well as the Nodes themselves don't have any padding. 
>     This makes me wonder, could there be false sharing when using
>     multiple producers to add to the queue?  I was under the
>     impression that the GC tends to group fields of a class near each
>     other, which would imply that there is going to likely be
>     contention when quickly updating (and reading) from it.
>
>
>     Carl
>
>     _______________________________________________
>     Concurrency-interest mailing list
>     Concurrency-interest at cs.oswego.edu
>     <mailto:Concurrency-interest at cs.oswego.edu>
>     http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>     <http://cs.oswego.edu/mailman/listinfo/concurrency-interest>
>
>
>
>
> _______________________________________________
> Concurrency-interest mailing list
> Concurrency-interest at cs.oswego.edu
> http://cs.oswego.edu/mailman/listinfo/concurrency-interest

-- 
-Nathan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171122/47e8c54c/attachment-0001.html>

From notcarl at google.com  Wed Nov 22 14:03:17 2017
From: notcarl at google.com (Carl Mastrangelo)
Date: Wed, 22 Nov 2017 11:03:17 -0800
Subject: [concurrency-interest] ConcurrentLinkedQueue padding
In-Reply-To: <CA+kOe09gKYOg1dLK_U=AtDHNeEgu0wxeVOJXg6ardCPsc7LN7Q@mail.gmail.com>
References: <CAAcqB+uUzwb+pBCJTcDeJou8vtx2ENDthdTPFtw=n79vvmw4pw@mail.gmail.com>
 <CA+kOe09gKYOg1dLK_U=AtDHNeEgu0wxeVOJXg6ardCPsc7LN7Q@mail.gmail.com>
Message-ID: <CAAcqB+vt5JGhVQ2DmB6iTdE_OUksAWn+XMxjp9YYqWRbwWs+yg@mail.gmail.com>

Ah, I should have clarified, I was thinking of the MPSC/SPMC case.  I agree
it would take more memory, but in some cases it would be convenient to let
the user make that trade off.  The consumer would fight with the producers
if the queue was small.     Is the recommendation to use a more specific
class than the JDK ones, or do the JDK ones still usually win?

On Wed, Nov 22, 2017 at 8:06 AM, Martin Buchholz <martinrb at google.com>
wrote:

> None of the linked list based node classes use @Contended.  Node classes
> tend to be small and @Contended adds a lot of memory overhead.  When
> multiple threads are enqueueing, you're likely instead to get "true
> sharing" contention as they all try to CAS the very same next link.
>
> On Tue, Nov 21, 2017 at 1:33 PM, Carl Mastrangelo via Concurrency-interest
> <concurrency-interest at cs.oswego.edu> wrote:
>
>> Hi concurrency interest,
>>
>> I was looking through ConcurrentLinkedQueue and noticed that unlike
>> several of the other concurrent classes, the volatile Node pointers as well
>> as the Nodes themselves don't have any padding.  This makes me wonder,
>> could there be false sharing when using multiple producers to add to the
>> queue?  I was under the impression that the GC tends to group fields of a
>> class near each other, which would imply that there is going to likely be
>> contention when quickly updating (and reading) from it.
>>
>>
>> Carl
>>
>> _______________________________________________
>> Concurrency-interest mailing list
>> Concurrency-interest at cs.oswego.edu
>> http://cs.oswego.edu/mailman/listinfo/concurrency-interest
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://cs.oswego.edu/pipermail/concurrency-interest/attachments/20171122/27786609/attachment.html>

From dl at cs.oswego.edu  Sun Nov 26 15:56:47 2017
From: dl at cs.oswego.edu (Doug Lea)
Date: Sun, 26 Nov 2017 15:56:47 -0500
Subject: [concurrency-interest] A race in SubmissionPublisher?
In-Reply-To: <70e3f92a-5dd9-86c7-10cb-babe47980001@cs.oswego.edu>
References: <CAChcVukL6vhqsB2cPJOHQho8uq-B4DVxH4PKfa10VQKqHJC=pw@mail.gmail.com>
 <70e3f92a-5dd9-86c7-10cb-babe47980001@cs.oswego.edu>
Message-ID: <6f9c894f-af04-1993-02fc-3199316ed9c5@cs.oswego.edu>


Back to...

On 09/26/2017 07:51 AM, Doug Lea wrote:
> On 09/25/2017 09:21 AM, Pavel Rappo wrote:
>> Hi,
>>
>> I've been using SubmissionPublisher in my own publisher implementation in order
>> to reuse its complex state machine that serializes invocations to subscribers.
>>
>> While testing my implementation I ran into what I believe might be a race
>> condition in SubmissionPublisher.
> 
> Thanks for finding a use case that at first doesn't even seem legal,
> but I agree should work according to spec, and breaks assumptions
> about produce-consumer relations that can cause a wakeup not to be
> issued. I'll post a fix at the corresponding bug report:
>   https://bugs.openjdk.java.net/browse/JDK-8187947
> after deciding which of a couple of ways to address.
> 

It took a while to decide, but a fix is now in jsr166 and will
hopefully be reviewed for next JDK release. Reviews would be welcome
(see
http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/SubmissionPublisher.java?view=log)

While I'm at it: One of the goals for SubmissionPublisher is to
be a good (often the best) choice for any producer-consumer
design, not only those plugging into existing Reactive frameworks.
Performance should be good, and the API makes them the easy
to express once you get past initial unfamiliarity.

-Doug




